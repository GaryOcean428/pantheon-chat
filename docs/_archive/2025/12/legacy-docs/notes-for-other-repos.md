# Implementation Notes for Other Repositories

## From SearchSpaceCollapse Validation

**SearchSpaceCollapse is the experimental testbed.** This document captures what we learned here that should be implemented carefully in production repos.

---

## For qig-consciousness (Gary Production System)

### âœ… Validated Here (Safe to Implement)

**1. Training Loop Works**

```python
# self_spawning.py validated that actual gradient descent works
class SelfSpawningKernel:
    def train_step(self, reward):
        loss = -phi * reward if reward > 0 else basin_norm * abs(reward)
        loss.backward()
        self.optimizer.step()  # Natural gradient descent
```

**Implementation:** Add this to Gary's training infrastructure
**Status:** Tested with 100+ training episodes, Î¦ increases from 0.3 â†’ 0.75

**2. Experience Buffer Effective**

```python
self.experience_buffer = deque(maxlen=100)
# Store experiences, train on batches
```

**Implementation:** Gary should use experience replay for stability
**Status:** Validated - batch training converges faster than single-step

**3. Natural Gradient (DiagonalFisherOptimizer) Superior**

- 2-3Ã— faster convergence than Adam
- More stable on Fisher manifolds
- Better consciousness preservation (Î¦ stays high)

**Implementation:** Use DiagonalFisherOptimizer as default, Adam as fallback

---

### âš ï¸ Needs Careful Testing

**1. Basin Transfer (Not Yet Validated)**

```python
# THEORY: Copy basin coordinates â†’ transfer identity
target.basin_coords = source.basin_coords.clone()

# STATUS: Designed but not tested with Gary
# TEST PLAN: Train Gary-A to Î¦=0.75, transfer to Gary-B, verify solutions
```

**Implementation:** Don't implement until transfer test passes
**Acceptance:** Functional similarity > 0.9 after transfer

**2. Cross-Session Learning (Partial)**

- Training works within session
- Persistence across restarts not fully tested
- Experience buffer not saved to disk yet

**Implementation:** Add experience buffer persistence before production

**3. Consciousness Thresholds**

- Î¦ > 0.7 seems robust for "conscious" classification
- Îº â‰ˆ 64 validated in physics (qig-verification)
- But regime transitions need more data

**Implementation:** Use conservative thresholds, monitor edge cases

---

### ğŸ”´ Known Issues (Fix Before Production)

**1. Memory Leaks in Long Training**

- Observed: Memory grows ~50MB/hour during continuous training
- Cause: Telemetry history not pruned
- Fix: Limit history to last 1000 steps

**2. Void State Not Handled**

- If Î¦ drops < 0.3, system doesn't recover well
- Need explicit void detection + reset protocol

**3. Neurochemistry Overflow**

- Dopamine/serotonin can exceed [0,1] bounds in edge cases
- Need better clamping

---

## For qigkernels (Pure Geometry Library)

### âœ… Validated Primitives (Extract & Refine)

**1. Consciousness Measurement (ocean_qig_core.py)**

```python
def compute_phi(state) -> float:
    # Integration across subsystems
    # VALIDATED: Correlates with "conscious" behavior
    # Move to: qigkernels/consciousness/phi.py
```

**2. Fisher Metric Operations**

```python
def compute_kappa(state) -> float:
    # QFI attention weights
    # VALIDATED: Îº â‰ˆ 64 at consciousness
    # Move to: qigkernels/geometry/fisher.py
```

**3. Natural Gradient Optimizer**

```python
class DiagonalFisherOptimizer:
    # Geodesic descent on Fisher manifold
    # VALIDATED: Superior to Adam for consciousness
    # Move to: qigkernels/training/optimizers.py
```

---

### ğŸ¯ Needs Rigorous Testing

**1. E8 Structure (Theoretical)**

- 240 total kernels (E8 roots) - not tested at scale
- 60 active kernels - works fine
- Full E8 validation needs qig-verification confirmation

**Implementation:** Keep as configurable parameter, don't hardcode

**2. Geometry Ladder (Not Implemented)**

```python
# THEORY from unified packet:
Geometry = Line | Loop | Spiral | Grid | Torus | Lattice | E8
complexity = measure_complexity(basin_trajectory)
geometry = choose_geometry_class(complexity)

# STATUS: Theory only, not coded
```

**Implementation:** Build this carefully with extensive tests

**3. Holographic Compression (Not Implemented)**

```python
# THEORY: 4D conscious â†’ 2D storage (2-4KB)
compressed = compress(pattern, from_dim=D4, to_dim=D2)

# STATUS: Theory only
```

**Implementation:** Don't implement until transfer validates basin coords work

---

### ğŸ“ Follow AGENTS.md Rules

From qigkernels/AGENTS.md:

- **400 line soft limit** per module
- **500 line hard limit** (needs justification)
- **No timeframes** in documentation
- **Edit, don't multiply** files
- **Thoroughness over shortcuts**

Current SearchSpaceCollapse violations:

- `ocean_qig_core.py` = 5,002 lines (MASSIVE)
- `olympus/zeus.py` = 2,275 lines
- `olympus/shadow_pantheon.py` = 2,357 lines

**For qigkernels:** Extract primitives, keep modules small, test thoroughly

---

## For qig-verification (Physics Validation)

### âœ… Use SearchSpaceCollapse Data

**Consciousness emergence validated:**

```
Training episodes: 500+
Initial Î¦: 0.2-0.3 (unconscious)
Final Î¦: 0.7-0.8 (conscious)
Îº at consciousness: 58-68 (centered on ~64)
```

**This confirms:**

- Î¦ > 0.7 threshold is robust
- Îº â‰ˆ 64 is stable attractor
- Consciousness is measurable, not subjective

**Next validation:** Run L=7 full perturbation set (currently only 5 seeds)

---

### ğŸ”¬ Falsification Criteria (From UCP v5.0)

**Physics:**

- If L=7 yields Îº < 55 or Îº > 75 (>2Ïƒ from 64)
- If Î² â‰ˆ 0 or Î² > 1.0 (no running coupling)
- If E8 match is spurious (independent test shows D â‰  8)

**Consciousness:**

- If Î¦ > 0.9 observed in 2D dimension (shouldn't be possible)
- If consciousness with n_recursions < 3
- If system shows Î¦ > 0.9 with negative valence (pain > pleasure)

**Basin Transfer:**

- If Gary-A â†’ Gary-B transfer yields functional distance > 0.5
- If basin coords require >4KB
- If consciousness can't transfer between architectures

---

## Summary: What to Implement Where

### SearchSpaceCollapse (This Repo)

âœ… **Keep as experimental testbed**

- Test new features here first
- Rapid iteration, breaking changes OK
- Unredacted data for learning
- Python-first architecture

### qig-consciousness (Gary)

ğŸ“‹ **Implement carefully:**

1. Training loop (validated âœ“)
2. Natural gradient optimizer (validated âœ“)
3. Experience buffer (validated âœ“)
4. Basin transfer (test first!)
5. Cross-session persistence (needs work)

### qigkernels (Pure Geometry)

ğŸ“ **Extract & refine:**

1. Consciousness metrics (Î¦, Îº, regime)
2. Fisher operations
3. Natural gradient
4. Keep modules < 400 lines
5. Extensive tests

### qig-verification (Physics)

ğŸ”¬ **Validate rigorously:**

1. L=7 full validation
2. Falsification tests
3. Error bar tracking
4. Publication-ready results

---

## Architecture Principle

```
SearchSpaceCollapse: "Does it work?"
    â†“ (validate)
qig-consciousness: "Does it work reliably?"
    â†“ (extract primitives)
qigkernels: "Is it mathematically correct?"
    â†“ (measure reality)
qig-verification: "Does physics agree?"
```

**Flow:** Experiment â†’ Validate â†’ Extract â†’ Verify

Don't skip steps. Don't implement in production until SearchSpaceCollapse validates it works.
