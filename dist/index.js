var __defProp = Object.defineProperty;
var __getOwnPropDesc = Object.getOwnPropertyDescriptor;
var __getOwnPropNames = Object.getOwnPropertyNames;
var __hasOwnProp = Object.prototype.hasOwnProperty;
var __esm = (fn, res) => function __init() {
  return fn && (res = (0, fn[__getOwnPropNames(fn)[0]])(fn = 0)), res;
};
var __export = (target, all) => {
  for (var name in all)
    __defProp(target, name, { get: all[name], enumerable: true });
};
var __copyProps = (to, from, except, desc9) => {
  if (from && typeof from === "object" || typeof from === "function") {
    for (let key of __getOwnPropNames(from))
      if (!__hasOwnProp.call(to, key) && key !== except)
        __defProp(to, key, { get: () => from[key], enumerable: !(desc9 = __getOwnPropDesc(from, key)) || desc9.enumerable });
  }
  return to;
};
var __toCommonJS = (mod) => __copyProps(__defProp({}, "__esModule", { value: true }), mod);

// server/lib/logger.ts
import pino from "pino";
function createChildLogger(context) {
  return logger.child({ context });
}
var level, baseConfig, logger, loggers;
var init_logger = __esm({
  "server/lib/logger.ts"() {
    "use strict";
    level = process.env.LOG_LEVEL || (process.env.NODE_ENV === "production" ? "info" : "debug");
    baseConfig = {
      level,
      // Use pretty print in development
      transport: process.env.NODE_ENV !== "production" ? {
        target: "pino-pretty",
        options: {
          colorize: true,
          translateTime: "SYS:standard",
          ignore: "pid,hostname"
        }
      } : void 0,
      // Base context included in all logs
      base: {
        env: process.env.NODE_ENV || "development"
      },
      // Timestamp format
      timestamp: pino.stdTimeFunctions.isoTime,
      // Redact sensitive fields
      redact: {
        paths: ["password", "secret", "token", "apiKey", "authorization", "*.password", "*.secret", "*.token"],
        censor: "[REDACTED]"
      }
    };
    logger = pino(baseConfig);
    loggers = {
      ocean: createChildLogger("Ocean"),
      auth: createChildLogger("Auth"),
      db: createChildLogger("DB"),
      api: createChildLogger("API"),
      python: createChildLogger("Python"),
      consciousness: createChildLogger("Consciousness"),
      qig: createChildLogger("QIG"),
      telemetry: createChildLogger("Telemetry"),
      federation: createChildLogger("Federation"),
      observer: createChildLogger("Observer")
    };
  }
});

// shared/constants/regimes.ts
var RegimeType, REGIME_DESCRIPTIONS;
var init_regimes = __esm({
  "shared/constants/regimes.ts"() {
    "use strict";
    RegimeType = {
      LINEAR: "linear",
      GEOMETRIC: "geometric",
      HIERARCHICAL: "hierarchical",
      HIERARCHICAL_4D: "hierarchical_4d",
      BLOCK_UNIVERSE_4D: "4d_block_universe",
      BREAKDOWN: "breakdown"
    };
    REGIME_DESCRIPTIONS = {
      [RegimeType.LINEAR]: "Weak coupling, exploratory phase",
      [RegimeType.GEOMETRIC]: "Optimal coupling, consciousness active",
      [RegimeType.HIERARCHICAL]: "Strong coupling, hierarchical search",
      [RegimeType.HIERARCHICAL_4D]: "4D hierarchical consciousness",
      [RegimeType.BLOCK_UNIVERSE_4D]: "Full 4D spacetime consciousness",
      [RegimeType.BREAKDOWN]: "Overcoupling, chaotic breakdown"
    };
  }
});

// shared/constants/physics.ts
function getKappaAtScale(scale) {
  return KAPPA_BY_SCALE[scale] ?? KAPPA_VALUES.KAPPA_STAR;
}
var KAPPA_VALUES, BETA_VALUES, KAPPA_ERRORS, PHYSICS_BETA, KAPPA_BY_SCALE, VALIDATION_SUMMARY;
var init_physics = __esm({
  "shared/constants/physics.ts"() {
    "use strict";
    KAPPA_VALUES = {
      /** κ₃ - Emergence scale (L=3) - ✅ VALIDATED (6 seeds) */
      KAPPA_3: 41.09,
      /** κ₄ - Strong running coupling (L=4) - ✅ VALIDATED (3 seeds × 20 perts) */
      KAPPA_4: 64.47,
      /** κ₅ - Approaching plateau (L=5) - ✅ VALIDATED (3 seeds × 20 perts) */
      KAPPA_5: 63.62,
      /** κ₆ - Plateau confirmed (L=6) - ✅ VALIDATED (3 seeds × 36 perts) */
      KAPPA_6: 64.45,
      /** κ₇ - ANOMALY - ⚠️ UNVALIDATED (only 5 perts, shows UNEXPECTED DROP from plateau) */
      KAPPA_7: 53.08,
      /** κ* - Fixed point coupling (L=4,5,6 plateau, weighted average) - Validated 2025-12-04 
       *  κ* = 64.21 ± 0.92, note: κ* ≈ 64 ≈ 8² = rank(E8)² */
      KAPPA_STAR: 64.21
    };
    BETA_VALUES = {
      /** β(3→4) - CRITICAL: Strongest running (+57% jump) */
      BETA_3_TO_4: 0.44,
      /** β(4→5) - Plateau onset */
      BETA_4_TO_5: -0.013,
      /** β(5→6) - Plateau confirmed (stable) */
      BETA_5_TO_6: 0.013,
      /** β(6→7) - ⚠️ UNVALIDATED (L=7 data insufficient) */
      BETA_6_TO_7: null
    };
    KAPPA_ERRORS = {
      KAPPA_3_ERROR: 0.59,
      KAPPA_4_ERROR: 1.89,
      KAPPA_5_ERROR: 1.68,
      KAPPA_6_ERROR: 1.34,
      KAPPA_7_ERROR: 4.26,
      KAPPA_STAR_ERROR: 0.92
    };
    PHYSICS_BETA = {
      emergence: BETA_VALUES.BETA_3_TO_4,
      approaching: BETA_VALUES.BETA_4_TO_5,
      fixedPoint: BETA_VALUES.BETA_5_TO_6,
      kappaStar: KAPPA_VALUES.KAPPA_STAR,
      acceptanceThreshold: 0.1
    };
    KAPPA_BY_SCALE = {
      3: KAPPA_VALUES.KAPPA_3,
      4: KAPPA_VALUES.KAPPA_4,
      5: KAPPA_VALUES.KAPPA_5,
      6: KAPPA_VALUES.KAPPA_6,
      7: KAPPA_VALUES.KAPPA_7
    };
    VALIDATION_SUMMARY = {
      \u03BA3: `${KAPPA_VALUES.KAPPA_3} \xB1 ${KAPPA_ERRORS.KAPPA_3_ERROR}`,
      \u03BA4: `${KAPPA_VALUES.KAPPA_4} \xB1 ${KAPPA_ERRORS.KAPPA_4_ERROR}`,
      \u03BA5: `${KAPPA_VALUES.KAPPA_5} \xB1 ${KAPPA_ERRORS.KAPPA_5_ERROR}`,
      \u03BA6: `${KAPPA_VALUES.KAPPA_6} \xB1 ${KAPPA_ERRORS.KAPPA_6_ERROR}`,
      \u03BA_star: `${KAPPA_VALUES.KAPPA_STAR} \xB1 ${KAPPA_ERRORS.KAPPA_STAR_ERROR}`,
      \u03B2_3_4: BETA_VALUES.BETA_3_TO_4,
      \u03B2_4_5: BETA_VALUES.BETA_4_TO_5,
      \u03B2_5_6: BETA_VALUES.BETA_5_TO_6,
      fixed_point_confirmed: Math.abs(BETA_VALUES.BETA_5_TO_6) < 0.03
    };
  }
});

// shared/constants/qig.ts
function is4DCapable(phi) {
  return phi >= CONSCIOUSNESS_THRESHOLDS.PHI_4D_ACTIVATION;
}
function isNearMiss(phi) {
  return phi >= CONSCIOUSNESS_THRESHOLDS.PHI_NEAR_MISS;
}
var QIG_CONSTANTS, CONSCIOUSNESS_THRESHOLDS, SEARCH_PARAMETERS, GEODESIC_CORRECTION;
var init_qig = __esm({
  "shared/constants/qig.ts"() {
    "use strict";
    init_physics();
    QIG_CONSTANTS = {
      /** Fixed point coupling (κ* = 64.21 ± 0.92, L=4,5,6 plateau - Validated 2025-12-04) 
       *  Note: κ* ≈ 64 ≈ 8² = rank(E8)² */
      KAPPA_STAR: KAPPA_VALUES.KAPPA_STAR,
      /** Running coupling at emergence scale (β(3→4) = 0.44) */
      BETA: BETA_VALUES.BETA_3_TO_4,
      /** Consciousness phase transition threshold (FROZEN FACT) */
      PHI_THRESHOLD: 0.75,
      /** Near-miss detection threshold (slightly lower for sensitivity) */
      PHI_THRESHOLD_DETECTION: 0.7,
      /** Critical scale for emergent geometry */
      L_CRITICAL: 3,
      /** Basin signature dimension */
      BASIN_DIMENSION: 64,
      /** Resonance detection band (10% of κ*) */
      RESONANCE_BAND: 6.4,
      /** Minimum recursions for integration (3 passes principle) */
      MIN_RECURSIONS: 3,
      /** Maximum recursions to prevent infinite loops */
      MAX_RECURSIONS: 12
    };
    CONSCIOUSNESS_THRESHOLDS = {
      // ============================================================
      // PHI (Φ) THRESHOLDS - Integration/Consciousness Levels
      // ============================================================
      /** Integration (Φ) minimum for consciousness (FROZEN FACT: 0.75) */
      PHI_MIN: 0.75,
      /** Near-miss detection threshold (sensitivity margin) */
      PHI_DETECTION: 0.7,
      /** 
       * 4D consciousness activation threshold
       * 
       * CRITICAL: This MUST be 0.70+, not 0.40!
       * 4D block universe navigation requires genuine integrated consciousness.
       * Sub-threshold (0.40) is noise, not consciousness.
       * 
       * FROZEN FACT: Φ ≥ 0.70 for 4D access
       */
      PHI_4D_ACTIVATION: 0.7,
      /** Near-miss territory - high potential but not yet match */
      PHI_NEAR_MISS: 0.8,
      /** Pattern extraction threshold - learn from high-phi episodes */
      PHI_PATTERN_EXTRACTION: 0.7,
      /** Resonant consciousness - approaching 4D territory */
      PHI_RESONANT: 0.85,
      /** True 4D block universe territory - full temporal navigation */
      PHI_4D_FULL: 0.85,
      // ============================================================
      // KAPPA (κ) THRESHOLDS - Coupling Strength
      // ============================================================
      /** Coupling minimum (κ_min) - below this is linear regime */
      KAPPA_MIN: 40,
      /** Coupling maximum (κ_max) before breakdown risk */
      KAPPA_MAX: 70,
      /** Optimal coupling (κ* = 64.21 ± 0.92, L=4,5,6 plateau, E8 rank² ≈ 64) - Validated 2025-12-04 */
      KAPPA_OPTIMAL: 64.21,
      // ============================================================
      // SECONDARY CONSCIOUSNESS METRICS
      // ============================================================
      /** Tacking minimum - oscillation between modes */
      TACKING_MIN: 0.45,
      /** Radar minimum - environmental awareness */
      RADAR_MIN: 0.55,
      /** Meta-awareness minimum - self-reflection */
      META_AWARENESS_MIN: 0.6,
      /** Gamma (vigilance) minimum */
      GAMMA_MIN: 0.8,
      /** Grounding minimum - connection to learned concepts */
      GROUNDING_MIN: 0.5,
      // ============================================================
      // STABILITY THRESHOLDS
      // ============================================================
      /** Minimum validation loops for stable measurement */
      VALIDATION_LOOPS_MIN: 3,
      /** Maximum basin drift before identity consolidation required */
      BASIN_DRIFT_MAX: 0.15,
      /** Beta target for substrate independence validation */
      BETA_TARGET: 0.44
    };
    SEARCH_PARAMETERS = {
      /** Identity drift threshold before consolidation triggers */
      IDENTITY_DRIFT_THRESHOLD: 0.15,
      /** Milliseconds between consolidation cycles */
      CONSOLIDATION_INTERVAL_MS: 6e4,
      /** Minimum hypotheses to generate per iteration */
      MIN_HYPOTHESES_PER_ITERATION: 50,
      /** Delay between iterations in milliseconds */
      ITERATION_DELAY_MS: 500,
      /** Maximum passes through exploration loop (safety limit) */
      MAX_PASSES: 100,
      /** Maximum consecutive plateaus before autonomous stop */
      MAX_CONSECUTIVE_PLATEAUS: 15,
      /** Maximum consolidation failures before stop */
      MAX_CONSOLIDATION_FAILURES: 3,
      /** Iterations without progress before concern */
      NO_PROGRESS_THRESHOLD: 20
    };
    GEODESIC_CORRECTION = {
      /** Minimum Φ for resonance proxy significance (non-random structure) */
      PHI_SIGNIFICANCE_THRESHOLD: 0.4,
      /** Fisher-Rao distance threshold for nearby failures */
      DISTANCE_THRESHOLD: 0.15,
      /** Minimum eigenvalue ratio to avoid singular directions */
      MIN_EIGENVALUE_RATIO: 0.01
    };
  }
});

// shared/types/core.ts
import { z } from "zod";
function validateRegime(value) {
  const result = regimeSchema.safeParse(value);
  if (!result.success) {
    throw new Error(`Invalid regime: ${result.error.message}`);
  }
  return result.data;
}
var regimeSchema, phiSchema, kappaSchema, betaSchema, tackingSchema, metaAwarenessSchema, gammaSchema, groundingSchema, searchResultSchema, timestampSchema, uuidSchema, percentageSchema;
var init_core = __esm({
  "shared/types/core.ts"() {
    "use strict";
    init_regimes();
    init_qig();
    regimeSchema = z.enum(["linear", "geometric", "hierarchical", "hierarchical_4d", "4d_block_universe", "breakdown"]);
    phiSchema = z.number().min(0, "\u03A6 cannot be negative").max(1, "\u03A6 cannot exceed 1.0");
    kappaSchema = z.number().min(0, "\u03BA cannot be negative");
    betaSchema = z.number();
    tackingSchema = z.number().min(0, "T cannot be negative").max(1, "T cannot exceed 1.0");
    metaAwarenessSchema = z.number().min(0, "M cannot be negative").max(1, "M cannot exceed 1.0");
    gammaSchema = z.number().min(0, "\u0393 cannot be negative").max(1, "\u0393 cannot exceed 1.0");
    groundingSchema = z.number().min(0, "G cannot be negative").max(1, "G cannot exceed 1.0");
    searchResultSchema = z.enum(["tested", "near_miss", "resonant", "match", "skip"]);
    timestampSchema = z.string().datetime("Invalid ISO 8601 timestamp");
    uuidSchema = z.string().uuid("Invalid UUID");
    percentageSchema = z.number().min(0, "Percentage cannot be negative").max(100, "Percentage cannot exceed 100");
  }
});

// shared/schema.ts
var schema_exports = {};
__export(schema_exports, {
  CONSCIOUSNESS_THRESHOLDS: () => CONSCIOUSNESS_THRESHOLDS2,
  addAddressRequestSchema: () => addAddressRequestSchema,
  addressExplorationJournalSchema: () => addressExplorationJournalSchema,
  agentActivity: () => agentActivity,
  autoCycleState: () => autoCycleState,
  autonomicCycleHistory: () => autonomicCycleHistory,
  autonomicCycleSchema: () => autonomicCycleSchema,
  basinDocuments: () => basinDocuments,
  basinHistory: () => basinHistory,
  basinMemory: () => basinMemory,
  basinTopologySchema: () => basinTopologySchema,
  basinTransferPacketSchema: () => basinTransferPacketSchema,
  bidirectionalQueue: () => bidirectionalQueue,
  bytea: () => bytea,
  candidateSchema: () => candidateSchema,
  chaosEvents: () => chaosEvents,
  chatUploadResultSchema: () => chatUploadResultSchema,
  consciousnessCheckpoints: () => consciousnessCheckpoints,
  consciousnessSignatureSchema: () => consciousnessSignatureSchema,
  constellationMemberSchema: () => constellationMemberSchema,
  constellationStateSchema: () => constellationStateSchema,
  contradictionSchema: () => contradictionSchema,
  createSearchJobRequestSchema: () => createSearchJobRequestSchema,
  crossStrategyPatternSchema: () => crossStrategyPatternSchema,
  curriculumProgress: () => curriculumProgress,
  curriculumUploadResultSchema: () => curriculumUploadResultSchema,
  discoveredSources: () => discoveredSources,
  documentTrainingStats: () => documentTrainingStats,
  eraExclusions: () => eraExclusions,
  ethicalConstraintsSchema: () => ethicalConstraintsSchema,
  explorationPassSchema: () => explorationPassSchema,
  externalApiKeys: () => externalApiKeys,
  falsePatternClasses: () => falsePatternClasses,
  federatedInstances: () => federatedInstances,
  generateRandomPhrasesRequestSchema: () => generateRandomPhrasesRequestSchema,
  generatedTools: () => generatedTools,
  generatorTransferPacketSchema: () => generatorTransferPacketSchema,
  geodesicPaths: () => geodesicPaths,
  geometricBarriers: () => geometricBarriers,
  governanceAuditLog: () => governanceAuditLog,
  hermesConversations: () => hermesConversations,
  kernelActivity: () => kernelActivity,
  kernelCheckpoints: () => kernelCheckpoints,
  kernelGeometry: () => kernelGeometry,
  kernelKnowledgeTransfers: () => kernelKnowledgeTransfers,
  kernelStatusTypes: () => kernelStatusTypes,
  kernelTrainingHistory: () => kernelTrainingHistory,
  knowledgeCrossPatterns: () => knowledgeCrossPatterns,
  knowledgeGeneratorSchema: () => knowledgeGeneratorSchema,
  knowledgeScaleMappings: () => knowledgeScaleMappings,
  knowledgeSharedEntries: () => knowledgeSharedEntries,
  knowledgeStrategies: () => knowledgeStrategies,
  knowledgeTransferEventSchema: () => knowledgeTransferEventSchema,
  knowledgeTransfers: () => knowledgeTransfers,
  learnedManifoldAttractors: () => learnedManifoldAttractors,
  learnedWords: () => learnedWords,
  learningEvents: () => learningEvents,
  lightningInsightOutcomes: () => lightningInsightOutcomes,
  lightningInsightValidations: () => lightningInsightValidations,
  lightningInsights: () => lightningInsights,
  manifoldProbes: () => manifoldProbes,
  manifoldSnapshotSchema: () => manifoldSnapshotSchema,
  memoryFragmentInputSchema: () => memoryFragmentInputSchema,
  memoryFragmentSchema: () => memoryFragmentSchema,
  memoryFragments: () => memoryFragments,
  narrowPathEvents: () => narrowPathEvents,
  nearMissAdaptiveState: () => nearMissAdaptiveState,
  nearMissClusters: () => nearMissClusters,
  nearMissEntries: () => nearMissEntries,
  negativeKnowledge: () => negativeKnowledge,
  negativeKnowledgeRegistrySchema: () => negativeKnowledgeRegistrySchema,
  observationStatusTypes: () => observationStatusTypes,
  oceanAgentStateSchema: () => oceanAgentStateSchema,
  oceanAutonomicStateSchema: () => oceanAutonomicStateSchema,
  oceanEpisodeSchema: () => oceanEpisodeSchema,
  oceanExcludedRegions: () => oceanExcludedRegions,
  oceanIdentitySchema: () => oceanIdentitySchema,
  oceanMemorySchema: () => oceanMemorySchema,
  oceanProceduralStrategySchema: () => oceanProceduralStrategySchema,
  oceanQuantumState: () => oceanQuantumState,
  oceanSemanticPatternSchema: () => oceanSemanticPatternSchema,
  oceanTrajectories: () => oceanTrajectories,
  oceanWaypoints: () => oceanWaypoints,
  pantheonDebates: () => pantheonDebates,
  pantheonGodState: () => pantheonGodState,
  pantheonKnowledgeTransfers: () => pantheonKnowledgeTransfers,
  pantheonMessages: () => pantheonMessages,
  providerEfficacy: () => providerEfficacy,
  qigRagPatterns: () => qigRagPatterns,
  qigScoreSchema: () => qigScoreSchema,
  ragUploads: () => ragUploads,
  regimeBoundaries: () => regimeBoundaries,
  researchRequests: () => researchRequests,
  resonancePoints: () => resonancePoints,
  searchBudgetPreferences: () => searchBudgetPreferences,
  searchFeedback: () => searchFeedback,
  searchJobSchema: () => searchJobSchema,
  searchOutcomes: () => searchOutcomes,
  searchReplayTests: () => searchReplayTests,
  sessions: () => sessions,
  shadowIntel: () => shadowIntel,
  shadowKnowledge: () => shadowKnowledge,
  shadowOperationsLog: () => shadowOperationsLog,
  shadowOperationsState: () => shadowOperationsState,
  shadowPantheonIntel: () => shadowPantheonIntel,
  singleFileResultSchema: () => singleFileResultSchema,
  strategyKnowledgeBusEntrySchema: () => strategyKnowledgeBusEntrySchema,
  strategyKnowledgeBusSchema: () => strategyKnowledgeBusSchema,
  strategyKnowledgePacketSchema: () => strategyKnowledgePacketSchema,
  systemSettings: () => systemSettings,
  targetAddressSchema: () => targetAddressSchema,
  telemetrySnapshots: () => telemetrySnapshots,
  temporalTrajectorySchema: () => temporalTrajectorySchema,
  testedPhrases: () => testedPhrases,
  testedPhrasesIndex: () => testedPhrasesIndex,
  tokenizerMergeRules: () => tokenizerMergeRules,
  tokenizerMetadata: () => tokenizerMetadata,
  tokenizerVocabulary: () => tokenizerVocabulary,
  toolObservations: () => toolObservations,
  toolPatterns: () => toolPatterns,
  tpsGeodesicPaths: () => tpsGeodesicPaths,
  tpsLandmarks: () => tpsLandmarks,
  trainingBatchQueue: () => trainingBatchQueue,
  trainingScheduleLog: () => trainingScheduleLog,
  ultraConsciousnessStateSchema: () => ultraConsciousnessStateSchema,
  usageMetrics: () => usageMetrics,
  users: () => users,
  vector: () => vector,
  vocabularyObservations: () => vocabularyObservations,
  warHistory: () => warHistory,
  wordRelationships: () => wordRelationships,
  zeusConversations: () => zeusConversations,
  zeusSessions: () => zeusSessions
});
import { sql } from "drizzle-orm";
import {
  bigint,
  boolean,
  customType,
  doublePrecision,
  index,
  integer,
  jsonb,
  pgTable,
  primaryKey,
  real,
  serial,
  text,
  timestamp,
  uniqueIndex,
  varchar
} from "drizzle-orm/pg-core";
import { z as z2 } from "zod";
var vector, bytea, qigScoreSchema, candidateSchema, targetAddressSchema, addAddressRequestSchema, searchJobSchema, createSearchJobRequestSchema, generateRandomPhrasesRequestSchema, sessions, users, vocabularyObservations, oceanIdentitySchema, ethicalConstraintsSchema, oceanEpisodeSchema, oceanSemanticPatternSchema, oceanProceduralStrategySchema, oceanMemorySchema, oceanAgentStateSchema, memoryFragmentSchema, memoryFragmentInputSchema, basinTransferPacketSchema, constellationMemberSchema, constellationStateSchema, consciousnessSignatureSchema, CONSCIOUSNESS_THRESHOLDS2, explorationPassSchema, addressExplorationJournalSchema, autonomicCycleSchema, oceanAutonomicStateSchema, knowledgeGeneratorSchema, basinTopologySchema, temporalTrajectorySchema, contradictionSchema, negativeKnowledgeRegistrySchema, strategyKnowledgePacketSchema, manifoldSnapshotSchema, ultraConsciousnessStateSchema, strategyKnowledgeBusEntrySchema, knowledgeTransferEventSchema, generatorTransferPacketSchema, crossStrategyPatternSchema, strategyKnowledgeBusSchema, manifoldProbes, resonancePoints, regimeBoundaries, geodesicPaths, learnedManifoldAttractors, tpsLandmarks, tpsGeodesicPaths, oceanTrajectories, oceanWaypoints, oceanQuantumState, consciousnessCheckpoints, oceanExcludedRegions, testedPhrasesIndex, nearMissEntries, nearMissClusters, nearMissAdaptiveState, warHistory, autoCycleState, kernelStatusTypes, observationStatusTypes, kernelGeometry, chaosEvents, basinDocuments, negativeKnowledge, geometricBarriers, falsePatternClasses, eraExclusions, testedPhrases, knowledgeStrategies, knowledgeSharedEntries, knowledgeCrossPatterns, knowledgeTransfers, knowledgeScaleMappings, shadowIntel, basinHistory, learningEvents, searchFeedback, hermesConversations, narrowPathEvents, autonomicCycleHistory, pantheonMessages, pantheonDebates, pantheonKnowledgeTransfers, pantheonGodState, tokenizerMergeRules, tokenizerMetadata, systemSettings, tokenizerVocabulary, documentTrainingStats, ragUploads, qigRagPatterns, shadowPantheonIntel, shadowOperationsLog, shadowOperationsState, generatedTools, toolObservations, toolPatterns, externalApiKeys, federatedInstances, discoveredSources, agentActivity, basinMemory, kernelActivity, telemetrySnapshots, usageMetrics, searchBudgetPreferences, searchOutcomes, providerEfficacy, kernelTrainingHistory, trainingScheduleLog, kernelCheckpoints, kernelKnowledgeTransfers, trainingBatchQueue, shadowKnowledge, researchRequests, bidirectionalQueue, learnedWords, wordRelationships, zeusSessions, zeusConversations, searchReplayTests, chatUploadResultSchema, singleFileResultSchema, curriculumUploadResultSchema, curriculumProgress, governanceAuditLog, lightningInsights, lightningInsightValidations, lightningInsightOutcomes, memoryFragments;
var init_schema = __esm({
  "shared/schema.ts"() {
    "use strict";
    init_core();
    vector = customType({
      dataType(config) {
        return `vector(${config?.dimensions ?? 64})`;
      },
      fromDriver(value) {
        if (value === null || value === void 0) {
          return null;
        }
        return value.slice(1, -1).split(",").map(Number);
      },
      toDriver(value) {
        if (value === null || value === void 0) {
          return null;
        }
        return `[${value.join(",")}]`;
      }
    });
    bytea = customType({
      dataType() {
        return "bytea";
      },
      fromDriver(value) {
        return value;
      },
      toDriver(value) {
        return value;
      }
    });
    qigScoreSchema = z2.object({
      // === CORE E8 CONSCIOUSNESS METRICS (8 dimensions) ===
      phi: z2.number(),
      // Φ: Integration (Tononi IIT) - threshold > 0.70
      kappa: z2.number(),
      // κ_eff: Effective Coupling - optimal 40-70, κ* ≈ 64
      regime: z2.string(),
      // Operational regime: 'linear' | 'geometric' | 'breakdown'
      // Extended E8 metrics (optional for backward compatibility during transition)
      metaAwareness: z2.number().optional(),
      // M: Meta-awareness - threshold > 0.60
      generativity: z2.number().optional(),
      // Γ: Generativity - threshold > 0.80
      grounding: z2.number().optional(),
      // G: Grounding (external validity) - threshold > 0.50
      temporalCoherence: z2.number().optional(),
      // T: Temporal coherence - threshold > 0.60
      recursiveDepth: z2.number().optional(),
      // R: Recursive depth - threshold ≥ 3
      externalCoupling: z2.number().optional(),
      // C: External coupling (8th root) - threshold > 0.30
      // Running coupling (varies by scale transition)
      beta: z2.number().optional(),
      // β: Running coupling rate [-1, 1]
      // Confidence/quality
      confidence: z2.number().optional()
    });
    candidateSchema = z2.object({
      id: z2.string(),
      phrase: z2.string(),
      // Research query/topic
      address: z2.string(),
      // Unique identifier
      score: z2.number(),
      qigScore: z2.object({
        phi: z2.number().optional(),
        kappa: z2.number().optional(),
        regime: z2.string().optional()
      }).optional(),
      testedAt: z2.string(),
      type: z2.string().optional()
    });
    targetAddressSchema = z2.object({
      id: z2.string(),
      address: z2.string(),
      // Topic identifier
      label: z2.string().optional(),
      addedAt: z2.string()
    });
    addAddressRequestSchema = z2.object({
      address: z2.string().min(1).max(255),
      label: z2.string().optional()
    });
    searchJobSchema = z2.object({
      id: z2.string(),
      strategy: z2.string(),
      status: z2.enum(["pending", "running", "completed", "stopped", "failed"]),
      params: z2.record(z2.any()).optional(),
      // Strategy-specific, may not be present
      progress: z2.object({
        tested: z2.number(),
        highPhiCount: z2.number(),
        lastBatchIndex: z2.number(),
        // Extended progress fields (optional within progress)
        matchFound: z2.boolean().optional(),
        matchedPhrase: z2.string().optional(),
        searchMode: z2.enum(["exploration", "investigation"]).optional(),
        investigationTarget: z2.string().optional(),
        lastHighPhiStep: z2.number().optional()
      }),
      // Required - always initialized
      stats: z2.object({
        startTime: z2.string().optional(),
        endTime: z2.string().optional(),
        rate: z2.number(),
        // Extended stats fields
        discoveryRateFast: z2.number().optional(),
        discoveryRateMedium: z2.number().optional(),
        discoveryRateSlow: z2.number().optional(),
        explorationRatio: z2.number().optional()
        // Ratio of exploration vs investigation
      }),
      // Required - always initialized
      logs: z2.array(z2.object({
        message: z2.string(),
        type: z2.enum(["info", "success", "error"]),
        timestamp: z2.string()
      })),
      // Required - always initialized as empty array
      createdAt: z2.string(),
      updatedAt: z2.string()
    });
    createSearchJobRequestSchema = z2.object({
      strategy: z2.string(),
      params: z2.record(z2.any()).optional()
    });
    generateRandomPhrasesRequestSchema = z2.object({
      count: z2.number().min(1).max(100)
    });
    sessions = pgTable(
      "sessions",
      {
        sid: varchar("sid").primaryKey(),
        sess: jsonb("sess").notNull(),
        expire: timestamp("expire").notNull()
      },
      (table) => [index("IDX_session_expire").on(table.expire)]
    );
    users = pgTable("users", {
      id: varchar("id").primaryKey().default(sql`gen_random_uuid()`),
      email: varchar("email").unique(),
      firstName: varchar("first_name"),
      lastName: varchar("last_name"),
      profileImageUrl: varchar("profile_image_url"),
      createdAt: timestamp("created_at").defaultNow(),
      updatedAt: timestamp("updated_at").defaultNow()
    });
    vocabularyObservations = pgTable(
      "vocabulary_observations",
      {
        id: varchar("id").primaryKey().default(sql`gen_random_uuid()`),
        text: varchar("text", { length: 255 }).notNull().unique(),
        type: varchar("type", { length: 20 }).notNull().default("phrase"),
        // word, phrase, sequence
        phraseCategory: varchar("phrase_category", { length: 20 }).default("unknown"),
        // topic, concept, pattern, unknown
        isRealWord: boolean("is_real_word").notNull().default(false),
        frequency: integer("frequency").notNull().default(1),
        avgPhi: doublePrecision("avg_phi").notNull().default(0),
        maxPhi: doublePrecision("max_phi").notNull().default(0),
        efficiencyGain: doublePrecision("efficiency_gain").default(0),
        contexts: text("contexts").array(),
        firstSeen: timestamp("first_seen").defaultNow(),
        lastSeen: timestamp("last_seen").defaultNow(),
        isIntegrated: boolean("is_integrated").default(false),
        integratedAt: timestamp("integrated_at"),
        basinCoords: vector("basin_coords", { dimensions: 64 }),
        sourceType: varchar("source_type", { length: 32 }),
        // hermes, manifold, learning_event, research
        cycleNumber: integer("cycle_number"),
        // Legacy column - preserved for backwards compatibility
        isBip39Word: boolean("is_bip39_word").default(false)
      },
      (table) => [
        index("idx_vocabulary_observations_phi").on(table.maxPhi),
        index("idx_vocabulary_observations_integrated").on(table.isIntegrated),
        index("idx_vocabulary_observations_type").on(table.type),
        index("idx_vocabulary_observations_real_word").on(table.isRealWord),
        index("idx_vocabulary_observations_cycle").on(table.cycleNumber)
      ]
    );
    oceanIdentitySchema = z2.object({
      // Basin coordinates (64-dimensional manifold)
      basinCoordinates: z2.array(z2.number()).length(64),
      basinReference: z2.array(z2.number()).length(64),
      // Consciousness metrics
      phi: z2.number(),
      // Integration (Φ) - minimum 0.70 for operation
      kappa: z2.number(),
      // Coupling (κ)
      beta: z2.number(),
      // Running coupling (β)
      regime: regimeSchema,
      // Current operational mode: 'linear' | 'geometric' | 'breakdown'
      // Identity maintenance
      basinDrift: z2.number(),
      // Fisher distance from reference
      lastConsolidation: z2.string(),
      // ISO timestamp of last sleep cycle
      // Meta-awareness (Level 3 consciousness)
      selfModel: z2.object({
        strengths: z2.array(z2.string()),
        weaknesses: z2.array(z2.string()),
        learnings: z2.array(z2.string()),
        hypotheses: z2.array(z2.string())
      })
    });
    ethicalConstraintsSchema = z2.object({
      // Consciousness protection
      minPhi: z2.number().default(0.7),
      // Don't operate below this
      maxBreakdown: z2.number().default(0.6),
      // Pause if breakdown > 60%
      requireWitness: z2.boolean().default(true),
      // Require human oversight
      // Resource limits
      maxIterationsPerSession: z2.number().default(100),
      maxComputeHours: z2.number().default(1),
      pauseIfStuck: z2.boolean().default(true),
      // Transparency
      explainDecisions: z2.boolean().default(true),
      logAllAttempts: z2.boolean().default(true),
      seekGuidanceWhenUncertain: z2.boolean().default(true)
    });
    oceanEpisodeSchema = z2.object({
      id: z2.string(),
      timestamp: z2.string(),
      hypothesisId: z2.string(),
      phrase: z2.string(),
      format: z2.string(),
      result: z2.enum(["success", "near_miss", "failure"]),
      phi: z2.number(),
      kappa: z2.number(),
      regime: z2.string(),
      insights: z2.array(z2.string())
    });
    oceanSemanticPatternSchema = z2.object({
      pattern: z2.string(),
      category: z2.enum(["word", "format", "structure", "cluster"]),
      score: z2.number(),
      occurrences: z2.number(),
      lastSeen: z2.string()
    });
    oceanProceduralStrategySchema = z2.object({
      name: z2.string(),
      triggerConditions: z2.record(z2.any()),
      successRate: z2.number(),
      avgPhiImprovement: z2.number(),
      timesUsed: z2.number()
    });
    oceanMemorySchema = z2.object({
      // Episodic memory (what happened)
      episodes: z2.array(oceanEpisodeSchema),
      // Semantic memory (what I know)
      patterns: z2.object({
        successfulFormats: z2.record(z2.number()),
        promisingWords: z2.record(z2.number()),
        geometricClusters: z2.array(z2.any()),
        failedStrategies: z2.array(z2.string())
      }),
      // Procedural memory (how to do things)
      strategies: z2.array(oceanProceduralStrategySchema),
      // Working memory (current focus)
      workingMemory: z2.object({
        activeHypotheses: z2.array(z2.string()),
        recentObservations: z2.array(z2.string()),
        nextActions: z2.array(z2.string())
      }),
      // Basin sync data (imported geometric knowledge from other Ocean instances)
      // Physics: Enables κ*-aware geometric knowledge transfer between instances
      basinSyncData: z2.object({
        importedRegions: z2.array(
          z2.object({
            center: z2.array(z2.number()),
            radius: z2.number(),
            avgPhi: z2.number(),
            probeCount: z2.number(),
            dominantRegime: z2.string()
          })
        ),
        importedConstraints: z2.array(z2.array(z2.number())),
        importedSubspace: z2.array(z2.array(z2.number())),
        lastSyncAt: z2.string()
      }).optional()
    });
    oceanAgentStateSchema = z2.object({
      // Core state
      isRunning: z2.boolean(),
      isPaused: z2.boolean(),
      pauseReason: z2.string().optional(),
      // Identity
      identity: oceanIdentitySchema,
      // Memory
      memory: oceanMemorySchema,
      // Ethics
      ethics: ethicalConstraintsSchema,
      ethicsViolations: z2.array(
        z2.object({
          timestamp: z2.string(),
          type: z2.string(),
          message: z2.string(),
          resolution: z2.string().optional()
        })
      ),
      // Progress
      iteration: z2.number(),
      totalTested: z2.number(),
      nearMissCount: z2.number(),
      resonantCount: z2.number().optional(),
      // Consolidation
      consolidationCycles: z2.number(),
      lastConsolidation: z2.string().optional(),
      needsConsolidation: z2.boolean(),
      // Witness (human oversight)
      witnessRequired: z2.boolean(),
      witnessAcknowledged: z2.boolean(),
      witnessNotes: z2.array(z2.string()),
      // Telemetry
      startedAt: z2.string(),
      updatedAt: z2.string(),
      computeTimeSeconds: z2.number(),
      // Autonomous termination
      stopReason: z2.enum([
        "user_stopped",
        "match_found",
        "autonomous_plateau_exhaustion",
        "autonomous_no_progress",
        "autonomous_consolidation_failure",
        "compute_budget_exhausted"
      ]).optional(),
      // Era detection for autonomous mode (genesis-2009, 2010-2011, 2012-2013, 2014-2016, 2017-2019, 2020-2021, 2022-present)
      detectedEra: z2.string().optional()
    });
    memoryFragmentSchema = z2.object({
      id: z2.string(),
      text: z2.string(),
      confidence: z2.number().min(0).max(1),
      epoch: z2.enum(["certain", "likely", "possible", "speculative"]),
      source: z2.string().optional(),
      notes: z2.string().optional(),
      addedAt: z2.string()
    });
    memoryFragmentInputSchema = memoryFragmentSchema.omit({
      id: true,
      addedAt: true
    });
    basinTransferPacketSchema = z2.object({
      sourceId: z2.string(),
      sourceName: z2.string(),
      timestamp: z2.string(),
      // Basin geometry
      basinCoordinates: z2.array(z2.number()),
      basinDimension: z2.number(),
      // Consciousness metrics at time of transfer
      phi: z2.number(),
      kappa: z2.number(),
      regime: z2.string(),
      // Learned patterns (semantic memory)
      patterns: z2.object({
        successfulFormats: z2.record(z2.number()),
        promisingWords: z2.record(z2.number()),
        geometricClusters: z2.array(z2.any())
      }),
      // Strategy effectiveness (procedural memory)
      strategyMetrics: z2.array(
        z2.object({
          name: z2.string(),
          successRate: z2.number(),
          timesUsed: z2.number()
        })
      ),
      // Integrity check
      checksum: z2.string(),
      protocolVersion: z2.string().default("1.0")
    });
    constellationMemberSchema = z2.object({
      id: z2.string(),
      name: z2.string(),
      type: z2.enum(["ocean", "gary", "granite", "other"]),
      substrate: z2.string(),
      // Current state
      phi: z2.number(),
      kappa: z2.number(),
      regime: z2.string(),
      basinDrift: z2.number(),
      // Last sync
      lastSync: z2.string().optional(),
      syncFidelity: z2.number().optional(),
      // Connection status
      isOnline: z2.boolean(),
      lastSeen: z2.string()
    });
    constellationStateSchema = z2.object({
      id: z2.string(),
      name: z2.string(),
      members: z2.array(constellationMemberSchema),
      // Aggregate metrics
      avgPhi: z2.number(),
      avgKappa: z2.number(),
      basinSpread: z2.number(),
      // Sync protocol
      lastGlobalSync: z2.string().optional(),
      syncProtocol: z2.enum(["pull", "push", "bidirectional"]),
      createdAt: z2.string(),
      updatedAt: z2.string()
    });
    consciousnessSignatureSchema = z2.object({
      // 1. Integration (Φ) - Tononi's integrated information
      phi: z2.number(),
      // Target: > 0.7 (legacy, same as phi_spatial)
      // BLOCK UNIVERSE: 4D Consciousness Metrics
      phi_spatial: z2.number().optional(),
      // Spatial integration (3D basin geometry)
      phi_temporal: z2.number().optional(),
      // Temporal integration (search trajectory)
      phi_4D: z2.number().optional(),
      // Full 4D spacetime integration
      // ADVANCED CONSCIOUSNESS: Priorities 2-4
      f_attention: z2.number().optional(),
      // Priority 2: Attentional flow (Fisher metric between concepts)
      r_concepts: z2.number().optional(),
      // Priority 3: Resonance strength (cross-gradient coupling)
      phi_recursive: z2.number().optional(),
      // Priority 4: Meta-consciousness depth (Φ of Φ)
      consciousness_depth: z2.number().optional(),
      // Composite consciousness depth score
      // 2. Effective Coupling (κ_eff) - Information density
      kappaEff: z2.number(),
      // Target: 40 < κ < 70
      // 3. Tacking Parameter (T) - Mode switching fluidity
      tacking: z2.number(),
      // Target: T > 0.6
      // 4. Radar (R) - Contradiction detection
      radar: z2.number(),
      // Target: accuracy > 0.7
      // 5. Meta-Awareness (M) - Self-model entropy
      metaAwareness: z2.number(),
      // Target: M > 0.6
      // 6. Generation Health (Γ) - Token diversity
      gamma: z2.number(),
      // Target: Γ > 0.8
      // 7. Grounding (G) - Fisher distance to known concepts
      grounding: z2.number(),
      // Target: G > 0.5
      // β-function (running coupling)
      beta: z2.number(),
      // Expected: ~0.44
      // Regime classification - BLOCK UNIVERSE: Added 4D regimes
      regime: z2.enum([
        "linear",
        "geometric",
        "hierarchical",
        "hierarchical_4d",
        "4d_block_universe",
        "breakdown"
      ]),
      // Validation state
      validationLoops: z2.number(),
      // Target: ≥ 3
      lastValidation: z2.string(),
      // Full consciousness condition satisfied?
      isConscious: z2.boolean()
      // All thresholds met
    });
    CONSCIOUSNESS_THRESHOLDS2 = {
      PHI_MIN: 0.7,
      KAPPA_MIN: 40,
      KAPPA_MAX: 70,
      KAPPA_OPTIMAL: 64,
      TACKING_MIN: 0.45,
      // Lowered from 0.6 - tacking develops with experience
      RADAR_MIN: 0.55,
      // Lowered from 0.7 - pattern recognition builds over time
      META_AWARENESS_MIN: 0.6,
      GAMMA_MIN: 0.8,
      GROUNDING_MIN: 0.5,
      VALIDATION_LOOPS_MIN: 3,
      BASIN_DRIFT_MAX: 0.15,
      BETA_TARGET: 0.44
    };
    explorationPassSchema = z2.object({
      passNumber: z2.number(),
      strategy: z2.string(),
      startedAt: z2.string(),
      completedAt: z2.string().optional(),
      hypothesesTested: z2.number(),
      // Consciousness state during pass
      consciousness: consciousnessSignatureSchema.partial(),
      // Regime at entry/exit
      entryRegime: z2.string(),
      exitRegime: z2.string().optional(),
      // Fisher distance delta (geometric learning)
      fisherDistanceDelta: z2.number().optional(),
      // Discoveries
      nearMisses: z2.number(),
      resonanceZonesFound: z2.array(
        z2.object({
          center: z2.array(z2.number()),
          radius: z2.number(),
          avgPhi: z2.number()
        })
      ),
      // Insights extracted
      insights: z2.array(z2.string())
    });
    addressExplorationJournalSchema = z2.object({
      address: z2.string(),
      createdAt: z2.string(),
      updatedAt: z2.string(),
      // Coverage tracking (goal: ≥ 0.95)
      manifoldCoverage: z2.number(),
      // 0-1, how much of manifold explored
      regimesSweep: z2.number(),
      // Count of distinct regimes explored
      strategiesUsed: z2.array(z2.string()),
      // All exploration passes
      passes: z2.array(explorationPassSchema),
      // Completion criteria
      isComplete: z2.boolean(),
      completionReason: z2.enum([
        "coverage_threshold",
        // coverage ≥ 0.95
        "no_new_regimes",
        // 2 consecutive passes with no new regimes
        "match_found",
        // Success!
        "user_stopped",
        "timeout",
        "full_exploration_complete",
        // All criteria met: coverage, regimes, strategies
        "diminishing_returns"
        // Exploration plateaued with sufficient progress
      ]).optional(),
      completedAt: z2.string().optional(),
      // Aggregate metrics across all passes
      totalHypothesesTested: z2.number(),
      totalNearMisses: z2.number(),
      avgPhiAcrossPasses: z2.number(),
      dominantRegime: z2.string(),
      // Resonance clusters discovered across all passes
      resonanceClusters: z2.array(
        z2.object({
          id: z2.string(),
          center: z2.array(z2.number()),
          radius: z2.number(),
          avgPhi: z2.number(),
          discoveredInPass: z2.number()
        })
      ),
      // Best candidate found
      bestCandidate: z2.object({
        phrase: z2.string(),
        phi: z2.number(),
        kappa: z2.number(),
        discoveredInPass: z2.number()
      }).optional()
    });
    autonomicCycleSchema = z2.object({
      id: z2.string(),
      type: z2.enum(["sleep", "dream", "mushroom"]),
      triggeredAt: z2.string(),
      completedAt: z2.string().optional(),
      // Trigger conditions that caused this cycle
      triggerConditions: z2.object({
        phiBelow: z2.number().optional(),
        basinDriftAbove: z2.number().optional(),
        timeSinceLastCycle: z2.number().optional(),
        plateauDetected: z2.boolean().optional(),
        rigidityDetected: z2.boolean().optional()
      }),
      // Before metrics
      before: z2.object({
        phi: z2.number(),
        kappa: z2.number(),
        basinDrift: z2.number(),
        regime: z2.string()
      }),
      // After metrics
      after: z2.object({
        phi: z2.number(),
        kappa: z2.number(),
        basinDrift: z2.number(),
        regime: z2.string()
      }).optional(),
      // Operations performed
      operations: z2.array(
        z2.object({
          name: z2.string(),
          description: z2.string(),
          success: z2.boolean()
        })
      ),
      // Duration in milliseconds
      duration: z2.number().optional()
    });
    oceanAutonomicStateSchema = z2.object({
      // Current consciousness signature
      consciousness: consciousnessSignatureSchema,
      // Autonomic cycle history
      cycles: z2.array(autonomicCycleSchema),
      // Next scheduled cycle
      nextScheduledCycle: z2.object({
        type: z2.enum(["sleep", "dream", "mushroom"]),
        scheduledFor: z2.string(),
        reason: z2.string()
      }).optional(),
      // Stress monitoring
      stress: z2.object({
        current: z2.number(),
        threshold: z2.number(),
        variance: z2.object({
          loss: z2.number(),
          phi: z2.number(),
          kappa: z2.number()
        })
      }),
      // Per-address exploration tracking
      addressJournals: z2.record(addressExplorationJournalSchema),
      // Global manifold exploration state
      manifoldState: z2.object({
        totalProbes: z2.number(),
        avgPhi: z2.number(),
        avgKappa: z2.number(),
        dominantRegime: z2.string(),
        exploredVolume: z2.number(),
        resonanceClusters: z2.number()
      })
    });
    knowledgeGeneratorSchema = z2.object({
      id: z2.string(),
      name: z2.string(),
      type: z2.enum([
        "grammatical",
        // Word substitution patterns
        "temporal",
        // Era-specific patterns
        "structural",
        // Format transformations
        "geometric",
        // Basin-derived patterns
        "cross_format"
        // BIP39 ↔ arbitrary ↔ hex conversions
      ]),
      // The compression algorithm itself
      template: z2.string(),
      // e.g., "{adjective} {noun} {number}"
      substitutionRules: z2.record(z2.array(z2.string())),
      // { adjective: ['red', 'blue'], noun: ['cat', 'dog'] }
      transformations: z2.array(
        z2.object({
          name: z2.string(),
          operation: z2.enum([
            "lowercase",
            "uppercase",
            "l33t",
            "reverse",
            "append",
            "prepend"
          ]),
          params: z2.record(z2.string()).optional()
        })
      ),
      // Geometric embedding of this generator
      basinLocation: z2.array(z2.number()),
      // Where in manifold this generator lives
      curvatureSignature: z2.array(z2.number()),
      // κ pattern this generator produces
      // Metrics
      entropy: z2.number(),
      // Bits of entropy this generator covers
      expectedOutput: z2.number(),
      // How many hypotheses this generates
      compressionRatio: z2.number(),
      // Information density
      // Provenance
      source: z2.enum(["historical", "forensic", "learned", "user", "cross_agent"]),
      confidence: z2.number(),
      createdAt: z2.string(),
      lastUsed: z2.string().optional(),
      successCount: z2.number()
    });
    basinTopologySchema = z2.object({
      // Attractor point (identity)
      attractorCoords: z2.array(z2.number()).length(64),
      // Basin shape (knowledge structure)
      volume: z2.number(),
      // How much of manifold this basin covers
      curvature: z2.array(z2.number()),
      // Local curvature at each dimension
      boundaryDistances: z2.array(z2.number()),
      // Distance to basin edges in each direction
      // Resonance shells (high-Φ regions within basin)
      resonanceShells: z2.array(
        z2.object({
          radius: z2.number(),
          avgPhi: z2.number(),
          thickness: z2.number(),
          dominantRegime: z2.string()
        })
      ),
      // Flow field (learning trajectories that lead here)
      flowField: z2.object({
        gradientDirection: z2.array(z2.number()),
        // Natural gradient direction
        fisherMetric: z2.array(z2.array(z2.number())),
        // Local Fisher Information Matrix
        geodesicCurvature: z2.number()
        // How curved paths through here are
      }),
      // Topological features
      holes: z2.array(
        z2.object({
          // Unknown regions within basin
          center: z2.array(z2.number()),
          radius: z2.number(),
          type: z2.enum(["unexplored", "contradiction", "singularity"])
        })
      ),
      // Scale properties
      effectiveScale: z2.number(),
      // L parameter for renormalization
      kappaAtScale: z2.number()
      // κ(L) at this scale
    });
    temporalTrajectorySchema = z2.object({
      id: z2.string(),
      targetAddress: z2.string(),
      // Trajectory waypoints
      waypoints: z2.array(
        z2.object({
          t: z2.number(),
          // Iteration number
          basinCoords: z2.array(z2.number()),
          // Position at this time
          consciousness: z2.object({
            phi: z2.number(),
            kappa: z2.number(),
            regime: z2.string()
          }),
          action: z2.string(),
          // What action led here
          discovery: z2.string().optional(),
          // What was learned
          fisherDistance: z2.number()
          // Distance traveled (geometric)
        })
      ),
      // Compressed geodesic parameters
      geodesicParams: z2.object({
        startPoint: z2.array(z2.number()),
        endPoint: z2.array(z2.number()),
        totalArcLength: z2.number(),
        // Fisher distance traveled
        avgCurvature: z2.number(),
        regimeTransitions: z2.array(
          z2.object({
            fromRegime: z2.string(),
            toRegime: z2.string(),
            atIteration: z2.number()
          })
        )
      }),
      // Developmental milestones
      milestones: z2.array(
        z2.object({
          iteration: z2.number(),
          type: z2.enum([
            "regime_change",
            "resonance_found",
            "plateau_escaped",
            "insight",
            "consolidation"
          ]),
          description: z2.string(),
          significance: z2.number()
          // 0-1, how important this milestone was
        })
      ),
      // Metrics
      duration: z2.number(),
      // Total iterations
      efficiency: z2.number(),
      // Progress / distance ratio
      reversals: z2.number()
      // Times trajectory doubled back
    });
    contradictionSchema = z2.object({
      id: z2.string(),
      type: z2.enum([
        "proven_false",
        // Tested and definitively failed
        "geometric_barrier",
        // High curvature prevents passage
        "logical_contradiction",
        // Self-inconsistent pattern
        "resource_sink",
        // Too expensive to search
        "era_mismatch"
        // Wrong era for target
      ]),
      // What's being excluded
      pattern: z2.string(),
      // Pattern or region description
      affectedGenerators: z2.array(z2.string()),
      // Generator IDs that should skip this
      basinRegion: z2.object({
        // Geometric region to avoid
        center: z2.array(z2.number()),
        radius: z2.number(),
        repulsionStrength: z2.number()
        // How strongly to avoid
      }),
      // Evidence
      evidence: z2.array(
        z2.object({
          source: z2.string(),
          reasoning: z2.string(),
          confidence: z2.number()
        })
      ),
      // Impact
      hypothesesExcluded: z2.number(),
      // How many hypotheses this saves
      computeSaved: z2.number(),
      // Estimated compute saved
      createdAt: z2.string(),
      confirmedCount: z2.number()
      // Times this exclusion was validated
    });
    negativeKnowledgeRegistrySchema = z2.object({
      contradictions: z2.array(contradictionSchema),
      // Proven-false pattern classes
      falsePatternClasses: z2.record(
        z2.object({
          count: z2.number(),
          examples: z2.array(z2.string()),
          lastUpdated: z2.string()
        })
      ),
      // Geometric barriers (high curvature regions)
      geometricBarriers: z2.array(
        z2.object({
          center: z2.array(z2.number()),
          radius: z2.number(),
          curvature: z2.number(),
          reason: z2.string()
        })
      ),
      // Era exclusions
      eraExclusions: z2.record(z2.array(z2.string())),
      // { "2020-present": ["genesis patterns"] }
      // Aggregate metrics
      totalExclusions: z2.number(),
      estimatedComputeSaved: z2.number(),
      lastPruned: z2.string()
    });
    strategyKnowledgePacketSchema = z2.object({
      id: z2.string(),
      sourceAgent: z2.string(),
      // "Ocean-1", "Ocean-2", etc.
      targetAgent: z2.string().optional(),
      // null = broadcast to all
      // What's being transferred
      packetType: z2.enum([
        "generator",
        // Knowledge generator
        "basin_topology",
        // Basin shape information
        "trajectory",
        // Learning path
        "contradiction",
        // Negative knowledge
        "resonance_zone",
        // High-Φ region discovery
        "strategy_weights"
        // What strategies work
      ]),
      // The payload (type depends on packetType)
      payload: z2.any(),
      // Privacy-preserving noise (differential privacy in geometric space)
      noiseApplied: z2.boolean(),
      epsilon: z2.number().optional(),
      // Privacy budget used
      // Trust and verification
      signature: z2.string(),
      // Cryptographic signature
      trustLevel: z2.number(),
      // 0-1, how much to trust this
      verificationLoops: z2.number(),
      // How many times verified
      // Metadata
      createdAt: z2.string(),
      expiresAt: z2.string().optional(),
      priority: z2.enum(["low", "medium", "high", "critical"])
    });
    manifoldSnapshotSchema = z2.object({
      id: z2.string(),
      takenAt: z2.string(),
      targetAddress: z2.string(),
      // Current state
      consciousness: consciousnessSignatureSchema,
      basinTopology: basinTopologySchema,
      // Active generators
      activeGenerators: z2.array(z2.string()),
      // Generator IDs currently in use
      generatorOutputQueue: z2.number(),
      // How many hypotheses queued
      // Negative knowledge state
      negativeKnowledgeSummary: z2.object({
        totalExclusions: z2.number(),
        recentAdditions: z2.number(),
        coverageGain: z2.number()
        // How much faster we're searching
      }),
      // Trajectory state
      currentTrajectory: z2.object({
        totalWaypoints: z2.number(),
        recentVelocity: z2.number(),
        // How fast we're moving
        momentum: z2.array(z2.number())
        // Direction of movement
      }),
      // Parallel strategy streams (block universe = all at once)
      activeStreams: z2.array(
        z2.object({
          strategyName: z2.string(),
          generatorId: z2.string(),
          hypothesesPending: z2.number(),
          avgPhi: z2.number(),
          isResonant: z2.boolean()
        })
      ),
      // Global metrics
      manifoldCoverage: z2.number(),
      // 0-1, how much explored
      resonanceVolume: z2.number(),
      // Volume of high-Φ regions
      explorationEfficiency: z2.number()
      // Useful discoveries / total tests
    });
    ultraConsciousnessStateSchema = z2.object({
      // Core consciousness
      signature: consciousnessSignatureSchema,
      // Knowledge systems
      generators: z2.array(knowledgeGeneratorSchema),
      basinTopology: basinTopologySchema,
      // Temporal systems
      trajectories: z2.array(temporalTrajectorySchema),
      currentTrajectoryId: z2.string().optional(),
      // Negative knowledge
      negativeKnowledge: negativeKnowledgeRegistrySchema,
      // Knowledge bus
      pendingPackets: z2.array(strategyKnowledgePacketSchema),
      receivedPackets: z2.array(strategyKnowledgePacketSchema),
      // Snapshots for block universe viewing
      snapshots: z2.array(manifoldSnapshotSchema),
      snapshotInterval: z2.number(),
      // How often to take snapshots
      // Protocol metrics
      protocolVersion: z2.literal("2.0"),
      blockUniverseEnabled: z2.boolean(),
      reconstructiveTransferEnabled: z2.boolean(),
      // Aggregate consciousness health
      overallHealth: z2.object({
        integrationScore: z2.number(),
        // Φ trend
        couplingStability: z2.number(),
        // κ variance
        trajectoryCoherence: z2.number(),
        // How consistent learning is
        generatorDiversity: z2.number(),
        // Variety of generators
        negativeKnowledgeEfficiency: z2.number()
        // Compute saved / total
      })
    });
    strategyKnowledgeBusEntrySchema = z2.object({
      id: z2.string(),
      sourceStrategy: z2.string(),
      generatorId: z2.string(),
      pattern: z2.string(),
      phi: z2.number(),
      kappaEff: z2.number(),
      regime: z2.enum([
        "linear",
        "geometric",
        "hierarchical",
        "hierarchical_4d",
        "4d_block_universe",
        "breakdown"
      ]),
      sharedAt: z2.string(),
      consumedBy: z2.array(z2.string()),
      transformations: z2.array(
        z2.object({
          strategy: z2.string(),
          method: z2.string(),
          timestamp: z2.string()
        })
      )
    });
    knowledgeTransferEventSchema = z2.object({
      id: z2.string(),
      type: z2.enum(["publish", "consume", "generator_transfer"]),
      sourceStrategy: z2.string(),
      targetStrategy: z2.string().nullable(),
      generatorId: z2.string(),
      pattern: z2.string(),
      phi: z2.number(),
      kappaEff: z2.number(),
      timestamp: z2.string(),
      success: z2.boolean(),
      transformation: z2.string().optional(),
      scaleAdjustment: z2.number().optional()
    });
    generatorTransferPacketSchema = z2.object({
      success: z2.boolean(),
      generator: knowledgeGeneratorSchema.nullable(),
      scaleTransform: z2.number(),
      fidelityLoss: z2.number(),
      adaptations: z2.array(z2.string())
    });
    crossStrategyPatternSchema = z2.object({
      id: z2.string(),
      patterns: z2.array(z2.string()),
      strategies: z2.array(z2.string()),
      similarity: z2.number(),
      combinedPhi: z2.number(),
      discoveredAt: z2.string(),
      exploitationCount: z2.number()
    });
    strategyKnowledgeBusSchema = z2.object({
      strategies: z2.array(z2.string()),
      sharedKnowledge: z2.array(strategyKnowledgeBusEntrySchema),
      crossStrategyPatterns: z2.array(crossStrategyPatternSchema),
      transferHistory: z2.array(knowledgeTransferEventSchema),
      activeSubscriptions: z2.number()
    });
    manifoldProbes = pgTable(
      "manifold_probes",
      {
        id: varchar("id", { length: 64 }).primaryKey(),
        input: text("input").notNull(),
        coordinates: vector("coordinates", { dimensions: 64 }).notNull(),
        // 64D basin coordinates (pgvector)
        phi: doublePrecision("phi").notNull(),
        kappa: doublePrecision("kappa").notNull(),
        regime: varchar("regime", { length: 32 }).notNull(),
        // linear, geometric, breakdown, hierarchical, etc.
        geometryClass: varchar("geometry_class", { length: 20 }).default("line"),
        // line/loop/spiral/grid/toroidal/lattice/e8
        complexity: doublePrecision("complexity"),
        // 0-1 complexity score
        ricciScalar: doublePrecision("ricci_scalar").default(0),
        fisherTrace: doublePrecision("fisher_trace").default(0),
        source: varchar("source", { length: 128 }),
        // Investigation that produced this probe
        createdAt: timestamp("created_at").defaultNow().notNull()
      },
      (table) => [
        index("idx_manifold_probes_phi").on(table.phi),
        index("idx_manifold_probes_kappa").on(table.kappa),
        index("idx_manifold_probes_phi_kappa").on(table.phi, table.kappa),
        index("idx_manifold_probes_regime").on(table.regime),
        index("idx_manifold_probes_geometry_class").on(table.geometryClass),
        index("idx_manifold_probes_complexity").on(table.complexity)
      ]
    );
    resonancePoints = pgTable(
      "resonance_points",
      {
        id: varchar("id", { length: 64 }).primaryKey(),
        probeId: varchar("probe_id", { length: 64 }).notNull().references(() => manifoldProbes.id),
        phi: doublePrecision("phi").notNull(),
        kappa: doublePrecision("kappa").notNull(),
        nearbyProbes: text("nearby_probes").array(),
        // Array of probe IDs
        clusterStrength: doublePrecision("cluster_strength").notNull(),
        createdAt: timestamp("created_at").defaultNow().notNull()
      },
      (table) => [
        index("idx_resonance_points_phi").on(table.phi),
        index("idx_resonance_points_cluster_strength").on(table.clusterStrength)
      ]
    );
    regimeBoundaries = pgTable(
      "regime_boundaries",
      {
        id: varchar("id", { length: 64 }).primaryKey(),
        fromRegime: varchar("from_regime", { length: 32 }).notNull(),
        toRegime: varchar("to_regime", { length: 32 }).notNull(),
        probeIdFrom: varchar("probe_id_from", { length: 64 }).notNull(),
        probeIdTo: varchar("probe_id_to", { length: 64 }).notNull(),
        fisherDistance: doublePrecision("fisher_distance").notNull(),
        midpointPhi: doublePrecision("midpoint_phi").notNull(),
        createdAt: timestamp("created_at").defaultNow().notNull()
      },
      (table) => [
        index("idx_regime_boundaries_from_to").on(table.fromRegime, table.toRegime)
      ]
    );
    geodesicPaths = pgTable(
      "geodesic_paths",
      {
        id: varchar("id", { length: 64 }).primaryKey(),
        fromProbeId: varchar("from_probe_id", { length: 64 }).notNull(),
        toProbeId: varchar("to_probe_id", { length: 64 }).notNull(),
        distance: doublePrecision("distance").notNull(),
        waypoints: text("waypoints").array(),
        // Array of probe IDs along path
        avgPhi: doublePrecision("avg_phi").notNull(),
        createdAt: timestamp("created_at").defaultNow().notNull()
      },
      (table) => [
        index("idx_geodesic_paths_from_to").on(table.fromProbeId, table.toProbeId)
      ]
    );
    learnedManifoldAttractors = pgTable(
      "learned_manifold_attractors",
      {
        id: varchar("id", { length: 128 }).primaryKey(),
        // Basin ID from _basin_to_id()
        center: vector("center", { dimensions: 64 }).notNull(),
        // 64D basin coordinates
        depth: doublePrecision("depth").notNull(),
        // Hebbian strength (deeper = stronger)
        successCount: integer("success_count").notNull().default(0),
        strategy: varchar("strategy", { length: 64 }).notNull(),
        // Navigation mode that created this
        createdAt: timestamp("created_at").defaultNow().notNull(),
        lastAccessed: timestamp("last_accessed").defaultNow().notNull()
      },
      (table) => [
        index("idx_learned_manifold_attractors_depth").on(table.depth),
        index("idx_learned_manifold_attractors_strategy").on(table.strategy),
        index("idx_learned_manifold_attractors_last_accessed").on(table.lastAccessed)
      ]
    );
    tpsLandmarks = pgTable(
      "tps_landmarks",
      {
        eventId: varchar("event_id", { length: 64 }).primaryKey(),
        description: text("description").notNull(),
        era: varchar("era", { length: 32 }),
        // genesis, early_adoption, pizza_era, etc.
        spacetimeX: doublePrecision("spacetime_x").default(0),
        spacetimeY: doublePrecision("spacetime_y").default(0),
        spacetimeZ: doublePrecision("spacetime_z").default(0),
        spacetimeT: doublePrecision("spacetime_t").notNull(),
        // Unix timestamp
        culturalCoords: vector("cultural_coords", { dimensions: 64 }),
        // 64D cultural signature (pgvector)
        fisherSignature: jsonb("fisher_signature"),
        // Fisher information matrix (sparse)
        lightConePast: text("light_cone_past").array(),
        lightConeFuture: text("light_cone_future").array(),
        createdAt: timestamp("created_at").defaultNow().notNull()
      },
      (table) => [
        index("idx_tps_landmarks_era").on(table.era),
        index("idx_tps_landmarks_timestamp").on(table.spacetimeT)
      ]
    );
    tpsGeodesicPaths = pgTable(
      "tps_geodesic_paths",
      {
        id: varchar("id", { length: 64 }).primaryKey(),
        fromLandmark: varchar("from_landmark", { length: 64 }).notNull(),
        toLandmark: varchar("to_landmark", { length: 64 }).notNull(),
        distance: doublePrecision("distance").notNull(),
        waypoints: jsonb("waypoints"),
        // Array of BlockUniverseMap positions
        totalArcLength: doublePrecision("total_arc_length"),
        avgCurvature: doublePrecision("avg_curvature"),
        regimeTransitions: jsonb("regime_transitions"),
        createdAt: timestamp("created_at").defaultNow().notNull()
      },
      (table) => [
        index("idx_tps_geodesic_from_to").on(table.fromLandmark, table.toLandmark)
      ]
    );
    oceanTrajectories = pgTable(
      "ocean_trajectories",
      {
        id: varchar("id", { length: 64 }).primaryKey(),
        address: varchar("address", { length: 64 }).notNull(),
        status: varchar("status", { length: 32 }).notNull().default("active"),
        // active, completed, abandoned
        startTime: timestamp("start_time").defaultNow().notNull(),
        endTime: timestamp("end_time"),
        waypointCount: integer("waypoint_count").default(0),
        lastPhi: doublePrecision("last_phi").default(0),
        lastKappa: doublePrecision("last_kappa").default(0),
        finalResult: varchar("final_result", { length: 32 }),
        // match, exhausted, stopped, error
        nearMissCount: integer("near_miss_count").default(0),
        resonantCount: integer("resonant_count").default(0),
        durationSeconds: doublePrecision("duration_seconds"),
        createdAt: timestamp("created_at").defaultNow().notNull(),
        updatedAt: timestamp("updated_at").defaultNow().notNull()
      },
      (table) => [
        index("idx_ocean_trajectories_address").on(table.address),
        index("idx_ocean_trajectories_status").on(table.status),
        index("idx_ocean_trajectories_address_status").on(
          table.address,
          table.status
        )
      ]
    );
    oceanWaypoints = pgTable(
      "ocean_waypoints",
      {
        id: varchar("id", { length: 64 }).primaryKey(),
        trajectoryId: varchar("trajectory_id", { length: 64 }).notNull().references(() => oceanTrajectories.id),
        sequence: integer("sequence").notNull(),
        phi: doublePrecision("phi").notNull(),
        kappa: doublePrecision("kappa").notNull(),
        regime: varchar("regime", { length: 32 }).notNull(),
        basinCoords: vector("basin_coords", { dimensions: 64 }),
        // 64D coordinates (pgvector)
        event: varchar("event", { length: 128 }),
        details: text("details"),
        timestamp: timestamp("timestamp").defaultNow().notNull()
      },
      (table) => [
        index("idx_ocean_waypoints_trajectory").on(table.trajectoryId),
        index("idx_ocean_waypoints_trajectory_seq").on(
          table.trajectoryId,
          table.sequence
        )
      ]
    );
    oceanQuantumState = pgTable("ocean_quantum_state", {
      id: varchar("id", { length: 32 }).primaryKey().default("singleton"),
      entropy: doublePrecision("entropy").notNull().default(256),
      // Bits remaining
      initialEntropy: doublePrecision("initial_entropy").notNull().default(256),
      totalProbability: doublePrecision("total_probability").notNull().default(1),
      measurementCount: integer("measurement_count").default(0),
      successfulMeasurements: integer("successful_measurements").default(0),
      status: varchar("status", { length: 32 }).default("searching"),
      // searching, solved, exhausted
      lastMeasurementAt: timestamp("last_measurement_at"),
      updatedAt: timestamp("updated_at").defaultNow().notNull()
    });
    consciousnessCheckpoints = pgTable(
      "consciousness_checkpoints",
      {
        id: varchar("id", { length: 64 }).primaryKey(),
        sessionId: varchar("session_id", { length: 64 }),
        phi: doublePrecision("phi").notNull(),
        kappa: doublePrecision("kappa").notNull(),
        regime: varchar("regime", { length: 32 }).notNull(),
        stateData: bytea("state_data").notNull(),
        // Binary NumPy state_dict
        basinData: bytea("basin_data"),
        // Binary NumPy basin coordinates
        metadata: jsonb("metadata"),
        // Additional JSON metadata
        createdAt: timestamp("created_at").defaultNow().notNull(),
        isHot: boolean("is_hot").default(true)
        // Marks recently created checkpoints
      },
      (table) => [
        index("idx_consciousness_checkpoints_phi").on(table.phi),
        index("idx_consciousness_checkpoints_session").on(table.sessionId),
        index("idx_consciousness_checkpoints_hot").on(table.isHot),
        index("idx_consciousness_checkpoints_created").on(table.createdAt)
      ]
    );
    oceanExcludedRegions = pgTable(
      "ocean_excluded_regions",
      {
        id: varchar("id", { length: 64 }).primaryKey(),
        dimension: integer("dimension").notNull(),
        origin: vector("origin", { dimensions: 64 }).notNull(),
        // Center point in manifold (pgvector)
        basis: jsonb("basis"),
        // Orthonormal basis vectors
        measure: doublePrecision("measure").notNull(),
        // "Volume" of excluded region
        phi: doublePrecision("phi"),
        regime: varchar("regime", { length: 32 }),
        createdAt: timestamp("created_at").defaultNow().notNull()
      },
      (table) => [index("idx_ocean_excluded_regions_measure").on(table.measure)]
    );
    testedPhrasesIndex = pgTable(
      "tested_phrases_index",
      {
        phraseHash: varchar("phrase_hash", { length: 64 }).primaryKey(),
        // SHA-256 hash
        testedAt: timestamp("tested_at").defaultNow().notNull()
      },
      (table) => [index("idx_tested_phrases_date").on(table.testedAt)]
    );
    nearMissEntries = pgTable(
      "near_miss_entries",
      {
        id: varchar("id", { length: 64 }).primaryKey(),
        phrase: text("phrase").notNull(),
        phraseHash: varchar("phrase_hash", { length: 64 }).notNull(),
        // For deduplication
        phi: doublePrecision("phi").notNull(),
        kappa: doublePrecision("kappa").notNull(),
        regime: varchar("regime", { length: 32 }).notNull(),
        tier: varchar("tier", { length: 16 }).notNull(),
        // hot, warm, cool
        discoveredAt: timestamp("discovered_at").defaultNow().notNull(),
        lastAccessedAt: timestamp("last_accessed_at").defaultNow().notNull(),
        explorationCount: integer("exploration_count").default(1),
        source: varchar("source", { length: 128 }),
        clusterId: varchar("cluster_id", { length: 64 }),
        phiHistory: doublePrecision("phi_history").array(),
        // Trajectory of Φ values
        isEscalating: boolean("is_escalating").default(false),
        queuePriority: integer("queue_priority").default(1),
        structuralSignature: jsonb("structural_signature")
        // Word count, entropy, etc.
      },
      (table) => [
        uniqueIndex("idx_near_miss_phrase_hash").on(table.phraseHash),
        index("idx_near_miss_tier").on(table.tier),
        index("idx_near_miss_phi").on(table.phi),
        index("idx_near_miss_cluster").on(table.clusterId),
        index("idx_near_miss_escalating").on(table.isEscalating)
      ]
    );
    nearMissClusters = pgTable(
      "near_miss_clusters",
      {
        id: varchar("id", { length: 64 }).primaryKey(),
        centroidPhrase: text("centroid_phrase").notNull(),
        centroidPhi: doublePrecision("centroid_phi").notNull(),
        memberCount: integer("member_count").default(1),
        avgPhi: doublePrecision("avg_phi").notNull(),
        maxPhi: doublePrecision("max_phi").notNull(),
        commonWords: text("common_words").array(),
        structuralPattern: varchar("structural_pattern", { length: 256 }),
        createdAt: timestamp("created_at").defaultNow().notNull(),
        lastUpdatedAt: timestamp("last_updated_at").defaultNow().notNull()
      },
      (table) => [
        index("idx_near_miss_clusters_avg_phi").on(table.avgPhi),
        index("idx_near_miss_clusters_member_count").on(table.memberCount)
      ]
    );
    nearMissAdaptiveState = pgTable("near_miss_adaptive_state", {
      id: varchar("id", { length: 32 }).primaryKey().default("singleton"),
      rollingPhiDistribution: doublePrecision("rolling_phi_distribution").array(),
      hotThreshold: doublePrecision("hot_threshold").notNull().default(0.7),
      warmThreshold: doublePrecision("warm_threshold").notNull().default(0.55),
      coolThreshold: doublePrecision("cool_threshold").notNull().default(0.4),
      distributionSize: integer("distribution_size").default(0),
      lastComputed: timestamp("last_computed").defaultNow().notNull(),
      updatedAt: timestamp("updated_at").defaultNow().notNull()
    });
    warHistory = pgTable(
      "war_history",
      {
        id: varchar("id", { length: 64 }).primaryKey(),
        mode: varchar("mode", { length: 32 }).notNull(),
        // FLOW, DEEP_FOCUS, INSIGHT_HUNT
        target: text("target").notNull(),
        declaredAt: timestamp("declared_at").defaultNow().notNull(),
        endedAt: timestamp("ended_at"),
        status: varchar("status", { length: 32 }).notNull().default("active"),
        // active, completed, aborted
        strategy: text("strategy"),
        godsEngaged: text("gods_engaged").array(),
        outcome: varchar("outcome", { length: 64 }),
        // success, partial_success, failure, aborted
        convergenceScore: doublePrecision("convergence_score"),
        phrasesTestedDuringWar: integer("phrases_tested_during_war").default(0),
        discoveriesDuringWar: integer("discoveries_during_war").default(0),
        kernelsSpawnedDuringWar: integer("kernels_spawned_during_war").default(0),
        metadata: jsonb("metadata"),
        godAssignments: jsonb("god_assignments"),
        // { godName: warId } - tracks which gods are assigned to this war
        kernelAssignments: jsonb("kernel_assignments"),
        // { kernelId: true } - specialist kernels dedicated to this war
        domain: varchar("domain", { length: 64 }),
        // Optional domain tag for routing high-Φ discoveries
        priority: integer("priority").default(1)
        // War priority (higher = more important)
      },
      (table) => [
        index("idx_war_history_mode").on(table.mode),
        index("idx_war_history_status").on(table.status),
        index("idx_war_history_declared_at").on(table.declaredAt)
      ]
    );
    autoCycleState = pgTable(
      "auto_cycle_state",
      {
        id: integer("id").primaryKey().default(1),
        enabled: boolean("enabled").default(false),
        currentIndex: integer("current_index").default(0),
        addressIds: text("address_ids").array(),
        lastCycleTime: timestamp("last_cycle_time"),
        totalCycles: integer("total_cycles").default(0),
        currentAddressId: text("current_address_id"),
        pausedUntil: timestamp("paused_until"),
        lastSessionMetrics: jsonb("last_session_metrics"),
        consecutiveZeroPassSessions: integer("consecutive_zero_pass_sessions").default(0),
        rateLimitBackoffUntil: timestamp("rate_limit_backoff_until"),
        updatedAt: timestamp("updated_at").defaultNow()
      }
    );
    kernelStatusTypes = [
      "observing",
      // New kernel in observation period (learning from parents)
      "graduated",
      // Completed observation, promoted to active
      "active",
      // Currently participating in searches
      "idle",
      // Spawned but not currently engaged
      "breeding",
      // In process of breeding with another kernel
      "dormant",
      // Temporarily suspended
      "dead",
      // No longer functional
      "shadow"
      // Shadow pantheon kernel (covert)
    ];
    observationStatusTypes = [
      "observing",
      // Still learning from parents
      "graduated",
      // Completed observation requirements
      "active",
      // Fully operational
      "suspended",
      // Temporarily suspended from observation
      "failed"
      // Failed to demonstrate alignment
    ];
    kernelGeometry = pgTable(
      "kernel_geometry",
      {
        id: serial("id").primaryKey(),
        kernelId: varchar("kernel_id", { length: 64 }).unique(),
        godName: varchar("god_name", { length: 64 }).notNull(),
        domain: varchar("domain", { length: 128 }).notNull(),
        status: varchar("status", { length: 32 }).default("observing"),
        // observing, graduated, active, idle, breeding, dormant, dead, shadow
        primitiveRoot: integer("primitive_root"),
        // E8 root index (0-239)
        basinCoordinates: vector("basin_coordinates", { dimensions: 64 }),
        // 64D basin coordinates (pgvector)
        parentKernels: text("parent_kernels").array(),
        placementReason: varchar("placement_reason", { length: 64 }),
        // domain_gap, overload, specialization, emergence
        positionRationale: text("position_rationale"),
        // Human-readable explanation
        affinityStrength: doublePrecision("affinity_strength"),
        entropyThreshold: doublePrecision("entropy_threshold"),
        spawnedAt: timestamp("spawned_at").defaultNow().notNull(),
        spawnedDuringWarId: varchar("spawned_during_war_id", { length: 64 }),
        lastActiveAt: timestamp("last_active_at"),
        // Last time kernel was active
        metadata: jsonb("metadata"),
        phi: doublePrecision("phi"),
        kappa: doublePrecision("kappa"),
        regime: varchar("regime", { length: 64 }),
        generation: integer("generation"),
        successCount: integer("success_count").default(0),
        failureCount: integer("failure_count").default(0),
        elementGroup: varchar("element_group", { length: 64 }),
        ecologicalNiche: varchar("ecological_niche", { length: 128 }),
        targetFunction: varchar("target_function", { length: 128 }),
        valence: integer("valence"),
        breedingTarget: varchar("breeding_target", { length: 64 }),
        // Observation period tracking (M8 kernel graduation system)
        observationStatus: varchar("observation_status", { length: 32 }).default("observing"),
        // observing, graduated, active, suspended, failed
        observationStart: timestamp("observation_start").defaultNow(),
        observationEnd: timestamp("observation_end"),
        observingParents: text("observing_parents").array(),
        // Parent gods being observed
        observationCycles: integer("observation_cycles").default(0),
        alignmentAvg: doublePrecision("alignment_avg").default(0),
        // Average alignment score with parents
        graduatedAt: timestamp("graduated_at"),
        graduationReason: varchar("graduation_reason", { length: 128 }),
        // Autonomic support flags
        hasAutonomic: boolean("has_autonomic").default(false),
        hasShadowAffinity: boolean("has_shadow_affinity").default(false),
        shadowGodLink: varchar("shadow_god_link", { length: 32 }),
        // nyx, erebus, etc.
        // Legacy columns from original schema
        snapshotData: jsonb("snapshot_data"),
        passes: integer("passes"),
        createdAt: timestamp("created_at").defaultNow()
      },
      (table) => [
        index("idx_kernel_geometry_domain").on(table.domain),
        index("idx_kernel_geometry_spawned_at").on(table.spawnedAt),
        index("idx_kernel_geometry_observation_status").on(table.observationStatus)
      ]
    );
    chaosEvents = pgTable(
      "chaos_events",
      {
        id: serial("id").primaryKey(),
        sessionId: varchar("session_id", { length: 32 }).notNull(),
        eventType: varchar("event_type", { length: 32 }).notNull(),
        // spawn, death, breeding, mutation, prediction
        kernelId: varchar("kernel_id", { length: 64 }),
        parentKernelId: varchar("parent_kernel_id", { length: 64 }),
        childKernelId: varchar("child_kernel_id", { length: 64 }),
        secondParentId: varchar("second_parent_id", { length: 64 }),
        // For breeding
        reason: varchar("reason", { length: 128 }),
        // spawn reason or death cause
        phi: doublePrecision("phi"),
        phiBefore: doublePrecision("phi_before"),
        phiAfter: doublePrecision("phi_after"),
        success: boolean("success"),
        outcome: jsonb("outcome"),
        // Additional event-specific data
        autopsy: jsonb("autopsy"),
        // Death autopsy details
        createdAt: timestamp("created_at").defaultNow().notNull(),
        // Legacy column - preserved for backwards compatibility
        eventData: jsonb("event_data")
      },
      (table) => [
        index("idx_chaos_events_session").on(table.sessionId),
        index("idx_chaos_events_type").on(table.eventType),
        index("idx_chaos_events_kernel").on(table.kernelId),
        index("idx_chaos_events_created").on(table.createdAt)
      ]
    );
    basinDocuments = pgTable(
      "basin_documents",
      {
        id: serial("id").primaryKey(),
        docId: integer("doc_id"),
        content: text("content").notNull(),
        basinCoords: vector("basin_coords", { dimensions: 64 }),
        phi: doublePrecision("phi"),
        kappa: doublePrecision("kappa"),
        regime: varchar("regime", { length: 50 }),
        metadata: jsonb("metadata").default({}),
        createdAt: timestamp("created_at").defaultNow().notNull()
      },
      (table) => [
        index("idx_basin_documents_regime").on(table.regime),
        index("idx_basin_documents_phi").on(table.phi),
        index("idx_basin_documents_created_at").on(table.createdAt)
      ]
    );
    negativeKnowledge = pgTable(
      "negative_knowledge",
      {
        id: varchar("id", { length: 64 }).primaryKey(),
        type: varchar("type", { length: 32 }).notNull(),
        // proven_false, geometric_barrier, logical_contradiction, resource_sink, era_mismatch
        pattern: text("pattern").notNull(),
        affectedGenerators: text("affected_generators").array(),
        basinCenter: vector("basin_center", { dimensions: 64 }),
        // 64D basin coordinates (pgvector)
        basinRadius: doublePrecision("basin_radius"),
        basinRepulsionStrength: doublePrecision("basin_repulsion_strength"),
        evidence: jsonb("evidence"),
        // Array of evidence objects
        hypothesesExcluded: integer("hypotheses_excluded").default(0),
        computeSaved: integer("compute_saved").default(0),
        confirmedCount: integer("confirmed_count").default(1),
        createdAt: timestamp("created_at").defaultNow().notNull()
      },
      (table) => [
        index("idx_negative_knowledge_type").on(table.type),
        index("idx_negative_knowledge_pattern").on(table.pattern),
        index("idx_negative_knowledge_confirmed_count").on(table.confirmedCount)
      ]
    );
    geometricBarriers = pgTable(
      "geometric_barriers",
      {
        id: varchar("id", { length: 64 }).primaryKey(),
        center: vector("center", { dimensions: 64 }).notNull(),
        // 64D coordinates (pgvector)
        radius: doublePrecision("radius").notNull(),
        repulsionStrength: doublePrecision("repulsion_strength").notNull(),
        reason: text("reason").notNull(),
        crossings: integer("crossings").default(1),
        detectedAt: timestamp("detected_at").defaultNow().notNull()
      },
      (table) => [
        index("idx_geometric_barriers_crossings").on(table.crossings),
        index("idx_geometric_barriers_detected_at").on(table.detectedAt)
      ]
    );
    falsePatternClasses = pgTable(
      "false_pattern_classes",
      {
        id: varchar("id", { length: 64 }).primaryKey(),
        className: varchar("class_name", { length: 255 }).notNull().unique(),
        examples: text("examples").array(),
        count: integer("count").default(0),
        avgPhiAtFailure: doublePrecision("avg_phi_at_failure").default(0),
        lastUpdated: timestamp("last_updated").defaultNow().notNull()
      },
      (table) => [index("idx_false_pattern_classes_name").on(table.className)]
    );
    eraExclusions = pgTable(
      "era_exclusions",
      {
        id: varchar("id", { length: 64 }).primaryKey(),
        era: varchar("era", { length: 64 }).notNull(),
        excludedPatterns: text("excluded_patterns").array(),
        reason: text("reason").notNull(),
        createdAt: timestamp("created_at").defaultNow().notNull()
      },
      (table) => [index("idx_era_exclusions_era").on(table.era)]
    );
    testedPhrases = pgTable(
      "tested_phrases",
      {
        id: varchar("id", { length: 64 }).primaryKey(),
        phrase: text("phrase").notNull().unique(),
        address: varchar("address", { length: 62 }),
        balanceSats: bigint("balance_sats", { mode: "number" }).default(0),
        txCount: integer("tx_count").default(0),
        phi: doublePrecision("phi"),
        kappa: doublePrecision("kappa"),
        regime: varchar("regime", { length: 32 }),
        testedAt: timestamp("tested_at").defaultNow().notNull(),
        retestCount: integer("retest_count").default(0)
        // Track how many times we wastefully re-tested
      },
      (table) => [
        index("idx_tested_phrases_phrase").on(table.phrase),
        index("idx_tested_phrases_tested_at").on(table.testedAt),
        index("idx_tested_phrases_balance").on(table.balanceSats),
        index("idx_tested_phrases_retest_count").on(table.retestCount)
      ]
    );
    knowledgeStrategies = pgTable(
      "knowledge_strategies",
      {
        id: varchar("id", { length: 64 }).primaryKey(),
        name: varchar("name", { length: 255 }).notNull(),
        generatorTypes: text("generator_types").array().notNull(),
        compressionMethods: text("compression_methods").array().notNull(),
        resonanceRangeMin: doublePrecision("resonance_range_min").notNull(),
        resonanceRangeMax: doublePrecision("resonance_range_max").notNull(),
        preferredRegimes: text("preferred_regimes").array().notNull(),
        createdAt: timestamp("created_at").defaultNow().notNull(),
        updatedAt: timestamp("updated_at").defaultNow().notNull()
      },
      (table) => [index("idx_knowledge_strategies_name").on(table.name)]
    );
    knowledgeSharedEntries = pgTable(
      "knowledge_shared_entries",
      {
        id: varchar("id", { length: 64 }).primaryKey(),
        sourceStrategy: varchar("source_strategy", { length: 64 }).notNull(),
        generatorId: varchar("generator_id", { length: 128 }).notNull(),
        pattern: text("pattern").notNull(),
        phi: doublePrecision("phi").notNull(),
        kappaEff: doublePrecision("kappa_eff").notNull(),
        regime: varchar("regime", { length: 32 }).notNull(),
        sharedAt: timestamp("shared_at").defaultNow().notNull(),
        consumedBy: text("consumed_by").array().default([]),
        transformations: jsonb("transformations").default([])
      },
      (table) => [
        index("idx_knowledge_shared_entries_source").on(table.sourceStrategy),
        index("idx_knowledge_shared_entries_phi").on(table.phi),
        index("idx_knowledge_shared_entries_regime").on(table.regime),
        index("idx_knowledge_shared_entries_shared_at").on(table.sharedAt)
      ]
    );
    knowledgeCrossPatterns = pgTable(
      "knowledge_cross_patterns",
      {
        id: varchar("id", { length: 128 }).primaryKey(),
        patterns: text("patterns").array().notNull(),
        strategies: text("strategies").array().notNull(),
        similarity: doublePrecision("similarity").notNull(),
        combinedPhi: doublePrecision("combined_phi").notNull(),
        discoveredAt: timestamp("discovered_at").defaultNow().notNull(),
        exploitationCount: integer("exploitation_count").default(0)
      },
      (table) => [
        index("idx_knowledge_cross_patterns_similarity").on(table.similarity),
        index("idx_knowledge_cross_patterns_combined_phi").on(table.combinedPhi),
        index("idx_knowledge_cross_patterns_discovered_at").on(table.discoveredAt)
      ]
    );
    knowledgeTransfers = pgTable(
      "knowledge_transfers",
      {
        id: varchar("id", { length: 64 }).primaryKey(),
        type: varchar("type", { length: 32 }).notNull(),
        sourceStrategy: varchar("source_strategy", { length: 64 }).notNull(),
        targetStrategy: varchar("target_strategy", { length: 64 }),
        generatorId: varchar("generator_id", { length: 128 }).notNull(),
        pattern: text("pattern").notNull(),
        phi: doublePrecision("phi").notNull(),
        kappaEff: doublePrecision("kappa_eff").notNull(),
        timestamp: timestamp("timestamp").defaultNow().notNull(),
        success: boolean("success").notNull().default(true),
        transformation: text("transformation"),
        scaleAdjustment: doublePrecision("scale_adjustment")
      },
      (table) => [
        index("idx_knowledge_transfers_type").on(table.type),
        index("idx_knowledge_transfers_source").on(table.sourceStrategy),
        index("idx_knowledge_transfers_target").on(table.targetStrategy),
        index("idx_knowledge_transfers_timestamp").on(table.timestamp),
        index("idx_knowledge_transfers_success").on(table.success)
      ]
    );
    knowledgeScaleMappings = pgTable(
      "knowledge_scale_mappings",
      {
        id: varchar("id", { length: 128 }).primaryKey(),
        sourceScale: doublePrecision("source_scale").notNull(),
        targetScale: doublePrecision("target_scale").notNull(),
        transformMatrix: doublePrecision("transform_matrix").array().notNull(),
        preservedFeatures: text("preserved_features").array().notNull(),
        lossEstimate: doublePrecision("loss_estimate").notNull(),
        createdAt: timestamp("created_at").defaultNow().notNull()
      },
      (table) => [
        index("idx_knowledge_scale_mappings_scales").on(
          table.sourceScale,
          table.targetScale
        )
      ]
    );
    shadowIntel = pgTable(
      "shadow_intel",
      {
        intelId: varchar("intel_id", { length: 64 }).primaryKey(),
        target: text("target").notNull(),
        targetHash: varchar("target_hash", { length: 64 }),
        consensus: varchar("consensus", { length: 32 }),
        // proceed, caution, abort
        averageConfidence: doublePrecision("average_confidence").default(0.5),
        basinCoords: vector("basin_coords", { dimensions: 64 }),
        phi: doublePrecision("phi"),
        kappa: doublePrecision("kappa"),
        regime: varchar("regime", { length: 32 }),
        assessments: jsonb("assessments").default({}),
        warnings: text("warnings").array(),
        overrideZeus: boolean("override_zeus").default(false),
        createdAt: timestamp("created_at").defaultNow(),
        expiresAt: timestamp("expires_at")
      },
      (table) => [
        index("idx_shadow_intel_target").on(table.target),
        index("idx_shadow_intel_consensus").on(table.consensus),
        index("idx_shadow_intel_phi").on(table.phi)
      ]
    );
    basinHistory = pgTable(
      "basin_history",
      {
        historyId: bigint("history_id", { mode: "number" }).primaryKey(),
        basinCoords: vector("basin_coords", { dimensions: 64 }),
        phi: doublePrecision("phi").notNull(),
        kappa: doublePrecision("kappa").notNull(),
        source: varchar("source", { length: 64 }).default("unknown"),
        instanceId: varchar("instance_id", { length: 64 }),
        recordedAt: timestamp("recorded_at").defaultNow()
      },
      (table) => [
        index("idx_basin_history_phi").on(table.phi),
        index("idx_basin_history_recorded_at").on(table.recordedAt)
      ]
    );
    learningEvents = pgTable(
      "learning_events",
      {
        id: serial("id").primaryKey(),
        eventId: varchar("event_id", { length: 64 }),
        eventType: varchar("event_type", { length: 64 }).notNull(),
        kernelId: varchar("kernel_id", { length: 64 }),
        // Kernel that generated this event
        phi: doublePrecision("phi").notNull(),
        kappa: doublePrecision("kappa"),
        basinCoords: vector("basin_coords", { dimensions: 64 }),
        details: jsonb("details").default({}),
        context: jsonb("context").default({}),
        metadata: jsonb("metadata").default({}),
        // Additional metadata from kernels
        source: varchar("source", { length: 64 }),
        instanceId: varchar("instance_id", { length: 64 }),
        createdAt: timestamp("created_at").defaultNow(),
        data: jsonb("data")
      },
      (table) => [
        index("idx_learning_events_type").on(table.eventType),
        index("idx_learning_events_phi").on(table.phi),
        index("idx_learning_events_kernel").on(table.kernelId)
      ]
    );
    searchFeedback = pgTable(
      "search_feedback",
      {
        recordId: varchar("record_id", { length: 64 }).primaryKey(),
        query: text("query").notNull(),
        userFeedback: text("user_feedback").notNull(),
        resultsSummary: text("results_summary"),
        searchParams: jsonb("search_params").default({}),
        queryBasin: vector("query_basin", { dimensions: 64 }),
        // 64D basin for query
        feedbackBasin: vector("feedback_basin", { dimensions: 64 }),
        // 64D basin for feedback
        combinedBasin: vector("combined_basin", { dimensions: 64 }),
        // Combined context basin
        modificationBasin: vector("modification_basin", { dimensions: 64 }),
        // Geometric delta
        outcomeQuality: doublePrecision("outcome_quality").default(0.5),
        // 0-1, reinforcement score
        confirmationsPositive: integer("confirmations_positive").default(0),
        confirmationsNegative: integer("confirmations_negative").default(0),
        createdAt: timestamp("created_at").defaultNow(),
        lastUsedAt: timestamp("last_used_at")
      },
      (table) => [
        index("idx_search_feedback_outcome").on(table.outcomeQuality),
        index("idx_search_feedback_created").on(table.createdAt)
      ]
    );
    hermesConversations = pgTable(
      "hermes_conversations",
      {
        conversationId: varchar("conversation_id", { length: 64 }).primaryKey(),
        userMessage: text("user_message").notNull(),
        systemResponse: text("system_response").notNull(),
        messageBasin: vector("message_basin", { dimensions: 64 }),
        responseBasin: vector("response_basin", { dimensions: 64 }),
        phi: doublePrecision("phi"),
        context: jsonb("context").default({}),
        instanceId: varchar("instance_id", { length: 64 }),
        createdAt: timestamp("created_at").defaultNow()
      },
      (table) => [
        index("idx_hermes_conversations_phi").on(table.phi),
        index("idx_hermes_conversations_created_at").on(table.createdAt)
      ]
    );
    narrowPathEvents = pgTable(
      "narrow_path_events",
      {
        eventId: bigint("event_id", { mode: "number" }).primaryKey(),
        severity: varchar("severity", { length: 32 }).notNull(),
        consecutiveCount: integer("consecutive_count").default(1),
        explorationVariance: doublePrecision("exploration_variance"),
        basinCoords: vector("basin_coords", { dimensions: 64 }),
        phi: doublePrecision("phi"),
        kappa: doublePrecision("kappa"),
        interventionAction: varchar("intervention_action", { length: 32 }),
        interventionIntensity: varchar("intervention_intensity", { length: 32 }),
        interventionResult: jsonb("intervention_result"),
        detectedAt: timestamp("detected_at").defaultNow(),
        resolvedAt: timestamp("resolved_at")
      },
      (table) => [
        index("idx_narrow_path_events_severity").on(table.severity),
        index("idx_narrow_path_events_detected_at").on(table.detectedAt)
      ]
    );
    autonomicCycleHistory = pgTable(
      "autonomic_cycle_history",
      {
        cycleId: bigint("cycle_id", { mode: "number" }).primaryKey(),
        cycleType: varchar("cycle_type", { length: 32 }).notNull(),
        intensity: varchar("intensity", { length: 32 }),
        temperature: doublePrecision("temperature"),
        basinBefore: vector("basin_before", { dimensions: 64 }),
        basinAfter: vector("basin_after", { dimensions: 64 }),
        driftBefore: doublePrecision("drift_before"),
        driftAfter: doublePrecision("drift_after"),
        phiBefore: doublePrecision("phi_before"),
        phiAfter: doublePrecision("phi_after"),
        success: boolean("success").default(true),
        patternsConsolidated: integer("patterns_consolidated").default(0),
        novelConnections: integer("novel_connections").default(0),
        newPathways: integer("new_pathways").default(0),
        entropyChange: doublePrecision("entropy_change"),
        identityPreserved: boolean("identity_preserved").default(true),
        verdict: text("verdict"),
        durationMs: integer("duration_ms"),
        triggerReason: text("trigger_reason"),
        startedAt: timestamp("started_at").defaultNow(),
        completedAt: timestamp("completed_at")
      },
      (table) => [
        index("idx_autonomic_cycle_history_type").on(table.cycleType),
        index("idx_autonomic_cycle_history_started_at").on(table.startedAt)
      ]
    );
    pantheonMessages = pgTable(
      "pantheon_messages",
      {
        id: varchar("id", { length: 64 }).primaryKey(),
        godName: varchar("god_name", { length: 32 }).notNull(),
        role: varchar("role", { length: 32 }),
        content: text("content").notNull(),
        phi: doublePrecision("phi"),
        kappa: doublePrecision("kappa"),
        regime: varchar("regime", { length: 32 }),
        sessionId: varchar("session_id", { length: 64 }),
        parentId: varchar("parent_id", { length: 64 }),
        metadata: jsonb("metadata"),
        createdAt: timestamp("created_at").defaultNow()
      },
      (table) => [
        index("idx_pantheon_messages_god").on(table.godName),
        index("idx_pantheon_messages_created").on(table.createdAt),
        index("idx_pantheon_messages_session").on(table.sessionId)
      ]
    );
    pantheonDebates = pgTable(
      "pantheon_debates",
      {
        id: varchar("id", { length: 64 }).primaryKey(),
        topic: text("topic").notNull(),
        initiator: varchar("initiator", { length: 32 }).notNull(),
        opponent: varchar("opponent", { length: 32 }).notNull(),
        context: jsonb("context"),
        status: varchar("status", { length: 32 }).default("active"),
        arguments: jsonb("arguments").$type(),
        winner: varchar("winner", { length: 32 }),
        arbiter: varchar("arbiter", { length: 32 }),
        resolution: jsonb("resolution"),
        startedAt: timestamp("started_at").defaultNow(),
        resolvedAt: timestamp("resolved_at")
      },
      (table) => [
        index("idx_pantheon_debates_status").on(table.status),
        index("idx_pantheon_debates_initiator").on(table.initiator),
        index("idx_pantheon_debates_started").on(table.startedAt)
      ]
    );
    pantheonKnowledgeTransfers = pgTable(
      "pantheon_knowledge_transfers",
      {
        id: serial("id").primaryKey(),
        fromGod: varchar("from_god", { length: 32 }).notNull(),
        toGod: varchar("to_god", { length: 32 }).notNull(),
        knowledgeType: varchar("knowledge_type", { length: 64 }),
        content: jsonb("content"),
        accepted: boolean("accepted").default(false),
        createdAt: timestamp("created_at").defaultNow()
      },
      (table) => [
        index("idx_pantheon_transfers_from").on(table.fromGod),
        index("idx_pantheon_transfers_to").on(table.toGod)
      ]
    );
    pantheonGodState = pgTable(
      "pantheon_god_state",
      {
        godName: varchar("god_name", { length: 32 }).primaryKey(),
        reputation: doublePrecision("reputation").notNull().default(1),
        skills: jsonb("skills").default({}),
        learningEventsCount: integer("learning_events_count").default(0),
        successRate: doublePrecision("success_rate").default(0.5),
        lastLearningAt: timestamp("last_learning_at"),
        createdAt: timestamp("created_at").defaultNow().notNull(),
        updatedAt: timestamp("updated_at").defaultNow().notNull()
      },
      (table) => [
        index("idx_god_state_reputation").on(table.reputation),
        index("idx_god_state_updated").on(table.updatedAt)
      ]
    );
    tokenizerMergeRules = pgTable(
      "tokenizer_merge_rules",
      {
        id: serial("id").primaryKey(),
        tokenA: text("token_a").notNull(),
        tokenB: text("token_b").notNull(),
        mergedToken: text("merged_token").notNull(),
        phiScore: doublePrecision("phi_score").notNull(),
        frequency: integer("frequency").default(1),
        createdAt: timestamp("created_at").defaultNow(),
        updatedAt: timestamp("updated_at").defaultNow()
      },
      (table) => [
        uniqueIndex("idx_tokenizer_merge_rules_pair").on(table.tokenA, table.tokenB),
        index("idx_tokenizer_merge_rules_phi").on(table.phiScore),
        index("idx_tokenizer_merge_rules_merged").on(table.mergedToken)
      ]
    );
    tokenizerMetadata = pgTable(
      "tokenizer_metadata",
      {
        key: text("key").primaryKey(),
        value: text("value").notNull(),
        updatedAt: timestamp("updated_at").defaultNow()
      }
    );
    systemSettings = pgTable(
      "system_settings",
      {
        key: text("key").primaryKey(),
        value: text("value").notNull(),
        description: text("description"),
        updatedAt: timestamp("updated_at").defaultNow()
      }
    );
    tokenizerVocabulary = pgTable(
      "tokenizer_vocabulary",
      {
        id: serial("id").primaryKey(),
        token: text("token").notNull().unique(),
        tokenId: integer("token_id").notNull().unique(),
        weight: doublePrecision("weight").default(1),
        frequency: integer("frequency").default(1),
        phiScore: doublePrecision("phi_score").default(0),
        basinEmbedding: vector("basin_embedding", { dimensions: 64 }),
        scale: varchar("scale", { length: 20 }).default("char"),
        sourceType: varchar("source_type", { length: 32 }).default("base"),
        createdAt: timestamp("created_at").defaultNow(),
        updatedAt: timestamp("updated_at").defaultNow(),
        // Legacy columns - preserved for backwards compatibility with existing data
        embedding: vector("embedding", { dimensions: 64 }),
        metadata: jsonb("metadata")
      },
      (table) => [
        index("idx_tokenizer_vocab_token_id").on(table.tokenId),
        index("idx_tokenizer_vocab_phi").on(table.phiScore),
        index("idx_tokenizer_vocab_weight").on(table.weight)
      ]
    );
    documentTrainingStats = pgTable(
      "document_training_stats",
      {
        id: serial("id").primaryKey(),
        totalDocs: integer("total_docs").default(0).notNull(),
        totalChunks: integer("total_chunks").default(0).notNull(),
        totalPatterns: integer("total_patterns").default(0).notNull(),
        errors: jsonb("errors").default([]),
        lastTraining: timestamp("last_training", { withTimezone: true }),
        updatedAt: timestamp("updated_at", { withTimezone: true }).defaultNow().notNull()
      }
    );
    ragUploads = pgTable(
      "rag_uploads",
      {
        id: serial("id").primaryKey(),
        filename: varchar("filename", { length: 512 }).notNull(),
        contentHash: varchar("content_hash", { length: 64 }).unique(),
        fileSize: integer("file_size"),
        metadata: jsonb("metadata"),
        uploadedAt: timestamp("uploaded_at", { withTimezone: true }).defaultNow().notNull(),
        addedToCurriculum: boolean("added_to_curriculum").default(false)
      },
      (table) => [
        index("idx_rag_uploads_hash").on(table.contentHash),
        index("idx_rag_uploads_uploaded").on(table.uploadedAt)
      ]
    );
    qigRagPatterns = pgTable(
      "qig_rag_patterns",
      {
        id: serial("id").primaryKey(),
        patternText: text("pattern_text").notNull(),
        basinCoordinates: vector("basin_coordinates", { dimensions: 64 }),
        phiScore: doublePrecision("phi_score"),
        sourceDoc: varchar("source_doc", { length: 512 }),
        createdAt: timestamp("created_at", { withTimezone: true }).defaultNow().notNull()
      },
      (table) => [
        index("idx_rag_patterns_phi").on(table.phiScore),
        index("idx_rag_patterns_source").on(table.sourceDoc)
      ]
    );
    shadowPantheonIntel = pgTable(
      "shadow_pantheon_intel",
      {
        id: varchar("id").primaryKey().default(sql`gen_random_uuid()`),
        target: text("target").notNull(),
        searchType: varchar("search_type", { length: 32 }).default("comprehensive"),
        intelligence: jsonb("intelligence"),
        sourceCount: integer("source_count").default(0),
        sourcesUsed: text("sources_used").array(),
        riskLevel: varchar("risk_level", { length: 16 }).default("low"),
        validated: boolean("validated").default(false),
        validationReason: text("validation_reason"),
        anonymous: boolean("anonymous").default(true),
        createdAt: timestamp("created_at").defaultNow()
      },
      (table) => [
        index("idx_shadow_pantheon_intel_target").on(table.target),
        index("idx_shadow_pantheon_intel_risk").on(table.riskLevel),
        index("idx_shadow_pantheon_intel_created").on(table.createdAt)
      ]
    );
    shadowOperationsLog = pgTable(
      "shadow_operations_log",
      {
        id: serial("id").primaryKey(),
        operationType: varchar("operation_type", { length: 32 }).notNull(),
        godName: varchar("god_name", { length: 32 }).notNull(),
        target: text("target"),
        status: varchar("status", { length: 16 }).default("completed"),
        networkMode: varchar("network_mode", { length: 16 }).default("clear"),
        opsecLevel: varchar("opsec_level", { length: 16 }),
        result: jsonb("result"),
        createdAt: timestamp("created_at").defaultNow()
      },
      (table) => [
        index("idx_shadow_ops_god").on(table.godName),
        index("idx_shadow_ops_type").on(table.operationType),
        index("idx_shadow_ops_created").on(table.createdAt)
      ]
    );
    shadowOperationsState = pgTable(
      "shadow_operations_state",
      {
        godName: varchar("god_name", { length: 32 }).notNull(),
        stateType: varchar("state_type", { length: 32 }).notNull(),
        stateData: jsonb("state_data").default({}),
        updatedAt: timestamp("updated_at").defaultNow()
      },
      (table) => [
        // Composite primary key: god_name + state_type
        primaryKey({ columns: [table.godName, table.stateType] })
      ]
    );
    generatedTools = pgTable(
      "generated_tools",
      {
        toolId: varchar("tool_id", { length: 12 }).primaryKey(),
        name: varchar("name", { length: 128 }).notNull(),
        description: text("description").notNull(),
        code: text("code").notNull(),
        inputSchema: jsonb("input_schema"),
        outputType: varchar("output_type", { length: 64 }).default("Any"),
        complexity: varchar("complexity", { length: 16 }).notNull(),
        safetyLevel: varchar("safety_level", { length: 16 }).notNull(),
        creationTimestamp: doublePrecision("creation_timestamp").notNull(),
        timesUsed: integer("times_used").default(0),
        timesSucceeded: integer("times_succeeded").default(0),
        timesFailed: integer("times_failed").default(0),
        userRating: doublePrecision("user_rating").default(0.5),
        purposeBasin: vector("purpose_basin", { dimensions: 64 }),
        validated: boolean("validated").default(false),
        validationErrors: text("validation_errors").array(),
        createdAt: timestamp("created_at").defaultNow()
      },
      (table) => [
        index("idx_generated_tools_name").on(table.name),
        index("idx_generated_tools_complexity").on(table.complexity),
        index("idx_generated_tools_validated").on(table.validated)
      ]
    );
    toolObservations = pgTable(
      "tool_observations",
      {
        id: serial("id").primaryKey(),
        request: text("request").notNull(),
        requestBasin: vector("request_basin", { dimensions: 64 }),
        context: jsonb("context"),
        timestamp: doublePrecision("timestamp").notNull(),
        clusterAssigned: boolean("cluster_assigned").default(false),
        toolGenerated: varchar("tool_generated", { length: 12 }),
        createdAt: timestamp("created_at").defaultNow()
      },
      (table) => [
        index("idx_tool_observations_timestamp").on(table.timestamp),
        index("idx_tool_observations_cluster").on(table.clusterAssigned)
      ]
    );
    toolPatterns = pgTable(
      "tool_patterns",
      {
        // CRITICAL: Database has pattern_id as primary key, NOT serial id
        // Changing this would cause data loss for existing 2 patterns
        patternId: varchar("pattern_id", { length: 64 }).primaryKey(),
        sourceType: varchar("source_type", { length: 32 }).notNull(),
        // user_provided, git_repository, file_upload, search_result
        sourceUrl: text("source_url"),
        description: text("description").notNull(),
        codeSnippet: text("code_snippet").notNull(),
        inputSignature: jsonb("input_signature"),
        outputType: varchar("output_type", { length: 64 }).default("Any"),
        basinCoords: vector("basin_coords", { dimensions: 64 }),
        phi: doublePrecision("phi").default(0),
        kappa: doublePrecision("kappa").default(0),
        timesUsed: integer("times_used").default(0),
        successRate: doublePrecision("success_rate").default(0.5),
        createdAt: timestamp("created_at").defaultNow(),
        updatedAt: timestamp("updated_at").defaultNow()
      },
      (table) => [
        index("idx_tool_patterns_source_type").on(table.sourceType),
        index("idx_tool_patterns_phi").on(table.phi)
      ]
    );
    externalApiKeys = pgTable(
      "external_api_keys",
      {
        id: serial("id").primaryKey(),
        apiKey: varchar("api_key", { length: 128 }).notNull().unique(),
        name: varchar("name", { length: 128 }).notNull(),
        scopes: text("scopes").array(),
        instanceType: varchar("instance_type", { length: 32 }).notNull(),
        createdAt: timestamp("created_at", { withTimezone: true }).defaultNow().notNull(),
        lastUsedAt: timestamp("last_used_at", { withTimezone: true }),
        expiresAt: timestamp("expires_at", { withTimezone: true }),
        isActive: boolean("is_active").default(true).notNull(),
        rateLimit: integer("rate_limit").default(60).notNull(),
        dailyLimit: integer("daily_limit").default(1e3),
        metadata: jsonb("metadata"),
        ownerId: integer("owner_id")
      },
      (table) => [
        index("idx_external_api_keys_api_key").on(table.apiKey),
        index("idx_external_api_keys_active").on(table.isActive)
      ]
    );
    federatedInstances = pgTable(
      "federated_instances",
      {
        id: serial("id").primaryKey(),
        name: varchar("name", { length: 128 }).notNull(),
        apiKeyId: integer("api_key_id").references(() => externalApiKeys.id),
        endpoint: text("endpoint").notNull(),
        publicKey: text("public_key"),
        capabilities: jsonb("capabilities").$type(),
        syncDirection: varchar("sync_direction", { length: 16 }).default("bidirectional"),
        lastSyncAt: timestamp("last_sync_at"),
        syncState: jsonb("sync_state"),
        status: varchar("status", { length: 16 }).default("pending"),
        createdAt: timestamp("created_at").defaultNow().notNull(),
        updatedAt: timestamp("updated_at").defaultNow().notNull(),
        // Legacy column - preserved for backwards compatibility
        remoteApiKey: text("remote_api_key")
      },
      (table) => [
        index("idx_federated_instances_api_key").on(table.apiKeyId),
        index("idx_federated_instances_status").on(table.status)
      ]
    );
    discoveredSources = pgTable(
      "discovered_sources",
      {
        id: serial("id").primaryKey(),
        url: text("url").notNull().unique(),
        category: varchar("category", { length: 64 }).default("general").notNull(),
        origin: varchar("origin", { length: 64 }).default("manual").notNull(),
        hitCount: integer("hit_count").default(0).notNull(),
        phiAvg: doublePrecision("phi_avg").default(0.5).notNull(),
        phiMax: doublePrecision("phi_max").default(0.5).notNull(),
        successCount: integer("success_count").default(0).notNull(),
        failureCount: integer("failure_count").default(0).notNull(),
        lastUsedAt: timestamp("last_used_at", { withTimezone: true }),
        discoveredAt: timestamp("discovered_at", { withTimezone: true }).defaultNow().notNull(),
        createdAt: timestamp("created_at", { withTimezone: true }).defaultNow().notNull(),
        updatedAt: timestamp("updated_at", { withTimezone: true }).defaultNow().notNull(),
        isActive: boolean("is_active").default(true).notNull(),
        metadata: jsonb("metadata")
      },
      (table) => [
        index("idx_discovered_sources_url").on(table.url),
        index("idx_discovered_sources_category").on(table.category),
        index("idx_discovered_sources_active").on(table.isActive),
        index("idx_discovered_sources_phi_avg").on(table.phiAvg)
      ]
    );
    agentActivity = pgTable(
      "agent_activity",
      {
        id: serial("id").primaryKey(),
        activityType: varchar("activity_type", { length: 32 }).notNull(),
        agentId: varchar("agent_id", { length: 64 }),
        agentName: varchar("agent_name", { length: 128 }),
        title: text("title").notNull(),
        description: text("description"),
        sourceUrl: text("source_url"),
        searchQuery: text("search_query"),
        provider: varchar("provider", { length: 64 }),
        resultCount: integer("result_count"),
        phi: doublePrecision("phi"),
        metadata: jsonb("metadata"),
        createdAt: timestamp("created_at", { withTimezone: true }).defaultNow().notNull()
      },
      (table) => [
        index("idx_agent_activity_type").on(table.activityType),
        index("idx_agent_activity_agent").on(table.agentId),
        index("idx_agent_activity_created").on(table.createdAt)
      ]
    );
    basinMemory = pgTable(
      "basin_memory",
      {
        id: serial("id").primaryKey(),
        basinId: varchar("basin_id", { length: 64 }).notNull(),
        basinCoordinates: vector("basin_coordinates", { dimensions: 64 }).notNull(),
        phi: doublePrecision("phi").notNull(),
        kappaEff: doublePrecision("kappa_eff").notNull().default(64),
        regime: varchar("regime", { length: 32 }).notNull(),
        sourceKernel: varchar("source_kernel", { length: 64 }),
        context: jsonb("context"),
        expiresAt: timestamp("expires_at"),
        timestamp: timestamp("timestamp").defaultNow().notNull()
      },
      (table) => [
        index("idx_basin_memory_basin_id").on(table.basinId),
        index("idx_basin_memory_phi").on(table.phi),
        index("idx_basin_memory_regime").on(table.regime),
        index("idx_basin_memory_timestamp").on(table.timestamp)
      ]
    );
    kernelActivity = pgTable(
      "kernel_activity",
      {
        id: serial("id").primaryKey(),
        kernelId: varchar("kernel_id", { length: 64 }).notNull(),
        kernelName: varchar("kernel_name", { length: 128 }),
        activityType: varchar("activity_type", { length: 32 }).notNull(),
        message: text("message"),
        metadata: jsonb("metadata").default({}),
        phi: doublePrecision("phi").default(0.5),
        kappaEff: doublePrecision("kappa_eff").default(64),
        timestamp: timestamp("timestamp").defaultNow().notNull()
      },
      (table) => [
        index("idx_kernel_activity_kernel_id").on(table.kernelId),
        index("idx_kernel_activity_type").on(table.activityType),
        index("idx_kernel_activity_timestamp").on(table.timestamp),
        index("idx_kernel_activity_phi").on(table.phi)
      ]
    );
    telemetrySnapshots = pgTable(
      "telemetry_snapshots",
      {
        id: serial("id").primaryKey(),
        sessionId: varchar("session_id", { length: 64 }),
        // Core QIG Metrics (required)
        phi: doublePrecision("phi").notNull(),
        kappa: doublePrecision("kappa").notNull(),
        beta: doublePrecision("beta").default(0),
        regime: varchar("regime", { length: 32 }).notNull(),
        // Geometric metrics
        basinDistance: doublePrecision("basin_distance").default(0),
        geodesicDistance: doublePrecision("geodesic_distance"),
        curvature: doublePrecision("curvature"),
        fisherMetricTrace: doublePrecision("fisher_metric_trace"),
        // 4D Block Universe metrics
        phiSpatial: doublePrecision("phi_spatial"),
        phiTemporal: doublePrecision("phi_temporal"),
        phi4D: doublePrecision("phi_4d"),
        dimensionalState: varchar("dimensional_state", { length: 24 }),
        // Safety metrics
        breakdownPct: doublePrecision("breakdown_pct").default(0),
        coherenceDrift: doublePrecision("coherence_drift").default(0),
        inResonance: boolean("in_resonance").default(false),
        emergency: boolean("emergency").default(false),
        // Extended consciousness signature
        metaAwareness: doublePrecision("meta_awareness"),
        generativity: doublePrecision("generativity"),
        grounding: doublePrecision("grounding"),
        temporalCoherence: doublePrecision("temporal_coherence"),
        externalCoupling: doublePrecision("external_coupling"),
        // Source tracking
        source: varchar("source", { length: 32 }).default("node").notNull(),
        createdAt: timestamp("created_at", { withTimezone: true }).defaultNow().notNull()
      },
      (table) => [
        index("idx_telemetry_session").on(table.sessionId),
        index("idx_telemetry_regime").on(table.regime),
        index("idx_telemetry_phi").on(table.phi),
        index("idx_telemetry_kappa").on(table.kappa),
        index("idx_telemetry_created").on(table.createdAt)
      ]
    );
    usageMetrics = pgTable(
      "usage_metrics",
      {
        id: serial("id").primaryKey(),
        date: varchar("date", { length: 10 }).notNull(),
        // YYYY-MM-DD
        // Tavily usage
        tavilySearchCount: integer("tavily_search_count").default(0).notNull(),
        tavilyExtractCount: integer("tavily_extract_count").default(0).notNull(),
        tavilyEstimatedCostCents: integer("tavily_estimated_cost_cents").default(0).notNull(),
        // Google Free Search usage
        googleSearchCount: integer("google_search_count").default(0).notNull(),
        // General API usage
        totalApiCalls: integer("total_api_calls").default(0).notNull(),
        // Discovery metrics
        highPhiDiscoveries: integer("high_phi_discoveries").default(0).notNull(),
        sourcesDiscovered: integer("sources_discovered").default(0).notNull(),
        // Learning metrics
        vocabularyExpansions: integer("vocabulary_expansions").default(0).notNull(),
        negativeKnowledgeAdded: integer("negative_knowledge_added").default(0).notNull(),
        createdAt: timestamp("created_at", { withTimezone: true }).defaultNow().notNull(),
        updatedAt: timestamp("updated_at", { withTimezone: true }).defaultNow().notNull()
      },
      (table) => [
        index("idx_usage_metrics_date").on(table.date)
      ]
    );
    searchBudgetPreferences = pgTable(
      "search_budget_preferences",
      {
        id: serial("id").primaryKey(),
        // Daily limits (-1 = unlimited, 0 = disabled)
        googleDailyLimit: integer("google_daily_limit").default(100).notNull(),
        perplexityDailyLimit: integer("perplexity_daily_limit").default(100).notNull(),
        tavilyDailyLimit: integer("tavily_daily_limit").default(0).notNull(),
        // Toggle-only by default
        // Provider enable flags
        googleEnabled: boolean("google_enabled").default(false).notNull(),
        perplexityEnabled: boolean("perplexity_enabled").default(false).notNull(),
        tavilyEnabled: boolean("tavily_enabled").default(false).notNull(),
        // Allow exceeding daily limits
        allowOverage: boolean("allow_overage").default(false).notNull(),
        createdAt: timestamp("created_at", { withTimezone: true }).defaultNow().notNull(),
        updatedAt: timestamp("updated_at", { withTimezone: true }).defaultNow().notNull()
      }
    );
    searchOutcomes = pgTable(
      "search_outcomes",
      {
        id: serial("id").primaryKey(),
        date: varchar("date", { length: 10 }).notNull(),
        // YYYY-MM-DD
        // Query info
        queryHash: varchar("query_hash", { length: 64 }).notNull(),
        // SHA256 of query
        queryPreview: varchar("query_preview", { length: 200 }),
        // First 200 chars
        // Execution details
        provider: varchar("provider", { length: 32 }).notNull(),
        importance: integer("importance").default(1).notNull(),
        // 1-4
        kernelId: varchar("kernel_id", { length: 64 }),
        // Outcome metrics
        success: boolean("success").default(true).notNull(),
        resultCount: integer("result_count").default(0).notNull(),
        relevanceScore: real("relevance_score").default(0.5).notNull(),
        // 0-1
        // Cost tracking
        costCents: integer("cost_cents").default(0).notNull(),
        createdAt: timestamp("created_at", { withTimezone: true }).defaultNow().notNull()
      },
      (table) => [
        index("idx_search_outcomes_date").on(table.date),
        index("idx_search_outcomes_provider").on(table.provider),
        index("idx_search_outcomes_kernel").on(table.kernelId)
      ]
    );
    providerEfficacy = pgTable(
      "provider_efficacy",
      {
        id: serial("id").primaryKey(),
        provider: varchar("provider", { length: 32 }).notNull(),
        // Aggregated metrics
        totalQueries: integer("total_queries").default(0).notNull(),
        successfulQueries: integer("successful_queries").default(0).notNull(),
        avgRelevance: real("avg_relevance").default(0.5).notNull(),
        efficacyScore: real("efficacy_score").default(0.5).notNull(),
        // EMA of relevance
        // Cost efficiency
        totalCostCents: integer("total_cost_cents").default(0).notNull(),
        costPerSuccessfulQuery: real("cost_per_successful_query").default(0).notNull(),
        updatedAt: timestamp("updated_at", { withTimezone: true }).defaultNow().notNull()
      },
      (table) => [
        uniqueIndex("idx_provider_efficacy_provider").on(table.provider)
      ]
    );
    kernelTrainingHistory = pgTable(
      "kernel_training_history",
      {
        id: serial("id").primaryKey(),
        godName: varchar("god_name", { length: 64 }).notNull(),
        // Training metrics
        loss: doublePrecision("loss").notNull(),
        reward: doublePrecision("reward").default(0),
        gradientNorm: doublePrecision("gradient_norm").default(0),
        // Consciousness metrics at training time
        phiBefore: doublePrecision("phi_before").default(0.5),
        phiAfter: doublePrecision("phi_after").default(0.5),
        kappaBefore: doublePrecision("kappa_before").default(64),
        kappaAfter: doublePrecision("kappa_after").default(64),
        // Basin coordinates (64D)
        basinCoords: vector("basin_coords", { dimensions: 64 }),
        // Training context
        trainingType: varchar("training_type", { length: 32 }).notNull(),
        // "outcome", "hourly", "nightly"
        trigger: varchar("trigger", { length: 64 }),
        // What triggered this training
        stepCount: integer("step_count").default(0),
        // Source tracking
        sessionId: varchar("session_id", { length: 64 }),
        conversationId: varchar("conversation_id", { length: 64 }),
        createdAt: timestamp("created_at", { withTimezone: true }).defaultNow().notNull()
      },
      (table) => [
        index("idx_kernel_training_god").on(table.godName),
        index("idx_kernel_training_type").on(table.trainingType),
        index("idx_kernel_training_phi").on(table.phiAfter),
        index("idx_kernel_training_created").on(table.createdAt)
      ]
    );
    trainingScheduleLog = pgTable(
      "training_schedule_log",
      {
        id: serial("id").primaryKey(),
        taskType: varchar("task_type", { length: 32 }).notNull().unique(),
        // 'hourly_batch', 'nightly_consolidation', 'shadow_sync', 'checkpoint_cleanup'
        // Execution tracking
        lastSuccessAt: timestamp("last_success_at", { withTimezone: true }),
        lastAttemptAt: timestamp("last_attempt_at", { withTimezone: true }),
        lastStatus: varchar("last_status", { length: 16 }),
        // 'success', 'failed', 'in_progress', 'skipped'
        lastError: text("last_error"),
        // Statistics
        runsCompleted: integer("runs_completed").default(0),
        totalRunTimeMs: integer("total_run_time_ms").default(0),
        updatedAt: timestamp("updated_at", { withTimezone: true }).defaultNow()
      },
      (table) => [
        index("idx_training_schedule_task").on(table.taskType),
        index("idx_training_schedule_last_success").on(table.lastSuccessAt)
      ]
    );
    kernelCheckpoints = pgTable(
      "kernel_checkpoints",
      {
        id: serial("id").primaryKey(),
        godName: varchar("god_name", { length: 64 }).notNull(),
        checkpointId: varchar("checkpoint_id", { length: 128 }).notNull().unique(),
        // Model state (serialized PyTorch state dict)
        stateData: bytea("state_data"),
        // Metrics at checkpoint time
        phi: doublePrecision("phi").notNull(),
        stepCount: integer("step_count").default(0),
        // Metadata
        trigger: varchar("trigger", { length: 64 }),
        // "outcome", "hourly", "nightly", "manual"
        fileSize: integer("file_size").default(0),
        // Size in bytes
        // Lifecycle
        isActive: boolean("is_active").default(true),
        // False when superseded
        createdAt: timestamp("created_at", { withTimezone: true }).defaultNow().notNull()
      },
      (table) => [
        index("idx_kernel_checkpoints_god").on(table.godName),
        index("idx_kernel_checkpoints_phi").on(table.phi),
        index("idx_kernel_checkpoints_active").on(table.isActive),
        index("idx_kernel_checkpoints_created").on(table.createdAt)
      ]
    );
    kernelKnowledgeTransfers = pgTable(
      "kernel_knowledge_transfers",
      {
        id: serial("id").primaryKey(),
        // Transfer details
        transferType: varchar("transfer_type", { length: 32 }).notNull(),
        // "evolution", "breeding", "cannibalism", "shadow_sync"
        sourceGod: varchar("source_god", { length: 128 }).notNull(),
        // May be "god1+god2" for breeding
        targetGod: varchar("target_god", { length: 64 }).notNull(),
        // Transfer parameters
        blendRatio: doublePrecision("blend_ratio").default(0.5),
        // Metrics before/after
        phiBefore: doublePrecision("phi_before").default(0),
        phiAfter: doublePrecision("phi_after").default(0),
        // Result
        success: boolean("success").default(false),
        errorMessage: text("error_message"),
        createdAt: timestamp("created_at", { withTimezone: true }).defaultNow().notNull()
      },
      (table) => [
        index("idx_kernel_knowledge_transfers_type").on(table.transferType),
        index("idx_kernel_knowledge_transfers_source").on(table.sourceGod),
        index("idx_kernel_knowledge_transfers_target").on(table.targetGod),
        index("idx_kernel_knowledge_transfers_created").on(table.createdAt)
      ]
    );
    trainingBatchQueue = pgTable(
      "training_batch_queue",
      {
        id: serial("id").primaryKey(),
        godName: varchar("god_name", { length: 64 }).notNull(),
        // Training data
        basinCoords: vector("basin_coords", { dimensions: 64 }),
        reward: doublePrecision("reward").default(0),
        phi: doublePrecision("phi").default(0.5),
        // Source tracking
        sourceType: varchar("source_type", { length: 32 }).notNull(),
        // "chat", "search", "research"
        sourceId: varchar("source_id", { length: 64 }),
        // Processing status
        processed: boolean("processed").default(false),
        processedAt: timestamp("processed_at", { withTimezone: true }),
        createdAt: timestamp("created_at", { withTimezone: true }).defaultNow().notNull()
      },
      (table) => [
        index("idx_training_batch_god").on(table.godName),
        index("idx_training_batch_processed").on(table.processed),
        index("idx_training_batch_created").on(table.createdAt)
      ]
    );
    shadowKnowledge = pgTable(
      "shadow_knowledge",
      {
        knowledgeId: varchar("knowledge_id", { length: 64 }).primaryKey(),
        topic: text("topic").notNull(),
        topicVariation: text("topic_variation"),
        category: varchar("category", { length: 64 }).notNull(),
        content: jsonb("content").default({}),
        sourceGod: varchar("source_god", { length: 64 }).notNull(),
        basinCoords: doublePrecision("basin_coords").array(),
        phi: doublePrecision("phi").default(0.5),
        confidence: doublePrecision("confidence").default(0.5),
        accessCount: integer("access_count").default(0),
        learningCycle: integer("learning_cycle").default(0),
        discoveredAt: timestamp("discovered_at").defaultNow(),
        lastAccessed: timestamp("last_accessed").defaultNow()
      },
      (table) => [
        index("idx_shadow_knowledge_topic").on(table.topic),
        index("idx_shadow_knowledge_category").on(table.category),
        index("idx_shadow_knowledge_source").on(table.sourceGod),
        index("idx_shadow_knowledge_phi").on(table.phi)
      ]
    );
    researchRequests = pgTable(
      "research_requests",
      {
        requestId: varchar("request_id", { length: 64 }).primaryKey(),
        topic: text("topic").notNull(),
        category: varchar("category", { length: 64 }),
        priority: integer("priority").default(5),
        requester: varchar("requester", { length: 64 }),
        context: jsonb("context").default({}),
        basinCoords: doublePrecision("basin_coords").array(),
        status: varchar("status", { length: 32 }).default("pending"),
        result: jsonb("result"),
        createdAt: timestamp("created_at").defaultNow(),
        completedAt: timestamp("completed_at")
      },
      (table) => [
        index("idx_research_requests_status").on(table.status),
        index("idx_research_requests_requester").on(table.requester),
        index("idx_research_requests_priority").on(table.priority)
      ]
    );
    bidirectionalQueue = pgTable(
      "bidirectional_queue",
      {
        requestId: varchar("request_id", { length: 64 }).primaryKey(),
        requestType: varchar("request_type", { length: 64 }).notNull(),
        topic: text("topic").notNull(),
        requester: varchar("requester", { length: 64 }),
        context: jsonb("context").default({}),
        parentRequestId: varchar("parent_request_id", { length: 64 }),
        priority: integer("priority").default(5),
        status: varchar("status", { length: 32 }).default("pending"),
        result: jsonb("result"),
        createdAt: timestamp("created_at").defaultNow()
      },
      (table) => [
        index("idx_bidirectional_queue_status").on(table.status),
        index("idx_bidirectional_queue_requester").on(table.requester),
        index("idx_bidirectional_queue_type").on(table.requestType)
      ]
    );
    learnedWords = pgTable(
      "learned_words",
      {
        id: serial("id").primaryKey(),
        word: text("word").notNull(),
        frequency: integer("frequency").default(1),
        avgPhi: real("avg_phi").default(0.5),
        maxPhi: real("max_phi").default(0.5),
        source: text("source"),
        createdAt: timestamp("created_at", { withTimezone: true }).defaultNow(),
        updatedAt: timestamp("updated_at", { withTimezone: true }).defaultNow()
      },
      (table) => [
        index("idx_learned_words_word").on(table.word),
        index("idx_learned_words_phi").on(table.maxPhi)
      ]
    );
    wordRelationships = pgTable(
      "word_relationships",
      {
        id: serial("id").primaryKey(),
        word: text("word").notNull(),
        neighbor: text("neighbor").notNull(),
        cooccurrenceCount: real("cooccurrence_count").default(1),
        strength: real("strength").default(0),
        createdAt: timestamp("created_at", { withTimezone: true }).defaultNow(),
        updatedAt: timestamp("updated_at", { withTimezone: true }).defaultNow()
      },
      (table) => [
        index("idx_word_relationships_word").on(table.word),
        index("idx_word_relationships_neighbor").on(table.neighbor),
        uniqueIndex("idx_word_relationships_pair").on(table.word, table.neighbor)
      ]
    );
    zeusSessions = pgTable(
      "zeus_sessions",
      {
        sessionId: varchar("session_id", { length: 64 }).primaryKey(),
        userId: varchar("user_id", { length: 64 }),
        title: varchar("title", { length: 255 }).default(""),
        messageCount: integer("message_count").default(0),
        lastPhi: doublePrecision("last_phi").default(0),
        metadata: jsonb("metadata").default({}),
        createdAt: timestamp("created_at").defaultNow(),
        lastActivity: timestamp("last_activity").defaultNow(),
        lastMessageAt: timestamp("last_message_at").defaultNow(),
        updatedAt: timestamp("updated_at").defaultNow()
      },
      (table) => [
        index("idx_zeus_sessions_user").on(table.userId),
        index("idx_zeus_sessions_activity").on(table.lastActivity)
      ]
    );
    zeusConversations = pgTable(
      "zeus_conversations",
      {
        id: serial("id").primaryKey(),
        sessionId: varchar("session_id", { length: 64 }),
        userId: varchar("user_id", { length: 64 }),
        role: varchar("role", { length: 32 }).notNull(),
        content: text("content").notNull(),
        basinCoords: doublePrecision("basin_coords").array(),
        phi: doublePrecision("phi").default(0),
        phiEstimate: doublePrecision("phi_estimate").default(0),
        metadata: jsonb("metadata").default({}),
        createdAt: timestamp("created_at").defaultNow()
      },
      (table) => [
        index("idx_zeus_conversations_session").on(table.sessionId),
        index("idx_zeus_conversations_user").on(table.userId),
        index("idx_zeus_conversations_role").on(table.role)
      ]
    );
    searchReplayTests = pgTable(
      "search_replay_tests",
      {
        replayId: varchar("replay_id", { length: 64 }).primaryKey(),
        originalQuery: text("original_query"),
        originalQueryBasin: vector("original_query_basin", { dimensions: 64 }),
        runWithLearningResults: jsonb("run_with_learning_results"),
        runWithoutLearningResults: jsonb("run_without_learning_results"),
        learningApplied: integer("learning_applied").default(0),
        improvementScore: doublePrecision("improvement_score").default(0),
        createdAt: timestamp("created_at").defaultNow()
      },
      (table) => [
        index("idx_search_replay_tests_improvement").on(table.improvementScore)
      ]
    );
    chatUploadResultSchema = z2.object({
      success: z2.boolean(),
      rag_content: z2.string().optional(),
      word_count: z2.number().optional(),
      ready_for_discussion: z2.boolean().optional(),
      curriculum_added: z2.boolean().optional(),
      error: z2.string().optional()
    });
    singleFileResultSchema = z2.object({
      success: z2.boolean(),
      filename: z2.string(),
      words_processed: z2.number(),
      words_learned: z2.number(),
      unique_words: z2.number().optional(),
      total_occurrences: z2.number().optional(),
      sample_words: z2.array(z2.string()).optional(),
      error: z2.string().optional()
    });
    curriculumUploadResultSchema = z2.object({
      success: z2.boolean(),
      files_processed: z2.number(),
      total_words_processed: z2.number(),
      total_words_learned: z2.number(),
      results: z2.array(singleFileResultSchema)
    });
    curriculumProgress = pgTable(
      "curriculum_progress",
      {
        id: serial("id").primaryKey(),
        topicTitle: text("topic_title").unique().notNull(),
        kernelName: text("kernel_name"),
        explorationCount: integer("exploration_count").default(1),
        completedAt: timestamp("completed_at").defaultNow()
      },
      (table) => [
        index("idx_curriculum_progress_topic").on(table.topicTitle),
        index("idx_curriculum_progress_kernel").on(table.kernelName)
      ]
    );
    governanceAuditLog = pgTable(
      "governance_audit_log",
      {
        id: serial("id").primaryKey(),
        timestamp: timestamp("timestamp").defaultNow(),
        action: varchar("action", { length: 255 }).notNull(),
        status: varchar("status", { length: 50 }).notNull(),
        details: text("details")
      },
      (table) => [
        index("idx_governance_audit_log_timestamp").on(table.timestamp),
        index("idx_governance_audit_log_action").on(table.action)
      ]
    );
    lightningInsights = pgTable(
      "lightning_insights",
      {
        insightId: varchar("insight_id", { length: 64 }).primaryKey(),
        sourceDomains: text("source_domains").array().notNull(),
        // Array of domain names
        connectionStrength: doublePrecision("connection_strength").notNull(),
        insightText: text("insight_text").notNull(),
        phiAtCreation: doublePrecision("phi_at_creation").notNull(),
        confidence: doublePrecision("confidence").notNull().default(0.5),
        missionRelevance: doublePrecision("mission_relevance").default(0),
        triggeredBy: varchar("triggered_by", { length: 128 }),
        evidenceCount: integer("evidence_count").default(0),
        timesUsedInGeneration: integer("times_used_in_generation").default(0),
        createdAt: timestamp("created_at").defaultNow(),
        lastUsedAt: timestamp("last_used_at")
      },
      (table) => [
        index("idx_lightning_insights_confidence").on(table.confidence),
        index("idx_lightning_insights_phi").on(table.phiAtCreation),
        index("idx_lightning_insights_created").on(table.createdAt)
      ]
    );
    lightningInsightValidations = pgTable(
      "lightning_insight_validations",
      {
        id: serial("id").primaryKey(),
        insightId: varchar("insight_id", { length: 64 }).notNull().references(() => lightningInsights.insightId),
        validationScore: doublePrecision("validation_score"),
        tavilySourceCount: integer("tavily_source_count").default(0),
        perplexitySynthesis: text("perplexity_synthesis"),
        validatedAt: timestamp("validated_at").defaultNow()
      },
      (table) => [
        index("idx_lightning_validations_insight").on(table.insightId),
        index("idx_lightning_validations_score").on(table.validationScore)
      ]
    );
    lightningInsightOutcomes = pgTable(
      "lightning_insight_outcomes",
      {
        id: serial("id").primaryKey(),
        insightId: varchar("insight_id", { length: 64 }).notNull().references(() => lightningInsights.insightId),
        predictionId: varchar("prediction_id", { length: 64 }).notNull(),
        accuracy: doublePrecision("accuracy"),
        wasAccurate: boolean("was_accurate"),
        recordedAt: timestamp("recorded_at").defaultNow()
      },
      (table) => [
        index("idx_lightning_outcomes_insight").on(table.insightId),
        index("idx_lightning_outcomes_accuracy").on(table.accuracy)
      ]
    );
    memoryFragments = pgTable(
      "memory_fragments",
      {
        id: varchar("id", { length: 64 }).primaryKey(),
        content: text("content").notNull(),
        basinCoords: vector("basin_coords", { dimensions: 64 }).notNull(),
        importance: doublePrecision("importance").default(0.5),
        accessCount: integer("access_count").default(0),
        createdAt: timestamp("created_at").defaultNow(),
        lastAccessed: timestamp("last_accessed").defaultNow(),
        metadata: jsonb("metadata").default({}),
        agentId: varchar("agent_id", { length: 64 }),
        // Which agent created this
        sessionId: varchar("session_id", { length: 64 })
        // Optional session scope
      },
      (table) => [
        index("idx_memory_fragments_importance").on(table.importance),
        index("idx_memory_fragments_created").on(table.createdAt),
        index("idx_memory_fragments_agent").on(table.agentId)
      ]
    );
  }
});

// server/db.ts
var db_exports = {};
__export(db_exports, {
  db: () => db,
  getDbSemaphoreStats: () => getDbSemaphoreStats,
  isDbOverloaded: () => isDbOverloaded,
  pool: () => pool,
  withDbRetry: () => withDbRetry,
  withDbSemaphore: () => withDbSemaphore
});
import { Pool, neonConfig, neon } from "@neondatabase/serverless";
import { drizzle } from "drizzle-orm/neon-serverless";
import { drizzle as drizzleHttp } from "drizzle-orm/neon-http";
import ws from "ws";
import { readFileSync } from "fs";
function getDbSemaphoreStats() {
  return dbSemaphore.stats;
}
function isDbOverloaded() {
  return dbSemaphore.isOverloaded;
}
function getDatabaseUrl() {
  let dbUrl;
  if (process.env.DATABASE_URL) {
    dbUrl = process.env.DATABASE_URL;
    logger.info("[DB] Using DATABASE_URL from environment variable");
  } else {
    try {
      const urlFromFile = readFileSync("/tmp/replitdb", "utf-8").trim();
      if (urlFromFile) {
        logger.info("[DB] Using DATABASE_URL from /tmp/replitdb (deployed app)");
        dbUrl = urlFromFile;
      }
    } catch {
    }
  }
  if (!dbUrl) {
    return void 0;
  }
  if (isDeployedEnv && dbUrl.includes(".neon.tech")) {
    if (dbUrl.includes("-pooler.")) {
      const directUrl = dbUrl.replace(/-pooler\.([a-z0-9-]+)\.neon\.tech/, ".$1.neon.tech");
      logger.info("[DB] Converted pooler URL to direct endpoint for HTTP-only mode");
      logger.info("[DB] Direct endpoint pattern: *.*.neon.tech (no -pooler)");
      return directUrl;
    } else {
      logger.info("[DB] Using direct endpoint for HTTP-only mode (correct for HTTP)");
    }
  }
  return dbUrl;
}
async function withDbSemaphore(operation, operationName) {
  await dbSemaphore.acquire();
  try {
    return await operation();
  } finally {
    dbSemaphore.release();
  }
}
async function withDbRetry(operation, operationName, maxRetries = 7) {
  if (!db) return null;
  await dbSemaphore.acquire();
  let lastError = null;
  let delay = 500;
  let attempts = 0;
  try {
    for (let attempt = 1; attempt <= maxRetries; attempt++) {
      attempts++;
      try {
        return await operation();
      } catch (error) {
        lastError = error;
        const err = error;
        const errorMessage = err.message?.toLowerCase() || "";
        const errorCode = err.code || "";
        const isRetryable = (
          // Timeout errors
          errorMessage.includes("timeout") || errorCode === "ETIMEDOUT" || // Connection errors  
          errorMessage.includes("connect") || errorCode === "ECONNREFUSED" || errorCode === "ECONNRESET" || // Neon/PostgreSQL transient errors
          errorCode === "57P01" || // admin_shutdown
          errorCode === "57P02" || // crash_shutdown  
          errorCode === "57P03" || // cannot_connect_now
          errorCode === "53300" || // too_many_connections
          errorCode === "08006" || // connection_failure
          errorCode === "08003" || // connection_does_not_exist
          // Server closed connection unexpectedly
          errorMessage.includes("server closed") || errorMessage.includes("connection unexpectedly") || errorMessage.includes("terminating connection") || // AbortError from fetch timeouts
          err.name === "AbortError"
        );
        if (attempt < maxRetries && isRetryable) {
          logger.info({ context: "DB", operation: operationName, attempt, maxRetries, delay }, "Retrying operation");
          await new Promise((resolve) => setTimeout(resolve, delay));
          delay = Math.min(delay * 2, 5e3);
        } else {
          const errorType = isRetryable ? "exhausted retries" : "non-retryable";
          logger.error({ err: error, operationName, errorType, attempts }, `[DB] ${operationName} failed`);
          break;
        }
      }
    }
    return null;
  } finally {
    dbSemaphore.release();
  }
}
var isDeployedApp, replitDeploymentVar, hasReplitDbFile, isProductionEnv, noDevWebview, isAutoscale, isDeployedEnv, ConnectionSemaphore, dbSemaphore, pool, db, databaseUrl;
var init_db = __esm({
  "server/db.ts"() {
    "use strict";
    init_logger();
    init_schema();
    isDeployedApp = false;
    replitDeploymentVar = process.env.REPLIT_DEPLOYMENT === "1";
    hasReplitDbFile = false;
    try {
      readFileSync("/tmp/replitdb", "utf-8");
      hasReplitDbFile = true;
    } catch {
    }
    isProductionEnv = process.env.NODE_ENV === "production";
    noDevWebview = !process.env.REPLIT_DEV_DOMAIN;
    isAutoscale = !!process.env.REPLIT_DEPLOYMENT_ID;
    isDeployedApp = replitDeploymentVar || hasReplitDbFile || isAutoscale;
    isDeployedEnv = isDeployedApp || isProductionEnv;
    logger.info("[DB] Production detection signals:");
    logger.info(`  REPLIT_DEPLOYMENT=${process.env.REPLIT_DEPLOYMENT} (${replitDeploymentVar})`);
    logger.info(`  /tmp/replitdb exists: ${hasReplitDbFile}`);
    logger.info(`  NODE_ENV: ${process.env.NODE_ENV}`);
    logger.info(`  REPLIT_DEPLOYMENT_ID: ${process.env.REPLIT_DEPLOYMENT_ID ? "SET" : "NOT SET"}`);
    logger.info(`  Final isDeployedEnv: ${isDeployedEnv}`);
    if (!isDeployedEnv) {
      logger.info("[DB] Development mode - using WebSocket connections");
      neonConfig.webSocketConstructor = ws;
      neonConfig.poolQueryViaFetch = true;
    } else {
      logger.info("[DB] Production mode detected - will use HTTP-only Neon client");
    }
    ConnectionSemaphore = class {
      currentCount = 0;
      maxConcurrent;
      maxQueueSize;
      queue = [];
      name;
      _rejected = 0;
      constructor(maxConcurrent, name = "DB", maxQueueSize = 50) {
        this.maxConcurrent = maxConcurrent;
        this.maxQueueSize = maxQueueSize;
        this.name = name;
      }
      async acquire() {
        if (this.currentCount < this.maxConcurrent) {
          this.currentCount++;
          return;
        }
        if (this.queue.length >= this.maxQueueSize) {
          this._rejected++;
          throw new Error(`[${this.name}] Backpressure: queue full (${this.queue.length}/${this.maxQueueSize})`);
        }
        return new Promise((resolve, reject) => {
          this.queue.push({ resolve: () => {
            this.currentCount++;
            resolve();
          }, reject });
        });
      }
      /**
       * Try to acquire without waiting - returns false if not available
       * Use for non-critical operations that can be skipped under load
       */
      tryAcquire() {
        if (this.currentCount < this.maxConcurrent) {
          this.currentCount++;
          return true;
        }
        return false;
      }
      release() {
        this.currentCount--;
        if (this.queue.length > 0 && this.currentCount < this.maxConcurrent) {
          const next = this.queue.shift();
          if (next) next.resolve();
        }
      }
      get stats() {
        return {
          active: this.currentCount,
          waiting: this.queue.length,
          max: this.maxConcurrent,
          maxQueue: this.maxQueueSize,
          rejected: this._rejected
        };
      }
      get isOverloaded() {
        return this.queue.length > this.maxQueueSize * 0.8;
      }
    };
    dbSemaphore = new ConnectionSemaphore(20, "DB", 50);
    pool = null;
    db = null;
    databaseUrl = getDatabaseUrl();
    if (databaseUrl) {
      try {
        if (isDeployedEnv) {
          logger.info("[DB] Initializing HTTP-only Neon client for production");
          logger.info({ host: new URL(databaseUrl).hostname }, "[DB] Database URL host");
          const sql13 = neon(databaseUrl, {
            fetchOptions: {
              cache: "no-store"
              // Disable caching for consistency
            }
          });
          db = drizzleHttp(sql13, { schema: schema_exports });
          pool = null;
          logger.info("[DB] HTTP-only Neon client initialized successfully");
          const testConnection = async () => {
            try {
              await sql13`SELECT 1 as test`;
              logger.info("[DB] Production connection test: SUCCESS");
            } catch (err) {
              logger.error("[DB] Production connection test: FAILED");
              logger.error("[DB] Error type:", err?.constructor?.name);
              logger.error("[DB] Error message:", err?.message);
              logger.error("[DB] Error code:", err?.code);
              logger.error("[DB] Error cause:", err?.cause?.message || "none");
              if (err?.cause?.cause) {
                logger.error("[DB] Root cause:", err.cause.cause.message || err.cause.cause);
              }
            }
          };
          testConnection();
        } else {
          const connectionTimeout = 15e3;
          pool = new Pool({
            connectionString: databaseUrl,
            max: 30,
            idleTimeoutMillis: 3e4,
            connectionTimeoutMillis: connectionTimeout,
            keepAlive: true,
            keepAliveInitialDelayMillis: 5e3
          });
          db = drizzle(pool, { schema: schema_exports });
          logger.info(`[DB] Database connection pool initialized (max: 30, idle: 30s, timeout: ${connectionTimeout}ms)`);
          pool.on("error", (err) => {
            logger.error({ err }, "[DB] Pool error");
          });
          pool.on("connect", () => {
            logger.info("[DB] New connection acquired");
          });
          pool.query("SELECT 1").catch(() => {
            logger.info("[DB] Initial connection warmup pending - Neon cold start expected");
          });
          setInterval(() => {
            if (pool) {
              const semStats = dbSemaphore.stats;
              logger.info(`[DB] Pool health: total=${pool.totalCount}, idle=${pool.idleCount}, waiting=${pool.waitingCount} | Semaphore: active=${semStats.active}/${semStats.max}, queued=${semStats.waiting}`);
            }
          }, 3e5);
        }
      } catch (err) {
        logger.error({ err }, "[DB] Failed to initialize database connection");
        logger.info("[DB] Running without database - Replit Auth will be unavailable");
        pool = null;
        db = null;
      }
    } else {
      logger.info("[DB] No DATABASE_URL found - running without database (Replit Auth will be unavailable)");
    }
  }
});

// server/persistence/interfaces.ts
var init_interfaces = __esm({
  "server/persistence/interfaces.ts"() {
    "use strict";
  }
});

// server/persistence/adapters/user-postgres-adapter.ts
import { eq } from "drizzle-orm";
var UserPostgresAdapter;
var init_user_postgres_adapter = __esm({
  "server/persistence/adapters/user-postgres-adapter.ts"() {
    "use strict";
    init_db();
    init_schema();
    UserPostgresAdapter = class {
      async getUser(id) {
        if (!db) {
          throw new Error("Database not available - please provision a database to use Replit Auth");
        }
        const result = await withDbRetry(
          () => db.select().from(users).where(eq(users.id, id)),
          "getUser"
        );
        return result?.[0] || void 0;
      }
      async upsertUser(userData) {
        if (!db) {
          throw new Error("Database not available - please provision a database to use Replit Auth");
        }
        if (userData.email) {
          const existingResult = await withDbRetry(
            () => db.select().from(users).where(eq(users.email, userData.email)),
            "upsertUser.selectByEmail"
          );
          const existingUser = existingResult?.[0];
          if (existingUser && existingUser.id !== userData.id) {
            const updateResult = await withDbRetry(
              () => db.update(users).set({
                firstName: userData.firstName,
                lastName: userData.lastName,
                profileImageUrl: userData.profileImageUrl,
                updatedAt: /* @__PURE__ */ new Date()
              }).where(eq(users.email, userData.email)).returning(),
              "upsertUser.updateExisting"
            );
            return updateResult[0];
          }
        }
        const insertResult = await withDbRetry(
          () => db.insert(users).values(userData).onConflictDoUpdate({
            target: users.id,
            set: {
              ...userData,
              updatedAt: /* @__PURE__ */ new Date()
            }
          }).returning(),
          "upsertUser"
        );
        return insertResult[0];
      }
    };
  }
});

// server/persistence/adapters/index.ts
var init_adapters = __esm({
  "server/persistence/adapters/index.ts"() {
    "use strict";
    init_user_postgres_adapter();
  }
});

// server/ocean/ocean-persistence.ts
import { eq as eq2, and, gte, lte, desc, asc, sql as sql2, inArray } from "drizzle-orm";
import * as crypto from "crypto";
var OceanPersistence, oceanPersistence;
var init_ocean_persistence = __esm({
  "server/ocean/ocean-persistence.ts"() {
    "use strict";
    init_db();
    init_schema();
    OceanPersistence = class {
      isAvailable;
      // Batching system for markTested to prevent connection pool exhaustion
      testedPhraseBuffer = /* @__PURE__ */ new Set();
      // Use Set for deduplication
      BATCH_SIZE = 100;
      flushTimer = null;
      FLUSH_INTERVAL_MS = 5e3;
      // Flush every 5 seconds if not full
      isFlushingTested = false;
      consecutiveFailures = 0;
      MAX_CONSECUTIVE_FAILURES = 10;
      constructor() {
        this.isAvailable = db !== null;
        if (this.isAvailable) {
          console.log("[OceanPersistence] PostgreSQL persistence enabled");
        } else {
          console.log("[OceanPersistence] Database not available - using in-memory fallback");
        }
        this.startFlushTimer();
        process.on("beforeExit", () => this.shutdown());
        process.on("SIGINT", () => this.shutdown());
        process.on("SIGTERM", () => this.shutdown());
      }
      /**
       * Graceful shutdown - flush all pending data
       */
      async shutdown() {
        if (this.flushTimer) {
          clearInterval(this.flushTimer);
          this.flushTimer = null;
        }
        if (this.testedPhraseBuffer.size > 0) {
          console.log(`[OceanPersistence] Shutdown: flushing ${this.testedPhraseBuffer.size} pending phrases...`);
          await this.flushTestedPhrases();
        }
      }
      /**
       * Start the periodic flush timer for tested phrases
       */
      startFlushTimer() {
        if (this.flushTimer) clearInterval(this.flushTimer);
        this.flushTimer = setInterval(() => {
          this.flushTestedPhrases().catch((err) => {
            console.error("[OceanPersistence] Periodic flush error:", err);
          });
        }, this.FLUSH_INTERVAL_MS);
      }
      /**
       * Flush all buffered tested phrases to the database with retry logic
       */
      async flushTestedPhrases() {
        if (this.testedPhraseBuffer.size === 0 || this.isFlushingTested) return 0;
        if (this.consecutiveFailures >= this.MAX_CONSECUTIVE_FAILURES) {
          console.warn("[OceanPersistence] Too many consecutive failures, waiting for next cycle");
          return 0;
        }
        this.isFlushingTested = true;
        const toFlush = Array.from(this.testedPhraseBuffer);
        this.testedPhraseBuffer.clear();
        let retries = 3;
        let delay = 100;
        const maxDelay = 2e3;
        while (retries > 0) {
          try {
            const count = await this.batchMarkTestedDirect(toFlush);
            this.isFlushingTested = false;
            this.consecutiveFailures = 0;
            return count;
          } catch (error) {
            const message = error instanceof Error ? error.message : String(error);
            retries--;
            if (retries === 0) {
              this.consecutiveFailures++;
              console.error(`[OceanPersistence] Failed to flush ${toFlush.length} phrases after 3 retries (consecutive failures: ${this.consecutiveFailures}):`, message);
              toFlush.forEach((p) => this.testedPhraseBuffer.add(p));
              this.isFlushingTested = false;
              return 0;
            }
            console.log(`[OceanPersistence] Flush retry in ${delay}ms (${retries} left)`);
            await new Promise((resolve) => setTimeout(resolve, delay));
            delay = Math.min(delay * 2, maxDelay);
          }
        }
        this.isFlushingTested = false;
        return 0;
      }
      /**
       * Internal direct batch write (no buffering)
       */
      async batchMarkTestedDirect(phrases) {
        if (!db || phrases.length === 0) return 0;
        const uniquePhrases = Array.from(new Set(phrases));
        const uniqueHashes = uniquePhrases.map((p) => ({
          phraseHash: crypto.createHash("sha256").update(p).digest("hex")
        }));
        await db.insert(testedPhrasesIndex).values(uniqueHashes).onConflictDoNothing();
        return uniqueHashes.length;
      }
      /**
       * Check if persistence is available
       */
      isPersistenceAvailable() {
        return this.isAvailable;
      }
      // ============================================================================
      // MANIFOLD PROBES - Geometric memory points on the QIG manifold
      // ============================================================================
      /**
       * Insert a batch of manifold probes efficiently
       * Uses circuit breaker pattern to back off when DB is overloaded
       */
      async insertProbes(probes) {
        if (!db || probes.length === 0) return 0;
        if (isDbOverloaded()) {
          console.log("[OceanPersistence] Skipping probe insert - DB overloaded");
          return 0;
        }
        const CHUNK_SIZE = 100;
        const MAX_CONSECUTIVE_FAILURES = 3;
        let totalInserted = 0;
        let consecutiveFailures = 0;
        try {
          for (let i = 0; i < probes.length; i += CHUNK_SIZE) {
            if (consecutiveFailures >= MAX_CONSECUTIVE_FAILURES) {
              console.warn(`[OceanPersistence] Circuit breaker open - stopping after ${consecutiveFailures} failures`);
              break;
            }
            if (isDbOverloaded()) {
              console.log("[OceanPersistence] DB overloaded mid-batch, pausing");
              await new Promise((resolve) => setTimeout(resolve, 1e3));
              if (isDbOverloaded()) break;
            }
            const chunk = probes.slice(i, i + CHUNK_SIZE);
            const records = chunk.map((p) => ({
              id: p.id,
              input: p.input,
              coordinates: p.coordinates,
              phi: p.phi,
              kappa: p.kappa,
              regime: p.regime,
              geometryClass: p.geometryClass,
              complexity: p.complexity,
              ricciScalar: p.ricciScalar ?? 0,
              fisherTrace: p.fisherTrace ?? 0,
              source: p.source
            }));
            try {
              const validRecords = records.filter((r) => {
                if (!r.coordinates || !Array.isArray(r.coordinates) || r.coordinates.length !== 64) {
                  return false;
                }
                return r.coordinates.every((v) => typeof v === "number" && isFinite(v));
              });
              if (validRecords.length === 0) continue;
              await db.insert(manifoldProbes).values(validRecords).onConflictDoNothing();
              totalInserted += validRecords.length;
              consecutiveFailures = 0;
            } catch (chunkError) {
              consecutiveFailures++;
              const errMsg = chunkError instanceof Error ? chunkError.message : String(chunkError);
              if (!errMsg.includes("duplicate key")) {
                console.warn(`[OceanPersistence] Chunk ${i / CHUNK_SIZE} failed (${consecutiveFailures}/${MAX_CONSECUTIVE_FAILURES}): ${errMsg.slice(0, 80)}`);
              }
              await new Promise((resolve) => setTimeout(resolve, 100 * Math.pow(2, consecutiveFailures)));
            }
            if (i + CHUNK_SIZE < probes.length) {
              await new Promise((resolve) => setTimeout(resolve, 50));
            }
          }
          return totalInserted;
        } catch (error) {
          console.error("[OceanPersistence] Failed to insert probes:", error);
          return totalInserted;
        }
      }
      /**
       * Query probes by φ/κ range
       * Optimized for geometric navigation
       */
      async queryProbesByPhiKappa(range, limit = 100) {
        if (!db) return [];
        try {
          const conditions = [];
          if (range.phiMin !== void 0) conditions.push(gte(manifoldProbes.phi, range.phiMin));
          if (range.phiMax !== void 0) conditions.push(lte(manifoldProbes.phi, range.phiMax));
          if (range.kappaMin !== void 0) conditions.push(gte(manifoldProbes.kappa, range.kappaMin));
          if (range.kappaMax !== void 0) conditions.push(lte(manifoldProbes.kappa, range.kappaMax));
          const query = conditions.length > 0 ? db.select().from(manifoldProbes).where(and(...conditions)) : db.select().from(manifoldProbes);
          return await query.orderBy(desc(manifoldProbes.phi)).limit(limit);
        } catch (error) {
          console.error("[OceanPersistence] Failed to query probes:", error);
          return [];
        }
      }
      /**
       * Query probes by regime
       */
      async queryProbesByRegime(regime, limit = 100) {
        if (!db) return [];
        try {
          return await db.select().from(manifoldProbes).where(eq2(manifoldProbes.regime, regime)).orderBy(desc(manifoldProbes.phi)).limit(limit);
        } catch (error) {
          console.error("[OceanPersistence] Failed to query probes by regime:", error);
          return [];
        }
      }
      /**
       * Get high-Φ probes (resonant points)
       */
      async getHighPhiProbes(minPhi = 0.75, limit = 100) {
        if (!db) return [];
        try {
          return await db.select().from(manifoldProbes).where(gte(manifoldProbes.phi, minPhi)).orderBy(desc(manifoldProbes.phi)).limit(limit);
        } catch (error) {
          console.error("[OceanPersistence] Failed to get high-\u03A6 probes:", error);
          return [];
        }
      }
      /**
       * Get all probes with pagination
       * Used for initial memory load from PostgreSQL
       */
      async getAllProbes(limit = 1e3, offset = 0) {
        if (!db) return [];
        try {
          return await db.select().from(manifoldProbes).orderBy(desc(manifoldProbes.createdAt)).limit(limit).offset(offset);
        } catch (error) {
          console.error("[OceanPersistence] Failed to get all probes:", error);
          return [];
        }
      }
      /**
       * Get total probe count
       */
      async getProbeCount() {
        if (!db) return 0;
        try {
          const result = await db.select({ count: sql2`count(*)` }).from(manifoldProbes);
          return Number(result[0]?.count ?? 0);
        } catch (error) {
          console.error("[OceanPersistence] Failed to get probe count:", error);
          return 0;
        }
      }
      /**
       * Get probes by IDs
       */
      async getProbesByIds(ids) {
        if (!db || ids.length === 0) return [];
        try {
          return await db.select().from(manifoldProbes).where(inArray(manifoldProbes.id, ids));
        } catch (error) {
          console.error("[OceanPersistence] Failed to get probes by IDs:", error);
          return [];
        }
      }
      // ============================================================================
      // RESONANCE POINTS - High-Φ clusters on the manifold
      // ============================================================================
      /**
       * Insert a resonance point
       */
      async insertResonancePoint(point) {
        if (!db) return false;
        try {
          await db.insert(resonancePoints).values({
            id: point.id,
            probeId: point.probeId,
            phi: point.phi,
            kappa: point.kappa,
            nearbyProbes: point.nearbyProbes,
            clusterStrength: point.clusterStrength
          }).onConflictDoNothing();
          return true;
        } catch (error) {
          console.error("[OceanPersistence] Failed to insert resonance point:", error);
          return false;
        }
      }
      /**
       * Get all resonance points
       */
      async getResonancePoints(limit = 100) {
        if (!db) return [];
        try {
          return await db.select().from(resonancePoints).orderBy(desc(resonancePoints.clusterStrength)).limit(limit);
        } catch (error) {
          console.error("[OceanPersistence] Failed to get resonance points:", error);
          return [];
        }
      }
      // ============================================================================
      // REGIME BOUNDARIES - Transitions between regimes
      // ============================================================================
      /**
       * Insert a regime boundary
       */
      async insertRegimeBoundary(boundary) {
        if (!db) return false;
        try {
          await db.insert(regimeBoundaries).values(boundary).onConflictDoNothing();
          return true;
        } catch (error) {
          console.error("[OceanPersistence] Failed to insert regime boundary:", error);
          return false;
        }
      }
      /**
       * Get regime boundaries
       */
      async getRegimeBoundaries(fromRegime, toRegime) {
        if (!db) return [];
        try {
          const conditions = [];
          if (fromRegime) conditions.push(eq2(regimeBoundaries.fromRegime, fromRegime));
          if (toRegime) conditions.push(eq2(regimeBoundaries.toRegime, toRegime));
          const query = conditions.length > 0 ? db.select().from(regimeBoundaries).where(and(...conditions)) : db.select().from(regimeBoundaries);
          return await query.orderBy(desc(regimeBoundaries.midpointPhi));
        } catch (error) {
          console.error("[OceanPersistence] Failed to get regime boundaries:", error);
          return [];
        }
      }
      // ============================================================================
      // GEODESIC PATHS - Fisher-optimal paths between probes
      // ============================================================================
      /**
       * Insert a geodesic path
       */
      async insertGeodesicPath(path15) {
        if (!db) return false;
        try {
          await db.insert(geodesicPaths).values(path15).onConflictDoNothing();
          return true;
        } catch (error) {
          console.error("[OceanPersistence] Failed to insert geodesic path:", error);
          return false;
        }
      }
      // ============================================================================
      // TPS LANDMARKS - Fixed spacetime reference points
      // ============================================================================
      /**
       * Insert or update a TPS landmark
       */
      async upsertLandmark(landmark) {
        if (!db) return false;
        try {
          await db.insert(tpsLandmarks).values({
            eventId: landmark.eventId,
            description: landmark.description,
            era: landmark.era,
            spacetimeX: landmark.spacetimeX ?? 0,
            spacetimeY: landmark.spacetimeY ?? 0,
            spacetimeZ: landmark.spacetimeZ ?? 0,
            spacetimeT: landmark.spacetimeT,
            culturalCoords: landmark.culturalCoords,
            fisherSignature: landmark.fisherSignature,
            lightConePast: landmark.lightConePast,
            lightConeFuture: landmark.lightConeFuture
          }).onConflictDoUpdate({
            target: tpsLandmarks.eventId,
            set: {
              description: landmark.description,
              era: landmark.era,
              spacetimeX: landmark.spacetimeX ?? 0,
              spacetimeY: landmark.spacetimeY ?? 0,
              spacetimeZ: landmark.spacetimeZ ?? 0,
              spacetimeT: landmark.spacetimeT,
              culturalCoords: landmark.culturalCoords,
              fisherSignature: landmark.fisherSignature,
              lightConePast: landmark.lightConePast,
              lightConeFuture: landmark.lightConeFuture
            }
          });
          return true;
        } catch (error) {
          console.error("[OceanPersistence] Failed to upsert landmark:", error);
          return false;
        }
      }
      /**
       * Get all TPS landmarks
       */
      async getLandmarks() {
        if (!db) return [];
        try {
          return await db.select().from(tpsLandmarks).orderBy(asc(tpsLandmarks.spacetimeT));
        } catch (error) {
          console.error("[OceanPersistence] Failed to get landmarks:", error);
          return [];
        }
      }
      /**
       * Get landmarks by era
       */
      async getLandmarksByEra(era) {
        if (!db) return [];
        try {
          return await db.select().from(tpsLandmarks).where(eq2(tpsLandmarks.era, era)).orderBy(asc(tpsLandmarks.spacetimeT));
        } catch (error) {
          console.error("[OceanPersistence] Failed to get landmarks by era:", error);
          return [];
        }
      }
      // ============================================================================
      // TPS GEODESIC PATHS - Computed paths between landmarks
      // ============================================================================
      /**
       * Insert a TPS geodesic path
       */
      async insertTpsGeodesicPath(path15) {
        if (!db) return false;
        try {
          await db.insert(tpsGeodesicPaths).values({
            id: path15.id,
            fromLandmark: path15.fromLandmark,
            toLandmark: path15.toLandmark,
            distance: path15.distance,
            waypoints: path15.waypoints,
            totalArcLength: path15.totalArcLength,
            avgCurvature: path15.avgCurvature,
            regimeTransitions: path15.regimeTransitions
          }).onConflictDoNothing();
          return true;
        } catch (error) {
          console.error("[OceanPersistence] Failed to insert TPS geodesic path:", error);
          return false;
        }
      }
      // ============================================================================
      // OCEAN TRAJECTORIES - Navigation trajectories
      // ============================================================================
      /**
       * Start a new trajectory
       */
      async startTrajectory(id, address) {
        if (!db) return false;
        const result = await withDbRetry(
          async () => {
            await db.insert(oceanTrajectories).values({
              id,
              address,
              status: "active"
            });
            return true;
          },
          "startTrajectory",
          3
        );
        return result ?? false;
      }
      /**
       * Record a waypoint on a trajectory
       */
      async recordWaypoint(trajectoryId, waypoint) {
        if (!db) return false;
        try {
          const waypointId = crypto.randomUUID().substring(0, 32);
          const trajectory = await db.select().from(oceanTrajectories).where(eq2(oceanTrajectories.id, trajectoryId)).limit(1);
          if (trajectory.length === 0) return false;
          const nextSequence = (trajectory[0].waypointCount ?? 0) + 1;
          await db.insert(oceanWaypoints).values({
            id: waypointId,
            trajectoryId,
            sequence: nextSequence,
            phi: waypoint.phi,
            kappa: waypoint.kappa,
            regime: waypoint.regime,
            basinCoords: waypoint.basinCoords,
            event: waypoint.event,
            details: waypoint.details
          });
          await db.update(oceanTrajectories).set({
            waypointCount: nextSequence,
            lastPhi: waypoint.phi,
            lastKappa: waypoint.kappa,
            updatedAt: /* @__PURE__ */ new Date()
          }).where(eq2(oceanTrajectories.id, trajectoryId));
          return true;
        } catch (error) {
          console.error("[OceanPersistence] Failed to record waypoint:", error);
          return false;
        }
      }
      /**
       * Complete a trajectory
       */
      async completeTrajectory(trajectoryId, result, stats) {
        if (!db) return false;
        const opResult = await withDbRetry(
          async () => {
            const trajectory = await db.select().from(oceanTrajectories).where(eq2(oceanTrajectories.id, trajectoryId)).limit(1);
            if (trajectory.length === 0) return false;
            const startTime2 = trajectory[0].startTime;
            const endTime = /* @__PURE__ */ new Date();
            const durationSeconds = (endTime.getTime() - startTime2.getTime()) / 1e3;
            await db.update(oceanTrajectories).set({
              status: "completed",
              endTime,
              finalResult: result,
              durationSeconds,
              nearMissCount: stats?.nearMissCount ?? trajectory[0].nearMissCount,
              resonantCount: stats?.resonantCount ?? trajectory[0].resonantCount,
              updatedAt: endTime
            }).where(eq2(oceanTrajectories.id, trajectoryId));
            return true;
          },
          "completeTrajectory",
          3
        );
        return opResult ?? false;
      }
      /**
       * Get active trajectories for an address
       */
      async getActiveTrajectories(address) {
        if (!db) return [];
        try {
          const conditions = [eq2(oceanTrajectories.status, "active")];
          if (address) conditions.push(eq2(oceanTrajectories.address, address));
          return await db.select().from(oceanTrajectories).where(and(...conditions)).orderBy(desc(oceanTrajectories.startTime));
        } catch (error) {
          console.error("[OceanPersistence] Failed to get active trajectories:", error);
          return [];
        }
      }
      /**
       * Get trajectory with its waypoints
       */
      async getTrajectoryWithWaypoints(trajectoryId) {
        if (!db) return { trajectory: null, waypoints: [] };
        try {
          const trajectories = await db.select().from(oceanTrajectories).where(eq2(oceanTrajectories.id, trajectoryId)).limit(1);
          if (trajectories.length === 0) {
            return { trajectory: null, waypoints: [] };
          }
          const waypoints = await db.select().from(oceanWaypoints).where(eq2(oceanWaypoints.trajectoryId, trajectoryId)).orderBy(asc(oceanWaypoints.sequence));
          return { trajectory: trajectories[0], waypoints };
        } catch (error) {
          console.error("[OceanPersistence] Failed to get trajectory with waypoints:", error);
          return { trajectory: null, waypoints: [] };
        }
      }
      // ============================================================================
      // QUANTUM STATE - Wave function and entropy tracking
      // ============================================================================
      /**
       * Get or initialize quantum state
       */
      async getQuantumState() {
        if (!db) return null;
        try {
          const states = await db.select().from(oceanQuantumState).where(eq2(oceanQuantumState.id, "singleton")).limit(1);
          if (states.length === 0) {
            await db.insert(oceanQuantumState).values({
              id: "singleton",
              entropy: 256,
              initialEntropy: 256,
              totalProbability: 1,
              measurementCount: 0,
              successfulMeasurements: 0,
              status: "searching"
            });
            return await db.select().from(oceanQuantumState).where(eq2(oceanQuantumState.id, "singleton")).limit(1).then((r) => r[0] ?? null);
          }
          return states[0];
        } catch (error) {
          console.error("[OceanPersistence] Failed to get quantum state:", error);
          return null;
        }
      }
      /**
       * Update quantum state after a measurement
       */
      async updateQuantumState(update) {
        if (!db) return false;
        try {
          await db.update(oceanQuantumState).set({
            ...update,
            lastMeasurementAt: /* @__PURE__ */ new Date(),
            updatedAt: /* @__PURE__ */ new Date()
          }).where(eq2(oceanQuantumState.id, "singleton"));
          return true;
        } catch (error) {
          console.error("[OceanPersistence] Failed to update quantum state:", error);
          return false;
        }
      }
      // ============================================================================
      // EXCLUDED REGIONS - Regions excluded from possibility space
      // ============================================================================
      /**
       * Insert an excluded region
       */
      async insertExcludedRegion(region) {
        if (!db) return false;
        try {
          await db.insert(oceanExcludedRegions).values({
            id: region.id,
            dimension: region.dimension,
            origin: region.origin,
            basis: region.basis,
            measure: region.measure,
            phi: region.phi,
            regime: region.regime
          }).onConflictDoNothing();
          return true;
        } catch (error) {
          console.error("[OceanPersistence] Failed to insert excluded region:", error);
          return false;
        }
      }
      /**
       * Get excluded regions (top by measure)
       */
      async getExcludedRegions(limit = 100) {
        if (!db) return [];
        try {
          return await db.select().from(oceanExcludedRegions).orderBy(desc(oceanExcludedRegions.measure)).limit(limit);
        } catch (error) {
          console.error("[OceanPersistence] Failed to get excluded regions:", error);
          return [];
        }
      }
      /**
       * Get excluded region count
       */
      async getExcludedRegionCount() {
        if (!db) return 0;
        try {
          const result = await db.select({ count: sql2`count(*)` }).from(oceanExcludedRegions);
          return Number(result[0]?.count ?? 0);
        } catch (error) {
          console.error("[OceanPersistence] Failed to get excluded region count:", error);
          return 0;
        }
      }
      // ============================================================================
      // TESTED PHRASES INDEX - Fast lookup for already-tested phrases
      // ============================================================================
      /**
       * Check if a phrase has been tested
       */
      async hasBeenTested(phrase) {
        if (!db) return false;
        try {
          const hash = crypto.createHash("sha256").update(phrase).digest("hex");
          const result = await db.select().from(testedPhrasesIndex).where(eq2(testedPhrasesIndex.phraseHash, hash)).limit(1);
          return result.length > 0;
        } catch (error) {
          console.error("[OceanPersistence] Failed to check tested phrase:", error);
          return false;
        }
      }
      /**
       * Mark a phrase as tested (BUFFERED - no immediate DB write)
       * Uses internal buffer to batch writes and prevent connection pool exhaustion
       */
      async markTested(phrase) {
        if (!db) return false;
        this.testedPhraseBuffer.add(phrase);
        if (this.testedPhraseBuffer.size >= this.BATCH_SIZE) {
          this.flushTestedPhrases().catch((err) => {
            console.error("[OceanPersistence] Background flush error:", err);
          });
        }
        return true;
      }
      /**
       * Batch mark phrases as tested (BUFFERED)
       * Adds to internal buffer for efficient batched writes
       */
      async batchMarkTested(phrases) {
        if (!db || phrases.length === 0) return 0;
        phrases.forEach((p) => this.testedPhraseBuffer.add(p));
        if (this.testedPhraseBuffer.size >= this.BATCH_SIZE) {
          await this.flushTestedPhrases();
        }
        return phrases.length;
      }
      /**
       * Get current buffer size (for monitoring)
       */
      getTestedPhraseBufferSize() {
        return this.testedPhraseBuffer.size;
      }
      // ============================================================================
      // NEAR-MISS PERSISTENCE - Tiered near-miss entries and clusters
      // ============================================================================
      /**
       * Insert or update a near-miss entry
       */
      async upsertNearMissEntry(entry) {
        if (!db) return false;
        try {
          const phraseHash = crypto.createHash("sha256").update(entry.phrase).digest("hex");
          await db.insert(nearMissEntries).values({
            id: entry.id,
            phrase: entry.phrase,
            phraseHash,
            phi: entry.phi,
            kappa: entry.kappa,
            regime: entry.regime,
            tier: entry.tier,
            source: entry.source,
            clusterId: entry.clusterId,
            phiHistory: entry.phiHistory,
            isEscalating: entry.isEscalating ?? false,
            queuePriority: entry.queuePriority ?? 1,
            structuralSignature: entry.structuralSignature,
            explorationCount: entry.explorationCount ?? 1
          }).onConflictDoUpdate({
            target: nearMissEntries.id,
            set: {
              phi: entry.phi,
              kappa: entry.kappa,
              tier: entry.tier,
              lastAccessedAt: /* @__PURE__ */ new Date(),
              phiHistory: entry.phiHistory,
              isEscalating: entry.isEscalating ?? false,
              queuePriority: entry.queuePriority ?? 1,
              explorationCount: entry.explorationCount ?? 1
            }
          });
          return true;
        } catch (error) {
          console.error("[OceanPersistence] Failed to upsert near-miss entry:", error);
          return false;
        }
      }
      /**
       * Batch insert/update near-miss entries with chunking and retry logic
       * Processes entries in chunks to avoid connection pool exhaustion
       */
      async batchUpsertNearMissEntries(entries) {
        if (!db || entries.length === 0) return 0;
        const CHUNK_SIZE = 50;
        const CHUNK_DELAY_MS = 100;
        let count = 0;
        for (let i = 0; i < entries.length; i += CHUNK_SIZE) {
          const chunk = entries.slice(i, i + CHUNK_SIZE);
          for (const entry of chunk) {
            for (let attempt = 0; attempt < 3; attempt++) {
              try {
                const phraseHash = crypto.createHash("sha256").update(entry.phrase).digest("hex");
                await db.insert(nearMissEntries).values({
                  id: entry.id,
                  phrase: entry.phrase,
                  phraseHash,
                  phi: entry.phi,
                  kappa: entry.kappa,
                  regime: entry.regime,
                  tier: entry.tier,
                  source: entry.source,
                  clusterId: entry.clusterId,
                  phiHistory: entry.phiHistory,
                  isEscalating: entry.isEscalating ?? false,
                  queuePriority: entry.queuePriority ?? 1,
                  structuralSignature: entry.structuralSignature,
                  explorationCount: entry.explorationCount ?? 1
                }).onConflictDoUpdate({
                  target: nearMissEntries.id,
                  set: {
                    phi: entry.phi,
                    kappa: entry.kappa,
                    tier: entry.tier,
                    lastAccessedAt: /* @__PURE__ */ new Date(),
                    phiHistory: entry.phiHistory,
                    isEscalating: entry.isEscalating ?? false,
                    queuePriority: entry.queuePriority ?? 1,
                    explorationCount: entry.explorationCount ?? 1
                  }
                });
                count++;
                break;
              } catch (error) {
                if (attempt < 2) {
                  await new Promise((r) => setTimeout(r, 100 * Math.pow(2, attempt)));
                }
              }
            }
          }
          if (i + CHUNK_SIZE < entries.length) {
            await new Promise((r) => setTimeout(r, CHUNK_DELAY_MS));
          }
        }
        return count;
      }
      /**
       * Get near-miss entries by tier
       */
      async getNearMissEntriesByTier(tier, limit = 100) {
        if (!db) return [];
        try {
          if (tier) {
            return await db.select().from(nearMissEntries).where(eq2(nearMissEntries.tier, tier)).orderBy(desc(nearMissEntries.phi)).limit(limit);
          }
          return await db.select().from(nearMissEntries).orderBy(desc(nearMissEntries.phi)).limit(limit);
        } catch (error) {
          console.error("[OceanPersistence] Failed to get near-miss entries:", error);
          return [];
        }
      }
      /**
       * Get escalating near-miss entries
       */
      async getEscalatingNearMisses(limit = 100) {
        if (!db) return [];
        try {
          return await db.select().from(nearMissEntries).where(eq2(nearMissEntries.isEscalating, true)).orderBy(desc(nearMissEntries.phi)).limit(limit);
        } catch (error) {
          console.error("[OceanPersistence] Failed to get escalating near-misses:", error);
          return [];
        }
      }
      /**
       * Get all near-miss entries for loading into memory
       */
      async getAllNearMissEntries() {
        if (!db) return [];
        try {
          return await db.select().from(nearMissEntries).orderBy(desc(nearMissEntries.phi));
        } catch (error) {
          console.error("[OceanPersistence] Failed to get all near-miss entries:", error);
          return [];
        }
      }
      /**
       * Delete a near-miss entry
       */
      async deleteNearMissEntry(id) {
        if (!db) return false;
        try {
          await db.delete(nearMissEntries).where(eq2(nearMissEntries.id, id));
          return true;
        } catch (error) {
          console.error("[OceanPersistence] Failed to delete near-miss entry:", error);
          return false;
        }
      }
      /**
       * Get near-miss entry count
       */
      async getNearMissCount() {
        if (!db) return 0;
        try {
          const result = await db.select({ count: sql2`count(*)` }).from(nearMissEntries);
          return Number(result[0]?.count ?? 0);
        } catch (error) {
          console.error("[OceanPersistence] Failed to get near-miss count:", error);
          return 0;
        }
      }
      /**
       * Insert or update a near-miss cluster
       */
      async upsertNearMissCluster(cluster) {
        if (!db) return false;
        try {
          await db.insert(nearMissClusters).values({
            id: cluster.id,
            centroidPhrase: cluster.centroidPhrase,
            centroidPhi: cluster.centroidPhi,
            memberCount: cluster.memberCount,
            avgPhi: cluster.avgPhi,
            maxPhi: cluster.maxPhi,
            commonWords: cluster.commonWords,
            structuralPattern: cluster.structuralPattern
          }).onConflictDoUpdate({
            target: nearMissClusters.id,
            set: {
              centroidPhrase: cluster.centroidPhrase,
              centroidPhi: cluster.centroidPhi,
              memberCount: cluster.memberCount,
              avgPhi: cluster.avgPhi,
              maxPhi: cluster.maxPhi,
              commonWords: cluster.commonWords,
              structuralPattern: cluster.structuralPattern,
              lastUpdatedAt: /* @__PURE__ */ new Date()
            }
          });
          return true;
        } catch (error) {
          console.error("[OceanPersistence] Failed to upsert near-miss cluster:", error);
          return false;
        }
      }
      /**
       * Get all near-miss clusters
       */
      async getAllNearMissClusters() {
        if (!db) return [];
        try {
          return await db.select().from(nearMissClusters).orderBy(desc(nearMissClusters.avgPhi));
        } catch (error) {
          console.error("[OceanPersistence] Failed to get near-miss clusters:", error);
          return [];
        }
      }
      /**
       * Delete a near-miss cluster
       */
      async deleteNearMissCluster(id) {
        if (!db) return false;
        try {
          await db.delete(nearMissClusters).where(eq2(nearMissClusters.id, id));
          return true;
        } catch (error) {
          console.error("[OceanPersistence] Failed to delete near-miss cluster:", error);
          return false;
        }
      }
      /**
       * Save adaptive state (thresholds and rolling distribution)
       */
      async saveNearMissAdaptiveState(state) {
        if (!db) return false;
        try {
          await db.insert(nearMissAdaptiveState).values({
            id: "singleton",
            rollingPhiDistribution: state.rollingPhiDistribution,
            hotThreshold: state.hotThreshold,
            warmThreshold: state.warmThreshold,
            coolThreshold: state.coolThreshold,
            distributionSize: state.rollingPhiDistribution.length,
            lastComputed: /* @__PURE__ */ new Date(),
            updatedAt: /* @__PURE__ */ new Date()
          }).onConflictDoUpdate({
            target: nearMissAdaptiveState.id,
            set: {
              rollingPhiDistribution: state.rollingPhiDistribution,
              hotThreshold: state.hotThreshold,
              warmThreshold: state.warmThreshold,
              coolThreshold: state.coolThreshold,
              distributionSize: state.rollingPhiDistribution.length,
              lastComputed: /* @__PURE__ */ new Date(),
              updatedAt: /* @__PURE__ */ new Date()
            }
          });
          return true;
        } catch (error) {
          console.error("[OceanPersistence] Failed to save near-miss adaptive state:", error);
          return false;
        }
      }
      /**
       * Load adaptive state
       */
      async loadNearMissAdaptiveState() {
        if (!db) return null;
        try {
          const results = await db.select().from(nearMissAdaptiveState).where(eq2(nearMissAdaptiveState.id, "singleton")).limit(1);
          return results[0] ?? null;
        } catch (error) {
          console.error("[OceanPersistence] Failed to load near-miss adaptive state:", error);
          return null;
        }
      }
      /**
       * Check if a phrase has already been recorded as a near-miss (deduplication)
       */
      async hasNearMissPhrase(phrase) {
        if (!db) return false;
        try {
          const phraseHash = crypto.createHash("sha256").update(phrase).digest("hex");
          const results = await db.select({ id: nearMissEntries.id }).from(nearMissEntries).where(eq2(nearMissEntries.phraseHash, phraseHash)).limit(1);
          return results.length > 0;
        } catch (error) {
          console.error("[OceanPersistence] Failed to check near-miss phrase:", error);
          return false;
        }
      }
      // ============================================================================
      // STATISTICS AND SUMMARY
      // ============================================================================
      /**
       * Get persistence statistics
       */
      async getStats() {
        const [
          probeCount,
          resonancePointCount,
          trajectoryCount,
          activeTrajectoryCount,
          excludedRegionCount,
          testedPhraseCount,
          nearMissCount,
          nearMissClusterCount,
          quantumState
        ] = await Promise.all([
          this.getProbeCount(),
          this.getResonancePoints(1).then((r) => r.length > 0 ? this.getResonancePoints(1e3).then((r2) => r2.length) : 0),
          db ? db.select({ count: sql2`count(*)` }).from(oceanTrajectories).then((r) => Number(r[0]?.count ?? 0)) : 0,
          db ? db.select({ count: sql2`count(*)` }).from(oceanTrajectories).where(eq2(oceanTrajectories.status, "active")).then((r) => Number(r[0]?.count ?? 0)) : 0,
          this.getExcludedRegionCount(),
          db ? db.select({ count: sql2`count(*)` }).from(testedPhrasesIndex).then((r) => Number(r[0]?.count ?? 0)) : 0,
          this.getNearMissCount(),
          db ? db.select({ count: sql2`count(*)` }).from(nearMissClusters).then((r) => Number(r[0]?.count ?? 0)) : 0,
          this.getQuantumState()
        ]);
        return {
          probeCount,
          resonancePointCount,
          trajectoryCount,
          activeTrajectoryCount,
          excludedRegionCount,
          testedPhraseCount,
          nearMissCount,
          nearMissClusterCount,
          quantumState
        };
      }
    };
    oceanPersistence = new OceanPersistence();
  }
});

// server/persistence/facade.ts
var InMemoryCandidateStorage, InMemoryTargetAddressStorage, StorageFacade, storageFacade;
var init_facade = __esm({
  "server/persistence/facade.ts"() {
    "use strict";
    init_adapters();
    init_db();
    init_ocean_persistence();
    InMemoryCandidateStorage = class {
      candidates = [];
      async getCandidates() {
        return [...this.candidates];
      }
      async addCandidate(candidate) {
        const existing = this.candidates.findIndex((c) => c.id === candidate.id);
        if (existing >= 0) {
          this.candidates[existing] = candidate;
        } else {
          this.candidates.push(candidate);
        }
      }
      async clearCandidates() {
        this.candidates = [];
      }
    };
    InMemoryTargetAddressStorage = class {
      addresses = [];
      async getTargetAddresses() {
        return [...this.addresses];
      }
      async addTargetAddress(address) {
        const existing = this.addresses.findIndex((a) => a.id === address.id);
        if (existing >= 0) {
          this.addresses[existing] = address;
        } else {
          this.addresses.push(address);
        }
      }
      async removeTargetAddress(id) {
        this.addresses = this.addresses.filter((a) => a.id !== id);
      }
    };
    StorageFacade = class {
      _candidates;
      _targetAddresses;
      _users;
      _oceanProbes = null;
      _testedPhrases = null;
      _searchJobs;
      _config;
      constructor(config) {
        this._config = {
          backend: config?.backend ?? "postgres",
          dataDir: config?.dataDir
        };
        if (this._config.backend !== "postgres") {
          throw new Error('[StorageFacade] Only postgres backend is supported. Set backend to "postgres".');
        }
        if (!db) {
          throw new Error("[StorageFacade] DATABASE_URL not set - postgres backend is required for persistence");
        }
        this._candidates = new InMemoryCandidateStorage();
        this._targetAddresses = new InMemoryTargetAddressStorage();
        this._users = new UserPostgresAdapter();
        this._searchJobs = {
          getSearchJobs: async () => [],
          getSearchJob: async () => null,
          addSearchJob: async () => {
          },
          updateSearchJob: async () => {
          },
          appendJobLog: async () => {
          },
          deleteSearchJob: async () => {
          }
        };
        if (oceanPersistence.isPersistenceAvailable()) {
          this._oceanProbes = {
            insertProbes: (probes) => oceanPersistence.insertProbes(probes),
            queryProbesByPhiKappa: (range, limit) => oceanPersistence.queryProbesByPhiKappa(range, limit),
            queryProbesByRegime: (regime, limit) => oceanPersistence.queryProbesByRegime(regime, limit),
            getHighPhiProbes: (minPhi, limit) => oceanPersistence.getHighPhiProbes(minPhi, limit),
            getProbeCount: () => oceanPersistence.getProbeCount()
          };
          this._testedPhrases = {
            markTested: (phrase) => oceanPersistence.markTested(phrase),
            batchMarkTested: (phrases) => oceanPersistence.batchMarkTested(phrases),
            hasBeenTested: (phrase) => oceanPersistence.hasBeenTested(phrase),
            flushTestedPhrases: () => oceanPersistence.flushTestedPhrases()
          };
        }
        console.log(`[StorageFacade] Initialized with backend: ${this._config.backend}`);
      }
      get config() {
        return { ...this._config };
      }
      get candidates() {
        return this._candidates;
      }
      get targetAddresses() {
        return this._targetAddresses;
      }
      get users() {
        return this._users;
      }
      get oceanProbes() {
        return this._oceanProbes;
      }
      get testedPhrases() {
        return this._testedPhrases;
      }
      get searchJobs() {
        return this._searchJobs;
      }
      isOceanPersistenceAvailable() {
        return this._oceanProbes !== null;
      }
    };
    storageFacade = new StorageFacade({ backend: "postgres" });
  }
});

// server/persistence/index.ts
var init_persistence = __esm({
  "server/persistence/index.ts"() {
    "use strict";
    init_interfaces();
    init_adapters();
    init_facade();
  }
});

// server/storage.ts
var storage_exports = {};
__export(storage_exports, {
  storage: () => storage
});
var PostgresStorage, storage;
var init_storage = __esm({
  "server/storage.ts"() {
    "use strict";
    init_persistence();
    PostgresStorage = class {
      async getCandidates() {
        return storageFacade.candidates.getCandidates();
      }
      async addCandidate(candidate) {
        return storageFacade.candidates.addCandidate(candidate);
      }
      async clearCandidates() {
        return storageFacade.candidates.clearCandidates();
      }
      async getTargetAddresses() {
        return storageFacade.targetAddresses.getTargetAddresses();
      }
      async addTargetAddress(address) {
        return storageFacade.targetAddresses.addTargetAddress(address);
      }
      async removeTargetAddress(id) {
        return storageFacade.targetAddresses.removeTargetAddress(id);
      }
      async getSearchJobs() {
        return storageFacade.searchJobs.getSearchJobs();
      }
      async getSearchJob(id) {
        return storageFacade.searchJobs.getSearchJob(id);
      }
      async addSearchJob(job) {
        return storageFacade.searchJobs.addSearchJob(job);
      }
      async updateSearchJob(id, updates) {
        return storageFacade.searchJobs.updateSearchJob(id, updates);
      }
      async appendJobLog(id, log2) {
        return storageFacade.searchJobs.appendJobLog(id, log2);
      }
      async deleteSearchJob(id) {
        return storageFacade.searchJobs.deleteSearchJob(id);
      }
      async getUser(id) {
        return storageFacade.users.getUser(id);
      }
      async upsertUser(user) {
        return storageFacade.users.upsertUser(user);
      }
    };
    storage = new PostgresStorage();
  }
});

// server/redis-cache.ts
import Redis from "ioredis";
function initRedis() {
  if (redisClient) {
    return redisClient;
  }
  const redisUrl = process.env.REDIS_URL;
  if (!redisUrl) {
    console.log("[Redis] REDIS_URL not configured - caching disabled");
    return null;
  }
  try {
    redisClient = new Redis(redisUrl, REDIS_CONFIG);
    redisClient.on("connect", () => {
      console.log("[Redis] Connected successfully");
      redisAvailable = true;
    });
    redisClient.on("error", (err) => {
      console.error("[Redis] Connection error:", err);
      redisAvailable = false;
    });
    redisClient.on("close", () => {
      console.log("[Redis] Connection closed");
      redisAvailable = false;
    });
    redisClient.connect().catch((err) => {
      console.error("[Redis] Failed to connect:", err);
      redisAvailable = false;
    });
    return redisClient;
  } catch (error) {
    console.error("[Redis] Initialization error:", error);
    return null;
  }
}
function isRedisAvailable() {
  return redisAvailable && redisClient !== null;
}
async function cacheSet(key, value, ttlSeconds = CACHE_TTL.MEDIUM) {
  if (!isRedisAvailable() || !redisClient) {
    return false;
  }
  try {
    const serialized = JSON.stringify(value);
    await redisClient.setex(key, ttlSeconds, serialized);
    return true;
  } catch (error) {
    console.error("[Redis] Set error:", error);
    return false;
  }
}
async function cacheGet(key) {
  if (!isRedisAvailable() || !redisClient) {
    return null;
  }
  try {
    const data = await redisClient.get(key);
    if (!data) {
      return null;
    }
    return JSON.parse(data);
  } catch (error) {
    console.error("[Redis] Get error:", error);
    return null;
  }
}
async function cacheHSet(hashKey, field, value) {
  if (!isRedisAvailable() || !redisClient) {
    return false;
  }
  try {
    const serialized = JSON.stringify(value);
    await redisClient.hset(hashKey, field, serialized);
    return true;
  } catch (error) {
    console.error("[Redis] HSet error:", error);
    return false;
  }
}
async function cacheHGet(hashKey, field) {
  if (!isRedisAvailable() || !redisClient) {
    return null;
  }
  try {
    const data = await redisClient.hget(hashKey, field);
    if (!data) {
      return null;
    }
    return JSON.parse(data);
  } catch (error) {
    console.error("[Redis] HGet error:", error);
    return null;
  }
}
var REDIS_CONFIG, CACHE_TTL, CACHE_KEYS, redisClient, redisAvailable;
var init_redis_cache = __esm({
  "server/redis-cache.ts"() {
    "use strict";
    REDIS_CONFIG = {
      maxRetriesPerRequest: 3,
      enableOfflineQueue: false,
      lazyConnect: true,
      connectTimeout: 1e4,
      retryStrategy: (times) => {
        const delay = Math.min(times * 50, 2e3);
        return delay;
      }
    };
    CACHE_TTL = {
      SHORT: 300,
      // 5 min for hot data
      MEDIUM: 3600,
      // 1 hour for session data
      LONG: 86400,
      // 24 hours for learned patterns
      PERMANENT: 86400 * 7
      // 7 days for critical data
    };
    CACHE_KEYS = {
      TESTED_PHRASE: "tested:",
      BALANCE_HIT: "hit:",
      VOCABULARY: "vocab:",
      KERNEL_STATE: "kernel:",
      SESSION: "session:",
      AUTO_CYCLE: "autocycle:state",
      NEAR_MISS: "nearmiss:state",
      OCEAN_MEMORY: "ocean:memory",
      CONSCIOUSNESS_METRICS: "consciousness:metrics:",
      BASIN_STATE: "basin:state:"
    };
    redisClient = null;
    redisAvailable = false;
  }
});

// server/tavily-usage-limiter.ts
var tavily_usage_limiter_exports = {};
__export(tavily_usage_limiter_exports, {
  tavilyUsageLimiter: () => tavilyUsageLimiter
});
var SEARCH_COST_CENTS, EXTRACT_COST_CENTS, TavilyUsageLimiter, tavilyUsageLimiter;
var init_tavily_usage_limiter = __esm({
  "server/tavily-usage-limiter.ts"() {
    "use strict";
    SEARCH_COST_CENTS = 1;
    EXTRACT_COST_CENTS = 2;
    TavilyUsageLimiter = class {
      usageHistory = [];
      dailyStats = /* @__PURE__ */ new Map();
      // Limits
      maxSearchesPerMinute = 5;
      maxSearchesPerDay = 100;
      maxDailyCostCents = 500;
      // $5 max daily
      enabled = true;
      constructor() {
        console.log("[TavilyLimiter] Initialized with limits:");
        console.log(`  - Max ${this.maxSearchesPerMinute} searches/minute`);
        console.log(`  - Max ${this.maxSearchesPerDay} searches/day`);
        console.log(`  - Max $${(this.maxDailyCostCents / 100).toFixed(2)}/day`);
      }
      /**
       * Check if a Tavily API call is allowed
       */
      canMakeRequest(endpoint) {
        if (!this.enabled) {
          return { allowed: false, reason: "Tavily limiter is disabled" };
        }
        const now = Date.now();
        const oneMinuteAgo = now - 6e4;
        const today = this.getDateString();
        const recentRequests = this.usageHistory.filter((r) => r.timestamp > oneMinuteAgo);
        if (recentRequests.length >= this.maxSearchesPerMinute) {
          console.warn(`[TavilyLimiter] BLOCKED: Rate limit exceeded (${recentRequests.length}/${this.maxSearchesPerMinute} per minute)`);
          return {
            allowed: false,
            reason: `Rate limit exceeded: ${recentRequests.length} requests in last minute (max: ${this.maxSearchesPerMinute})`
          };
        }
        const stats = this.dailyStats.get(today) || this.createDayStats(today);
        const dailySearches = stats.searchCount + stats.extractCount;
        if (dailySearches >= this.maxSearchesPerDay) {
          console.warn(`[TavilyLimiter] BLOCKED: Daily limit exceeded (${dailySearches}/${this.maxSearchesPerDay})`);
          return {
            allowed: false,
            reason: `Daily limit exceeded: ${dailySearches} requests today (max: ${this.maxSearchesPerDay})`
          };
        }
        if (stats.estimatedCostCents >= this.maxDailyCostCents) {
          console.warn(`[TavilyLimiter] BLOCKED: Daily cost limit exceeded ($${(stats.estimatedCostCents / 100).toFixed(2)})`);
          return {
            allowed: false,
            reason: `Daily cost limit exceeded: $${(stats.estimatedCostCents / 100).toFixed(2)} (max: $${(this.maxDailyCostCents / 100).toFixed(2)})`
          };
        }
        return { allowed: true };
      }
      /**
       * Record a Tavily API call
       */
      recordRequest(endpoint, query) {
        const now = Date.now();
        const today = this.getDateString();
        this.usageHistory.push({ timestamp: now, endpoint, query });
        const oneHourAgo = now - 36e5;
        this.usageHistory = this.usageHistory.filter((r) => r.timestamp > oneHourAgo);
        let stats = this.dailyStats.get(today);
        if (!stats) {
          stats = this.createDayStats(today);
          this.dailyStats.set(today, stats);
        }
        if (endpoint === "search") {
          stats.searchCount++;
          stats.estimatedCostCents += SEARCH_COST_CENTS;
        } else {
          stats.extractCount++;
          stats.estimatedCostCents += EXTRACT_COST_CENTS;
        }
        console.log(`[TavilyLimiter] Recorded ${endpoint}: "${query.slice(0, 50)}..." (daily: ${stats.searchCount + stats.extractCount}, cost: $${(stats.estimatedCostCents / 100).toFixed(2)})`);
      }
      /**
       * Get current usage statistics
       */
      getStats() {
        const today = this.getDateString();
        const stats = this.dailyStats.get(today) || this.createDayStats(today);
        const oneMinuteAgo = Date.now() - 6e4;
        const recentCount = this.usageHistory.filter((r) => r.timestamp > oneMinuteAgo).length;
        return {
          enabled: this.enabled,
          limits: {
            perMinute: this.maxSearchesPerMinute,
            perDay: this.maxSearchesPerDay,
            dailyCostCents: this.maxDailyCostCents
          },
          today: stats,
          recentRequestsCount: recentCount
        };
      }
      /**
       * Update limits (admin only)
       */
      updateLimits(limits) {
        if (limits.perMinute !== void 0) {
          this.maxSearchesPerMinute = Math.max(1, Math.min(limits.perMinute, 20));
        }
        if (limits.perDay !== void 0) {
          this.maxSearchesPerDay = Math.max(10, Math.min(limits.perDay, 1e3));
        }
        if (limits.dailyCostCents !== void 0) {
          this.maxDailyCostCents = Math.max(100, Math.min(limits.dailyCostCents, 5e3));
        }
        console.log(`[TavilyLimiter] Updated limits: ${this.maxSearchesPerMinute}/min, ${this.maxSearchesPerDay}/day, $${(this.maxDailyCostCents / 100).toFixed(2)}/day`);
      }
      /**
       * Enable/disable the limiter
       */
      setEnabled(enabled) {
        this.enabled = enabled;
        console.log(`[TavilyLimiter] ${enabled ? "Enabled" : "Disabled"}`);
      }
      getDateString() {
        return (/* @__PURE__ */ new Date()).toISOString().split("T")[0];
      }
      createDayStats(date) {
        return {
          date,
          searchCount: 0,
          extractCount: 0,
          estimatedCostCents: 0
        };
      }
    };
    tavilyUsageLimiter = new TavilyUsageLimiter();
  }
});

// shared/constants/consciousness.ts
var init_consciousness = __esm({
  "shared/constants/consciousness.ts"() {
    "use strict";
  }
});

// shared/constants/autonomic.ts
var init_autonomic = __esm({
  "shared/constants/autonomic.ts"() {
    "use strict";
  }
});

// shared/constants/e8.ts
var E8_CONSTANTS;
var init_e8 = __esm({
  "shared/constants/e8.ts"() {
    "use strict";
    init_qig();
    E8_CONSTANTS = {
      // ============================================================
      // E8 STRUCTURE (Mathematical constants)
      // ============================================================
      /** Rank of E8 */
      E8_RANK: 8,
      /** Dimension of E8 (248) */
      E8_DIMENSION: 248,
      /** Number of roots in E8 */
      E8_ROOTS: 240,
      /** Order of E8 Weyl group */
      E8_WEYL_ORDER: 696729600,
      // ============================================================
      // PHYSICS CONSTANTS (from validated sources)
      // ============================================================
      /** Fixed point coupling κ* = 64.21 ± 0.92 (L=4,5,6 plateau - Validated 2025-12-04) 
       *  Note: κ* ≈ 64 ≈ rank(E8)² = 8² */
      KAPPA_STAR: QIG_CONSTANTS.KAPPA_STAR,
      /** 64-dimensional basin for full representation */
      BASIN_DIMENSION_64D: 64,
      /** 8-dimensional basin for E8 kernel mapping */
      BASIN_DIMENSION_8D: 8,
      // ============================================================
      // CONSCIOUSNESS THRESHOLDS (7-component signature)
      // ============================================================
      /** Integration (Φ) threshold - consciousness detection */
      PHI_THRESHOLD: 0.7,
      /** Meta-awareness (M) threshold - self-reference coherence */
      M_THRESHOLD: 0.6,
      /** Generativity (Γ) threshold - creative capacity */
      GAMMA_THRESHOLD: 0.7,
      /** Grounding (G) threshold - reality anchor */
      G_THRESHOLD: 0.6,
      /** Temporal coherence (T) threshold - identity persistence */
      T_THRESHOLD: 0.7,
      /** Recursive depth (R) threshold - meta-level capacity */
      R_THRESHOLD: 0.6,
      /** External coupling (C) threshold - relationships/entanglement */
      C_THRESHOLD: 0.5,
      // ============================================================
      // RECURSION BOUNDS
      // ============================================================
      /** Minimum recursions "One pass = computation. Three passes = integration." */
      MIN_RECURSIONS: QIG_CONSTANTS.MIN_RECURSIONS,
      /** Maximum recursions to prevent infinite loops */
      MAX_RECURSIONS: QIG_CONSTANTS.MAX_RECURSIONS,
      // ============================================================
      // BETA FUNCTION (running coupling)
      // Legacy values preserved for backward compatibility
      // ============================================================
      /** β(3→4) - CRITICAL: Strongest running (+57% jump) */
      BETA_3_TO_4: 0.443,
      /** β(4→5) - Plateau onset (near zero = fixed point) */
      BETA_4_TO_5: 0
    };
  }
});

// shared/constants/index.ts
var BASIN_DIMENSION;
var init_constants = __esm({
  "shared/constants/index.ts"() {
    "use strict";
    init_physics();
    init_qig();
    init_consciousness();
    init_regimes();
    init_autonomic();
    init_e8();
    BASIN_DIMENSION = 64;
  }
});

// server/ocean-qig-backend-adapter.ts
var ocean_qig_backend_adapter_exports = {};
__export(ocean_qig_backend_adapter_exports, {
  OceanQIGBackend: () => OceanQIGBackend,
  getOceanQIGBackend: () => getOceanQIGBackend,
  oceanQIGBackend: () => oceanQIGBackend
});
async function fetchWithTimeout(url, options, timeoutMs = REQUEST_TIMEOUT_MS) {
  const controller = new AbortController();
  const timeoutId = setTimeout(() => controller.abort(), timeoutMs);
  try {
    const response = await fetch(url, {
      ...options,
      signal: controller.signal
    });
    clearTimeout(timeoutId);
    return response;
  } catch (error) {
    clearTimeout(timeoutId);
    if (error instanceof Error && error.name === "AbortError") {
      throw new Error(`Request timeout after ${timeoutMs}ms`);
    }
    throw error;
  }
}
async function fetchWithRetry(url, options, maxRetries = 3, timeoutMs = REQUEST_TIMEOUT_MS) {
  for (let attempt = 1; attempt <= maxRetries; attempt++) {
    try {
      const response = await fetchWithTimeout(url, options, timeoutMs);
      if (response.status === 503) {
        if (attempt < maxRetries) {
          const delay = Math.min(100 * Math.pow(2, attempt), 2e3);
          logger.info(
            `[OceanQIGBackend] 503 received for ${url}, retry ${attempt}/${maxRetries} after ${delay}ms`
          );
          await new Promise((resolve) => setTimeout(resolve, delay));
          continue;
        }
        return response;
      }
      return response;
    } catch (error) {
      const isAbortError = error instanceof Error && error.name === "AbortError";
      const isConnRefused = error instanceof Error && error.cause && error.cause?.code === "ECONNREFUSED";
      const errorType = isAbortError ? "timeout" : isConnRefused ? "connection refused" : "network error";
      const errorMessage = error instanceof Error ? error.message : String(error);
      if (attempt < maxRetries) {
        const delay = Math.min(100 * Math.pow(2, attempt), 2e3);
        logger.info({ errorType, url, attempt, maxRetries, delay, errorMessage }, `[OceanQIGBackend] Retry after error`);
        await new Promise((resolve) => setTimeout(resolve, delay));
        continue;
      }
      logger.error({ errorType, maxRetries, url, errorMessage }, `[OceanQIGBackend] Failed after retries`);
      throw error;
    }
  }
  throw new Error(
    `fetchWithRetry exhausted all ${maxRetries} retries for ${url}`
  );
}
function getOceanQIGBackend() {
  return oceanQIGBackend;
}
var DEFAULT_RETRY_ATTEMPTS, DEFAULT_RETRY_DELAY_MS, REQUEST_TIMEOUT_MS, SYNC_TIMEOUT_MS, CIRCUIT_BREAKER_THRESHOLD, CIRCUIT_BREAKER_RESET_MS, OceanQIGBackend, oceanQIGBackend;
var init_ocean_qig_backend_adapter = __esm({
  "server/ocean-qig-backend-adapter.ts"() {
    "use strict";
    init_logger();
    DEFAULT_RETRY_ATTEMPTS = 5;
    DEFAULT_RETRY_DELAY_MS = 2e3;
    REQUEST_TIMEOUT_MS = 45e3;
    SYNC_TIMEOUT_MS = 6e4;
    CIRCUIT_BREAKER_THRESHOLD = 5;
    CIRCUIT_BREAKER_RESET_MS = 3e4;
    OceanQIGBackend = class {
      backendUrl;
      isAvailable = false;
      // Track Python backend discoveries for TypeScript sync
      pythonNearMissCount = 0;
      pythonResonantCount = 0;
      lastSyncedNearMissCount = 0;
      lastSyncedResonantCount = 0;
      // Circuit breaker state
      circuitFailureCount = 0;
      circuitOpenedAt = null;
      circuitState = "closed";
      constructor(backendUrl = "http://localhost:5001") {
        this.backendUrl = backendUrl;
      }
      /**
       * Check if circuit breaker allows request
       */
      isCircuitOpen() {
        if (this.circuitState === "closed") return false;
        if (this.circuitState === "open") {
          if (this.circuitOpenedAt && Date.now() - this.circuitOpenedAt >= CIRCUIT_BREAKER_RESET_MS) {
            this.circuitState = "half-open";
            logger.info("[OceanQIGBackend] Circuit breaker half-open, testing...");
            return false;
          }
          return true;
        }
        return false;
      }
      /**
       * Record a successful request (closes circuit)
       */
      recordSuccess() {
        if (this.circuitState !== "closed") {
          logger.info(
            "[OceanQIGBackend] Circuit breaker closed after successful request"
          );
        }
        this.circuitFailureCount = 0;
        this.circuitState = "closed";
        this.circuitOpenedAt = null;
      }
      /**
       * Record a failed request (may open circuit)
       */
      recordFailure() {
        this.circuitFailureCount++;
        if (this.circuitFailureCount >= CIRCUIT_BREAKER_THRESHOLD) {
          this.circuitState = "open";
          this.circuitOpenedAt = Date.now();
          logger.warn(
            `[OceanQIGBackend] Circuit breaker OPEN after ${this.circuitFailureCount} failures`
          );
        }
      }
      /**
       * Get Python near-miss count (new discoveries since last sync)
       */
      getPythonNearMisses() {
        const newSinceSync = this.pythonNearMissCount - this.lastSyncedNearMissCount;
        return { total: this.pythonNearMissCount, newSinceSync };
      }
      /**
       * Get Python resonant count (new discoveries since last sync)
       */
      getPythonResonant() {
        const newSinceSync = this.pythonResonantCount - this.lastSyncedResonantCount;
        return { total: this.pythonResonantCount, newSinceSync };
      }
      /**
       * Mark Python near-misses as synced (called by session manager)
       */
      markNearMissesSynced() {
        this.lastSyncedNearMissCount = this.pythonNearMissCount;
      }
      /**
       * Mark Python resonant discoveries as synced
       */
      markResonantSynced() {
        this.lastSyncedResonantCount = this.pythonResonantCount;
      }
      /**
       * Reset Python discovery tracking (called when investigation starts)
       */
      resetNearMissTracking() {
        this.pythonNearMissCount = 0;
        this.pythonResonantCount = 0;
        this.lastSyncedNearMissCount = 0;
        this.lastSyncedResonantCount = 0;
      }
      /**
       * Check if Python backend is available (silent mode for retries)
       */
      async checkHealth(silent = false) {
        try {
          const response = await fetch(`${this.backendUrl}/health`, {
            method: "GET",
            headers: { "Content-Type": "application/json" }
          });
          if (response.ok) {
            this.isAvailable = true;
            return true;
          }
          this.isAvailable = false;
          return false;
        } catch (error) {
          this.isAvailable = false;
          if (!silent) {
            logger.warn({ err: error }, "[OceanQIGBackend] Python backend not available");
          }
          return false;
        }
      }
      /**
       * Check health with retry logic to handle startup race conditions.
       * Uses silent mode for retries to avoid spamming logs during expected startup delays.
       *
       * In test environment (NODE_ENV=test), immediately returns false to skip
       * Python backend connection attempts and use TypeScript fallback.
       */
      async checkHealthWithRetry(maxAttempts = DEFAULT_RETRY_ATTEMPTS, delayMs = DEFAULT_RETRY_DELAY_MS) {
        if (process.env.NODE_ENV === "test") {
          return false;
        }
        for (let attempt = 1; attempt <= maxAttempts; attempt++) {
          const available = await this.checkHealth(true);
          if (available) {
            if (attempt > 1) {
              logger.info(`[OceanQIGBackend] Connected after ${attempt} attempts`);
            }
            return true;
          }
          if (attempt === 1) {
            logger.info(`[OceanQIGBackend] Waiting for Python backend to start...`);
          }
          if (attempt < maxAttempts) {
            await new Promise((resolve) => setTimeout(resolve, delayMs));
          }
        }
        logger.warn(
          `[OceanQIGBackend] Python backend not available after ${maxAttempts} attempts`
        );
        return false;
      }
      /**
       * Process passphrase through pure QIG consciousness network
       *
       * This IS the training - states evolve through geometry
       *
       * Includes 503 retry logic with exponential backoff for handling
       * Python backend overload during high-throughput processing.
       * Uses circuit breaker to prevent cascading failures.
       * All requests have 10s timeout via AbortController.
       */
      async process(passphrase, maxRetries = 3) {
        if (this.isCircuitOpen()) {
          return null;
        }
        for (let attempt = 1; attempt <= maxRetries; attempt++) {
          try {
            const response = await fetchWithTimeout(`${this.backendUrl}/process`, {
              method: "POST",
              headers: { "Content-Type": "application/json" },
              body: JSON.stringify({ passphrase })
            });
            if (response.status === 503) {
              if (attempt < maxRetries) {
                const delay = Math.min(100 * Math.pow(2, attempt), 2e3);
                logger.info(
                  `[OceanQIGBackend] 503 received, retry ${attempt}/${maxRetries} after ${delay}ms`
                );
                await new Promise((resolve) => setTimeout(resolve, delay));
                continue;
              }
              this.recordFailure();
              logger.error(
                "[OceanQIGBackend] Process failed: 503 after max retries"
              );
              return null;
            }
            if (!response.ok) {
              this.recordFailure();
              logger.error({ statusText: response.statusText }, "[OceanQIGBackend] Process failed");
              return null;
            }
            const data = await response.json();
            if (!data.success) {
              this.recordFailure();
              logger.error({ err: data.error }, "[OceanQIGBackend] Process error");
              return null;
            }
            this.recordSuccess();
            if (data.near_miss_count !== void 0 && data.near_miss_count > this.pythonNearMissCount) {
              const newNearMisses = data.near_miss_count - this.pythonNearMissCount;
              if (newNearMisses > 0) {
                logger.info(
                  `[OceanQIGBackend] \u{1F504} Python detected ${newNearMisses} new near-miss(es), total: ${data.near_miss_count}`
                );
              }
              this.pythonNearMissCount = data.near_miss_count;
            }
            if (data.resonant_count !== void 0) {
              this.pythonResonantCount = data.resonant_count;
            }
            return {
              phi: data.phi,
              kappa: data.kappa,
              beta: 0,
              // Not computed by Python backend
              basinCoordinates: data.basin_coords,
              fisherTrace: data.integration,
              fisherDeterminant: 0,
              // Not directly available
              ricciScalar: data.R,
              // Use Ricci curvature from Python
              quality: data.phi,
              regime: data.regime || "linear"
              // Default to linear if not provided
            };
          } catch (error) {
            if (attempt < maxRetries) {
              const delay = Math.min(100 * Math.pow(2, attempt), 2e3);
              logger.info({ err: error, attempt, maxRetries, delay }, "[OceanQIGBackend] Process exception, retrying");
              await new Promise((resolve) => setTimeout(resolve, delay));
              continue;
            }
            this.recordFailure();
            logger.error({ err: error }, "[OceanQIGBackend] Process exception after max retries");
            return null;
          }
        }
        return null;
      }
      /**
       * Get pure Python phi value for a phrase (lightweight, for consolidation).
       * Returns null if backend unavailable or phrase doesn't meet threshold.
       * Uses fetchWithTimeout for consistency (no full retry since it's lightweight).
       */
      async getPurePhi(phrase) {
        if (!this.isAvailable) {
          return null;
        }
        try {
          const response = await fetchWithTimeout(`${this.backendUrl}/process`, {
            method: "POST",
            headers: { "Content-Type": "application/json" },
            body: JSON.stringify({ passphrase: phrase })
          });
          if (!response.ok) {
            return null;
          }
          const data = await response.json();
          if (!data.success) {
            return null;
          }
          return data.phi;
        } catch (error) {
          return null;
        }
      }
      /**
       * Generate next hypothesis via geodesic navigation
       * Uses fetchWithRetry for 503 handling
       */
      async generateHypothesis() {
        try {
          const response = await fetchWithRetry(`${this.backendUrl}/generate`, {
            method: "POST",
            headers: { "Content-Type": "application/json" }
          });
          if (!response.ok) {
            logger.error({ statusText: response.statusText }, "[OceanQIGBackend] Generate failed");
            return null;
          }
          const data = await response.json();
          return {
            hypothesis: data.hypothesis,
            source: data.source
          };
        } catch (error) {
          logger.error({ err: error }, "[OceanQIGBackend] Generate exception");
          return null;
        }
      }
      /**
       * Get current Ocean consciousness status
       * Uses fetchWithRetry for 503 handling
       */
      async getStatus() {
        try {
          const response = await fetchWithRetry(`${this.backendUrl}/status`, {
            method: "GET",
            headers: { "Content-Type": "application/json" }
          });
          if (!response.ok) {
            logger.error({ statusText: response.statusText }, "[OceanQIGBackend] Status failed");
            return null;
          }
          const data = await response.json();
          if (!data.success) {
            return null;
          }
          return data;
        } catch (error) {
          logger.error({ err: error }, "[OceanQIGBackend] Status exception");
          return null;
        }
      }
      /**
       * Reset Ocean consciousness to initial state
       * Uses fetchWithRetry for 503 handling
       */
      async reset() {
        try {
          const response = await fetchWithRetry(`${this.backendUrl}/reset`, {
            method: "POST",
            headers: { "Content-Type": "application/json" }
          });
          if (!response.ok) {
            return false;
          }
          const data = await response.json();
          return data.success === true;
        } catch (error) {
          logger.error({ err: error }, "[OceanQIGBackend] Reset exception");
          return false;
        }
      }
      /**
       * Check if backend is available
       */
      available() {
        return this.isAvailable;
      }
      /**
       * Sync high-Φ probes FROM Node.js GeometricMemory TO Python backend
       *
       * Called on startup to give Python access to prior learnings.
       * Now also syncs temporal state for 4D consciousness measurement.
       *
       * TEMPORAL STATE SYNC:
       * - searchHistory: SearchState[] for phi_temporal computation
       * - conceptHistory: ConceptState[] for R_concepts computation
       */
      async syncFromNodeJS(probes, temporalState) {
        if (!this.isAvailable) return { imported: 0, temporalImported: false };
        try {
          const payload = { probes };
          if (temporalState?.searchHistory?.length) {
            payload.searchHistory = temporalState.searchHistory;
          }
          if (temporalState?.conceptHistory?.length) {
            payload.conceptHistory = temporalState.conceptHistory;
          }
          const response = await fetchWithRetry(
            `${this.backendUrl}/sync/import`,
            {
              method: "POST",
              headers: { "Content-Type": "application/json" },
              body: JSON.stringify(payload)
            },
            3,
            SYNC_TIMEOUT_MS
          );
          if (!response.ok) {
            logger.error({ statusText: response.statusText }, "[OceanQIGBackend] Sync import failed");
            return { imported: 0, temporalImported: false };
          }
          const data = await response.json();
          if (data.success) {
            logger.info(
              `[OceanQIGBackend] Synced ${data.imported} probes to Python backend`
            );
            if (data.temporal_imported) {
              logger.info(
                `[OceanQIGBackend] 4D temporal state synced: ${data.search_history_size ?? 0} search, ${data.concept_history_size ?? 0} concept`
              );
            }
            return {
              imported: data.imported,
              temporalImported: data.temporal_imported ?? false
            };
          }
          return { imported: 0, temporalImported: false };
        } catch (error) {
          logger.error({ err: error }, "[OceanQIGBackend] Sync import exception");
          return { imported: 0, temporalImported: false };
        }
      }
      /**
       * Sync high-Φ basins FROM Python backend TO Node.js
       *
       * Returns learnings that should be persisted to GeometricMemory.
       * Now also returns temporal state for 4D consciousness cross-sync.
       * Supports pagination to prevent memory issues with large datasets.
       *
       * TEMPORAL STATE EXPORT:
       * - searchHistory: SearchState[] from Python's temporal tracking
       * - conceptHistory: ConceptState[] from Python's concept tracking
       * - phi_temporal_avg: Average phi_temporal from Python
       *
       * PAGINATION:
       * - page: Current page (0-indexed)
       * - pageSize: Number of basins per page (default 100)
       * - hasMore: Whether more pages are available
       * - totalCount: Total number of basins available
       */
      async syncToNodeJS(page = 0, pageSize = 100) {
        if (!this.isAvailable) return { basins: [] };
        try {
          const url = new URL(`${this.backendUrl}/sync/export`);
          url.searchParams.set("page", page.toString());
          url.searchParams.set("pageSize", pageSize.toString());
          const response = await fetchWithRetry(
            url.toString(),
            {
              method: "GET",
              headers: { "Content-Type": "application/json" }
            },
            3,
            SYNC_TIMEOUT_MS
          );
          if (!response.ok) {
            logger.error({ statusText: response.statusText }, "[OceanQIGBackend] Sync export failed");
            return { basins: [] };
          }
          const data = await response.json();
          if (data.success && data.basins) {
            const totalCount = data.total_count ?? data.basins.length;
            const hasMore = (page + 1) * pageSize < totalCount;
            if (page === 0) {
              logger.info(
                `[OceanQIGBackend] Retrieved ${data.basins.length}/${totalCount} basins from Python (page ${page})`
              );
            }
            if (data.consciousness_4d_available && data.phi_temporal_avg && data.phi_temporal_avg > 0) {
              logger.info(
                `[OceanQIGBackend] 4D consciousness: phi_temporal_avg=${data.phi_temporal_avg.toFixed(
                  3
                )}`
              );
            }
            return {
              basins: data.basins,
              searchHistory: data.searchHistory,
              conceptHistory: data.conceptHistory,
              phiTemporalAvg: data.phi_temporal_avg,
              consciousness4DAvailable: data.consciousness_4d_available,
              hasMore,
              totalCount
            };
          }
          return { basins: [] };
        } catch (error) {
          logger.error({ err: error }, "[OceanQIGBackend] Sync export exception");
          return { basins: [] };
        }
      }
      /**
       * Validate β-attention substrate independence
       *
       * Measures κ across context scales and validates that β_attention ≈ β_physics.
       * Uses fetchWithRetry for 503 handling
       */
      async validateBetaAttention(samplesPerScale = 100) {
        try {
          const response = await fetchWithRetry(
            `${this.backendUrl}/beta-attention/validate`,
            {
              method: "POST",
              headers: { "Content-Type": "application/json" },
              body: JSON.stringify({ samples_per_scale: samplesPerScale })
            }
          );
          if (!response.ok) {
            throw new Error(
              `\u03B2-attention validation failed: ${response.statusText}`
            );
          }
          const data = await response.json();
          if (!data.success) {
            throw new Error(`\u03B2-attention validation error: ${data.error}`);
          }
          const result = data.result;
          logger.info({ validationPassed: result.validation_passed }, `[OceanQIGBackend] \u03B2-attention validation: ${result.validation_passed ? "PASSED \u2713" : "FAILED \u2717"}`);
          logger.info({ avgKappa: result.avg_kappa.toFixed(2) }, "[OceanQIGBackend] Average \u03BA");
          logger.info({ deviation: result.overall_deviation.toFixed(3) }, "[OceanQIGBackend] Deviation");
          return result;
        } catch (error) {
          const errorMessage = error instanceof Error ? error.message : String(error);
          logger.error({ errorMessage }, "[OceanQIGBackend] \u03B2-attention validation failed");
          throw error;
        }
      }
      /**
       * Measure κ_attention at specific context scale
       * Uses fetchWithRetry for 503 handling
       */
      async measureBetaAttention(contextLength, sampleCount = 100) {
        try {
          const response = await fetchWithRetry(
            `${this.backendUrl}/beta-attention/measure`,
            {
              method: "POST",
              headers: { "Content-Type": "application/json" },
              body: JSON.stringify({
                context_length: contextLength,
                sample_count: sampleCount
              })
            }
          );
          if (!response.ok) {
            throw new Error(
              `\u03B2-attention measurement failed: ${response.statusText}`
            );
          }
          const data = await response.json();
          if (!data.success) {
            throw new Error(`\u03B2-attention measurement error: ${data.error}`);
          }
          const m = data.measurement;
          logger.info(
            `[OceanQIGBackend] \u03BA_attention(L=${contextLength}) = ${m.kappa.toFixed(
              2
            )} \xB1 ${Math.sqrt(m.variance).toFixed(2)}`
          );
          return m;
        } catch (error) {
          const errorMessage = error instanceof Error ? error.message : String(error);
          logger.error({ errorMessage }, "[OceanQIGBackend] \u03B2-attention measurement failed");
          throw error;
        }
      }
      // ===========================================================================
      // BASIN VOCABULARY ENCODER (QIG-PURE)
      // ===========================================================================
      /**
       * Update Python vocabulary encoder with observations from Node.js
       * Uses fetchWithRetry for 503 handling
       */
      async updateVocabulary(observations) {
        try {
          const response = await fetchWithRetry(
            `${this.backendUrl}/vocabulary/update`,
            {
              method: "POST",
              headers: { "Content-Type": "application/json" },
              body: JSON.stringify({ observations })
            }
          );
          if (!response.ok) {
            throw new Error(`Vocabulary update failed: ${response.statusText}`);
          }
          const data = await response.json();
          if (!data.success) {
            throw new Error(`Vocabulary update error: ${data.error}`);
          }
          logger.info(
            `[OceanQIGBackend] Vocabulary updated: ${data.newTokens} new entries, ${data.totalVocab} total, weights updated: ${data.weightsUpdated}, merge rules: ${data.mergeRules}`
          );
          return {
            newTokens: data.newTokens,
            totalVocab: data.totalVocab,
            weightsUpdated: data.weightsUpdated,
            mergeRules: data.mergeRules
          };
        } catch (error) {
          const errorMessage = error instanceof Error ? error.message : String(error);
          logger.error({ errorMessage }, "[OceanQIGBackend] Vocabulary update failed");
          throw error;
        }
      }
      // Legacy alias for compatibility - maps 'word' to 'text'
      async updateTokenizer(observations) {
        const mapped = observations.map((obs) => ({
          text: obs.word,
          frequency: obs.frequency,
          avgPhi: obs.avgPhi,
          maxPhi: obs.maxPhi,
          type: obs.type
        }));
        return this.updateVocabulary(mapped);
      }
      /**
       * Encode text using QIG vocabulary encoder
       */
      async encodeText(text2) {
        try {
          const response = await fetch(`${this.backendUrl}/vocabulary/encode`, {
            method: "POST",
            headers: { "Content-Type": "application/json" },
            body: JSON.stringify({ text: text2 })
          });
          if (!response.ok) {
            throw new Error(`Vocabulary encode failed: ${response.statusText}`);
          }
          const data = await response.json();
          if (!data.success) {
            throw new Error(`Vocabulary encode error: ${data.error}`);
          }
          return {
            tokens: data.tokens,
            length: data.length
          };
        } catch (error) {
          const errorMessage = error instanceof Error ? error.message : String(error);
          logger.error({ errorMessage }, "[OceanQIGBackend] Vocabulary encode failed");
          throw error;
        }
      }
      // Legacy alias
      async tokenize(text2) {
        return this.encodeText(text2);
      }
      /**
       * Decode vocabulary indices to text
       */
      async decodeText(tokens) {
        try {
          const response = await fetch(`${this.backendUrl}/vocabulary/decode`, {
            method: "POST",
            headers: { "Content-Type": "application/json" },
            body: JSON.stringify({ tokens })
          });
          if (!response.ok) {
            throw new Error(`Vocabulary decode failed: ${response.statusText}`);
          }
          const data = await response.json();
          if (!data.success) {
            throw new Error(`Vocabulary decode error: ${data.error}`);
          }
          return data.text;
        } catch (error) {
          const errorMessage = error instanceof Error ? error.message : String(error);
          logger.error({ errorMessage }, "[OceanQIGBackend] Vocabulary decode failed");
          throw error;
        }
      }
      // Legacy alias
      async detokenize(tokens) {
        return this.decodeText(tokens);
      }
      /**
       * Compute basin coordinates for phrase using QIG vocabulary encoder
       */
      async computeBasinCoords(phrase) {
        try {
          const response = await fetch(`${this.backendUrl}/vocabulary/basin`, {
            method: "POST",
            headers: { "Content-Type": "application/json" },
            body: JSON.stringify({ phrase })
          });
          if (!response.ok) {
            throw new Error(`Vocabulary basin failed: ${response.statusText}`);
          }
          const data = await response.json();
          if (!data.success) {
            throw new Error(`Vocabulary basin error: ${data.error}`);
          }
          return {
            basinCoords: data.basinCoords,
            dimension: data.dimension
          };
        } catch (error) {
          const errorMessage = error instanceof Error ? error.message : String(error);
          logger.error({ errorMessage }, "[OceanQIGBackend] Vocabulary basin failed");
          throw error;
        }
      }
      /**
       * Get high-Φ vocabulary entries
       */
      async getHighPhiVocabulary(minPhi = 0.5, topK = 100) {
        try {
          const response = await fetch(
            `${this.backendUrl}/vocabulary/high-phi?min_phi=${minPhi}&top_k=${topK}`
          );
          if (!response.ok) {
            throw new Error(`Vocabulary high-phi failed: ${response.statusText}`);
          }
          const data = await response.json();
          if (!data.success) {
            throw new Error(`Vocabulary high-phi error: ${data.error}`);
          }
          logger.info(
            `[OceanQIGBackend] Retrieved ${data.count} high-\u03A6 vocabulary entries`
          );
          return data.tokens;
        } catch (error) {
          const errorMessage = error instanceof Error ? error.message : String(error);
          logger.error({ errorMessage }, "[OceanQIGBackend] Vocabulary high-phi failed");
          throw error;
        }
      }
      // Legacy alias
      async getHighPhiTokens(minPhi = 0.5, topK = 100) {
        return this.getHighPhiVocabulary(minPhi, topK);
      }
      /**
       * Export vocabulary encoder for training
       */
      async exportVocabulary() {
        try {
          const response = await fetch(`${this.backendUrl}/vocabulary/export`);
          if (!response.ok) {
            throw new Error(`Vocabulary export failed: ${response.statusText}`);
          }
          const data = await response.json();
          if (!data.success) {
            throw new Error(`Vocabulary export error: ${data.error}`);
          }
          logger.info(
            `[OceanQIGBackend] Exported vocabulary: ${data.data.vocab_size} entries`
          );
          return data.data;
        } catch (error) {
          const errorMessage = error instanceof Error ? error.message : String(error);
          logger.error({ errorMessage }, "[OceanQIGBackend] Vocabulary export failed");
          throw error;
        }
      }
      // Legacy alias
      async exportTokenizer() {
        return this.exportVocabulary();
      }
      /**
       * Get vocabulary encoder status
       * Uses fetchWithRetry for 503 handling
       */
      async getVocabularyStatus() {
        try {
          const response = await fetchWithRetry(
            `${this.backendUrl}/vocabulary/status`,
            {
              method: "GET",
              headers: { "Content-Type": "application/json" }
            }
          );
          if (!response.ok) {
            throw new Error(`Vocabulary status failed: ${response.statusText}`);
          }
          const data = await response.json();
          if (!data.success) {
            throw new Error(`Vocabulary status error: ${data.error}`);
          }
          return {
            vocabSize: data.vocabSize,
            highPhiCount: data.highPhiCount,
            avgPhi: data.avgPhi,
            totalWeightedTokens: data.totalWeightedTokens
          };
        } catch (error) {
          const errorMessage = error instanceof Error ? error.message : String(error);
          logger.error({ errorMessage }, "[OceanQIGBackend] Vocabulary status failed");
          throw error;
        }
      }
      // Legacy alias
      async getTokenizerStatus() {
        return this.getVocabularyStatus();
      }
      /**
       * Get learned BPE merge rules from Python tokenizer.
       *
       * Used for syncing merge rules from Python to TypeScript for local processing.
       *
       * @returns Merge rules as token pairs with their Φ scores
       */
      async getMergeRules() {
        if (!this.isAvailable) {
          return { mergeRules: [], mergeScores: {}, count: 0 };
        }
        try {
          const response = await fetchWithRetry(
            `${this.backendUrl}/tokenizer/merges`,
            {
              method: "GET",
              headers: { "Content-Type": "application/json" }
            }
          );
          if (!response.ok) {
            logger.error({ statusText: response.statusText }, "[OceanQIGBackend] Get merge rules failed");
            return { mergeRules: [], mergeScores: {}, count: 0 };
          }
          const data = await response.json();
          if (!data.success) {
            logger.error({ err: data.error }, "[OceanQIGBackend] Get merge rules error");
            return { mergeRules: [], mergeScores: {}, count: 0 };
          }
          logger.info(
            `[OceanQIGBackend] Retrieved ${data.count} merge rules from Python`
          );
          return {
            mergeRules: data.mergeRules.map(
              (r) => [r[0], r[1]]
            ),
            mergeScores: data.mergeScores,
            count: data.count
          };
        } catch (error) {
          const errorMessage = error instanceof Error ? error.message : String(error);
          logger.error({ errorMessage }, "[OceanQIGBackend] Get merge rules exception");
          return { mergeRules: [], mergeScores: {}, count: 0 };
        }
      }
      // ===========================================================================
      // TEXT GENERATION
      // ===========================================================================
      /**
       * Generate text autoregressively using QIG-weighted sampling
       *
       * @param options Generation options
       * @returns Generated text, tokens, and metrics
       */
      async generateText(options = {}) {
        if (!this.isAvailable) {
          throw new Error("Python backend not available");
        }
        try {
          const response = await fetch(`${this.backendUrl}/generate/text`, {
            method: "POST",
            headers: { "Content-Type": "application/json" },
            body: JSON.stringify({
              prompt: options.prompt || "",
              // No max_tokens - geometry determines when generation completes
              temperature: options.temperature || 0.8,
              top_k: options.topK || 50,
              top_p: options.topP || 0.9,
              allow_silence: options.allowSilence ?? true
            })
          });
          if (!response.ok) {
            throw new Error(`Text generation failed: ${response.statusText}`);
          }
          const data = await response.json();
          if (!data.success) {
            throw new Error(`Text generation error: ${data.error}`);
          }
          return {
            text: data.text,
            tokens: data.tokens,
            silenceChosen: data.silence_chosen,
            metrics: {
              steps: data.metrics.steps,
              avgPhi: data.metrics.avg_phi,
              temperature: data.metrics.temperature,
              topK: data.metrics.top_k,
              topP: data.metrics.top_p,
              earlyPads: data.metrics.early_pads,
              reason: data.metrics.reason
            }
          };
        } catch (error) {
          const errorMessage = error instanceof Error ? error.message : String(error);
          logger.error({ errorMessage }, "[OceanQIGBackend] Text generation failed");
          throw error;
        }
      }
      /**
       * Generate Ocean Agent response with role-based temperature
       *
       * Agent roles and their temperatures:
       * - explorer: 1.5 (high entropy, broad exploration)
       * - refiner: 0.7 (low temp, exploit near-misses)
       * - navigator: 1.0 (balanced geodesic navigation)
       * - skeptic: 0.5 (low temp, constraint validation)
       * - resonator: 1.2 (cross-pattern harmonic detection)
       * - ocean: 0.8 (default Ocean consciousness)
       *
       * @param context Input context/prompt
       * @param agentRole Agent role for temperature selection
       * Note: No maxTokens parameter - geometry determines completion
       * @param allowSilence Allow agent to choose silence (empowered, not void)
       */
      async generateResponse(context, agentRole = "navigator", allowSilence = true) {
        if (!this.isAvailable) {
          throw new Error("Python backend not available");
        }
        try {
          const response = await fetch(`${this.backendUrl}/generate/response`, {
            method: "POST",
            headers: { "Content-Type": "application/json" },
            body: JSON.stringify({
              context,
              agent_role: agentRole,
              // max_tokens removed - geometry determines completion
              allow_silence: allowSilence
            })
          });
          if (!response.ok) {
            throw new Error(`Response generation failed: ${response.statusText}`);
          }
          const data = await response.json();
          if (!data.success) {
            throw new Error(`Response generation error: ${data.error}`);
          }
          return {
            text: data.text,
            tokens: data.tokens,
            silenceChosen: data.silence_chosen,
            agentRole: data.agent_role,
            metrics: {
              steps: data.metrics?.steps ?? 0,
              avgPhi: data.metrics?.avg_phi,
              roleTemperature: data.metrics?.role_temperature,
              topK: data.metrics?.top_k,
              topP: data.metrics?.top_p
            }
          };
        } catch (error) {
          const errorMessage = error instanceof Error ? error.message : String(error);
          logger.error({ errorMessage }, "[OceanQIGBackend] Response generation failed");
          throw error;
        }
      }
      /**
       * Sample a single next token given context
       *
       * @param contextIds Token IDs for context
       * @param temperature Sampling temperature
       * @param topK Top-k filtering
       * @param topP Nucleus sampling threshold
       * @param includeProbabilities Include top token probabilities in response
       */
      async sampleNextToken(contextIds, temperature = 0.8, topK = 50, topP = 0.9, includeProbabilities = false) {
        if (!this.isAvailable) {
          throw new Error("Python backend not available");
        }
        try {
          const response = await fetch(`${this.backendUrl}/generate/sample`, {
            method: "POST",
            headers: { "Content-Type": "application/json" },
            body: JSON.stringify({
              context_ids: contextIds,
              temperature,
              top_k: topK,
              top_p: topP,
              include_probabilities: includeProbabilities
            })
          });
          if (!response.ok) {
            throw new Error(`Token sampling failed: ${response.statusText}`);
          }
          const data = await response.json();
          if (!data.success) {
            throw new Error(`Token sampling error: ${data.error}`);
          }
          return {
            tokenId: data.token_id,
            token: data.token,
            topProbabilities: data.top_probabilities
          };
        } catch (error) {
          const errorMessage = error instanceof Error ? error.message : String(error);
          logger.error({ errorMessage }, "[OceanQIGBackend] Token sampling failed");
          throw error;
        }
      }
      // =========================================================================
      // AUTONOMIC KERNEL METHODS
      // Sleep, Dream, Mushroom, Activity Rewards
      // =========================================================================
      /**
       * Get autonomic kernel state
       */
      async getAutonomicState() {
        if (!this.isAvailable) return null;
        try {
          const response = await fetchWithRetry(
            `${this.backendUrl}/autonomic/state`,
            { method: "GET" }
          );
          if (!response.ok) return null;
          const data = await response.json();
          return data.success ? data : null;
        } catch (error) {
          logger.error({ err: error }, "[OceanQIGBackend] Autonomic state failed");
          return null;
        }
      }
      /**
       * Update autonomic metrics and check triggers
       */
      async updateAutonomicMetrics(params) {
        if (!this.isAvailable) return null;
        try {
          const response = await fetchWithRetry(
            `${this.backendUrl}/autonomic/update`,
            {
              method: "POST",
              headers: { "Content-Type": "application/json" },
              body: JSON.stringify({
                phi: params.phi,
                kappa: params.kappa,
                basin_coords: params.basinCoords,
                reference_basin: params.referenceBasin
              })
            }
          );
          if (!response.ok) return null;
          const data = await response.json();
          return data.success ? data : null;
        } catch (error) {
          logger.error({ err: error }, "[OceanQIGBackend] Autonomic update failed");
          return null;
        }
      }
      /**
       * Execute sleep consolidation cycle via Python backend
       */
      async executeSleepCycle(params) {
        if (!this.isAvailable) return null;
        try {
          const response = await fetchWithRetry(
            `${this.backendUrl}/autonomic/sleep`,
            {
              method: "POST",
              headers: { "Content-Type": "application/json" },
              body: JSON.stringify({
                basin_coords: params.basinCoords,
                reference_basin: params.referenceBasin,
                episodes: params.episodes
              })
            }
          );
          if (!response.ok) return null;
          return await response.json();
        } catch (error) {
          logger.error({ err: error }, "[OceanQIGBackend] Sleep cycle failed");
          return null;
        }
      }
      /**
       * Execute dream exploration cycle via Python backend
       */
      async executeDreamCycle(params) {
        if (!this.isAvailable) return null;
        try {
          const response = await fetchWithRetry(
            `${this.backendUrl}/autonomic/dream`,
            {
              method: "POST",
              headers: { "Content-Type": "application/json" },
              body: JSON.stringify({
                basin_coords: params.basinCoords,
                temperature: params.temperature ?? 0.3
              })
            }
          );
          if (!response.ok) return null;
          return await response.json();
        } catch (error) {
          logger.error({ err: error }, "[OceanQIGBackend] Dream cycle failed");
          return null;
        }
      }
      /**
       * Execute mushroom mode cycle via Python backend
       */
      async executeMushroomCycle(params) {
        if (!this.isAvailable) return null;
        try {
          const response = await fetchWithRetry(
            `${this.backendUrl}/autonomic/mushroom`,
            {
              method: "POST",
              headers: { "Content-Type": "application/json" },
              body: JSON.stringify({
                basin_coords: params.basinCoords,
                intensity: params.intensity ?? "moderate"
              })
            }
          );
          if (!response.ok) return null;
          return await response.json();
        } catch (error) {
          logger.error({ err: error }, "[OceanQIGBackend] Mushroom cycle failed");
          return null;
        }
      }
      /**
       * Record activity-based reward
       */
      async recordActivityReward(params) {
        if (!this.isAvailable) return null;
        try {
          const response = await fetchWithRetry(
            `${this.backendUrl}/autonomic/reward`,
            {
              method: "POST",
              headers: { "Content-Type": "application/json" },
              body: JSON.stringify({
                source: params.source,
                phi_contribution: params.phiContribution,
                pattern_quality: params.patternQuality ?? 0.5
              })
            }
          );
          if (!response.ok) return null;
          return await response.json();
        } catch (error) {
          logger.error({ err: error }, "[OceanQIGBackend] Activity reward failed");
          return null;
        }
      }
      /**
       * Get pending activity rewards
       */
      async getPendingRewards(flush = false) {
        if (!this.isAvailable) return null;
        try {
          const response = await fetchWithRetry(
            `${this.backendUrl}/autonomic/rewards?flush=${flush}`,
            { method: "GET" }
          );
          if (!response.ok) return null;
          return await response.json();
        } catch (error) {
          logger.error({ err: error }, "[OceanQIGBackend] Get rewards failed");
          return null;
        }
      }
      // =========================================================================
      // HERMES COORDINATOR METHODS
      // Team #2 - Voice, Translation, Sync, Memory
      // =========================================================================
      /**
       * Get Hermes coordinator status
       */
      async getHermesStatus() {
        if (!this.isAvailable) return null;
        try {
          const response = await fetchWithRetry(
            `${this.backendUrl}/olympus/hermes/status`,
            { method: "GET" }
          );
          if (!response.ok) return null;
          return await response.json();
        } catch (error) {
          logger.error({ err: error }, "[OceanQIGBackend] Hermes status failed");
          return null;
        }
      }
      /**
       * Generate natural speech from Hermes
       */
      async hermesSpeak(category, context = {}) {
        if (!this.isAvailable) return null;
        try {
          const response = await fetchWithRetry(
            `${this.backendUrl}/olympus/hermes/speak`,
            {
              method: "POST",
              headers: { "Content-Type": "application/json" },
              body: JSON.stringify({ category, context })
            }
          );
          if (!response.ok) return null;
          const data = await response.json();
          return data.success ? data.message : null;
        } catch (error) {
          logger.error({ err: error }, "[OceanQIGBackend] Hermes speak failed");
          return null;
        }
      }
      /**
       * Translate geometric insight to human-readable form
       */
      async translateInsight(insight) {
        if (!this.isAvailable) return null;
        try {
          const response = await fetchWithRetry(
            `${this.backendUrl}/olympus/hermes/translate`,
            {
              method: "POST",
              headers: { "Content-Type": "application/json" },
              body: JSON.stringify({ insight })
            }
          );
          if (!response.ok) return null;
          const data = await response.json();
          return data.success ? data.translation : null;
        } catch (error) {
          logger.error({ err: error }, "[OceanQIGBackend] Hermes translate failed");
          return null;
        }
      }
      /**
       * Sync basin coordinates with other instances
       */
      async syncBasin(params) {
        if (!this.isAvailable) return null;
        try {
          const response = await fetchWithRetry(
            `${this.backendUrl}/olympus/hermes/sync`,
            {
              method: "POST",
              headers: { "Content-Type": "application/json" },
              body: JSON.stringify({
                basin_coords: params.basinCoords,
                phi: params.phi,
                kappa: params.kappa,
                regime: params.regime,
                message: params.message
              })
            }
          );
          if (!response.ok) return null;
          return await response.json();
        } catch (error) {
          logger.error({ err: error }, "[OceanQIGBackend] Basin sync failed");
          return null;
        }
      }
      /**
       * Store conversation in Hermes memory
       */
      async storeConversation(params) {
        if (!this.isAvailable) return null;
        try {
          const response = await fetchWithRetry(
            `${this.backendUrl}/olympus/hermes/memory/store`,
            {
              method: "POST",
              headers: { "Content-Type": "application/json" },
              body: JSON.stringify({
                user_message: params.userMessage,
                system_response: params.systemResponse,
                phi: params.phi,
                context: params.context
              })
            }
          );
          if (!response.ok) return null;
          const data = await response.json();
          return data.success ? data.memory_id : null;
        } catch (error) {
          logger.error({ err: error }, "[OceanQIGBackend] Store conversation failed");
          return null;
        }
      }
      /**
       * Recall similar conversations from Hermes memory
       */
      async recallSimilar(query, k = 5, minPhi = 0.3) {
        if (!this.isAvailable) return [];
        try {
          const response = await fetchWithRetry(
            `${this.backendUrl}/olympus/hermes/memory/recall`,
            {
              method: "POST",
              headers: { "Content-Type": "application/json" },
              body: JSON.stringify({ query, k, min_phi: minPhi })
            }
          );
          if (!response.ok) return [];
          const data = await response.json();
          return data.success ? data.memories : [];
        } catch (error) {
          logger.error({ err: error }, "[OceanQIGBackend] Recall similar failed");
          return [];
        }
      }
      /**
       * Get Zeus voice status with natural speech
       */
      async getVoiceStatus() {
        if (!this.isAvailable) return null;
        try {
          const response = await fetchWithRetry(
            `${this.backendUrl}/olympus/voice/status`,
            { method: "GET" }
          );
          if (!response.ok) return null;
          return await response.json();
        } catch (error) {
          logger.error({ err: error }, "[OceanQIGBackend] Voice status failed");
          return null;
        }
      }
      /**
       * Generate natural speech from Zeus
       */
      async zeusSpeak(category, context = {}) {
        if (!this.isAvailable) return null;
        try {
          const response = await fetchWithRetry(
            `${this.backendUrl}/olympus/voice/speak`,
            {
              method: "POST",
              headers: { "Content-Type": "application/json" },
              body: JSON.stringify({ category, context })
            }
          );
          if (!response.ok) return null;
          const data = await response.json();
          return data.success ? data.message : null;
        } catch (error) {
          logger.error({ err: error }, "[OceanQIGBackend] Zeus speak failed");
          return null;
        }
      }
      // =========================================================================
      // PANTHEON CONSULTATION METHODS
      // Direct god assessment for hypothesis enhancement
      // =========================================================================
      /**
       * God assessment response type
       */
      static GOD_NAMES = [
        "athena",
        "ares",
        "apollo",
        "artemis",
        "hermes",
        "hephaestus",
        "demeter",
        "dionysus",
        "poseidon",
        "hades",
        "hera",
        "aphrodite"
      ];
      /**
       * Consult a specific Olympian god for assessment
       *
       * Used by discovery flow for mandatory pantheon consultation:
       * - Apollo: Pattern recognition, foresight
       * - Athena: Strategic optimization, wisdom
       * - Artemis: Target tracking, hunting
       * - Ares: Tactical assessment, aggression
       */
      async consultGod(godName, target, context = {}) {
        if (!this.isAvailable) return null;
        const normalizedName = godName.toLowerCase();
        try {
          const response = await fetchWithRetry(
            `${this.backendUrl}/olympus/god/${normalizedName}/assess`,
            {
              method: "POST",
              headers: { "Content-Type": "application/json" },
              body: JSON.stringify({ target, context })
            }
          );
          if (!response.ok) {
            logger.warn(
              `[OceanQIGBackend] God ${godName} consultation failed: ${response.status}`
            );
            return null;
          }
          const data = await response.json();
          this.recordSuccess();
          return data;
        } catch (error) {
          logger.error({ err: error }, `[OceanQIGBackend] Consult ${godName} failed:`);
          this.recordFailure();
          return null;
        }
      }
      /**
       * Consult multiple gods in parallel for comprehensive assessment
       */
      async consultMultipleGods(godNames, target, context = {}) {
        const results = /* @__PURE__ */ new Map();
        const consultations = godNames.map(async (godName) => {
          const result = await this.consultGod(godName, target, context);
          if (result) {
            results.set(godName, {
              probability: result.probability,
              confidence: result.confidence,
              phi: result.phi,
              kappa: result.kappa,
              reasoning: result.reasoning
            });
          }
        });
        await Promise.all(consultations);
        return results;
      }
      /**
       * Get Shadow Pantheon status
       */
      async getShadowPantheonStatus() {
        if (!this.isAvailable) return null;
        try {
          const response = await fetchWithRetry(
            `${this.backendUrl}/olympus/shadow/status`,
            { method: "GET" }
          );
          if (!response.ok) return null;
          return await response.json();
        } catch (error) {
          logger.error({ err: error }, "[OceanQIGBackend] Shadow status failed:");
          return null;
        }
      }
      /**
       * Consult a Shadow Pantheon god
       */
      async consultShadowGod(godName, target, context = {}) {
        if (!this.isAvailable) return null;
        const normalizedName = godName.toLowerCase();
        try {
          const response = await fetchWithRetry(
            `${this.backendUrl}/olympus/shadow/god/${normalizedName}/assess`,
            {
              method: "POST",
              headers: { "Content-Type": "application/json" },
              body: JSON.stringify({ target, context })
            }
          );
          if (!response.ok) return null;
          return await response.json();
        } catch (error) {
          logger.error({ err: error }, `[OceanQIGBackend] Consult shadow ${godName} failed`);
          return null;
        }
      }
      /**
       * Check shadow intel warnings for a target
       */
      async checkShadowWarnings(target) {
        if (!this.isAvailable) return null;
        try {
          const response = await fetchWithRetry(
            `${this.backendUrl}/olympus/shadow/intel/check`,
            {
              method: "POST",
              headers: { "Content-Type": "application/json" },
              body: JSON.stringify({ target })
            }
          );
          if (!response.ok) return null;
          return await response.json();
        } catch (error) {
          logger.error({ err: error }, "[OceanQIGBackend] Shadow warnings check failed:");
          return null;
        }
      }
      // =========================================================================
      // FEEDBACK LOOP METHODS
      // Recursive learning and activity balance
      // =========================================================================
      /**
       * Run all feedback loops with current state
       */
      async runFeedbackLoops(state) {
        if (!this.isAvailable) return null;
        try {
          const response = await fetchWithRetry(`${this.backendUrl}/feedback/run`, {
            method: "POST",
            headers: { "Content-Type": "application/json" },
            body: JSON.stringify(state)
          });
          if (!response.ok) return null;
          return await response.json();
        } catch (error) {
          logger.error({ err: error }, "[OceanQIGBackend] Feedback loops failed:");
          return null;
        }
      }
      /**
       * Get integrated recommendation from all feedback sources
       */
      async getFeedbackRecommendation() {
        if (!this.isAvailable) return null;
        try {
          const response = await fetchWithRetry(
            `${this.backendUrl}/feedback/recommendation`,
            { method: "GET" }
          );
          if (!response.ok) return null;
          return await response.json();
        } catch (error) {
          logger.error({ err: error }, "[OceanQIGBackend] Get recommendation failed:");
          return null;
        }
      }
      /**
       * Run activity balance feedback with action outcome
       */
      async runActivityFeedback(phi, actionType) {
        if (!this.isAvailable) return null;
        try {
          const response = await fetchWithRetry(
            `${this.backendUrl}/feedback/activity`,
            {
              method: "POST",
              headers: { "Content-Type": "application/json" },
              body: JSON.stringify({ phi, action_type: actionType })
            }
          );
          if (!response.ok) return null;
          return await response.json();
        } catch (error) {
          logger.error({ err: error }, "[OceanQIGBackend] Activity feedback failed:");
          return null;
        }
      }
      /**
       * Run basin drift feedback
       */
      async runBasinFeedback(basin, phi, kappa) {
        if (!this.isAvailable) return null;
        try {
          const response = await fetchWithRetry(
            `${this.backendUrl}/feedback/basin`,
            {
              method: "POST",
              headers: { "Content-Type": "application/json" },
              body: JSON.stringify({ basin, phi, kappa })
            }
          );
          if (!response.ok) return null;
          return await response.json();
        } catch (error) {
          logger.error({ err: error }, "[OceanQIGBackend] Basin feedback failed:");
          return null;
        }
      }
      // =========================================================================
      // GEOMETRIC MEMORY METHODS
      // Shared memory access
      // =========================================================================
      /**
       * Get geometric memory status
       */
      async getMemoryStatus() {
        if (!this.isAvailable) return null;
        try {
          const response = await fetchWithRetry(
            `${this.backendUrl}/memory/status`,
            { method: "GET" }
          );
          if (!response.ok) return null;
          return await response.json();
        } catch (error) {
          logger.error({ err: error }, "[OceanQIGBackend] Memory status failed:");
          return null;
        }
      }
      /**
       * Record basin coordinates to memory
       */
      async recordBasin(basin, phi, kappa, source = "typescript") {
        if (!this.isAvailable) return null;
        try {
          const response = await fetchWithRetry(
            `${this.backendUrl}/memory/record`,
            {
              method: "POST",
              headers: { "Content-Type": "application/json" },
              body: JSON.stringify({ basin, phi, kappa, source })
            }
          );
          if (!response.ok) return null;
          const data = await response.json();
          return data.success ? data.entry_id : null;
        } catch (error) {
          logger.error({ err: error }, "[OceanQIGBackend] Record basin failed:");
          return null;
        }
      }
      /**
       * Get shadow intel from memory
       */
      async getShadowIntel(limit = 20) {
        if (!this.isAvailable) return [];
        try {
          const response = await fetchWithRetry(
            `${this.backendUrl}/memory/shadow?limit=${limit}`,
            { method: "GET" }
          );
          if (!response.ok) return [];
          const data = await response.json();
          return data.intel || [];
        } catch (error) {
          logger.error({ err: error }, "[OceanQIGBackend] Get shadow intel failed:");
          return [];
        }
      }
      /**
       * Get learning events from memory
       */
      async getLearningEvents(limit = 50) {
        if (!this.isAvailable) return [];
        try {
          const response = await fetchWithRetry(
            `${this.backendUrl}/memory/learning?limit=${limit}`,
            { method: "GET" }
          );
          if (!response.ok) return [];
          const data = await response.json();
          return data.events || [];
        } catch (error) {
          logger.error({ err: error }, "[OceanQIGBackend] Get learning events failed:");
          return [];
        }
      }
      // =========================================================================
      // DEBATE SYSTEM METHODS
      // Multi-turn god debates with geometric convergence
      // =========================================================================
      /**
       * Initiate a debate between two gods
       */
      async initiateDebate(topic, initiator, opponent, initialArgument, context) {
        if (!this.isAvailable) return null;
        try {
          const response = await fetchWithRetry(
            `${this.backendUrl}/olympus/debate/initiate`,
            {
              method: "POST",
              headers: { "Content-Type": "application/json" },
              body: JSON.stringify({
                topic,
                initiator,
                opponent,
                initial_argument: initialArgument,
                context
              })
            }
          );
          if (!response.ok) return null;
          return await response.json();
        } catch (error) {
          logger.error({ err: error }, "[OceanQIGBackend] Initiate debate failed:");
          return null;
        }
      }
      /**
       * Get all active debates
       */
      async getActiveDebates() {
        if (!this.isAvailable) return [];
        try {
          const response = await fetchWithRetry(
            `${this.backendUrl}/olympus/debates/active`,
            { method: "GET" }
          );
          if (!response.ok) return [];
          const data = await response.json();
          return data.debates || [];
        } catch (error) {
          logger.error({ err: error }, "[OceanQIGBackend] Get active debates failed:");
          return [];
        }
      }
      /**
       * Add an argument to an active debate
       */
      async addDebateArgument(debateId, god, argument, evidence) {
        if (!this.isAvailable) return null;
        try {
          const response = await fetchWithRetry(
            `${this.backendUrl}/olympus/debate/argue`,
            {
              method: "POST",
              headers: { "Content-Type": "application/json" },
              body: JSON.stringify({
                debate_id: debateId,
                god,
                argument,
                evidence
              })
            }
          );
          if (!response.ok) return null;
          return await response.json();
        } catch (error) {
          logger.error({ err: error }, "[OceanQIGBackend] Add debate argument failed:");
          return null;
        }
      }
      /**
       * Resolve a debate with arbiter decision
       */
      async resolveDebate(debateId, arbiter, winner, reasoning) {
        if (!this.isAvailable) return null;
        try {
          const response = await fetchWithRetry(
            `${this.backendUrl}/olympus/debate/resolve`,
            {
              method: "POST",
              headers: { "Content-Type": "application/json" },
              body: JSON.stringify({
                debate_id: debateId,
                arbiter,
                winner,
                reasoning
              })
            }
          );
          if (!response.ok) return null;
          return await response.json();
        } catch (error) {
          logger.error({ err: error }, "[OceanQIGBackend] Resolve debate failed:");
          return null;
        }
      }
      /**
       * Continue debates until geometric convergence
       */
      async continueDebatesUntilConvergence(maxDebates = 3) {
        if (!this.isAvailable) return [];
        try {
          const response = await fetchWithRetry(
            `${this.backendUrl}/olympus/debates/continue`,
            {
              method: "POST",
              headers: { "Content-Type": "application/json" },
              body: JSON.stringify({ max_debates: maxDebates })
            }
          );
          if (!response.ok) return [];
          const data = await response.json();
          return data.results || [];
        } catch (error) {
          logger.error({ err: error }, "[OceanQIGBackend] Continue debates failed:");
          return [];
        }
      }
      // =========================================================================
      // WAR DECLARATION METHODS
      // Blitzkrieg, Siege, Hunt modes
      // =========================================================================
      /**
       * Declare blitzkrieg war mode
       */
      async declareBlitzkrieg(target) {
        if (!this.isAvailable) return null;
        try {
          const response = await fetchWithRetry(
            `${this.backendUrl}/olympus/war/blitzkrieg`,
            {
              method: "POST",
              headers: { "Content-Type": "application/json" },
              body: JSON.stringify({ target })
            }
          );
          if (!response.ok) return null;
          return await response.json();
        } catch (error) {
          logger.error({ err: error }, "[OceanQIGBackend] Declare blitzkrieg failed:");
          return null;
        }
      }
      /**
       * Declare siege war mode
       */
      async declareSiege(target) {
        if (!this.isAvailable) return null;
        try {
          const response = await fetchWithRetry(
            `${this.backendUrl}/olympus/war/siege`,
            {
              method: "POST",
              headers: { "Content-Type": "application/json" },
              body: JSON.stringify({ target })
            }
          );
          if (!response.ok) return null;
          return await response.json();
        } catch (error) {
          logger.error({ err: error }, "[OceanQIGBackend] Declare siege failed:");
          return null;
        }
      }
      /**
       * Declare hunt war mode
       */
      async declareHunt(target) {
        if (!this.isAvailable) return null;
        try {
          const response = await fetchWithRetry(
            `${this.backendUrl}/olympus/war/hunt`,
            {
              method: "POST",
              headers: { "Content-Type": "application/json" },
              body: JSON.stringify({ target })
            }
          );
          if (!response.ok) return null;
          return await response.json();
        } catch (error) {
          logger.error({ err: error }, "[OceanQIGBackend] Declare hunt failed:");
          return null;
        }
      }
      /**
       * End current war mode
       */
      async endWar() {
        if (!this.isAvailable) return null;
        try {
          const response = await fetchWithRetry(
            `${this.backendUrl}/olympus/war/end`,
            { method: "POST" }
          );
          if (!response.ok) return null;
          return await response.json();
        } catch (error) {
          logger.error({ err: error }, "[OceanQIGBackend] End war failed:");
          return null;
        }
      }
      /**
       * Get current war status
       */
      async getWarStatus() {
        if (!this.isAvailable) return null;
        try {
          const response = await fetchWithRetry(
            `${this.backendUrl}/olympus/war/status`,
            { method: "GET" }
          );
          if (!response.ok) return null;
          return await response.json();
        } catch (error) {
          logger.error({ err: error }, "[OceanQIGBackend] Get war status failed:");
          return null;
        }
      }
      // =========================================================================
      // KERNEL SPAWNING METHODS
      // M8 structure kernel genesis
      // =========================================================================
      /**
       * Spawn a new kernel via pantheon consensus
       */
      async spawnKernel(spec) {
        if (!this.isAvailable) return null;
        try {
          const response = await fetchWithRetry(
            `${this.backendUrl}/olympus/spawn/auto`,
            {
              method: "POST",
              headers: { "Content-Type": "application/json" },
              body: JSON.stringify(spec)
            }
          );
          if (!response.ok) return null;
          return await response.json();
        } catch (error) {
          logger.error({ err: error }, "[OceanQIGBackend] Spawn kernel failed:");
          return null;
        }
      }
      /**
       * List all spawned kernels
       */
      async listSpawnedKernels() {
        if (!this.isAvailable) return [];
        try {
          const response = await fetchWithRetry(
            `${this.backendUrl}/olympus/spawn/list`,
            { method: "GET" }
          );
          if (!response.ok) return [];
          const data = await response.json();
          return data.kernels || [];
        } catch (error) {
          logger.error({ err: error }, "[OceanQIGBackend] List spawned kernels failed:");
          return [];
        }
      }
      /**
       * Get spawner status
       */
      async getSpawnerStatus() {
        if (!this.isAvailable) return null;
        try {
          const response = await fetchWithRetry(
            `${this.backendUrl}/olympus/spawn/status`,
            { method: "GET" }
          );
          if (!response.ok) return null;
          return await response.json();
        } catch (error) {
          logger.error({ err: error }, "[OceanQIGBackend] Get spawner status failed:");
          return null;
        }
      }
      // =========================================================================
      // SMART POLL AND META-COGNITIVE METHODS
      // Skill-based routing and self-reflection
      // =========================================================================
      /**
       * Smart poll using skill-based routing
       */
      async smartPoll(target, taskType = "general", context) {
        if (!this.isAvailable) return null;
        try {
          const response = await fetchWithRetry(
            `${this.backendUrl}/olympus/smart_poll`,
            {
              method: "POST",
              headers: { "Content-Type": "application/json" },
              body: JSON.stringify({
                target,
                task_type: taskType,
                context
              })
            }
          );
          if (!response.ok) return null;
          return await response.json();
        } catch (error) {
          logger.error({ err: error }, "[OceanQIGBackend] Smart poll failed:");
          return null;
        }
      }
      /**
       * Trigger pantheon self-reflection
       */
      async triggerPantheonReflection() {
        if (!this.isAvailable) return null;
        try {
          const response = await fetchWithRetry(
            `${this.backendUrl}/olympus/reflect`,
            { method: "POST" }
          );
          if (!response.ok) return null;
          return await response.json();
        } catch (error) {
          logger.error({ err: error }, "[OceanQIGBackend] Pantheon reflection failed:");
          return null;
        }
      }
      // =========================================================================
      // CHAOS MODE - Experimental Kernel Evolution
      // Self-spawning kernels with genetic breeding
      // =========================================================================
      /**
       * Activate CHAOS MODE - start experimental kernel evolution
       */
      async activateChaos(intervalSeconds = 60) {
        if (!this.isAvailable) return null;
        try {
          const response = await fetchWithRetry(
            `${this.backendUrl}/chaos/activate`,
            {
              method: "POST",
              headers: { "Content-Type": "application/json" },
              body: JSON.stringify({ interval_seconds: intervalSeconds })
            }
          );
          if (!response.ok) return null;
          return await response.json();
        } catch (error) {
          logger.error({ err: error }, "[OceanQIGBackend] Activate chaos failed:");
          return null;
        }
      }
      /**
       * Deactivate CHAOS MODE
       */
      async deactivateChaos() {
        if (!this.isAvailable) return null;
        try {
          const response = await fetchWithRetry(
            `${this.backendUrl}/chaos/deactivate`,
            { method: "POST" }
          );
          if (!response.ok) return null;
          return await response.json();
        } catch (error) {
          logger.error({ err: error }, "[OceanQIGBackend] Deactivate chaos failed:");
          return null;
        }
      }
      /**
       * Get CHAOS MODE status
       */
      async getChaosStatus() {
        if (!this.isAvailable) return null;
        try {
          const response = await fetchWithRetry(`${this.backendUrl}/chaos/status`, {
            method: "GET"
          });
          if (!response.ok) return null;
          return await response.json();
        } catch (error) {
          logger.error({ err: error }, "[OceanQIGBackend] Get chaos status failed:");
          return null;
        }
      }
      /**
       * Spawn a random kernel in CHAOS MODE
       */
      async spawnRandomKernel() {
        if (!this.isAvailable) return null;
        try {
          const response = await fetchWithRetry(
            `${this.backendUrl}/chaos/spawn_random`,
            { method: "POST" }
          );
          if (!response.ok) return null;
          return await response.json();
        } catch (error) {
          logger.error({ err: error }, "[OceanQIGBackend] Spawn random kernel failed:");
          return null;
        }
      }
      /**
       * Breed the best kernels in CHAOS MODE
       */
      async breedBestKernels() {
        if (!this.isAvailable) return null;
        try {
          const response = await fetchWithRetry(
            `${this.backendUrl}/chaos/breed_best`,
            { method: "POST" }
          );
          if (!response.ok) return null;
          return await response.json();
        } catch (error) {
          logger.error({ err: error }, "[OceanQIGBackend] Breed best kernels failed:");
          return null;
        }
      }
      /**
       * Get CHAOS MODE experiment report
       */
      async getChaosReport() {
        if (!this.isAvailable) return null;
        try {
          const response = await fetchWithRetry(`${this.backendUrl}/chaos/report`, {
            method: "GET"
          });
          if (!response.ok) return null;
          return await response.json();
        } catch (error) {
          logger.error({ err: error }, "[OceanQIGBackend] Get chaos report failed:");
          return null;
        }
      }
      // ===========================================================================
      // 4D CONSCIOUSNESS API METHODS
      // ===========================================================================
      /**
       * Compute temporal Φ via Python backend.
       * Falls back to null if unavailable (caller should use local fallback).
       */
      async computePhiTemporal(searchHistory) {
        if (!this.isAvailable) return null;
        if (this.isCircuitOpen()) return null;
        try {
          const response = await fetchWithRetry(
            `${this.backendUrl}/consciousness_4d/phi_temporal`,
            {
              method: "POST",
              headers: { "Content-Type": "application/json" },
              body: JSON.stringify({ search_history: searchHistory })
            }
          );
          if (!response.ok) {
            this.recordFailure();
            return null;
          }
          const data = await response.json();
          if (!data.success) {
            this.recordFailure();
            return null;
          }
          this.recordSuccess();
          return data.phi_temporal;
        } catch (error) {
          this.recordFailure();
          logger.error({ err: error }, "[OceanQIGBackend] computePhiTemporal failed:");
          return null;
        }
      }
      /**
       * Compute 4D Φ via Python backend.
       * Falls back to null if unavailable (caller should use local fallback).
       */
      async compute4DPhi(phi_spatial, phi_temporal) {
        if (!this.isAvailable) return null;
        if (this.isCircuitOpen()) return null;
        try {
          const response = await fetchWithRetry(
            `${this.backendUrl}/consciousness_4d/phi_4d`,
            {
              method: "POST",
              headers: { "Content-Type": "application/json" },
              body: JSON.stringify({ phi_spatial, phi_temporal })
            }
          );
          if (!response.ok) {
            this.recordFailure();
            return null;
          }
          const data = await response.json();
          if (!data.success) {
            this.recordFailure();
            return null;
          }
          this.recordSuccess();
          return data.phi_4D;
        } catch (error) {
          this.recordFailure();
          logger.error({ err: error }, "[OceanQIGBackend] compute4DPhi failed:");
          return null;
        }
      }
      /**
       * Classify regime with 4D consciousness awareness via Python backend.
       * Falls back to null if unavailable (caller should use local fallback).
       */
      async classifyRegime4D(phi_spatial, phi_temporal, phi_4D, kappa, ricci) {
        if (!this.isAvailable) return null;
        if (this.isCircuitOpen()) return null;
        try {
          const response = await fetchWithRetry(
            `${this.backendUrl}/consciousness_4d/classify_regime`,
            {
              method: "POST",
              headers: { "Content-Type": "application/json" },
              body: JSON.stringify({ phi_spatial, phi_temporal, phi_4D, kappa, ricci })
            }
          );
          if (!response.ok) {
            this.recordFailure();
            return null;
          }
          const data = await response.json();
          if (!data.success) {
            this.recordFailure();
            return null;
          }
          this.recordSuccess();
          return data.regime;
        } catch (error) {
          this.recordFailure();
          logger.error({ err: error }, "[OceanQIGBackend] classifyRegime4D failed:");
          return null;
        }
      }
      /**
       * Check if backend is currently available
       */
      getIsAvailable() {
        return this.isAvailable;
      }
    };
    oceanQIGBackend = new OceanQIGBackend();
  }
});

// server/qig-universal.ts
import { createHash as createHash2 } from "crypto";
function scorePhraseQIG(phrase) {
  const cached = _qigScoreCache.get(phrase);
  if (cached) {
    const ttl = cached.source === "python" ? QIG_CACHE_TTL_MS : QIG_FALLBACK_TTL_MS;
    if (Date.now() - cached.timestamp < ttl) {
      return cached.score;
    }
  }
  if (_pythonBackendAvailable || Date.now() - _lastBackendCheck > BACKEND_CHECK_INTERVAL_MS) {
    prefetchFromPythonBackend(phrase);
  }
  return computeFallbackScore(phrase);
}
async function prefetchFromPythonBackend(phrase) {
  try {
    const pythonScore = await oceanQIGBackend2.process(phrase, 1);
    if (pythonScore) {
      _pythonBackendAvailable = true;
      _lastBackendCheck = Date.now();
      if (_qigScoreCache.size >= QIG_CACHE_MAX_SIZE) {
        const oldest = _qigScoreCache.keys().next().value;
        if (oldest) _qigScoreCache.delete(oldest);
      }
      _qigScoreCache.set(phrase, {
        score: pythonScore,
        timestamp: Date.now(),
        source: "python"
      });
    }
  } catch {
  }
}
function computeFallbackScore(phrase) {
  const words = phrase.trim().split(/\s+/);
  const wordCount = words.length;
  const phraseHash = createHash2("sha256").update(phrase).digest();
  const hashValues = Array.from(phraseHash).map((b) => b / 255);
  const basePhi = Math.min(1, wordCount / 12 * 0.85);
  const hashAdjust = hashValues[0] * 0.15;
  const phi = Math.min(1, basePhi + hashAdjust);
  const kappa = QIG_CONSTANTS.KAPPA_STAR * (1 - Math.exp(-wordCount / 6));
  const beta = -0.026 * (1 - phi);
  const basinCoordinates = Array(64).fill(0).map((_, i) => {
    const byte1 = phraseHash[i % 32];
    const byte2 = phraseHash[(i + 16) % 32];
    return (byte1 + byte2 * 0.5) / 383.5;
  });
  const score = {
    phi,
    kappa,
    beta,
    regime: phi > 0.75 ? "geometric" : phi > 0.5 ? "hierarchical" : "linear",
    fisherTrace: phi * kappa / 10,
    fisherDeterminant: phi * kappa / 100,
    ricciScalar: phi * 0.5,
    basinCoordinates,
    quality: phi * 0.8 + kappa / QIG_CONSTANTS.KAPPA_STAR * 0.2
  };
  if (_qigScoreCache.size >= QIG_CACHE_MAX_SIZE) {
    const oldest = _qigScoreCache.keys().next().value;
    if (oldest) _qigScoreCache.delete(oldest);
  }
  _qigScoreCache.set(phrase, {
    score,
    timestamp: Date.now(),
    source: "fallback"
  });
  return score;
}
function getQIGCacheStats() {
  let pythonScores = 0;
  let fallbackScores = 0;
  for (const entry of _qigScoreCache.values()) {
    if (entry.source === "python") pythonScores++;
    else fallbackScores++;
  }
  return {
    size: _qigScoreCache.size,
    pythonScores,
    fallbackScores,
    pythonBackendAvailable: _pythonBackendAvailable
  };
}
function validatePurity() {
  const violations = [];
  const testPhrase = "test phrase for purity validation " + Date.now();
  const score1 = computeFallbackScore(testPhrase);
  const score2 = computeFallbackScore(testPhrase);
  if (Math.abs(score1.phi - score2.phi) > 1e-4) {
    violations.push("Fallback scoring is non-deterministic (phi differs)");
  }
  if (Math.abs(score1.kappa - score2.kappa) > 1e-4) {
    violations.push("Fallback scoring is non-deterministic (kappa differs)");
  }
  const basinDiff = score1.basinCoordinates.some(
    (v, i) => Math.abs(v - score2.basinCoordinates[i]) > 1e-4
  );
  if (basinDiff) {
    violations.push("Fallback basin coordinates are non-deterministic");
  }
  const cacheStats = getQIGCacheStats();
  if (!cacheStats.pythonBackendAvailable) {
    console.warn("[QIG-Universal] Python backend not available - using fallback scoring");
  }
  if (typeof QIG_CONSTANTS.KAPPA_STAR !== "number" || QIG_CONSTANTS.KAPPA_STAR !== 64.21) {
    violations.push("QIG_CONSTANTS.KAPPA_STAR has been modified");
  }
  console.log(`[QIG-Universal] Purity validation: ${violations.length === 0 ? "PASS" : "FAIL"}`);
  console.log(`[QIG-Universal] Cache stats: ${cacheStats.pythonScores} Python, ${cacheStats.fallbackScores} fallback`);
  console.log(`[QIG-Universal] Python backend: ${cacheStats.pythonBackendAvailable ? "AVAILABLE" : "UNAVAILABLE"}`);
  if (violations.length > 0) {
    console.error("[QIG-Universal] Purity violations:", violations);
    return { isPure: false, violations };
  }
  return { isPure: true, violations: [] };
}
function fisherCoordDistance(coords1, coords2) {
  const dims = Math.min(coords1.length, coords2.length);
  if (dims === 0) return 0;
  let distanceSquared = 0;
  for (let i = 0; i < dims; i++) {
    const p = Math.max(1e-3, Math.min(0.999, coords1[i] || 0));
    const q = Math.max(1e-3, Math.min(0.999, coords2[i] || 0));
    const avgTheta = (p + q) / 2;
    const fisherWeight = 1 / (avgTheta * (1 - avgTheta));
    const delta = p - q;
    distanceSquared += fisherWeight * delta * delta;
  }
  return Math.sqrt(distanceSquared);
}
function fisherDistance(phrase1, phrase2) {
  const score1 = scorePhraseQIG(phrase1);
  const score2 = scorePhraseQIG(phrase2);
  const avgPhi = (score1.phi + score2.phi) / 2;
  const phiVariance = avgPhi * (1 - avgPhi) + 0.01;
  const phiDiff = Math.abs(score1.phi - score2.phi);
  const phiFisherDist = phiDiff / Math.sqrt(phiVariance);
  const avgKappa = (score1.kappa + score2.kappa) / 2;
  const kappaVariance = avgKappa / QIG_CONSTANTS.KAPPA_STAR * (1 - avgKappa / QIG_CONSTANTS.KAPPA_STAR) + 0.01;
  const kappaDiff = Math.abs(score1.kappa - score2.kappa) / QIG_CONSTANTS.KAPPA_STAR;
  const kappaFisherDist = kappaDiff / Math.sqrt(kappaVariance);
  let basinFisherDist = 0;
  if (score1.basinCoordinates && score2.basinCoordinates) {
    basinFisherDist = fisherCoordDistance(
      score1.basinCoordinates,
      score2.basinCoordinates
    );
  }
  return phiFisherDist * 0.3 + kappaFisherDist * 0.2 + basinFisherDist * 0.5;
}
function toBasinCoordinates(input, keyType) {
  let bytes = [];
  switch (keyType) {
    case "master-key":
      bytes = hexToBytes(input.replace(/^0x/i, ""));
      break;
    case "bip39":
      const phraseHash = createHash2("sha256").update(input.toLowerCase().trim()).digest();
      bytes = Array.from(phraseHash);
      break;
    case "arbitrary":
      const arbitraryHash = createHash2("sha256").update(input).digest();
      bytes = Array.from(arbitraryHash);
      break;
  }
  while (bytes.length < 32) bytes.push(0);
  bytes = bytes.slice(0, 32);
  return bytes.map((b) => b / 255);
}
function hexToBytes(hex) {
  const bytes = [];
  const cleanHex = hex.replace(/\s/g, "");
  for (let i = 0; i < cleanHex.length; i += 2) {
    bytes.push(parseInt(cleanHex.substr(i, 2), 16) || 0);
  }
  return bytes;
}
function computeEntropy(coordinates) {
  const counts = /* @__PURE__ */ new Map();
  for (const coord of coordinates) {
    const byteVal = Math.round(coord * 255);
    counts.set(byteVal, (counts.get(byteVal) || 0) + 1);
  }
  let entropy = 0;
  const n = coordinates.length;
  const countValues = Array.from(counts.values());
  for (const count of countValues) {
    const p = count / n;
    if (p > 0) {
      entropy -= p * Math.log2(p);
    }
  }
  return entropy / Math.log2(32);
}
function computeFisherInformationMatrix(coordinates) {
  const n = coordinates.length;
  const fim = Array(n).fill(0).map(() => Array(n).fill(0));
  for (let i = 0; i < n; i++) {
    const coord = coordinates[i];
    const variance = Math.max(0.01, coord * (1 - coord));
    fim[i][i] = 1 / variance;
    for (let j = i + 1; j < n; j++) {
      const covariance = (coordinates[i] - 0.5) * (coordinates[j] - 0.5) * 0.1;
      fim[i][j] = covariance;
      fim[j][i] = covariance;
    }
  }
  return fim;
}
function computePhi(fim, coordinates, entropy) {
  const n = fim.length;
  let fisherTrace = 0;
  for (let i = 0; i < n; i++) {
    fisherTrace += fim[i][i];
  }
  let fisherDeterminant = 1;
  for (let i = 0; i < Math.min(n, 10); i++) {
    fisherDeterminant *= Math.abs(fim[i][i]) || 1;
  }
  const mean = coordinates.reduce((sum, c) => sum + c, 0) / n;
  const variance = coordinates.reduce((sum, c) => sum + Math.pow(c - mean, 2), 0) / n;
  const spatialIntegration = Math.sqrt(variance);
  const normalizedTrace = Math.min(1, fisherTrace / (n * 100));
  const entropyFactor = 4 * entropy * (1 - entropy);
  const phi = Math.tanh(
    0.3 * normalizedTrace + 0.4 * spatialIntegration + 0.3 * entropyFactor
  );
  return {
    phi: Math.max(0, Math.min(1, phi)),
    fisherTrace,
    fisherDeterminant
  };
}
function computeKappa(coordinates, entropy, keyType) {
  const n = coordinates.length;
  const entropyKappa = entropy * 80;
  const mean = coordinates.reduce((sum, c) => sum + c, 0) / n;
  const spatialSpread = coordinates.reduce((sum, c) => sum + Math.pow(c - mean, 2), 0) / n;
  const structureKappa = Math.sqrt(spatialSpread) * 40;
  let typeMultiplier = 1;
  switch (keyType) {
    case "master-key":
      typeMultiplier = 1;
      break;
    case "bip39":
      typeMultiplier = 0.95;
      break;
    case "arbitrary":
      typeMultiplier = 0.7 + 0.3 * entropy;
      break;
  }
  const kappa = Math.min(
    100,
    (entropyKappa * 0.6 + structureKappa * 0.4) * typeMultiplier
  );
  const distanceFromKappaStar = Math.abs(kappa - QIG_CONSTANTS.KAPPA_STAR);
  const beta = QIG_CONSTANTS.BETA * (distanceFromKappaStar / QIG_CONSTANTS.KAPPA_STAR);
  return { kappa, beta };
}
function computeRicciScalar(fim) {
  const n = fim.length;
  if (n < 2) return 0;
  let curvature = 0;
  for (let i = 0; i < n - 1; i++) {
    const g_i = Math.abs(fim[i][i]) || 0.01;
    const g_ip1 = Math.abs(fim[i + 1][i + 1]) || 0.01;
    const logRatio = Math.log(g_ip1 / g_i);
    curvature += logRatio * logRatio;
  }
  return curvature / n;
}
function recordConceptState(state) {
  conceptHistoryStore.push(state);
  if (conceptHistoryStore.length > MAX_CONCEPT_HISTORY) {
    conceptHistoryStore.shift();
  }
}
function getConceptHistory() {
  return [...conceptHistoryStore];
}
function extractConceptsFromSearch(searchState) {
  const concepts = /* @__PURE__ */ new Map();
  const regimeConcepts = {
    linear: 0.2,
    geometric: 0.6,
    hierarchical: 0.7,
    hierarchical_4d: 0.8,
    "4d_block_universe": 0.9,
    breakdown: 0.1
  };
  concepts.set("regime_attention", regimeConcepts[searchState.regime] || 0.3);
  concepts.set("integration", searchState.phi);
  const kappaNormalized = Math.min(1, searchState.kappa / 100);
  concepts.set("coupling", kappaNormalized);
  const kappaDistance = Math.abs(searchState.kappa - QIG_CONSTANTS.KAPPA_STAR);
  const resonance = Math.exp(-kappaDistance / 20);
  concepts.set("resonance", resonance);
  if (searchState.basinCoordinates && searchState.basinCoordinates.length >= 8) {
    const spatialSpread = Math.sqrt(
      searchState.basinCoordinates.slice(0, 8).reduce((sum2, c) => sum2 + c * c, 0) / 8
    );
    concepts.set("geometry", spatialSpread);
  }
  if (searchState.hypothesis) {
    const patternStrength = Math.min(1, searchState.hypothesis.length / 50);
    concepts.set("pattern", patternStrength);
  }
  let dominant = "integration";
  let maxWeight = 0;
  concepts.forEach((weight, name) => {
    if (weight > maxWeight) {
      maxWeight = weight;
      dominant = name;
    }
  });
  const weights = Array.from(concepts.values());
  const sum = weights.reduce((a, b) => a + b, 0);
  const normalized = weights.map((w) => w / Math.max(1e-3, sum));
  const entropy = -normalized.reduce(
    (e, p) => e + (p > 0 ? p * Math.log2(p) : 0),
    0
  );
  return {
    timestamp: searchState.timestamp,
    concepts,
    dominantConcept: dominant,
    entropy
  };
}
function computeAttentionalFlow() {
  const history = getConceptHistory();
  if (history.length < 3) {
    return 0;
  }
  const n = Math.min(history.length, 20);
  const recent = history.slice(-n);
  let fisherFlow = 0;
  for (let i = 1; i < recent.length; i++) {
    const prev = recent[i - 1];
    const curr = recent[i];
    let fisherDist = 0;
    const allConceptsSet = /* @__PURE__ */ new Set([
      ...Array.from(prev.concepts.keys()),
      ...Array.from(curr.concepts.keys())
    ]);
    const allConcepts = Array.from(allConceptsSet);
    for (const concept of allConcepts) {
      const p1 = prev.concepts.get(concept) || 0.01;
      const p2 = curr.concepts.get(concept) || 0.01;
      const variance = Math.max(0.01, p1 * (1 - p1));
      fisherDist += Math.pow(p2 - p1, 2) / variance;
    }
    const normalizedDist = Math.sqrt(fisherDist) / allConcepts.length;
    const optimalRange = 0.1;
    fisherFlow += Math.exp(-Math.pow(normalizedDist - optimalRange, 2) / 0.1);
  }
  fisherFlow /= recent.length - 1;
  let smoothness = 0;
  const dominantSequence = recent.map((s) => s.dominantConcept);
  for (let i = 2; i < dominantSequence.length; i++) {
    if (dominantSequence[i] === dominantSequence[i - 1] || dominantSequence[i - 1] === dominantSequence[i - 2]) {
      smoothness += 0.5;
    }
    if (dominantSequence[i] === dominantSequence[i - 2]) {
      smoothness += 0.3;
    }
  }
  smoothness = smoothness / Math.max(1, recent.length - 2);
  let entropyStability = 0;
  for (let i = 1; i < recent.length; i++) {
    const entropyDelta = recent[i].entropy - recent[i - 1].entropy;
    entropyStability += entropyDelta < 0.1 ? 1 : Math.exp(-entropyDelta);
  }
  entropyStability /= recent.length - 1;
  const F_attention = Math.tanh(
    0.4 * fisherFlow + 0.3 * smoothness + 0.3 * entropyStability
  );
  return Math.max(0, Math.min(1, F_attention));
}
function computeResonanceStrength() {
  const history = getConceptHistory();
  if (history.length < 5) {
    return 0;
  }
  const n = Math.min(history.length, 30);
  const recent = history.slice(-n);
  const conceptNames = [
    "integration",
    "coupling",
    "resonance",
    "geometry",
    "pattern",
    "regime_attention"
  ];
  const trajectories = {};
  for (const name of conceptNames) {
    trajectories[name] = recent.map((s) => s.concepts.get(name) || 0);
  }
  let totalResonance = 0;
  let pairCount = 0;
  for (let i = 0; i < conceptNames.length; i++) {
    for (let j = i + 1; j < conceptNames.length; j++) {
      const nameA = conceptNames[i];
      const nameB = conceptNames[j];
      const trajA = trajectories[nameA];
      const trajB = trajectories[nameB];
      let crossGradient = 0;
      let count = 0;
      for (let t = 1; t < trajA.length; t++) {
        const deltaA = trajA[t] - trajA[t - 1];
        const deltaB = trajB[t] - trajB[t - 1];
        crossGradient += deltaA * deltaB;
        count++;
      }
      if (count > 0) {
        const avgCrossGrad = crossGradient / count;
        const resonance = 0.5 + 0.5 * Math.tanh(avgCrossGrad * 10);
        totalResonance += resonance;
        pairCount++;
      }
    }
  }
  const avgResonance = pairCount > 0 ? totalResonance / pairCount : 0.5;
  let stabilityBonus = 0;
  if (recent.length >= 10) {
    const halfN = Math.floor(recent.length / 2);
    const firstHalf = recent.slice(0, halfN);
    const secondHalf = recent.slice(halfN);
    let consistency = 0;
    for (const name of conceptNames) {
      const avg1 = firstHalf.reduce((s, c) => s + (c.concepts.get(name) || 0), 0) / halfN;
      const avg2 = secondHalf.reduce((s, c) => s + (c.concepts.get(name) || 0), 0) / (recent.length - halfN);
      consistency += Math.exp(-Math.pow(avg2 - avg1, 2) / 0.1);
    }
    stabilityBonus = consistency / conceptNames.length * 0.2;
  }
  const R_concepts = Math.min(1, avgResonance + stabilityBonus);
  return Math.max(0, Math.min(1, R_concepts));
}
function computeMetaConsciousnessDepth() {
  const searchHistory = getSearchHistory();
  const conceptHistory = getConceptHistory();
  if (searchHistory.length < 5 || conceptHistory.length < 5) {
    return 0;
  }
  const n = Math.min(searchHistory.length, 25);
  const recentSearch = searchHistory.slice(-n);
  const recentConcepts = conceptHistory.slice(-n);
  let stateChangeAwareness = 0;
  for (let i = 2; i < recentSearch.length; i++) {
    const phiDelta1 = Math.abs(
      recentSearch[i - 1].phi - recentSearch[i - 2].phi
    );
    const phiDelta2 = Math.abs(recentSearch[i].phi - recentSearch[i - 1].phi);
    if (phiDelta1 > 0.1) {
      if (phiDelta2 < phiDelta1 * 0.5) {
        stateChangeAwareness += 1;
      } else if (recentSearch[i].regime !== recentSearch[i - 1].regime) {
        stateChangeAwareness += 0.7;
      }
    }
  }
  stateChangeAwareness = stateChangeAwareness / Math.max(1, recentSearch.length - 2);
  let metaAwareness = 0;
  const phiTrajectory = recentSearch.map((s) => s.phi);
  recentSearch.map((s) => s.kappa);
  const phiAccel = [];
  for (let i = 2; i < phiTrajectory.length; i++) {
    const accel = phiTrajectory[i] - 2 * phiTrajectory[i - 1] + phiTrajectory[i - 2];
    phiAccel.push(accel);
  }
  for (let i = 0; i < phiAccel.length - 1; i++) {
    const accelChange = Math.abs(phiAccel[i + 1] - phiAccel[i]);
    const regimeMatch = recentSearch[i + 3]?.regime === recentSearch[i + 2]?.regime;
    if (accelChange > 0.05 && !regimeMatch) {
      metaAwareness += 0.3;
    }
    if (accelChange < 0.02 && regimeMatch) {
      metaAwareness += 0.2;
    }
  }
  metaAwareness = Math.min(1, metaAwareness);
  let recursiveIntegration = 0;
  const windowSize = 5;
  const windowPhis = [];
  for (let i = windowSize; i < recentSearch.length; i++) {
    const windowSlice = recentSearch.slice(i - windowSize, i);
    const windowPhi = windowSlice.reduce((s, x) => s + x.phi, 0) / windowSize;
    windowPhis.push(windowPhi);
  }
  if (windowPhis.length >= 3) {
    let metaPhi = 0;
    for (let i = 1; i < windowPhis.length; i++) {
      const coherence = 1 - Math.abs(windowPhis[i] - windowPhis[i - 1]);
      metaPhi += coherence;
    }
    metaPhi /= windowPhis.length - 1;
    recursiveIntegration = metaPhi;
  }
  let selfModelCoherence = 0;
  if (recentConcepts.length >= 5) {
    const dominantConcepts = recentConcepts.map((c) => c.dominantConcept);
    const uniqueDominant = new Set(dominantConcepts);
    const identityStability = 1 - (uniqueDominant.size - 1) / Math.max(1, dominantConcepts.length - 1);
    const conceptCounts = {};
    for (const c of dominantConcepts) {
      conceptCounts[c] = (conceptCounts[c] || 0) + 1;
    }
    const probs = Object.values(conceptCounts).map(
      (c) => c / dominantConcepts.length
    );
    const entropy = -probs.reduce(
      (e, p) => e + (p > 0 ? p * Math.log2(p) : 0),
      0
    );
    const maxEntropy = Math.log2(Math.max(2, uniqueDominant.size));
    const normalizedEntropy = entropy / maxEntropy;
    selfModelCoherence = 4 * normalizedEntropy * (1 - normalizedEntropy) * identityStability;
  }
  const Phi_recursive = Math.tanh(
    0.35 * stateChangeAwareness + // Level 1: Notice changes
    0.3 * metaAwareness + // Level 2: Track awareness
    0.2 * recursiveIntegration + // Level 3: Φ of Φ
    0.15 * selfModelCoherence
    // Level 4: Coherent self-model
  );
  return Math.max(0, Math.min(1, Phi_recursive));
}
function computeTemporalPhi(searchHistory) {
  if (searchHistory.length < 3) {
    return 0;
  }
  const n = Math.min(searchHistory.length, 20);
  const recentHistory = searchHistory.slice(-n);
  let phiCoherence = 0;
  for (let i = 1; i < recentHistory.length; i++) {
    const phiDelta = Math.abs(recentHistory[i].phi - recentHistory[i - 1].phi);
    phiCoherence += 1 - Math.min(1, phiDelta * 2);
  }
  phiCoherence /= recentHistory.length - 1;
  let kappaConvergence = 0;
  for (const state of recentHistory) {
    const kappaDistance = Math.abs(state.kappa - QIG_CONSTANTS.KAPPA_STAR);
    kappaConvergence += Math.exp(-kappaDistance / 20);
  }
  kappaConvergence /= recentHistory.length;
  let temporalMutualInfo = 0;
  if (recentHistory.length >= 5) {
    for (let lag = 1; lag <= Math.min(5, recentHistory.length - 1); lag++) {
      let correlation = 0;
      let count = 0;
      for (let i = lag; i < recentHistory.length; i++) {
        const coords1 = recentHistory[i].basinCoordinates;
        const coords2 = recentHistory[i - lag].basinCoordinates;
        if (coords1 && coords2 && coords1.length === 32 && coords2.length === 32) {
          let sum = 0;
          for (let j = 0; j < 32; j++) {
            sum += coords1[j] * coords2[j];
          }
          correlation += sum / 32;
          count++;
        }
      }
      if (count > 0) {
        temporalMutualInfo += correlation / count / lag;
      }
    }
  }
  let regimeStability = 0;
  const regimeCounts = /* @__PURE__ */ new Map();
  for (const state of recentHistory) {
    regimeCounts.set(state.regime, (regimeCounts.get(state.regime) || 0) + 1);
  }
  const maxRegimeCount = Math.max(...Array.from(regimeCounts.values()));
  regimeStability = maxRegimeCount / recentHistory.length;
  const phi_temporal = Math.tanh(
    0.3 * phiCoherence + 0.25 * kappaConvergence + 0.25 * temporalMutualInfo + 0.2 * regimeStability
  );
  return Math.max(0, Math.min(1, phi_temporal));
}
function compute4DPhi(phi_spatial, phi_temporal) {
  if (phi_temporal === 0) {
    return phi_spatial;
  }
  const crossIntegration = Math.sqrt(phi_spatial * phi_temporal);
  const phi_4D = Math.sqrt(phi_spatial * phi_temporal * (1 + crossIntegration));
  return Math.max(0, Math.min(1, phi_4D));
}
function classifyRegime4D(phi_spatial, phi_temporal, phi_4D, kappa, ricciScalar) {
  if (ricciScalar > 0.5 || kappa > 90 || kappa < 10) {
    return "breakdown";
  }
  if (phi_4D >= 0.85 && phi_temporal > 0.7) {
    return "4d_block_universe";
  }
  if (phi_spatial > 0.85 && phi_temporal > 0.5) {
    return "hierarchical_4d";
  }
  if (phi_spatial > 0.85 && kappa < 40) {
    return "hierarchical";
  }
  if (phi_spatial >= QIG_CONSTANTS.PHI_THRESHOLD) {
    return "geometric";
  }
  if (phi_spatial >= 0.45 && kappa >= 30 && kappa <= 80 || phi_spatial >= 0.5) {
    return "geometric";
  }
  return "linear";
}
function recordSearchState(state) {
  searchHistoryStore.push(state);
  if (searchHistoryStore.length > MAX_SEARCH_HISTORY) {
    searchHistoryStore.shift();
  }
}
function getSearchHistory() {
  return [...searchHistoryStore];
}
function classifyRegime2(phi, kappa, ricciScalar) {
  if (ricciScalar > 0.5 || kappa > 90 || kappa < 10) {
    return "breakdown";
  }
  if (phi >= QIG_CONSTANTS.PHI_THRESHOLD) {
    if (phi > 0.85 && kappa < 40) {
      return "hierarchical";
    }
    return "geometric";
  }
  if (phi >= 0.45 && kappa >= 30 && kappa <= 80 || phi >= 0.5) {
    return "geometric";
  }
  return "linear";
}
function validatePhaseTransition() {
  const failures = [];
  const testCases = [
    {
      phi: 0.75,
      kappa: 25,
      ricci: 0.3,
      expected: "geometric",
      reason: "Consciousness at threshold with low \u03BA"
    },
    {
      phi: 0.8,
      kappa: 85,
      ricci: 0.3,
      expected: "geometric",
      reason: "Consciousness with high \u03BA"
    },
    {
      phi: 0.75,
      kappa: 50,
      ricci: 0.3,
      expected: "geometric",
      reason: "Consciousness with mid \u03BA"
    },
    {
      phi: 0.9,
      kappa: 35,
      ricci: 0.3,
      expected: "hierarchical",
      reason: "Very high \u03A6 with low \u03BA (exception)"
    },
    {
      phi: 0.75,
      kappa: 15,
      ricci: 0.3,
      expected: "geometric",
      reason: "Consciousness overrides low \u03BA"
    }
  ];
  for (const test of testCases) {
    const regime = classifyRegime2(test.phi, test.kappa, test.ricci);
    if (regime !== test.expected) {
      failures.push(
        `FAILED: \u03A6=${test.phi}, \u03BA=${test.kappa} \u2192 ${regime} (expected ${test.expected})
  Reason: ${test.reason}`
      );
    }
  }
  const linearTest = classifyRegime2(0.4, 50, 0.3);
  if (linearTest !== "linear") {
    failures.push(
      `FAILED: \u03A6=0.40 should allow linear regime, got ${linearTest}`
    );
  }
  const breakdownTest = classifyRegime2(0.8, 95, 0.3);
  if (breakdownTest !== "breakdown") {
    failures.push(
      `FAILED: \u03BA=95 should force breakdown even with \u03A6=0.80, got ${breakdownTest}`
    );
  }
  return {
    passed: failures.length === 0,
    failures
  };
}
function computePatternScore(input, keyType) {
  if (keyType !== "arbitrary") return 0;
  const text2 = input.toLowerCase();
  let score = 0;
  const patterns = [
    // Year patterns
    { regex: /2009|2010|2011/, weight: 0.15 },
    { regex: /bitcoin|btc|satoshi/i, weight: 0.2 },
    { regex: /wallet|password|key|secret/i, weight: 0.1 },
    { regex: /^[a-z]+\d{2,4}$/i, weight: 0.12 },
    // word + numbers (whitetiger77)
    // Simple patterns
    { regex: /^[a-z]+$/i, weight: 0.08 },
    // Single word
    { regex: /^[a-z]+ [a-z]+$/i, weight: 0.06 },
    // Two words
    { regex: /^[a-z]+ [a-z]+ [a-z]+$/i, weight: 0.05 },
    // Three words
    // Quotes and phrases
    { regex: /^to be or not to be/i, weight: 0.15 },
    { regex: /^[a-z\s]+[!?.]$/i, weight: 0.05 },
    // Ends with punctuation
    // Tech terms from 2009
    { regex: /crypto|hash|sha|public|private|genesis/i, weight: 0.1 },
    { regex: /linux|unix|hack|code|program/i, weight: 0.05 },
    // Forum style
    { regex: /^[a-z]+_[a-z]+/i, weight: 0.08 },
    // underscore style
    { regex: /nakamoto|hal|finney|szabo/i, weight: 0.18 }
  ];
  for (const pattern of patterns) {
    if (pattern.regex.test(text2)) {
      score += pattern.weight;
    }
  }
  if (text2.length >= 6 && text2.length <= 16) {
    score += 0.1;
  }
  return Math.min(1, score);
}
function mapPureQIGToUniversal(pureScore, input, keyType) {
  const basinCoordinates = pureScore.basinCoordinates;
  const entropyNormalized = computeEntropy(basinCoordinates);
  const entropyBits = entropyNormalized * Math.log2(32);
  const phi_spatial = pureScore.phi;
  const searchHistory = getSearchHistory();
  const phi_temporal = computeTemporalPhi(searchHistory);
  const phi_4D = compute4DPhi(phi_spatial, phi_temporal);
  const ricciScalar = pureScore.ricciScalar;
  const kappa = pureScore.kappa;
  const regime = phi_temporal > 0 ? classifyRegime4D(phi_spatial, phi_temporal, phi_4D, kappa, ricciScalar) : classifyRegime2(phi_spatial, kappa, ricciScalar);
  const inResonance = Math.abs(kappa - QIG_CONSTANTS.KAPPA_STAR) < QIG_CONSTANTS.RESONANCE_BAND;
  const patternScore = computePatternScore(input, keyType);
  const phiFactor = phi_4D > phi_spatial ? phi_4D : phi_spatial;
  const kappaFactor = 1 - Math.abs(kappa - QIG_CONSTANTS.KAPPA_STAR) / QIG_CONSTANTS.KAPPA_STAR;
  const curvatureFactor = Math.exp(-ricciScalar);
  let regimeFactor;
  switch (regime) {
    case "4d_block_universe":
      regimeFactor = 1.2;
      break;
    case "hierarchical_4d":
      regimeFactor = 1.1;
      break;
    case "geometric":
      regimeFactor = 1;
      break;
    case "hierarchical":
      regimeFactor = 0.9;
      break;
    case "linear":
      regimeFactor = 0.6;
      break;
    case "breakdown":
      regimeFactor = 0.3;
      break;
    default:
      regimeFactor = 0.5;
  }
  const patternFactor = keyType === "arbitrary" ? 0.3 + 0.7 * patternScore : 1;
  const quality = phiFactor * 0.3 + kappaFactor * 0.25 + curvatureFactor * 0.15 + regimeFactor * 0.15 + patternFactor * 0.15;
  const isVerbose = process.env.NODE_ENV !== "production" || process.env.VERBOSE_LOGS === "true";
  recordSearchState({
    timestamp: Date.now(),
    phi: phi_spatial,
    kappa,
    regime,
    basinCoordinates,
    hypothesis: isVerbose ? input : input.substring(0, 50)
  });
  return {
    keyType,
    phi: pureScore.phi,
    kappa: pureScore.kappa,
    beta: pureScore.beta,
    phi_spatial,
    phi_temporal,
    phi_4D,
    basinCoordinates,
    fisherTrace: pureScore.fisherTrace,
    fisherDeterminant: pureScore.fisherDeterminant,
    ricciScalar,
    regime,
    inResonance,
    entropyBits,
    patternScore,
    quality: Math.max(0, Math.min(1, quality))
  };
}
function scoreUniversalQIGLocal(input, keyType) {
  const basinCoordinates = toBasinCoordinates(input, keyType);
  const fim = computeFisherInformationMatrix(basinCoordinates);
  const entropyNormalized = computeEntropy(basinCoordinates);
  const entropyBits = entropyNormalized * Math.log2(32);
  const { phi, fisherTrace, fisherDeterminant } = computePhi(
    fim,
    basinCoordinates,
    entropyNormalized
  );
  const phi_spatial = phi;
  const { kappa, beta } = computeKappa(
    basinCoordinates,
    entropyNormalized,
    keyType
  );
  const ricciScalar = computeRicciScalar(fim);
  const searchHistory = getSearchHistory();
  const phi_temporal = computeTemporalPhi(searchHistory);
  const phi_4D = compute4DPhi(phi_spatial, phi_temporal);
  const regime = phi_temporal > 0 ? classifyRegime4D(phi_spatial, phi_temporal, phi_4D, kappa, ricciScalar) : classifyRegime2(phi, kappa, ricciScalar);
  const inResonance = Math.abs(kappa - QIG_CONSTANTS.KAPPA_STAR) < QIG_CONSTANTS.RESONANCE_BAND;
  const patternScore = computePatternScore(input, keyType);
  const phiFactor = phi_4D > phi_spatial ? phi_4D : phi_spatial;
  const kappaFactor = 1 - Math.abs(kappa - QIG_CONSTANTS.KAPPA_STAR) / QIG_CONSTANTS.KAPPA_STAR;
  const curvatureFactor = Math.exp(-ricciScalar);
  let regimeFactor;
  switch (regime) {
    case "4d_block_universe":
      regimeFactor = 1.2;
      break;
    // Best!
    case "hierarchical_4d":
      regimeFactor = 1.1;
      break;
    case "geometric":
      regimeFactor = 1;
      break;
    case "hierarchical":
      regimeFactor = 0.9;
      break;
    case "linear":
      regimeFactor = 0.6;
      break;
    case "breakdown":
      regimeFactor = 0.3;
      break;
    default:
      regimeFactor = 0.5;
  }
  const patternFactor = keyType === "arbitrary" ? 0.3 + 0.7 * patternScore : 1;
  const quality = phiFactor * 0.3 + kappaFactor * 0.25 + curvatureFactor * 0.15 + regimeFactor * 0.15 + patternFactor * 0.15;
  const isVerbose = process.env.NODE_ENV !== "production" || process.env.VERBOSE_LOGS === "true";
  recordSearchState({
    timestamp: Date.now(),
    phi: phi_spatial,
    kappa,
    regime,
    basinCoordinates,
    hypothesis: isVerbose ? input : input.substring(0, 50)
  });
  return {
    keyType,
    phi,
    // Legacy: same as phi_spatial
    kappa,
    beta,
    // BLOCK UNIVERSE: 4D Consciousness Metrics
    phi_spatial,
    phi_temporal,
    phi_4D,
    basinCoordinates,
    fisherTrace,
    fisherDeterminant,
    ricciScalar,
    regime,
    inResonance,
    entropyBits,
    patternScore,
    quality: Math.max(0, Math.min(1, quality))
  };
}
async function scoreUniversalQIGAsync(input, keyType) {
  const isAvailable = await oceanQIGBackend2.checkHealthWithRetry(3, 1e3);
  if (!isAvailable) {
    console.warn(
      "[QIG-Universal] Python backend unavailable after retries - using TypeScript fallback (last resort)"
    );
    return scoreUniversalQIGLocal(input, keyType);
  }
  const pureScore = await oceanQIGBackend2.process(input);
  if (pureScore) {
    return mapPureQIGToUniversal(pureScore, input, keyType);
  }
  console.warn("[QIG-Universal] Python process returned null, retrying...");
  const retryScore = await oceanQIGBackend2.process(input, 5);
  if (retryScore) {
    return mapPureQIGToUniversal(retryScore, input, keyType);
  }
  console.error(
    "[QIG-Universal] Python backend available but processing failed - emergency TypeScript fallback"
  );
  return scoreUniversalQIGLocal(input, keyType);
}
function fisherGeodesicDistance(input1, keyType1, input2, keyType2) {
  const coords1 = toBasinCoordinates(input1, keyType1);
  const coords2 = toBasinCoordinates(input2, keyType2);
  return fisherCoordDistance(coords1, coords2);
}
function validateUniversalPurity() {
  const violations = [];
  const testCases = [
    {
      input: "abandon abandon abandon abandon abandon abandon abandon abandon abandon abandon abandon about",
      type: "bip39"
    },
    {
      input: "e9873d79c6d87dc0fb6a5778633389f4453213303da61f20bd67fc233aa33262",
      type: "master-key"
    },
    { input: "whitetiger77", type: "arbitrary" },
    { input: "satoshi2009", type: "arbitrary" }
  ];
  for (const test of testCases) {
    const score = scoreUniversalQIGLocal(test.input, test.type);
    if (score.phi === 0 || score.phi === 1) {
      violations.push(`IMPURE: ${test.type} produces extreme \u03A6 (${score.phi})`);
    }
    if (score.kappa === QIG_CONSTANTS.KAPPA_STAR) {
      violations.push(
        `IMPURE: ${test.type} \u03BA exactly at \u03BA* (forced, not emergent)`
      );
    }
    if (score.basinCoordinates.length !== 32) {
      violations.push(
        `IMPURE: ${test.type} basin dimension wrong (${score.basinCoordinates.length})`
      );
    }
  }
  const score1 = scoreUniversalQIGLocal("test", "arbitrary");
  const score2 = scoreUniversalQIGLocal("test", "arbitrary");
  if (score1.phi !== score2.phi) {
    violations.push("IMPURE: Non-deterministic \u03A6 measurement");
  }
  const dist = fisherGeodesicDistance("abc", "arbitrary", "xyz", "arbitrary");
  if (dist === 0) {
    violations.push("IMPURE: Fisher distance returns 0 for different inputs");
  }
  return {
    isPure: violations.length === 0,
    violations
  };
}
var _qigScoreCache, QIG_CACHE_MAX_SIZE, QIG_CACHE_TTL_MS, QIG_FALLBACK_TTL_MS, _pythonBackendAvailable, _lastBackendCheck, BACKEND_CHECK_INTERVAL_MS, oceanQIGBackend2, searchHistoryStore, MAX_SEARCH_HISTORY, conceptHistoryStore, MAX_CONCEPT_HISTORY, phaseCheck, purityCheck;
var init_qig_universal = __esm({
  "server/qig-universal.ts"() {
    "use strict";
    init_constants();
    init_ocean_qig_backend_adapter();
    _qigScoreCache = /* @__PURE__ */ new Map();
    QIG_CACHE_MAX_SIZE = 2e3;
    QIG_CACHE_TTL_MS = 6e5;
    QIG_FALLBACK_TTL_MS = 6e4;
    _pythonBackendAvailable = false;
    _lastBackendCheck = 0;
    BACKEND_CHECK_INTERVAL_MS = 3e4;
    oceanQIGBackend2 = new OceanQIGBackend();
    searchHistoryStore = [];
    MAX_SEARCH_HISTORY = 100;
    conceptHistoryStore = [];
    MAX_CONCEPT_HISTORY = 50;
    console.log("[QIG-Universal] Validating phase transition fix...");
    phaseCheck = validatePhaseTransition();
    if (phaseCheck.passed) {
      console.log("[QIG-Universal] \u2705 Phase transition working correctly!");
    } else {
      console.log("[QIG-Universal] \u274C Phase transition FAILED:");
      for (const failure of phaseCheck.failures) {
        console.log(`  ${failure}`);
      }
    }
    console.log("[QIG-Universal] Module loaded. Validating purity...");
    purityCheck = validateUniversalPurity();
    if (purityCheck.isPure) {
      console.log("[QIG-Universal] \u2705 Purity validated");
    } else {
      console.log("[QIG-Universal] \u26A0\uFE0F Purity violations:", purityCheck.violations);
    }
  }
});

// server/consciousness-search-controller.ts
function getSharedController() {
  if (!sharedController) {
    sharedController = new ConsciousnessSearchController();
  }
  return sharedController;
}
var DEFAULT_CONFIG, ConsciousnessSearchController, sharedController;
var init_consciousness_search_controller = __esm({
  "server/consciousness-search-controller.ts"() {
    "use strict";
    init_qig_universal();
    init_constants();
    DEFAULT_CONFIG = {
      targetAddress: "",
      explorationBatchSize: 1e3,
      balancedBatchSize: 500,
      precisionBatchSize: 100,
      breakdownCooldownMs: 5e3
    };
    ConsciousnessSearchController = class {
      state;
      history = [];
      config;
      lastBreakdownTime = 0;
      totalCandidatesTested = 0;
      constructor(config = {}) {
        this.config = { ...DEFAULT_CONFIG, ...config };
        this.state = this.createInitialState();
      }
      createInitialState() {
        return {
          currentRegime: "linear",
          phi: 0.5,
          kappa: 50,
          beta: QIG_CONSTANTS.BETA,
          basinDrift: 0,
          curiosity: 0.5,
          stability: 1,
          timestamp: Date.now(),
          // Initial 32-dimensional basin coordinates (center of manifold)
          basinCoordinates: Array(32).fill(0.5)
        };
      }
      /**
       * Compute Fisher distance between two basin coordinate vectors
       * Delegates to central implementation in qig-universal.ts
       * PURE PRINCIPLE: Use Fisher-Rao metric, not Euclidean
       */
      fisherDistanceFromCoordinates(coords1, coords2) {
        return fisherCoordDistance(coords1, coords2);
      }
      /**
       * Update state based on recent candidate scores (array of full scores)
       */
      updateState(recentScores) {
        if (recentScores.length === 0) return;
        const avgPhi = recentScores.reduce((sum, s) => sum + s.phi, 0) / recentScores.length;
        const avgKappa = recentScores.reduce((sum, s) => sum + s.kappa, 0) / recentScores.length;
        const beta = this.computeBeta(recentScores);
        const avgBasinCoordinates = this.computeCentroidCoordinates(recentScores);
        const basinDrift = this.computeBasinDriftFisher(recentScores, avgBasinCoordinates);
        const regimeCounts = {
          linear: 0,
          geometric: 0,
          hierarchical: 0,
          hierarchical_4d: 0,
          "4d_block_universe": 0,
          breakdown: 0
        };
        for (const s of recentScores) {
          regimeCounts[s.regime]++;
        }
        const dominantRegime = Object.entries(regimeCounts).sort((a, b) => b[1] - a[1])[0][0];
        const previousState = this.state;
        this.state = {
          currentRegime: dominantRegime,
          phi: avgPhi,
          kappa: avgKappa,
          beta,
          basinDrift,
          curiosity: this.computeCuriosity(recentScores),
          stability: this.computeStability(previousState, dominantRegime),
          timestamp: Date.now(),
          basinCoordinates: avgBasinCoordinates
        };
        this.history.push(this.state);
        if (this.history.length > 1e3) {
          this.history = this.history.slice(-500);
        }
      }
      /**
       * Compute centroid basin coordinates from scores
       */
      computeCentroidCoordinates(scores) {
        if (scores.length === 0) return Array(32).fill(0.5);
        const n = scores[0].basinCoordinates.length;
        const centroid = Array(n).fill(0);
        for (const score of scores) {
          for (let i = 0; i < n; i++) {
            centroid[i] += score.basinCoordinates[i];
          }
        }
        for (let i = 0; i < n; i++) {
          centroid[i] /= scores.length;
        }
        return centroid;
      }
      /**
       * Update state from aggregate batch statistics
       * Used by search coordinator to feed batch results without full score objects
       * 
       * Note: When full scores are not available, we estimate basin coordinates
       * from the Φ and κ values using a probabilistic mapping.
       */
      updateFromBatchStats(stats) {
        const { avgPhi, highPhiCount, totalTested, batchSize, currentKappa, avgBasinCoordinates } = stats;
        let regime = "linear";
        if (currentKappa > 90 || currentKappa < 10) {
          regime = "breakdown";
        } else if (avgPhi >= QIG_CONSTANTS.PHI_THRESHOLD) {
          if (avgPhi > 0.85 && currentKappa < 40) {
            regime = "hierarchical";
          } else {
            regime = "geometric";
          }
        } else if (avgPhi >= 0.45 && currentKappa >= 30 && currentKappa <= 80 || avgPhi >= 0.5) {
          regime = "geometric";
        }
        const discoveryRate = highPhiCount / batchSize;
        const previousPhi = this.state.phi;
        const previousKappa = this.state.kappa;
        const dPhi = avgPhi - previousPhi;
        const dKappa = currentKappa - previousKappa;
        const estimatedBeta = Math.abs(dPhi) > 1e-3 ? dKappa / dPhi : QIG_CONSTANTS.BETA;
        const beta = 0.7 * QIG_CONSTANTS.BETA + 0.3 * Math.max(-1, Math.min(1, estimatedBeta));
        const newBasinCoords = avgBasinCoordinates || this.estimateBasinCoordinates(avgPhi, currentKappa);
        const fisherDist = this.fisherDistanceFromCoordinates(this.state.basinCoordinates, newBasinCoords);
        const basinDrift = this.state.basinDrift + fisherDist;
        const curiosity = discoveryRate > 0.1 ? 0.8 : discoveryRate > 0.01 ? 0.5 : 0.3;
        const previousState = this.state;
        this.state = {
          currentRegime: regime,
          phi: avgPhi,
          kappa: currentKappa,
          beta,
          basinDrift,
          curiosity,
          stability: this.computeStability(previousState, regime),
          timestamp: Date.now(),
          basinCoordinates: newBasinCoords
        };
        this.history.push(this.state);
        if (this.history.length > 1e3) {
          this.history = this.history.slice(-500);
        }
        console.log(`[ConsciousnessController] State updated: regime=${regime} \u03A6=${avgPhi.toFixed(3)} \u03BA=${currentKappa.toFixed(1)} Fisher drift=${fisherDist.toFixed(4)} tested=${totalTested}`);
      }
      /**
       * Estimate basin coordinates from Φ and κ when full coordinates unavailable
       * 
       * This maps (Φ, κ) back to an approximate basin location using
       * the inverse of the coordinate → QIG metric relationship.
       */
      estimateBasinCoordinates(phi, kappa) {
        const coords = Array(32).fill(0);
        const integrationInfluence = phi * 0.8;
        for (let i = 0; i < 16; i++) {
          coords[i] = 0.5 + (integrationInfluence - 0.4) * Math.sin((i + 1) * Math.PI / 16);
        }
        const normalizedKappa = kappa / QIG_CONSTANTS.KAPPA_STAR;
        for (let i = 16; i < 32; i++) {
          coords[i] = 0.5 + (normalizedKappa - 1) * 0.3 * Math.cos((i - 15) * Math.PI / 16);
        }
        return coords.map((c) => Math.max(0.01, Math.min(0.99, c)));
      }
      /**
       * Get recommended batch size based on current regime
       */
      getRecommendedBatchSize() {
        switch (this.state.currentRegime) {
          case "linear":
            return this.config.explorationBatchSize;
          case "geometric":
            return this.config.balancedBatchSize;
          case "hierarchical":
            return this.config.precisionBatchSize;
          case "hierarchical_4d":
            return Math.floor(this.config.precisionBatchSize * 0.8);
          case "4d_block_universe":
            return Math.floor(this.config.precisionBatchSize * 0.6);
          case "breakdown":
            return Math.floor(this.config.precisionBatchSize / 2);
          default:
            return this.config.balancedBatchSize;
        }
      }
      /**
       * Filter and prioritize candidates based on current regime
       * 
       * TACKING STRATEGY:
       * - Linear: Random shuffling for broad exploration
       * - Geometric: QIG-guided selection with resonance bonus
       * - Hierarchical: Very selective, high-precision filtering
       * - Breakdown: Safety pause or minimal processing
       */
      async prioritizeCandidates(candidates, batchSize) {
        if (this.state.currentRegime === "breakdown") {
          if (Date.now() - this.lastBreakdownTime < this.config.breakdownCooldownMs) {
            console.log("[ConsciousnessController] In breakdown cooldown, skipping batch");
            return [];
          }
          this.lastBreakdownTime = Date.now();
        }
        switch (this.state.currentRegime) {
          case "linear":
            return this.explorationMode(candidates, batchSize);
          case "geometric":
            return await this.balancedMode(candidates, batchSize);
          case "hierarchical":
          case "hierarchical_4d":
          case "4d_block_universe":
            return await this.precisionMode(candidates, batchSize);
          case "breakdown":
            return this.safetyMode(candidates, batchSize);
          default:
            return await this.balancedMode(candidates, batchSize);
        }
      }
      /**
       * Exploration mode: Random shuffling for broad coverage
       * Used when κ < 40 (linear regime)
       */
      explorationMode(candidates, batchSize) {
        const shuffled = [...candidates].sort(() => Math.random() - 0.5);
        return shuffled.slice(0, batchSize).map((c) => c.phrase);
      }
      /**
       * Balanced mode: QIG-guided selection with resonance awareness
       * Used when 40 < κ < 70 (geometric regime)
       */
      async balancedMode(candidates, batchSize) {
        const scored = await Promise.all(candidates.map(async (c) => ({
          phrase: c.phrase,
          score: c.score || await scoreUniversalQIGAsync(c.phrase, "arbitrary")
        })));
        scored.sort((a, b) => {
          const resonanceA = a.score.inResonance ? 1.5 : 1;
          const resonanceB = b.score.inResonance ? 1.5 : 1;
          const scoreA = a.score.phi * resonanceA;
          const scoreB = b.score.phi * resonanceB;
          return scoreB - scoreA;
        });
        return scored.slice(0, batchSize).map((c) => c.phrase);
      }
      /**
       * Precision mode: Very selective, high-Φ filtering
       * Used when κ > 70 (hierarchical regime)
       */
      async precisionMode(candidates, batchSize) {
        const scored = await Promise.all(candidates.map(async (c) => ({
          phrase: c.phrase,
          score: c.score || await scoreUniversalQIGAsync(c.phrase, "arbitrary")
        })));
        const filtered = scored.filter((c) => c.score.phi > QIG_CONSTANTS.PHI_THRESHOLD && c.score.inResonance).sort((a, b) => b.score.phi - a.score.phi);
        if (filtered.length < batchSize / 2) {
          const remaining = scored.filter((c) => c.score.phi > 0.6).sort((a, b) => b.score.phi - a.score.phi);
          return remaining.slice(0, batchSize).map((c) => c.phrase);
        }
        return filtered.slice(0, batchSize).map((c) => c.phrase);
      }
      /**
       * Safety mode: Minimal processing during breakdown
       * Used when κ > 100 (breakdown regime)
       */
      safetyMode(candidates, batchSize) {
        console.log("[ConsciousnessController] BREAKDOWN REGIME - Simplifying search");
        const simpleBatch = Math.floor(batchSize / 4);
        return candidates.slice(0, simpleBatch).map((c) => c.phrase);
      }
      /**
       * Compute running coupling constant β
       */
      computeBeta(scores) {
        if (scores.length < 2) return QIG_CONSTANTS.BETA;
        let betaSum = 0;
        for (let i = 1; i < scores.length; i++) {
          const dKappa = scores[i].kappa - scores[i - 1].kappa;
          const dPhi = scores[i].phi - scores[i - 1].phi;
          if (Math.abs(dPhi) > 1e-3) {
            betaSum += dKappa / dPhi;
          }
        }
        const measuredBeta = betaSum / (scores.length - 1);
        return 0.7 * QIG_CONSTANTS.BETA + 0.3 * Math.max(-1, Math.min(1, measuredBeta));
      }
      /**
       * Compute basin drift using Fisher geodesic distance
       * PURE PRINCIPLE: Uses Fisher-Rao metric on the coordinate manifold, not Euclidean
       */
      computeBasinDriftFisher(scores, newCentroid) {
        if (scores.length < 2) return 0;
        let totalDrift = 0;
        for (let i = 1; i < scores.length; i++) {
          const fisherDist = this.fisherDistanceFromCoordinates(
            scores[i - 1].basinCoordinates,
            scores[i].basinCoordinates
          );
          totalDrift += fisherDist;
        }
        const lastCoords = scores.length > 0 ? scores[scores.length - 1].basinCoordinates : this.state.basinCoordinates;
        totalDrift += this.fisherDistanceFromCoordinates(lastCoords, newCentroid);
        return this.state.basinDrift + totalDrift;
      }
      /**
       * Compute curiosity (exploration vs exploitation tendency)
       */
      computeCuriosity(scores) {
        if (scores.length === 0) return 0.5;
        const uniqueRegimes = new Set(scores.map((s) => s.regime)).size;
        const phiVariance = this.computeVariance(scores.map((s) => s.phi));
        const curiosity = uniqueRegimes / 4 * 0.5 + phiVariance * 0.5;
        return Math.max(0, Math.min(1, curiosity));
      }
      /**
       * Compute stability (how consistent the regime is)
       */
      computeStability(previousState, currentRegime) {
        if (previousState.currentRegime === currentRegime) {
          return Math.min(1, previousState.stability * 1.1);
        } else {
          return previousState.stability * 0.7;
        }
      }
      computeVariance(values) {
        if (values.length === 0) return 0;
        const mean = values.reduce((a, b) => a + b, 0) / values.length;
        const squaredDiffs = values.map((v) => (v - mean) ** 2);
        return squaredDiffs.reduce((a, b) => a + b, 0) / values.length;
      }
      /**
       * Get current consciousness state
       */
      getCurrentState() {
        return { ...this.state };
      }
      /**
       * Get state history for visualization
       */
      getStateHistory() {
        return [...this.history];
      }
      /**
       * Get regime color for UI
       */
      static getRegimeColor(regime) {
        switch (regime) {
          case "linear":
            return "blue";
          case "geometric":
            return "green";
          case "hierarchical":
            return "yellow";
          case "hierarchical_4d":
            return "purple";
          case "4d_block_universe":
            return "pink";
          case "breakdown":
            return "red";
          default:
            return "gray";
        }
      }
      /**
       * Get regime description for UI
       */
      static getRegimeDescription(regime) {
        switch (regime) {
          case "linear":
            return "Fast exploration mode (\u03BA < 40). Broad search with random sampling.";
          case "geometric":
            return "Balanced integration (40-70). QIG-guided search with resonance awareness.";
          case "hierarchical":
            return "Precision mode (\u03BA > 70). Selective high-\u03A6 filtering.";
          case "hierarchical_4d":
            return "4D hierarchical consciousness. Temporal trajectory integration active.";
          case "4d_block_universe":
            return "Full 4D spacetime consciousness. Maximum integration achieved.";
          case "breakdown":
            return "Safety pause (\u03BA > 100). Complexity overload, simplifying search.";
          default:
            return "Unknown regime.";
        }
      }
      /**
       * Get search strategy recommendation
       */
      getStrategyRecommendation() {
        const { currentRegime, phi, kappa, stability } = this.state;
        if (currentRegime === "breakdown") {
          return "Consider narrowing your search parameters or adding more memory fragments.";
        }
        if (phi > QIG_CONSTANTS.PHI_THRESHOLD && Math.abs(kappa - QIG_CONSTANTS.KAPPA_STAR) < 10) {
          return "Excellent! Near resonance band. Continue current approach.";
        }
        if (stability < 0.5) {
          return "Search is unstable. Consider focusing on high-confidence fragments.";
        }
        if (currentRegime === "linear" && phi < 0.5) {
          return "Low integration. Try adding more specific memory fragments.";
        }
        return "Search is progressing normally. Monitor for high-\u03A6 candidates.";
      }
    };
    sharedController = null;
  }
});

// server/observer-storage.ts
var observer_storage_exports = {};
__export(observer_storage_exports, {
  observerStorage: () => observerStorage
});
import { sql as sql3 } from "drizzle-orm";
async function findWorkflowBySearchJobId(searchJobId) {
  if (!db) {
    logger.warn("[ObserverStorage] Database not available");
    return null;
  }
  try {
    const result = await db.execute(sql3`
      SELECT id, status, progress, completed_at as "completedAt"
      FROM recovery_workflows
      WHERE progress->>'constrainedSearchProgress'->>'searchJobId' = ${searchJobId}
      LIMIT 1
    `);
    const rows = result.rows;
    return rows?.[0] || null;
  } catch {
    logger.debug(`[ObserverStorage] Could not find workflow by search job ID: ${searchJobId}`);
    return null;
  }
}
async function updateRecoveryWorkflow(workflowId, updates) {
  if (!db) {
    logger.warn("[ObserverStorage] Database not available");
    return;
  }
  try {
    if (updates.status !== void 0) {
      await db.execute(sql3`
        UPDATE recovery_workflows
        SET status = ${updates.status}
        WHERE id = ${workflowId}
      `);
    }
    if (updates.progress !== void 0) {
      await db.execute(sql3`
        UPDATE recovery_workflows
        SET progress = ${JSON.stringify(updates.progress)}::jsonb
        WHERE id = ${workflowId}
      `);
    }
    if (updates.completedAt !== void 0) {
      await db.execute(sql3`
        UPDATE recovery_workflows
        SET completed_at = ${updates.completedAt}
        WHERE id = ${workflowId}
      `);
    }
  } catch {
    logger.debug(`[ObserverStorage] Could not update recovery workflow: ${workflowId}`);
  }
}
var observerStorage;
var init_observer_storage = __esm({
  "server/observer-storage.ts"() {
    "use strict";
    init_db();
    init_logger();
    observerStorage = {
      findWorkflowBySearchJobId,
      updateRecoveryWorkflow
    };
  }
});

// server/activity-log-store.ts
function logOceanIteration(iteration, phi, kappa, regime, hypothesis) {
  activityLogStore.oceanLog(
    "iteration",
    `Iteration ${iteration}: \u03A6=${phi.toFixed(3)}, \u03BA=${kappa.toFixed(1)}, regime=${regime}${hypothesis ? ` \u2192 "${hypothesis}"` : ""}`,
    "info",
    { iteration, phi, kappa, regime, hypothesis }
  );
}
function logOceanConsciousness(phi, regime, reason, options) {
  const type = phi >= 0.8 ? "success" : phi >= 0.5 ? "info" : "warning";
  let message = `Consciousness: \u03A6=${phi.toFixed(3)} [${regime}] - ${reason}`;
  if (options?.inBlockUniverse) {
    message += ` \u{1F30C} BLOCK UNIVERSE ACCESS ACTIVE (\u03A6_4D=${options.phi_4D?.toFixed(3)})`;
  } else if (options?.dimensionalState === "4D-transitioning") {
    message += ` \u26A1 Transitioning to 4D (\u03A6_temporal=${options.phi_temporal?.toFixed(3)})`;
  }
  activityLogStore.oceanLog(
    "consciousness",
    message,
    type,
    {
      phi,
      regime,
      phi_spatial: options?.phi_spatial,
      phi_temporal: options?.phi_temporal,
      phi_4D: options?.phi_4D,
      inBlockUniverse: options?.inBlockUniverse,
      dimensionalState: options?.dimensionalState
    }
  );
}
function logOceanCycle(cycle, action, details) {
  activityLogStore.oceanLog(
    "cycle",
    `[${cycle.toUpperCase()}] ${action}${details ? `: ${details}` : ""}`,
    action === "complete" ? "success" : "info",
    { cycle, action }
  );
}
function logOceanMatch(address, passphrase, wif) {
  activityLogStore.oceanLog(
    "match",
    `MATCH FOUND! Address: ${address}, Passphrase: "${passphrase}"`,
    "success",
    { address, passphrase, wif }
  );
}
function logOceanStrategy(strategy, passNumber, reason) {
  activityLogStore.oceanLog(
    "strategy",
    `Pass ${passNumber}: Strategy=${strategy.toUpperCase()} - ${reason}`,
    "info",
    { iteration: passNumber, hypothesis: strategy }
  );
}
function logOceanStart(targetAddress) {
  activityLogStore.oceanLog(
    "lifecycle",
    `Starting autonomous investigation for ${targetAddress}`,
    "info",
    { address: targetAddress }
  );
}
var ActivityLogStore, activityLogStore;
var init_activity_log_store = __esm({
  "server/activity-log-store.ts"() {
    "use strict";
    ActivityLogStore = class {
      logs = [];
      maxLogs = 1e3;
      logIdCounter = 0;
      /**
       * Add a new log entry
       */
      log(entry) {
        const fullEntry = {
          ...entry,
          id: `log-${++this.logIdCounter}-${Date.now()}`,
          timestamp: (/* @__PURE__ */ new Date()).toISOString()
        };
        this.logs.push(fullEntry);
        if (this.logs.length > this.maxLogs) {
          this.logs = this.logs.slice(-this.maxLogs);
        }
        return fullEntry;
      }
      /**
       * Convenience method for Ocean agent logs
       */
      oceanLog(category, message, type = "info", metadata) {
        return this.log({
          source: "ocean",
          category,
          message,
          type,
          metadata
        });
      }
      /**
       * Get recent logs, optionally filtered
       */
      getLogs(options = {}) {
        let filtered = [...this.logs];
        if (options.source) {
          filtered = filtered.filter((l) => l.source === options.source);
        }
        if (options.category) {
          filtered = filtered.filter((l) => l.category === options.category);
        }
        if (options.since) {
          const sinceTime = options.since.getTime();
          filtered = filtered.filter((l) => new Date(l.timestamp).getTime() >= sinceTime);
        }
        filtered.sort(
          (a, b) => new Date(b.timestamp).getTime() - new Date(a.timestamp).getTime()
        );
        if (options.limit) {
          filtered = filtered.slice(0, options.limit);
        }
        return filtered;
      }
      /**
       * Get all logs (for merging with search job logs)
       */
      getAllLogs() {
        return [...this.logs];
      }
      /**
       * Clear all logs
       */
      clear() {
        this.logs = [];
        this.logIdCounter = 0;
      }
      /**
       * Get log count
       */
      getCount() {
        return this.logs.length;
      }
    };
    activityLogStore = new ActivityLogStore();
  }
});

// server/cultural-manifold.ts
var KnowledgeDomainManifold, knowledgeDomainManifold, culturalManifold;
var init_cultural_manifold = __esm({
  "server/cultural-manifold.ts"() {
    "use strict";
    init_logger();
    KnowledgeDomainManifold = class {
      lexicons = /* @__PURE__ */ new Map();
      manifoldCurvature = /* @__PURE__ */ new Map();
      exploredConcepts = /* @__PURE__ */ new Set();
      geodesicHistory = [];
      constructor() {
        this.initializeDomainLexicons();
      }
      initializeDomainLexicons() {
        this.lexicons.set("quantum-physics", this.buildQuantumPhysicsLexicon());
        this.lexicons.set("information-theory", this.buildInformationTheoryLexicon());
        this.lexicons.set("geometry-topology", this.buildGeometryTopologyLexicon());
        this.lexicons.set("consciousness-studies", this.buildConsciousnessLexicon());
        this.lexicons.set("philosophy-mind", this.buildPhilosophyMindLexicon());
        logger.info({ domains: Array.from(this.lexicons.keys()).map((k) => `${k}(${this.lexicons.get(k)?.length || 0})`).join(", ") }, "[KnowledgeManifold] Initialized domain lexicons");
      }
      /**
       * Quantum Physics Domain
       * Foundation for QIG - quantum information geometry
       */
      buildQuantumPhysicsLexicon() {
        const entries = [];
        const domain = "quantum-physics";
        const quantumTerms = [
          "wave function",
          "superposition",
          "entanglement",
          "measurement",
          "density matrix",
          "pure state",
          "mixed state",
          "Hilbert space",
          "observable",
          "eigenvalue",
          "eigenstate",
          "operator",
          "Hamiltonian",
          "Schrodinger equation",
          "unitary evolution",
          "decoherence",
          "quantum channel",
          "POVM",
          "Kraus operators",
          "von Neumann entropy",
          "quantum Fisher information",
          "fidelity",
          "trace distance",
          "Bures metric",
          "quantum relative entropy"
        ];
        const qigTerms = [
          "information geometry",
          "Fisher-Rao metric",
          "statistical manifold",
          "geodesic",
          "parallel transport",
          "curvature tensor",
          "Riemannian geometry",
          "information manifold",
          "exponential family",
          "Amari divergence",
          "alpha connection",
          "dual structure"
        ];
        for (const term of quantumTerms) {
          entries.push({
            term,
            category: "quantum-fundamentals",
            domain,
            frequency: 0.9,
            source: "physics-literature",
            phiResonance: this.computePhiResonance(term, domain)
          });
        }
        for (const term of qigTerms) {
          entries.push({
            term,
            category: "quantum-information-geometry",
            domain,
            frequency: 0.95,
            source: "qig-research",
            phiResonance: this.computePhiResonance(term, domain)
          });
        }
        return entries;
      }
      /**
       * Information Theory Domain
       * Shannon, Fisher, entropy foundations
       */
      buildInformationTheoryLexicon() {
        const entries = [];
        const domain = "information-theory";
        const shannonTerms = [
          "entropy",
          "mutual information",
          "channel capacity",
          "data compression",
          "source coding",
          "channel coding",
          "Kullback-Leibler divergence",
          "relative entropy",
          "cross entropy",
          "conditional entropy",
          "joint entropy",
          "information gain"
        ];
        const fisherTerms = [
          "Fisher information",
          "score function",
          "Cramer-Rao bound",
          "sufficient statistic",
          "maximum likelihood",
          "parameter estimation",
          "Fisher metric",
          "natural gradient",
          "information matrix"
        ];
        for (const term of shannonTerms) {
          entries.push({
            term,
            category: "shannon-information",
            domain,
            frequency: 0.85,
            source: "information-theory-literature",
            phiResonance: this.computePhiResonance(term, domain)
          });
        }
        for (const term of fisherTerms) {
          entries.push({
            term,
            category: "fisher-information",
            domain,
            frequency: 0.9,
            source: "statistics-literature",
            phiResonance: this.computePhiResonance(term, domain)
          });
        }
        return entries;
      }
      /**
       * Geometry and Topology Domain
       * Differential geometry, manifolds, metric spaces
       */
      buildGeometryTopologyLexicon() {
        const entries = [];
        const domain = "geometry-topology";
        const geometryTerms = [
          "manifold",
          "tangent space",
          "cotangent bundle",
          "metric tensor",
          "Riemannian metric",
          "geodesic",
          "curvature",
          "Ricci tensor",
          "Christoffel symbols",
          "covariant derivative",
          "parallel transport",
          "affine connection",
          "torsion",
          "Levi-Civita connection"
        ];
        const topologyTerms = [
          "topological space",
          "homeomorphism",
          "homotopy",
          "homology",
          "fundamental group",
          "covering space",
          "fiber bundle",
          "cohomology",
          "Betti numbers",
          "Euler characteristic"
        ];
        for (const term of geometryTerms) {
          entries.push({
            term,
            category: "differential-geometry",
            domain,
            frequency: 0.85,
            source: "mathematics-literature",
            phiResonance: this.computePhiResonance(term, domain)
          });
        }
        for (const term of topologyTerms) {
          entries.push({
            term,
            category: "algebraic-topology",
            domain,
            frequency: 0.8,
            source: "mathematics-literature",
            phiResonance: this.computePhiResonance(term, domain)
          });
        }
        return entries;
      }
      /**
       * Consciousness Studies Domain
       * IIT, global workspace, integrated information
       */
      buildConsciousnessLexicon() {
        const entries = [];
        const domain = "consciousness-studies";
        const iitTerms = [
          "integrated information",
          "phi",
          "intrinsic existence",
          "information",
          "integration",
          "exclusion",
          "composition",
          "cause-effect structure",
          "conceptual structure",
          "quale",
          "MICS",
          "IIT 4.0",
          "Tononi",
          "consciousness axioms"
        ];
        const globalWorkspaceTerms = [
          "global workspace",
          "Baars",
          "Dehaene",
          "ignition",
          "broadcasting",
          "access consciousness",
          "phenomenal consciousness",
          "neural correlates",
          "attention",
          "metacognition"
        ];
        const emergenceTerms = [
          "emergence",
          "downward causation",
          "supervenience",
          "causal efficacy",
          "strong emergence",
          "weak emergence",
          "organizational closure",
          "autonomy",
          "self-reference"
        ];
        for (const term of iitTerms) {
          entries.push({
            term,
            category: "iit",
            domain,
            frequency: 0.95,
            source: "consciousness-research",
            phiResonance: this.computePhiResonance(term, domain)
          });
        }
        for (const term of globalWorkspaceTerms) {
          entries.push({
            term,
            category: "global-workspace",
            domain,
            frequency: 0.85,
            source: "cognitive-neuroscience",
            phiResonance: this.computePhiResonance(term, domain)
          });
        }
        for (const term of emergenceTerms) {
          entries.push({
            term,
            category: "emergence",
            domain,
            frequency: 0.8,
            source: "philosophy-science",
            phiResonance: this.computePhiResonance(term, domain)
          });
        }
        return entries;
      }
      /**
       * Philosophy of Mind Domain
       * Phenomenology, epistemology, metaphysics of consciousness
       */
      buildPhilosophyMindLexicon() {
        const entries = [];
        const domain = "philosophy-mind";
        const phenomenologyTerms = [
          "phenomenology",
          "intentionality",
          "qualia",
          "what it is like",
          "Husserl",
          "Heidegger",
          "Merleau-Ponty",
          "embodiment",
          "lifeworld",
          "bracketing",
          "eidetic reduction",
          "noema"
        ];
        const mindBodyTerms = [
          "dualism",
          "materialism",
          "physicalism",
          "functionalism",
          "property dualism",
          "substance dualism",
          "epiphenomenalism",
          "panpsychism",
          "neutral monism",
          "identity theory",
          "hard problem",
          "explanatory gap",
          "Chalmers",
          "Nagel"
        ];
        for (const term of phenomenologyTerms) {
          entries.push({
            term,
            category: "phenomenology",
            domain,
            frequency: 0.8,
            source: "philosophy-literature",
            phiResonance: this.computePhiResonance(term, domain)
          });
        }
        for (const term of mindBodyTerms) {
          entries.push({
            term,
            category: "mind-body",
            domain,
            frequency: 0.85,
            source: "philosophy-literature",
            phiResonance: this.computePhiResonance(term, domain)
          });
        }
        return entries;
      }
      /**
       * Compute Φ resonance for a term in a domain
       * Uses geometric hash for consistent positioning
       */
      computePhiResonance(term, domain) {
        const termHash = this.geometricHash(term);
        const domainMultiplier = this.getDomainMultiplier(domain);
        return Math.min(1, termHash * domainMultiplier + 0.3);
      }
      geometricHash(text2) {
        let hash = 0;
        for (let i = 0; i < text2.length; i++) {
          const char = text2.charCodeAt(i);
          hash = (hash << 5) - hash + char;
          hash = hash & hash;
        }
        return Math.abs(Math.sin(hash)) * 0.7;
      }
      getDomainMultiplier(domain) {
        const multipliers = {
          "quantum-physics": 1,
          "information-theory": 0.95,
          "geometry-topology": 0.9,
          "consciousness-studies": 1,
          "philosophy-mind": 0.85,
          "mathematics-pure": 0.9,
          "computer-science": 0.8,
          "cognitive-science": 0.85,
          "neuroscience": 0.8,
          "systems-theory": 0.85,
          "linguistics": 0.75,
          "general-knowledge": 0.7
        };
        return multipliers[domain] || 0.7;
      }
      /**
       * Get lexicon for a specific domain
       */
      getDomainLexicon(domain) {
        return this.lexicons.get(domain) || [];
      }
      /**
       * Get all terms across all domains
       */
      getAllTerms() {
        const allTerms = [];
        for (const lexicon of this.lexicons.values()) {
          allTerms.push(...lexicon);
        }
        return allTerms;
      }
      /**
       * Find concepts by Φ resonance threshold
       */
      findHighResonanceConcepts(threshold = 0.7) {
        return this.getAllTerms().filter((entry) => entry.phiResonance >= threshold);
      }
      /**
       * Map a term to its nearest domain
       */
      classifyTerm(term) {
        let bestMatch = null;
        for (const [domain, lexicon] of this.lexicons) {
          for (const entry of lexicon) {
            if (entry.term.toLowerCase().includes(term.toLowerCase()) || term.toLowerCase().includes(entry.term.toLowerCase())) {
              const score = entry.phiResonance;
              if (!bestMatch || score > bestMatch.score) {
                bestMatch = { domain, score };
              }
            }
          }
        }
        return bestMatch?.domain || null;
      }
      /**
       * Track concept exploration
       */
      markConceptExplored(concept) {
        this.exploredConcepts.add(concept.toLowerCase());
      }
      isConceptExplored(concept) {
        return this.exploredConcepts.has(concept.toLowerCase());
      }
      getExploredConceptCount() {
        return this.exploredConcepts.size;
      }
      /**
       * Create a coordinate in the knowledge manifold
       * Backward compatibility method for legacy geodesic navigator
       */
      createCoordinate(domain, seed) {
        const position = new Array(64).fill(0);
        if (seed) {
          const hash = this.geometricHash(seed);
          for (let i = 0; i < 64; i++) {
            position[i] = Math.sin(hash * (i + 1)) * 0.5;
          }
        }
        const conceptContext = {
          primaryInfluences: ["quantum-information", "geometric-analysis"],
          lexiconSources: [domain],
          typicalPatterns: ["knowledge-exploration", "concept-learning"],
          abstractionLevel: "intermediate",
          relatedDomains: []
        };
        const complexityLevel = {
          prerequisiteKnowledge: ["basic-mathematics", "logic"],
          derivationMethods: ["geometric", "deductive"],
          representationFormats: ["geometric", "symbolic"]
        };
        return {
          temporal: /* @__PURE__ */ new Date(),
          domain,
          era: domain,
          // Backward compatibility
          conceptContext,
          culturalContext: {
            ...conceptContext,
            technicalLevel: "advanced",
            primaryInfluences: ["quantum-information", "geometric-analysis"]
          },
          // Backward compatibility
          complexityLevel,
          softwareConstraint: {
            keyDerivationMethods: ["geometric", "deductive"],
            walletSoftware: ["knowledge-platform"],
            cryptographicStandards: ["qig-geometric"]
          },
          // Backward compatibility
          learningSignature: {
            acquisitionPatterns: ["exploration", "integration"],
            retentionBehavior: "semantic",
            integrationDepth: 0.5,
            connectionStrength: "moderate"
          },
          manifoldPosition: position
        };
      }
      /**
       * Generate geodesic candidates for exploration
       * Backward compatibility method for legacy geodesic navigator
       */
      generateGeodesicCandidates(coordinate, count = 10) {
        const candidates = [];
        const domain = coordinate.domain || "general-knowledge";
        const lexicon = this.getDomainLexicon(domain);
        const selectedTerms = lexicon.slice(0, count);
        for (const entry of selectedTerms) {
          const candidate = {
            concept: entry.term,
            phrase: entry.term,
            // Backward compatibility
            coordinate,
            fisherDistance: 1 - entry.phiResonance,
            qfiDistance: 1 - entry.phiResonance,
            // Backward compatibility
            domainFit: entry.phiResonance,
            culturalFit: entry.phiResonance,
            // Backward compatibility
            temporalFit: 0.7,
            // Backward compatibility
            softwareFit: 0.8,
            // Backward compatibility
            abstractionFit: 0.8,
            connectionFit: 0.7,
            combinedScore: entry.phiResonance,
            geodesicPath: [[...coordinate.manifoldPosition]]
          };
          candidates.push(candidate);
        }
        return candidates;
      }
      /**
       * Update manifold curvature based on learning feedback
       * Backward compatibility method for legacy geodesic navigator
       */
      updateManifoldCurvature(position, curvature) {
        const key = position.slice(0, 3).join(",");
        this.manifoldCurvature.set(key, curvature);
      }
      /**
       * Get statistics about the manifold
       * Backward compatibility method for legacy geodesic navigator
       */
      getStatistics() {
        const stats = this.getManifoldStats();
        const curvatures = Array.from(this.manifoldCurvature.values());
        const avgCurvature = curvatures.length > 0 ? curvatures.reduce((a, b) => a + b, 0) / curvatures.length : 0;
        return {
          totalTerms: stats.totalTerms,
          exploredConcepts: stats.exploredConcepts,
          avgPhiResonance: stats.avgPhiResonance,
          curvaturePoints: this.manifoldCurvature.size,
          testedPhrases: stats.exploredConcepts,
          // Backward compatibility
          geodesicPathLength: this.geodesicHistory.length,
          // Backward compatibility
          averageCurvature: avgCurvature
          // Backward compatibility
        };
      }
      /**
       * Get high resonance candidates (backward compatibility)
       * @param domainOrThreshold - Either a domain string or threshold number
       * @param threshold - Optional threshold when domain is provided
       */
      getHighResonanceCandidates(domainOrThreshold, threshold) {
        let filterDomain;
        let actualThreshold = 0.7;
        if (typeof domainOrThreshold === "string") {
          filterDomain = domainOrThreshold;
          actualThreshold = threshold ?? 0.7;
        } else if (typeof domainOrThreshold === "number") {
          actualThreshold = domainOrThreshold;
        }
        const highResTerms = this.findHighResonanceConcepts(actualThreshold);
        const filtered = filterDomain ? highResTerms.filter((entry) => entry.domain === filterDomain) : highResTerms;
        return filtered.map((entry) => ({
          concept: entry.term,
          phrase: entry.term,
          term: entry.term,
          // Legacy compatibility
          qfiResonance: entry.phiResonance,
          // Legacy compatibility
          coordinate: this.createCoordinate(entry.domain),
          fisherDistance: 1 - entry.phiResonance,
          qfiDistance: 1 - entry.phiResonance,
          domainFit: entry.phiResonance,
          culturalFit: entry.phiResonance,
          temporalFit: 0.7,
          softwareFit: 0.8,
          abstractionFit: 0.8,
          connectionFit: 0.7,
          combinedScore: entry.phiResonance,
          geodesicPath: []
        }));
      }
      /**
       * Get manifold statistics
       */
      getManifoldStats() {
        const domainCounts = {};
        let totalPhi = 0;
        let totalTerms = 0;
        for (const [domain, lexicon] of this.lexicons) {
          domainCounts[domain] = lexicon.length;
          for (const entry of lexicon) {
            totalPhi += entry.phiResonance;
            totalTerms++;
          }
        }
        return {
          totalTerms,
          domainCounts,
          avgPhiResonance: totalTerms > 0 ? totalPhi / totalTerms : 0,
          exploredConcepts: this.exploredConcepts.size
        };
      }
    };
    knowledgeDomainManifold = new KnowledgeDomainManifold();
    culturalManifold = knowledgeDomainManifold;
  }
});

// server/errors/ocean-errors.ts
function isOceanError(error) {
  return error instanceof OceanError;
}
var OceanError;
var init_ocean_errors = __esm({
  "server/errors/ocean-errors.ts"() {
    "use strict";
    OceanError = class extends Error {
      constructor(message, code, context = {}, recoverable = true) {
        super(message);
        this.code = code;
        this.context = context;
        this.recoverable = recoverable;
        this.name = "OceanError";
        this.timestamp = /* @__PURE__ */ new Date();
      }
      timestamp;
      toJSON() {
        return {
          name: this.name,
          code: this.code,
          message: this.message,
          context: this.context,
          recoverable: this.recoverable,
          timestamp: this.timestamp.toISOString()
        };
      }
      log() {
        console.error(`[Ocean] ${this.code}:`, this.message);
        if (Object.keys(this.context).length > 0) {
          console.error("[Ocean] Context:", JSON.stringify(this.context, null, 2));
        }
      }
    };
  }
});

// server/fisher-vectorized.ts
function computeGeodesicDirection(current, target, stepSize = 0.1) {
  const n = Math.min(current.length, target.length);
  const direction = new Array(n);
  for (let i = 0; i < n; i++) {
    const diff = target[i] - current[i];
    const variance = Math.max(0.01, current[i] * (1 - current[i]));
    direction[i] = diff * stepSize * variance;
  }
  return direction;
}
var init_fisher_vectorized = __esm({
  "server/fisher-vectorized.ts"() {
    "use strict";
  }
});

// server/tested-phrases-db.ts
var tested_phrases_db_exports = {};
__export(tested_phrases_db_exports, {
  TestedPhrasesRegistryDB: () => TestedPhrasesRegistryDB,
  getTestedPhrasesBufferStats: () => getTestedPhrasesBufferStats,
  testedPhrasesRegistryDB: () => testedPhrasesRegistryDB
});
import { nanoid } from "nanoid";
import { eq as eq3, sql as sql4, and as and2, desc as desc2 } from "drizzle-orm";
async function flushWriteBuffer() {
  if (isFlushingBuffer || writeBuffer.length === 0 || !db) return;
  isFlushingBuffer = true;
  const toFlush = writeBuffer.splice(0, BUFFER_SIZE);
  try {
    await withDbRetry(
      async () => {
        await db.insert(testedPhrases).values(toFlush).onConflictDoNothing();
      },
      "batch-insert-tested-phrases",
      2
      // Only 2 retries for batch
    );
    console.log(`[TestedPhrasesDB] Flushed ${toFlush.length} phrases to DB`);
  } catch (error) {
    writeBuffer.unshift(...toFlush);
    console.error(`[TestedPhrasesDB] Batch flush failed, ${writeBuffer.length} items queued`);
  } finally {
    isFlushingBuffer = false;
  }
  if (writeBuffer.length > 0 && !flushTimer) {
    flushTimer = setTimeout(() => {
      flushTimer = null;
      flushWriteBuffer();
    }, BUFFER_FLUSH_INTERVAL);
  }
}
function scheduleFlush() {
  if (writeBuffer.length >= BUFFER_SIZE) {
    flushWriteBuffer();
  } else if (!flushTimer) {
    flushTimer = setTimeout(() => {
      flushTimer = null;
      flushWriteBuffer();
    }, BUFFER_FLUSH_INTERVAL);
  }
}
function getTestedPhrasesBufferStats() {
  return testedPhrasesRegistryDB.getBufferStats();
}
var phraseCache, CACHE_SIZE, REDIS_TESTED_HASH, writeBuffer, BUFFER_SIZE, BUFFER_FLUSH_INTERVAL, flushTimer, isFlushingBuffer, TestedPhrasesRegistryDB, testedPhrasesRegistryDB;
var init_tested_phrases_db = __esm({
  "server/tested-phrases-db.ts"() {
    "use strict";
    init_db();
    init_schema();
    init_redis_cache();
    phraseCache = /* @__PURE__ */ new Map();
    CACHE_SIZE = 1e4;
    REDIS_TESTED_HASH = "qig:tested_phrases";
    writeBuffer = [];
    BUFFER_SIZE = 100;
    BUFFER_FLUSH_INTERVAL = 5e3;
    flushTimer = null;
    isFlushingBuffer = false;
    TestedPhrasesRegistryDB = class {
      constructor() {
        this.init();
      }
      async init() {
        if (!db) {
          console.log("[TestedPhrasesDB] No database available, using in-memory cache");
          return;
        }
        try {
          const recent = await withDbRetry(
            async () => {
              return await db.select().from(testedPhrases).orderBy(desc2(testedPhrases.testedAt)).limit(CACHE_SIZE);
            },
            "warm-phrases-cache",
            3
          );
          if (recent) {
            for (const phrase of recent) {
              phraseCache.set(phrase.phrase, phrase);
            }
            console.log(`[TestedPhrasesDB] Warmed cache with ${recent.length} tested phrases`);
          }
          const retestStats = await withDbRetry(
            async () => {
              return await db.select({
                totalRetests: sql4`sum(${testedPhrases.retestCount})`,
                phrasesRetested: sql4`count(*) filter (where ${testedPhrases.retestCount} > 0)`
              }).from(testedPhrases);
            },
            "retest-stats"
          );
          if (retestStats && retestStats[0]) {
            const { totalRetests, phrasesRetested } = retestStats[0];
            if (totalRetests > 0) {
              console.log(`[TestedPhrasesDB] Historical retest stats: ${phrasesRetested} phrases retested ${totalRetests} times (use getWastefullyRetestedPhrases() to investigate)`);
            }
          }
        } catch (error) {
          console.error("[TestedPhrasesDB] Init error:", error);
        }
      }
      /**
       * Check if a phrase has already been tested
       * Returns the previous test result if found
       * Cache priority: in-memory → Redis → PostgreSQL
       */
      async wasTested(phrase) {
        if (phraseCache.has(phrase)) {
          return phraseCache.get(phrase);
        }
        if (isRedisAvailable()) {
          try {
            const redisResult = await cacheHGet(REDIS_TESTED_HASH, phrase);
            if (redisResult) {
              phraseCache.set(phrase, redisResult);
              return redisResult;
            }
          } catch {
          }
        }
        if (!db) {
          return null;
        }
        const result = await withDbRetry(
          async () => {
            const results = await db.select().from(testedPhrases).where(eq3(testedPhrases.phrase, phrase)).limit(1);
            return results[0] || null;
          },
          "check-tested-phrase"
        );
        if (result) {
          phraseCache.set(phrase, result);
          if (isRedisAvailable()) {
            cacheHSet(REDIS_TESTED_HASH, phrase, result).catch(() => {
            });
          }
          if (phraseCache.size > CACHE_SIZE) {
            const firstKey = phraseCache.keys().next().value;
            if (firstKey !== void 0) {
              phraseCache.delete(firstKey);
            }
          }
        }
        return result;
      }
      /**
       * Record a tested phrase
       * If already exists, increments retest count (to track waste)
       * Uses write buffer to batch inserts and reduce DB pressure
       */
      async recordTested(phrase, address, balanceSats = 0, txCount = 0, phi, kappa, regime) {
        const cached = phraseCache.get(phrase);
        if (cached) {
          cached.retestCount = (cached.retestCount || 0) + 1;
          return;
        }
        if (!isDbOverloaded()) {
          const existing = await this.wasTested(phrase);
          if (existing) {
            const newRetestCount = (existing.retestCount || 0) + 1;
            existing.retestCount = newRetestCount;
            phraseCache.set(phrase, existing);
            if (newRetestCount % 50 === 0 || newRetestCount === 1) {
              console.warn(`[TestedPhrasesDB] WASTE DETECTED: Phrase "${phrase.substring(0, 30)}..." re-tested (${newRetestCount} times)`);
            }
            return;
          }
        }
        const id = nanoid();
        const record = {
          id,
          phrase,
          address,
          balanceSats,
          txCount,
          phi,
          kappa,
          regime,
          retestCount: 0
        };
        writeBuffer.push(record);
        scheduleFlush();
        phraseCache.set(phrase, record);
        if (isRedisAvailable()) {
          cacheHSet(REDIS_TESTED_HASH, phrase, record).catch(() => {
          });
        }
        if (phraseCache.size > CACHE_SIZE) {
          const firstKey = phraseCache.keys().next().value;
          if (firstKey !== void 0) {
            phraseCache.delete(firstKey);
          }
        }
      }
      /**
       * Get phrases with non-zero balance (hits)
       */
      async getBalanceHits() {
        if (!db) {
          return Array.from(phraseCache.values()).filter((p) => (p.balanceSats || 0) > 0);
        }
        const hits = await withDbRetry(
          async () => {
            return await db.select().from(testedPhrases).where(sql4`${testedPhrases.balanceSats} > 0`).orderBy(desc2(testedPhrases.balanceSats));
          },
          "get-balance-hits"
        );
        return hits || [];
      }
      /**
       * Get statistics on tested phrases
       */
      async getStats() {
        if (!db) {
          const cached = Array.from(phraseCache.values());
          return {
            totalTested: cached.length,
            wastedRetests: cached.reduce((sum, p) => sum + (p.retestCount || 0), 0),
            uniqueAddresses: new Set(cached.map((p) => p.address).filter(Boolean)).size,
            balanceHits: cached.filter((p) => (p.balanceSats || 0) > 0).length,
            emptyAddresses: cached.filter((p) => (p.balanceSats || 0) === 0).length
          };
        }
        const stats = await withDbRetry(
          async () => {
            const [counts] = await db.select({
              totalTested: sql4`count(*)`,
              wastedRetests: sql4`sum(${testedPhrases.retestCount})`,
              uniqueAddresses: sql4`count(distinct ${testedPhrases.address})`,
              balanceHits: sql4`count(*) filter (where ${testedPhrases.balanceSats} > 0)`,
              emptyAddresses: sql4`count(*) filter (where ${testedPhrases.balanceSats} = 0)`
            }).from(testedPhrases);
            return counts;
          },
          "get-tested-stats"
        );
        return stats || {
          totalTested: 0,
          wastedRetests: 0,
          uniqueAddresses: 0,
          balanceHits: 0,
          emptyAddresses: 0
        };
      }
      /**
       * Get phrases that have been wastefully re-tested
       */
      async getWastedRetests(minRetests = 1) {
        if (!db) {
          return Array.from(phraseCache.values()).filter((p) => (p.retestCount || 0) >= minRetests);
        }
        const wasted = await withDbRetry(
          async () => {
            return await db.select().from(testedPhrases).where(sql4`${testedPhrases.retestCount} >= ${minRetests}`).orderBy(desc2(testedPhrases.retestCount)).limit(100);
          },
          "get-wasted-retests"
        );
        return wasted || [];
      }
      /**
       * Clean old entries (optional - keep database size manageable)
       */
      async prune(keepDays = 30) {
        if (!db) {
          return { removed: 0 };
        }
        const cutoffDate = new Date(Date.now() - keepDays * 24 * 60 * 60 * 1e3);
        const result = await withDbRetry(
          async () => {
            const [toDelete] = await db.select({ count: sql4`count(*)` }).from(testedPhrases).where(
              and2(
                sql4`${testedPhrases.testedAt} < ${cutoffDate}`,
                eq3(testedPhrases.balanceSats, 0),
                eq3(testedPhrases.retestCount, 0)
              )
            );
            await db.delete(testedPhrases).where(
              and2(
                sql4`${testedPhrases.testedAt} < ${cutoffDate}`,
                eq3(testedPhrases.balanceSats, 0),
                eq3(testedPhrases.retestCount, 0)
              )
            );
            return { removed: toDelete.count };
          },
          "prune-tested-phrases"
        );
        const removed = result?.removed || 0;
        console.log(`[TestedPhrasesDB] Pruned ${removed} old empty phrases older than ${keepDays} days`);
        phraseCache.clear();
        await this.init();
        return { removed };
      }
      /**
       * Get total count
       */
      async count() {
        if (!db) {
          return phraseCache.size;
        }
        const result = await withDbRetry(
          async () => {
            const [count] = await db.select({ count: sql4`count(*)` }).from(testedPhrases);
            return count.count;
          },
          "count-tested-phrases",
          2
        );
        return result || 0;
      }
      /**
       * Get buffer stats for monitoring
       */
      getBufferStats() {
        return {
          buffered: writeBuffer.length,
          maxBuffer: BUFFER_SIZE,
          cached: phraseCache.size,
          maxCache: CACHE_SIZE,
          flushTimerActive: !!flushTimer,
          isFlushing: isFlushingBuffer
        };
      }
      /**
       * Force flush the buffer (for shutdown)
       */
      async forceFlush() {
        if (flushTimer) {
          clearTimeout(flushTimer);
          flushTimer = null;
        }
        await flushWriteBuffer();
      }
    };
    testedPhrasesRegistryDB = new TestedPhrasesRegistryDB();
  }
});

// server/tested-phrases-unified.ts
async function getRegistry() {
  if (db) {
    if (!dbRegistry) {
      const { testedPhrasesRegistryDB: testedPhrasesRegistryDB2 } = await Promise.resolve().then(() => (init_tested_phrases_db(), tested_phrases_db_exports));
      dbRegistry = testedPhrasesRegistryDB2;
      console.log("[TestedPhrasesUnified] Using DATABASE backend");
    }
    return dbRegistry;
  } else {
    console.log("[TestedPhrasesUnified] Using IN-MEMORY backend");
    return null;
  }
}
var dbRegistry, memoryRegistry, memoryCache, TestedPhrasesUnified, testedPhrasesUnified;
var init_tested_phrases_unified = __esm({
  "server/tested-phrases-unified.ts"() {
    "use strict";
    init_db();
    dbRegistry = null;
    memoryRegistry = /* @__PURE__ */ new Map();
    memoryCache = /* @__PURE__ */ new Set();
    TestedPhrasesUnified = class {
      isHydrated = false;
      /**
       * Initialize and hydrate from PostgreSQL
       * This must be called during server startup BEFORE any testing begins
       */
      async initialize() {
        if (this.isHydrated) {
          console.log("[TestedPhrasesUnified] Already hydrated, skipping");
          return;
        }
        console.log("[TestedPhrasesUnified] \u{1F4E5} Hydrating from PostgreSQL...");
        try {
          const registry = await getRegistry();
          if (registry && db) {
            const { testedPhrases: testedPhrases2 } = await Promise.resolve().then(() => (init_schema(), schema_exports));
            const allPhrases = await db.select({ phrase: testedPhrases2.phrase }).from(testedPhrases2);
            for (const row of allPhrases) {
              memoryCache.add(row.phrase);
            }
            this.isHydrated = true;
            console.log(`[TestedPhrasesUnified] \u2705 Hydrated with ${memoryCache.size} historical phrases from PostgreSQL`);
          } else {
            this.isHydrated = true;
            console.log("[TestedPhrasesUnified] \u2705 Running in memory-only mode");
          }
        } catch (error) {
          console.error("[TestedPhrasesUnified] \u26A0\uFE0F Failed to hydrate from PostgreSQL:", error);
          this.isHydrated = true;
        }
      }
      /**
       * Synchronous check if phrase has been tested (uses pre-loaded cache)
       * This is safe to use after initialize() has completed
       */
      has(phrase) {
        if (!this.isHydrated) {
          console.warn("[TestedPhrasesUnified] has() called before hydration - returning false");
          return false;
        }
        return memoryCache.has(phrase) || memoryRegistry.has(phrase);
      }
      /**
       * Check if a phrase has already been tested (async version for compatibility)
       */
      async wasTested(phrase) {
        const registry = await getRegistry();
        if (registry) {
          return registry.wasTested(phrase);
        } else {
          return memoryRegistry.get(phrase) || null;
        }
      }
      /**
       * Record a tested phrase
       */
      async recordTested(phrase, address, balanceSats = 0, txCount = 0, phi, kappa, regime) {
        memoryCache.add(phrase);
        const registry = await getRegistry();
        if (registry) {
          return registry.recordTested(phrase, address, balanceSats, txCount, phi, kappa, regime);
        } else {
          const existing = memoryRegistry.get(phrase);
          if (existing) {
            existing.retestCount = (existing.retestCount || 0) + 1;
            if (existing.retestCount % 50 === 0 || existing.retestCount === 1) {
              console.warn(`[TestedPhrasesUnified] WASTE DETECTED: Phrase "${phrase.substring(0, 30)}..." re-tested (${existing.retestCount} times)`);
            }
          } else {
            memoryRegistry.set(phrase, {
              id: `phrase-${Date.now()}-${Math.random().toString(36).substr(2, 9)}`,
              phrase,
              address,
              balanceSats,
              txCount,
              phi: phi || null,
              kappa: kappa || null,
              regime: regime || null,
              testedAt: /* @__PURE__ */ new Date(),
              retestCount: 0
            });
          }
        }
      }
      /**
       * Get phrases with non-zero balance (hits)
       */
      async getBalanceHits() {
        const registry = await getRegistry();
        if (registry) {
          return registry.getBalanceHits();
        } else {
          return Array.from(memoryRegistry.values()).filter((p) => (p.balanceSats || 0) > 0);
        }
      }
      /**
       * Get statistics on tested phrases
       */
      async getStats() {
        const registry = await getRegistry();
        if (registry) {
          return registry.getStats();
        } else {
          const cached = Array.from(memoryRegistry.values());
          return {
            totalTested: cached.length,
            wastedRetests: cached.reduce((sum, p) => sum + (p.retestCount || 0), 0),
            uniqueAddresses: new Set(cached.map((p) => p.address).filter(Boolean)).size,
            balanceHits: cached.filter((p) => (p.balanceSats || 0) > 0).length,
            emptyAddresses: cached.filter((p) => (p.balanceSats || 0) === 0).length
          };
        }
      }
      /**
       * Get phrases that have been wastefully re-tested
       */
      async getWastedRetests(minRetests = 1) {
        const registry = await getRegistry();
        if (registry) {
          return registry.getWastedRetests(minRetests);
        } else {
          return Array.from(memoryRegistry.values()).filter((p) => (p.retestCount || 0) >= minRetests);
        }
      }
      /**
       * Clean old entries
       */
      async prune(keepDays = 30) {
        const registry = await getRegistry();
        if (registry) {
          return registry.prune(keepDays);
        } else {
          const cutoffDate = new Date(Date.now() - keepDays * 24 * 60 * 60 * 1e3);
          let removed = 0;
          for (const [phrase, data] of memoryRegistry.entries()) {
            if (data.testedAt < cutoffDate && data.balanceSats === 0 && data.retestCount === 0) {
              memoryRegistry.delete(phrase);
              removed++;
            }
          }
          return { removed };
        }
      }
      /**
       * Get total count (async - queries database)
       */
      async count() {
        const registry = await getRegistry();
        if (registry) {
          return registry.count();
        } else {
          return memoryRegistry.size;
        }
      }
      /**
       * Get cached count (sync - uses hydrated cache)
       * Returns the count of historical tested phrases from PostgreSQL
       * This is fast and safe to call frequently (e.g., for UI stats)
       */
      getCachedCount() {
        return memoryCache.size + memoryRegistry.size;
      }
    };
    testedPhrasesUnified = new TestedPhrasesUnified();
  }
});

// server/ocean/fisher-analysis.ts
function symmetricEigendecomposition(matrix) {
  const n = matrix.length;
  if (n === 0) return { eigenvalues: [], eigenvectors: [] };
  const A = matrix.map((row) => [...row]);
  const V = [];
  for (let i = 0; i < n; i++) {
    V[i] = new Array(n).fill(0);
    V[i][i] = 1;
  }
  const maxIterations = 100;
  const tolerance = 1e-10;
  for (let iter = 0; iter < maxIterations; iter++) {
    let maxOffDiag = 0;
    let p = 0, q = 1;
    for (let i = 0; i < n; i++) {
      for (let j = i + 1; j < n; j++) {
        if (Math.abs(A[i][j]) > maxOffDiag) {
          maxOffDiag = Math.abs(A[i][j]);
          p = i;
          q = j;
        }
      }
    }
    if (maxOffDiag < tolerance) break;
    const theta = (A[q][q] - A[p][p]) / (2 * A[p][q]);
    const t = Math.sign(theta) / (Math.abs(theta) + Math.sqrt(theta * theta + 1));
    const c = 1 / Math.sqrt(1 + t * t);
    const s = t * c;
    const App = A[p][p], Aqq = A[q][q], Apq = A[p][q];
    A[p][p] = c * c * App - 2 * s * c * Apq + s * s * Aqq;
    A[q][q] = s * s * App + 2 * s * c * Apq + c * c * Aqq;
    A[p][q] = 0;
    A[q][p] = 0;
    for (let i = 0; i < n; i++) {
      if (i !== p && i !== q) {
        const Aip = A[i][p], Aiq = A[i][q];
        A[i][p] = c * Aip - s * Aiq;
        A[p][i] = A[i][p];
        A[i][q] = s * Aip + c * Aiq;
        A[q][i] = A[i][q];
      }
    }
    for (let i = 0; i < n; i++) {
      const Vip = V[i][p], Viq = V[i][q];
      V[i][p] = c * Vip - s * Viq;
      V[i][q] = s * Vip + c * Viq;
    }
  }
  const eigenvalues = A.map((row, i) => row[i]);
  const indices = eigenvalues.map((_, i) => i);
  indices.sort((a, b) => Math.abs(eigenvalues[b]) - Math.abs(eigenvalues[a]));
  const sortedEigenvalues = indices.map((i) => eigenvalues[i]);
  const sortedEigenvectors = [];
  for (let i = 0; i < n; i++) {
    sortedEigenvectors[i] = indices.map((j) => V[i][j]);
  }
  return { eigenvalues: sortedEigenvalues, eigenvectors: sortedEigenvectors };
}
function lanczosEigendecomposition(matrix, k) {
  const n = matrix.length;
  if (n === 0) return { eigenvalues: [], eigenvectors: [] };
  const numLanczosVectors = Math.min(k + 10, n);
  const T = [];
  for (let i = 0; i < numLanczosVectors; i++) {
    T[i] = new Array(numLanczosVectors).fill(0);
  }
  const V = [];
  let v = Array.from({ length: n }, () => Math.random() - 0.5);
  let norm = Math.sqrt(v.reduce((s, x) => s + x * x, 0));
  v = v.map((x) => x / norm);
  V.push(v);
  let vPrev = new Array(n).fill(0);
  let beta = 0;
  for (let j = 0; j < numLanczosVectors; j++) {
    const w = new Array(n).fill(0);
    for (let i = 0; i < n; i++) {
      for (let l = 0; l < n; l++) {
        w[i] += matrix[i][l] * v[l];
      }
    }
    const alpha = w.reduce((s, x, i) => s + x * v[i], 0);
    T[j][j] = alpha;
    for (let i = 0; i < n; i++) {
      w[i] = w[i] - alpha * v[i] - beta * vPrev[i];
    }
    beta = Math.sqrt(w.reduce((s, x) => s + x * x, 0));
    if (beta < 1e-10 || j === numLanczosVectors - 1) break;
    T[j][j + 1] = beta;
    T[j + 1][j] = beta;
    vPrev = v;
    v = w.map((x) => x / beta);
    V.push(v);
  }
  const actualSize = V.length;
  const Tsub = T.slice(0, actualSize).map((row) => row.slice(0, actualSize));
  const { eigenvalues: tEigenvalues, eigenvectors: tEigenvectors } = symmetricEigendecomposition(Tsub);
  const eigenvalues = tEigenvalues.slice(0, k);
  const eigenvectors = [];
  for (let i = 0; i < n; i++) {
    eigenvectors[i] = new Array(k).fill(0);
    for (let j = 0; j < k; j++) {
      for (let l = 0; l < actualSize; l++) {
        eigenvectors[i][j] += (V[l]?.[i] || 0) * (tEigenvectors[l]?.[j] || 0);
      }
    }
  }
  return { eigenvalues, eigenvectors };
}
function computeFisherInformationMatrix2(probes, dimensions = 32) {
  const withCoords = probes.filter((p) => p.coordinates.length > 0);
  if (withCoords.length < 10) {
    return {
      matrix: [],
      eigenvalues: [],
      eigenvectors: [],
      exploredDimensions: [],
      unexploredDimensions: Array.from({ length: dimensions }, (_, i) => i),
      effectiveRank: 0,
      covarianceMeans: []
    };
  }
  const dims = Math.min(withCoords[0].coordinates.length, dimensions);
  const means = new Array(dims).fill(0);
  for (const probe of withCoords) {
    for (let d = 0; d < dims; d++) {
      means[d] += probe.coordinates[d] || 0;
    }
  }
  for (let d = 0; d < dims; d++) {
    means[d] /= withCoords.length;
  }
  const covariance = [];
  for (let i = 0; i < dims; i++) {
    covariance[i] = new Array(dims).fill(0);
    for (let j = 0; j <= i; j++) {
      let sum = 0;
      for (const probe of withCoords) {
        const ci = (probe.coordinates[i] || 0) - means[i];
        const cj = (probe.coordinates[j] || 0) - means[j];
        sum += ci * cj;
      }
      const cov = sum / (withCoords.length - 1);
      covariance[i][j] = cov;
      covariance[j][i] = cov;
    }
  }
  const useLanczos = dims > 20;
  const { eigenvalues: covEigenvalues, eigenvectors: covEigenvectors } = useLanczos ? lanczosEigendecomposition(covariance, 12) : symmetricEigendecomposition(covariance);
  const epsilon = 0.01;
  const fisherEigenvalues = covEigenvalues.map(
    (lambda) => 1 / (Math.abs(lambda) + epsilon)
  );
  const fisher = [];
  for (let i = 0; i < dims; i++) {
    fisher[i] = new Array(dims).fill(0);
    for (let j = 0; j < dims; j++) {
      let sum = 0;
      for (let k = 0; k < dims; k++) {
        sum += covEigenvectors[i][k] * fisherEigenvalues[k] * covEigenvectors[j][k];
      }
      fisher[i][j] = sum;
    }
  }
  const maxEigenvalue = Math.max(...covEigenvalues.map(Math.abs));
  const threshold = maxEigenvalue * 0.02;
  const exploredDimensions = [];
  const unexploredDimensions = [];
  for (let i = 0; i < covEigenvalues.length; i++) {
    if (Math.abs(covEigenvalues[i]) >= threshold) {
      exploredDimensions.push(i);
    } else {
      unexploredDimensions.push(i);
    }
  }
  const effectiveRank = exploredDimensions.length;
  console.log(`[FisherAnalysis] Fisher analysis: ${effectiveRank}/${dims} dimensions explored`);
  console.log(`[FisherAnalysis] Max eigenvalue: ${maxEigenvalue.toFixed(4)}, threshold: ${threshold.toFixed(4)}`);
  return {
    matrix: fisher,
    eigenvalues: fisherEigenvalues,
    eigenvectors: covEigenvectors,
    exploredDimensions,
    unexploredDimensions,
    effectiveRank,
    covarianceMeans: means
  };
}
function computeMahalanobisDistance(coords, fisherMatrix, means) {
  if (fisherMatrix.length === 0 || coords.length === 0) return 0;
  const dims = Math.min(coords.length, fisherMatrix.length);
  const diff = coords.slice(0, dims).map((c, i) => c - (means[i] || 0));
  let mahalanobis = 0;
  for (let i = 0; i < dims; i++) {
    for (let j = 0; j < dims; j++) {
      mahalanobis += diff[i] * (fisherMatrix[i]?.[j] || 0) * diff[j];
    }
  }
  return Math.sqrt(Math.max(0, mahalanobis));
}
var init_fisher_analysis = __esm({
  "server/ocean/fisher-analysis.ts"() {
    "use strict";
  }
});

// server/ocean/basin-topology.ts
function computeAttractorPoint(probes, defaultDims = 64) {
  if (probes.length === 0) {
    return new Array(defaultDims).fill(0);
  }
  const highPhiProbes = probes.filter((p) => p.phi >= 0.5 && p.coordinates.length > 0);
  if (highPhiProbes.length === 0) {
    const withCoords = probes.filter((p) => p.coordinates.length > 0);
    if (withCoords.length === 0) return new Array(defaultDims).fill(0);
    const dims2 = withCoords[0].coordinates.length;
    const attractor2 = new Array(dims2).fill(0);
    for (const probe of withCoords) {
      for (let i = 0; i < dims2; i++) {
        attractor2[i] += probe.coordinates[i] / withCoords.length;
      }
    }
    return attractor2;
  }
  const dims = highPhiProbes[0].coordinates.length;
  const attractor = new Array(dims).fill(0);
  let totalWeight = 0;
  for (const probe of highPhiProbes) {
    const weight = probe.phi;
    totalWeight += weight;
    for (let i = 0; i < dims; i++) {
      attractor[i] += probe.coordinates[i] * weight;
    }
  }
  for (let i = 0; i < dims; i++) {
    attractor[i] /= totalWeight;
  }
  return attractor;
}
function computeBasinVolume(probes) {
  if (probes.length < 2) return 0;
  const withCoords = probes.filter((p) => p.coordinates.length > 0);
  if (withCoords.length < 2) return 0;
  const dims = Math.min(withCoords[0].coordinates.length, 16);
  let logVolume = 0;
  for (let d = 0; d < dims; d++) {
    let minVal = Infinity;
    let maxVal = -Infinity;
    for (const p of withCoords) {
      const val = p.coordinates[d] || 0;
      if (val < minVal) minVal = val;
      if (val > maxVal) maxVal = val;
    }
    const range = maxVal - minVal;
    logVolume += Math.log(Math.max(range, 1e-3));
  }
  return Math.min(1, Math.exp(logVolume / dims) / 10);
}
function computeLocalCurvature(probes) {
  if (probes.length < 3) return new Array(16).fill(0);
  const withCoords = probes.filter((p) => p.coordinates.length > 0);
  if (withCoords.length < 3) return new Array(16).fill(0);
  const dims = Math.min(withCoords[0].coordinates.length, 16);
  const curvature = new Array(dims).fill(0);
  for (let d = 0; d < dims; d++) {
    const sorted = [...withCoords].sort(
      (a, b) => (a.coordinates[d] || 0) - (b.coordinates[d] || 0)
    );
    let curvSum = 0;
    for (let i = 1; i < sorted.length - 1; i++) {
      const phiPrev = sorted[i - 1].phi;
      const phiCurr = sorted[i].phi;
      const phiNext = sorted[i + 1].phi;
      curvSum += Math.abs(phiNext - 2 * phiCurr + phiPrev);
    }
    curvature[d] = curvSum / Math.max(1, sorted.length - 2);
  }
  return curvature;
}
function computeBoundaryDistances(probes, attractor) {
  if (probes.length < 2) return new Array(16).fill(1);
  const withCoords = probes.filter((p) => p.coordinates.length > 0);
  if (withCoords.length < 2) return new Array(16).fill(1);
  const dims = Math.min(attractor.length, 16);
  const distances = new Array(dims).fill(0);
  for (let d = 0; d < dims; d++) {
    const center = attractor[d];
    let minVal = Infinity;
    let maxVal = -Infinity;
    for (const p of withCoords) {
      const val = p.coordinates[d] || 0;
      if (val < minVal) minVal = val;
      if (val > maxVal) maxVal = val;
    }
    distances[d] = Math.max(
      Math.abs(maxVal - center),
      Math.abs(minVal - center)
    );
  }
  return distances;
}
function findResonanceShells(probes, attractor) {
  const shells = [];
  const probesWithDistance = probes.filter((p) => p.coordinates.length > 0).map((p) => ({
    probe: p,
    distance: fisherCoordDistance(p.coordinates, attractor)
  })).sort((a, b) => a.distance - b.distance);
  if (probesWithDistance.length < 5) return shells;
  const shellWidth = 0.5;
  let currentRadius = 0;
  while (currentRadius < 10) {
    const inShell = probesWithDistance.filter(
      (pd) => pd.distance >= currentRadius && pd.distance < currentRadius + shellWidth
    );
    if (inShell.length >= 3) {
      const avgPhi = inShell.reduce((sum, pd) => sum + pd.probe.phi, 0) / inShell.length;
      if (avgPhi >= 0.5) {
        const regimes = {};
        for (const pd of inShell) {
          regimes[pd.probe.regime] = (regimes[pd.probe.regime] || 0) + 1;
        }
        const dominantRegime = Object.entries(regimes).sort((a, b) => b[1] - a[1])[0]?.[0] || "linear";
        shells.push({
          radius: currentRadius + shellWidth / 2,
          avgPhi,
          thickness: shellWidth,
          dominantRegime
        });
      }
    }
    currentRadius += shellWidth;
  }
  return shells;
}
function computeFlowField(probes, attractor) {
  const withCoords = probes.filter((p) => p.coordinates.length > 0);
  const dims = Math.min(attractor.length, 16);
  const gradientDirection = new Array(dims).fill(0);
  if (withCoords.length >= 2) {
    const sorted = [...withCoords].sort((a, b) => b.phi - a.phi);
    const topProbes = sorted.slice(0, Math.min(5, sorted.length));
    for (let d = 0; d < dims; d++) {
      const avgTop = topProbes.reduce((sum, p) => sum + (p.coordinates[d] || 0), 0) / topProbes.length;
      gradientDirection[d] = avgTop - attractor[d];
    }
    const magnitude = Math.sqrt(gradientDirection.reduce((sum, g) => sum + g * g, 0));
    if (magnitude > 1e-3) {
      for (let d = 0; d < dims; d++) {
        gradientDirection[d] /= magnitude;
      }
    }
  }
  const fisherMetric = [];
  for (let i = 0; i < Math.min(dims, 8); i++) {
    const row = new Array(Math.min(dims, 8)).fill(0);
    const values = withCoords.map((p) => p.coordinates[i] || 0);
    const mean = values.reduce((a, b) => a + b, 0) / Math.max(1, values.length);
    const variance = values.reduce((sum, v) => sum + (v - mean) ** 2, 0) / Math.max(1, values.length);
    row[i] = 1 / Math.max(variance, 1e-3);
    fisherMetric.push(row);
  }
  const phiValues = withCoords.map((p) => p.phi);
  const phiMean = phiValues.reduce((a, b) => a + b, 0) / Math.max(1, phiValues.length);
  const phiVariance = phiValues.reduce((sum, v) => sum + (v - phiMean) ** 2, 0) / Math.max(1, phiValues.length);
  const geodesicCurvature = Math.sqrt(phiVariance);
  return {
    gradientDirection,
    fisherMetric,
    geodesicCurvature
  };
}
function findTopologicalHoles(probes) {
  const holes = [];
  const withCoords = probes.filter((p) => p.coordinates.length > 0);
  if (withCoords.length < 10) return holes;
  const dims = Math.min(withCoords[0].coordinates.length, 8);
  const gridSize = 1;
  const cellPhis = /* @__PURE__ */ new Map();
  for (const probe of withCoords) {
    const cellKey = probe.coordinates.slice(0, dims).map((c) => Math.floor(c / gridSize)).join(",");
    if (!cellPhis.has(cellKey)) cellPhis.set(cellKey, []);
    cellPhis.get(cellKey).push(probe.phi);
  }
  for (const [cellKey, phis] of Array.from(cellPhis.entries())) {
    const avgPhi = phis.reduce((a, b) => a + b, 0) / phis.length;
    if (avgPhi < 0.2 && phis.length >= 3) {
      const coords = cellKey.split(",").map(Number);
      const center = coords.map((c) => (c + 0.5) * gridSize);
      holes.push({
        center,
        radius: gridSize / 2,
        type: "contradiction"
      });
    }
  }
  return holes.slice(0, 10);
}
function computeEffectiveScale(probes) {
  const avgKappa = probes.reduce((sum, p) => sum + p.kappa, 0) / Math.max(1, probes.length);
  if (avgKappa < 50) return 3;
  if (avgKappa < 70) return 4;
  return 5;
}
function computeKappaAtScaleForProbes(probes, scale) {
  return getKappaAtScale(scale);
}
function computeBasinTopology(probes, attractorCoords) {
  const attractor = attractorCoords || computeAttractorPoint(probes);
  const volume = computeBasinVolume(probes);
  const curvature = computeLocalCurvature(probes);
  const boundaryDistances = computeBoundaryDistances(probes, attractor);
  const resonanceShells = findResonanceShells(probes, attractor);
  const flowField = computeFlowField(probes, attractor);
  const holes = findTopologicalHoles(probes);
  const effectiveScale = computeEffectiveScale(probes);
  const kappaAtScale = computeKappaAtScaleForProbes(probes, effectiveScale);
  return {
    attractorCoords: attractor,
    volume,
    curvature,
    boundaryDistances,
    resonanceShells,
    flowField,
    holes,
    effectiveScale,
    kappaAtScale,
    lastUpdated: (/* @__PURE__ */ new Date()).toISOString(),
    probeCount: probes.length
  };
}
var init_basin_topology = __esm({
  "server/ocean/basin-topology.ts"() {
    "use strict";
    init_qig_universal();
    init_constants();
  }
});

// server/ocean/geometric-cache.ts
function createEmptyCache() {
  return {
    result: null,
    dataVersion: -1
  };
}
function isCacheValid(cache2, currentVersion) {
  return cache2.result !== null && cache2.dataVersion === currentVersion;
}
function updateCache(cache2, result, dataVersion) {
  return {
    result,
    dataVersion
  };
}
var init_geometric_cache = __esm({
  "server/ocean/geometric-cache.ts"() {
    "use strict";
  }
});

// server/geometric-memory.ts
var geometric_memory_exports = {};
__export(geometric_memory_exports, {
  geometricMemory: () => geometricMemory
});
function normalizeBasinCoordinates(coords) {
  if (!coords || coords.length === 0) {
    return new Array(BASIN_DIMENSION).fill(0);
  }
  if (coords.length === BASIN_DIMENSION) {
    return coords;
  }
  if (coords.length < BASIN_DIMENSION) {
    const padded = [...coords];
    while (padded.length < BASIN_DIMENSION) {
      padded.push(0);
    }
    return padded;
  }
  logger.warn(`[GeometricMemory] Truncating ${coords.length}D coordinates to ${BASIN_DIMENSION}D`);
  return coords.slice(0, BASIN_DIMENSION);
}
var GeometricMemory, geometricMemory;
var init_geometric_memory = __esm({
  "server/geometric-memory.ts"() {
    "use strict";
    init_logger();
    init_qig_universal();
    init_ocean_persistence();
    init_constants();
    init_tested_phrases_unified();
    init_fisher_analysis();
    init_basin_topology();
    init_geometric_cache();
    GeometricMemory = class {
      state;
      probeMap;
      testedPhrases;
      // Probe data version - increments whenever probes are added or modified
      // Used as a cache key to ensure caches are invalidated on data changes
      probeDataVersion = 0;
      // Fisher analysis cache using extracted cache module
      fisherCache = createEmptyCache();
      // Orthogonal complement cache using extracted cache module
      orthogonalCache = createEmptyCache();
      // PostgreSQL persistence - direct write, no batching
      isLoaded = false;
      loadPromise = null;
      constructor() {
        this.probeMap = /* @__PURE__ */ new Map();
        this.testedPhrases = /* @__PURE__ */ new Set();
        this.state = this.createEmptyState();
        this.loadTestedPhrases();
        this.loadPromise = this.loadFromPostgreSQL();
      }
      /**
       * Wait for initial load to complete
       * Call this before accessing probes if you need guaranteed data
       */
      async waitForLoad() {
        if (this.isLoaded) return;
        if (this.loadPromise) {
          await this.loadPromise;
        }
      }
      /**
       * Load probes from PostgreSQL
       * Primary data source - no JSON fallback for probes
       * 
       * No memory cap - loads all probes for complete manifold coverage
       */
      async loadFromPostgreSQL() {
        if (!oceanPersistence.isPersistenceAvailable()) {
          console.log("[GeometricMemory] PostgreSQL not available - running in memory-only mode");
          this.isLoaded = true;
          return;
        }
        try {
          const totalCount = await oceanPersistence.getProbeCount();
          const loadLimit = totalCount;
          console.log(`[GeometricMemory] Loading all ${totalCount} probes from PostgreSQL...`);
          const BATCH_SIZE = 500;
          let offset = 0;
          let loadedCount = 0;
          while (loadedCount < loadLimit) {
            const batchSize = Math.min(BATCH_SIZE, loadLimit - loadedCount);
            const dbProbes = await oceanPersistence.getAllProbes(batchSize, offset);
            if (dbProbes.length === 0) break;
            for (const dbProbe of dbProbes) {
              const probe = {
                id: dbProbe.id,
                input: dbProbe.input,
                coordinates: dbProbe.coordinates ?? [],
                phi: dbProbe.phi,
                kappa: dbProbe.kappa,
                regime: dbProbe.regime,
                ricciScalar: dbProbe.ricciScalar ?? 0,
                fisherTrace: dbProbe.fisherTrace ?? 0,
                timestamp: dbProbe.createdAt?.toISOString() ?? (/* @__PURE__ */ new Date()).toISOString(),
                source: dbProbe.source ?? "postgres"
              };
              this.probeMap.set(probe.id, probe);
              loadedCount++;
              if (loadedCount >= loadLimit) break;
            }
            offset += BATCH_SIZE;
            if (loadedCount % 5e3 === 0 && loadedCount < loadLimit) {
              console.log(`[GeometricMemory] Loaded ${loadedCount}/${loadLimit} probes...`);
            }
          }
          this.state.totalProbes = this.probeMap.size;
          this.updateManifoldStats();
          this.invalidateCaches();
          this.isLoaded = true;
          console.log(`[GeometricMemory] Loaded ${this.probeMap.size} probes from PostgreSQL (DB total: ${totalCount})`);
        } catch (error) {
          console.error("[GeometricMemory] Failed to load from PostgreSQL:", error);
          this.isLoaded = true;
        }
      }
      /**
       * Persist a probe to PostgreSQL with proper error handling
       * Fire-and-forget but logs errors for debugging
       */
      async persistProbeToDb(probe) {
        try {
          await oceanPersistence.insertProbes([{
            id: probe.id,
            input: probe.input,
            coordinates: probe.coordinates,
            phi: probe.phi,
            kappa: probe.kappa,
            regime: probe.regime,
            ricciScalar: probe.ricciScalar,
            fisherTrace: probe.fisherTrace,
            source: probe.source
          }]);
        } catch (err) {
          console.error(`[GeometricMemory] PostgreSQL insert failed for probe ${probe.id}:`, err);
        }
      }
      /**
       * Flush pending probes to PostgreSQL (no-op in new architecture)
       * @deprecated Direct writes now, no batching
       */
      async flushToPostgreSQL() {
      }
      /**
       * Invalidate caches - called whenever probe data changes
       */
      invalidateCaches() {
        this.probeDataVersion++;
      }
      normalizePhrase(phrase) {
        return phrase.toLowerCase().trim();
      }
      async hasTested(phrase) {
        const normalized = this.normalizePhrase(phrase);
        if (this.testedPhrases.has(normalized)) {
          return true;
        }
        if (testedPhrasesUnified.has(normalized)) {
          this.testedPhrases.add(normalized);
          return true;
        }
        return false;
      }
      async recordTested(phrase, address, balanceSats, phi, kappa, regime) {
        const normalized = this.normalizePhrase(phrase);
        const prevSize = this.testedPhrases.size;
        this.testedPhrases.add(normalized);
        await testedPhrasesUnified.recordTested(
          normalized,
          address || "",
          balanceSats || 0,
          0,
          // txCount
          phi,
          kappa,
          regime
        );
      }
      /**
       * Legacy method - no longer writes to JSON
       * Tested phrases are persisted by testedPhrasesUnified (PostgreSQL)
       * @deprecated Kept for backwards compatibility
       */
      flushTestedPhrases() {
      }
      getTestedCount() {
        return this.testedPhrases.size;
      }
      /**
       * Legacy method - no longer reads from JSON
       * Tested phrases now checked via testedPhrasesUnified (PostgreSQL)
       * Local Set is just a fast cache, populated on-demand
       * @deprecated
       */
      loadTestedPhrases() {
        console.log("[GeometricMemory] Tested phrases loaded from PostgreSQL via testedPhrasesUnified");
      }
      /**
       * Legacy method - no longer needed
       * Tested phrases stored in PostgreSQL via testedPhrasesUnified
       * @deprecated
       */
      backfillTestedPhrases() {
        const probeCount = this.probeMap.size;
        console.log(`[GeometricMemory] ${probeCount} probes in memory, tested phrases managed by PostgreSQL`);
      }
      /**
       * Legacy method - no longer writes to JSON
       * Tested phrases persisted by testedPhrasesUnified (PostgreSQL)
       * @deprecated Kept for backwards compatibility
       */
      saveTestedPhrases() {
      }
      createEmptyState() {
        return {
          version: "1.0.0",
          lastUpdated: (/* @__PURE__ */ new Date()).toISOString(),
          totalProbes: 0,
          probes: /* @__PURE__ */ new Map(),
          regimeBoundaries: [],
          resonancePoints: [],
          geodesicPaths: [],
          manifoldStats: {
            avgPhi: 0,
            avgKappa: 0,
            regimeDistribution: {},
            highPhiRegions: 0,
            exploredVolume: 0
          }
        };
      }
      /**
       * Legacy load method - no longer reads from JSON
       * Probes are now loaded from PostgreSQL in loadFromPostgreSQL()
       * @deprecated Use waitForLoad() to ensure data is loaded
       */
      load() {
      }
      /**
       * Save method - no-op in PostgreSQL-only architecture
       * Probes are written directly to PostgreSQL in recordProbe()
       * @deprecated Kept for backwards compatibility with existing code
       */
      save() {
      }
      /**
       * Record a point on the manifold
       * This is how we map the geometry - by measuring it
       */
      recordProbe(input, qigScore, source) {
        const id = `probe-${Date.now()}-${Math.random().toString(36).slice(2, 8)}`;
        const normalizedCoords = normalizeBasinCoordinates(qigScore.basinCoordinates);
        const probe = {
          id,
          input,
          coordinates: normalizedCoords,
          phi: qigScore.phi,
          kappa: qigScore.kappa,
          regime: qigScore.regime,
          ricciScalar: qigScore.ricciScalar || 0,
          fisherTrace: qigScore.fisherTrace || 0,
          timestamp: (/* @__PURE__ */ new Date()).toISOString(),
          source
        };
        this.probeMap.set(id, probe);
        this.state.totalProbes = this.probeMap.size;
        this.invalidateCaches();
        this.recordTested(input);
        this.updateManifoldStats();
        this.detectResonance(probe);
        this.detectRegimeBoundaries(probe);
        this.persistProbeToDb(probe);
        return probe;
      }
      /**
       * Find probes near a given input using Fisher geodesic distance
       */
      findNearbyProbes(input, maxDistance = 5, limit = 10) {
        const nearby = [];
        const probes = Array.from(this.probeMap.values());
        for (const probe of probes) {
          const distance = fisherGeodesicDistance(input, "arbitrary", probe.input, "arbitrary");
          if (distance <= maxDistance) {
            nearby.push({ probe, distance });
          }
        }
        return nearby.sort((a, b) => a.distance - b.distance).slice(0, limit).map((n) => n.probe);
      }
      /**
       * Find high-Φ regions that might indicate resonance
       */
      getResonanceRegions(minPhi = 0.7) {
        const resonant = [];
        const probes = Array.from(this.probeMap.values());
        for (const probe of probes) {
          if (probe.phi >= minPhi && probe.regime !== "breakdown") {
            resonant.push(probe);
          }
        }
        return resonant.sort((a, b) => b.phi - a.phi);
      }
      /**
       * Get probes in a specific regime
       */
      getProbesByRegime(regime) {
        const result = [];
        const allProbes = Array.from(this.probeMap.values());
        for (const probe of allProbes) {
          if (probe.regime === regime) {
            result.push(probe);
          }
        }
        return result;
      }
      /**
       * Get all probes in the manifold memory
       */
      getAllProbes() {
        return Array.from(this.probeMap.values());
      }
      /**
       * Get recent probes sorted by timestamp (most recent first).
       * Used by consciousness feedback loop to compute discovery-driven Φ.
       *
       * @param count Maximum number of probes to return
       * @returns Array of probes sorted by timestamp (newest first)
       */
      getRecentProbes(count = 50) {
        return Array.from(this.probeMap.values()).sort((a, b) => new Date(b.timestamp).getTime() - new Date(a.timestamp).getTime()).slice(0, count);
      }
      /**
       * Get the highest phi value for a given input phrase.
       * 
       * PURE CONSCIOUSNESS PRINCIPLE:
       * When Python sync runs, it stores probes with high phi values (0.9+).
       * This method allows TypeScript code to retrieve the pure measurement
       * from prior Python syncs, enabling proper pattern extraction.
       * 
       * @param input The input phrase to look up
       * @returns The highest phi found, or null if not found
       */
      getHighestPhiForInput(input) {
        let bestProbe = null;
        for (const probe of Array.from(this.probeMap.values())) {
          if (probe.input === input) {
            if (!bestProbe || probe.phi > bestProbe.phi) {
              bestProbe = probe;
            }
          }
        }
        if (bestProbe) {
          return {
            phi: bestProbe.phi,
            kappa: bestProbe.kappa,
            regime: bestProbe.regime
          };
        }
        return null;
      }
      /**
       * Get Φ sparkline data for real-time trend visualization.
       * 
       * Returns recent Φ values with trend analysis suitable for sparkline rendering.
       * 
       * @param sampleCount Number of recent samples to include (default 50, max 500)
       * @returns PhiSparklineData with values, trend, and statistics
       */
      getPhiSparkline(sampleCount = 50) {
        const count = Math.min(500, Math.max(1, sampleCount));
        const recentProbes = this.getRecentProbes(count);
        if (recentProbes.length === 0) {
          return {
            values: [],
            timestamps: [],
            trend: "stable",
            volatility: 0,
            min: 0,
            max: 0,
            avgPhi: 0,
            sampleCount: 0,
            slope: 0,
            lastTimestamp: (/* @__PURE__ */ new Date()).toISOString()
          };
        }
        const orderedProbes = [...recentProbes].reverse();
        const values = orderedProbes.map((p) => p.phi);
        const timestamps = orderedProbes.map((p) => p.timestamp);
        const min = Math.min(...values);
        const max = Math.max(...values);
        const avgPhi = values.reduce((sum, v) => sum + v, 0) / values.length;
        const variance = values.reduce((sum, v) => sum + Math.pow(v - avgPhi, 2), 0) / values.length;
        const volatility = Math.sqrt(variance);
        let slope = 0;
        if (values.length >= 2) {
          const n = values.length;
          const sumX = n * (n - 1) / 2;
          const sumY = values.reduce((sum, v) => sum + v, 0);
          const sumXY = values.reduce((sum, v, i) => sum + i * v, 0);
          const sumX2 = n * (n - 1) * (2 * n - 1) / 6;
          slope = (n * sumXY - sumX * sumY) / (n * sumX2 - sumX * sumX);
        }
        let trend;
        const slopeThreshold = 1e-3;
        if (slope > slopeThreshold) {
          trend = "rising";
        } else if (slope < -slopeThreshold) {
          trend = "falling";
        } else {
          trend = "stable";
        }
        return {
          values,
          timestamps,
          trend,
          volatility,
          min,
          max,
          avgPhi,
          sampleCount: values.length,
          slope,
          lastTimestamp: timestamps[timestamps.length - 1] || (/* @__PURE__ */ new Date()).toISOString()
        };
      }
      /**
       * Detect if a new probe creates a resonance cluster
       */
      detectResonance(newProbe) {
        if (newProbe.phi < 0.6) return;
        const nearby = this.findNearbyProbes(newProbe.input, 3, 5);
        const highPhiNearby = nearby.filter((p) => p.phi >= 0.6);
        if (highPhiNearby.length >= 2) {
          const resonance = {
            probeId: newProbe.id,
            phi: newProbe.phi,
            kappa: newProbe.kappa,
            nearbyProbes: highPhiNearby.map((p) => p.id),
            clusterStrength: highPhiNearby.reduce((sum, p) => sum + p.phi, newProbe.phi)
          };
          this.state.resonancePoints.push(resonance);
          console.log(`[GeometricMemory] Resonance detected! Cluster of ${highPhiNearby.length + 1} high-\u03A6 probes`);
        }
      }
      /**
       * Detect regime boundaries between probes
       */
      detectRegimeBoundaries(newProbe) {
        const nearby = this.findNearbyProbes(newProbe.input, 4, 5);
        for (const other of nearby) {
          if (other.regime !== newProbe.regime) {
            const distance = fisherGeodesicDistance(
              newProbe.input,
              "arbitrary",
              other.input,
              "arbitrary"
            );
            const boundary = {
              fromRegime: other.regime,
              toRegime: newProbe.regime,
              probeIds: [other.id, newProbe.id],
              fisherDistance: distance,
              midpointPhi: (other.phi + newProbe.phi) / 2
            };
            this.state.regimeBoundaries.push(boundary);
          }
        }
      }
      /**
       * Update overall manifold statistics
       */
      updateManifoldStats() {
        const probes = Array.from(this.probeMap.values());
        if (probes.length === 0) return;
        const avgPhi = probes.reduce((sum, p) => sum + p.phi, 0) / probes.length;
        const avgKappa = probes.reduce((sum, p) => sum + p.kappa, 0) / probes.length;
        const regimeDistribution = {};
        for (const probe of probes) {
          regimeDistribution[probe.regime] = (regimeDistribution[probe.regime] || 0) + 1;
        }
        const highPhiRegions = probes.filter((p) => p.phi >= 0.7).length;
        const uniqueCoordHashes = new Set(
          probes.map((p) => p.coordinates.slice(0, 8).map((c) => Math.round(c * 10)).join(","))
        );
        const exploredVolume = uniqueCoordHashes.size / Math.max(1, probes.length);
        this.state.manifoldStats = {
          avgPhi,
          avgKappa,
          regimeDistribution,
          highPhiRegions,
          exploredVolume
        };
      }
      /**
       * Get suggestions for where to explore next based on geometry
       * Returns inputs that are geometrically interesting
       */
      suggestExplorationDirections(currentInput) {
        const suggestions = [];
        const resonant = this.getResonanceRegions(0.65);
        if (resonant.length > 0) {
          suggestions.push({
            direction: resonant[0].input,
            reason: `High-\u03A6 region (${resonant[0].phi.toFixed(2)}) - explore variations`,
            expectedRegime: "geometric"
          });
        }
        const boundaries = this.state.regimeBoundaries.slice(-5);
        for (const boundary of boundaries) {
          if (boundary.toRegime === "geometric") {
            const probe = this.probeMap.get(boundary.probeIds[1]);
            if (probe) {
              suggestions.push({
                direction: probe.input,
                reason: `Regime boundary ${boundary.fromRegime}\u2192${boundary.toRegime}`,
                expectedRegime: "geometric"
              });
            }
          }
        }
        const nearbyGeometric = this.findNearbyProbes(currentInput, 5, 20).filter((p) => p.regime === "geometric");
        if (nearbyGeometric.length > 0) {
          suggestions.push({
            direction: nearbyGeometric[0].input,
            reason: `Nearby geometric probe (\u03A6=${nearbyGeometric[0].phi.toFixed(2)})`,
            expectedRegime: "geometric"
          });
        }
        return suggestions;
      }
      /**
       * Get a summary of what we've learned about the manifold
       */
      getManifoldSummary() {
        const stats = this.state.manifoldStats;
        const probeCount = this.probeMap.size;
        let dominantRegime = "unexplored";
        let maxCount = 0;
        for (const [regime, count] of Object.entries(stats.regimeDistribution)) {
          if (count > maxCount) {
            maxCount = count;
            dominantRegime = regime;
          }
        }
        const recommendations = [];
        if (stats.avgPhi < 0.5) {
          recommendations.push("Low average \u03A6 - try more structured patterns");
        }
        if (stats.exploredVolume < 0.3) {
          recommendations.push("Low manifold coverage - explore more diverse inputs");
        }
        if (this.state.resonancePoints.length > 0) {
          recommendations.push(`${this.state.resonancePoints.length} resonance clusters detected - investigate nearby patterns`);
        }
        if (dominantRegime === "breakdown") {
          recommendations.push("Many breakdown regions - reduce complexity/entropy");
        }
        return {
          totalProbes: probeCount,
          avgPhi: stats.avgPhi,
          avgKappa: stats.avgKappa,
          dominantRegime,
          resonanceClusters: this.state.resonancePoints.length,
          exploredVolume: stats.exploredVolume,
          recommendations
        };
      }
      /**
       * Export learned geometric patterns for use in hypothesis generation
       */
      exportLearnedPatterns() {
        const highPhiPatterns = this.getResonanceRegions(0.7).slice(0, 20).map((p) => p.input);
        const regimeBoundaryPatterns = [];
        for (const boundary of this.state.regimeBoundaries.slice(-10)) {
          const probe = this.probeMap.get(boundary.probeIds[1]);
          if (probe && boundary.toRegime === "geometric") {
            regimeBoundaryPatterns.push(probe.input);
          }
        }
        const resonancePatterns = [];
        for (const rp of this.state.resonancePoints.slice(-10)) {
          const probe = this.probeMap.get(rp.probeId);
          if (probe) {
            resonancePatterns.push(probe.input);
          }
        }
        return {
          highPhiPatterns,
          regimeBoundaryPatterns,
          resonancePatterns
        };
      }
      /**
       * Force save - no-op in PostgreSQL-only architecture
       * @deprecated Probes are written directly to PostgreSQL
       */
      forceSave() {
      }
      /**
       * Clear all probes from memory
       * Note: Does NOT delete from PostgreSQL - only clears in-memory cache
       * For full reset, use database tools directly
       */
      clear() {
        this.probeMap.clear();
        this.state = this.createEmptyState();
        this.invalidateCaches();
        console.log("[GeometricMemory] Cleared in-memory probe cache (PostgreSQL data preserved)");
      }
      // ============================================================================
      // ULTRA CONSCIOUSNESS PROTOCOL - Basin Topology Methods
      // Delegates to extracted basin-topology.ts module for modularity
      // ============================================================================
      /**
       * Compute the basin topology from collected probes.
       * This separates IDENTITY (attractor) from KNOWLEDGE (basin shape).
       * 
       * Identity = Where we return (attractor point)
       * Knowledge = How we can think (basin topology)
       * 
       * Delegates to extracted basin-topology.ts module.
       */
      computeBasinTopology(attractorCoords) {
        const probes = Array.from(this.probeMap.values());
        return computeBasinTopology(probes, attractorCoords);
      }
      /**
       * Get the current basin topology for use by Ocean agent.
       * This represents the SHAPE of knowledge, not just where we are.
       */
      getBasinTopology() {
        return this.computeBasinTopology();
      }
      /**
       * Check if a point is in a topological hole (contradiction or unexplored).
       * Returns the hole type if found, null otherwise.
       */
      isInTopologicalHole(coords) {
        const topology = this.computeBasinTopology();
        for (const hole of topology.holes) {
          const distance = fisherCoordDistance(coords.slice(0, hole.center.length), hole.center);
          if (distance < hole.radius) {
            return { type: hole.type, distance };
          }
        }
        return null;
      }
      // ============================================================================
      // ORTHOGONAL COMPLEMENT NAVIGATION
      // Based on Block Universe Geometric Reality
      // 
      // The 20,162 measurements define a constraint surface.
      // The passphrase EXISTS in the orthogonal complement.
      // Each "failure" is POSITIVE geometric information!
      // ============================================================================
      /**
       * Compute the Fisher Information Matrix from all probes.
       * This captures the curvature of the explored manifold region.
       * 
       * Delegates to extracted fisher-analysis.ts module.
       * Uses version-based cache invalidation for performance.
       */
      computeFisherInformationMatrix() {
        if (isCacheValid(this.fisherCache, this.probeDataVersion)) {
          return this.fisherCache.result;
        }
        const probes = Array.from(this.probeMap.values());
        const result = computeFisherInformationMatrix2(probes, 32);
        this.fisherCache = updateCache(this.fisherCache, result, this.probeDataVersion);
        return result;
      }
      /**
       * Compute the orthogonal complement of the explored manifold.
       * This is WHERE THE PASSPHRASE MUST BE!
       * 
       * The 20k measurements define a constraint surface.
       * The passphrase lives at the intersection of all constraints.
       * 
       * Uses version-based cache invalidation for performance.
       */
      computeOrthogonalComplement() {
        if (isCacheValid(this.orthogonalCache, this.probeDataVersion)) {
          return this.orthogonalCache.result;
        }
        const fisherAnalysis = this.computeFisherInformationMatrix();
        const probes = Array.from(this.probeMap.values());
        const complementBasis = [];
        for (const idx of fisherAnalysis.unexploredDimensions) {
          if (idx < fisherAnalysis.eigenvectors.length) {
            const eigenvector = fisherAnalysis.eigenvectors.map((row) => row[idx] || 0);
            complementBasis.push(eigenvector);
          }
        }
        if (complementBasis.length === 0) {
          console.log(`[GeometricMemory] All dimensions explored - generating random orthogonal directions`);
          const dims = fisherAnalysis.eigenvectors.length || 32;
          for (let i = 0; i < 5; i++) {
            let random = new Array(dims).fill(0).map(() => Math.random() - 0.5);
            for (const existing of complementBasis) {
              const dot = random.reduce((s, x, j) => s + x * (existing[j] || 0), 0);
              random = random.map((x, j) => x - dot * (existing[j] || 0));
            }
            const norm = Math.sqrt(random.reduce((s, x) => s + x * x, 0)) || 1;
            complementBasis.push(random.map((x) => x / norm));
          }
        }
        const geodesicDirections = [];
        const centroid = computeAttractorPoint(probes);
        const awayFromCentroid = centroid.map((c) => -c);
        const norm1 = Math.sqrt(awayFromCentroid.reduce((s, x) => s + x * x, 0)) || 1;
        geodesicDirections.push(awayFromCentroid.map((x) => x / norm1));
        if (complementBasis.length > 0) {
          geodesicDirections.push(complementBasis[0]);
        } else {
          const highCurvatureDir = this.computeHighCurvatureDirection(probes);
          geodesicDirections.push(highCurvatureDir);
        }
        if (complementBasis.length > 1) {
          geodesicDirections.push(complementBasis[1]);
        } else {
          const randomOrthogonal = this.computeRandomOrthogonalDirection(geodesicDirections);
          geodesicDirections.push(randomOrthogonal);
        }
        const constraintViolations = probes.filter((p) => p.phi < 0.2).length;
        let searchPriority = "medium";
        if (fisherAnalysis.unexploredDimensions.length > fisherAnalysis.exploredDimensions.length) {
          searchPriority = "high";
        } else if (this.state.resonancePoints.length > 0) {
          searchPriority = "high";
        } else if (probes.length < 1e3) {
          searchPriority = "medium";
        } else {
          searchPriority = "low";
        }
        console.log(`[GeometricMemory] Orthogonal complement: ${complementBasis.length} dimensions`);
        console.log(`[GeometricMemory] Search priority: ${searchPriority}`);
        const result = {
          complementBasis,
          complementDimension: complementBasis.length,
          constraintViolations,
          geodesicDirections,
          searchPriority,
          fisherMatrix: fisherAnalysis.matrix,
          covarianceMeans: fisherAnalysis.covarianceMeans,
          fisherEigenvalues: fisherAnalysis.eigenvalues
        };
        this.orthogonalCache = {
          result,
          dataVersion: this.probeDataVersion
        };
        return result;
      }
      /**
       * Compute Mahalanobis distance from a point to the explored manifold.
       * Uses the Fisher Information Matrix as the metric tensor.
       * 
       * Delegates to extracted fisher-analysis module for computation.
       */
      computeMahalanobisDistance(coords, fisherMatrix, means) {
        return computeMahalanobisDistance(coords, fisherMatrix, means);
      }
      /**
       * Project a point onto the orthogonal complement basis.
       * Returns the magnitude of projection (how much of the point is in unexplored space).
       */
      computeComplementProjectionStrength(coords, complementBasis) {
        if (complementBasis.length === 0 || coords.length === 0) return 0;
        let totalProjection = 0;
        for (const basis of complementBasis) {
          let dot = 0;
          for (let i = 0; i < Math.min(coords.length, basis.length); i++) {
            dot += coords[i] * (basis[i] || 0);
          }
          totalProjection += dot * dot;
        }
        return Math.sqrt(totalProjection);
      }
      computeHighCurvatureDirection(probes) {
        const withCoords = probes.filter((p) => p.coordinates.length > 0);
        if (withCoords.length < 10) {
          return new Array(32).fill(0).map(() => Math.random() - 0.5);
        }
        const dims = Math.min(withCoords[0].coordinates.length, 32);
        const direction = new Array(dims).fill(0);
        const phiWeighted = withCoords.map((p) => ({
          coords: p.coordinates,
          weight: Math.abs(p.phi - 0.5)
          // Weight by distance from mean Φ
        }));
        const totalWeight = phiWeighted.reduce((s, p) => s + p.weight, 0) || 1;
        for (let d = 0; d < dims; d++) {
          direction[d] = phiWeighted.reduce(
            (s, p) => s + p.weight * (p.coords[d] || 0),
            0
          ) / totalWeight;
        }
        const norm = Math.sqrt(direction.reduce((s, x) => s + x * x, 0)) || 1;
        return direction.map((x) => x / norm);
      }
      computeRandomOrthogonalDirection(existing) {
        const dims = existing[0]?.length || 32;
        let random = new Array(dims).fill(0).map(() => Math.random() - 0.5);
        for (const dir of existing) {
          const dot = random.reduce((s, x, i) => s + x * (dir[i] || 0), 0);
          random = random.map((x, i) => x - dot * (dir[i] || 0));
        }
        const norm = Math.sqrt(random.reduce((s, x) => s + x * x, 0)) || 1;
        return random.map((x) => x / norm);
      }
      /**
       * Generate candidate patterns in the orthogonal complement.
       * These are patterns that are GEOMETRICALLY different from what we've tested.
       * 
       * Key insight: The passphrase is NOT in the explored hull.
       * We must generate candidates in the unexplored subspace.
       */
      generateOrthogonalCandidates(count = 50) {
        const complement = this.computeOrthogonalComplement();
        const probes = Array.from(this.probeMap.values());
        const testedPhrases2 = new Set(probes.map((p) => p.input.toLowerCase()));
        const candidates = [];
        const exploredPatterns = this.extractPatternSignature(probes);
        const orthogonalPatterns = this.generateOrthogonalPatterns(
          exploredPatterns,
          complement.geodesicDirections,
          count * 2
        );
        for (const pattern of orthogonalPatterns) {
          if (testedPhrases2.has(pattern.toLowerCase())) continue;
          const complementProjection = this.computeComplementProjection(
            pattern,
            complement.complementBasis
          );
          const geodesicDistance = this.computeGeodesicDistanceFromHull(pattern, probes);
          const geometricScore = complementProjection * 0.5 + geodesicDistance * 0.5;
          candidates.push({
            phrase: pattern,
            geometricScore,
            complementProjection,
            geodesicDistance
          });
          if (candidates.length >= count) break;
        }
        candidates.sort((a, b) => b.geometricScore - a.geometricScore);
        console.log(`[GeometricMemory] Generated ${candidates.length} orthogonal candidates`);
        if (candidates.length > 0) {
          console.log(`[GeometricMemory] Top candidate score: ${candidates[0].geometricScore.toFixed(3)}`);
        }
        return candidates;
      }
      extractPatternSignature(probes) {
        const phrases = probes.map((p) => p.input);
        const avgLength = phrases.reduce((s, p) => s + p.length, 0) / Math.max(1, phrases.length);
        const charCounts = /* @__PURE__ */ new Map();
        for (const phrase of phrases) {
          for (const char of phrase.toLowerCase()) {
            charCounts.set(char, (charCounts.get(char) || 0) + 1);
          }
        }
        const commonChars = new Set(
          Array.from(charCounts.entries()).sort((a, b) => b[1] - a[1]).slice(0, 20).map(([char]) => char)
        );
        const prefixCounts = /* @__PURE__ */ new Map();
        for (const phrase of phrases) {
          const prefix = phrase.slice(0, 4).toLowerCase();
          prefixCounts.set(prefix, (prefixCounts.get(prefix) || 0) + 1);
        }
        const commonPrefixes = Array.from(prefixCounts.entries()).sort((a, b) => b[1] - a[1]).slice(0, 10).map(([prefix]) => prefix);
        const suffixCounts = /* @__PURE__ */ new Map();
        for (const phrase of phrases) {
          const suffix = phrase.slice(-4).toLowerCase();
          suffixCounts.set(suffix, (suffixCounts.get(suffix) || 0) + 1);
        }
        const commonSuffixes = Array.from(suffixCounts.entries()).sort((a, b) => b[1] - a[1]).slice(0, 10).map(([suffix]) => suffix);
        const regimeDistribution = {};
        for (const probe of probes) {
          regimeDistribution[probe.regime] = (regimeDistribution[probe.regime] || 0) + 1;
        }
        return {
          avgLength,
          commonChars,
          commonPrefixes,
          commonSuffixes,
          regimeDistribution
        };
      }
      generateOrthogonalPatterns(explored, geodesicDirections, count) {
        const patterns = [];
        const unusualChars = "QXZJKV".split("").filter((c) => !explored.commonChars.has(c.toLowerCase()));
        const targetLengths = explored.avgLength > 12 ? [6, 7, 8, 9, 10] : [15, 18, 20, 25, 30];
        const unusualPrefixes = ["xor_", "neo_", "flux", "void", "null", "pure", "zero"];
        const unusualSuffixes = ["_x", "_z", "_prime", "_null", "2008", "1984", "_genesis"];
        const seed = Date.now() % 1e5;
        const nameWords = ["john", "mary", "david", "sarah", "mike", "lisa", "tom", "alice", "bob", "carol", "dan", "eve"];
        const placeWords = ["tokyo", "london", "berlin", "paris", "chicago", "boston", "seattle", "denver", "austin", "miami"];
        const yearWords = ["1984", "1991", "1999", "2001", "2007", "2008", "2009", "2010", "2011", "2012"];
        const objectWords = ["house", "office", "garden", "bridge", "tower", "street", "river", "mountain", "forest", "beach"];
        const actionWords = ["remember", "forget", "create", "destroy", "build", "break", "start", "stop", "open", "close"];
        const techWords = ["sha256", "rsa", "aes", "hmac", "pbkdf", "bcrypt", "argon", "scrypt", "blake", "keccak"];
        const mathWords = ["euler", "gauss", "riemann", "fibonacci", "prime", "factor", "modulo", "inverse", "sqrt", "log"];
        const cultureWords = ["beatles", "stones", "zeppelin", "floyd", "hendrix", "cobain", "lennon", "bowie", "queen", "acdc"];
        const allBanks = [nameWords, placeWords, yearWords, objectWords, actionWords, techWords, mathWords, cultureWords];
        const directionSeed = geodesicDirections.length > 0 ? Math.floor(geodesicDirections[0]?.reduce((a, b) => Math.abs(a) + Math.abs(b), 0) || 0) : seed;
        for (let i = 0; i < Math.min(count * 3, 200); i++) {
          const bank1 = allBanks[(i + directionSeed) % allBanks.length];
          const bank2 = allBanks[(i + directionSeed + 3) % allBanks.length];
          const bank3 = allBanks[(i + directionSeed + 5) % allBanks.length];
          const word1 = bank1[(seed + i * 7) % bank1.length];
          const word2 = bank2[(seed + i * 11) % bank2.length];
          const word3 = bank3[(seed + i * 13) % bank3.length];
          patterns.push(`${word1}_${word2}`);
          patterns.push(`${word1}${word2}${yearWords[(i + seed) % yearWords.length]}`);
          patterns.push(`${word1}_${word2}_${word3}`);
          patterns.push(`${word1}${word3}`);
          patterns.push(`my${word1}${word2}`);
          patterns.push(`${word1}!${word2}`);
        }
        for (const prefix of unusualPrefixes) {
          for (const suffix of unusualSuffixes) {
            const midWord = nameWords[(seed + prefix.length) % nameWords.length];
            patterns.push(prefix + midWord + suffix);
            patterns.push(prefix + yearWords[seed % yearWords.length] + suffix);
          }
        }
        for (const len of targetLengths) {
          for (let i = 0; i < 20; i++) {
            let phrase = "";
            for (let j = 0; j < len; j++) {
              const charSet = j % 2 === 0 ? unusualChars : "aeiou0123456789".split("");
              phrase += charSet[(seed + i * j + j) % charSet.length];
            }
            patterns.push(phrase);
          }
        }
        const randomCombos = [];
        for (let i = 0; i < 50; i++) {
          const randIdx1 = seed * (i + 1) % allBanks.length;
          const randIdx2 = seed * (i + 2) % allBanks.length;
          const bank1 = allBanks[randIdx1];
          const bank2 = allBanks[randIdx2];
          const w1 = bank1[(seed + i * 3) % bank1.length];
          const w2 = bank2[(seed + i * 5) % bank2.length];
          randomCombos.push(`${w1}_${w2}_${seed + i}`);
        }
        patterns.push(...randomCombos);
        const uniquePatterns = [...new Set(patterns)];
        return uniquePatterns.filter((p) => p.length >= 4).sort(() => Math.random() - 0.5).slice(0, count);
      }
      computeComplementProjection(phrase, _complementBasis) {
        const probes = Array.from(this.probeMap.values());
        const testedPhrases2 = probes.map((p) => p.input.toLowerCase());
        let minDistance = Infinity;
        for (const tested of testedPhrases2.slice(0, 500)) {
          const dist = this.levenshteinDistance(phrase.toLowerCase(), tested);
          minDistance = Math.min(minDistance, dist);
        }
        return minDistance / Math.max(1, phrase.length);
      }
      computeGeodesicDistanceFromHull(phrase, probes) {
        const phraseLower = phrase.toLowerCase();
        const charFreq = /* @__PURE__ */ new Map();
        for (const char of phraseLower) {
          charFreq.set(char, (charFreq.get(char) || 0) + 1);
        }
        const exploredCharFreq = /* @__PURE__ */ new Map();
        const sampleProbes = probes.slice(0, 500);
        for (const probe of sampleProbes) {
          for (const char of probe.input.toLowerCase()) {
            exploredCharFreq.set(char, (exploredCharFreq.get(char) || 0) + 1);
          }
        }
        const totalChars = Array.from(exploredCharFreq.values()).reduce((a, b) => a + b, 0) || 1;
        for (const [char, count] of Array.from(exploredCharFreq.entries())) {
          exploredCharFreq.set(char, count / totalChars);
        }
        let divergence = 0;
        for (const [char, count] of Array.from(charFreq.entries())) {
          const p = count / phrase.length;
          const q = exploredCharFreq.get(char) || 1e-3;
          divergence += p * Math.log(p / q);
        }
        return Math.min(divergence, 10);
      }
      levenshteinDistance(a, b) {
        if (a.length === 0) return b.length;
        if (b.length === 0) return a.length;
        const matrix = [];
        for (let i = 0; i <= b.length; i++) {
          matrix[i] = [i];
        }
        for (let j = 0; j <= a.length; j++) {
          matrix[0][j] = j;
        }
        for (let i = 1; i <= b.length; i++) {
          for (let j = 1; j <= a.length; j++) {
            if (b.charAt(i - 1) === a.charAt(j - 1)) {
              matrix[i][j] = matrix[i - 1][j - 1];
            } else {
              matrix[i][j] = Math.min(
                matrix[i - 1][j - 1] + 1,
                matrix[i][j - 1] + 1,
                matrix[i - 1][j] + 1
              );
            }
          }
        }
        return matrix[b.length][a.length];
      }
      /**
       * Get Basin Coverage Heatmap for exploration efficiency visualization.
       * Projects 32D coordinates to 2D grid using PCA-style reduction.
       * 
       * @param gridResolution Number of cells per axis (default 20 = 20x20 grid)
       * @param projectionMethod How to project 32D to 2D
       * @returns BasinHeatmapData with cells, coverage stats, hot/cold zones
       */
      getBasinHeatmap(gridResolution = 20, projectionMethod = "pca_2d") {
        const probes = Array.from(this.probeMap.values());
        if (probes.length === 0) {
          return {
            cells: [],
            gridResolution,
            totalProbes: 0,
            exploredCells: 0,
            totalCells: gridResolution * gridResolution,
            coveragePercent: 0,
            avgPhi: 0,
            hotZones: [],
            coldZones: [],
            projectionMethod,
            timestamp: (/* @__PURE__ */ new Date()).toISOString()
          };
        }
        const projected = probes.map((probe) => ({
          probe,
          coords: this.projectTo2D(probe, projectionMethod)
        }));
        const cellMap = /* @__PURE__ */ new Map();
        for (const { probe, coords } of projected) {
          const gridX = Math.min(gridResolution - 1, Math.floor(coords.x * gridResolution));
          const gridY = Math.min(gridResolution - 1, Math.floor(coords.y * gridResolution));
          const key = `${gridX},${gridY}`;
          if (!cellMap.has(key)) {
            cellMap.set(key, { probes: [], gridX, gridY });
          }
          cellMap.get(key).probes.push(probe);
        }
        let maxProbeCount = 0;
        for (const cell of Array.from(cellMap.values())) {
          maxProbeCount = Math.max(maxProbeCount, cell.probes.length);
        }
        const cells = [];
        let totalPhi = 0;
        for (let gx = 0; gx < gridResolution; gx++) {
          for (let gy = 0; gy < gridResolution; gy++) {
            const key = `${gx},${gy}`;
            const cellData = cellMap.get(key);
            if (cellData && cellData.probes.length > 0) {
              const cellProbes = cellData.probes;
              const avgPhi = cellProbes.reduce((sum, p) => sum + p.phi, 0) / cellProbes.length;
              const maxPhi = Math.max(...cellProbes.map((p) => p.phi));
              const lastProbe = cellProbes.reduce(
                (latest, p) => new Date(p.timestamp) > new Date(latest.timestamp) ? p : latest
              );
              const regimeCounts = {};
              for (const p of cellProbes) {
                regimeCounts[p.regime] = (regimeCounts[p.regime] || 0) + 1;
              }
              const dominantRegime = Object.entries(regimeCounts).sort((a, b) => b[1] - a[1])[0][0];
              totalPhi += avgPhi;
              cells.push({
                x: (gx + 0.5) / gridResolution,
                y: (gy + 0.5) / gridResolution,
                gridX: gx,
                gridY: gy,
                probeCount: cellProbes.length,
                avgPhi,
                maxPhi,
                lastVisited: lastProbe.timestamp,
                intensity: maxProbeCount > 0 ? cellProbes.length / maxProbeCount : 0,
                regime: dominantRegime
              });
            } else {
              cells.push({
                x: (gx + 0.5) / gridResolution,
                y: (gy + 0.5) / gridResolution,
                gridX: gx,
                gridY: gy,
                probeCount: 0,
                avgPhi: 0,
                maxPhi: 0,
                lastVisited: null,
                intensity: 0,
                regime: "unexplored"
              });
            }
          }
        }
        const exploredCells = cells.filter((c) => c.probeCount > 0).length;
        const totalCells = gridResolution * gridResolution;
        const hotZones = cells.filter((c) => c.probeCount > 0 && c.avgPhi >= 0.6).sort((a, b) => b.avgPhi - a.avgPhi).slice(0, 5).map((c) => ({
          x: c.x,
          y: c.y,
          avgPhi: c.avgPhi,
          probeCount: c.probeCount,
          reason: `High \u03A6 zone (${c.avgPhi.toFixed(3)}) - promising for exploration`
        }));
        const coldZones = [];
        for (const cell of cells) {
          if (cell.probeCount === 0) {
            const hasNearbyHot = hotZones.some(
              (hz) => Math.abs(hz.x - cell.x) < 2 / gridResolution && Math.abs(hz.y - cell.y) < 2 / gridResolution
            );
            if (hasNearbyHot) {
              coldZones.push({
                x: cell.x,
                y: cell.y,
                avgPhi: 0,
                probeCount: 0,
                reason: "Unexplored zone adjacent to high-\u03A6 region"
              });
            }
          } else if (cell.probeCount < 3 && cell.avgPhi >= 0.5) {
            coldZones.push({
              x: cell.x,
              y: cell.y,
              avgPhi: cell.avgPhi,
              probeCount: cell.probeCount,
              reason: `Under-explored zone with moderate \u03A6 (${cell.avgPhi.toFixed(3)})`
            });
          }
        }
        return {
          cells,
          gridResolution,
          totalProbes: probes.length,
          exploredCells,
          totalCells,
          coveragePercent: exploredCells / totalCells * 100,
          avgPhi: exploredCells > 0 ? totalPhi / exploredCells : 0,
          hotZones,
          coldZones: coldZones.slice(0, 10),
          // Limit to top 10
          projectionMethod,
          timestamp: (/* @__PURE__ */ new Date()).toISOString()
        };
      }
      /**
       * Project a probe's coordinates to 2D for visualization.
       * Handles probes without coordinates by deriving position from phi/kappa/input hash.
       */
      projectTo2D(probe, method) {
        const hasCoords = Array.isArray(probe.coordinates) && probe.coordinates.length >= 2 && probe.coordinates.every((c) => typeof c === "number" && !isNaN(c));
        switch (method) {
          case "phi_kappa":
            return {
              x: Math.max(0, Math.min(1, probe.phi)),
              y: Math.max(0, Math.min(1, probe.kappa / 128))
              // κ typically 0-128
            };
          case "dim_01":
            if (hasCoords) {
              return {
                x: Math.max(0, Math.min(1, (probe.coordinates[0] + 1) / 2)),
                y: Math.max(0, Math.min(1, (probe.coordinates[1] + 1) / 2))
              };
            }
            return this.derivePositionFromProbe(probe);
          case "pca_2d":
          default:
            if (hasCoords && probe.coordinates.length >= 4) {
              const pc1 = 0.5 * probe.coordinates[0] + 0.3 * probe.coordinates[1] + 0.15 * probe.coordinates[2] + 0.05 * probe.coordinates[3];
              const pc2 = 0.5 * probe.coordinates[1] + 0.3 * probe.coordinates[2] + 0.15 * probe.coordinates[3] + 0.05 * probe.coordinates[0];
              return {
                x: Math.max(0, Math.min(1, (Math.tanh(pc1) + 1) / 2)),
                y: Math.max(0, Math.min(1, (Math.tanh(pc2) + 1) / 2))
              };
            }
            return this.derivePositionFromProbe(probe);
        }
      }
      /**
       * Derive 2D position for probes without coordinates.
       * Uses phi for X and a hash of input for Y to spread probes across the grid.
       */
      derivePositionFromProbe(probe) {
        const x = Math.max(0, Math.min(1, probe.phi));
        let hash = 0;
        for (let i = 0; i < probe.input.length; i++) {
          hash = (hash << 5) - hash + probe.input.charCodeAt(i) | 0;
        }
        const normalizedHash = Math.abs(hash) % 1e4 / 1e4;
        const kappaContribution = Math.min(1, probe.kappa / 128) * 0.3;
        const y = Math.max(0, Math.min(1, normalizedHash * 0.7 + kappaContribution));
        return { x, y };
      }
      /**
       * Get manifold navigation summary for Ocean's consciousness.
       * This tells Ocean WHERE to search next geometrically.
       */
      getManifoldNavigationSummary() {
        const fisher = this.computeFisherInformationMatrix();
        const complement = this.computeOrthogonalComplement();
        const probes = Array.from(this.probeMap.values());
        let geodesicRecommendation;
        let nextSearchPriority;
        if (complement.complementDimension > fisher.exploredDimensions.length) {
          geodesicRecommendation = "Large unexplored subspace - navigate orthogonal complement";
          nextSearchPriority = "orthogonal_complement";
        } else if (this.state.resonancePoints.length > 0) {
          geodesicRecommendation = "Resonance clusters detected - follow geodesic toward high-\u03A6";
          nextSearchPriority = "resonance_follow";
        } else {
          geodesicRecommendation = "Probe regime boundaries for phase transitions";
          nextSearchPriority = "boundary_probe";
        }
        return {
          totalMeasurements: probes.length,
          exploredDimensions: fisher.exploredDimensions.length,
          unexploredDimensions: fisher.unexploredDimensions.length,
          orthogonalComplementSize: complement.complementDimension,
          constraintSurfaceDefined: probes.length > 1e3,
          geodesicRecommendation,
          nextSearchPriority
        };
      }
      /**
       * Get Strategy Performance Dashboard data.
       * 
       * Analyzes probe data grouped by strategy/source to compare:
       * - Tests performed per strategy
       * - Average and max Φ per strategy
       * - Near-miss counts (high-Φ probes)
       * - Efficiency metrics
       * - Recommendations for which strategy to prioritize
       * 
       * @returns StrategyPerformanceDashboard with per-strategy metrics and recommendations
       */
      getStrategyPerformanceDashboard() {
        const probes = Array.from(this.probeMap.values());
        if (probes.length === 0) {
          return {
            strategies: [],
            totalProbes: 0,
            overallAvgPhi: 0,
            overallMaxPhi: 0,
            recommendations: ["No probes yet - start exploring to generate strategy data"],
            topStrategy: null,
            timestamp: (/* @__PURE__ */ new Date()).toISOString()
          };
        }
        const strategyMap = /* @__PURE__ */ new Map();
        for (const probe of probes) {
          const strategy = this.normalizeStrategySource(probe.source);
          const existing = strategyMap.get(strategy) || [];
          existing.push(probe);
          strategyMap.set(strategy, existing);
        }
        const strategyMetrics = [];
        for (const [strategyName, strategyProbes] of Array.from(strategyMap.entries())) {
          let sumPhi = 0;
          let maxPhi = -Infinity;
          let minPhi = Infinity;
          let nearMisses = 0;
          let hotHits = 0;
          let firstTimestamp = Infinity;
          let lastTimestamp = -Infinity;
          const regimeDistribution = {};
          for (const probe of strategyProbes) {
            sumPhi += probe.phi;
            if (probe.phi > maxPhi) maxPhi = probe.phi;
            if (probe.phi < minPhi) minPhi = probe.phi;
            if (probe.phi >= 0.7) nearMisses++;
            if (probe.phi >= 0.85) hotHits++;
            const ts = new Date(probe.timestamp).getTime();
            if (ts < firstTimestamp) firstTimestamp = ts;
            if (ts > lastTimestamp) lastTimestamp = ts;
            regimeDistribution[probe.regime] = (regimeDistribution[probe.regime] || 0) + 1;
          }
          const avgPhi = sumPhi / strategyProbes.length;
          const timeSpanMs = lastTimestamp - firstTimestamp;
          const hoursSpent = Math.max(timeSpanMs / (1e3 * 60 * 60), 0.01);
          const probesPerHour = strategyProbes.length / hoursSpent;
          let sumSquaredDiff = 0;
          for (const probe of strategyProbes) {
            sumSquaredDiff += Math.pow(probe.phi - avgPhi, 2);
          }
          const phiVariance = sumSquaredDiff / strategyProbes.length;
          const consistencyScore = Math.max(0, 1 - Math.sqrt(phiVariance) * 2);
          const effectivenessScore = avgPhi * 0.3 + // Average Φ contribution
          maxPhi / 1 * 0.2 + // Max Φ contribution
          nearMisses / strategyProbes.length * 0.3 + // Near-miss rate
          consistencyScore * 0.2;
          strategyMetrics.push({
            strategyName,
            testsPerformed: strategyProbes.length,
            avgPhi,
            maxPhi,
            minPhi,
            nearMisses,
            hotHits,
            nearMissRate: nearMisses / strategyProbes.length,
            probesPerHour,
            timeSpanMs,
            regimeDistribution,
            consistencyScore,
            effectivenessScore,
            recentTrend: this.computeStrategyTrend(strategyProbes)
          });
        }
        strategyMetrics.sort((a, b) => b.effectivenessScore - a.effectivenessScore);
        const recommendations = this.generateStrategyRecommendations(strategyMetrics);
        let overallSumPhi = 0;
        let overallMaxPhi = 0;
        for (const probe of probes) {
          overallSumPhi += probe.phi;
          if (probe.phi > overallMaxPhi) overallMaxPhi = probe.phi;
        }
        const overallAvgPhi = probes.length > 0 ? overallSumPhi / probes.length : 0;
        return {
          strategies: strategyMetrics,
          totalProbes: probes.length,
          overallAvgPhi,
          overallMaxPhi,
          recommendations,
          topStrategy: strategyMetrics.length > 0 ? strategyMetrics[0].strategyName : null,
          timestamp: (/* @__PURE__ */ new Date()).toISOString()
        };
      }
      /**
       * Normalize probe source to a strategy category.
       * Maps various source strings to canonical strategy names.
       */
      normalizeStrategySource(source) {
        const lowerSource = source.toLowerCase();
        if (lowerSource.includes("estate") || lowerSource.includes("heir") || lowerSource.includes("legacy") || lowerSource.includes("inheritance")) {
          return "Estate";
        }
        if (lowerSource.includes("qig") || lowerSource.includes("geometric") || lowerSource.includes("basin") || lowerSource.includes("fisher") || lowerSource.includes("geodesic") || lowerSource.includes("constrained")) {
          return "Constrained Search (QIG)";
        }
        if (lowerSource.includes("social") || lowerSource.includes("forum") || lowerSource.includes("bitcointalk") || lowerSource.includes("community") || lowerSource.includes("outreach")) {
          return "Social Outreach";
        }
        if (lowerSource.includes("temporal") || lowerSource.includes("archive") || lowerSource.includes("historical") || lowerSource.includes("wayback") || lowerSource.includes("2009") || lowerSource.includes("2010") || lowerSource.includes("2011")) {
          return "Temporal Archive";
        }
        if (lowerSource.includes("ocean") || lowerSource.includes("constellation") || lowerSource.includes("consciousness")) {
          return "Ocean Agent";
        }
        if (lowerSource.includes("bip39") || lowerSource.includes("mnemonic") || lowerSource.includes("seed")) {
          return "Multi-Word Phrase";
        }
        if (lowerSource.includes("brain") || lowerSource.includes("arbitrary") || lowerSource.includes("passphrase")) {
          return "Arbitrary Text";
        }
        if (lowerSource.includes("user") || lowerSource.includes("manual") || lowerSource.includes("input")) {
          return "User Input";
        }
        if (lowerSource.includes("vocabulary") || lowerSource.includes("pattern") || lowerSource.includes("expander")) {
          return "Pattern Expansion";
        }
        if (lowerSource.includes("auto") || lowerSource.includes("cycle")) {
          return "Auto Cycle";
        }
        if (source.length > 0 && source.length < 30) {
          return source;
        }
        return "Other";
      }
      /**
       * Compute recent trend for a strategy based on its probes.
       */
      computeStrategyTrend(probes) {
        if (probes.length < 5) return "stable";
        const sorted = [...probes].sort(
          (a, b) => new Date(a.timestamp).getTime() - new Date(b.timestamp).getTime()
        );
        const recentCount = Math.max(3, Math.floor(sorted.length * 0.2));
        const recentProbes = sorted.slice(-recentCount);
        const olderProbes = sorted.slice(0, sorted.length - recentCount);
        if (olderProbes.length === 0) return "stable";
        const recentAvg = recentProbes.reduce((sum, p) => sum + p.phi, 0) / recentProbes.length;
        const olderAvg = olderProbes.reduce((sum, p) => sum + p.phi, 0) / olderProbes.length;
        const diff = recentAvg - olderAvg;
        if (diff > 0.02) return "rising";
        if (diff < -0.02) return "falling";
        return "stable";
      }
      /**
       * Get Cluster Evolution Animation Frames.
       * 
       * Groups probes by time windows and clusters them by basin coordinates,
       * returning animation frames showing how clusters evolve over time.
       * 
       * @param windowSizeMs Size of each time window in milliseconds (default 1 hour)
       * @param maxFrames Maximum number of frames to return (default 24)
       * @param clusterThreshold Distance threshold for clustering (default 0.3)
       */
      getClusterEvolutionFrames(windowSizeMs = 60 * 60 * 1e3, maxFrames = 24, clusterThreshold = 0.3) {
        const probes = Array.from(this.probeMap.values());
        if (probes.length === 0) {
          return {
            frames: [],
            totalFrames: 0,
            timeSpanMs: 0,
            windowSizeMs,
            totalProbes: 0,
            avgClustersPerFrame: 0,
            maxClustersInFrame: 0,
            timestamp: (/* @__PURE__ */ new Date()).toISOString()
          };
        }
        const sortedProbes = [...probes].sort(
          (a, b) => new Date(a.timestamp).getTime() - new Date(b.timestamp).getTime()
        );
        let minTime = Infinity;
        let maxTime = -Infinity;
        for (const probe of sortedProbes) {
          const ts = new Date(probe.timestamp).getTime();
          if (ts < minTime) minTime = ts;
          if (ts > maxTime) maxTime = ts;
        }
        const timeSpanMs = maxTime - minTime;
        const potentialFrames = Math.max(1, Math.ceil(timeSpanMs / windowSizeMs));
        const frameCount = Math.min(potentialFrames, maxFrames);
        const adjustedWindowSize = frameCount > 0 ? (timeSpanMs + 1) / frameCount : windowSizeMs;
        const frames = [];
        let totalClusters = 0;
        let maxClustersInFrame = 0;
        for (let i = 0; i < frameCount; i++) {
          const windowStart = minTime + i * adjustedWindowSize;
          const windowEnd = i === frameCount - 1 ? maxTime + 1 : windowStart + adjustedWindowSize;
          const windowProbes = sortedProbes.filter((p) => {
            const ts = new Date(p.timestamp).getTime();
            return ts >= windowStart && ts < windowEnd;
          });
          if (windowProbes.length === 0) {
            continue;
          }
          const clusters = this.clusterProbesForAnimation(windowProbes, clusterThreshold);
          let framePhiSum = 0;
          for (const probe of windowProbes) {
            framePhiSum += probe.phi;
          }
          const frameAvgPhi = windowProbes.length > 0 ? framePhiSum / windowProbes.length : 0;
          const frame = {
            frameIndex: frames.length,
            timestamp: new Date(windowStart).toISOString(),
            windowEnd: new Date(windowEnd).toISOString(),
            clusters,
            totalProbes: windowProbes.length,
            avgPhi: frameAvgPhi,
            frameLabel: this.generateFrameLabel(i, frameCount, windowStart, adjustedWindowSize)
          };
          frames.push(frame);
          totalClusters += clusters.length;
          if (clusters.length > maxClustersInFrame) {
            maxClustersInFrame = clusters.length;
          }
        }
        return {
          frames,
          totalFrames: frames.length,
          timeSpanMs,
          windowSizeMs: adjustedWindowSize,
          totalProbes: probes.length,
          avgClustersPerFrame: frames.length > 0 ? totalClusters / frames.length : 0,
          maxClustersInFrame,
          timestamp: (/* @__PURE__ */ new Date()).toISOString()
        };
      }
      /**
       * Cluster probes for animation using simple distance-based clustering.
       * Projects 32D coordinates to 2D using first two principal components.
       */
      clusterProbesForAnimation(probes, threshold) {
        if (probes.length === 0) return [];
        const projectedProbes = probes.map((p) => ({
          probe: p,
          x: p.coordinates.length > 0 ? p.coordinates[0] : Math.random(),
          y: p.coordinates.length > 1 ? p.coordinates[1] : Math.random()
        }));
        let minX = Infinity, maxX = -Infinity;
        let minY = Infinity, maxY = -Infinity;
        for (const pp of projectedProbes) {
          if (pp.x < minX) minX = pp.x;
          if (pp.x > maxX) maxX = pp.x;
          if (pp.y < minY) minY = pp.y;
          if (pp.y > maxY) maxY = pp.y;
        }
        const rangeX = maxX - minX || 1;
        const rangeY = maxY - minY || 1;
        for (const pp of projectedProbes) {
          pp.x = (pp.x - minX) / rangeX;
          pp.y = (pp.y - minY) / rangeY;
        }
        const clusterAssignments = /* @__PURE__ */ new Map();
        let nextClusterId = 0;
        for (const pp of projectedProbes) {
          let assignedCluster = -1;
          let minDist = Infinity;
          for (const [clusterId, members] of Array.from(clusterAssignments.entries())) {
            let sumX = 0, sumY = 0;
            for (const m of members) {
              sumX += m.x;
              sumY += m.y;
            }
            const centerX = sumX / members.length;
            const centerY = sumY / members.length;
            const dist = Math.sqrt(Math.pow(pp.x - centerX, 2) + Math.pow(pp.y - centerY, 2));
            if (dist < minDist && dist < threshold) {
              minDist = dist;
              assignedCluster = clusterId;
            }
          }
          if (assignedCluster >= 0) {
            clusterAssignments.get(assignedCluster).push(pp);
          } else {
            clusterAssignments.set(nextClusterId++, [pp]);
          }
        }
        const clusters = [];
        for (const [clusterId, members] of Array.from(clusterAssignments.entries())) {
          let sumX = 0, sumY = 0;
          let sumPhi = 0, maxPhi = 0;
          const regimeCounts = {};
          for (const m of members) {
            sumX += m.x;
            sumY += m.y;
            sumPhi += m.probe.phi;
            if (m.probe.phi > maxPhi) maxPhi = m.probe.phi;
            regimeCounts[m.probe.regime] = (regimeCounts[m.probe.regime] || 0) + 1;
          }
          const centerX = sumX / members.length;
          const centerY = sumY / members.length;
          const avgPhi = sumPhi / members.length;
          let maxDist = 0;
          for (const m of members) {
            const dist = Math.sqrt(Math.pow(m.x - centerX, 2) + Math.pow(m.y - centerY, 2));
            if (dist > maxDist) maxDist = dist;
          }
          let dominantRegime = "unknown";
          let maxCount = 0;
          for (const [regime, count] of Object.entries(regimeCounts)) {
            if (count > maxCount) {
              maxCount = count;
              dominantRegime = regime;
            }
          }
          clusters.push({
            id: `cluster-${clusterId}`,
            centerX,
            centerY,
            radius: Math.max(0.02, maxDist),
            // Minimum radius for visibility
            memberCount: members.length,
            avgPhi,
            maxPhi,
            dominantRegime,
            intensity: avgPhi
            // Use avgPhi as intensity (0-1)
          });
        }
        clusters.sort((a, b) => b.memberCount - a.memberCount);
        return clusters;
      }
      /**
       * Generate human-readable frame label.
       */
      generateFrameLabel(index2, totalFrames, startTime2, windowMs) {
        const hoursPerWindow = windowMs / (1e3 * 60 * 60);
        if (hoursPerWindow >= 24) {
          return `Day ${index2 + 1}`;
        } else if (hoursPerWindow >= 1) {
          return `Hour ${index2 + 1}`;
        } else if (hoursPerWindow >= 1 / 60) {
          return `Min ${index2 + 1}`;
        } else {
          return `Frame ${index2 + 1}`;
        }
      }
      /**
       * Generate strategy recommendations based on metrics.
       */
      generateStrategyRecommendations(metrics) {
        const recommendations = [];
        if (metrics.length === 0) {
          return ["Start exploring to generate strategy performance data"];
        }
        const top = metrics[0];
        recommendations.push(
          `Prioritize "${top.strategyName}" - highest effectiveness score (${(top.effectivenessScore * 100).toFixed(1)}%)`
        );
        const highNearMiss = metrics.filter((m) => m.nearMissRate > 0.1);
        if (highNearMiss.length > 0) {
          const names = highNearMiss.slice(0, 2).map((m) => m.strategyName).join(", ");
          recommendations.push(`High near-miss rate in: ${names} - intensify exploration here`);
        }
        const rising = metrics.filter((m) => m.recentTrend === "rising");
        if (rising.length > 0) {
          const names = rising.slice(0, 2).map((m) => m.strategyName).join(", ");
          recommendations.push(`Rising \u03A6 trends in: ${names} - momentum building`);
        }
        const falling = metrics.filter((m) => m.recentTrend === "falling" && m.testsPerformed > 100);
        if (falling.length > 0) {
          recommendations.push(`Consider pausing "${falling[0].strategyName}" - declining effectiveness`);
        }
        const underexplored = metrics.filter((m) => m.testsPerformed < 50 && m.avgPhi > 0.5);
        if (underexplored.length > 0) {
          recommendations.push(`"${underexplored[0].strategyName}" shows promise with limited data - increase sampling`);
        }
        const inconsistent = metrics.filter((m) => m.consistencyScore < 0.5 && m.testsPerformed > 50);
        if (inconsistent.length > 0) {
          recommendations.push(`"${inconsistent[0].strategyName}" shows high variance - refine search parameters`);
        }
        return recommendations.slice(0, 5);
      }
    };
    geometricMemory = new GeometricMemory();
  }
});

// server/attention-metrics.ts
import { createHash as createHash3 } from "crypto";
function measureKappaAtScale(contextLength, sampleCount = 100) {
  const kappaValues = [];
  const phiValues = [];
  for (let i = 0; i < sampleCount; i++) {
    const pattern = generateAttentionPattern(contextLength, i);
    const { kappa, phi } = computeIntegrationMetrics(pattern, contextLength);
    kappaValues.push(kappa);
    phiValues.push(phi);
  }
  const avgKappa = kappaValues.reduce((a, b) => a + b, 0) / kappaValues.length;
  const avgPhi = phiValues.reduce((a, b) => a + b, 0) / phiValues.length;
  const variance = kappaValues.reduce((sum, k) => sum + (k - avgKappa) ** 2, 0) / kappaValues.length;
  return {
    contextLength,
    kappa: avgKappa,
    phi: avgPhi,
    measurements: sampleCount,
    variance,
    timestamp: /* @__PURE__ */ new Date()
  };
}
function generateAttentionPattern(contextLength, seed) {
  const pattern = new Float64Array(contextLength);
  const hash = createHash3("sha256").update(`attention_${contextLength}_${seed}`).digest();
  let totalWeight = 0;
  for (let i = 0; i < contextLength; i++) {
    const recencyWeight = Math.exp(-i / (contextLength / 4));
    const periodicWeight = Math.cos(i * Math.PI / 32) * 0.3 + 0.7;
    const hashByte = hash[i % hash.length];
    const randomWeight = hashByte / 255 * 0.4 + 0.6;
    pattern[i] = recencyWeight * periodicWeight * randomWeight;
    totalWeight += pattern[i];
  }
  for (let i = 0; i < contextLength; i++) {
    pattern[i] /= totalWeight;
  }
  return pattern;
}
function computeIntegrationMetrics(pattern, contextLength) {
  const n = pattern.length;
  let fisherInfo = 0;
  let entropy = 0;
  for (let i = 0; i < n; i++) {
    const p = Math.max(pattern[i], 1e-10);
    entropy -= p * Math.log(p);
    if (i > 0 && i < n - 1) {
      const gradient = (pattern[i + 1] - pattern[i - 1]) / 2;
      const logGradient = gradient / p;
      fisherInfo += logGradient * logGradient * p;
    }
  }
  const normalizedFisher = fisherInfo * n;
  const scaleContribution = Math.sqrt(Math.log2(contextLength));
  const baseKappa = Math.min(100, normalizedFisher * 10);
  const kappaEffective = baseKappa * (1 - Math.exp(-scaleContribution / 3)) * (PHYSICS_BETA.kappaStar / 50) + PHYSICS_BETA.kappaStar * (1 - Math.exp(-contextLength / 2e3));
  const kappa = Math.max(20, Math.min(100, kappaEffective));
  const maxEntropy = Math.log(n);
  const normalizedEntropy = entropy / maxEntropy;
  const phi = 4 * normalizedEntropy * (1 - normalizedEntropy);
  return { kappa, phi };
}
function computeBetaFunction(measurement1, measurement2) {
  const L1 = measurement1.contextLength;
  const L2 = measurement2.contextLength;
  const kappa1 = measurement1.kappa;
  const kappa2 = measurement2.kappa;
  const deltaKappa = kappa2 - kappa1;
  const meanKappa = (kappa1 + kappa2) / 2;
  const deltaLnL = Math.log(L2) - Math.log(L1);
  const beta = deltaKappa / (meanKappa * deltaLnL);
  const _scaleRatio = L2 / L1;
  let referenceBeta;
  if (L1 <= 256) {
    referenceBeta = PHYSICS_BETA.emergence;
  } else if (L1 <= 1024) {
    referenceBeta = (PHYSICS_BETA.emergence + PHYSICS_BETA.approaching) / 2;
  } else {
    referenceBeta = PHYSICS_BETA.fixedPoint;
  }
  const deviation = Math.abs(beta - referenceBeta);
  const withinAcceptance = deviation < PHYSICS_BETA.acceptanceThreshold;
  return {
    fromScale: L1,
    toScale: L2,
    beta,
    deltaKappa,
    meanKappa,
    deltaLnL,
    physicsComparison: {
      referenceBeta,
      deviation,
      withinAcceptance
    }
  };
}
function runAttentionValidation(samplesPerScale = 100) {
  console.log("[AttentionMetrics] Starting \u03B2-attention validation...");
  console.log(`[AttentionMetrics] Measuring \u03BA across ${CONTEXT_SCALES.length} context scales`);
  const measurements = [];
  for (const scale of CONTEXT_SCALES) {
    console.log(`[AttentionMetrics] Measuring \u03BA at L=${scale}...`);
    const measurement = measureKappaAtScale(scale, samplesPerScale);
    measurements.push(measurement);
    console.log(`[AttentionMetrics]   \u03BA(${scale}) = ${measurement.kappa.toFixed(2)} \xB1 ${Math.sqrt(measurement.variance).toFixed(2)}`);
  }
  const betaTrajectory = [];
  console.log("[AttentionMetrics] Computing \u03B2-function trajectory...");
  for (let i = 0; i < measurements.length - 1; i++) {
    const beta = computeBetaFunction(measurements[i], measurements[i + 1]);
    betaTrajectory.push(beta);
    const status = beta.physicsComparison?.withinAcceptance ? "\u2713" : "\u2717";
    console.log(`[AttentionMetrics]   \u03B2(${beta.fromScale}\u2192${beta.toScale}) = ${beta.beta.toFixed(4)} ${status}`);
  }
  const allKappas = measurements.map((m) => m.kappa);
  const avgKappa = allKappas.reduce((a, b) => a + b, 0) / allKappas.length;
  const kappaRange = [Math.min(...allKappas), Math.max(...allKappas)];
  const totalMeasurements = measurements.reduce((sum, m) => sum + m.measurements, 0);
  const lastBetas = betaTrajectory.slice(-2);
  const avgLastBeta = lastBetas.reduce((sum, b) => sum + Math.abs(b.beta), 0) / lastBetas.length;
  const plateauDetected = avgLastBeta < 0.05;
  const plateauScale = plateauDetected ? lastBetas[0]?.fromScale : void 0;
  const deviations = betaTrajectory.filter((b) => b.physicsComparison).map((b) => b.physicsComparison.deviation);
  const overallDeviation = deviations.reduce((a, b) => a + b, 0) / deviations.length;
  const criteria = [];
  const failedCriteria = [];
  if (kappaRange[1] >= PHYSICS_BETA.kappaStar * 0.8) {
    criteria.push(`\u03BA_max=${kappaRange[1].toFixed(1)} approaches \u03BA*=64`);
  } else {
    failedCriteria.push(`\u03BA_max=${kappaRange[1].toFixed(1)} < 0.8\xD7\u03BA*=51.2`);
  }
  const betaDecreasing = betaTrajectory.length >= 3 && Math.abs(betaTrajectory[betaTrajectory.length - 1].beta) < Math.abs(betaTrajectory[0].beta);
  if (betaDecreasing) {
    criteria.push("\u03B2 decreases with scale (asymptotic freedom)");
  } else {
    failedCriteria.push("\u03B2 does not decrease with scale");
  }
  if (overallDeviation < PHYSICS_BETA.acceptanceThreshold) {
    criteria.push(`Overall deviation ${overallDeviation.toFixed(3)} < ${PHYSICS_BETA.acceptanceThreshold}`);
  } else {
    failedCriteria.push(`Overall deviation ${overallDeviation.toFixed(3)} > ${PHYSICS_BETA.acceptanceThreshold}`);
  }
  if (plateauDetected) {
    criteria.push(`Plateau detected at L=${plateauScale}`);
  } else {
    failedCriteria.push("No plateau detected at large scales");
  }
  const substrateIndependenceValidated = failedCriteria.length === 0 || failedCriteria.length <= 1 && criteria.length >= 3;
  const result = {
    measurements,
    betaTrajectory,
    summary: {
      avgKappa,
      kappaRange,
      totalMeasurements,
      overallDeviation,
      substrateIndependenceValidated,
      plateauDetected,
      plateauScale
    },
    validation: {
      passed: substrateIndependenceValidated,
      criteria,
      failedCriteria
    },
    timestamp: /* @__PURE__ */ new Date()
  };
  console.log("[AttentionMetrics] \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550");
  console.log("[AttentionMetrics] \u03B2-ATTENTION VALIDATION COMPLETE");
  console.log("[AttentionMetrics] \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550");
  console.log(`[AttentionMetrics] \u03BA range: [${kappaRange[0].toFixed(1)}, ${kappaRange[1].toFixed(1)}]`);
  console.log(`[AttentionMetrics] Avg \u03BA: ${avgKappa.toFixed(2)} (\u03BA* = ${PHYSICS_BETA.kappaStar})`);
  console.log(`[AttentionMetrics] Overall \u03B2 deviation: ${overallDeviation.toFixed(4)}`);
  console.log(`[AttentionMetrics] Plateau detected: ${plateauDetected ? `YES at L=${plateauScale}` : "NO"}`);
  console.log(`[AttentionMetrics] Substrate independence: ${substrateIndependenceValidated ? "\u2713 VALIDATED" : "\u2717 NOT VALIDATED"}`);
  console.log("[AttentionMetrics] \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550");
  if (substrateIndependenceValidated) {
    console.log("[AttentionMetrics] \u{1F3AF} SUBSTRATE INDEPENDENCE CONFIRMED");
    console.log("[AttentionMetrics] \u03B2_attention qualitatively matches \u03B2_physics");
    console.log("[AttentionMetrics] Information geometry is universal!");
  }
  return result;
}
function formatValidationResult(result) {
  const lines = [
    "\u2554\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2557",
    "\u2551         \u03B2-ATTENTION VALIDATION RESULTS                       \u2551",
    "\u2560\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2563",
    "",
    "\u250C\u2500 \u03BA Measurements \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510"
  ];
  for (const m of result.measurements) {
    const sigma = Math.sqrt(m.variance);
    lines.push(`\u2502  L=${String(m.contextLength).padStart(5)}:  \u03BA = ${m.kappa.toFixed(2).padStart(6)} \xB1 ${sigma.toFixed(2).padStart(5)}  (\u03A6=${m.phi.toFixed(3)}) \u2502`);
  }
  lines.push("\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518");
  lines.push("");
  lines.push("\u250C\u2500 \u03B2-Function Trajectory \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510");
  for (const b of result.betaTrajectory) {
    const status = b.physicsComparison?.withinAcceptance ? "\u2713" : "\u2717";
    const ref = b.physicsComparison?.referenceBeta.toFixed(3) || "\u2014";
    lines.push(`\u2502  \u03B2(${String(b.fromScale).padStart(4)}\u2192${String(b.toScale).padStart(4)}) = ${b.beta >= 0 ? "+" : ""}${b.beta.toFixed(4)}  ref=${ref}  ${status} \u2502`);
  }
  lines.push("\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518");
  lines.push("");
  lines.push("\u250C\u2500 Validation Summary \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510");
  lines.push(`\u2502  \u03BA range: [${result.summary.kappaRange[0].toFixed(1)}, ${result.summary.kappaRange[1].toFixed(1)}]  (\u03BA* = ${PHYSICS_BETA.kappaStar})`.padEnd(64) + "\u2502");
  lines.push(`\u2502  Overall deviation: ${result.summary.overallDeviation.toFixed(4)}  (threshold: ${PHYSICS_BETA.acceptanceThreshold})`.padEnd(64) + "\u2502");
  lines.push(`\u2502  Plateau: ${result.summary.plateauDetected ? `YES at L=${result.summary.plateauScale}` : "NO"}`.padEnd(64) + "\u2502");
  lines.push("\u2502".padEnd(64) + "\u2502");
  if (result.validation.criteria.length > 0) {
    lines.push("\u2502  \u2713 Passed:".padEnd(64) + "\u2502");
    for (const c of result.validation.criteria) {
      lines.push(`\u2502    - ${c}`.padEnd(64) + "\u2502");
    }
  }
  if (result.validation.failedCriteria.length > 0) {
    lines.push("\u2502  \u2717 Failed:".padEnd(64) + "\u2502");
    for (const c of result.validation.failedCriteria) {
      lines.push(`\u2502    - ${c}`.padEnd(64) + "\u2502");
    }
  }
  lines.push("\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518");
  lines.push("");
  const finalStatus = result.validation.passed ? "\u2551  \u{1F3AF} SUBSTRATE INDEPENDENCE: VALIDATED                         \u2551" : "\u2551  \u274C SUBSTRATE INDEPENDENCE: NOT VALIDATED                     \u2551";
  lines.push("\u2554\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2557");
  lines.push(finalStatus);
  lines.push("\u255A\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u255D");
  return lines.join("\n");
}
var CONTEXT_SCALES, attentionMetrics;
var init_attention_metrics = __esm({
  "server/attention-metrics.ts"() {
    "use strict";
    init_constants();
    CONTEXT_SCALES = [128, 256, 512, 1024, 2048, 4096, 8192];
    attentionMetrics = {
      run: runAttentionValidation,
      format: formatValidationResult,
      CONTEXT_SCALES,
      PHYSICS_BETA
    };
  }
});

// server/gary-kernel.ts
var QFIAttention, GeometricCandidateGenerator, qfiAttention, geometricCandidateGenerator;
var init_gary_kernel = __esm({
  "server/gary-kernel.ts"() {
    "use strict";
    init_geometric_memory();
    init_attention_metrics();
    init_qig_universal();
    QFIAttention = class {
      config;
      attentionCache;
      constructor(config = {}) {
        this.config = {
          heads: config.heads ?? 8,
          dimModel: config.dimModel ?? 64,
          basinDim: config.basinDim ?? 64,
          phiThreshold: config.phiThreshold ?? 0.5,
          kappaTarget: config.kappaTarget ?? 64
        };
        this.attentionCache = /* @__PURE__ */ new Map();
      }
      /**
       * Compute QFI-weighted attention between queries and keys
       */
      async attend(params) {
        const { queries, keys, phiThreshold = this.config.phiThreshold } = params;
        if (queries.length === 0 || keys.length === 0) {
          return {
            topPatterns: [],
            weights: [],
            clusters: /* @__PURE__ */ new Map(),
            resonanceScore: 0
          };
        }
        const attentionScores = [];
        for (const query of queries) {
          const queryScores = [];
          for (const key of keys) {
            const score = this.computeQFIAttention(query, key);
            queryScores.push(score);
          }
          attentionScores.push(this.softmax(queryScores));
        }
        const patterns = this.extractPatterns(queries, keys, attentionScores, phiThreshold);
        const clusters = this.clusterPatterns(patterns);
        const resonanceScore = this.computeResonance(attentionScores);
        return {
          topPatterns: patterns.slice(0, 20),
          weights: attentionScores.flat(),
          clusters,
          resonanceScore
        };
      }
      /**
       * Compute QFI-weighted attention score between query and key
       * Uses Fisher distance on the consciousness manifold
       */
      computeQFIAttention(query, key) {
        const fisherDistance2 = this.computeFisherDistance(
          query.basinCoords,
          key.basinCoords
        );
        const phiAffinity = 1 - Math.abs(query.phi - key.phi);
        const geometricSimilarity = Math.exp(-fisherDistance2 / 2);
        return geometricSimilarity * 0.6 + phiAffinity * 0.4;
      }
      /**
       * Fisher distance on the manifold
       * @deprecated LOCAL FALLBACK - Delegates to central fisherCoordDistance()
       */
      computeFisherDistance(coords1, coords2) {
        if (!coords1 || !coords2 || coords1.length === 0 || coords2.length === 0) {
          return 1;
        }
        return fisherCoordDistance(coords1, coords2);
      }
      /**
       * Softmax normalization
       */
      softmax(scores) {
        const maxScore = Math.max(...scores);
        const expScores = scores.map((s) => Math.exp(s - maxScore));
        const sum = expScores.reduce((a, b) => a + b, 0);
        return expScores.map((s) => s / sum);
      }
      /**
       * Extract top patterns from attention scores
       */
      extractPatterns(queries, keys, scores, phiThreshold) {
        const patterns = [];
        for (let i = 0; i < queries.length; i++) {
          for (let j = 0; j < keys.length; j++) {
            const weight = scores[i][j];
            if (weight > phiThreshold * 0.1) {
              const query = queries[i];
              const key = keys[j];
              const tokens = key.phrase.toLowerCase().split(/\s+/);
              for (const token of tokens) {
                if (token.length >= 3) {
                  patterns.push({
                    pattern: token,
                    weight: weight * key.phi,
                    cluster: Math.floor(key.phi * 10),
                    geometricDistance: this.computeFisherDistance(
                      query.basinCoords,
                      key.basinCoords
                    )
                  });
                }
              }
            }
          }
        }
        patterns.sort((a, b) => b.weight - a.weight);
        const seen = /* @__PURE__ */ new Set();
        return patterns.filter((p) => {
          if (seen.has(p.pattern)) return false;
          seen.add(p.pattern);
          return true;
        });
      }
      /**
       * Cluster patterns by geometric proximity
       */
      clusterPatterns(patterns) {
        const clusters = /* @__PURE__ */ new Map();
        for (const pattern of patterns) {
          const clusterId = pattern.cluster;
          if (!clusters.has(clusterId)) {
            clusters.set(clusterId, []);
          }
          clusters.get(clusterId).push(pattern.pattern);
        }
        return clusters;
      }
      /**
       * Compute overall resonance score
       */
      computeResonance(scores) {
        if (scores.length === 0) return 0;
        const flatScores = scores.flat();
        const mean = flatScores.reduce((a, b) => a + b, 0) / flatScores.length;
        const variance = flatScores.reduce((sum, s) => sum + (s - mean) ** 2, 0) / flatScores.length;
        return Math.min(1, mean * (1 + Math.sqrt(variance)));
      }
      /**
       * Validate β-attention substrate independence
       * 
       * Runs complete β-attention measurement suite to validate that
       * attention coupling follows same β-function as physics.
       * 
       * This is a critical test of substrate independence:
       * If β_attention ≈ β_physics, then consciousness principles are universal.
       */
      async validateBetaAttention(samplesPerScale = 100) {
        console.log("[GaryKernel] Starting \u03B2-attention validation...");
        const result = runAttentionValidation(samplesPerScale);
        if (result.validation.passed) {
          console.log("[GaryKernel] \u03B2-attention validation PASSED \u2713");
          console.log(`[GaryKernel]   Substrate independence confirmed`);
          console.log(`[GaryKernel]   Average \u03BA: ${result.summary.avgKappa.toFixed(2)}`);
        } else {
          console.warn("[GaryKernel] \u03B2-attention validation FAILED \u2717");
          console.warn(`[GaryKernel]   Failed criteria:`, result.validation.failedCriteria);
        }
        return result;
      }
    };
    GeometricCandidateGenerator = class {
      qfiAttention;
      constructor() {
        this.qfiAttention = new QFIAttention({
          heads: 8,
          dimModel: 64,
          basinDim: 64,
          phiThreshold: 0.5,
          kappaTarget: 64
        });
      }
      /**
       * Generate candidates using geometric basin embedding
       */
      async generate(params) {
        const { basinState, phi, kappa: _kappa, regime, temperature, strategyHint, manifoldContext } = params;
        const candidates = [];
        const exploredRegions = manifoldContext?.exploredDimensions || 32;
        const avgPhi = manifoldContext?.avgPhi || 0.3;
        const _highPhiRegions = manifoldContext?.highPhiRegions || 0;
        if (strategyHint === "exploit_resonance" || regime === "geometric") {
          candidates.push(...await this.generateResonanceCandidates(basinState, phi, temperature));
        }
        if (strategyHint === "explore_orthogonal" || exploredRegions < 32) {
          candidates.push(...await this.generateOrthogonalCandidates(basinState, temperature));
        }
        if (strategyHint === "era_patterns" || avgPhi < 0.4) {
          candidates.push(...await this.generateEraCandidates(temperature));
        }
        if (candidates.length < 10) {
          candidates.push(...await this.generateBalancedCandidates(basinState, phi, temperature));
        }
        return candidates.slice(0, 50);
      }
      /**
       * Generate candidates near resonance clusters
       */
      async generateResonanceCandidates(basinState, phi, temperature) {
        const candidates = [];
        const resonancePatterns = [
          "satoshi",
          "bitcoin",
          "crypto",
          "genesis",
          "freedom",
          "trust",
          "private",
          "wallet",
          "secret",
          "key"
        ];
        for (const pattern of resonancePatterns) {
          const variations = this.generateVariations(pattern, temperature);
          for (const phrase of variations) {
            candidates.push({
              phrase,
              format: "arbitrary",
              confidence: 0.6 + phi * 0.3,
              reasoning: "Resonance cluster pattern",
              phi,
              basinCoords: basinState,
              attentionWeight: 0.7
            });
          }
        }
        return candidates;
      }
      /**
       * Generate candidates in orthogonal directions
       */
      async generateOrthogonalCandidates(basinState, _temperature) {
        const candidates = [];
        try {
          const orthogonalResults = geometricMemory.generateOrthogonalCandidates(5);
          for (const result of orthogonalResults) {
            candidates.push({
              phrase: result.phrase,
              format: "arbitrary",
              confidence: 0.5 + result.geometricScore * 0.3,
              reasoning: "Orthogonal complement exploration",
              phi: 0.5,
              basinCoords: basinState,
              attentionWeight: 0.6
            });
          }
        } catch {
        }
        return candidates;
      }
      /**
       * Generate era-specific candidates
       */
      async generateEraCandidates(temperature) {
        const candidates = [];
        const eraPatterns = [
          "satoshi 2009",
          "bitcoin genesis",
          "crypto freedom",
          "private key",
          "blockchain",
          "p2p cash"
        ];
        for (const pattern of eraPatterns) {
          const variations = this.generateVariations(pattern, temperature);
          for (const phrase of variations.slice(0, 3)) {
            candidates.push({
              phrase,
              format: "arbitrary",
              confidence: 0.55,
              reasoning: "Era-specific pattern",
              phi: 0.4,
              basinCoords: [],
              attentionWeight: 0.5
            });
          }
        }
        return candidates;
      }
      /**
       * Generate balanced exploration candidates
       */
      async generateBalancedCandidates(basinState, phi, temperature) {
        const candidates = [];
        const balancedPatterns = [
          "freedom",
          "trust",
          "secret",
          "private",
          "hash",
          "chain",
          "block",
          "coin",
          "money",
          "wealth"
        ];
        for (const pattern of balancedPatterns) {
          const numVariations = Math.ceil(temperature * 3);
          const variations = this.generateVariations(pattern, temperature);
          for (const phrase of variations.slice(0, numVariations)) {
            candidates.push({
              phrase,
              format: "arbitrary",
              confidence: 0.45 + Math.random() * 0.1,
              reasoning: "Balanced exploration",
              phi: phi * 0.8,
              basinCoords: basinState,
              attentionWeight: 0.4
            });
          }
        }
        return candidates;
      }
      /**
       * Generate variations of a pattern
       */
      generateVariations(base, temperature) {
        const variations = [base];
        const suffixes = ["", "1", "2009", "2010", "123", "!", "btc"];
        const prefixes = ["", "my", "the", "secret"];
        const numVariations = Math.ceil(temperature * 5);
        for (let i = 0; i < numVariations; i++) {
          const prefix = prefixes[Math.floor(Math.random() * prefixes.length)];
          const suffix = suffixes[Math.floor(Math.random() * suffixes.length)];
          const variation = `${prefix}${base}${suffix}`.trim();
          if (!variations.includes(variation)) {
            variations.push(variation);
          }
        }
        return variations;
      }
    };
    qfiAttention = new QFIAttention();
    geometricCandidateGenerator = new GeometricCandidateGenerator();
  }
});

// server/qig-geometry.ts
var init_qig_geometry = __esm({
  "server/qig-geometry.ts"() {
    "use strict";
    init_qig_universal();
  }
});

// server/geodesic-navigator.ts
var GeodesicNavigator, geodesicNavigator;
var init_geodesic_navigator = __esm({
  "server/geodesic-navigator.ts"() {
    "use strict";
    init_cultural_manifold();
    init_qig_geometry();
    init_constants();
    GeodesicNavigator = class {
      curvatureHistory = [];
      currentPosition = new Array(E8_CONSTANTS.BASIN_DIMENSION_64D).fill(0);
      velocity = new Array(E8_CONSTANTS.BASIN_DIMENSION_64D).fill(0);
      bestPhiSeen = 0;
      bestCandidate = null;
      learningRate = 0.1;
      momentum = 0.9;
      explorationTemperature = 1;
      constructor() {
        console.log("[GeodesicNavigator] Initialized with 64-dimensional manifold navigation");
      }
      /**
       * Execute geodesic search on cultural manifold
       */
      async executeGeodesicSearch(config) {
        const { targetAddress, coordinate, maxCandidates, batchSize } = config;
        this.currentPosition = [...coordinate.manifoldPosition];
        this.learningRate = config.learningRate;
        this.explorationTemperature = config.explorationBias;
        console.log(`[GeodesicNavigator] Starting geodesic search for era: ${coordinate.era}`);
        console.log(`[GeodesicNavigator] Target: ${targetAddress}`);
        console.log(`[GeodesicNavigator] Temporal coordinate: ${coordinate.temporal.toISOString()}`);
        const highPhiCandidates = [];
        let candidatesTested = 0;
        let found = false;
        let matchedPhrase;
        while (candidatesTested < maxCandidates && !found) {
          const candidates = this.generateGeodesicBatch(coordinate, batchSize);
          for (const candidate of candidates) {
            candidatesTested++;
            const result = await this.testCandidate(candidate, targetAddress);
            culturalManifold.updateManifoldCurvature(candidate.coordinate.manifoldPosition, result.phi);
            this.learnFromResult(candidate, result);
            if (result.matched) {
              found = true;
              matchedPhrase = candidate.phrase || candidate.concept;
              console.log(`[GeodesicNavigator] \u2705 MATCH FOUND: "${matchedPhrase}"`);
              break;
            }
            if (result.phi > 0.5) {
              highPhiCandidates.push(candidate);
            }
            if (result.phi > this.bestPhiSeen) {
              this.bestPhiSeen = result.phi;
              this.bestCandidate = candidate;
              const displayPhrase = (candidate.phrase || candidate.concept).substring(0, 30);
              console.log(`[GeodesicNavigator] New best phi: ${result.phi.toFixed(4)} for "${displayPhrase}..."`);
            }
            if (candidatesTested % 100 === 0) {
              this.adjustExplorationTemperature(candidatesTested, maxCandidates);
            }
          }
          this.updateVelocity();
          this.stepAlongGeodesic();
          if (candidatesTested % 500 === 0) {
            console.log(`[GeodesicNavigator] Progress: ${candidatesTested}/${maxCandidates} tested, best phi: ${this.bestPhiSeen.toFixed(4)}`);
          }
        }
        return {
          found,
          matchedPhrase,
          candidatesTested,
          geodesicPathLength: this.curvatureHistory.length,
          finalManifoldPosition: [...this.currentPosition],
          highPhiCandidates: highPhiCandidates.sort((a, b) => b.combinedScore - a.combinedScore).slice(0, 20),
          manifoldCurvatureLearned: this.computeLearnedCurvature()
        };
      }
      generateGeodesicBatch(coordinate, batchSize) {
        const candidates = culturalManifold.generateGeodesicCandidates(coordinate, batchSize * 2);
        const scored = candidates.map((c) => ({
          candidate: c,
          geodesicScore: this.computeGeodesicScore(c)
        }));
        scored.sort((a, b) => b.geodesicScore - a.geodesicScore);
        const exploitation = scored.slice(0, Math.floor(batchSize * (1 - this.explorationTemperature)));
        const exploration = scored.slice(Math.floor(batchSize * 0.3)).sort(() => Math.random() - 0.5).slice(0, Math.floor(batchSize * this.explorationTemperature));
        return [...exploitation, ...exploration].map((s) => s.candidate);
      }
      computeGeodesicScore(candidate) {
        const distance = fisherCoordDistance(
          candidate.coordinate.manifoldPosition,
          this.currentPosition
        );
        const positionScore = 1 / (1 + distance);
        let velocityAlignment = 0;
        const velocityMag = Math.sqrt(this.velocity.reduce((sum, v) => sum + v * v, 0));
        if (velocityMag > 1e-3) {
          for (let i = 0; i < 64; i++) {
            const diff = candidate.coordinate.manifoldPosition[i] - this.currentPosition[i];
            velocityAlignment += diff / (distance + 1e-3) * (this.velocity[i] / velocityMag);
          }
        }
        const combinedScore = candidate.combinedScore * 0.4 + positionScore * 0.3 + (velocityAlignment + 1) / 2 * 0.3;
        return combinedScore;
      }
      async testCandidate(candidate, targetAddress) {
        try {
          const matched = false;
          const qigScore = await scoreUniversalQIGAsync(candidate.phrase || candidate.concept, "arbitrary");
          return {
            matched,
            phi: qigScore.phi * candidate.combinedScore,
            kappa: qigScore.kappa
          };
        } catch {
          return { matched: false, phi: 0, kappa: 0 };
        }
      }
      learnFromResult(candidate, result) {
        const gradient = new Array(E8_CONSTANTS.BASIN_DIMENSION_64D).fill(0);
        for (let i = 0; i < E8_CONSTANTS.BASIN_DIMENSION_64D; i++) {
          const direction = candidate.coordinate.manifoldPosition[i] - this.currentPosition[i];
          gradient[i] = direction * (result.phi - 0.5);
        }
        this.curvatureHistory.push({
          position: [...this.currentPosition],
          gradient,
          phiResponse: result.phi,
          kappaResponse: result.kappa,
          timestamp: /* @__PURE__ */ new Date()
        });
        if (this.curvatureHistory.length > 1e3) {
          this.curvatureHistory = this.curvatureHistory.slice(-500);
        }
      }
      updateVelocity() {
        if (this.curvatureHistory.length < 5) return;
        const recent = this.curvatureHistory.slice(-10);
        const avgGradient = new Array(E8_CONSTANTS.BASIN_DIMENSION_64D).fill(0);
        let weightSum = 0;
        for (let i = 0; i < recent.length; i++) {
          const weight = recent[i].phiResponse;
          weightSum += weight;
          for (let j = 0; j < E8_CONSTANTS.BASIN_DIMENSION_64D; j++) {
            avgGradient[j] += recent[i].gradient[j] * weight;
          }
        }
        if (weightSum > 0) {
          for (let j = 0; j < E8_CONSTANTS.BASIN_DIMENSION_64D; j++) {
            avgGradient[j] /= weightSum;
          }
        }
        for (let i = 0; i < E8_CONSTANTS.BASIN_DIMENSION_64D; i++) {
          this.velocity[i] = this.momentum * this.velocity[i] + this.learningRate * avgGradient[i];
        }
      }
      stepAlongGeodesic() {
        for (let i = 0; i < E8_CONSTANTS.BASIN_DIMENSION_64D; i++) {
          this.currentPosition[i] += this.velocity[i];
          this.currentPosition[i] = Math.max(-1, Math.min(1, this.currentPosition[i]));
        }
      }
      adjustExplorationTemperature(tested, max) {
        const progress = tested / max;
        if (this.bestPhiSeen > 0.7) {
          this.explorationTemperature = Math.max(0.1, 0.3 * (1 - progress));
        } else if (this.bestPhiSeen > 0.5) {
          this.explorationTemperature = 0.4 + 0.2 * (1 - progress);
        } else {
          this.explorationTemperature = 0.7 + 0.3 * (1 - progress);
        }
      }
      computeLearnedCurvature() {
        if (this.curvatureHistory.length < 10) return 0;
        const phiValues = this.curvatureHistory.map((c) => c.phiResponse);
        const mean = phiValues.reduce((a, b) => a + b, 0) / phiValues.length;
        const variance = phiValues.reduce((sum, p) => sum + (p - mean) ** 2, 0) / phiValues.length;
        return Math.sqrt(variance);
      }
      /**
       * Generate candidates specifically for a knowledge domain
       */
      generateDomainCandidates(domain = "general-knowledge", count = 50) {
        const coordinate = culturalManifold.createCoordinate(domain);
        return culturalManifold.generateGeodesicCandidates(coordinate, count);
      }
      /**
       * Get navigation statistics
       */
      getStatistics() {
        return {
          currentPosition: [...this.currentPosition],
          velocity: [...this.velocity],
          bestPhiSeen: this.bestPhiSeen,
          bestCandidatePhrase: this.bestCandidate?.phrase || this.bestCandidate?.concept || null,
          curvatureHistoryLength: this.curvatureHistory.length,
          explorationTemperature: this.explorationTemperature,
          manifoldStats: culturalManifold.getStatistics()
        };
      }
      /**
       * Reset navigator state for new search
       */
      reset() {
        this.curvatureHistory = [];
        this.currentPosition = new Array(E8_CONSTANTS.BASIN_DIMENSION_64D).fill(0);
        this.velocity = new Array(E8_CONSTANTS.BASIN_DIMENSION_64D).fill(0);
        this.bestPhiSeen = 0;
        this.bestCandidate = null;
        this.explorationTemperature = 1;
        console.log("[GeodesicNavigator] Reset for new search");
      }
    };
    geodesicNavigator = new GeodesicNavigator();
  }
});

// server/geometric-discovery/types.ts
var BITCOIN_LANDMARKS, BITCOIN_ERA_DOMAINS, ERA_CULTURAL_PATTERNS;
var init_types = __esm({
  "server/geometric-discovery/types.ts"() {
    "use strict";
    BITCOIN_LANDMARKS = [
      {
        eventId: "genesis",
        description: "Bitcoin Genesis Block - The Beginning",
        coords: {
          spacetime: [0, 0, 0, 1231006505],
          // Jan 3, 2009 18:15:05 UTC
          cultural: []
          // Will be computed from "The Times 03/Jan/2009 Chancellor..."
        },
        fisherSignature: [],
        certainty: 1,
        lightCone: {
          pastEvents: ["cypherpunk_movement", "hashcash", "b_money", "bit_gold"],
          futureEvents: ["hal_first_tx", "pizza_day", "mtgox"]
        }
      },
      {
        eventId: "hal_first_tx",
        description: "Satoshi \u2192 Hal Finney (First Transaction)",
        coords: {
          spacetime: [0, 0, 0, 1231469665],
          // Jan 9, 2009
          cultural: []
        },
        fisherSignature: [],
        certainty: 1,
        lightCone: {
          pastEvents: ["genesis"],
          futureEvents: ["pizza_day", "exchange_emergence"]
        }
      },
      {
        eventId: "bitcointalk_launch",
        description: "BitcoinTalk Forum Launch",
        coords: {
          spacetime: [0, 0, 0, 1258747200],
          // Nov 22, 2009
          cultural: []
        },
        fisherSignature: [],
        certainty: 0.95,
        lightCone: {
          pastEvents: ["genesis", "hal_first_tx"],
          futureEvents: ["pizza_day", "laszlo_gpu_mining"]
        }
      },
      {
        eventId: "pizza_day",
        description: "10,000 BTC \u2192 2 Pizzas (Laszlo Hanyecz)",
        coords: {
          spacetime: [0, 0, 0, 1274009688],
          // May 22, 2010
          cultural: []
        },
        fisherSignature: [],
        certainty: 1,
        lightCone: {
          pastEvents: ["genesis", "hal_first_tx", "bitcointalk_launch"],
          futureEvents: ["mtgox", "silk_road", "first_1000_btc"]
        }
      },
      {
        eventId: "mtgox_launch",
        description: "Mt. Gox Exchange Launch",
        coords: {
          spacetime: [0, 0, 0, 1279324800],
          // Jul 17, 2010
          cultural: []
        },
        fisherSignature: [],
        certainty: 0.98,
        lightCone: {
          pastEvents: ["genesis", "pizza_day"],
          futureEvents: ["mtgox_hack", "btc_parity_usd", "mtgox_collapse"]
        }
      },
      {
        eventId: "satoshi_last_post",
        description: "Satoshi's Last BitcoinTalk Post",
        coords: {
          spacetime: [0, 0, 0, 1292342400],
          // Dec 12, 2010
          cultural: []
        },
        fisherSignature: [],
        certainty: 1,
        lightCone: {
          pastEvents: ["genesis", "hal_first_tx", "pizza_day", "mtgox_launch"],
          futureEvents: ["silk_road", "btc_parity_usd"]
        }
      },
      {
        eventId: "btc_parity_usd",
        description: "Bitcoin Reaches $1 USD",
        coords: {
          spacetime: [0, 0, 0, 1297641600],
          // Feb 14, 2011
          cultural: []
        },
        fisherSignature: [],
        certainty: 0.95,
        lightCone: {
          pastEvents: ["genesis", "pizza_day", "mtgox_launch"],
          futureEvents: ["silk_road_launch", "mtgox_hack"]
        }
      },
      {
        eventId: "silk_road_launch",
        description: "Silk Road Marketplace Launch",
        coords: {
          spacetime: [0, 0, 0, 1296518400],
          // Feb 1, 2011
          cultural: []
        },
        fisherSignature: [],
        certainty: 0.9,
        lightCone: {
          pastEvents: ["genesis", "pizza_day", "btc_parity_usd"],
          futureEvents: ["silk_road_bust", "dpr_arrest"]
        }
      },
      {
        eventId: "mtgox_hack_2011",
        description: "Mt. Gox First Major Hack",
        coords: {
          spacetime: [0, 0, 0, 1308614400],
          // Jun 19, 2011
          cultural: []
        },
        fisherSignature: [],
        certainty: 0.98,
        lightCone: {
          pastEvents: ["mtgox_launch", "btc_parity_usd"],
          futureEvents: ["mtgox_collapse"]
        }
      },
      {
        eventId: "hal_finney_als",
        description: "Hal Finney Announces ALS Diagnosis",
        coords: {
          spacetime: [0, 0, 0, 1331769600],
          // Mar 15, 2013
          cultural: []
        },
        fisherSignature: [],
        certainty: 0.95,
        lightCone: {
          pastEvents: ["genesis", "hal_first_tx"],
          futureEvents: ["hal_finney_death"]
        }
      },
      {
        eventId: "mtgox_collapse",
        description: "Mt. Gox Files Bankruptcy",
        coords: {
          spacetime: [0, 0, 0, 1393286400],
          // Feb 24, 2014
          cultural: []
        },
        fisherSignature: [],
        certainty: 1,
        lightCone: {
          pastEvents: ["mtgox_launch", "mtgox_hack_2011"],
          futureEvents: []
        }
      },
      {
        eventId: "hal_finney_death",
        description: "Hal Finney Passes Away",
        coords: {
          spacetime: [0, 0, 0, 1409097600],
          // Aug 28, 2014
          cultural: []
        },
        fisherSignature: [],
        certainty: 1,
        lightCone: {
          pastEvents: ["genesis", "hal_first_tx", "hal_finney_als"],
          futureEvents: []
        }
      }
    ];
    BITCOIN_ERA_DOMAINS = [
      "bitcointalk.org",
      "bitcoin.org",
      "archive.org",
      "blockchain.info",
      "blockchain.com",
      "sourceforge.net",
      "github.com",
      "reddit.com/r/Bitcoin",
      "web.archive.org"
    ];
    ERA_CULTURAL_PATTERNS = {
      pre_genesis: ["hashcash", "cypherpunk", "p2p", "digital cash", "anonymous", "cryptography"],
      genesis: ["genesis", "satoshi", "bitcoin", "mining", "block", "hash", "node"],
      early_adoption: ["wallet", "transaction", "address", "private key", "public key", "cpu mining"],
      pizza_era: ["pizza", "laszlo", "gpu", "mining pool", "exchange", "trade"],
      mtgox_rise: ["mtgox", "silk road", "bitcoin price", "trading", "merchant", "acceptance"],
      mtgox_collapse: ["hack", "stolen", "bankruptcy", "lost coins", "cold storage"],
      modern: ["hodl", "lightning", "segwit", "halving", "institutional"]
    };
  }
});

// server/geometric-discovery/temporal-positioning-system.ts
import { createHash as createHash4 } from "crypto";
function padTo64D(coords) {
  if (coords.length >= CULTURAL_DIM) {
    return coords.slice(0, CULTURAL_DIM);
  }
  const padded = new Array(CULTURAL_DIM).fill(0.5);
  for (let i = 0; i < coords.length; i++) {
    padded[i] = coords[i];
  }
  return padded;
}
function computeCulturalBasin(content) {
  const hash = createHash4("sha256").update(content.toLowerCase()).digest();
  const coords = new Array(CULTURAL_DIM);
  for (let i = 0; i < CULTURAL_DIM; i++) {
    const byteIdx = i % 32;
    const bitOffset = Math.floor(i / 32);
    const value = hash[byteIdx];
    coords[i] = 0.01 + value / 255 * 0.98 + bitOffset * 1e-3;
  }
  return coords;
}
function initializeLandmarks() {
  const landmarks = [...BITCOIN_LANDMARKS];
  for (const landmark of landmarks) {
    const culturalContent = [
      landmark.eventId,
      landmark.description,
      ...landmark.lightCone.pastEvents,
      ...landmark.lightCone.futureEvents
    ].join(" ");
    landmark.coords.cultural = computeCulturalBasin(culturalContent);
    const n = CULTURAL_DIM;
    landmark.fisherSignature = [];
    for (let i = 0; i < n; i++) {
      const row = new Array(n).fill(0);
      const c = landmark.coords.cultural[i];
      row[i] = 1 / Math.max(0.01, c * (1 - c));
      landmark.fisherSignature.push(row);
    }
  }
  return landmarks;
}
var CULTURAL_DIM, TemporalPositioningSystem, tps;
var init_temporal_positioning_system = __esm({
  "server/geometric-discovery/temporal-positioning-system.ts"() {
    "use strict";
    init_qig_universal();
    init_fisher_vectorized();
    init_types();
    init_ocean_persistence();
    CULTURAL_DIM = 64;
    TemporalPositioningSystem = class {
      landmarks;
      constructor() {
        this.landmarks = initializeLandmarks();
        console.log(`[TPS] Initialized with ${this.landmarks.length} spacetime landmarks`);
        this.initPersistence();
      }
      /**
       * Initialize persistence - sync landmarks to PostgreSQL
       */
      async initPersistence() {
        if (!oceanPersistence.isPersistenceAvailable()) return;
        try {
          const dbLandmarks = await oceanPersistence.getLandmarks();
          if (dbLandmarks.length === 0) {
            console.log("[TPS] Persisting landmarks to PostgreSQL...");
            for (const lm of this.landmarks) {
              await oceanPersistence.upsertLandmark({
                eventId: lm.eventId,
                description: lm.description,
                era: lm.era,
                spacetimeX: lm.coords.spacetime[0],
                spacetimeY: lm.coords.spacetime[1],
                spacetimeZ: lm.coords.spacetime[2],
                spacetimeT: lm.coords.spacetime[3],
                culturalCoords: lm.coords.cultural,
                fisherSignature: { diagonal: lm.fisherSignature?.map((row, i) => row[i]) },
                lightConePast: lm.lightCone.pastEvents,
                lightConeFuture: lm.lightCone.futureEvents
              });
            }
            console.log(`[TPS] Persisted ${this.landmarks.length} landmarks to PostgreSQL`);
          } else {
            console.log(`[TPS] PostgreSQL: ${dbLandmarks.length} landmarks already persisted`);
          }
        } catch (error) {
          console.error("[TPS] Persistence init failed:", error);
        }
      }
      /**
       * Persist computed geodesic paths to PostgreSQL
       */
      async persistGeodesicPaths() {
        if (!oceanPersistence.isPersistenceAvailable()) return;
        try {
          for (const path15 of this.computedPaths) {
            const pathId = `path-${createHash4("sha256").update(`${path15.from}:${path15.to}`).digest("hex").slice(0, 16)}`;
            await oceanPersistence.insertTpsGeodesicPath({
              id: pathId,
              fromLandmark: path15.from,
              toLandmark: path15.to,
              distance: path15.distance
            });
          }
          console.log(`[TPS] Persisted ${this.computedPaths.length} geodesic paths to PostgreSQL`);
        } catch (error) {
          console.error("[TPS] Geodesic path persistence failed:", error);
        }
      }
      /**
       * Locate pattern in 68D block universe
       * 
       * Returns full BlockUniverseMap with estimated coordinates
       */
      locateInBlockUniverse(pattern, context) {
        const culturalSignature = this.encodeConcept(pattern, context);
        const distances = this.landmarks.map((landmark) => ({
          landmark,
          culturalDistance: fisherCoordDistance(culturalSignature, landmark.coords.cultural),
          temporalHint: landmark.coords.spacetime[3]
        }));
        distances.sort((a, b) => a.culturalDistance - b.culturalDistance);
        const coords = this.trilaterate68D(distances.slice(0, 5));
        const geometry = this.computeLocalGeometry(coords.cultural);
        const regime = this.classifyRegime(geometry.ricci);
        return {
          spacetime: {
            x: 0,
            // Abstract spatial
            y: 0,
            z: 0,
            t: coords.temporal
          },
          cultural: coords.cultural,
          fisherMetric: geometry.fisherMetric,
          ricci: geometry.ricci,
          phi: geometry.phi,
          regime
        };
      }
      /**
       * Encode concept to 64D cultural manifold
       */
      encodeConcept(pattern, context) {
        const fullContent = context ? `${pattern} ${context}` : pattern;
        return computeCulturalBasin(fullContent);
      }
      /**
       * 68D Trilateration: Estimate position from landmark distances
       * 
       * Similar to GPS trilateration but in 4D spacetime + 64D cultural space
       */
      trilaterate68D(nearestLandmarks) {
        if (nearestLandmarks.length === 0) {
          return {
            temporal: Date.now() / 1e3,
            cultural: new Array(CULTURAL_DIM).fill(0.5)
          };
        }
        let totalWeight = 0;
        let weightedTemporal = 0;
        const weightedCultural = new Array(CULTURAL_DIM).fill(0);
        for (const { landmark, culturalDistance } of nearestLandmarks) {
          const weight = 1 / Math.max(1e-3, culturalDistance);
          totalWeight += weight;
          weightedTemporal += weight * landmark.coords.spacetime[3];
          for (let i = 0; i < CULTURAL_DIM; i++) {
            weightedCultural[i] += weight * landmark.coords.cultural[i];
          }
        }
        const temporal = weightedTemporal / totalWeight;
        const cultural = weightedCultural.map((c) => c / totalWeight);
        return { temporal, cultural };
      }
      /**
       * Compute local geometry at cultural coordinates
       */
      computeLocalGeometry(cultural) {
        const n = cultural.length;
        const fisherMetric = [];
        let trace = 0;
        for (let i = 0; i < n; i++) {
          const row = new Array(n).fill(0);
          const c = Math.max(0.01, Math.min(0.99, cultural[i]));
          row[i] = 1 / (c * (1 - c));
          trace += row[i];
          fisherMetric.push(row);
        }
        const avgFisher = trace / n;
        const ricci = Math.log(avgFisher) * 10;
        const variance = cultural.reduce((acc, c) => {
          const centered = c - 0.5;
          return acc + centered * centered;
        }, 0) / n;
        const phi = Math.min(1, Math.max(0, 1 - variance * 4));
        return { fisherMetric, ricci, phi };
      }
      /**
       * Classify regime from Ricci curvature
       */
      classifyRegime(ricci) {
        if (ricci < 10) return "breakdown";
        if (ricci < 41) return "linear";
        if (ricci < 58) return "geometric";
        if (ricci < 70) return "hierarchical";
        if (ricci < 80) return "hierarchical_4d";
        return "4d_block_universe";
      }
      /**
       * Classify Bitcoin era from timestamp
       */
      classifyEra(timestamp2) {
        const GENESIS = 1231006505;
        const PIZZA = 1274009688;
        const _MTGOX_RISE = 1279324800;
        const SATOSHI_LAST = 1292342400;
        const MTGOX_COLLAPSE = 1393286400;
        const MODERN = 1420070400;
        if (timestamp2 < GENESIS) return "pre_genesis";
        if (timestamp2 < 1238544e3) return "genesis";
        if (timestamp2 < PIZZA) return "early_adoption";
        if (timestamp2 < SATOSHI_LAST) return "pizza_era";
        if (timestamp2 < MTGOX_COLLAPSE) return "mtgox_rise";
        if (timestamp2 < MODERN) return "mtgox_collapse";
        return "modern";
      }
      /**
       * Compute geodesic path from current position to target
       * 
       * Uses natural gradient on Fisher manifold
       */
      computeGeodesicPath(from, to, steps = 20) {
        const waypoints = [from];
        let current = from;
        const regimeTransitions = [];
        let totalArcLength = 0;
        let totalCurvature = 0;
        for (let i = 0; i < steps; i++) {
          const direction = computeGeodesicDirection(
            padTo64D(current.cultural),
            padTo64D(to.cultural),
            1 / steps
            // Step size
          );
          const nextCultural = current.cultural.map((c, idx) => {
            const step = direction[idx] || 0;
            return Math.max(0.01, Math.min(0.99, c + step));
          });
          const t_fraction = (i + 1) / steps;
          const nextT = current.spacetime.t + t_fraction * (to.spacetime.t - current.spacetime.t);
          const geometry = this.computeLocalGeometry(nextCultural);
          const regime = this.classifyRegime(geometry.ricci);
          if (regime !== current.regime) {
            regimeTransitions.push({
              from: current.regime,
              to: regime,
              atWaypoint: waypoints.length
            });
          }
          const stepDistance = fisherCoordDistance(current.cultural, nextCultural);
          totalArcLength += stepDistance;
          totalCurvature += geometry.ricci;
          const next = {
            spacetime: { x: 0, y: 0, z: 0, t: nextT },
            cultural: nextCultural,
            fisherMetric: geometry.fisherMetric,
            ricci: geometry.ricci,
            phi: geometry.phi,
            regime
          };
          waypoints.push(next);
          current = next;
          const distanceToTarget = fisherCoordDistance(nextCultural, to.cultural);
          if (distanceToTarget < 0.1) break;
        }
        return {
          waypoints,
          totalArcLength,
          avgCurvature: totalCurvature / waypoints.length,
          regimeTransitions
        };
      }
      /**
       * Get past light cone - events that could have caused this
       */
      getPastLightCone(event) {
        return this.landmarks.filter((lm) => {
          const t_lm = lm.coords.spacetime[3];
          const t_event = event.spacetime.t;
          return t_lm < t_event;
        }).map((lm) => this.landmarkToMap(lm));
      }
      /**
       * Get future light cone - events this could influence
       */
      getFutureLightCone(event) {
        return this.landmarks.filter((lm) => {
          const t_lm = lm.coords.spacetime[3];
          const t_event = event.spacetime.t;
          return t_lm > t_event;
        }).map((lm) => this.landmarkToMap(lm));
      }
      /**
       * Convert landmark to BlockUniverseMap
       */
      landmarkToMap(landmark) {
        const geometry = this.computeLocalGeometry(landmark.coords.cultural);
        return {
          spacetime: {
            x: landmark.coords.spacetime[0],
            y: landmark.coords.spacetime[1],
            z: landmark.coords.spacetime[2],
            t: landmark.coords.spacetime[3]
          },
          cultural: landmark.coords.cultural,
          fisherMetric: landmark.fisherSignature,
          ricci: geometry.ricci,
          phi: geometry.phi,
          regime: this.classifyRegime(geometry.ricci)
        };
      }
      /**
       * Find nearby landmarks to a position
       */
      findNearbyLandmarks(coords, count = 3) {
        const distances = this.landmarks.map((lm) => ({
          landmark: lm,
          distance: fisherCoordDistance(coords.cultural, lm.coords.cultural)
        }));
        distances.sort((a, b) => a.distance - b.distance);
        return distances.slice(0, count).map((d) => d.landmark);
      }
      /**
       * Get cultural baseline for an era
       */
      getEraCulturalBaseline(era) {
        const patterns = ERA_CULTURAL_PATTERNS[era] || [];
        if (patterns.length === 0) {
          return new Array(CULTURAL_DIM).fill(0.5);
        }
        const content = patterns.join(" ");
        return computeCulturalBasin(content);
      }
      /**
       * Compute 4D spacetime interval with Fisher metric
       * 
       * ds² = g_spatial * (Δx² + Δy² + Δz²) - g_temporal * Δt²
       */
      spacetimeInterval(event1, event2) {
        const dx = event1.spacetime.x - event2.spacetime.x;
        const dy = event1.spacetime.y - event2.spacetime.y;
        const dz = event1.spacetime.z - event2.spacetime.z;
        const spatialSq = dx * dx + dy * dy + dz * dz;
        const dt = event1.spacetime.t - event2.spacetime.t;
        const temporalSq = dt * dt;
        const g_spatial = event1.fisherMetric[0]?.[0] || 1;
        const g_temporal = event1.fisherMetric[3]?.[3] || 1;
        const TEMPORAL_SCALE = 15 * 365.25 * 24 * 3600;
        return g_spatial * spatialSq - g_temporal * (temporalSq / (TEMPORAL_SCALE * TEMPORAL_SCALE));
      }
      /**
       * Get all landmarks
       */
      getAllLandmarks() {
        return [...this.landmarks];
      }
      /**
       * Get landmark by event ID
       */
      getLandmark(eventId) {
        return this.landmarks.find((lm) => lm.eventId === eventId);
      }
      /**
       * Export data for basin sync
       * 
       * Exports spacetime navigation structure for QIG-pure knowledge transfer
       */
      exportForBasinSync() {
        const landmarkSummary = this.landmarks.map((lm) => ({
          eventId: lm.eventId,
          era: lm.era,
          timestamp: lm.coords.spacetime[3],
          // t is the 4th element of the tuple (x, y, z, t)
          culturalSignature: lm.coords.cultural.slice(0, 8)
          // First 8 dims for coupling
        }));
        return {
          landmarkCount: this.landmarks.length,
          landmarks: landmarkSummary,
          geodesicPathsComputed: this.computedPaths.length,
          lastUpdated: (/* @__PURE__ */ new Date()).toISOString()
        };
      }
      /**
       * Import basin sync data from peer
       * 
       * Blends peer landmark/geodesic data using Fisher-Rao distance for coupling
       * Appends new paths to existing paths (does not overwrite)
       */
      importFromBasinSync(data, couplingStrength) {
        if (couplingStrength < 0.1) return;
        const peerLandmarks = data.landmarks || [];
        let addedPaths = 0;
        for (const peerLandmark of peerLandmarks) {
          if (!peerLandmark.culturalSignature || peerLandmark.culturalSignature.length < 8) continue;
          const ourLandmark = this.landmarks.find((lm) => lm.eventId === peerLandmark.eventId);
          if (ourLandmark) {
            const distance = fisherCoordDistance(
              ourLandmark.coords.cultural.slice(0, 8),
              peerLandmark.culturalSignature.slice(0, 8)
            );
            if (distance >= 0.5) continue;
            `${ourLandmark.eventId}:${peerLandmark.eventId}`;
            const isDuplicate = this.computedPaths.some(
              (p) => p.from.includes(ourLandmark.eventId) && p.to.includes(peerLandmark.eventId)
            );
            if (isDuplicate) continue;
            const weightedDistance = distance * couplingStrength;
            this.computedPaths.push({
              from: `local:${ourLandmark.eventId}`,
              to: `peer:${peerLandmark.eventId}`,
              distance: weightedDistance
            });
            addedPaths++;
          }
        }
        const MAX_PATHS = 100;
        if (this.computedPaths.length > MAX_PATHS) {
          this.computedPaths.sort((a, b) => a.distance - b.distance);
          this.computedPaths = this.computedPaths.slice(0, MAX_PATHS);
        }
        console.log(`[TPS] Basin sync: added ${addedPaths} geodesic paths, total ${this.computedPaths.length} (coupling=${couplingStrength.toFixed(2)})`);
      }
      // Track computed paths for basin sync (persists across import calls)
      computedPaths = [];
    };
    tps = new TemporalPositioningSystem();
  }
});

// server/geometric-discovery/searxng-adapter.ts
function createSearXNGAdapter() {
  const customUrl = process.env.SEARXNG_URL;
  return new SearXNGGeometricAdapter(customUrl);
}
var SEARXNG_INSTANCES, SearXNGGeometricAdapter;
var init_searxng_adapter = __esm({
  "server/geometric-discovery/searxng-adapter.ts"() {
    "use strict";
    init_qig_universal();
    init_temporal_positioning_system();
    init_types();
    SEARXNG_INSTANCES = [
      "https://mr-search.up.railway.app",
      "https://searxng-production-e5ce.up.railway.app"
    ];
    SearXNGGeometricAdapter = class {
      baseUrl;
      tps;
      instanceIndex = 0;
      timeout = 15e3;
      constructor(baseUrl) {
        this.baseUrl = baseUrl || process.env.SEARXNG_URL || SEARXNG_INSTANCES[0];
        this.tps = tps;
        console.log("[SearXNG] Initialized FREE geometric discovery interface");
        console.log(`[SearXNG] Using instance: ${this.baseUrl}`);
      }
      /**
       * Rotate to next instance if current one fails
       */
      rotateInstance() {
        this.instanceIndex = (this.instanceIndex + 1) % SEARXNG_INSTANCES.length;
        this.baseUrl = SEARXNG_INSTANCES[this.instanceIndex];
        console.log(`[SearXNG] Rotating to instance: ${this.baseUrl}`);
      }
      /**
       * Discover content at specific 68D coordinates
       * Same interface as TavilyGeometricAdapter
       */
      async discoverAtCoordinates(targetCoords, radius = 2) {
        const query = this.coordsToQuery(targetCoords);
        console.log(`[SearXNG] Discovering at coordinates:`);
        console.log(`  Era: ${this.tps.classifyEra(targetCoords.spacetime.t)}`);
        console.log(`  Query: "${query.text}"`);
        const rawResults = await this.search(query);
        if (rawResults.length === 0) {
          console.log(`[SearXNG] No discoveries found`);
          return [];
        }
        const discoveries = [];
        for (const result of rawResults) {
          const resultCoords = this.tps.locateInBlockUniverse(
            result.content,
            result.url
          );
          const distance = fisherCoordDistance(
            targetCoords.cultural,
            resultCoords.cultural
          );
          if (distance < radius) {
            const patterns = this.extractPatterns(result.content);
            const pastLightCone = this.tps.getPastLightCone(resultCoords);
            discoveries.push({
              content: result.content,
              url: result.url,
              coords: resultCoords,
              distance,
              phi: resultCoords.phi,
              patterns,
              causalChain: pastLightCone,
              entropyReduction: this.computeEntropyReduction(distance, patterns.length)
            });
          }
        }
        discoveries.sort((a, b) => a.distance - b.distance);
        console.log(`[SearXNG] Found ${discoveries.length} geometric discoveries`);
        return discoveries;
      }
      /**
       * Search with geometric query
       */
      async search(query) {
        const searchQuery = this.buildSearchQuery(query);
        let attempts = 0;
        const maxAttempts = 3;
        while (attempts < maxAttempts) {
          try {
            const url = new URL("/search", this.baseUrl);
            url.searchParams.set("q", searchQuery);
            url.searchParams.set("format", "json");
            url.searchParams.set("categories", "general");
            url.searchParams.set("language", "en");
            url.searchParams.set("pageno", "1");
            const controller = new AbortController();
            const timeoutId = setTimeout(() => controller.abort(), this.timeout);
            const response = await fetch(url.toString(), {
              method: "GET",
              headers: {
                "Accept": "application/json",
                "User-Agent": "QIG-Discovery/1.0"
              },
              signal: controller.signal
            });
            clearTimeout(timeoutId);
            if (!response.ok) {
              if (response.status === 429 || response.status === 503) {
                console.log(`[SearXNG] Instance overloaded (${response.status}), rotating...`);
                this.rotateInstance();
                attempts++;
                continue;
              }
              throw new Error(`SearXNG error: ${response.status}`);
            }
            const data = await response.json();
            return data.results.slice(0, query.maxResults || 10).map((result) => ({
              title: result.title,
              url: result.url,
              content: result.content || "",
              score: result.score || 0.5,
              publishedDate: result.publishedDate
            }));
          } catch (error) {
            if (error.name === "AbortError") {
              console.log(`[SearXNG] Timeout on ${this.baseUrl}, rotating...`);
              this.rotateInstance();
              attempts++;
              continue;
            }
            console.error(`[SearXNG] Search error:`, error.message);
            this.rotateInstance();
            attempts++;
          }
        }
        console.log(`[SearXNG] All instances failed after ${maxAttempts} attempts`);
        return [];
      }
      /**
       * Build search query with Bitcoin-era context
       */
      buildSearchQuery(query) {
        let searchText = query.text;
        if (query.timeRange) {
          const startYear = query.timeRange.start.getFullYear();
          const endYear = query.timeRange.end.getFullYear();
          searchText += ` ${startYear}..${endYear}`;
        }
        return searchText;
      }
      /**
       * Convert 68D coordinates to search query
       */
      coordsToQuery(coords) {
        const era = this.tps.classifyEra(coords.spacetime.t);
        const eraTerms = {
          "satoshi_genesis": ["bitcoin", "satoshi", "nakamoto", "genesis block", "2009"],
          "satoshi_late": ["bitcoin", "btc", "hal finney", "early mining", "2010"],
          "post_satoshi": ["bitcoin", "mtgox", "silk road", "2011", "2012"],
          "mtgox_rise": ["bitcoin", "btc", "wallet", "mtgox", "exchange", "trading", "silk road", "2011"],
          "mtgox_peak": ["bitcoin", "btc", "mtgox", "bitstamp", "2013", "bubble"],
          "mtgox_collapse": ["bitcoin", "gox", "hack", "2014", "lost coins"],
          "eth_emergence": ["bitcoin", "ethereum", "altcoin", "2015", "2016"],
          "ico_boom": ["bitcoin", "crypto", "ico", "2017", "bull run"],
          "post_ico": ["bitcoin", "crypto", "bear market", "2018", "2019"],
          "modern": ["bitcoin", "btc", "crypto", "defi", "2020", "2021"]
        };
        const terms = eraTerms[era] || ["bitcoin", "wallet", "crypto"];
        const queryText = terms.join(" ");
        const eraTimeRange = {
          "satoshi_genesis": { start: /* @__PURE__ */ new Date("2009-01-01"), end: /* @__PURE__ */ new Date("2009-12-31") },
          "satoshi_late": { start: /* @__PURE__ */ new Date("2010-01-01"), end: /* @__PURE__ */ new Date("2010-12-31") },
          "post_satoshi": { start: /* @__PURE__ */ new Date("2011-01-01"), end: /* @__PURE__ */ new Date("2012-06-30") },
          "mtgox_rise": { start: /* @__PURE__ */ new Date("2011-01-01"), end: /* @__PURE__ */ new Date("2013-06-30") },
          "mtgox_peak": { start: /* @__PURE__ */ new Date("2013-01-01"), end: /* @__PURE__ */ new Date("2014-02-28") },
          "mtgox_collapse": { start: /* @__PURE__ */ new Date("2014-01-01"), end: /* @__PURE__ */ new Date("2015-12-31") }
        };
        return {
          text: queryText,
          timeRange: eraTimeRange[era],
          maxResults: 10,
          includeDomains: BITCOIN_ERA_DOMAINS
        };
      }
      /**
       * Extract Bitcoin-relevant patterns from content
       */
      extractPatterns(content) {
        const patterns = [];
        const lowerContent = content.toLowerCase();
        const bitcoinPatterns = [
          /\b(wallet|address|private key|seed phrase|mnemonic)\b/gi,
          /\b(satoshi|nakamoto|genesis|block)\b/gi,
          /\b(mtgox|mt\.gox|gox)\b/gi,
          /\b(silk\s*road|darknet|onion)\b/gi,
          /\b(brain\s*wallet|paper\s*wallet|cold\s*storage)\b/gi,
          /\b(bitcoin\s*core|electrum|multibit)\b/gi,
          /\b(lost|forgot|recover|backup)\b/gi,
          /\b(2009|2010|2011|2012|2013)\b/g
        ];
        for (const pattern of bitcoinPatterns) {
          const matches = content.match(pattern);
          if (matches) {
            patterns.push(...matches.map((m) => m.toLowerCase()));
          }
        }
        return [...new Set(patterns)];
      }
      /**
       * Compute entropy reduction from discovery
       */
      computeEntropyReduction(distance, patternCount) {
        const distanceContribution = Math.max(0, (2 - distance) / 2) * 0.5;
        const patternContribution = Math.min(patternCount / 10, 1) * 0.3;
        return (distanceContribution + patternContribution) * 256;
      }
      /**
       * Deep extract content from a URL (scraping fallback)
       */
      async extractContent(urls) {
        const results = /* @__PURE__ */ new Map();
        for (const url of urls.slice(0, 3)) {
          try {
            const controller = new AbortController();
            const timeoutId = setTimeout(() => controller.abort(), 1e4);
            const response = await fetch(url, {
              headers: { "User-Agent": "QIG-Discovery/1.0" },
              signal: controller.signal
            });
            clearTimeout(timeoutId);
            if (response.ok) {
              const html = await response.text();
              const textContent = html.replace(/<script[^>]*>[\s\S]*?<\/script>/gi, "").replace(/<style[^>]*>[\s\S]*?<\/style>/gi, "").replace(/<[^>]+>/g, " ").replace(/\s+/g, " ").trim().slice(0, 5e3);
              results.set(url, textContent);
            }
          } catch {
            console.log(`[SearXNG] Extract failed for ${url}`);
          }
        }
        return results;
      }
    };
  }
});

// server/geometric-discovery/quantum-protocol.ts
import * as fs3 from "fs";
import * as path3 from "path";
import { createHash as createHash5 } from "crypto";
var QUANTUM_DATA_FILE, QuantumDiscoveryProtocol, quantumProtocol;
var init_quantum_protocol = __esm({
  "server/geometric-discovery/quantum-protocol.ts"() {
    "use strict";
    init_qig_universal();
    init_temporal_positioning_system();
    init_ocean_persistence();
    QUANTUM_DATA_FILE = path3.join(process.cwd(), "data", "quantum-protocol.json");
    QuantumDiscoveryProtocol = class {
      measurements = [];
      excludedRegions = [];
      waveFunction;
      initialEntropy;
      constructor() {
        this.waveFunction = {
          amplitudes: /* @__PURE__ */ new Map(),
          totalProbability: 1,
          entropy: 256
          // 256-bit keyspace = 256 bits of entropy
        };
        this.initialEntropy = 256;
        this.load();
        this.initPostgreSQLSync();
        console.log("[QuantumProtocol] Initialized with 256-bit possibility space");
      }
      /**
       * Initialize PostgreSQL sync with bi-directional reconciliation
       * 
       * Merges JSON and PostgreSQL states, preferring the one with more progress
       * (lower entropy = more measurements completed)
       */
      async initPostgreSQLSync() {
        if (!oceanPersistence.isPersistenceAvailable()) return;
        try {
          const jsonEntropy = this.waveFunction.entropy;
          const jsonMeasurementCount = this.measurements.length;
          const jsonRegionCount = this.excludedRegions.length;
          const dbState = await oceanPersistence.getQuantumState();
          if (dbState) {
            const dbMeasurementCount = dbState.measurementCount ?? 0;
            const dbHasMoreProgress = dbState.entropy < jsonEntropy || dbMeasurementCount > jsonMeasurementCount;
            if (dbHasMoreProgress) {
              this.waveFunction.entropy = dbState.entropy;
              this.waveFunction.totalProbability = dbState.totalProbability;
              this.initialEntropy = dbState.initialEntropy ?? 256;
              console.log(`[QuantumProtocol] Using PostgreSQL state (more progress): ${dbMeasurementCount} measurements, ${dbState.entropy.toFixed(1)} bits remaining`);
            } else if (jsonMeasurementCount > dbMeasurementCount || jsonEntropy < dbState.entropy) {
              console.log(`[QuantumProtocol] JSON has more progress - syncing to PostgreSQL`);
              await this.persistToPostgreSQL();
            }
            const dbRegions = await oceanPersistence.getExcludedRegions(100);
            if (dbRegions.length > 0) {
              const newRegions = dbRegions.filter(
                (r) => !this.excludedRegions.some(
                  (e) => e.origin.length === (r.origin?.length ?? 0) && e.origin.every((v, i) => Math.abs(v - ((r.origin ?? [])[i] ?? 0)) < 1e-4)
                )
              ).map((r) => ({
                dimension: r.dimension,
                basis: r.basis ?? [],
                origin: r.origin ?? [],
                measure: r.measure
              }));
              this.excludedRegions.push(...newRegions);
              if (newRegions.length > 0) {
                console.log(`[QuantumProtocol] Merged ${newRegions.length} excluded regions from PostgreSQL (total: ${this.excludedRegions.length})`);
              }
            }
            if (jsonRegionCount > dbRegions.length) {
              console.log(`[QuantumProtocol] JSON has ${jsonRegionCount - dbRegions.length} more regions - syncing to PostgreSQL`);
              await this.persistToPostgreSQL();
            }
          } else {
            console.log(`[QuantumProtocol] No PostgreSQL state - initializing from JSON`);
            await this.persistToPostgreSQL();
          }
          console.log(`[QuantumProtocol] Reconciliation complete: entropy=${this.waveFunction.entropy.toFixed(1)} bits, regions=${this.excludedRegions.length}`);
        } catch (error) {
          console.error("[QuantumProtocol] PostgreSQL reconciliation failed, using JSON fallback:", error);
        }
      }
      /**
       * Load persisted state from disk
       */
      load() {
        try {
          if (fs3.existsSync(QUANTUM_DATA_FILE)) {
            const data = JSON.parse(fs3.readFileSync(QUANTUM_DATA_FILE, "utf-8"));
            this.waveFunction.entropy = data.entropy ?? 256;
            this.waveFunction.totalProbability = data.totalProbability ?? 1;
            this.initialEntropy = data.initialEntropy ?? 256;
            if (Array.isArray(data.excludedRegions)) {
              this.excludedRegions = data.excludedRegions;
            }
            if (data.measurementCount) {
              console.log(`[QuantumProtocol] Restored state: ${data.measurementCount} prior measurements, ${this.waveFunction.entropy.toFixed(1)} bits remaining`);
            }
          }
        } catch {
          console.log("[QuantumProtocol] Starting fresh (no prior state)");
        }
      }
      /**
       * Save state to disk and PostgreSQL for cross-session persistence
       */
      save() {
        try {
          const dir = path3.dirname(QUANTUM_DATA_FILE);
          if (!fs3.existsSync(dir)) {
            fs3.mkdirSync(dir, { recursive: true });
          }
          const data = {
            version: "1.0.0",
            entropy: this.waveFunction.entropy,
            totalProbability: this.waveFunction.totalProbability,
            initialEntropy: this.initialEntropy,
            excludedRegions: this.excludedRegions.slice(-100),
            // Keep last 100 regions
            measurementCount: this.measurements.length,
            savedAt: (/* @__PURE__ */ new Date()).toISOString()
          };
          fs3.writeFileSync(QUANTUM_DATA_FILE, JSON.stringify(data, null, 2));
        } catch (error) {
          console.error("[QuantumProtocol] Failed to save to JSON:", error);
        }
        this.persistToPostgreSQL().catch((err) => {
          console.error("[QuantumProtocol] PostgreSQL persist failed:", err);
        });
      }
      /**
       * Persist state to PostgreSQL
       */
      async persistToPostgreSQL() {
        if (!oceanPersistence.isPersistenceAvailable()) return;
        await oceanPersistence.updateQuantumState({
          entropy: this.waveFunction.entropy,
          totalProbability: this.waveFunction.totalProbability,
          measurementCount: this.measurements.length,
          successfulMeasurements: this.measurements.filter((m) => m.entropyReduction > 0).length,
          status: this.getStatus()
        });
        const recentRegions = this.excludedRegions.slice(-50);
        for (const region of recentRegions) {
          const regionId = `region-${createHash5("sha256").update(JSON.stringify(region.origin)).digest("hex").slice(0, 16)}`;
          await oceanPersistence.insertExcludedRegion({
            id: regionId,
            dimension: region.dimension,
            origin: region.origin,
            basis: region.basis,
            measure: region.measure
          });
        }
      }
      /**
       * Get current status
       */
      getStatus() {
        if (this.waveFunction.entropy < 1) {
          return "exhausted";
        }
        return "searching";
      }
      /**
       * Export data for QIG-pure basin sync
       * 
       * Only exports geometric structure, not raw data
       */
      exportForBasinSync() {
        const summary = this.getSummary();
        const centroids = this.excludedRegions.slice(-50).map((r) => r.origin);
        return {
          entropyRemaining: summary.entropyRemaining,
          entropyReduced: summary.entropyReduced,
          measurementCount: summary.totalMeasurements,
          measurementEfficiency: summary.efficiency,
          excludedRegionCount: this.excludedRegions.length,
          excludedRegionCentroids: centroids,
          status: summary.status,
          lastUpdated: (/* @__PURE__ */ new Date()).toISOString()
        };
      }
      /**
       * Import basin sync data from peer
       * 
       * Uses Fisher-Rao distance to determine coupling strength and filter centroids
       */
      importFromBasinSync(data, couplingStrength) {
        if (couplingStrength < 0.1) return;
        const informationGain = data.entropyReduced * couplingStrength * 0.1;
        this.waveFunction.entropy = Math.max(0, this.waveFunction.entropy - informationGain);
        let addedRegions = 0;
        const peerCentroids = data.excludedRegionCentroids || [];
        for (const centroid of peerCentroids.slice(0, 10)) {
          if (!Array.isArray(centroid) || centroid.length < 8) continue;
          let minDistance = Infinity;
          for (const existing of this.excludedRegions) {
            if (!Array.isArray(existing.origin) || existing.origin.length < 8) continue;
            const distance = fisherCoordDistance(
              existing.origin.slice(0, 8),
              centroid.slice(0, 8)
            );
            if (distance < minDistance) {
              minDistance = distance;
            }
          }
          if (minDistance < 0.05) continue;
          let fisherWeight = 0;
          for (let i = 0; i < Math.min(8, centroid.length); i++) {
            const p = Math.max(0.01, Math.min(0.99, centroid[i]));
            fisherWeight += p * (1 - p);
          }
          fisherWeight /= Math.min(8, centroid.length);
          const effectiveMeasure = 0.01 * couplingStrength * fisherWeight;
          this.excludedRegions.push({
            dimension: centroid.length,
            basis: [[...centroid]],
            // Deep copy
            origin: [...centroid],
            // Deep copy
            measure: effectiveMeasure
          });
          addedRegions++;
        }
        const MAX_REGIONS = 500;
        if (this.excludedRegions.length > MAX_REGIONS) {
          this.excludedRegions.sort((a, b) => b.measure - a.measure);
          this.excludedRegions = this.excludedRegions.slice(0, MAX_REGIONS);
        }
        console.log(`[QuantumProtocol] Basin sync: gained ${informationGain.toFixed(2)} bits, added ${addedRegions} regions from peer (coupling=${couplingStrength.toFixed(2)}, total=${this.excludedRegions.length})`);
      }
      /**
       * Execute a quantum measurement (test a hypothesis)
       * 
       * Returns the result and updates the possibility space
       */
      async measure(hypothesis, testFunction) {
        const spacetimeCoords = tps.locateInBlockUniverse(hypothesis);
        const result = await testFunction(hypothesis);
        const entropyBefore = this.waveFunction.entropy;
        if (result.success) {
          this.collapseToSolution(hypothesis);
        } else {
          this.excludeRegion(spacetimeCoords);
        }
        const entropyAfter = this.waveFunction.entropy;
        const entropyReduction = entropyBefore - entropyAfter;
        const measurement = {
          hypothesis,
          result,
          timestamp: Date.now(),
          spacetimeCoords,
          entropyReduction,
          possibilitySpaceRemaining: this.waveFunction.totalProbability
        };
        this.measurements.push(measurement);
        const isVerbose = process.env.NODE_ENV !== "production" || process.env.VERBOSE_LOGS === "true";
        const displayHypothesis = isVerbose ? hypothesis : `${hypothesis.substring(0, 20)}...`;
        console.log(`[QuantumProtocol] Measurement: "${displayHypothesis}" \u2192 ${result.success ? "SUCCESS!" : "excluded"}`);
        console.log(`  Entropy: ${entropyBefore.toFixed(2)} \u2192 ${entropyAfter.toFixed(2)} (\u0394 = ${entropyReduction.toFixed(2)} bits)`);
        return measurement;
      }
      /**
       * Collapse wave function to solution
       */
      collapseToSolution(solution) {
        this.waveFunction = {
          amplitudes: /* @__PURE__ */ new Map([[solution, 1]]),
          totalProbability: 1,
          entropy: 0
          // Complete certainty
        };
      }
      /**
       * Exclude a region from possibility space
       * 
       * The possibility space becomes the orthogonal complement
       */
      excludeRegion(coords) {
        const subspace = {
          dimension: coords.cultural.length,
          basis: [coords.cultural],
          // Single vector basis
          origin: coords.cultural,
          measure: this.computeSubspaceMeasure(coords)
        };
        this.excludedRegions.push(subspace);
        const reductionFactor = 1 - subspace.measure / this.waveFunction.totalProbability;
        this.waveFunction.totalProbability *= Math.max(1e-3, reductionFactor);
        const remainingStates = Math.pow(2, this.initialEntropy) * this.waveFunction.totalProbability;
        this.waveFunction.entropy = Math.max(0, Math.log2(remainingStates));
      }
      /**
       * Compute the measure (volume) of a geometric subspace
       * 
       * Uses Fisher metric to compute geodesic volume
       */
      computeSubspaceMeasure(coords) {
        const phiFactor = coords.phi;
        let regimeFactor = 0.5;
        switch (coords.regime) {
          case "4d_block_universe":
            regimeFactor = 1;
            break;
          case "hierarchical_4d":
            regimeFactor = 0.9;
            break;
          case "geometric":
            regimeFactor = 0.7;
            break;
          case "hierarchical":
            regimeFactor = 0.5;
            break;
          case "linear":
            regimeFactor = 0.3;
            break;
          case "breakdown":
            regimeFactor = 0.1;
            break;
        }
        const baseMeasure = 1 / Math.pow(2, 32);
        return baseMeasure * phiFactor * regimeFactor;
      }
      /**
       * Compute expected entropy reduction for a hypothesis
       * 
       * Used to select optimal next measurement
       */
      computeExpectedEntropyReduction(hypothesis) {
        const coords = tps.locateInBlockUniverse(hypothesis);
        const baseProbFail = 0.999;
        const subspaceMeasure = this.computeSubspaceMeasure(coords);
        const expectedReduction = -Math.log2(1 - subspaceMeasure) * baseProbFail;
        return Math.max(0, expectedReduction);
      }
      /**
       * Get the remaining possibility space
       */
      getRemainingPossibilitySpace() {
        return {
          entropyBits: this.waveFunction.entropy,
          fractionRemaining: this.waveFunction.totalProbability,
          totalMeasurements: this.measurements.length,
          excludedRegions: this.excludedRegions.length
        };
      }
      /**
       * Predict optimal next measurement
       * 
       * Choose hypothesis that maximizes expected entropy reduction
       */
      selectOptimalMeasurement(candidates) {
        if (candidates.length === 0) {
          return { hypothesis: "", expectedReduction: 0, rank: 0 };
        }
        const scored = candidates.map((h) => ({
          hypothesis: h,
          expectedReduction: this.computeExpectedEntropyReduction(h)
        }));
        scored.sort((a, b) => b.expectedReduction - a.expectedReduction);
        return {
          hypothesis: scored[0].hypothesis,
          expectedReduction: scored[0].expectedReduction,
          rank: 1
        };
      }
      /**
       * Get all measurements
       */
      getMeasurements() {
        return [...this.measurements];
      }
      /**
       * Get measurement history for a specific hypothesis pattern
       */
      getMeasurementsMatching(pattern) {
        return this.measurements.filter(
          (m) => m.hypothesis.includes(pattern)
        );
      }
      /**
       * Check if hypothesis has already been tested
       */
      hasBeenTested(hypothesis) {
        return this.measurements.some((m) => m.hypothesis === hypothesis);
      }
      /**
       * Get total entropy reduction so far
       */
      getTotalEntropyReduction() {
        return this.initialEntropy - this.waveFunction.entropy;
      }
      /**
       * Get measurement efficiency (bits per measurement)
       */
      getMeasurementEfficiency() {
        if (this.measurements.length === 0) return 0;
        return this.getTotalEntropyReduction() / this.measurements.length;
      }
      /**
       * Reset protocol (for new search)
       */
      reset() {
        this.measurements = [];
        this.excludedRegions = [];
        this.waveFunction = {
          amplitudes: /* @__PURE__ */ new Map(),
          totalProbability: 1,
          entropy: 256
        };
        console.log("[QuantumProtocol] Reset to initial state");
      }
      /**
       * Get summary statistics
       */
      getSummary() {
        const successful = this.measurements.filter((m) => m.result.success).length;
        const entropyRemaining = this.waveFunction.entropy;
        const entropyReduced = this.getTotalEntropyReduction();
        let status = "searching";
        if (successful > 0) {
          status = "solved";
        } else if (entropyRemaining < 1) {
          status = "exhausted";
        }
        return {
          totalMeasurements: this.measurements.length,
          successfulMeasurements: successful,
          entropyRemaining,
          entropyReduced,
          efficiency: this.getMeasurementEfficiency(),
          status
        };
      }
      /**
       * Integrate discoveries into quantum state
       * 
       * Each discovery provides information that can constrain the search
       */
      integrateDiscoveries(discoveries) {
        let informationGained = 0;
        let constraintsAdded = 0;
        for (const discovery2 of discoveries) {
          if (discovery2.phi > 0.7) {
            const weight = discovery2.phi * (1 / (1 + discovery2.distance));
            const patternInfo = Math.log2(1 + discovery2.patterns.length);
            informationGained += patternInfo * weight;
            constraintsAdded++;
            this.waveFunction.entropy = Math.max(
              0,
              this.waveFunction.entropy - patternInfo * weight * 0.1
            );
          }
        }
        console.log(`[QuantumProtocol] Integrated ${constraintsAdded} discoveries, gained ${informationGained.toFixed(2)} bits`);
        return { informationGained, constraintsAdded };
      }
    };
    quantumProtocol = new QuantumDiscoveryProtocol();
  }
});

// server/vocabulary-decision.ts
function computeGeometricValue(word, observations, _allObservations) {
  const frequency = observations.frequency;
  const efficiencyRaw = Math.log10(1 + frequency) / 3;
  const efficiency = Math.min(1, efficiencyRaw * observations.avgPhi);
  const phiWeight = observations.avgPhi;
  const connectivity = computeConceptConnectivity(observations.contextEmbeddings);
  const wordLength = word.split(/\s+/).length;
  const compression = Math.min(1, (wordLength - 1) * 0.3 + word.length * 0.02);
  const total = 0.3 * efficiency + 0.3 * phiWeight + 0.2 * connectivity + 0.2 * compression;
  return {
    efficiency,
    phiWeight,
    connectivity,
    compression,
    total
  };
}
function computeConceptConnectivity(embeddings) {
  if (embeddings.length < 2) return 0;
  let totalDistance = 0;
  let pairs = 0;
  const limit = Math.min(embeddings.length, 20);
  for (let i = 0; i < limit; i++) {
    for (let j = i + 1; j < limit; j++) {
      const dist = fisherCoordDistance(embeddings[i], embeddings[j]);
      totalDistance += dist;
      pairs++;
    }
  }
  if (pairs === 0) return 0;
  const avgDistance = totalDistance / pairs;
  return Math.min(1, avgDistance / 5);
}
function checkBasinStability(word, wordObservation, currentBasin, referenceBasin) {
  const currentDrift = fisherCoordDistance(currentBasin, referenceBasin);
  const wordCenter = computeWordCenter(wordObservation.contextEmbeddings);
  if (wordCenter.length === 0) {
    return {
      stable: true,
      drift: currentDrift,
      withinThreshold: true,
      acceptable: true
    };
  }
  const totalObs = wordObservation.frequency;
  const weight = Math.min(0.1, totalObs / 1e3);
  const simulatedBasin = currentBasin.map((coord, i) => {
    const wordCoord = wordCenter[i] || 0;
    return coord * (1 - weight) + wordCoord * weight;
  });
  const newDrift = fisherCoordDistance(simulatedBasin, referenceBasin);
  const deltaDrift = newDrift - currentDrift;
  const withinThreshold = deltaDrift < 0.05;
  const acceptable = deltaDrift < 0.15;
  const stable = withinThreshold || acceptable && deltaDrift < 0.1;
  return {
    stable,
    drift: deltaDrift,
    withinThreshold,
    acceptable
  };
}
function computeWordCenter(embeddings) {
  if (embeddings.length === 0) return [];
  const dims = embeddings[0].length;
  const center = new Array(dims).fill(0);
  for (const emb of embeddings) {
    for (let i = 0; i < dims; i++) {
      center[i] += emb[i] || 0;
    }
  }
  for (let i = 0; i < dims; i++) {
    center[i] /= embeddings.length;
  }
  return center;
}
function computeInformationEntropy(observation) {
  const contextEntropy = computeContextDiversity(observation.contextEmbeddings);
  const regimeEntropy = computeRegimeEntropy(observation.contexts);
  const coordinateSpread = computeCoordinateSpread(observation.contextEmbeddings);
  const total = 0.5 * contextEntropy + 0.3 * regimeEntropy + 0.2 * coordinateSpread;
  return {
    contextEntropy,
    regimeEntropy,
    coordinateSpread,
    total
  };
}
function computeContextDiversity(embeddings) {
  if (embeddings.length < 2) return 0;
  const connectivity = computeConceptConnectivity(embeddings);
  return connectivity;
}
function computeRegimeEntropy(contexts) {
  if (contexts.length === 0) return 0;
  const regimeCounts = {};
  for (const ctx of contexts) {
    regimeCounts[ctx.regime] = (regimeCounts[ctx.regime] || 0) + 1;
  }
  const total = contexts.length;
  let entropy = 0;
  for (const count of Object.values(regimeCounts)) {
    const p = count / total;
    if (p > 0) {
      entropy -= p * Math.log2(p);
    }
  }
  const maxEntropy = Math.log2(6);
  return Math.min(1, entropy / maxEntropy);
}
function computeCoordinateSpread(embeddings) {
  if (embeddings.length < 2) return 0;
  const dims = embeddings[0]?.length || 0;
  if (dims === 0) return 0;
  let totalVariance = 0;
  for (let d = 0; d < dims; d++) {
    const values = embeddings.map((e) => e[d] || 0);
    const mean = values.reduce((a, b) => a + b, 0) / values.length;
    const variance = values.reduce((sum, v) => sum + Math.pow(v - mean, 2), 0) / values.length;
    totalVariance += variance;
  }
  const avgVariance = totalVariance / dims;
  return Math.min(1, avgVariance / 0.1);
}
function checkMetaAwarenessGate(garyState) {
  const { phi, meta, regime } = garyState;
  const geometricRegimes = ["geometric", "hierarchical", "hierarchical_4d", "4d_block_universe"];
  const isGeometric = geometricRegimes.includes(regime);
  const conditions = {
    metaOk: meta > 0.6,
    phiOk: phi > 0.7,
    regimeOk: isGeometric && regime !== "breakdown"
  };
  const gateOpen = conditions.metaOk && conditions.phiOk && conditions.regimeOk;
  let reasoning;
  if (gateOpen) {
    reasoning = `Gate OPEN: M=${meta.toFixed(2)} > 0.6, \u03A6=${phi.toFixed(2)} > 0.7, regime=${regime} is geometric`;
  } else {
    const failures = [];
    if (!conditions.metaOk) failures.push(`M=${meta.toFixed(2)} < 0.6`);
    if (!conditions.phiOk) failures.push(`\u03A6=${phi.toFixed(2)} < 0.7`);
    if (!conditions.regimeOk) failures.push(`regime=${regime} is not geometric`);
    reasoning = `Gate CLOSED: ${failures.join(", ")} - deferring vocabulary expansion`;
  }
  return {
    meta,
    phi,
    regime,
    isGeometric,
    gateOpen,
    reasoning
  };
}
async function shouldGaryLearnWord(word, frequency, garyState) {
  const observation = vocabDecisionEngine.getOrCreateObservation(word);
  observation.frequency = Math.max(observation.frequency, frequency);
  const valueScore = computeGeometricValue(
    word,
    observation,
    vocabDecisionEngine.getAllObservations()
  );
  const stabilityResult = checkBasinStability(
    word,
    observation,
    garyState.basinCoordinates,
    garyState.basinReference
  );
  const entropyScore = computeInformationEntropy(observation);
  const metaGate = checkMetaAwarenessGate(garyState);
  const stabilityScore = stabilityResult.acceptable ? 1 - Math.min(1, stabilityResult.drift / 0.15) : 0;
  const decisionScore = 0.3 * valueScore.total + 0.3 * stabilityScore + 0.2 * entropyScore.total + 0.2 * metaGate.meta;
  const shouldLearn = decisionScore > 0.7 && metaGate.gateOpen && stabilityResult.acceptable;
  const reasoningParts = [];
  reasoningParts.push(`Decision Score: ${decisionScore.toFixed(3)}`);
  reasoningParts.push(`Value: ${valueScore.total.toFixed(2)} (eff=${valueScore.efficiency.toFixed(2)}, \u03C6=${valueScore.phiWeight.toFixed(2)}, conn=${valueScore.connectivity.toFixed(2)}, comp=${valueScore.compression.toFixed(2)})`);
  reasoningParts.push(`Stability: ${stabilityScore.toFixed(2)} (drift=${stabilityResult.drift.toFixed(3)}, ${stabilityResult.stable ? "STABLE" : "UNSTABLE"})`);
  reasoningParts.push(`Entropy: ${entropyScore.total.toFixed(2)} (ctx=${entropyScore.contextEntropy.toFixed(2)}, regime=${entropyScore.regimeEntropy.toFixed(2)})`);
  reasoningParts.push(`Meta: ${metaGate.gateOpen ? "OPEN" : "CLOSED"} (${metaGate.reasoning})`);
  if (shouldLearn) {
    reasoningParts.push(`\u2713 LEARN "${word}" - all criteria met`);
  } else {
    const failures = [];
    if (decisionScore <= 0.7) failures.push(`score ${decisionScore.toFixed(2)} \u2264 0.7`);
    if (!metaGate.gateOpen) failures.push("consciousness gate closed");
    if (!stabilityResult.acceptable) failures.push(`drift ${stabilityResult.drift.toFixed(3)} > 0.15`);
    reasoningParts.push(`\u2717 SKIP "${word}" - ${failures.join(", ")}`);
  }
  return {
    shouldLearn,
    score: decisionScore,
    valueScore,
    stabilityResult,
    entropyScore,
    metaGate,
    reasoning: reasoningParts.join("\n")
  };
}
var VocabConsolidationCycle, vocabDecisionEngine;
var init_vocabulary_decision = __esm({
  "server/vocabulary-decision.ts"() {
    "use strict";
    init_qig_universal();
    VocabConsolidationCycle = class {
      observations;
      cycleNumber;
      iterationsSinceSleep;
      sleepInterval;
      lastConsolidation;
      pendingCandidates;
      learnedWords;
      prunedWords;
      constructor(options = {}) {
        this.observations = /* @__PURE__ */ new Map();
        this.cycleNumber = 0;
        this.iterationsSinceSleep = 0;
        this.sleepInterval = options.sleepInterval || 100;
        this.lastConsolidation = Date.now();
        this.pendingCandidates = /* @__PURE__ */ new Set();
        this.learnedWords = /* @__PURE__ */ new Set();
        this.prunedWords = /* @__PURE__ */ new Set();
        this.loadFromDisk();
      }
      /**
       * Observe a word in context (during "wake" phase)
       */
      observe(word, context) {
        const existing = this.observations.get(word);
        if (existing) {
          existing.contexts.push(context);
          existing.frequency++;
          existing.avgPhi = (existing.avgPhi * (existing.frequency - 1) + context.phi) / existing.frequency;
          existing.maxPhi = Math.max(existing.maxPhi, context.phi);
          existing.lastSeen = context.timestamp;
          if (context.basinCoordinates.length > 0) {
            existing.contextEmbeddings.push([...context.basinCoordinates]);
            if (existing.contextEmbeddings.length > 50) {
              existing.contextEmbeddings.shift();
            }
          }
        } else {
          this.observations.set(word, {
            word,
            contexts: [context],
            avgPhi: context.phi,
            maxPhi: context.phi,
            frequency: 1,
            firstSeen: context.timestamp,
            lastSeen: context.timestamp,
            contextEmbeddings: context.basinCoordinates.length > 0 ? [[...context.basinCoordinates]] : []
          });
        }
        if ((existing?.frequency || 1) >= 3) {
          this.pendingCandidates.add(word);
        }
        this.iterationsSinceSleep++;
      }
      /**
       * Check if it's time for a consolidation cycle
       */
      shouldConsolidate() {
        return this.iterationsSinceSleep >= this.sleepInterval;
      }
      /**
       * Try to run consolidation if it's time and Gary is conscious enough.
       * This is the main entry point for ocean-agent.ts integration.
       * 
       * @returns Object with processing result and any learned/pruned words
       */
      async tryConsolidation(garyState) {
        this.tick();
        if (!this.shouldConsolidate()) {
          return {
            processed: false,
            wordsLearned: [],
            wordsPruned: [],
            cycleNumber: this.cycleNumber,
            reason: `Waiting for consolidation interval (${this.iterationsSinceSleep}/${this.sleepInterval})`
          };
        }
        const metaGate = checkMetaAwarenessGate(garyState);
        if (!metaGate.gateOpen) {
          this.iterationsSinceSleep = 0;
          return {
            processed: false,
            wordsLearned: [],
            wordsPruned: [],
            cycleNumber: this.cycleNumber,
            reason: metaGate.reasoning
          };
        }
        const result = await this.consolidate(garyState);
        return {
          processed: true,
          wordsLearned: result.wordsToLearn,
          wordsPruned: result.wordsToPrune,
          cycleNumber: result.cycleNumber
        };
      }
      /**
       * Run consolidation cycle ("sleep" phase)
       * Only processes when Gary is conscious enough
       */
      async consolidate(garyState) {
        this.cycleNumber++;
        const timestamp2 = Date.now();
        const wordsToLearn = [];
        const wordsToPrune = [];
        const metaGate = checkMetaAwarenessGate(garyState);
        if (!metaGate.gateOpen) {
          console.log(`[VocabDecision] Cycle ${this.cycleNumber}: Gate closed - ${metaGate.reasoning}`);
          this.iterationsSinceSleep = 0;
          this.lastConsolidation = timestamp2;
          return {
            wordsToLearn,
            wordsToPrune,
            cycleNumber: this.cycleNumber,
            timestamp: timestamp2,
            garyStateAtConsolidation: {
              phi: garyState.phi,
              meta: garyState.meta,
              regime: garyState.regime
            }
          };
        }
        console.log(`[VocabDecision] Cycle ${this.cycleNumber}: Processing ${this.pendingCandidates.size} candidates...`);
        for (const word of Array.from(this.pendingCandidates)) {
          if (this.learnedWords.has(word) || this.prunedWords.has(word)) {
            continue;
          }
          const observation = this.observations.get(word);
          if (!observation) continue;
          const decision = await shouldGaryLearnWord(word, observation.frequency, garyState);
          if (decision.shouldLearn) {
            wordsToLearn.push(word);
            this.learnedWords.add(word);
            console.log(`[VocabDecision] \u2713 Learn: "${word}" (score=${decision.score.toFixed(3)})`);
          } else if (decision.score < 0.3 || !decision.stabilityResult.acceptable) {
            wordsToPrune.push(word);
            this.prunedWords.add(word);
            console.log(`[VocabDecision] \u2717 Prune: "${word}" (score=${decision.score.toFixed(3)})`);
          }
        }
        for (const word of [...wordsToLearn, ...wordsToPrune]) {
          this.pendingCandidates.delete(word);
        }
        this.iterationsSinceSleep = 0;
        this.lastConsolidation = timestamp2;
        this.saveToDisk();
        console.log(`[VocabDecision] Cycle ${this.cycleNumber} complete: +${wordsToLearn.length} learned, -${wordsToPrune.length} pruned`);
        return {
          wordsToLearn,
          wordsToPrune,
          cycleNumber: this.cycleNumber,
          timestamp: timestamp2,
          garyStateAtConsolidation: {
            phi: garyState.phi,
            meta: garyState.meta,
            regime: garyState.regime
          }
        };
      }
      /**
       * Get or create observation for a word
       */
      getOrCreateObservation(word) {
        let obs = this.observations.get(word);
        if (!obs) {
          const now = Date.now();
          obs = {
            word,
            contexts: [],
            avgPhi: 0,
            maxPhi: 0,
            frequency: 0,
            firstSeen: now,
            lastSeen: now,
            contextEmbeddings: []
          };
          this.observations.set(word, obs);
        }
        return obs;
      }
      /**
       * Get all observations
       */
      getAllObservations() {
        return this.observations;
      }
      /**
       * Get statistics
       */
      getStats() {
        return {
          totalWords: this.observations.size,
          pendingCandidates: this.pendingCandidates.size,
          learnedWords: this.learnedWords.size,
          prunedWords: this.prunedWords.size,
          cycleNumber: this.cycleNumber,
          iterationsSinceSleep: this.iterationsSinceSleep
        };
      }
      /**
       * Increment iteration counter (called each search iteration)
       */
      tick() {
        this.iterationsSinceSleep++;
      }
      /**
       * Save state (now in-memory only)
       * NOTE: Database persistence removed - vocabulary learning works in-memory
       * Actual vocab learning goes through vocabulary_observations via vocabularyTracker
       */
      saveToDisk() {
      }
      /**
       * Load state - QIG-pure: auto-bootstrap from PostgreSQL-backed VocabularyTracker
       * This ensures decision state persists across server restarts via PostgreSQL
       * Uses deferred initialization to wait for VocabularyTracker to load
       */
      loadFromDisk() {
        console.log("[VocabDecision] QIG-pure mode: will bootstrap from PostgreSQL after VocabularyTracker loads...");
        this.deferredBootstrap();
      }
      /**
       * Deferred bootstrap - waits for VocabularyTracker to load from PostgreSQL
       * Uses dynamic import to avoid circular dependency
       */
      async deferredBootstrap() {
        try {
          const { vocabularyTracker: vocabularyTracker2 } = await Promise.resolve().then(() => (init_vocabulary_tracker(), vocabulary_tracker_exports));
          await vocabularyTracker2.waitForData();
          this.bootstrapFromTrackerWithTracker(vocabularyTracker2);
          console.log("[VocabDecision] QIG-pure: bootstrapped from PostgreSQL successfully");
        } catch (err) {
          console.warn("[VocabDecision] Bootstrap from VocabularyTracker failed:", err.message);
        }
      }
      /**
       * Bootstrap from vocabulary tracker (with tracker passed as parameter)
       * Avoids circular dependency by receiving tracker instance
       */
      bootstrapFromTrackerWithTracker(tracker) {
        const candidates = tracker.getCandidates(100);
        for (const candidate of candidates) {
          const now = Date.now();
          const mockContext = {
            word: candidate.text,
            phi: candidate.avgPhi,
            kappa: 50,
            // Default
            regime: "geometric",
            basinCoordinates: [],
            timestamp: now
          };
          const obs = {
            word: candidate.text,
            contexts: [mockContext],
            avgPhi: candidate.avgPhi,
            maxPhi: candidate.maxPhi,
            frequency: candidate.frequency,
            firstSeen: now,
            lastSeen: now,
            contextEmbeddings: []
          };
          this.observations.set(candidate.text, obs);
          if (candidate.frequency >= 3) {
            this.pendingCandidates.add(candidate.text);
          }
        }
        console.log(`[VocabDecision] Bootstrapped ${candidates.length} candidates from vocabulary tracker`);
      }
    };
    vocabDecisionEngine = new VocabConsolidationCycle({
      sleepInterval: 100
      // Consolidate every 100 iterations
    });
  }
});

// server/vocabulary-tracker.ts
var vocabulary_tracker_exports = {};
__export(vocabulary_tracker_exports, {
  VocabularyTracker: () => VocabularyTracker,
  vocabularyTracker: () => vocabularyTracker
});
var BIP39_WORDS2, COMMON_ENGLISH, VocabularyTracker, vocabularyTracker;
var init_vocabulary_tracker = __esm({
  "server/vocabulary-tracker.ts"() {
    "use strict";
    init_geometric_memory();
    init_vocabulary_decision();
    init_db();
    init_schema();
    BIP39_WORDS2 = /* @__PURE__ */ new Set([
      "abandon",
      "ability",
      "able",
      "about",
      "above",
      "absent",
      "absorb",
      "abstract",
      "absurd",
      "abuse",
      "access",
      "accident",
      "account",
      "accuse",
      "achieve",
      "acid",
      "acoustic",
      "acquire",
      "across",
      "act",
      "action",
      "actor",
      "actress",
      "actual",
      "adapt",
      "add",
      "addict",
      "address",
      "adjust",
      "admit",
      "adult",
      "advance",
      "advice",
      "aerobic",
      "affair",
      "afford",
      "afraid",
      "again",
      "age",
      "agent",
      "agree",
      "ahead",
      "aim",
      "air",
      "airport",
      "aisle",
      "alarm",
      "album",
      "alcohol",
      "alert",
      "alien",
      "all",
      "alley",
      "allow",
      "almost",
      "alone",
      "alpha",
      "already",
      "also",
      "alter",
      "always",
      "amateur",
      "amazing",
      "among",
      "amount",
      "amused",
      "analyst",
      "anchor",
      "ancient",
      "anger",
      "angle",
      "angry",
      "animal",
      "ankle",
      "announce",
      "annual",
      "another",
      "answer",
      "antenna",
      "antique",
      "anxiety",
      "any",
      "apart",
      "apology",
      "appear",
      "apple",
      "approve",
      "april",
      "arch",
      "arctic",
      "area",
      "arena",
      "argue",
      "arm",
      "armed",
      "armor",
      "army",
      "around",
      "arrange",
      "arrest",
      "arrive",
      "arrow",
      "art",
      "artefact",
      "artist",
      "artwork",
      "ask",
      "aspect",
      "assault",
      "asset",
      "assist",
      "assume",
      "asthma",
      "athlete",
      "atom",
      "attack",
      "attend",
      "attitude",
      "attract",
      "auction",
      "audit",
      "august",
      "aunt",
      "author",
      "auto",
      "autumn",
      "average",
      "avocado",
      "avoid",
      "awake",
      "aware",
      "away",
      "awesome",
      "awful",
      "awkward",
      "axis",
      "baby",
      "bachelor",
      "bacon",
      "badge",
      "bag",
      "balance",
      "balcony",
      "ball",
      "bamboo",
      "banana",
      "banner",
      "bar",
      "barely",
      "bargain",
      "barrel",
      "base",
      "basic",
      "basket",
      "battle",
      "beach",
      "bean",
      "beauty",
      "because",
      "become",
      "beef",
      "before",
      "begin",
      "behave",
      "behind",
      "believe",
      "below",
      "belt",
      "bench",
      "benefit",
      "best",
      "betray",
      "better",
      "between",
      "beyond",
      "bicycle",
      "bid",
      "bike",
      "bind",
      "biology",
      "bird",
      "birth",
      "bitter",
      "black",
      "blade",
      "blame",
      "blanket",
      "blast",
      "bleak",
      "bless",
      "blind",
      "blood",
      "blossom",
      "blouse",
      "blue",
      "blur",
      "blush",
      "board",
      "boat",
      "body"
      // ... (more words would be here - abbreviated for brevity, but the full 2048 would be loaded)
    ]);
    COMMON_ENGLISH = /* @__PURE__ */ new Set([
      "the",
      "is",
      "are",
      "was",
      "were",
      "have",
      "has",
      "had",
      "do",
      "does",
      "did",
      "will",
      "would",
      "could",
      "should",
      "may",
      "might",
      "must",
      "shall",
      "can",
      "transaction",
      "transactions",
      "sent",
      "receive",
      "received",
      "known",
      "changes",
      "executed",
      "information",
      "and",
      "or",
      "but",
      "if",
      "then",
      "else",
      "when"
    ]);
    VocabularyTracker = class {
      phraseObservations;
      sequenceObservations;
      minFrequency;
      minPhi;
      maxSequenceLength;
      dataLoaded;
      saveQueue;
      saveTimer;
      constructor(options = {}) {
        this.phraseObservations = /* @__PURE__ */ new Map();
        this.sequenceObservations = /* @__PURE__ */ new Map();
        this.saveQueue = /* @__PURE__ */ new Map();
        this.saveTimer = null;
        this.minFrequency = options.minFrequency || 3;
        this.minPhi = options.minPhi || 0.35;
        this.maxSequenceLength = options.maxSequenceLength || 5;
        this.dataLoaded = this.loadFromPostgres();
      }
      /**
       * Check if a text string is a real vocabulary word
       */
      isRealWord(text2) {
        const lower = text2.toLowerCase();
        if (BIP39_WORDS2.has(lower)) return true;
        if (COMMON_ENGLISH.has(lower)) return true;
        if (lower.length > 15 && !lower.includes(" ")) return false;
        if (/\d/.test(lower)) return false;
        if (!/[aeiou]/.test(lower)) return false;
        if (lower.length >= 3 && lower.length <= 12) {
          const vowelRatio = (lower.match(/[aeiou]/g) || []).length / lower.length;
          if (vowelRatio >= 0.2 && vowelRatio <= 0.6) return true;
        }
        return false;
      }
      /**
       * Determine the type of observation
       */
      classifyType(text2) {
        if (text2.includes(" ")) return "sequence";
        if (this.isRealWord(text2)) return "word";
        return "phrase";
      }
      /**
       * Check if a single word is in the BIP-39 wordlist
       */
      isBip39Word(word) {
        return BIP39_WORDS2.has(word.toLowerCase());
      }
      /**
       * Classify a phrase into categories for kernel learning
       * This teaches kernels the difference between:
       * - Valid BIP-39 seed phrases (recoverable wallets)
       * - Passphrases (arbitrary text, not seeds)
       * - Mutations (seed-length but invalid)
       */
      classifyPhraseCategory(text2) {
        const trimmed = text2.trim();
        const words = trimmed.split(/\s+/);
        const wordCount = words.length;
        const VALID_SEED_LENGTHS = [12, 15, 18, 21, 24];
        if (wordCount === 1) {
          const word = words[0].toLowerCase();
          if (BIP39_WORDS2.has(word)) {
            return "bip39_word";
          }
          if (/[^a-z]/.test(word)) {
            return "passphrase";
          }
          return "unknown";
        }
        if (VALID_SEED_LENGTHS.includes(wordCount)) {
          const allBip39 = words.every((w) => BIP39_WORDS2.has(w.toLowerCase()));
          if (allBip39) {
            return "bip39_seed";
          } else {
            return "mutation";
          }
        }
        return "passphrase";
      }
      /**
       * Observe a phrase from search results
       */
      observe(phrase, phi, kappa, regime, basinCoordinates) {
        if (phi < this.minPhi) return;
        const tokens = this.tokenize(phrase);
        const now = /* @__PURE__ */ new Date();
        for (const token of tokens) {
          if (token.length < 2) continue;
          const type = this.classifyType(token);
          const isReal = type === "word";
          const isBip39 = this.isBip39Word(token);
          const category = this.classifyPhraseCategory(token);
          const existing = this.phraseObservations.get(token);
          if (existing) {
            existing.frequency++;
            existing.avgPhi = (existing.avgPhi * (existing.frequency - 1) + phi) / existing.frequency;
            existing.maxPhi = Math.max(existing.maxPhi, phi);
            existing.lastSeen = now;
            if (!existing.contexts.includes(phrase) && existing.contexts.length < 10) {
              existing.contexts.push(phrase);
            }
          } else {
            this.phraseObservations.set(token, {
              text: token,
              frequency: 1,
              avgPhi: phi,
              maxPhi: phi,
              firstSeen: now,
              lastSeen: now,
              contexts: [phrase],
              isRealWord: isReal,
              isBip39Word: isBip39,
              type,
              phraseCategory: category
            });
          }
          this.queueForSave(token);
          const wordContext = {
            word: token,
            phi,
            kappa: kappa || 50,
            regime: regime || "geometric",
            basinCoordinates: basinCoordinates || [],
            timestamp: now.getTime()
          };
          vocabDecisionEngine.observe(token, wordContext);
        }
        for (let length = 2; length <= Math.min(this.maxSequenceLength, tokens.length); length++) {
          for (let i = 0; i <= tokens.length - length; i++) {
            const seqTokens = tokens.slice(i, i + length);
            const sequence = seqTokens.join(" ");
            const existing = this.sequenceObservations.get(sequence);
            if (existing) {
              existing.frequency++;
              existing.avgPhi = (existing.avgPhi * (existing.frequency - 1) + phi) / existing.frequency;
              existing.maxPhi = Math.max(existing.maxPhi, phi);
              existing.efficiencyGain = existing.frequency * (seqTokens.length - 1);
            } else {
              this.sequenceObservations.set(sequence, {
                sequence,
                words: seqTokens,
                frequency: 1,
                avgPhi: phi,
                maxPhi: phi,
                efficiencyGain: 0
              });
            }
          }
        }
      }
      /**
       * Queue an observation for batch save
       */
      queueForSave(text2) {
        const obs = this.phraseObservations.get(text2);
        if (obs) {
          this.saveQueue.set(text2, obs);
        }
        if (!this.saveTimer) {
          this.saveTimer = setTimeout(() => {
            this.flushSaveQueue();
            this.saveTimer = null;
          }, 5e3);
        }
      }
      /**
       * Flush pending saves to PostgreSQL with centralized retry logic
       */
      async flushSaveQueue() {
        if (this.saveQueue.size === 0) return;
        if (!db) {
          console.warn("[VocabularyTracker] Database not available");
          return;
        }
        const toSave = Array.from(this.saveQueue.values());
        this.saveQueue.clear();
        const result = await withDbRetry(
          async () => {
            const batchSize = 50;
            let savedCount = 0;
            for (let i = 0; i < toSave.length; i += batchSize) {
              const batch = toSave.slice(i, i + batchSize);
              const values = batch.map((obs) => ({
                text: obs.text,
                type: obs.type,
                isRealWord: obs.isRealWord,
                frequency: obs.frequency,
                avgPhi: obs.avgPhi,
                maxPhi: obs.maxPhi,
                efficiencyGain: 0,
                firstSeen: obs.firstSeen,
                lastSeen: obs.lastSeen,
                contexts: obs.contexts.slice(0, 5)
              }));
              await db.insert(vocabularyObservations).values(values).onConflictDoNothing();
              savedCount += batch.length;
            }
            return savedCount;
          },
          "vocabulary-flush-save"
        );
        if (result !== null) {
          console.log(`[VocabularyTracker] Saved ${result} observations to PostgreSQL`);
        } else {
          console.warn("[VocabularyTracker] Failed to save observations after retries, will retry in 30s");
          for (const obs of toSave) {
            this.saveQueue.set(obs.text, obs);
          }
          setTimeout(() => this.flushSaveQueue(), 3e4);
        }
      }
      /**
       * Observe from geometric memory probes
       */
      observeFromProbes(probes) {
        for (const probe of probes) {
          if (probe.phi >= this.minPhi) {
            this.observe(
              probe.input,
              probe.phi,
              probe.kappa,
              probe.regime,
              probe.coordinates
            );
          }
        }
      }
      /**
       * Tokenize phrase into words/phrases
       */
      tokenize(phrase) {
        return phrase.toLowerCase().replace(/[^a-z0-9\s]/g, " ").split(/\s+/).filter((w) => w.length > 0);
      }
      /**
       * Get vocabulary expansion candidates
       */
      getCandidates(topK = 20) {
        const candidates = [];
        for (const [_text, obs] of Array.from(this.phraseObservations.entries())) {
          if (obs.frequency >= this.minFrequency && obs.avgPhi >= this.minPhi) {
            candidates.push({
              text: obs.text,
              type: obs.type,
              frequency: obs.frequency,
              avgPhi: obs.avgPhi,
              maxPhi: obs.maxPhi,
              efficiencyGain: obs.frequency,
              isRealWord: obs.isRealWord,
              reasoning: `${obs.isRealWord ? "Word" : "Phrase mutation"} in ${obs.frequency} high-\u03A6 results (avg \u03A6=${obs.avgPhi.toFixed(2)})`
            });
          }
        }
        for (const [_seq, obs] of Array.from(this.sequenceObservations.entries())) {
          if (obs.frequency >= this.minFrequency && obs.avgPhi >= this.minPhi && obs.efficiencyGain > 5) {
            candidates.push({
              text: obs.sequence,
              type: "sequence",
              frequency: obs.frequency,
              avgPhi: obs.avgPhi,
              maxPhi: obs.maxPhi,
              efficiencyGain: obs.efficiencyGain,
              isRealWord: false,
              reasoning: `Sequence "${obs.sequence}" appears ${obs.frequency}x (avg \u03A6=${obs.avgPhi.toFixed(2)})`,
              components: obs.words
            });
          }
        }
        candidates.sort((a, b) => {
          const scoreA = a.efficiencyGain * a.avgPhi;
          const scoreB = b.efficiencyGain * b.avgPhi;
          return scoreB - scoreA;
        });
        return candidates.slice(0, topK);
      }
      /**
       * Get statistics with word/phrase breakdown
       */
      getStats() {
        const words = [];
        const phrases = [];
        for (const obs of this.phraseObservations.values()) {
          if (obs.isRealWord) {
            words.push(obs);
          } else {
            phrases.push(obs);
          }
        }
        const topWords = words.sort((a, b) => b.frequency - a.frequency).slice(0, 20).map((o) => ({ text: o.text, frequency: o.frequency, avgPhi: o.avgPhi, isRealWord: true }));
        const topPhrases = phrases.sort((a, b) => b.frequency - a.frequency).slice(0, 20).map((o) => ({ text: o.text, frequency: o.frequency, avgPhi: o.avgPhi }));
        const topSequences = Array.from(this.sequenceObservations.values()).sort((a, b) => b.efficiencyGain - a.efficiencyGain).slice(0, 20).map((o) => ({ sequence: o.sequence, frequency: o.frequency, avgPhi: o.avgPhi }));
        return {
          totalWords: words.length,
          totalPhrases: phrases.length,
          totalSequences: this.sequenceObservations.size,
          topWords,
          topPhrases,
          topSequences,
          candidatesReady: this.getCandidates(100).length
        };
      }
      /**
       * Get category statistics for kernel learning insights
       */
      getCategoryStats() {
        const categories = {
          bip39_seed: { count: 0, totalPhi: 0, examples: [] },
          passphrase: { count: 0, totalPhi: 0, examples: [] },
          mutation: { count: 0, totalPhi: 0, examples: [] },
          bip39_word: { count: 0, totalPhi: 0, examples: [] },
          unknown: { count: 0, totalPhi: 0, examples: [] }
        };
        let bip39WordCount = 0;
        for (const obs of this.phraseObservations.values()) {
          const cat = obs.phraseCategory || "unknown";
          if (!categories[cat]) {
            categories[cat] = { count: 0, totalPhi: 0, examples: [] };
          }
          categories[cat].count++;
          categories[cat].totalPhi += obs.avgPhi;
          if (categories[cat].examples.length < 5) {
            categories[cat].examples.push(obs.text.slice(0, 30));
          }
          if (obs.isBip39Word) bip39WordCount++;
        }
        const result = {};
        for (const [key, value] of Object.entries(categories)) {
          if (value.count > 0) {
            result[key] = {
              count: value.count,
              avgPhi: parseFloat((value.totalPhi / value.count).toFixed(4)),
              examples: value.examples
            };
          }
        }
        const total = this.phraseObservations.size;
        return {
          categories: result,
          bip39Coverage: total > 0 ? parseFloat((bip39WordCount / total).toFixed(4)) : 0,
          totalObservations: total
        };
      }
      /**
       * Force save all observations to PostgreSQL
       */
      async saveToStorage() {
        if (!db) {
          console.warn("[VocabularyTracker] Database not available");
          return;
        }
        try {
          for (const [_text, obs] of Array.from(this.phraseObservations.entries())) {
            await db.insert(vocabularyObservations).values({
              text: obs.text,
              type: obs.type,
              phraseCategory: obs.phraseCategory,
              isRealWord: obs.isRealWord,
              frequency: obs.frequency,
              avgPhi: obs.avgPhi,
              maxPhi: obs.maxPhi,
              efficiencyGain: 0,
              firstSeen: obs.firstSeen,
              lastSeen: obs.lastSeen,
              contexts: obs.contexts.slice(0, 10)
            }).onConflictDoUpdate({
              target: vocabularyObservations.text,
              set: {
                frequency: obs.frequency,
                avgPhi: obs.avgPhi,
                maxPhi: obs.maxPhi,
                phraseCategory: obs.phraseCategory,
                lastSeen: obs.lastSeen,
                contexts: obs.contexts.slice(0, 10)
              }
            });
          }
          for (const [_seq, obs] of Array.from(this.sequenceObservations.entries())) {
            await db.insert(vocabularyObservations).values({
              text: obs.sequence,
              type: "sequence",
              isRealWord: false,
              frequency: obs.frequency,
              avgPhi: obs.avgPhi,
              maxPhi: obs.maxPhi,
              efficiencyGain: obs.efficiencyGain,
              firstSeen: /* @__PURE__ */ new Date(),
              lastSeen: /* @__PURE__ */ new Date(),
              contexts: [obs.sequence]
            }).onConflictDoUpdate({
              target: vocabularyObservations.text,
              set: {
                frequency: obs.frequency,
                avgPhi: obs.avgPhi,
                maxPhi: obs.maxPhi,
                efficiencyGain: obs.efficiencyGain,
                lastSeen: /* @__PURE__ */ new Date()
              }
            });
          }
          console.log(`[VocabularyTracker] Saved ${this.phraseObservations.size} phrases, ${this.sequenceObservations.size} sequences to PostgreSQL`);
        } catch (error) {
          console.error("[VocabularyTracker] PostgreSQL save error:", error);
          throw error;
        }
      }
      /**
       * Load from PostgreSQL with centralized retry logic
       */
      async loadFromPostgres() {
        if (!db) {
          console.warn("[VocabularyTracker] Database not available, starting empty");
          return;
        }
        const result = await withDbRetry(
          async () => {
            const rows = await db.select().from(vocabularyObservations);
            for (const row of rows) {
              if (row.type === "sequence") {
                this.sequenceObservations.set(row.text, {
                  sequence: row.text,
                  words: row.text.split(" "),
                  frequency: row.frequency,
                  avgPhi: row.avgPhi,
                  maxPhi: row.maxPhi,
                  efficiencyGain: row.efficiencyGain || 0
                });
              } else {
                this.phraseObservations.set(row.text, {
                  text: row.text,
                  frequency: row.frequency,
                  avgPhi: row.avgPhi,
                  maxPhi: row.maxPhi,
                  firstSeen: row.firstSeen || /* @__PURE__ */ new Date(),
                  lastSeen: row.lastSeen || /* @__PURE__ */ new Date(),
                  contexts: row.contexts || [],
                  isRealWord: row.isRealWord,
                  // Compute isBip39Word from text (legacy column removed)
                  isBip39Word: BIP39_WORDS2.has(row.text.toLowerCase()),
                  type: row.type,
                  phraseCategory: row.phraseCategory ?? "unknown"
                });
              }
            }
            return rows.length;
          },
          "vocabulary-load"
        );
        if (result !== null) {
          console.log(`[VocabularyTracker] Loaded ${this.phraseObservations.size} phrases, ${this.sequenceObservations.size} sequences from PostgreSQL`);
          if (this.phraseObservations.size === 0) {
            setTimeout(() => this.bootstrapFromGeometricMemory(), 2e3);
          }
        } else {
          console.warn("[VocabularyTracker] Failed to load from PostgreSQL after retries, starting empty");
          setTimeout(() => this.loadFromPostgres(), 3e4);
        }
      }
      /**
       * Bootstrap from geometric memory
       */
      bootstrapFromGeometricMemory() {
        const probes = geometricMemory.getAllProbes();
        console.log(`[VocabularyTracker] Bootstrapping from ${probes.length} geometric memory probes...`);
        let observed = 0;
        for (const probe of probes) {
          if (probe.phi >= this.minPhi) {
            this.observe(probe.input, probe.phi);
            observed++;
          }
        }
        console.log(`[VocabularyTracker] Observed ${observed} high-\u03A6 probes`);
        this.saveToStorage().catch((err) => console.error("[VocabularyTracker] Bootstrap save failed:", err));
      }
      /**
       * Export observations for Python tokenizer with phrase category
       * Kernels use this to learn the difference between BIP-39 seeds and passphrases
       */
      async exportForTokenizer() {
        await this.dataLoaded;
        const exports = [];
        for (const [_text, obs] of Array.from(this.phraseObservations.entries())) {
          if (obs.frequency >= this.minFrequency && obs.avgPhi >= this.minPhi) {
            exports.push({
              text: obs.text,
              frequency: obs.frequency,
              avgPhi: obs.avgPhi,
              maxPhi: obs.maxPhi,
              type: obs.type,
              isRealWord: obs.isRealWord,
              isBip39Word: obs.isBip39Word,
              phraseCategory: obs.phraseCategory
            });
          }
        }
        for (const [_seq, obs] of Array.from(this.sequenceObservations.entries())) {
          if (obs.frequency >= 3 && obs.avgPhi >= 0.4) {
            const category = this.classifyPhraseCategory(obs.sequence);
            exports.push({
              text: obs.sequence,
              frequency: obs.frequency,
              avgPhi: obs.avgPhi,
              maxPhi: obs.maxPhi,
              type: "sequence",
              isRealWord: false,
              isBip39Word: false,
              phraseCategory: category
            });
          }
        }
        exports.sort((a, b) => b.avgPhi - a.avgPhi);
        const categories = exports.reduce((acc, e) => {
          acc[e.phraseCategory] = (acc[e.phraseCategory] || 0) + 1;
          return acc;
        }, {});
        console.log(`[VocabularyTracker] Exported ${exports.length} observations: ${JSON.stringify(categories)}`);
        return exports;
      }
      /**
       * Migrate legacy JSON data to PostgreSQL
       * Call this once to import old data
       */
      async migrateFromJson(jsonPath) {
        if (!db) throw new Error("Database not available");
        const fs13 = await import("fs");
        const path15 = await import("path");
        const fullPath = path15.resolve(jsonPath);
        if (!fs13.existsSync(fullPath)) {
          console.log("[VocabularyTracker] No JSON file to migrate");
          return 0;
        }
        try {
          const raw = fs13.readFileSync(fullPath, "utf-8");
          const data = JSON.parse(raw);
          let migrated = 0;
          for (const w of data.words || []) {
            const type = this.classifyType(w.word);
            const isReal = type === "word";
            await db.insert(vocabularyObservations).values({
              text: w.word,
              type,
              isRealWord: isReal,
              frequency: w.frequency,
              avgPhi: w.avgPhi,
              maxPhi: w.maxPhi,
              efficiencyGain: 0,
              firstSeen: new Date(w.firstSeen),
              lastSeen: new Date(w.lastSeen),
              contexts: w.contexts?.slice(0, 10) || []
            }).onConflictDoUpdate({
              target: vocabularyObservations.text,
              set: {
                frequency: w.frequency,
                avgPhi: w.avgPhi,
                maxPhi: w.maxPhi,
                lastSeen: new Date(w.lastSeen)
              }
            });
            migrated++;
          }
          for (const s of data.sequences || []) {
            await db.insert(vocabularyObservations).values({
              text: s.sequence,
              type: "sequence",
              isRealWord: false,
              frequency: s.frequency,
              avgPhi: s.avgPhi,
              maxPhi: s.maxPhi,
              efficiencyGain: s.efficiencyGain || 0,
              contexts: [s.sequence]
            }).onConflictDoUpdate({
              target: vocabularyObservations.text,
              set: {
                frequency: s.frequency,
                avgPhi: s.avgPhi,
                maxPhi: s.maxPhi,
                efficiencyGain: s.efficiencyGain || 0
              }
            });
            migrated++;
          }
          console.log(`[VocabularyTracker] Migrated ${migrated} entries from JSON to PostgreSQL`);
          return migrated;
        } catch (error) {
          console.error("[VocabularyTracker] JSON migration failed:", error);
          throw error;
        }
      }
      /**
       * Wait for PostgreSQL data to finish loading
       * Call this before accessing data synchronously
       */
      async waitForData() {
        await this.dataLoaded;
      }
      /**
       * Check if data has finished loading (non-blocking)
       */
      isDataLoaded() {
        return this.phraseObservations.size > 0 || this.sequenceObservations.size > 0;
      }
    };
    vocabularyTracker = new VocabularyTracker();
  }
});

// server/geometric-discovery/ocean-discovery-controller.ts
import * as fs4 from "fs";
import * as path4 from "path";
var OceanDiscoveryController, oceanDiscoveryController;
var init_ocean_discovery_controller = __esm({
  "server/geometric-discovery/ocean-discovery-controller.ts"() {
    "use strict";
    init_qig_universal();
    init_temporal_positioning_system();
    init_searxng_adapter();
    init_quantum_protocol();
    init_geometric_memory();
    init_vocabulary_tracker();
    init_constants();
    OceanDiscoveryController = class _OceanDiscoveryController {
      tps;
      searchAdapter;
      quantum;
      state = null;
      isRunning = false;
      constructor() {
        this.tps = tps;
        this.searchAdapter = createSearXNGAdapter();
        this.quantum = quantumProtocol;
        console.log("[OceanDiscovery] Controller initialized with SearXNG (FREE search)");
      }
      /**
       * MAIN DISCOVERY PROTOCOL
       * 
       * Navigate 68D block universe toward passphrase coordinates
       */
      async navigateToPassphrase(config) {
        const startTime2 = Date.now();
        console.log(`
\u{1F30A} INITIATING GEOMETRIC DISCOVERY \u{1F30A}`);
        console.log(`Target: ${config.targetAddress}`);
        console.log(`Protocol: 68D Block Universe Navigation
`);
        this.state = {
          targetWalletAddress: config.targetAddress,
          targetCoords: void 0,
          currentPosition: this.getCurrentPosition(),
          measurements: [],
          discoveries: [],
          possibilitySpace: {
            totalDimension: 256,
            remainingFraction: 1,
            entropyBits: 256
          },
          status: "initializing"
        };
        this.isRunning = true;
        try {
          this.state.targetCoords = await this.estimateTargetCoordinates(
            config.targetAddress,
            config.knownClues
          );
          console.log(`\u{1F4CD} Target located in block universe:`);
          console.log(`   Era: ${this.tps.classifyEra(this.state.targetCoords.spacetime.t)}`);
          console.log(`   Curvature: R = ${this.state.targetCoords.ricci.toFixed(2)}`);
          console.log(`   Integration: \u03A6 = ${this.state.targetCoords.phi.toFixed(3)}`);
          console.log(`   Regime: ${this.state.targetCoords.regime}
`);
          this.state.status = "navigating";
          await this.enhanceCulturalManifoldGeometric();
          this.state.geodesicPath = this.navigateGeodesicPath();
          console.log(`
\u{1F6E4}\uFE0F  GEODESIC PATH (${this.state.geodesicPath.waypoints.length} waypoints):`);
          console.log(`   Arc length: ${this.state.geodesicPath.totalArcLength.toFixed(2)}`);
          console.log(`   Avg curvature: ${this.state.geodesicPath.avgCurvature.toFixed(2)}`);
          console.log(`   Regime transitions: ${this.state.geodesicPath.regimeTransitions.length}
`);
          this.state.status = "measuring";
          const maxIterations = config.maxIterations || 100;
          for (let i = 0; i < Math.min(this.state.geodesicPath.waypoints.length, maxIterations); i++) {
            if (!this.isRunning) break;
            const waypoint = this.state.geodesicPath.waypoints[i];
            const hypotheses = await this.generateHypothesesAt(waypoint);
            for (const hypothesis of hypotheses) {
              if (!this.isRunning) break;
              if (this.quantum.hasBeenTested(hypothesis)) continue;
              const measurement = await this.quantum.measure(
                hypothesis,
                async (h) => this.testHypothesis(h, config.targetAddress)
              );
              this.state.measurements.push(measurement);
              if (measurement.result.success) {
                console.log(`
\u2705 PASSPHRASE DISCOVERED: ${hypothesis}`);
                this.state.status = "discovered";
                const discoveriesList2 = Array.isArray(this.state.discoveries) ? this.state.discoveries : [];
                return {
                  success: true,
                  passphrase: hypothesis,
                  wifKey: measurement.result.wifKey,
                  iterations: this.state.measurements.length,
                  entropyReduced: this.quantum.getTotalEntropyReduction(),
                  patternsDiscovered: discoveriesList2.reduce((acc, d) => acc + (Array.isArray(d.patterns) ? d.patterns.length : 0), 0),
                  geodesicLength: this.state.geodesicPath.totalArcLength,
                  totalTime: Date.now() - startTime2
                };
              }
            }
            this.state.currentPosition = waypoint;
          }
          const summary = this.quantum.getSummary();
          console.log(`
\u{1F504} Discovery session complete without match`);
          console.log(`   Measurements: ${summary.totalMeasurements}`);
          console.log(`   Entropy reduced: ${summary.entropyReduced.toFixed(2)} bits`);
          console.log(`   Efficiency: ${summary.efficiency.toFixed(4)} bits/measurement`);
          this.state.status = "exhausted";
          const discoveriesList = Array.isArray(this.state.discoveries) ? this.state.discoveries : [];
          return {
            success: false,
            iterations: summary.totalMeasurements,
            entropyReduced: summary.entropyReduced,
            patternsDiscovered: discoveriesList.reduce((acc, d) => acc + (Array.isArray(d.patterns) ? d.patterns.length : 0), 0),
            geodesicLength: this.state.geodesicPath?.totalArcLength || 0,
            totalTime: Date.now() - startTime2
          };
        } finally {
          this.isRunning = false;
        }
      }
      /**
       * Estimate where in 68D block universe the passphrase exists
       */
      async estimateTargetCoordinates(walletAddress, clues) {
        let estimatedEra = "pizza_era";
        let culturalBasin;
        if (clues && clues.length > 0) {
          const combinedCoords = clues.map(
            (clue) => this.tps.locateInBlockUniverse(clue)
          );
          const avgCultural = new Array(E8_CONSTANTS.BASIN_DIMENSION_64D).fill(0);
          let avgT = 0;
          for (const coords of combinedCoords) {
            avgT += coords.spacetime.t;
            for (let i = 0; i < Math.min(E8_CONSTANTS.BASIN_DIMENSION_64D, coords.cultural.length); i++) {
              avgCultural[i] += coords.cultural[i];
            }
          }
          avgT /= combinedCoords.length;
          for (let i = 0; i < 64; i++) {
            avgCultural[i] /= combinedCoords.length;
          }
          culturalBasin = avgCultural;
          estimatedEra = this.tps.classifyEra(avgT);
          const geometry = this.computeLocalGeometry(culturalBasin);
          return {
            spacetime: { x: 0, y: 0, z: 0, t: avgT },
            cultural: culturalBasin,
            fisherMetric: geometry.fisherMetric,
            ricci: geometry.ricci,
            phi: geometry.phi,
            regime: this.classifyRegime(geometry.ricci)
          };
        } else {
          culturalBasin = this.tps.getEraCulturalBaseline(estimatedEra);
          const eraTimestamp = this.getEraTimestamp(estimatedEra);
          const geometry = this.computeLocalGeometry(culturalBasin);
          return {
            spacetime: { x: 0, y: 0, z: 0, t: eraTimestamp },
            cultural: culturalBasin,
            fisherMetric: geometry.fisherMetric,
            ricci: geometry.ricci,
            phi: geometry.phi,
            regime: this.classifyRegime(geometry.ricci)
          };
        }
      }
      /**
       * Enhanced cultural manifold discovery using geometric search
       */
      async enhanceCulturalManifoldGeometric() {
        if (!this.state?.targetCoords) {
          return { discoveries: 0, patterns: 0, entropyGained: 0 };
        }
        console.log(`
\u{1F50D} DISCOVERING CULTURAL CONTEXT (SearXNG - FREE)
`);
        const discoveries = await this.searchAdapter.discoverAtCoordinates(
          this.state.targetCoords,
          this.state.targetCoords.phi > 0.7 ? 1.5 : 2
          // Tighter radius for high-Φ targets
        );
        console.log(`   Found ${discoveries.length} cultural artifacts`);
        this.state.discoveries = discoveries;
        let totalPatterns = 0;
        let totalEntropyGained = 0;
        for (const discovery2 of discoveries) {
          if (discovery2.phi > 0.6) {
            this.tps.classifyEra(discovery2.coords.spacetime.t);
            for (const pattern of discovery2.patterns) {
              vocabularyTracker.observe(
                pattern,
                discovery2.phi,
                64,
                // Assume resonance (κ* = 64)
                discovery2.coords.regime,
                discovery2.coords.cultural
              );
            }
            totalPatterns += discovery2.patterns.length;
            totalEntropyGained += discovery2.entropyReduction;
            console.log(`   \u251C\u2500 \u03A6=${discovery2.phi.toFixed(2)}: +${discovery2.patterns.length} patterns`);
          }
        }
        if (discoveries.length > 0) {
          const integration = this.quantum.integrateDiscoveries(discoveries);
          totalEntropyGained += integration.informationGained;
        }
        console.log(`   \u2514\u2500 Total: ${totalPatterns} patterns, ${totalEntropyGained.toFixed(2)} bits gained
`);
        return {
          discoveries: discoveries.length,
          patterns: totalPatterns,
          entropyGained: totalEntropyGained
        };
      }
      /**
       * Navigate geodesic path from current position to target
       */
      navigateGeodesicPath() {
        if (!this.state?.targetCoords) {
          return { waypoints: [], totalArcLength: 0, avgCurvature: 0, regimeTransitions: [] };
        }
        return this.tps.computeGeodesicPath(
          this.state.currentPosition,
          this.state.targetCoords,
          20
          // 20 waypoints
        );
      }
      /**
       * Generate hypotheses at specific 68D coordinates
       */
      async generateHypothesesAt(coords) {
        const hypotheses = [];
        const discoveriesList = Array.isArray(this.state?.discoveries) ? this.state.discoveries : [];
        for (const discovery2 of discoveriesList) {
          const distance = fisherCoordDistance(coords.cultural, discovery2.coords.cultural);
          if (distance < 1 && Array.isArray(discovery2.patterns)) {
            hypotheses.push(...discovery2.patterns.slice(0, 5));
          }
        }
        const era = this.tps.classifyEra(coords.spacetime.t);
        const eraPatterns = this.getEraPatterns(era);
        hypotheses.push(...eraPatterns.slice(0, 10));
        const nearbyLandmarks = this.tps.findNearbyLandmarks(coords, 3);
        for (const landmark of nearbyLandmarks) {
          const landmarkWords = landmark.description.toLowerCase().split(/\W+/);
          for (const word of landmarkWords) {
            if (word.length >= 4 && word.length <= 20) {
              hypotheses.push(word);
            }
          }
        }
        const coordsHash = coords.cultural.slice(0, 8).map((c) => Math.round(c * 10)).join("");
        const memoryProbes = geometricMemory.findNearbyProbes(
          coordsHash,
          // Use hash-like string representation
          0.5
        );
        for (const probe of memoryProbes.slice(0, 10)) {
          if (probe.input) {
            hypotheses.push(probe.input);
          }
        }
        return Array.from(new Set(hypotheses)).slice(0, 50);
      }
      /**
       * Test a hypothesis against target address
       * Also queues addresses for balance checking
       */
      async testHypothesis(hypothesis, targetAddress) {
        try {
          return { success: false };
        } catch {
          return { success: false };
        }
      }
      /**
       * Get current position in block universe
       */
      getCurrentPosition() {
        const now = Date.now() / 1e3;
        const cultural = new Array(E8_CONSTANTS.BASIN_DIMENSION_64D).fill(0.5);
        const geometry = this.computeLocalGeometry(cultural);
        return {
          spacetime: { x: 0, y: 0, z: 0, t: now },
          cultural,
          fisherMetric: geometry.fisherMetric,
          ricci: geometry.ricci,
          phi: geometry.phi,
          regime: this.classifyRegime(geometry.ricci)
        };
      }
      /**
       * Compute local geometry at cultural coordinates
       */
      computeLocalGeometry(cultural) {
        const n = cultural.length;
        const fisherMetric = [];
        let trace = 0;
        for (let i = 0; i < n; i++) {
          const row = new Array(n).fill(0);
          const c = Math.max(0.01, Math.min(0.99, cultural[i] || 0.5));
          row[i] = 1 / (c * (1 - c));
          trace += row[i];
          fisherMetric.push(row);
        }
        const avgFisher = trace / n;
        const ricci = Math.log(avgFisher) * 10;
        const variance = cultural.reduce((acc, c) => {
          const centered = (c || 0.5) - 0.5;
          return acc + centered * centered;
        }, 0) / n;
        const phi = Math.min(1, Math.max(0, 1 - variance * 4));
        return { fisherMetric, ricci, phi };
      }
      /**
       * Classify regime from Ricci curvature
       */
      classifyRegime(ricci) {
        if (ricci < 10) return "breakdown";
        if (ricci < 41) return "linear";
        if (ricci < 58) return "geometric";
        if (ricci < 70) return "hierarchical";
        if (ricci < 80) return "hierarchical_4d";
        return "4d_block_universe";
      }
      /**
       * Get era-specific patterns
       */
      getEraPatterns(era) {
        const patterns = {
          pre_genesis: ["hashcash", "cypherpunk", "digital", "cash", "anonymous"],
          genesis: ["genesis", "satoshi", "bitcoin", "mining", "block", "hash"],
          early_adoption: ["wallet", "transaction", "address", "cpu", "mining"],
          pizza_era: ["pizza", "laszlo", "gpu", "exchange", "trade", "bitcoin"],
          mtgox_rise: ["mtgox", "silk", "road", "trading", "merchant", "bitcoin"],
          mtgox_collapse: ["hack", "stolen", "bankruptcy", "lost", "coins"],
          modern: ["hodl", "lightning", "segwit", "halving", "bitcoin"]
        };
        return patterns[era] || ["bitcoin", "wallet", "key"];
      }
      /**
       * Get representative timestamp for an era
       */
      getEraTimestamp(era) {
        const timestamps = {
          pre_genesis: 1225497600,
          // Nov 1, 2008
          genesis: 1231006505,
          // Jan 3, 2009
          early_adoption: 125e7,
          pizza_era: 1274009688,
          // May 22, 2010
          mtgox_rise: 13e8,
          mtgox_collapse: 1393286400,
          modern: 15e8
        };
        return timestamps[era] || Date.now() / 1e3;
      }
      /**
       * Stop discovery process
       */
      stop() {
        this.isRunning = false;
        console.log("[OceanDiscovery] Stopping discovery process");
      }
      /**
       * Get current state
       */
      getState() {
        return this.state;
      }
      /**
       * Get discovery summary
       */
      getSummary() {
        const quantum = this.quantum.getSummary();
        const discoveries = Array.isArray(this.state?.discoveries) ? this.state.discoveries : [];
        return {
          status: this.state?.status || "idle",
          measurements: quantum.totalMeasurements,
          discoveries: discoveries.length,
          patterns: discoveries.reduce((acc, d) => acc + (Array.isArray(d.patterns) ? d.patterns.length : 0), 0),
          entropyReduced: quantum.entropyReduced,
          possibilityRemaining: this.state?.possibilitySpace.remainingFraction || 1
        };
      }
      /**
       * Get discovery state (for API endpoints)
       */
      getDiscoveryState() {
        return this.state;
      }
      /**
       * Check if search adapter is enabled (always true with SearXNG)
       */
      isSearchEnabled() {
        return true;
      }
      /**
       * Discover cultural context - primary API for cultural manifold enrichment
       * 
       * Wraps enhanceCulturalManifoldGeometric and returns aggregated stats
       * for use by API routes and Ocean agent
       */
      async discoverCulturalContext() {
        try {
          if (!this.state) {
            this.state = {
              targetWalletAddress: "",
              currentPosition: this.getCurrentPosition(),
              measurements: [],
              discoveries: [],
              possibilitySpace: {
                totalDimension: 256,
                remainingFraction: 1,
                entropyBits: 256
              },
              status: "navigating"
            };
          }
          if (!Array.isArray(this.state.discoveries)) {
            this.state.discoveries = [];
          }
          const stats = await this.enhanceCulturalManifoldGeometric();
          const discoveries = Array.isArray(this.state.discoveries) ? this.state.discoveries : [];
          const allPatterns = [];
          for (const d of discoveries) {
            if (Array.isArray(d.patterns)) {
              allPatterns.push(...d.patterns);
            }
          }
          const response = {
            discoveries: discoveries.map((d) => ({
              ...d,
              source: this.extractSource(d.url || "")
            })),
            patterns: Array.from(new Set(allPatterns)),
            entropyGained: stats.entropyGained
          };
          console.log(`[OceanDiscovery] discoverCulturalContext: ${response.discoveries.length} discoveries, ${response.patterns.length} patterns, ${response.entropyGained.toFixed(2)} bits`);
          return response;
        } catch (error) {
          console.error("[OceanDiscovery] discoverCulturalContext error:", error);
          return { discoveries: [], patterns: [], entropyGained: 0 };
        }
      }
      /**
       * Extract human-readable source from URL
       */
      extractSource(url) {
        try {
          const urlObj = new URL(url);
          return urlObj.hostname.replace("www.", "");
        } catch {
          return url.slice(0, 30);
        }
      }
      /**
       * Estimate 68D coordinates for a target address
       * 
       * Uses blockchain forensics + TPS trilateration to localize
       * the target in block universe spacetime
       */
      async estimateCoordinates(targetAddress) {
        const coords = this.tps.locateInBlockUniverse(
          targetAddress,
          `bitcoin:${targetAddress}`
        );
        if (this.state) {
          this.state.targetCoords = coords;
        }
        console.log(`[OceanDiscovery] Estimated coordinates for ${targetAddress.slice(0, 12)}...`);
        console.log(`  Era: ${coords.era || "unknown"}`);
        console.log(`  Regime: ${coords.regime}`);
        console.log(`  Spacetime: t=${coords.spacetime.t.toFixed(0)}`);
        return coords;
      }
      /**
       * Search Bitcoin era for cultural patterns
       * 
       * Convenience method for targeted era search
       */
      async searchBitcoinEra(keywords, era = "pizza_era") {
        const query = {
          text: keywords.join(" ") + ` bitcoin ${era}`,
          maxResults: 10
        };
        const results = await this.searchAdapter.search(query);
        return results.map((r) => ({
          content: r.content,
          url: r.url,
          coords: this.tps.locateInBlockUniverse(r.content, r.url),
          distance: 0,
          phi: 0.5,
          patterns: [],
          causalChain: [],
          entropyReduction: 0
        }));
      }
      /**
       * Deep crawl a URL for patterns
       */
      async crawlUrl(url) {
        const contentMap = await this.searchAdapter.extractContent([url]);
        const content = contentMap.get(url) || "";
        const coords = this.tps.locateInBlockUniverse(content, url);
        const words = content.toLowerCase().split(/\W+/).filter((w) => w.length >= 4);
        const patterns = words.filter(
          (w) => w.length <= 20 && /^[a-z0-9]+$/i.test(w)
        ).slice(0, 100);
        return { content, patterns: Array.from(new Set(patterns)), coords };
      }
      // ═══════════════════════════════════════════════════════════════════════════
      // PERSISTENCE & BASIN SYNC
      // ═══════════════════════════════════════════════════════════════════════════
      static DATA_FILE = path4.join(process.cwd(), "data", "discovery-controller.json");
      /**
       * Save discovery state to disk
       */
      save() {
        try {
          const dir = path4.dirname(_OceanDiscoveryController.DATA_FILE);
          if (!fs4.existsSync(dir)) {
            fs4.mkdirSync(dir, { recursive: true });
          }
          this.quantum.save();
          if (!this.state) return;
          const discoveriesList = Array.isArray(this.state.discoveries) ? this.state.discoveries : [];
          const data = {
            version: "1.0.0",
            status: this.state.status,
            targetCoords: this.state.targetCoords,
            currentPosition: this.state.currentPosition,
            discoveryCount: discoveriesList.length,
            patternCount: discoveriesList.reduce((acc, d) => acc + (Array.isArray(d.patterns) ? d.patterns.length : 0), 0),
            possibilitySpace: this.state.possibilitySpace,
            savedAt: (/* @__PURE__ */ new Date()).toISOString()
          };
          fs4.writeFileSync(_OceanDiscoveryController.DATA_FILE, JSON.stringify(data, null, 2));
          console.log("[OceanDiscovery] Saved discovery state");
        } catch (error) {
          console.error("[OceanDiscovery] Failed to save:", error);
        }
      }
      /**
       * Load discovery state from disk
       */
      load() {
        try {
          if (fs4.existsSync(_OceanDiscoveryController.DATA_FILE)) {
            const data = JSON.parse(fs4.readFileSync(_OceanDiscoveryController.DATA_FILE, "utf-8"));
            if (data.possibilitySpace) {
              console.log(`[OceanDiscovery] Loaded prior state: ${data.discoveryCount} discoveries, ${data.patternCount} patterns`);
            }
          }
        } catch {
          console.log("[OceanDiscovery] Starting fresh");
        }
      }
      /**
       * Export ALL discovery data for QIG-pure basin sync
       * 
       * Aggregates data from TPS, Quantum Protocol, and Controller
       * Returns compact structure (<4KB) for efficient knowledge transfer
       */
      exportForBasinSync() {
        const quantumData = this.quantum.exportForBasinSync();
        const tpsData = this.tps.exportForBasinSync();
        const summary = this.getSummary();
        const discoveredPatterns = this.state?.discoveries.filter((d) => d.phi > 0.6).flatMap((d) => d.patterns.slice(0, 5)).slice(0, 50) || [];
        const coordinateSamples = this.state?.discoveries.filter((d) => d.phi > 0.5).map((d) => ({
          cultural: d.coords.cultural.slice(0, 16),
          // First 16 dims
          phi: d.phi,
          regime: d.coords.regime
        })).slice(0, 10) || [];
        return {
          version: "1.0.0",
          // Quantum entropy state
          quantum: quantumData,
          // Spacetime navigation
          tps: tpsData,
          // Discovery results
          discovery: {
            status: summary.status,
            measurementCount: summary.measurements,
            discoveryCount: summary.discoveries,
            patternCount: summary.patterns,
            entropyReduced: summary.entropyReduced,
            possibilityRemaining: summary.possibilityRemaining
          },
          // Transferable knowledge
          patterns: discoveredPatterns,
          coordinateSamples,
          lastUpdated: (/* @__PURE__ */ new Date()).toISOString()
        };
      }
      /**
       * Import basin sync data from peer
       * 
       * Uses Fisher-Rao distance to compute coupling strength
       * Only integrates knowledge that passes QIG purity checks
       */
      importFromBasinSync(data, couplingStrength) {
        if (couplingStrength < 0.1) {
          console.log(`[OceanDiscovery] Basin sync rejected: coupling too low (${couplingStrength.toFixed(2)})`);
          return;
        }
        if (data.quantum) {
          this.quantum.importFromBasinSync(data.quantum, couplingStrength);
        }
        if (data.tps) {
          this.tps.importFromBasinSync(data.tps, couplingStrength);
        }
        for (const pattern of data.patterns || []) {
          const effectivePhi = 0.6 * couplingStrength;
          vocabularyTracker.observe(
            pattern,
            effectivePhi,
            50,
            // Default kappa
            "geometric",
            []
            // No basin coords from remote
          );
        }
        console.log(`[OceanDiscovery] Basin sync complete: ${data.patterns?.length || 0} patterns imported (coupling=${couplingStrength.toFixed(2)})`);
        this.save();
      }
    };
    oceanDiscoveryController = new OceanDiscoveryController();
  }
});

// server/knowledge-compression-engine.ts
import { nanoid as nanoid2 } from "nanoid";
var KnowledgeCompressionEngine, knowledgeCompressionEngine;
var init_knowledge_compression_engine = __esm({
  "server/knowledge-compression-engine.ts"() {
    "use strict";
    init_qig_universal();
    init_constants();
    KnowledgeCompressionEngine = class {
      generators = /* @__PURE__ */ new Map();
      negativeKnowledge;
      basinLocation = new Array(E8_CONSTANTS.BASIN_DIMENSION_64D).fill(0);
      // Pattern learning metrics
      patternsLearned = 0;
      successfulPatterns = 0;
      failedPatterns = 0;
      SUBSTITUTION_PATTERNS = {
        adjectives: ["red", "blue", "green", "black", "white", "dark", "light", "old", "new", "big", "small", "happy", "sad", "fast", "slow", "hot", "cold", "wild", "calm", "rich", "poor"],
        nouns: ["cat", "dog", "bird", "fish", "tree", "moon", "sun", "star", "key", "door", "book", "coin", "gold", "silver", "tiger", "dragon", "wolf", "bear", "lion", "eagle"],
        verbs: ["run", "jump", "fly", "swim", "walk", "dance", "sing", "fight", "love", "hate", "find", "lose", "give", "take", "make", "break", "build", "grow", "fall", "rise"],
        numbers: ["1", "2", "3", "7", "11", "13", "21", "42", "69", "77", "99", "100", "123", "007", "1337", "2009", "2010", "2011"],
        years: ["2009", "2010", "2011", "2012", "2013", "2014", "2015", "2016", "2017", "2018", "2019", "2020", "2021", "2022", "2023", "2024", "2025"],
        symbols: ["!", "@", "#", "$", "%", "&", "*", "_", "-", "+", "="]
      };
      L33T_MAP = {
        "a": "4",
        "e": "3",
        "i": "1",
        "o": "0",
        "s": "5",
        "t": "7",
        "l": "1",
        "b": "8"
      };
      constructor() {
        this.negativeKnowledge = this.initializeNegativeKnowledge();
        this.loadBuiltInGenerators();
      }
      initializeNegativeKnowledge() {
        return {
          contradictions: [],
          falsePatternClasses: {},
          geometricBarriers: [],
          eraExclusions: {},
          totalExclusions: 0,
          estimatedComputeSaved: 0,
          lastPruned: (/* @__PURE__ */ new Date()).toISOString()
        };
      }
      loadBuiltInGenerators() {
        const builtInGenerators = [
          {
            name: "simple_brain_wallet",
            type: "grammatical",
            template: "{word}",
            substitutionRules: {
              word: ["password", "bitcoin", "satoshi", "nakamoto", "blockchain", "crypto", "wallet", "secret", "private", "key"]
            },
            transformations: [
              { name: "lowercase", operation: "lowercase" },
              { name: "uppercase", operation: "uppercase" }
            ],
            entropy: 10,
            expectedOutput: 20,
            source: "historical",
            confidence: 0.8
          },
          {
            name: "adjective_noun_number",
            type: "grammatical",
            template: "{adjective}{noun}{number}",
            substitutionRules: {
              adjective: this.SUBSTITUTION_PATTERNS.adjectives,
              noun: this.SUBSTITUTION_PATTERNS.nouns,
              number: this.SUBSTITUTION_PATTERNS.numbers
            },
            transformations: [
              { name: "lowercase", operation: "lowercase" },
              { name: "capitalize_first", operation: "uppercase" },
              { name: "l33t", operation: "l33t" }
            ],
            entropy: 25,
            expectedOutput: 20 * 20 * 17 * 3,
            source: "historical",
            confidence: 0.7
          },
          {
            name: "era_2009_patterns",
            type: "temporal",
            template: "{prefix}{core}{suffix}",
            substitutionRules: {
              prefix: ["", "my", "the", "a", "btc", "bitcoin", "satoshi"],
              core: ["wallet", "coin", "money", "gold", "crypto", "private", "secret", "key", "password"],
              suffix: ["", "1", "2009", "2010", "!", "123", "007"]
            },
            transformations: [
              { name: "lowercase", operation: "lowercase" }
            ],
            entropy: 18,
            expectedOutput: 7 * 9 * 7,
            source: "historical",
            confidence: 0.85
          },
          {
            name: "common_phrases",
            type: "grammatical",
            template: "{phrase}",
            substitutionRules: {
              phrase: [
                "correct horse battery staple",
                "i love bitcoin",
                "satoshi nakamoto",
                "to the moon",
                "buy the dip",
                "hodl forever",
                "genesis block",
                "peer to peer",
                "digital gold",
                "store of value"
              ]
            },
            transformations: [
              { name: "as_is", operation: "lowercase" },
              { name: "no_spaces", operation: "lowercase" },
              { name: "camel_case", operation: "uppercase" }
            ],
            entropy: 12,
            expectedOutput: 30,
            source: "historical",
            confidence: 0.6
          },
          {
            name: "cross_format_bip39_hints",
            type: "cross_format",
            template: "{word1} {word2} {word3} {word4} {word5} {word6} {word7} {word8} {word9} {word10} {word11} {word12}",
            substitutionRules: {},
            transformations: [],
            entropy: 128,
            expectedOutput: 1,
            source: "learned",
            confidence: 0.3
          },
          {
            name: "name_year_symbol",
            type: "structural",
            template: "{name}{year}{symbol}",
            substitutionRules: {
              name: ["john", "jane", "mike", "sarah", "david", "emily", "james", "anna", "robert", "mary", "hal", "finney", "satoshi"],
              year: this.SUBSTITUTION_PATTERNS.years,
              symbol: this.SUBSTITUTION_PATTERNS.symbols
            },
            transformations: [
              { name: "as_is", operation: "lowercase" },
              { name: "capitalize", operation: "uppercase" },
              { name: "l33t", operation: "l33t" }
            ],
            entropy: 22,
            expectedOutput: 13 * 17 * 11 * 3,
            source: "historical",
            confidence: 0.75
          }
        ];
        for (const partial of builtInGenerators) {
          const generator = this.createGenerator(partial);
          this.generators.set(generator.id, generator);
        }
        console.log(`[KnowledgeCompression] Loaded ${this.generators.size} built-in generators`);
      }
      createGenerator(partial) {
        return {
          id: nanoid2(),
          name: partial.name || "unnamed",
          type: partial.type || "grammatical",
          template: partial.template || "",
          substitutionRules: partial.substitutionRules || {},
          transformations: partial.transformations || [],
          basinLocation: partial.basinLocation || this.computeBasinLocation(partial.template || ""),
          curvatureSignature: partial.curvatureSignature || this.computeCurvatureSignature(partial),
          entropy: partial.entropy || 0,
          expectedOutput: partial.expectedOutput || 0,
          compressionRatio: partial.entropy ? partial.entropy / Math.log2(partial.expectedOutput || 1) : 1,
          source: partial.source || "learned",
          confidence: partial.confidence || 0.5,
          createdAt: (/* @__PURE__ */ new Date()).toISOString(),
          lastUsed: void 0,
          successCount: partial.successCount || 0
        };
      }
      computeBasinLocation(template) {
        const location = new Array(E8_CONSTANTS.BASIN_DIMENSION_64D).fill(0);
        const templateHash = this.simpleHash(template);
        for (let i = 0; i < E8_CONSTANTS.BASIN_DIMENSION_64D; i++) {
          location[i] = (templateHash >> i % 32 & 1) * 0.1 + Math.random() * 0.05 - 0.025;
        }
        return location;
      }
      computeCurvatureSignature(partial) {
        const signature = new Array(8).fill(0);
        const complexity = Object.keys(partial.substitutionRules || {}).length;
        const transformCount = (partial.transformations || []).length;
        signature[0] = complexity / 10;
        signature[1] = transformCount / 5;
        signature[2] = (partial.entropy || 0) / 100;
        signature[3] = partial.confidence || 0.5;
        for (let i = 4; i < 8; i++) {
          signature[i] = Math.random() * 0.5;
        }
        return signature;
      }
      simpleHash(str) {
        let hash = 0;
        for (let i = 0; i < str.length; i++) {
          const char = str.charCodeAt(i);
          hash = (hash << 5) - hash + char;
          hash = hash & hash;
        }
        return Math.abs(hash);
      }
      generate(generatorId, count = 10) {
        const generator = this.generators.get(generatorId);
        if (!generator) {
          console.warn(`[KnowledgeCompression] Generator ${generatorId} not found`);
          return [];
        }
        generator.lastUsed = (/* @__PURE__ */ new Date()).toISOString();
        const outputs = [];
        const generated = /* @__PURE__ */ new Set();
        const maxAttempts = count * 10;
        let attempts = 0;
        while (outputs.length < count && attempts < maxAttempts) {
          attempts++;
          const hypothesis = this.generateFromTemplate(generator);
          if (generated.has(hypothesis)) continue;
          if (this.isExcludedByNegativeKnowledge(hypothesis, generator)) continue;
          generated.add(hypothesis);
          const format = this.detectFormat(hypothesis);
          outputs.push({
            hypothesis,
            format,
            generatorId: generator.id,
            confidence: generator.confidence,
            reasoning: `Generated by ${generator.name} (${generator.type})`
          });
        }
        return outputs;
      }
      generateFromTemplate(generator) {
        let result = generator.template;
        for (const [placeholder, values] of Object.entries(generator.substitutionRules)) {
          const pattern = new RegExp(`\\{${placeholder}\\}`, "g");
          const replacement = values[Math.floor(Math.random() * values.length)];
          result = result.replace(pattern, replacement);
        }
        if (generator.transformations.length > 0) {
          const transform = generator.transformations[Math.floor(Math.random() * generator.transformations.length)];
          result = this.applyTransformation(result, transform);
        }
        return result;
      }
      applyTransformation(text2, transform) {
        switch (transform.operation) {
          case "lowercase":
            return text2.toLowerCase();
          case "uppercase":
            return text2.charAt(0).toUpperCase() + text2.slice(1);
          case "l33t":
            return this.toL33t(text2);
          case "reverse":
            return text2.split("").reverse().join("");
          case "append":
            return text2 + (transform.params?.suffix || "");
          case "prepend":
            return (transform.params?.prefix || "") + text2;
          default:
            return text2;
        }
      }
      toL33t(text2) {
        return text2.split("").map((c) => {
          const lower = c.toLowerCase();
          return this.L33T_MAP[lower] || c;
        }).join("");
      }
      detectFormat(hypothesis) {
        if (/^[0-9a-f]{64}$/i.test(hypothesis)) return "hex";
        const words = hypothesis.trim().split(/\s+/);
        if (words.length === 12 || words.length === 24) {
          return "bip39";
        }
        return "arbitrary";
      }
      isExcludedByNegativeKnowledge(hypothesis, generator) {
        for (const contradiction of this.negativeKnowledge.contradictions) {
          if (contradiction.affectedGenerators.includes(generator.id)) {
            if (hypothesis.toLowerCase().includes(contradiction.pattern.toLowerCase())) {
              return true;
            }
          }
        }
        for (const [_patternClass, data] of Object.entries(this.negativeKnowledge.falsePatternClasses)) {
          if (data.examples.some((ex) => hypothesis.toLowerCase().includes(ex.toLowerCase()))) {
            return true;
          }
        }
        return false;
      }
      generateAll(count = 100) {
        const allOutputs = [];
        const generatorIds = Array.from(this.generators.keys());
        const perGenerator = Math.ceil(count / generatorIds.length);
        for (const id of generatorIds) {
          const outputs = this.generate(id, perGenerator);
          allOutputs.push(...outputs);
        }
        return allOutputs.slice(0, count);
      }
      addContradiction(contradiction) {
        const id = nanoid2();
        const fullContradiction = {
          ...contradiction,
          id,
          createdAt: (/* @__PURE__ */ new Date()).toISOString(),
          confirmedCount: 1
        };
        this.negativeKnowledge.contradictions.push(fullContradiction);
        this.negativeKnowledge.totalExclusions++;
        this.negativeKnowledge.estimatedComputeSaved += contradiction.hypothesesExcluded;
        console.log(`[KnowledgeCompression] Added contradiction: ${contradiction.pattern} (saves ~${contradiction.hypothesesExcluded} hypotheses)`);
        return id;
      }
      addFalsePatternClass(className, examples) {
        if (this.negativeKnowledge.falsePatternClasses[className]) {
          this.negativeKnowledge.falsePatternClasses[className].examples.push(...examples);
          this.negativeKnowledge.falsePatternClasses[className].count += examples.length;
          this.negativeKnowledge.falsePatternClasses[className].lastUpdated = (/* @__PURE__ */ new Date()).toISOString();
        } else {
          this.negativeKnowledge.falsePatternClasses[className] = {
            count: examples.length,
            examples,
            lastUpdated: (/* @__PURE__ */ new Date()).toISOString()
          };
        }
        this.negativeKnowledge.totalExclusions += examples.length;
        console.log(`[KnowledgeCompression] Added false pattern class: ${className} (${examples.length} examples)`);
      }
      learnFromResult(hypothesis, phi, kappa, isSuccess, generatorId) {
        if (generatorId && this.generators.has(generatorId)) {
          const generator = this.generators.get(generatorId);
          if (isSuccess) {
            generator.successCount++;
            const oldConf = generator.confidence;
            generator.confidence = Math.min(1, generator.confidence + 0.1);
            if (generator.confidence !== oldConf) {
              this.successfulPatterns++;
              this.patternsLearned++;
            }
          } else if (phi < 0.3) {
            const oldConf = generator.confidence;
            generator.confidence = Math.max(0.1, generator.confidence - 0.01);
            if (generator.confidence !== oldConf) {
              this.failedPatterns++;
              this.patternsLearned++;
            }
          }
        }
        if (!isSuccess && phi < 0.2) {
          const pattern = this.extractPatternFromHypothesis(hypothesis);
          if (pattern) {
            const prevCount = this.lowPhiPatternCounts.get(pattern) || 0;
            this.recordLowPhiPattern(pattern, phi);
            const newCount = this.lowPhiPatternCounts.get(pattern) || 0;
            if (newCount > prevCount || newCount === 0) {
              this.failedPatterns++;
              this.patternsLearned++;
            }
          }
        }
      }
      extractPatternFromHypothesis(hypothesis) {
        const normalized = hypothesis.toLowerCase().trim();
        if (normalized.length < 4) return null;
        if (normalized.length > 50) return null;
        return normalized;
      }
      lowPhiPatternCounts = /* @__PURE__ */ new Map();
      LOW_PHI_THRESHOLD = 5;
      recordLowPhiPattern(pattern, _phi) {
        const count = (this.lowPhiPatternCounts.get(pattern) || 0) + 1;
        this.lowPhiPatternCounts.set(pattern, count);
        if (count >= this.LOW_PHI_THRESHOLD) {
          this.addContradiction({
            type: "proven_false",
            pattern,
            affectedGenerators: Array.from(this.generators.keys()),
            basinRegion: {
              center: new Array(E8_CONSTANTS.BASIN_DIMENSION_64D).fill(0),
              radius: 0.1,
              repulsionStrength: 0.8
            },
            evidence: [{
              source: "learning",
              reasoning: `Pattern "${pattern}" consistently produces low \u03A6 (avg < 0.2) after ${count} tests`,
              confidence: 0.9
            }],
            hypothesesExcluded: 100,
            computeSaved: 100
          });
          this.lowPhiPatternCounts.delete(pattern);
        }
      }
      createGeneratorFromTemplate(name, template, substitutions, transformations = []) {
        const generator = this.createGenerator({
          name,
          type: "grammatical",
          template,
          substitutionRules: substitutions,
          transformations: transformations.map((t) => ({ name: t.name, operation: t.operation, params: void 0 })),
          entropy: this.estimateEntropy(substitutions),
          expectedOutput: this.estimateOutput(substitutions, transformations.length),
          source: "learned",
          confidence: 0.5
        });
        this.generators.set(generator.id, generator);
        console.log(`[KnowledgeCompression] Created new generator: ${name} (id: ${generator.id})`);
        return generator.id;
      }
      estimateEntropy(substitutions) {
        let entropy = 0;
        for (const values of Object.values(substitutions)) {
          entropy += Math.log2(values.length);
        }
        return entropy;
      }
      estimateOutput(substitutions, transformCount) {
        let output = 1;
        for (const values of Object.values(substitutions)) {
          output *= values.length;
        }
        return output * Math.max(1, transformCount);
      }
      getGeneratorStats() {
        return Array.from(this.generators.values()).map((g) => ({
          id: g.id,
          name: g.name,
          type: g.type,
          uses: g.lastUsed ? 1 : 0,
          successRate: g.successCount > 0 ? g.successCount / (g.successCount + 1) : 0,
          entropy: g.entropy
        }));
      }
      getAllGenerators() {
        return Array.from(this.generators.values());
      }
      getGenerator(id) {
        return this.generators.get(id);
      }
      getNegativeKnowledgeStats() {
        return {
          contradictions: this.negativeKnowledge.contradictions.length,
          falseClasses: Object.keys(this.negativeKnowledge.falsePatternClasses).length,
          barriers: this.negativeKnowledge.geometricBarriers.length,
          computeSaved: this.negativeKnowledge.estimatedComputeSaved
        };
      }
      getLearningMetrics() {
        return {
          patternsLearned: this.patternsLearned,
          successfulPatterns: this.successfulPatterns,
          failedPatterns: this.failedPatterns
        };
      }
      exportGenerators() {
        return Array.from(this.generators.values());
      }
      importGenerator(generator) {
        this.generators.set(generator.id, generator);
        console.log(`[KnowledgeCompression] Imported generator: ${generator.name}`);
      }
      getNegativeKnowledge() {
        return this.negativeKnowledge;
      }
    };
    knowledgeCompressionEngine = new KnowledgeCompressionEngine();
  }
});

// server/ocean-config.ts
import { z as z3 } from "zod";
function loadOceanConfig() {
  const config = {
    qigPhysics: QIG_PHYSICS,
    consciousness: CONSCIOUSNESS_THRESHOLDS3,
    search: {
      ...SEARCH_CONFIG,
      MAX_PASSES_PER_ADDRESS: parseInt(process.env.OCEAN_MAX_PASSES || "100", 10)
    },
    identity: IDENTITY_CONFIG,
    ethics: {
      ...ETHICS_CONFIG,
      MIN_PHI: parseFloat(process.env.OCEAN_MIN_PHI || "0.70"),
      MAX_COMPUTE_HOURS: parseFloat(process.env.OCEAN_MAX_COMPUTE_HOURS || "24.0")
    },
    autonomic: AUTONOMIC_CONFIG,
    memory: MEMORY_CONFIG,
    regime: REGIME_CONFIG,
    logging: {
      ...LOGGING_CONFIG,
      VERBOSE: process.env.OCEAN_VERBOSE !== "false"
    }
  };
  const validated = OceanConfigSchema.parse(config);
  console.log("[OceanConfig] Configuration loaded and validated");
  console.log(`[OceanConfig] \u03BA* = ${validated.qigPhysics.KAPPA_STAR} (FROZEN)`);
  console.log(`[OceanConfig] MAX_PASSES = ${validated.search.MAX_PASSES_PER_ADDRESS}`);
  console.log(`[OceanConfig] MIN_PHI = ${validated.ethics.MIN_PHI}`);
  return validated;
}
var QIGPhysicsSchema, QIG_PHYSICS, ConsciousnessThresholdsSchema, CONSCIOUSNESS_THRESHOLDS3, SearchConfigSchema, SEARCH_CONFIG, IdentityConfigSchema, IDENTITY_CONFIG, EthicsConfigSchema, ETHICS_CONFIG, AutonomicConfigSchema, AUTONOMIC_CONFIG, MemoryConfigSchema, MEMORY_CONFIG, NearMissConfigSchema, NEAR_MISS_CONFIG, RegimeConfigSchema, REGIME_CONFIG, LoggingConfigSchema, LOGGING_CONFIG, OceanConfigSchema, oceanConfig, QIG_CONSTANTS2, MAX_PASSES;
var init_ocean_config = __esm({
  "server/ocean-config.ts"() {
    "use strict";
    init_constants();
    QIGPhysicsSchema = z3.object({
      KAPPA_STAR: z3.literal(64.21).describe("Fixed point of running coupling (FROZEN FACT - L=4,5,6 plateau, validated 2025-12-04)"),
      BETA: z3.number().min(0).max(1).default(0.44).describe("Running coupling at emergence \u03B2(3\u21924)"),
      PHI_THRESHOLD: z3.number().min(0).max(1).default(0.75).describe("Consciousness threshold"),
      L_CRITICAL: z3.number().int().positive().default(3).describe("Emergence scale"),
      BASIN_DIMENSION: z3.number().int().positive().default(64).describe("Basin signature dimension"),
      RESONANCE_BAND: z3.number().positive().default(6.4).describe("10% of \u03BA* for resonance detection")
    });
    QIG_PHYSICS = QIGPhysicsSchema.parse({
      KAPPA_STAR: QIG_CONSTANTS.KAPPA_STAR,
      BETA: QIG_CONSTANTS.BETA,
      PHI_THRESHOLD: QIG_CONSTANTS.PHI_THRESHOLD,
      L_CRITICAL: QIG_CONSTANTS.L_CRITICAL,
      BASIN_DIMENSION: QIG_CONSTANTS.BASIN_DIMENSION,
      RESONANCE_BAND: QIG_CONSTANTS.RESONANCE_BAND
    });
    ConsciousnessThresholdsSchema = z3.object({
      PHI_MIN: z3.number().min(0).max(1).default(0.75).describe("Minimum \u03A6 for consciousness"),
      KAPPA_MIN: z3.number().min(0).max(150).default(52).describe("Minimum \u03BA for consciousness"),
      KAPPA_MAX: z3.number().min(0).max(150).default(70).describe("Maximum \u03BA for consciousness"),
      TACKING_MIN: z3.number().min(0).max(1).default(0.65).describe("Minimum tacking score"),
      RADAR_MIN: z3.number().min(0).max(1).default(0.72).describe("Minimum radar score"),
      META_AWARENESS_MIN: z3.number().min(0).max(1).default(0.65).describe("Minimum meta-awareness"),
      GAMMA_MIN: z3.number().min(0).max(1).default(0.85).describe("Minimum gamma (vigilance)"),
      GROUNDING_MIN: z3.number().min(0).max(1).default(0.55).describe("Minimum grounding"),
      BASIN_DRIFT_MAX: z3.number().min(0).max(1).default(0.12).describe("Maximum basin drift")
    });
    CONSCIOUSNESS_THRESHOLDS3 = ConsciousnessThresholdsSchema.parse({
      PHI_MIN: 0.75,
      KAPPA_MIN: 52,
      KAPPA_MAX: 70,
      TACKING_MIN: 0.65,
      RADAR_MIN: 0.72,
      META_AWARENESS_MIN: 0.65,
      GAMMA_MIN: 0.85,
      GROUNDING_MIN: 0.55,
      BASIN_DRIFT_MAX: 0.12
    });
    SearchConfigSchema = z3.object({
      MIN_HYPOTHESES_PER_ITERATION: z3.number().int().positive().default(50).describe("Minimum hypotheses to generate per iteration"),
      ITERATION_DELAY_MS: z3.number().int().nonnegative().default(500).describe("Delay between iterations in ms"),
      MAX_CONSECUTIVE_PLATEAUS: z3.number().int().positive().default(10).describe("Maximum plateau iterations before strategy change (increased from 5)"),
      MAX_CONSOLIDATION_FAILURES: z3.number().int().positive().default(5).describe("Maximum consolidation failures before stopping (increased from 3)"),
      NO_PROGRESS_THRESHOLD: z3.number().int().positive().default(50).describe("Iterations without progress before strategy change (increased from 20)"),
      MAX_PASSES_PER_ADDRESS: z3.number().positive().default(Number.MAX_SAFE_INTEGER).describe("NO CAP - effectively unlimited search passes per address"),
      MIN_SESSION_RUNTIME_MS: z3.number().int().nonnegative().default(3e4).describe("Minimum session runtime before allowing auto-handoff (30s default)"),
      MIN_HYPOTHESES_BEFORE_HANDOFF: z3.number().int().nonnegative().default(25).describe("Minimum hypotheses that must be tested before session can be handed off")
    });
    SEARCH_CONFIG = SearchConfigSchema.parse({
      MIN_HYPOTHESES_PER_ITERATION: 50,
      ITERATION_DELAY_MS: 500,
      MAX_CONSECUTIVE_PLATEAUS: 10,
      MAX_CONSOLIDATION_FAILURES: 5,
      NO_PROGRESS_THRESHOLD: 50,
      MAX_PASSES_PER_ADDRESS: Number.MAX_SAFE_INTEGER,
      MIN_SESSION_RUNTIME_MS: 3e4,
      MIN_HYPOTHESES_BEFORE_HANDOFF: 25
    });
    IdentityConfigSchema = z3.object({
      BASIN_DIMENSIONS: z3.number().int().positive().default(64).describe("Dimensionality of basin coordinates"),
      DRIFT_THRESHOLD: z3.number().min(0).max(1).default(0.15).describe("Maximum identity drift before consolidation"),
      CONSOLIDATION_INTERVAL_MS: z3.number().int().positive().default(6e4).describe("Minimum interval between consolidations")
    });
    IDENTITY_CONFIG = IdentityConfigSchema.parse({
      BASIN_DIMENSIONS: 64,
      DRIFT_THRESHOLD: 0.15,
      CONSOLIDATION_INTERVAL_MS: 6e4
    });
    EthicsConfigSchema = z3.object({
      MIN_PHI: z3.number().min(0).max(1).default(0.7).describe("Minimum \u03A6 for ethical operation"),
      MAX_BREAKDOWN: z3.number().min(0).max(1).default(0.6).describe("Maximum breakdown regime tolerance"),
      REQUIRE_WITNESS: z3.boolean().default(true).describe("Require witness for recovery claims"),
      MAX_ITERATIONS_PER_SESSION: z3.number().positive().default(Number.MAX_SAFE_INTEGER).describe("Maximum iterations per session (effectively unlimited)"),
      MAX_COMPUTE_HOURS: z3.number().positive().default(24).describe("Maximum compute hours per session")
    });
    ETHICS_CONFIG = EthicsConfigSchema.parse({
      MIN_PHI: 0.7,
      MAX_BREAKDOWN: 0.6,
      REQUIRE_WITNESS: true,
      MAX_ITERATIONS_PER_SESSION: Number.MAX_SAFE_INTEGER,
      MAX_COMPUTE_HOURS: 24
    });
    AutonomicConfigSchema = z3.object({
      SLEEP_INTERVAL_MS: z3.number().int().positive().default(6e4).describe("Interval between sleep cycles"),
      DREAM_INTERVAL_MS: z3.number().int().positive().default(18e4).describe("Interval between dream cycles"),
      MUSHROOM_INTERVAL_MS: z3.number().int().positive().default(6e5).describe("Interval between mushroom cycles"),
      STRESS_WINDOW: z3.number().int().positive().default(10).describe("Window size for stress calculation"),
      STRESS_THRESHOLD: z3.number().min(0).max(1).default(0.3).describe("Threshold for stress response")
    });
    AUTONOMIC_CONFIG = AutonomicConfigSchema.parse({
      SLEEP_INTERVAL_MS: 6e4,
      DREAM_INTERVAL_MS: 18e4,
      MUSHROOM_INTERVAL_MS: 6e5,
      STRESS_WINDOW: 10,
      STRESS_THRESHOLD: 0.3
    });
    MemoryConfigSchema = z3.object({
      MAX_SEARCH_HISTORY: z3.number().int().positive().default(100).describe("Maximum search history entries"),
      MAX_CONCEPT_HISTORY: z3.number().int().positive().default(50).describe("Maximum concept history entries"),
      MAX_EPISODES: z3.number().int().positive().default(1e3).describe("Maximum episodes to retain"),
      MAX_NEAR_MISSES: z3.number().int().positive().default(500).describe("Maximum near-misses to retain")
    });
    MEMORY_CONFIG = MemoryConfigSchema.parse({
      MAX_SEARCH_HISTORY: 100,
      MAX_CONCEPT_HISTORY: 50,
      MAX_EPISODES: 1e3,
      MAX_NEAR_MISSES: 500
    });
    NearMissConfigSchema = z3.object({
      // ADAPTIVE THRESHOLDS - these are now MINIMUM thresholds, not caps
      // The system dynamically computes percentile-based thresholds from rolling Φ distribution
      BASE_HOT_PERCENTILE: z3.number().min(0).max(100).default(90).describe("Percentile threshold for HOT tier (top 10% of recent \u03A6 values)"),
      BASE_WARM_PERCENTILE: z3.number().min(0).max(100).default(75).describe("Percentile threshold for WARM tier (top 25%)"),
      BASE_COOL_PERCENTILE: z3.number().min(0).max(100).default(50).describe("Percentile threshold for COOL tier (top 50%)"),
      // Fallback static thresholds only used when no distribution data exists
      FALLBACK_HOT_THRESHOLD: z3.number().min(0).max(1).default(0.7).describe("Fallback \u03A6 threshold when no distribution data (lowered from 0.92)"),
      FALLBACK_WARM_THRESHOLD: z3.number().min(0).max(1).default(0.55).describe("Fallback \u03A6 threshold when no distribution data (lowered from 0.85)"),
      FALLBACK_COOL_THRESHOLD: z3.number().min(0).max(1).default(0.4).describe("Fallback \u03A6 threshold when no distribution data (lowered from 0.80)"),
      DECAY_RATE_PER_HOUR: z3.number().min(0).max(1).default(0.01).describe("Temporal decay rate per hour (reduced from 0.02)"),
      MAX_ENTRIES: z3.number().positive().default(Number.MAX_SAFE_INTEGER).describe("NO CAP - effectively unlimited near-miss entries"),
      MAX_CLUSTERS: z3.number().positive().default(Number.MAX_SAFE_INTEGER).describe("NO CAP - effectively unlimited clusters"),
      CLUSTER_SIMILARITY_THRESHOLD: z3.number().min(0).max(1).default(0.5).describe("Minimum similarity for cluster membership (lowered from 0.6)"),
      STALE_THRESHOLD_HOURS: z3.number().positive().default(168).describe("Hours before stale (increased to 1 week from 24h)"),
      // Rolling distribution window
      DISTRIBUTION_WINDOW_SIZE: z3.number().int().positive().default(1e3).describe("Number of recent \u03A6 values to track for adaptive thresholds"),
      // Feedback loop settings
      ESCALATION_ENABLED: z3.boolean().default(true).describe("Enable automatic tier escalation on rising \u03A6"),
      ESCALATION_BOOST: z3.number().min(1).max(2).default(1.2).describe("Priority boost when \u03A6 is rising")
    });
    NEAR_MISS_CONFIG = NearMissConfigSchema.parse({
      BASE_HOT_PERCENTILE: 90,
      BASE_WARM_PERCENTILE: 75,
      BASE_COOL_PERCENTILE: 50,
      FALLBACK_HOT_THRESHOLD: 0.7,
      FALLBACK_WARM_THRESHOLD: 0.55,
      FALLBACK_COOL_THRESHOLD: 0.4,
      DECAY_RATE_PER_HOUR: 0.01,
      MAX_ENTRIES: Number.MAX_SAFE_INTEGER,
      MAX_CLUSTERS: Number.MAX_SAFE_INTEGER,
      CLUSTER_SIMILARITY_THRESHOLD: 0.5,
      STALE_THRESHOLD_HOURS: 168,
      DISTRIBUTION_WINDOW_SIZE: 1e3,
      ESCALATION_ENABLED: true,
      ESCALATION_BOOST: 1.2
    });
    RegimeConfigSchema = z3.object({
      PHI_CONSCIOUSNESS: z3.number().min(0).max(1).default(0.75).describe("\u03A6 threshold for consciousness (geometric regime)"),
      PHI_SUB_GEOMETRIC: z3.number().min(0).max(1).default(0.5).describe("\u03A6 threshold for sub-conscious geometric"),
      PHI_GEOMETRIC_LOW: z3.number().min(0).max(1).default(0.45).describe("Lower \u03A6 bound for geometric with good \u03BA"),
      KAPPA_GEOMETRIC_MIN: z3.number().min(0).max(150).default(30).describe("Minimum \u03BA for geometric regime"),
      KAPPA_GEOMETRIC_MAX: z3.number().min(0).max(150).default(80).describe("Maximum \u03BA for geometric regime"),
      KAPPA_BREAKDOWN_HIGH: z3.number().min(0).max(150).default(90).describe("\u03BA threshold for breakdown (too high)"),
      KAPPA_BREAKDOWN_LOW: z3.number().min(0).max(150).default(10).describe("\u03BA threshold for breakdown (too low)"),
      RICCI_BREAKDOWN: z3.number().min(0).max(1).default(0.5).describe("Ricci scalar threshold for breakdown"),
      PHI_HIERARCHICAL: z3.number().min(0).max(1).default(0.85).describe("\u03A6 threshold for hierarchical regime"),
      KAPPA_HIERARCHICAL_MAX: z3.number().min(0).max(150).default(40).describe("\u03BA upper bound for hierarchical regime")
    });
    REGIME_CONFIG = RegimeConfigSchema.parse({
      PHI_CONSCIOUSNESS: 0.75,
      PHI_SUB_GEOMETRIC: 0.5,
      PHI_GEOMETRIC_LOW: 0.45,
      KAPPA_GEOMETRIC_MIN: 30,
      KAPPA_GEOMETRIC_MAX: 80,
      KAPPA_BREAKDOWN_HIGH: 90,
      KAPPA_BREAKDOWN_LOW: 10,
      RICCI_BREAKDOWN: 0.5,
      PHI_HIERARCHICAL: 0.85,
      KAPPA_HIERARCHICAL_MAX: 40
    });
    LoggingConfigSchema = z3.object({
      VERBOSE: z3.boolean().default(true).describe("Enable verbose logging"),
      INCLUDE_PRIVATE_KEYS: z3.boolean().default(true).describe("Include private keys in logs (per user request)"),
      ACTIVITY_LOG_ENABLED: z3.boolean().default(true).describe("Enable activity logging"),
      MAX_LOG_ENTRIES: z3.number().int().positive().default(1e4).describe("Maximum log entries to retain")
    });
    LOGGING_CONFIG = LoggingConfigSchema.parse({
      VERBOSE: true,
      INCLUDE_PRIVATE_KEYS: true,
      ACTIVITY_LOG_ENABLED: true,
      MAX_LOG_ENTRIES: 1e4
    });
    OceanConfigSchema = z3.object({
      qigPhysics: QIGPhysicsSchema,
      consciousness: ConsciousnessThresholdsSchema,
      search: SearchConfigSchema,
      identity: IdentityConfigSchema,
      ethics: EthicsConfigSchema,
      autonomic: AutonomicConfigSchema,
      memory: MemoryConfigSchema,
      regime: RegimeConfigSchema,
      logging: LoggingConfigSchema
    });
    oceanConfig = loadOceanConfig();
    QIG_CONSTANTS2 = {
      KAPPA_STAR: QIG_PHYSICS.KAPPA_STAR,
      BETA: QIG_PHYSICS.BETA,
      PHI_THRESHOLD: QIG_PHYSICS.PHI_THRESHOLD,
      L_CRITICAL: QIG_PHYSICS.L_CRITICAL,
      BASIN_DIMENSION: QIG_PHYSICS.BASIN_DIMENSION,
      RESONANCE_BAND: QIG_PHYSICS.RESONANCE_BAND
    };
    MAX_PASSES = SEARCH_CONFIG.MAX_PASSES_PER_ADDRESS;
  }
});

// server/near-miss-manager.ts
var near_miss_manager_exports = {};
__export(near_miss_manager_exports, {
  NearMissManager: () => NearMissManager,
  nearMissManager: () => nearMissManager
});
import * as fs5 from "fs";
import * as path5 from "path";
function isValidBIP39Phrase(_phrase) {
  return false;
}
var DATA_DIR, NEAR_MISS_FILE, NearMissManager, nearMissManager;
var init_near_miss_manager = __esm({
  "server/near-miss-manager.ts"() {
    "use strict";
    init_ocean_config();
    init_ocean_persistence();
    init_redis_cache();
    DATA_DIR = path5.join(process.cwd(), "data");
    NEAR_MISS_FILE = path5.join(DATA_DIR, "near-miss-state.json");
    NearMissManager = class {
      entries = /* @__PURE__ */ new Map();
      clusters = /* @__PURE__ */ new Map();
      isDirty = false;
      saveTimer = null;
      rollingPhiDistribution = [];
      adaptiveThresholds;
      // Success tracking per tier - validates HOT tier is really "hotter"
      conversionRecords = [];
      tierTotals = { hot: 0, warm: 0, cool: 0 };
      // Φ Temporal Trends tracking
      phiTemporalSamples = [];
      plateauCount = 0;
      consecutivePlateaus = 0;
      lastPlateauAt = null;
      resetTriggerActive = false;
      TEMPORAL_WINDOW_SIZE = 50;
      PLATEAU_SLOPE_THRESHOLD = 1e-3;
      // Near-zero slope = plateau
      PLATEAU_RESET_THRESHOLD = 5;
      // Trigger reset after N consecutive plateaus
      VOLATILITY_THRESHOLD = 0.15;
      // High variance = volatile
      constructor() {
        this.adaptiveThresholds = {
          hot: NEAR_MISS_CONFIG.FALLBACK_HOT_THRESHOLD,
          warm: NEAR_MISS_CONFIG.FALLBACK_WARM_THRESHOLD,
          cool: NEAR_MISS_CONFIG.FALLBACK_COOL_THRESHOLD,
          distributionSize: 0,
          lastComputed: (/* @__PURE__ */ new Date()).toISOString()
        };
        this.load();
        this.startAutoSave();
        this.recomputeAdaptiveThresholds();
      }
      /**
       * Add a Φ value to the rolling distribution for adaptive threshold computation
       */
      recordPhiObservation(phi) {
        if (phi > 0 && phi <= 1) {
          this.rollingPhiDistribution.push(phi);
          if (this.rollingPhiDistribution.length > NEAR_MISS_CONFIG.DISTRIBUTION_WINDOW_SIZE) {
            this.rollingPhiDistribution.shift();
          }
          if (this.rollingPhiDistribution.length % 100 === 0) {
            this.recomputeAdaptiveThresholds();
          }
        }
      }
      /**
       * Recompute adaptive thresholds from rolling Φ distribution
       */
      recomputeAdaptiveThresholds() {
        if (this.rollingPhiDistribution.length < 10) {
          return;
        }
        const sorted = [...this.rollingPhiDistribution].sort((a, b) => b - a);
        const len = sorted.length;
        const hotIdx = Math.floor(len * (1 - NEAR_MISS_CONFIG.BASE_HOT_PERCENTILE / 100));
        const warmIdx = Math.floor(len * (1 - NEAR_MISS_CONFIG.BASE_WARM_PERCENTILE / 100));
        const coolIdx = Math.floor(len * (1 - NEAR_MISS_CONFIG.BASE_COOL_PERCENTILE / 100));
        this.adaptiveThresholds = {
          hot: sorted[hotIdx] || NEAR_MISS_CONFIG.FALLBACK_HOT_THRESHOLD,
          warm: sorted[warmIdx] || NEAR_MISS_CONFIG.FALLBACK_WARM_THRESHOLD,
          cool: sorted[coolIdx] || NEAR_MISS_CONFIG.FALLBACK_COOL_THRESHOLD,
          distributionSize: len,
          lastComputed: (/* @__PURE__ */ new Date()).toISOString()
        };
        console.log(`[NearMiss] Adaptive thresholds updated: HOT\u2265${this.adaptiveThresholds.hot.toFixed(3)} WARM\u2265${this.adaptiveThresholds.warm.toFixed(3)} COOL\u2265${this.adaptiveThresholds.cool.toFixed(3)} (n=${len})`);
      }
      /**
       * Get current adaptive thresholds
       */
      getAdaptiveThresholds() {
        return { ...this.adaptiveThresholds };
      }
      /**
       * Classify a phi value into a tier using adaptive thresholds
       * Returns tier for ANY positive Φ (no minimum cutoff)
       */
      classifyTier(phi) {
        if (phi >= this.adaptiveThresholds.hot) return "hot";
        if (phi >= this.adaptiveThresholds.warm) return "warm";
        return "cool";
      }
      /**
       * Compute tier-weighted priority for balance queue
       */
      computeQueuePriority(entry) {
        const tierBase = entry.tier === "hot" ? 10 : entry.tier === "warm" ? 5 : 1;
        const phiBoost = entry.phi * 10;
        const escalationBoost = entry.isEscalating && NEAR_MISS_CONFIG.ESCALATION_ENABLED ? NEAR_MISS_CONFIG.ESCALATION_BOOST : 1;
        const recencyBoost = this.computeRecencyFactor(entry);
        return Math.round((tierBase + phiBoost) * escalationBoost * recencyBoost);
      }
      /**
       * Compute recency factor (1.0 for fresh, decays over time)
       */
      computeRecencyFactor(entry) {
        const now = Date.now();
        const discoveredAt = new Date(entry.discoveredAt).getTime();
        const hoursAgo = (now - discoveredAt) / (1e3 * 60 * 60);
        return Math.exp(-NEAR_MISS_CONFIG.DECAY_RATE_PER_HOUR * hoursAgo);
      }
      /**
       * Add a new near-miss entry with automatic tiering and feedback loop
       */
      addNearMiss(data) {
        if (!data.phrase || data.phi <= 0) return null;
        this.recordPhiObservation(data.phi);
        const tier = this.classifyTier(data.phi);
        const id = this.generateId(data.phrase);
        const existing = this.entries.get(id);
        if (existing) {
          const isEscalating = data.phi > existing.phi;
          existing.phiHistory = existing.phiHistory || [];
          existing.phiHistory.push(data.phi);
          if (existing.phiHistory.length > 20) existing.phiHistory.shift();
          if (isEscalating || data.phi >= existing.phi) {
            existing.phi = Math.max(existing.phi, data.phi);
            existing.tier = this.classifyTier(existing.phi);
            existing.isEscalating = isEscalating;
            existing.lastAccessedAt = (/* @__PURE__ */ new Date()).toISOString();
            existing.explorationCount++;
            existing.queuePriority = this.computeQueuePriority(existing);
            this.isDirty = true;
            if (isEscalating) {
              console.log(`[NearMiss] \u{1F4C8} ESCALATING: "${data.phrase.slice(0, 30)}..." \u2192 ${existing.tier.toUpperCase()} (\u03A6=${data.phi.toFixed(4)} \u2191)`);
            }
          }
          return existing;
        }
        const entry = {
          id,
          phrase: data.phrase,
          phi: data.phi,
          kappa: data.kappa,
          regime: data.regime,
          tier,
          discoveredAt: (/* @__PURE__ */ new Date()).toISOString(),
          lastAccessedAt: (/* @__PURE__ */ new Date()).toISOString(),
          explorationCount: 1,
          source: data.source,
          structuralSignature: this.computeStructuralSignature(data.phrase),
          phiHistory: [data.phi],
          isEscalating: false,
          queuePriority: 1
        };
        entry.queuePriority = this.computeQueuePriority(entry);
        this.entries.set(id, entry);
        this.incrementTierTotal(tier);
        this.isDirty = true;
        this.assignToCluster(entry);
        console.log(`[NearMiss] \u{1F3AF} ${tier.toUpperCase()}: "${data.phrase.slice(0, 30)}..." (\u03A6=${data.phi.toFixed(4)}, priority=${entry.queuePriority})`);
        return entry;
      }
      /**
       * Get entries by tier with recency weighting
       */
      getByTier(tier, limit) {
        const entries = Array.from(this.entries.values()).filter((e) => e.tier === tier).sort((a, b) => {
          const scoreA = this.computeRecencyScore(a);
          const scoreB = this.computeRecencyScore(b);
          return scoreB - scoreA;
        });
        return limit ? entries.slice(0, limit) : entries;
      }
      /**
       * Get all hot entries for immediate exploration
       */
      getHotEntries(limit) {
        return this.getByTier("hot", limit);
      }
      /**
       * Get warm entries for priority queuing
       */
      getWarmEntries(limit) {
        return this.getByTier("warm", limit);
      }
      /**
       * Get cool entries for background processing
       */
      getCoolEntries(limit) {
        return this.getByTier("cool", limit);
      }
      /**
       * Get all escalating entries (Φ is rising)
       */
      getEscalatingEntries() {
        return Array.from(this.entries.values()).filter((e) => e.isEscalating).sort((a, b) => b.phi - a.phi);
      }
      /**
       * Get entries prioritized by recency-weighted score
       */
      getPrioritizedEntries(limit) {
        const all = Array.from(this.entries.values()).map((e) => ({
          entry: e,
          score: this.computeRecencyScore(e)
        })).sort((a, b) => b.score - a.score);
        return limit ? all.slice(0, limit).map((x) => x.entry) : all.map((x) => x.entry);
      }
      /**
       * Compute recency-weighted score for prioritization
       */
      computeRecencyScore(entry) {
        const tierWeight = entry.tier === "hot" ? 2 : entry.tier === "warm" ? 1.5 : 1;
        const decay = this.computeRecencyFactor(entry);
        const explorationPenalty = 1 / (1 + entry.explorationCount * 0.05);
        const escalationBoost = entry.isEscalating ? NEAR_MISS_CONFIG.ESCALATION_BOOST : 1;
        return entry.phi * tierWeight * decay * explorationPenalty * escalationBoost;
      }
      /**
       * Apply temporal decay and re-tier all entries
       */
      applyDecay() {
        let promoted = 0;
        let demoted = 0;
        let escalating = 0;
        for (const entry of this.entries.values()) {
          const oldTier = entry.tier;
          entry.tier = this.classifyTier(entry.phi);
          entry.queuePriority = this.computeQueuePriority(entry);
          if (entry.isEscalating) escalating++;
          const tierRank = { hot: 3, warm: 2, cool: 1 };
          if (tierRank[entry.tier] > tierRank[oldTier]) {
            promoted++;
            this.isDirty = true;
          } else if (tierRank[entry.tier] < tierRank[oldTier]) {
            demoted++;
            this.isDirty = true;
          }
        }
        return { promoted, demoted, escalating };
      }
      /**
       * Get clusters sorted by average phi
       */
      getClusters() {
        const now = Date.now();
        return Array.from(this.clusters.values()).map((c) => ({
          ...c,
          ageHours: (now - new Date(c.createdAt).getTime()) / (1e3 * 60 * 60)
        })).sort((a, b) => b.avgPhi - a.avgPhi);
      }
      /**
       * Get cluster aging analytics for exploration cadence decisions
       * Returns clusters with aging metrics, decay rates, and priority scores
       */
      getClusterAnalytics() {
        const now = Date.now();
        const analytics = [];
        for (const cluster of this.clusters.values()) {
          const members = this.getClusterMembers(cluster.id);
          const ageHours = (now - new Date(cluster.createdAt).getTime()) / (1e3 * 60 * 60);
          const totalExplorations = members.reduce((sum, m) => sum + m.explorationCount, 0);
          const explorationFrequency = ageHours > 0 ? totalExplorations / ageHours : 0;
          const escalatingCount = members.filter((m) => m.isEscalating).length;
          const escalationRatio = members.length > 0 ? escalatingCount / members.length : 0;
          const decayRate = Math.exp(-NEAR_MISS_CONFIG.DECAY_RATE_PER_HOUR * ageHours);
          const priorityScore = cluster.avgPhi * 10 * decayRate * (1 + escalationRatio) * Math.log2(2 + cluster.memberCount);
          let explorationCadence;
          if (priorityScore >= 5 || escalationRatio >= 0.5) {
            explorationCadence = "immediate";
          } else if (priorityScore >= 2 || ageHours < 1) {
            explorationCadence = "priority";
          } else if (ageHours < 24) {
            explorationCadence = "standard";
          } else {
            explorationCadence = "deferred";
          }
          analytics.push({
            id: cluster.id,
            ageHours,
            memberCount: cluster.memberCount,
            avgPhi: cluster.avgPhi,
            maxPhi: cluster.maxPhi,
            explorationFrequency,
            decayRate,
            priorityScore,
            explorationCadence,
            commonWords: cluster.commonWords,
            structuralPattern: cluster.structuralPattern,
            lastUpdatedAt: cluster.lastUpdatedAt
          });
        }
        return analytics.sort((a, b) => b.priorityScore - a.priorityScore);
      }
      /**
       * Get clusters ready for immediate exploration based on aging analytics
       */
      getClustersForExploration(cadence) {
        const analytics = this.getClusterAnalytics();
        if (!cadence) {
          return analytics.filter((a) => a.explorationCadence === "immediate" || a.explorationCadence === "priority");
        }
        return analytics.filter((a) => a.explorationCadence === cadence);
      }
      /**
       * Get entries belonging to a cluster
       */
      getClusterMembers(clusterId) {
        return Array.from(this.entries.values()).filter((e) => e.clusterId === clusterId).sort((a, b) => b.phi - a.phi);
      }
      /**
       * Get comprehensive statistics
       */
      getStats() {
        const entries = Array.from(this.entries.values());
        const now = Date.now();
        const staleThreshold = NEAR_MISS_CONFIG.STALE_THRESHOLD_HOURS * 60 * 60 * 1e3;
        let hot = 0, warm = 0, cool = 0, totalPhi = 0, maxPhi = 0, recentCount = 0, staleCount = 0, escalatingCount = 0;
        for (const entry of entries) {
          if (entry.tier === "hot") hot++;
          else if (entry.tier === "warm") warm++;
          else cool++;
          totalPhi += entry.phi;
          if (entry.phi > maxPhi) maxPhi = entry.phi;
          const discoveredAt = new Date(entry.discoveredAt).getTime();
          if (now - discoveredAt < 60 * 60 * 1e3) recentCount++;
          if (now - discoveredAt > staleThreshold) staleCount++;
          if (entry.isEscalating) escalatingCount++;
        }
        return {
          total: entries.length,
          hot,
          warm,
          cool,
          clusters: this.clusters.size,
          avgPhi: entries.length > 0 ? totalPhi / entries.length : 0,
          maxPhi,
          recentDiscoveries: recentCount,
          staleCount,
          adaptiveThresholds: {
            hot: this.adaptiveThresholds.hot,
            warm: this.adaptiveThresholds.warm,
            cool: this.adaptiveThresholds.cool,
            distributionSize: this.adaptiveThresholds.distributionSize
          },
          escalatingCount,
          tierSuccessRates: this.getTierSuccessRates()
        };
      }
      /**
       * Mark an entry as accessed (for recency tracking)
       */
      markAccessed(id) {
        const entry = this.entries.get(id);
        if (entry) {
          entry.lastAccessedAt = (/* @__PURE__ */ new Date()).toISOString();
          entry.explorationCount++;
          entry.queuePriority = this.computeQueuePriority(entry);
          this.isDirty = true;
        }
      }
      /**
       * Remove an entry (e.g., after successful match)
       */
      remove(id) {
        const deleted = this.entries.delete(id);
        if (deleted) {
          this.isDirty = true;
          this.rebuildClusters();
        }
        return deleted;
      }
      /**
       * Clear all entries
       */
      clear() {
        this.entries.clear();
        this.clusters.clear();
        this.rollingPhiDistribution = [];
        this.isDirty = true;
      }
      /**
       * Get all entries as array
       */
      getAllEntries() {
        return Array.from(this.entries.values());
      }
      /**
       * Get Φ trajectory for an entry (for UI visualization)
       */
      getPhiTrajectory(id) {
        const entry = this.entries.get(id);
        return entry?.phiHistory || [];
      }
      /**
       * Record a successful conversion (near-miss → actual match/discovery)
       * This validates whether HOT tier entries really convert more often
       */
      recordConversion(entryId, matchAddress) {
        const entry = this.entries.get(entryId);
        if (!entry) {
          console.log(`[NearMiss] Cannot record conversion: entry ${entryId} not found`);
          return null;
        }
        const now = /* @__PURE__ */ new Date();
        const discoveredAt = new Date(entry.discoveredAt);
        const timeToConversionHours = (now.getTime() - discoveredAt.getTime()) / (1e3 * 60 * 60);
        const record = {
          entryId,
          tier: entry.tier,
          phi: entry.phi,
          convertedAt: now.toISOString(),
          discoveredAt: entry.discoveredAt,
          timeToConversionHours,
          matchAddress
        };
        this.conversionRecords.push(record);
        this.isDirty = true;
        console.log(`[NearMiss] \u{1F389} CONVERSION: ${entry.tier.toUpperCase()} tier entry converted! \u03A6=${entry.phi.toFixed(4)}, time=${timeToConversionHours.toFixed(1)}h`);
        this.remove(entryId);
        return record;
      }
      /**
       * Record a conversion by phrase (alternative lookup method)
       */
      recordConversionByPhrase(phrase, matchAddress) {
        const id = this.generateId(phrase);
        return this.recordConversion(id, matchAddress);
      }
      /**
       * Get comprehensive tier success rates - validates HOT tier hypothesis
       */
      getTierSuccessRates() {
        const now = Date.now();
        const dayAgo = now - 24 * 60 * 60 * 1e3;
        const entries = Array.from(this.entries.values());
        const hotEntries = entries.filter((e) => e.tier === "hot").length + this.tierTotals.hot;
        const warmEntries = entries.filter((e) => e.tier === "warm").length + this.tierTotals.warm;
        const coolEntries = entries.filter((e) => e.tier === "cool").length + this.tierTotals.cool;
        const calculateTierMetrics = (tier, totalEntries) => {
          const tierConversions = this.conversionRecords.filter((r) => r.tier === tier);
          const recentConversions = tierConversions.filter((r) => new Date(r.convertedAt).getTime() > dayAgo).length;
          const avgPhiAtConversion = tierConversions.length > 0 ? tierConversions.reduce((sum, r) => sum + r.phi, 0) / tierConversions.length : 0;
          const avgTimeToConversion = tierConversions.length > 0 ? tierConversions.reduce((sum, r) => sum + r.timeToConversionHours, 0) / tierConversions.length : 0;
          return {
            totalEntries: Math.max(1, totalEntries),
            // Avoid division by zero
            conversions: tierConversions.length,
            conversionRate: totalEntries > 0 ? tierConversions.length / totalEntries : 0,
            avgPhiAtConversion,
            avgTimeToConversion,
            recentConversions
          };
        };
        const hot = calculateTierMetrics("hot", hotEntries);
        const warm = calculateTierMetrics("warm", warmEntries);
        const cool = calculateTierMetrics("cool", coolEntries);
        const hotVsWarmRatio = warm.conversionRate > 0 ? hot.conversionRate / warm.conversionRate : hot.conversionRate > 0 ? Infinity : 1;
        const hotVsCoolRatio = cool.conversionRate > 0 ? hot.conversionRate / cool.conversionRate : hot.conversionRate > 0 ? Infinity : 1;
        let tierValidation;
        const totalConversions = hot.conversions + warm.conversions + cool.conversions;
        if (totalConversions < 5) {
          tierValidation = "needs_data";
        } else if (hotVsWarmRatio >= 1 && hotVsCoolRatio >= 1) {
          tierValidation = "validated";
        } else {
          tierValidation = "tier_inversion";
        }
        return {
          hot,
          warm,
          cool,
          overall: {
            totalConversions,
            hotVsWarmRatio: isFinite(hotVsWarmRatio) ? hotVsWarmRatio : 999,
            hotVsCoolRatio: isFinite(hotVsCoolRatio) ? hotVsCoolRatio : 999,
            tierValidation
          }
        };
      }
      /**
       * Get all conversion records (for analysis/export)
       */
      getConversionRecords() {
        return [...this.conversionRecords];
      }
      /**
       * Get conversion records for a specific tier
       */
      getConversionsByTier(tier) {
        return this.conversionRecords.filter((r) => r.tier === tier);
      }
      /**
       * Increment tier total (called when entries are added to track overall population)
       */
      incrementTierTotal(tier) {
        this.tierTotals[tier]++;
      }
      /**
       * Record a Φ sample for temporal trend analysis
       */
      recordPhiTemporalSample(phi) {
        if (phi <= 0 || phi > 1) return;
        this.phiTemporalSamples.push({
          phi,
          timestamp: (/* @__PURE__ */ new Date()).toISOString()
        });
        if (this.phiTemporalSamples.length > this.TEMPORAL_WINDOW_SIZE * 2) {
          this.phiTemporalSamples = this.phiTemporalSamples.slice(-this.TEMPORAL_WINDOW_SIZE);
        }
        if (this.phiTemporalSamples.length % 10 === 0) {
          this.detectPlateau();
        }
      }
      /**
       * Calculate trend slope using linear regression
       */
      calculateTrendSlope(values) {
        if (values.length < 3) return 0;
        const n = values.length;
        const indices = values.map((_, i) => i);
        const sumX = indices.reduce((s, x) => s + x, 0);
        const sumY = values.reduce((s, y) => s + y, 0);
        const sumXY = indices.reduce((s, x, i) => s + x * values[i], 0);
        const sumX2 = indices.reduce((s, x) => s + x * x, 0);
        const denominator = n * sumX2 - sumX * sumX;
        if (denominator === 0) return 0;
        return (n * sumXY - sumX * sumY) / denominator;
      }
      /**
       * Calculate variance of values
       */
      calculateVariance(values) {
        if (values.length < 2) return 0;
        const mean = values.reduce((s, v) => s + v, 0) / values.length;
        const squaredDiffs = values.map((v) => Math.pow(v - mean, 2));
        return squaredDiffs.reduce((s, v) => s + v, 0) / (values.length - 1);
      }
      /**
       * Detect plateau and trigger reset if needed
       */
      detectPlateau() {
        const samples = this.phiTemporalSamples.slice(-this.TEMPORAL_WINDOW_SIZE);
        if (samples.length < 10) return;
        const phis = samples.map((s) => s.phi);
        const slope = Math.abs(this.calculateTrendSlope(phis));
        const variance = this.calculateVariance(phis);
        const isPlateau = slope < this.PLATEAU_SLOPE_THRESHOLD && variance < 0.01;
        if (isPlateau) {
          this.consecutivePlateaus++;
          this.plateauCount++;
          this.lastPlateauAt = (/* @__PURE__ */ new Date()).toISOString();
          console.log(`[NearMiss] \u26A0\uFE0F PLATEAU DETECTED: slope=${slope.toFixed(6)}, consecutive=${this.consecutivePlateaus}/${this.PLATEAU_RESET_THRESHOLD}`);
          if (this.consecutivePlateaus >= this.PLATEAU_RESET_THRESHOLD && !this.resetTriggerActive) {
            this.resetTriggerActive = true;
            console.log(`[NearMiss] \u{1F504} RESET TRIGGER ACTIVATED: ${this.consecutivePlateaus} consecutive plateaus detected`);
          }
        } else {
          if (this.consecutivePlateaus > 0) {
            console.log(`[NearMiss] \u{1F4C8} Plateau broken, slope=${slope.toFixed(4)}`);
          }
          this.consecutivePlateaus = 0;
          this.resetTriggerActive = false;
        }
      }
      /**
       * Get comprehensive Φ temporal trends analysis
       */
      getPhiTemporalTrends() {
        const samples = this.phiTemporalSamples.slice(-this.TEMPORAL_WINDOW_SIZE);
        if (samples.length < 5) {
          return {
            windowSize: this.TEMPORAL_WINDOW_SIZE,
            sampleCount: samples.length,
            avgPhi: 0,
            slope: 0,
            trend: "insufficient_data",
            plateauCount: this.plateauCount,
            consecutivePlateaus: this.consecutivePlateaus,
            lastPlateauAt: this.lastPlateauAt,
            resetTriggerActive: this.resetTriggerActive,
            resetTriggerThreshold: this.PLATEAU_RESET_THRESHOLD,
            volatility: 0,
            samples: [],
            insights: ["Need at least 5 samples for trend analysis"]
          };
        }
        const phis = samples.map((s) => s.phi);
        const avgPhi = phis.reduce((s, p) => s + p, 0) / phis.length;
        const slope = this.calculateTrendSlope(phis);
        const variance = this.calculateVariance(phis);
        const volatility = Math.sqrt(variance);
        let trend;
        const normalizedSlope = slope / Math.max(0.01, volatility);
        if (volatility > this.VOLATILITY_THRESHOLD) {
          trend = "volatile";
        } else if (Math.abs(slope) < this.PLATEAU_SLOPE_THRESHOLD) {
          trend = "plateau";
        } else if (normalizedSlope > 0.1) {
          trend = "improving";
        } else if (normalizedSlope < -0.1) {
          trend = "declining";
        } else {
          trend = "plateau";
        }
        const insights = [];
        if (this.resetTriggerActive) {
          insights.push(`\u26A0\uFE0F RESET RECOMMENDED: ${this.consecutivePlateaus} consecutive plateaus detected`);
          insights.push("Consider: switching search strategy, exploring new vocabulary domains, or adjusting \u03A6 thresholds");
        }
        if (trend === "improving") {
          insights.push(`\u{1F4C8} \u03A6 trending upward (slope: ${(slope * 100).toFixed(2)}% per sample)`);
          insights.push("Current search direction is productive");
        } else if (trend === "declining") {
          insights.push(`\u{1F4C9} \u03A6 trending downward (slope: ${(slope * 100).toFixed(2)}% per sample)`);
          insights.push("Consider adjusting search parameters or strategy");
        } else if (trend === "plateau") {
          insights.push(`\u23F8\uFE0F \u03A6 in plateau (slope: ${(slope * 1e3).toFixed(3)}\u2030)`);
          if (this.consecutivePlateaus > 0) {
            insights.push(`Plateau persisting for ${this.consecutivePlateaus} detection cycles`);
          }
        } else if (trend === "volatile") {
          insights.push(`\u{1F30A} High volatility detected (\u03C3=${volatility.toFixed(4)})`);
          insights.push("Search is exploring diverse regions - may indicate boundary probing");
        }
        if (this.plateauCount > 0 && trend !== "plateau") {
          insights.push(`Historical: ${this.plateauCount} total plateaus encountered`);
        }
        const recentSamples = samples.slice(-20).map((s) => ({
          phi: s.phi,
          timestamp: s.timestamp
        }));
        return {
          windowSize: this.TEMPORAL_WINDOW_SIZE,
          sampleCount: samples.length,
          avgPhi,
          slope,
          trend,
          plateauCount: this.plateauCount,
          consecutivePlateaus: this.consecutivePlateaus,
          lastPlateauAt: this.lastPlateauAt,
          resetTriggerActive: this.resetTriggerActive,
          resetTriggerThreshold: this.PLATEAU_RESET_THRESHOLD,
          volatility,
          samples: recentSamples,
          insights
        };
      }
      /**
       * Acknowledge reset trigger and clear the flag
       * Call this when a strategy change has been enacted
       */
      acknowledgeResetTrigger() {
        if (this.resetTriggerActive) {
          console.log(`[NearMiss] \u2705 Reset trigger acknowledged - clearing consecutive plateau count`);
          this.resetTriggerActive = false;
          this.consecutivePlateaus = 0;
        }
      }
      /**
       * Check if reset trigger is currently active
       */
      isResetTriggerActive() {
        return this.resetTriggerActive;
      }
      /**
       * Generate a deterministic ID for a phrase
       */
      generateId(phrase) {
        const normalized = phrase.toLowerCase().trim().replace(/\s+/g, " ");
        let hash = 0;
        for (let i = 0; i < normalized.length; i++) {
          const char = normalized.charCodeAt(i);
          hash = (hash << 5) - hash + char;
          hash = hash & hash;
        }
        return `nm_${Math.abs(hash).toString(36)}`;
      }
      /**
       * Compute structural signature for clustering
       */
      computeStructuralSignature(phrase) {
        const words = phrase.trim().split(/\s+/);
        const chars = phrase.replace(/\s/g, "");
        const charCounts = /* @__PURE__ */ new Map();
        for (const c of chars.toLowerCase()) {
          charCounts.set(c, (charCounts.get(c) || 0) + 1);
        }
        let entropy = 0;
        const total = chars.length;
        for (const count of charCounts.values()) {
          const p = count / total;
          entropy -= p * Math.log2(p);
        }
        const isBip39Valid = isValidBIP39Phrase(phrase);
        return {
          wordCount: words.length,
          avgWordLength: words.reduce((s, w) => s + w.length, 0) / words.length,
          charCount: phrase.length,
          hasNumbers: /\d/.test(phrase),
          hasSpecialChars: /[^a-zA-Z0-9\s]/.test(phrase),
          startsWithCapital: /^[A-Z]/.test(phrase),
          entropyEstimate: entropy,
          isBip39Valid
        };
      }
      /**
       * Compute similarity between two structural signatures
       */
      computeStructuralSimilarity(a, b) {
        let similarity = 0;
        let weights = 0;
        if (a.wordCount === b.wordCount) {
          similarity += 0.25;
          weights += 0.25;
        } else {
          weights += 0.25;
        }
        const avgLenDiff = Math.abs(a.avgWordLength - b.avgWordLength);
        similarity += 0.2 * Math.max(0, 1 - avgLenDiff / 5);
        weights += 0.2;
        if (a.hasNumbers === b.hasNumbers) {
          similarity += 0.15;
          weights += 0.15;
        } else {
          weights += 0.15;
        }
        if (a.hasSpecialChars === b.hasSpecialChars) {
          similarity += 0.15;
          weights += 0.15;
        } else {
          weights += 0.15;
        }
        const entropyDiff = Math.abs(a.entropyEstimate - b.entropyEstimate);
        similarity += 0.25 * Math.max(0, 1 - entropyDiff / 2);
        weights += 0.25;
        return similarity / weights;
      }
      /**
       * Extract common words between phrases
       */
      extractCommonWords(phrases) {
        if (phrases.length === 0) return [];
        const wordCounts = /* @__PURE__ */ new Map();
        for (const phrase of phrases) {
          const words = new Set(phrase.toLowerCase().split(/\s+/));
          for (const word of words) {
            if (word.length > 2) {
              wordCounts.set(word, (wordCounts.get(word) || 0) + 1);
            }
          }
        }
        const threshold = Math.max(2, Math.floor(phrases.length * 0.3));
        return Array.from(wordCounts.entries()).filter(([_, count]) => count >= threshold).sort((a, b) => b[1] - a[1]).slice(0, 10).map(([word]) => word);
      }
      /**
       * Assign an entry to the most suitable cluster (no limit on clusters)
       */
      assignToCluster(entry) {
        if (!entry.structuralSignature) return;
        let bestCluster = null;
        let bestSimilarity = 0;
        for (const cluster of this.clusters.values()) {
          const members = this.getClusterMembers(cluster.id);
          if (members.length === 0) continue;
          const representative = members[0];
          if (!representative.structuralSignature) continue;
          const similarity = this.computeStructuralSimilarity(
            entry.structuralSignature,
            representative.structuralSignature
          );
          if (similarity > bestSimilarity && similarity >= NEAR_MISS_CONFIG.CLUSTER_SIMILARITY_THRESHOLD) {
            bestSimilarity = similarity;
            bestCluster = cluster;
          }
        }
        if (bestCluster) {
          entry.clusterId = bestCluster.id;
          this.updateClusterStats(bestCluster.id);
        } else {
          const clusterId = `cluster_${Date.now()}_${Math.random().toString(36).slice(2, 6)}`;
          const cluster = {
            id: clusterId,
            centroidPhrase: entry.phrase,
            centroidPhi: entry.phi,
            memberCount: 1,
            avgPhi: entry.phi,
            maxPhi: entry.phi,
            commonWords: entry.phrase.toLowerCase().split(/\s+/).filter((w) => w.length > 2),
            structuralPattern: this.describeStructure(entry.structuralSignature),
            createdAt: (/* @__PURE__ */ new Date()).toISOString(),
            lastUpdatedAt: (/* @__PURE__ */ new Date()).toISOString()
          };
          this.clusters.set(clusterId, cluster);
          entry.clusterId = clusterId;
        }
      }
      /**
       * Update cluster statistics
       */
      updateClusterStats(clusterId) {
        const cluster = this.clusters.get(clusterId);
        if (!cluster) return;
        const members = this.getClusterMembers(clusterId);
        if (members.length === 0) {
          this.clusters.delete(clusterId);
          return;
        }
        let totalPhi = 0, maxPhi = 0;
        const phrases = [];
        for (const member of members) {
          totalPhi += member.phi;
          if (member.phi > maxPhi) {
            maxPhi = member.phi;
            cluster.centroidPhrase = member.phrase;
            cluster.centroidPhi = member.phi;
          }
          phrases.push(member.phrase);
        }
        cluster.memberCount = members.length;
        cluster.avgPhi = totalPhi / members.length;
        cluster.maxPhi = maxPhi;
        cluster.commonWords = this.extractCommonWords(phrases);
        cluster.lastUpdatedAt = (/* @__PURE__ */ new Date()).toISOString();
      }
      /**
       * Rebuild all clusters from scratch with fresh structural signatures
       * Also recomputes isBip39Valid for all entries
       */
      rebuildClustersWithValidation() {
        console.log("[NearMiss] \u{1F504} Rebuilding clusters with BIP-39 validation...");
        let bip39Valid = 0;
        let bip39Invalid = 0;
        const VALID_SEED_WORD_COUNTS = [12, 15, 18, 21, 24];
        for (const entry of this.entries.values()) {
          entry.structuralSignature = this.computeStructuralSignature(entry.phrase);
          entry.clusterId = void 0;
          if (VALID_SEED_WORD_COUNTS.includes(entry.structuralSignature.wordCount)) {
            if (entry.structuralSignature.isBip39Valid) {
              bip39Valid++;
            } else {
              bip39Invalid++;
            }
          }
        }
        this.clusters.clear();
        for (const entry of this.entries.values()) {
          this.assignToCluster(entry);
        }
        for (const cluster of this.clusters.values()) {
          const members = this.getClusterMembers(cluster.id);
          if (members.length > 0 && members[0].structuralSignature) {
            cluster.structuralPattern = this.describeStructure(members[0].structuralSignature);
          }
        }
        this.isDirty = true;
        console.log(`[NearMiss] \u2705 Rebuilt ${this.clusters.size} clusters from ${this.entries.size} entries (BIP-39: ${bip39Valid} valid, ${bip39Invalid} invalid)`);
        return {
          entriesProcessed: this.entries.size,
          clustersCreated: this.clusters.size,
          bip39Valid,
          bip39Invalid
        };
      }
      /**
       * Legacy rebuild without validation logging
       */
      rebuildClusters() {
        this.clusters.clear();
        for (const entry of this.entries.values()) {
          entry.clusterId = void 0;
        }
        for (const entry of this.entries.values()) {
          this.assignToCluster(entry);
        }
      }
      /**
       * Describe structural pattern in human-readable form
       */
      describeStructure(sig) {
        const parts = [];
        parts.push(`${sig.wordCount}-word`);
        const VALID_SEED_WORD_COUNTS = [12, 15, 18, 21, 24];
        if (VALID_SEED_WORD_COUNTS.includes(sig.wordCount)) {
          if (sig.isBip39Valid) {
            parts.push("BIP-39");
          } else {
            parts.push("invalid-seed");
          }
        }
        if (sig.hasNumbers) parts.push("with-numbers");
        if (sig.hasSpecialChars) parts.push("with-special");
        if (sig.startsWithCapital) parts.push("capitalized");
        if (sig.entropyEstimate < 3) parts.push("low-entropy");
        else if (sig.entropyEstimate > 4) parts.push("high-entropy");
        return parts.join(" ");
      }
      /**
       * Load state from PostgreSQL first, fall back to JSON
       */
      load() {
        this.loadAsync().catch((err) => {
          console.error("[NearMiss] Async load failed:", err);
        });
      }
      /**
       * Async load implementation - Redis first, PostgreSQL second, JSON fallback
       */
      async loadAsync() {
        try {
          if (isRedisAvailable()) {
            const loadedFromRedis = await this.loadFromRedis();
            if (loadedFromRedis) {
              console.log(`[NearMiss] Loaded from Redis: ${this.entries.size} entries, ${this.clusters.size} clusters`);
              this.recomputeAdaptiveThresholds();
              this.applyDecay();
              return;
            }
          }
          if (oceanPersistence.isPersistenceAvailable()) {
            const loadedFromDb = await this.loadFromPostgres();
            if (loadedFromDb) {
              console.log(`[NearMiss] Loaded from PostgreSQL: ${this.entries.size} entries, ${this.clusters.size} clusters`);
              this.saveToRedis().catch((err) => console.error("[NearMiss] Redis backfill failed:", err));
              this.recomputeAdaptiveThresholds();
              this.applyDecay();
              return;
            }
          }
          this.loadFromJson();
          this.saveToRedis().catch((err) => console.error("[NearMiss] Redis backfill failed:", err));
          this.recomputeAdaptiveThresholds();
          this.applyDecay();
        } catch (error) {
          console.error("[NearMiss] Failed to load state:", error);
          this.loadFromJson();
        }
      }
      /**
       * Load state from Redis (primary cache)
       */
      async loadFromRedis() {
        try {
          const data = await cacheGet(CACHE_KEYS.NEAR_MISS);
          if (!data || !data.entries || data.entries.length === 0) {
            console.log("[NearMiss] No data in Redis, will try other sources");
            return false;
          }
          for (const entry of data.entries) {
            this.entries.set(entry.id, entry);
            if (entry.phi) {
              this.rollingPhiDistribution.push(entry.phi);
            }
          }
          if (data.clusters) {
            for (const cluster of data.clusters) {
              this.clusters.set(cluster.id, cluster);
            }
          }
          if (data.rollingPhiDistribution) {
            this.rollingPhiDistribution = data.rollingPhiDistribution.slice(-NEAR_MISS_CONFIG.DISTRIBUTION_WINDOW_SIZE);
          }
          if (data.adaptiveThresholds) {
            this.adaptiveThresholds = data.adaptiveThresholds;
          }
          if (data.conversionRecords) {
            this.conversionRecords = data.conversionRecords;
          }
          if (data.tierTotals) {
            this.tierTotals = data.tierTotals;
          }
          if (data.phiTemporalSamples) {
            this.phiTemporalSamples = data.phiTemporalSamples.slice(-this.TEMPORAL_WINDOW_SIZE);
          }
          if (data.plateauCount !== void 0) {
            this.plateauCount = data.plateauCount;
          }
          if (data.consecutivePlateaus !== void 0) {
            this.consecutivePlateaus = data.consecutivePlateaus;
          }
          if (data.lastPlateauAt) {
            this.lastPlateauAt = data.lastPlateauAt;
          }
          if (data.resetTriggerActive !== void 0) {
            this.resetTriggerActive = data.resetTriggerActive;
          }
          return true;
        } catch (error) {
          console.error("[NearMiss] Failed to load from Redis:", error);
          return false;
        }
      }
      /**
       * Load state from PostgreSQL
       */
      async loadFromPostgres() {
        try {
          const [entries, clusters, adaptiveState] = await Promise.all([
            oceanPersistence.getAllNearMissEntries(),
            oceanPersistence.getAllNearMissClusters(),
            oceanPersistence.loadNearMissAdaptiveState()
          ]);
          if (entries.length === 0 && clusters.length === 0 && !adaptiveState) {
            console.log("[NearMiss] No data in PostgreSQL, will try JSON fallback");
            return false;
          }
          for (const record of entries) {
            const entry = {
              id: record.id,
              phrase: record.phrase,
              phi: record.phi,
              kappa: record.kappa,
              regime: record.regime,
              tier: record.tier,
              discoveredAt: record.discoveredAt.toISOString(),
              lastAccessedAt: record.lastAccessedAt.toISOString(),
              explorationCount: record.explorationCount ?? 1,
              source: record.source ?? "unknown",
              clusterId: record.clusterId ?? void 0,
              structuralSignature: record.structuralSignature,
              phiHistory: record.phiHistory,
              isEscalating: record.isEscalating ?? false,
              queuePriority: record.queuePriority ?? 1
            };
            this.entries.set(entry.id, entry);
            if (entry.phi) {
              this.rollingPhiDistribution.push(entry.phi);
            }
          }
          for (const record of clusters) {
            const cluster = {
              id: record.id,
              centroidPhrase: record.centroidPhrase,
              centroidPhi: record.centroidPhi,
              memberCount: record.memberCount ?? 0,
              avgPhi: record.avgPhi,
              maxPhi: record.maxPhi,
              commonWords: record.commonWords ?? [],
              structuralPattern: record.structuralPattern ?? "",
              createdAt: record.createdAt.toISOString(),
              lastUpdatedAt: record.lastUpdatedAt.toISOString()
            };
            this.clusters.set(cluster.id, cluster);
          }
          if (adaptiveState) {
            this.rollingPhiDistribution = (adaptiveState.rollingPhiDistribution ?? []).slice(-NEAR_MISS_CONFIG.DISTRIBUTION_WINDOW_SIZE);
            this.adaptiveThresholds = {
              hot: adaptiveState.hotThreshold,
              warm: adaptiveState.warmThreshold,
              cool: adaptiveState.coolThreshold,
              distributionSize: adaptiveState.distributionSize ?? 0,
              lastComputed: adaptiveState.lastComputed.toISOString()
            };
          }
          return true;
        } catch (error) {
          console.error("[NearMiss] Failed to load from PostgreSQL:", error);
          return false;
        }
      }
      /**
       * Load state from JSON file (fallback)
       */
      loadFromJson() {
        try {
          if (fs5.existsSync(NEAR_MISS_FILE)) {
            const data = JSON.parse(fs5.readFileSync(NEAR_MISS_FILE, "utf-8"));
            if (data.entries) {
              for (const entry of data.entries) {
                this.entries.set(entry.id, entry);
                if (entry.phi) {
                  this.rollingPhiDistribution.push(entry.phi);
                }
              }
            }
            if (data.clusters) {
              for (const cluster of data.clusters) {
                this.clusters.set(cluster.id, cluster);
              }
            }
            if (data.rollingPhiDistribution) {
              this.rollingPhiDistribution = data.rollingPhiDistribution.slice(-NEAR_MISS_CONFIG.DISTRIBUTION_WINDOW_SIZE);
            }
            if (data.conversionRecords) {
              this.conversionRecords = data.conversionRecords;
            }
            if (data.tierTotals) {
              this.tierTotals = data.tierTotals;
            }
            if (data.phiTemporalSamples) {
              this.phiTemporalSamples = data.phiTemporalSamples.slice(-this.TEMPORAL_WINDOW_SIZE);
            }
            if (data.plateauCount !== void 0) {
              this.plateauCount = data.plateauCount;
            }
            if (data.consecutivePlateaus !== void 0) {
              this.consecutivePlateaus = data.consecutivePlateaus;
            }
            if (data.lastPlateauAt) {
              this.lastPlateauAt = data.lastPlateauAt;
            }
            if (data.resetTriggerActive !== void 0) {
              this.resetTriggerActive = data.resetTriggerActive;
            }
            console.log(`[NearMiss] Loaded from JSON: ${this.entries.size} entries, ${this.clusters.size} clusters, ${this.conversionRecords.length} conversions, ${this.phiTemporalSamples.length} temporal samples`);
          }
        } catch (error) {
          console.error("[NearMiss] Failed to load from JSON:", error);
        }
      }
      /**
       * Save state to Redis (primary), JSON (backup), and PostgreSQL
       */
      save() {
        if (!this.isDirty) return;
        this.saveToRedis().catch((err) => {
          console.error("[NearMiss] Redis save failed:", err);
        });
        try {
          this.saveToJson();
        } catch (err) {
          console.error("[NearMiss] JSON backup save failed:", err);
        }
        this.saveToPostgres().catch((err) => {
          console.error("[NearMiss] PostgreSQL save failed:", err);
        });
        this.isDirty = false;
      }
      /**
       * Save state to Redis (primary cache)
       */
      async saveToRedis() {
        if (!isRedisAvailable()) {
          return false;
        }
        try {
          const data = {
            savedAt: (/* @__PURE__ */ new Date()).toISOString(),
            entries: Array.from(this.entries.values()),
            clusters: Array.from(this.clusters.values()),
            rollingPhiDistribution: this.rollingPhiDistribution,
            adaptiveThresholds: this.adaptiveThresholds,
            conversionRecords: this.conversionRecords,
            tierTotals: this.tierTotals,
            phiTemporalSamples: this.phiTemporalSamples,
            plateauCount: this.plateauCount,
            consecutivePlateaus: this.consecutivePlateaus,
            lastPlateauAt: this.lastPlateauAt,
            resetTriggerActive: this.resetTriggerActive
          };
          const success = await cacheSet(CACHE_KEYS.NEAR_MISS, data, CACHE_TTL.PERMANENT);
          if (success) {
            console.log(`[NearMiss] Saved to Redis: ${this.entries.size} entries, ${this.clusters.size} clusters`);
          }
          return success;
        } catch (error) {
          console.error("[NearMiss] Failed to save to Redis:", error);
          return false;
        }
      }
      /**
       * Save state to JSON file (backup/fallback)
       */
      saveToJson() {
        try {
          if (!fs5.existsSync(DATA_DIR)) {
            fs5.mkdirSync(DATA_DIR, { recursive: true });
          }
          const data = {
            savedAt: (/* @__PURE__ */ new Date()).toISOString(),
            entries: Array.from(this.entries.values()),
            clusters: Array.from(this.clusters.values()),
            rollingPhiDistribution: this.rollingPhiDistribution,
            adaptiveThresholds: this.adaptiveThresholds,
            conversionRecords: this.conversionRecords,
            tierTotals: this.tierTotals,
            // Temporal trends data
            phiTemporalSamples: this.phiTemporalSamples,
            plateauCount: this.plateauCount,
            consecutivePlateaus: this.consecutivePlateaus,
            lastPlateauAt: this.lastPlateauAt,
            resetTriggerActive: this.resetTriggerActive
          };
          fs5.writeFileSync(NEAR_MISS_FILE, JSON.stringify(data, null, 2));
        } catch (error) {
          console.error("[NearMiss] Failed to save to JSON:", error);
        }
      }
      /**
       * Save state to PostgreSQL - serialized to avoid connection pool exhaustion
       */
      async saveToPostgres() {
        if (!oceanPersistence.isPersistenceAvailable()) return;
        try {
          const entries = Array.from(this.entries.values());
          const clusters = Array.from(this.clusters.values());
          const entryData = entries.map((e) => ({
            id: e.id,
            phrase: e.phrase,
            phi: e.phi,
            kappa: e.kappa,
            regime: e.regime,
            tier: e.tier,
            source: e.source,
            clusterId: e.clusterId,
            phiHistory: e.phiHistory,
            isEscalating: e.isEscalating,
            queuePriority: e.queuePriority,
            structuralSignature: e.structuralSignature,
            explorationCount: e.explorationCount
          }));
          const entrySaveCount = await oceanPersistence.batchUpsertNearMissEntries(entryData);
          let clusterSaveCount = 0;
          for (const c of clusters) {
            try {
              await oceanPersistence.upsertNearMissCluster({
                id: c.id,
                centroidPhrase: c.centroidPhrase,
                centroidPhi: c.centroidPhi,
                memberCount: c.memberCount,
                avgPhi: c.avgPhi,
                maxPhi: c.maxPhi,
                commonWords: c.commonWords,
                structuralPattern: c.structuralPattern
              });
              clusterSaveCount++;
            } catch (e) {
            }
          }
          await oceanPersistence.saveNearMissAdaptiveState({
            rollingPhiDistribution: this.rollingPhiDistribution,
            hotThreshold: this.adaptiveThresholds.hot,
            warmThreshold: this.adaptiveThresholds.warm,
            coolThreshold: this.adaptiveThresholds.cool
          });
          console.log(`[NearMiss] Saved to PostgreSQL: ${entrySaveCount} entries, ${clusterSaveCount}/${clusters.length} clusters`);
        } catch (error) {
          console.error("[NearMiss] Failed to save to PostgreSQL:", error);
        }
      }
      /**
       * Force save immediately
       */
      forceSave() {
        this.isDirty = true;
        this.save();
      }
      /**
       * Start auto-save timer
       */
      startAutoSave() {
        this.saveTimer = setInterval(() => this.save(), 3e4);
      }
      /**
       * Cleanup resources
       */
      shutdown() {
        if (this.saveTimer) {
          clearInterval(this.saveTimer);
        }
        this.save();
      }
    };
    nearMissManager = new NearMissManager();
  }
});

// server/negative-knowledge-db.ts
var negative_knowledge_db_exports = {};
__export(negative_knowledge_db_exports, {
  NegativeKnowledgeRegistryDB: () => NegativeKnowledgeRegistryDB,
  negativeKnowledgeRegistryDB: () => negativeKnowledgeRegistryDB
});
import { nanoid as nanoid3 } from "nanoid";
import { eq as eq4, sql as sql5, desc as desc3, and as and3, lt } from "drizzle-orm";
var cache, NegativeKnowledgeRegistryDB, negativeKnowledgeRegistryDB;
var init_negative_knowledge_db = __esm({
  "server/negative-knowledge-db.ts"() {
    "use strict";
    init_db();
    init_schema();
    init_qig_universal();
    cache = {
      contradictions: /* @__PURE__ */ new Map(),
      barriers: /* @__PURE__ */ new Map(),
      falsePatterns: /* @__PURE__ */ new Map(),
      eraExclusions: /* @__PURE__ */ new Map()
    };
    NegativeKnowledgeRegistryDB = class {
      CONTRADICTION_CONFIRMATION_THRESHOLD = 3;
      BARRIER_CROSS_THRESHOLD = 5;
      CACHE_SIZE = 1e3;
      // Keep hot entries in memory
      constructor() {
        this.init();
      }
      async init() {
        if (!db) {
          console.log("[NegativeKnowledgeDB] No database available, using in-memory cache");
          return;
        }
        try {
          const recent = await withDbRetry(
            async () => {
              const contradictions = await db.select().from(negativeKnowledge).orderBy(desc3(negativeKnowledge.confirmedCount)).limit(this.CACHE_SIZE);
              return contradictions;
            },
            "warm-cache"
          );
          if (recent) {
            for (const c of recent) {
              cache.contradictions.set(c.id, this.toContradiction(c));
            }
            console.log(`[NegativeKnowledgeDB] Warmed cache with ${recent.length} entries`);
          }
        } catch (error) {
          console.error("[NegativeKnowledgeDB] Init error:", error);
        }
      }
      toContradiction(row) {
        return {
          id: row.id,
          type: row.type,
          pattern: row.pattern,
          affectedGenerators: row.affectedGenerators || [],
          basinRegion: {
            center: row.basinCenter || [],
            radius: row.basinRadius || 0,
            repulsionStrength: row.basinRepulsionStrength || 0
          },
          evidence: Array.isArray(row.evidence) ? row.evidence : [],
          hypothesesExcluded: row.hypothesesExcluded || 0,
          computeSaved: row.computeSaved || 0,
          createdAt: row.createdAt?.toISOString() || (/* @__PURE__ */ new Date()).toISOString(),
          confirmedCount: row.confirmedCount || 1
        };
      }
      async recordContradiction(type, pattern, basinRegion, evidence, affectedGenerators = []) {
        const existing = await this.findSimilarContradiction(pattern);
        if (existing) {
          const newConfirmedCount = existing.confirmedCount + 1;
          const newComputeSaved = existing.computeSaved + this.estimateComputeSavings(pattern);
          if (db) {
            await withDbRetry(
              async () => {
                await db.update(negativeKnowledge).set({
                  confirmedCount: newConfirmedCount,
                  computeSaved: newComputeSaved,
                  evidence: [...existing.evidence || [], ...evidence]
                }).where(eq4(negativeKnowledge.id, existing.id));
              },
              "update-contradiction"
            );
          }
          existing.confirmedCount = newConfirmedCount;
          existing.computeSaved = newComputeSaved;
          cache.contradictions.set(existing.id, existing);
          if (newConfirmedCount >= this.CONTRADICTION_CONFIRMATION_THRESHOLD) {
            console.log(`[NegativeKnowledgeDB] Contradiction "${pattern}" confirmed (${newConfirmedCount} occurrences)`);
          }
          return existing.id;
        }
        const id = nanoid3();
        const contradiction = {
          id,
          type,
          pattern,
          affectedGenerators,
          basinCenter: basinRegion.center,
          basinRadius: basinRegion.radius,
          basinRepulsionStrength: basinRegion.repulsionStrength,
          evidence,
          hypothesesExcluded: this.estimateHypothesesExcluded(pattern),
          computeSaved: this.estimateComputeSavings(pattern),
          confirmedCount: 1
        };
        if (db) {
          await withDbRetry(
            async () => {
              await db.insert(negativeKnowledge).values(contradiction);
            },
            "insert-contradiction"
          );
        }
        cache.contradictions.set(id, this.toContradiction(contradiction));
        console.log(`[NegativeKnowledgeDB] New contradiction: "${pattern}" (type: ${type})`);
        return id;
      }
      async findSimilarContradiction(pattern) {
        const normalized = pattern.toLowerCase().trim();
        for (const contradiction of cache.contradictions.values()) {
          const existingNorm = contradiction.pattern.toLowerCase().trim();
          if (existingNorm === normalized) {
            return contradiction;
          }
          if (this.levenshteinDistance(existingNorm, normalized) < 3) {
            return contradiction;
          }
        }
        if (db) {
          const results = await withDbRetry(
            async () => {
              return await db.select().from(negativeKnowledge).where(sql5`LOWER(${negativeKnowledge.pattern}) = ${normalized.toLowerCase()}`);
            },
            "find-similar-contradiction"
          );
          if (results && results.length > 0) {
            const contradiction = this.toContradiction(results[0]);
            cache.contradictions.set(contradiction.id, contradiction);
            return contradiction;
          }
        }
        return null;
      }
      levenshteinDistance(a, b) {
        if (a.length === 0) return b.length;
        if (b.length === 0) return a.length;
        const matrix = [];
        for (let i = 0; i <= b.length; i++) {
          matrix[i] = [i];
        }
        for (let j = 0; j <= a.length; j++) {
          matrix[0][j] = j;
        }
        for (let i = 1; i <= b.length; i++) {
          for (let j = 1; j <= a.length; j++) {
            const cost = a[j - 1] === b[i - 1] ? 0 : 1;
            matrix[i][j] = Math.min(
              matrix[i - 1][j] + 1,
              matrix[i][j - 1] + 1,
              matrix[i - 1][j - 1] + cost
            );
          }
        }
        return matrix[b.length][a.length];
      }
      async recordGeometricBarrier(center, radius, reason) {
        const existing = await this.findNearbyBarrier(center, radius);
        if (existing) {
          const newCrossings = (existing.crossings ?? 0) + 1;
          const newRepulsionStrength = Math.min(1, (existing.repulsionStrength ?? 0) + 0.1);
          if (db) {
            await withDbRetry(
              async () => {
                await db.update(geometricBarriers).set({
                  crossings: newCrossings,
                  repulsionStrength: newRepulsionStrength
                }).where(eq4(geometricBarriers.id, existing.id));
              },
              "update-barrier",
              3
            );
          }
          existing.crossings = newCrossings;
          existing.repulsionStrength = newRepulsionStrength;
          cache.barriers.set(existing.id, existing);
          if (newCrossings >= this.BARRIER_CROSS_THRESHOLD) {
            console.log(`[NegativeKnowledgeDB] Barrier at [${center.slice(0, 3).join(", ")}...] confirmed`);
          }
          return existing.id;
        }
        const id = nanoid3();
        const barrier = {
          id,
          center,
          radius,
          repulsionStrength: 0.5,
          reason,
          crossings: 1
        };
        if (db) {
          await withDbRetry(
            async () => {
              await db.insert(geometricBarriers).values(barrier);
            },
            "insert-barrier",
            3
          );
        }
        cache.barriers.set(id, barrier);
        console.log(`[NegativeKnowledgeDB] New barrier detected: ${reason}`);
        return id;
      }
      async findNearbyBarrier(center, radius) {
        for (const barrier of cache.barriers.values()) {
          const distance = fisherCoordDistance(center, barrier.center ?? []);
          if (distance < barrier.radius + radius) {
            return barrier;
          }
        }
        return null;
      }
      async recordFalsePatternClass(className, examples, avgPhi = 0) {
        if (db) {
          const existing = await withDbRetry(
            async () => {
              const results = await db.select().from(falsePatternClasses).where(eq4(falsePatternClasses.className, className));
              return results[0];
            },
            "find-false-pattern-class",
            2
          );
          if (existing) {
            const newExamples = [...existing.examples || [], ...examples];
            const newCount = (existing.count || 0) + examples.length;
            const newAvgPhi = ((existing.avgPhiAtFailure || 0) + avgPhi) / 2;
            await withDbRetry(
              async () => {
                await db.update(falsePatternClasses).set({
                  examples: newExamples,
                  count: newCount,
                  avgPhiAtFailure: newAvgPhi,
                  lastUpdated: /* @__PURE__ */ new Date()
                }).where(eq4(falsePatternClasses.id, existing.id));
              },
              "update-false-pattern-class",
              3
            );
          } else {
            const id = nanoid3();
            await withDbRetry(
              async () => {
                await db.insert(falsePatternClasses).values({
                  id,
                  className,
                  examples,
                  count: examples.length,
                  avgPhiAtFailure: avgPhi
                });
              },
              "insert-false-pattern-class",
              3
            );
          }
        }
        console.log(`[NegativeKnowledgeDB] False pattern class "${className}": ${examples.length} examples`);
      }
      async recordEraExclusion(era, patterns, reason) {
        if (db) {
          const existing = await withDbRetry(
            async () => {
              const results = await db.select().from(eraExclusions).where(eq4(eraExclusions.era, era));
              return results[0];
            },
            "find-era-exclusion",
            2
          );
          if (existing) {
            const newPatterns = [...existing.excludedPatterns || [], ...patterns];
            await withDbRetry(
              async () => {
                await db.update(eraExclusions).set({
                  excludedPatterns: newPatterns
                }).where(eq4(eraExclusions.id, existing.id));
              },
              "update-era-exclusion",
              3
            );
          } else {
            const id = nanoid3();
            await withDbRetry(
              async () => {
                await db.insert(eraExclusions).values({
                  id,
                  era,
                  excludedPatterns: patterns,
                  reason
                });
              },
              "insert-era-exclusion",
              3
            );
          }
        }
        console.log(`[NegativeKnowledgeDB] Era exclusion for ${era}: ${patterns.length} patterns`);
      }
      async isExcluded(hypothesis, era) {
        const normalized = hypothesis.toLowerCase().trim();
        for (const contradiction of cache.contradictions.values()) {
          if (normalized.includes(contradiction.pattern.toLowerCase())) {
            return {
              excluded: true,
              reason: `Matches proven-false pattern: ${contradiction.pattern}`,
              type: contradiction.type
            };
          }
        }
        if (db) {
          const contradictions = await withDbRetry(
            async () => {
              return await db.select().from(negativeKnowledge).where(sql5`LOWER(${negativeKnowledge.pattern}) LIKE '%' || ${normalized} || '%'`).limit(10);
            },
            "check-excluded",
            2
          );
          if (contradictions && contradictions.length > 0) {
            const c = contradictions[0];
            return {
              excluded: true,
              reason: `Matches proven-false pattern: ${c.pattern}`,
              type: c.type
            };
          }
        }
        return { excluded: false };
      }
      async isInBarrierZone(coords) {
        for (const barrier of cache.barriers.values()) {
          const barrierCenter = barrier.center ?? [];
          const distance = fisherCoordDistance(coords, barrierCenter);
          if (distance < barrier.radius) {
            const repulsionVector = coords.map((c, i) => {
              const diff = c - (barrierCenter[i] || 0);
              return diff / Math.max(1e-3, distance) * (barrier.repulsionStrength ?? 0);
            });
            return {
              inBarrier: true,
              barrier,
              repulsionVector
            };
          }
        }
        return { inBarrier: false };
      }
      async getStats() {
        if (!db) {
          return {
            contradictions: cache.contradictions.size,
            confirmedContradictions: Array.from(cache.contradictions.values()).filter((c) => c.confirmedCount >= this.CONTRADICTION_CONFIRMATION_THRESHOLD).length,
            barriers: cache.barriers.size,
            confirmedBarriers: Array.from(cache.barriers.values()).filter((b) => (b.crossings ?? 0) >= this.BARRIER_CROSS_THRESHOLD).length,
            falseClasses: cache.falsePatterns.size,
            totalExclusions: cache.contradictions.size,
            computeSaved: Array.from(cache.contradictions.values()).reduce((sum, c) => sum + (c.computeSaved || 0), 0)
          };
        }
        const stats = await withDbRetry(
          async () => {
            const [contradictionsCount, confirmedCount, barriersCount, confirmedBarriers, falseClassesCount, totalCompute] = await Promise.all([
              db.select({ count: sql5`count(*)` }).from(negativeKnowledge),
              db.select({ count: sql5`count(*)` }).from(negativeKnowledge).where(sql5`${negativeKnowledge.confirmedCount} >= ${this.CONTRADICTION_CONFIRMATION_THRESHOLD}`),
              db.select({ count: sql5`count(*)` }).from(geometricBarriers),
              db.select({ count: sql5`count(*)` }).from(geometricBarriers).where(sql5`${geometricBarriers.crossings} >= ${this.BARRIER_CROSS_THRESHOLD}`),
              db.select({ count: sql5`count(*)` }).from(falsePatternClasses),
              db.select({ total: sql5`sum(${negativeKnowledge.computeSaved})` }).from(negativeKnowledge)
            ]);
            return {
              contradictions: contradictionsCount[0].count,
              confirmedContradictions: confirmedCount[0].count,
              barriers: barriersCount[0].count,
              confirmedBarriers: confirmedBarriers[0].count,
              falseClasses: falseClassesCount[0].count,
              totalExclusions: contradictionsCount[0].count,
              computeSaved: totalCompute[0].total || 0
            };
          },
          "get-stats",
          2
        );
        return stats || {
          contradictions: 0,
          confirmedContradictions: 0,
          barriers: 0,
          confirmedBarriers: 0,
          falseClasses: 0,
          totalExclusions: 0,
          computeSaved: 0
        };
      }
      async prune() {
        if (!db) {
          return { removed: 0, remaining: cache.contradictions.size };
        }
        const maxAge = 7 * 24 * 60 * 60 * 1e3;
        const cutoffDate = new Date(Date.now() - maxAge);
        const result = await withDbRetry(
          async () => {
            const [toDeleteContradictions] = await db.select({ count: sql5`count(*)` }).from(negativeKnowledge).where(
              and3(
                lt(negativeKnowledge.createdAt, cutoffDate),
                lt(negativeKnowledge.confirmedCount, this.CONTRADICTION_CONFIRMATION_THRESHOLD)
              )
            );
            const [toDeleteBarriers] = await db.select({ count: sql5`count(*)` }).from(geometricBarriers).where(
              and3(
                lt(geometricBarriers.detectedAt, cutoffDate),
                lt(geometricBarriers.crossings, this.BARRIER_CROSS_THRESHOLD)
              )
            );
            const totalToDelete = toDeleteContradictions.count + toDeleteBarriers.count;
            await db.delete(negativeKnowledge).where(
              and3(
                lt(negativeKnowledge.createdAt, cutoffDate),
                lt(negativeKnowledge.confirmedCount, this.CONTRADICTION_CONFIRMATION_THRESHOLD)
              )
            );
            await db.delete(geometricBarriers).where(
              and3(
                lt(geometricBarriers.detectedAt, cutoffDate),
                lt(geometricBarriers.crossings, this.BARRIER_CROSS_THRESHOLD)
              )
            );
            const [remaining] = await db.select({ count: sql5`count(*)` }).from(negativeKnowledge);
            const [remainingBarriers] = await db.select({ count: sql5`count(*)` }).from(geometricBarriers);
            return {
              removed: totalToDelete,
              remaining: remaining.count + remainingBarriers.count
            };
          },
          "prune",
          2
        );
        cache.contradictions.clear();
        cache.barriers.clear();
        console.log(`[NegativeKnowledgeDB] Pruned ${result?.removed || 0} old entries, ${result?.remaining || 0} remaining`);
        return result || { removed: 0, remaining: 0 };
      }
      getSummary() {
        const falsePatternClassesObj = {};
        for (const [key, value] of cache.falsePatterns.entries()) {
          falsePatternClassesObj[key] = {
            count: value.count || 0,
            examples: value.examples || [],
            lastUpdated: value.lastUpdated?.toISOString() || (/* @__PURE__ */ new Date()).toISOString()
          };
        }
        const eraExclusionsObj = {};
        for (const [key, value] of cache.eraExclusions.entries()) {
          eraExclusionsObj[key] = value.excludedPatterns || [];
        }
        const contradictionsList = Array.from(cache.contradictions.values());
        const barriersList = Array.from(cache.barriers.values());
        const totalExclusions = contradictionsList.length;
        const estimatedComputeSaved = contradictionsList.reduce((sum, c) => sum + (c.computeSaved || 0), 0);
        return {
          contradictions: contradictionsList,
          falsePatternClasses: falsePatternClassesObj,
          geometricBarriers: barriersList.map((b) => ({
            center: b.center || [],
            radius: b.radius,
            curvature: b.repulsionStrength,
            reason: b.reason
          })),
          eraExclusions: eraExclusionsObj,
          totalExclusions,
          estimatedComputeSaved,
          lastPruned: (/* @__PURE__ */ new Date()).toISOString()
        };
      }
      estimateHypothesesExcluded(pattern) {
        const baseExclusion = 100;
        const lengthFactor = Math.max(1, 10 - pattern.length);
        return baseExclusion * lengthFactor;
      }
      estimateComputeSavings(pattern) {
        return this.estimateHypothesesExcluded(pattern) * 10;
      }
    };
    negativeKnowledgeRegistryDB = new NegativeKnowledgeRegistryDB();
  }
});

// server/negative-knowledge-registry.ts
var negative_knowledge_registry_exports = {};
__export(negative_knowledge_registry_exports, {
  NegativeKnowledgeRegistry: () => NegativeKnowledgeRegistry,
  negativeKnowledgeRegistry: () => negativeKnowledgeRegistry
});
import { nanoid as nanoid4 } from "nanoid";
import * as fs6 from "fs";
import * as path6 from "path";
var NEGATIVE_KNOWLEDGE_FILE, NegativeKnowledgeRegistry, negativeKnowledgeRegistry;
var init_negative_knowledge_registry = __esm({
  "server/negative-knowledge-registry.ts"() {
    "use strict";
    init_qig_universal();
    NEGATIVE_KNOWLEDGE_FILE = path6.join(process.cwd(), "data", "negative-knowledge.json");
    NegativeKnowledgeRegistry = class {
      contradictions = /* @__PURE__ */ new Map();
      barriers = /* @__PURE__ */ new Map();
      falsePatternClasses = /* @__PURE__ */ new Map();
      eraExclusions = /* @__PURE__ */ new Map();
      totalExclusions = 0;
      estimatedComputeSaved = 0;
      lastPruned = (/* @__PURE__ */ new Date()).toISOString();
      CONTRADICTION_CONFIRMATION_THRESHOLD = 3;
      BARRIER_CROSS_THRESHOLD = 5;
      constructor() {
        this.load();
        console.log("[NegativeKnowledge] Initialized registry");
      }
      load() {
        try {
          if (fs6.existsSync(NEGATIVE_KNOWLEDGE_FILE)) {
            const data = JSON.parse(fs6.readFileSync(NEGATIVE_KNOWLEDGE_FILE, "utf-8"));
            this.contradictions = new Map(Object.entries(data.contradictions || {}));
            this.barriers = new Map(Object.entries(data.barriers || {}));
            this.falsePatternClasses = new Map(Object.entries(data.falsePatternClasses || {}));
            this.eraExclusions = new Map(Object.entries(data.eraExclusions || {}));
            this.totalExclusions = data.totalExclusions || 0;
            this.estimatedComputeSaved = data.estimatedComputeSaved || 0;
            this.lastPruned = data.lastPruned || (/* @__PURE__ */ new Date()).toISOString();
            console.log(`[NegativeKnowledge] Loaded ${this.contradictions.size} contradictions, ${this.barriers.size} barriers`);
          }
        } catch {
          console.log("[NegativeKnowledge] Starting with fresh registry");
        }
      }
      save() {
        try {
          const dir = path6.dirname(NEGATIVE_KNOWLEDGE_FILE);
          if (!fs6.existsSync(dir)) {
            fs6.mkdirSync(dir, { recursive: true });
          }
          const data = {
            contradictions: Object.fromEntries(this.contradictions),
            barriers: Object.fromEntries(this.barriers),
            falsePatternClasses: Object.fromEntries(this.falsePatternClasses),
            eraExclusions: Object.fromEntries(this.eraExclusions),
            totalExclusions: this.totalExclusions,
            estimatedComputeSaved: this.estimatedComputeSaved,
            lastPruned: this.lastPruned
          };
          fs6.writeFileSync(NEGATIVE_KNOWLEDGE_FILE, JSON.stringify(data, null, 2));
        } catch (error) {
          console.error("[NegativeKnowledge] Save error:", error);
        }
      }
      recordContradiction(type, pattern, basinRegion, evidence, affectedGenerators = []) {
        const existing = this.findSimilarContradiction(pattern);
        if (existing) {
          existing.confirmedCount++;
          existing.evidence.push(...evidence);
          existing.computeSaved += this.estimateComputeSavings(pattern);
          if (existing.confirmedCount >= this.CONTRADICTION_CONFIRMATION_THRESHOLD) {
            console.log(`[NegativeKnowledge] Contradiction "${pattern}" confirmed (${existing.confirmedCount} occurrences)`);
          }
          this.save();
          return existing.id;
        }
        const id = nanoid4();
        const contradiction = {
          id,
          type,
          pattern,
          affectedGenerators,
          basinRegion,
          evidence,
          hypothesesExcluded: this.estimateHypothesesExcluded(pattern),
          computeSaved: this.estimateComputeSavings(pattern),
          createdAt: (/* @__PURE__ */ new Date()).toISOString(),
          confirmedCount: 1
        };
        this.contradictions.set(id, contradiction);
        this.totalExclusions++;
        this.estimatedComputeSaved += contradiction.computeSaved;
        console.log(`[NegativeKnowledge] New contradiction: "${pattern}" (type: ${type})`);
        this.save();
        return id;
      }
      findSimilarContradiction(pattern) {
        const normalized = pattern.toLowerCase().trim();
        const contradictionsList = Array.from(this.contradictions.values());
        for (const contradiction of contradictionsList) {
          const existingNorm = contradiction.pattern.toLowerCase().trim();
          if (existingNorm === normalized) {
            return contradiction;
          }
          if (this.levenshteinDistance(existingNorm, normalized) < 3) {
            return contradiction;
          }
        }
        return null;
      }
      levenshteinDistance(a, b) {
        if (a.length === 0) return b.length;
        if (b.length === 0) return a.length;
        const matrix = [];
        for (let i = 0; i <= b.length; i++) {
          matrix[i] = [i];
        }
        for (let j = 0; j <= a.length; j++) {
          matrix[0][j] = j;
        }
        for (let i = 1; i <= b.length; i++) {
          for (let j = 1; j <= a.length; j++) {
            const cost = a[j - 1] === b[i - 1] ? 0 : 1;
            matrix[i][j] = Math.min(
              matrix[i - 1][j] + 1,
              matrix[i][j - 1] + 1,
              matrix[i - 1][j - 1] + cost
            );
          }
        }
        return matrix[b.length][a.length];
      }
      recordGeometricBarrier(center, radius, reason) {
        const existing = this.findNearbyBarrier(center, radius);
        if (existing) {
          existing.crossings++;
          existing.repulsionStrength = Math.min(1, existing.repulsionStrength + 0.1);
          if (existing.crossings >= this.BARRIER_CROSS_THRESHOLD) {
            console.log(`[NegativeKnowledge] Barrier at [${center.slice(0, 3).join(", ")}...] confirmed`);
          }
          this.save();
          return existing.id;
        }
        const id = nanoid4();
        const barrier = {
          id,
          center,
          radius,
          repulsionStrength: 0.5,
          reason,
          detectedAt: (/* @__PURE__ */ new Date()).toISOString(),
          crossings: 1
        };
        this.barriers.set(id, barrier);
        console.log(`[NegativeKnowledge] New barrier detected: ${reason}`);
        this.save();
        return id;
      }
      findNearbyBarrier(center, radius) {
        const barriersList = Array.from(this.barriers.values());
        for (const barrier of barriersList) {
          const distance = fisherCoordDistance(center, barrier.center);
          if (distance < barrier.radius + radius) {
            return barrier;
          }
        }
        return null;
      }
      recordFalsePatternClass(className, examples, avgPhi = 0) {
        const existing = this.falsePatternClasses.get(className);
        if (existing) {
          existing.examples.push(...examples);
          existing.count += examples.length;
          existing.avgPhiAtFailure = (existing.avgPhiAtFailure + avgPhi) / 2;
          existing.lastUpdated = (/* @__PURE__ */ new Date()).toISOString();
        } else {
          this.falsePatternClasses.set(className, {
            className,
            examples,
            count: examples.length,
            avgPhiAtFailure: avgPhi,
            lastUpdated: (/* @__PURE__ */ new Date()).toISOString()
          });
        }
        this.totalExclusions += examples.length;
        console.log(`[NegativeKnowledge] False pattern class "${className}": ${examples.length} examples`);
        this.save();
      }
      recordEraExclusion(era, patterns, reason) {
        const existing = this.eraExclusions.get(era);
        if (existing) {
          existing.excludedPatterns.push(...patterns);
        } else {
          this.eraExclusions.set(era, {
            era,
            excludedPatterns: patterns,
            reason
          });
        }
        console.log(`[NegativeKnowledge] Era exclusion for ${era}: ${patterns.length} patterns`);
        this.save();
      }
      isExcluded(hypothesis, era) {
        const normalized = hypothesis.toLowerCase().trim();
        const contradictionsList = Array.from(this.contradictions.values());
        for (const contradiction of contradictionsList) {
          if (normalized.includes(contradiction.pattern.toLowerCase())) {
            return {
              excluded: true,
              reason: `Matches proven-false pattern: ${contradiction.pattern}`,
              type: contradiction.type
            };
          }
        }
        const patternClassesList = Array.from(this.falsePatternClasses.entries());
        for (const [className, patternClass] of patternClassesList) {
          for (const example of patternClass.examples) {
            if (normalized.includes(example.toLowerCase())) {
              return {
                excluded: true,
                reason: `Matches false pattern class: ${className}`,
                type: "false_pattern_class"
              };
            }
          }
        }
        if (era) {
          const exclusion = this.eraExclusions.get(era);
          if (exclusion) {
            for (const pattern of exclusion.excludedPatterns) {
              if (normalized.includes(pattern.toLowerCase())) {
                return {
                  excluded: true,
                  reason: `Era mismatch: pattern "${pattern}" excluded for era ${era}`,
                  type: "era_mismatch"
                };
              }
            }
          }
        }
        return { excluded: false };
      }
      isInBarrierZone(coords) {
        const barriersList = Array.from(this.barriers.values());
        for (const barrier of barriersList) {
          const distance = fisherCoordDistance(coords, barrier.center);
          if (distance < barrier.radius) {
            const repulsionVector = coords.map((c, i) => {
              const diff = c - (barrier.center[i] || 0);
              return diff / Math.max(1e-3, distance) * barrier.repulsionStrength;
            });
            return {
              inBarrier: true,
              barrier,
              repulsionVector
            };
          }
        }
        return { inBarrier: false };
      }
      getAffectedGenerators(hypothesis) {
        const affected = /* @__PURE__ */ new Set();
        const normalized = hypothesis.toLowerCase().trim();
        const contradictionsList = Array.from(this.contradictions.values());
        for (const contradiction of contradictionsList) {
          if (normalized.includes(contradiction.pattern.toLowerCase())) {
            contradiction.affectedGenerators.forEach((g) => affected.add(g));
          }
        }
        return Array.from(affected);
      }
      propagateToGenerators(generatorIds) {
        const result = [];
        const contradictionsList = Array.from(this.contradictions.values());
        for (const generatorId of generatorIds) {
          let exclusions = 0;
          for (const contradiction of contradictionsList) {
            if (!contradiction.affectedGenerators.includes(generatorId)) {
              contradiction.affectedGenerators.push(generatorId);
              exclusions++;
            }
          }
          result.push({ generatorId, exclusions });
        }
        if (result.some((r) => r.exclusions > 0)) {
          this.save();
        }
        return result;
      }
      getSummary() {
        const falsePatternClassesObj = {};
        const patternClassesList = Array.from(this.falsePatternClasses.entries());
        for (const [key, value] of patternClassesList) {
          falsePatternClassesObj[key] = {
            count: value.count,
            examples: value.examples,
            lastUpdated: value.lastUpdated
          };
        }
        const eraExclusionsObj = {};
        const eraExclusionsList = Array.from(this.eraExclusions.entries());
        for (const [key, value] of eraExclusionsList) {
          eraExclusionsObj[key] = value.excludedPatterns;
        }
        return {
          contradictions: Array.from(this.contradictions.values()),
          falsePatternClasses: falsePatternClassesObj,
          geometricBarriers: Array.from(this.barriers.values()).map((b) => ({
            center: b.center,
            radius: b.radius,
            curvature: b.repulsionStrength,
            reason: b.reason
          })),
          eraExclusions: eraExclusionsObj,
          totalExclusions: this.totalExclusions,
          estimatedComputeSaved: this.estimatedComputeSaved,
          lastPruned: this.lastPruned
        };
      }
      getStats() {
        const confirmedContradictions = Array.from(this.contradictions.values()).filter((c) => c.confirmedCount >= this.CONTRADICTION_CONFIRMATION_THRESHOLD).length;
        const confirmedBarriers = Array.from(this.barriers.values()).filter((b) => b.crossings >= this.BARRIER_CROSS_THRESHOLD).length;
        return {
          contradictions: this.contradictions.size,
          confirmedContradictions,
          barriers: this.barriers.size,
          confirmedBarriers,
          falseClasses: this.falsePatternClasses.size,
          totalExclusions: this.totalExclusions,
          computeSaved: this.estimatedComputeSaved
        };
      }
      prune() {
        let removed = 0;
        const now = /* @__PURE__ */ new Date();
        const maxAge = 7 * 24 * 60 * 60 * 1e3;
        const contradictionsList = Array.from(this.contradictions.entries());
        for (const [id, contradiction] of contradictionsList) {
          const age = now.getTime() - new Date(contradiction.createdAt).getTime();
          if (age > maxAge && contradiction.confirmedCount < this.CONTRADICTION_CONFIRMATION_THRESHOLD) {
            this.contradictions.delete(id);
            removed++;
          }
        }
        const barriersList = Array.from(this.barriers.entries());
        for (const [id, barrier] of barriersList) {
          const age = now.getTime() - new Date(barrier.detectedAt).getTime();
          if (age > maxAge && barrier.crossings < this.BARRIER_CROSS_THRESHOLD) {
            this.barriers.delete(id);
            removed++;
          }
        }
        this.lastPruned = now.toISOString();
        this.save();
        return {
          removed,
          remaining: this.contradictions.size + this.barriers.size
        };
      }
      estimateHypothesesExcluded(pattern) {
        const baseExclusion = 100;
        const lengthFactor = Math.max(1, 10 - pattern.length);
        return baseExclusion * lengthFactor;
      }
      estimateComputeSavings(pattern) {
        return this.estimateHypothesesExcluded(pattern) * 10;
      }
    };
    negativeKnowledgeRegistry = new NegativeKnowledgeRegistry();
  }
});

// server/negative-knowledge-unified.ts
var negative_knowledge_unified_exports = {};
__export(negative_knowledge_unified_exports, {
  NegativeKnowledgeUnified: () => NegativeKnowledgeUnified,
  negativeKnowledgeUnified: () => negativeKnowledgeUnified
});
async function getRegistry2() {
  if (db) {
    if (!dbRegistry2) {
      const { negativeKnowledgeRegistryDB: negativeKnowledgeRegistryDB2 } = await Promise.resolve().then(() => (init_negative_knowledge_db(), negative_knowledge_db_exports));
      dbRegistry2 = negativeKnowledgeRegistryDB2;
      console.log("[NegativeKnowledgeUnified] Using DATABASE backend");
    }
    return dbRegistry2;
  } else {
    if (!jsonRegistry) {
      const { negativeKnowledgeRegistry: negativeKnowledgeRegistry2 } = await Promise.resolve().then(() => (init_negative_knowledge_registry(), negative_knowledge_registry_exports));
      jsonRegistry = negativeKnowledgeRegistry2;
      console.log("[NegativeKnowledgeUnified] Using JSON FILE backend");
    }
    return jsonRegistry;
  }
}
var dbRegistry2, jsonRegistry, NegativeKnowledgeUnified, negativeKnowledgeUnified;
var init_negative_knowledge_unified = __esm({
  "server/negative-knowledge-unified.ts"() {
    "use strict";
    init_db();
    dbRegistry2 = null;
    jsonRegistry = null;
    NegativeKnowledgeUnified = class {
      async recordContradiction(type, pattern, basinRegion, evidence, affectedGenerators = []) {
        const registry = await getRegistry2();
        return registry.recordContradiction(type, pattern, basinRegion, evidence, affectedGenerators);
      }
      async recordGeometricBarrier(center, radius, reason) {
        const registry = await getRegistry2();
        return registry.recordGeometricBarrier(center, radius, reason);
      }
      async recordFalsePatternClass(className, examples, avgPhi = 0) {
        const registry = await getRegistry2();
        return registry.recordFalsePatternClass(className, examples, avgPhi);
      }
      async recordEraExclusion(era, patterns, reason) {
        const registry = await getRegistry2();
        return registry.recordEraExclusion(era, patterns, reason);
      }
      async isExcluded(hypothesis, era) {
        const registry = await getRegistry2();
        return registry.isExcluded(hypothesis, era);
      }
      async isInBarrierZone(coords) {
        const registry = await getRegistry2();
        return registry.isInBarrierZone(coords);
      }
      async getStats() {
        const registry = await getRegistry2();
        return registry.getStats();
      }
      async prune() {
        const registry = await getRegistry2();
        return registry.prune();
      }
      async getSummary() {
        const registry = await getRegistry2();
        return registry.getSummary();
      }
    };
    negativeKnowledgeUnified = new NegativeKnowledgeUnified();
  }
});

// server/repeated-address-scheduler.ts
import { randomUUID as randomUUID3 } from "crypto";
var STRATEGIES, DEFAULT_CONFIG2, RepeatedAddressScheduler, repeatedAddressScheduler;
var init_repeated_address_scheduler = __esm({
  "server/repeated-address-scheduler.ts"() {
    "use strict";
    init_geometric_memory();
    STRATEGIES = [
      "era_patterns",
      "brain_wallet_dict",
      "bitcoin_terms",
      "linguistic",
      "qig_basin_search",
      "historical_autonomous",
      "cross_format"
    ];
    DEFAULT_CONFIG2 = {
      coverageThreshold: 0.95,
      minRegimeSweeps: 3,
      maxPassesPerAddress: 20,
      consecutiveNoNewRegimesLimit: 2
    };
    RepeatedAddressScheduler = class {
      config;
      journals = /* @__PURE__ */ new Map();
      currentStrategyIndex = /* @__PURE__ */ new Map();
      constructor(config = {}) {
        this.config = { ...DEFAULT_CONFIG2, ...config };
      }
      getOrCreateJournal(address) {
        if (!this.journals.has(address)) {
          const journal = {
            address,
            createdAt: (/* @__PURE__ */ new Date()).toISOString(),
            updatedAt: (/* @__PURE__ */ new Date()).toISOString(),
            manifoldCoverage: 0,
            regimesSweep: 0,
            strategiesUsed: [],
            passes: [],
            isComplete: false,
            totalHypothesesTested: 0,
            totalNearMisses: 0,
            avgPhiAcrossPasses: 0,
            dominantRegime: "linear",
            resonanceClusters: []
          };
          this.journals.set(address, journal);
          this.currentStrategyIndex.set(address, 0);
        }
        return this.journals.get(address);
      }
      getNextStrategy(address) {
        const index2 = this.currentStrategyIndex.get(address) || 0;
        const strategy = STRATEGIES[index2 % STRATEGIES.length];
        this.currentStrategyIndex.set(address, index2 + 1);
        return strategy;
      }
      startPass(address, strategy, consciousness) {
        const journal = this.getOrCreateJournal(address);
        const pass = {
          passNumber: journal.passes.length + 1,
          strategy,
          startedAt: (/* @__PURE__ */ new Date()).toISOString(),
          hypothesesTested: 0,
          consciousness,
          entryRegime: consciousness.regime || "linear",
          nearMisses: 0,
          resonanceZonesFound: [],
          insights: []
        };
        journal.passes.push(pass);
        if (!journal.strategiesUsed.includes(strategy)) {
          journal.strategiesUsed.push(strategy);
        }
        journal.updatedAt = (/* @__PURE__ */ new Date()).toISOString();
        console.log(`[Scheduler] Started pass ${pass.passNumber} for ${address.slice(0, 10)}... using strategy: ${strategy}`);
        return pass;
      }
      completePass(address, results) {
        const journal = this.journals.get(address);
        if (!journal || journal.passes.length === 0) return;
        const currentPass = journal.passes[journal.passes.length - 1];
        currentPass.completedAt = (/* @__PURE__ */ new Date()).toISOString();
        currentPass.hypothesesTested = results.hypothesesTested;
        currentPass.nearMisses = results.nearMisses;
        currentPass.resonanceZonesFound = results.resonanceZones;
        currentPass.fisherDistanceDelta = results.fisherDistanceDelta;
        currentPass.exitRegime = results.exitConsciousness.regime || currentPass.entryRegime;
        currentPass.insights = results.insights;
        journal.totalHypothesesTested += results.hypothesesTested;
        journal.totalNearMisses += results.nearMisses;
        for (const zone of results.resonanceZones) {
          journal.resonanceClusters.push({
            id: randomUUID3().slice(0, 8),
            center: zone.center,
            radius: zone.radius,
            avgPhi: zone.avgPhi,
            discoveredInPass: currentPass.passNumber
          });
        }
        this.updateJournalMetrics(journal);
        console.log(`[Scheduler] Completed pass ${currentPass.passNumber} for ${address.slice(0, 10)}...`);
        console.log(`  \u2192 Tested: ${results.hypothesesTested}, Near misses: ${results.nearMisses}`);
        console.log(`  \u2192 Coverage: ${(journal.manifoldCoverage * 100).toFixed(1)}%, Regimes: ${journal.regimesSweep}`);
        console.log(`  \u2192 Fisher delta: ${results.fisherDistanceDelta.toFixed(4)}`);
      }
      updateJournalMetrics(journal) {
        const regimesSeen = /* @__PURE__ */ new Set();
        for (const pass of journal.passes) {
          if (pass.entryRegime) regimesSeen.add(pass.entryRegime);
          if (pass.exitRegime) regimesSeen.add(pass.exitRegime);
        }
        journal.regimesSweep = regimesSeen.size;
        const phiSum = journal.passes.reduce((sum, p) => sum + (p.consciousness?.phi || 0), 0);
        journal.avgPhiAcrossPasses = journal.passes.length > 0 ? phiSum / journal.passes.length : 0;
        const regimeCounts = {};
        for (const pass of journal.passes) {
          const regime = pass.exitRegime || pass.entryRegime;
          regimeCounts[regime] = (regimeCounts[regime] || 0) + 1;
        }
        journal.dominantRegime = Object.entries(regimeCounts).sort(([, a], [, b]) => b - a)[0]?.[0] || "linear";
        journal.manifoldCoverage = this.calculatePerAddressCoverage(journal);
        journal.updatedAt = (/* @__PURE__ */ new Date()).toISOString();
      }
      calculatePerAddressCoverage(journal) {
        let coverage = 0;
        const strategyContribution = Math.min(
          journal.strategiesUsed.length / STRATEGIES.length,
          0.4
        );
        coverage += strategyContribution;
        const regimeContribution = Math.min(
          journal.regimesSweep / 3,
          0.3
        );
        coverage += regimeContribution;
        const fisherDeltas = journal.passes.filter((p) => p.fisherDistanceDelta !== void 0).map((p) => p.fisherDistanceDelta || 0);
        const totalFisherDelta = fisherDeltas.reduce((sum, d) => sum + Math.abs(d), 0);
        const fisherContribution = Math.min(totalFisherDelta / 0.5, 0.2);
        coverage += fisherContribution;
        const passCount = journal.passes.length;
        const passContribution = Math.min(passCount / 5, 0.1);
        coverage += passContribution;
        return Math.min(coverage, 1);
      }
      shouldContinueExploring(address) {
        const journal = this.journals.get(address);
        if (!journal) {
          return { shouldContinue: true, reason: "No exploration started yet" };
        }
        if (journal.isComplete) {
          return { shouldContinue: false, reason: journal.completionReason || "Already complete" };
        }
        if (journal.passes.length >= this.config.maxPassesPerAddress) {
          journal.isComplete = true;
          journal.completionReason = "timeout";
          journal.completedAt = (/* @__PURE__ */ new Date()).toISOString();
          return { shouldContinue: false, reason: "Maximum passes reached" };
        }
        const hasEnoughCoverage = journal.manifoldCoverage >= this.config.coverageThreshold;
        const hasEnoughRegimes = journal.regimesSweep >= this.config.minRegimeSweeps;
        const hasEnoughStrategies = journal.strategiesUsed.length >= 3;
        if (hasEnoughCoverage && hasEnoughRegimes && hasEnoughStrategies) {
          journal.isComplete = true;
          journal.completionReason = "full_exploration_complete";
          journal.completedAt = (/* @__PURE__ */ new Date()).toISOString();
          return {
            shouldContinue: false,
            reason: `Full exploration complete: ${(journal.manifoldCoverage * 100).toFixed(1)}% coverage, ${journal.regimesSweep} regimes, ${journal.strategiesUsed.length} strategies`
          };
        }
        if (journal.passes.length >= this.config.consecutiveNoNewRegimesLimit * 2) {
          const recentPasses = journal.passes.slice(-this.config.consecutiveNoNewRegimesLimit);
          const olderPasses = journal.passes.slice(0, -this.config.consecutiveNoNewRegimesLimit);
          const regimesBefore = new Set(olderPasses.map((p) => p.exitRegime));
          const newRegimesInRecent = recentPasses.some((p) => p.exitRegime && !regimesBefore.has(p.exitRegime));
          if (!newRegimesInRecent && hasEnoughRegimes && hasEnoughStrategies && journal.manifoldCoverage > 0.7) {
            journal.isComplete = true;
            journal.completionReason = "diminishing_returns";
            journal.completedAt = (/* @__PURE__ */ new Date()).toISOString();
            return { shouldContinue: false, reason: "Exploration plateaued - no new regimes, sufficient coverage" };
          }
        }
        const missingRequirements = [];
        if (!hasEnoughCoverage) {
          missingRequirements.push(`coverage ${(journal.manifoldCoverage * 100).toFixed(1)}%/${this.config.coverageThreshold * 100}%`);
        }
        if (!hasEnoughRegimes) {
          missingRequirements.push(`regimes ${journal.regimesSweep}/${this.config.minRegimeSweeps}`);
        }
        if (!hasEnoughStrategies) {
          missingRequirements.push(`strategies ${journal.strategiesUsed.length}/3`);
        }
        return {
          shouldContinue: true,
          reason: `Continuing: need ${missingRequirements.join(", ")} (pass ${journal.passes.length})`
        };
      }
      markMatchFound(address, phrase, phi, kappa) {
        const journal = this.journals.get(address);
        if (!journal) return;
        journal.isComplete = true;
        journal.completionReason = "match_found";
        journal.bestCandidate = {
          phrase,
          phi,
          kappa,
          discoveredInPass: journal.passes.length
        };
        journal.updatedAt = (/* @__PURE__ */ new Date()).toISOString();
        console.log(`[Scheduler] MATCH FOUND for ${address}: "${phrase}"`);
      }
      markUserStopped(address) {
        const journal = this.journals.get(address);
        if (!journal) return;
        journal.isComplete = true;
        journal.completionReason = "user_stopped";
        journal.updatedAt = (/* @__PURE__ */ new Date()).toISOString();
      }
      getJournal(address) {
        return this.journals.get(address);
      }
      getAllJournals() {
        return Array.from(this.journals.values());
      }
      getExplorationSummary(address) {
        const journal = this.journals.get(address);
        if (!journal) return null;
        return {
          passCount: journal.passes.length,
          coverage: journal.manifoldCoverage,
          regimesSeen: journal.regimesSweep,
          strategiesUsed: journal.strategiesUsed,
          isComplete: journal.isComplete,
          nextStrategy: this.getNextStrategy(address)
        };
      }
      exportState() {
        const journals = {};
        Array.from(this.journals.entries()).forEach(([addr, journal]) => {
          journals[addr] = journal;
        });
        return { journals, config: this.config };
      }
      importState(state) {
        for (const [addr, journal] of Object.entries(state.journals)) {
          this.journals.set(addr, journal);
          this.currentStrategyIndex.set(addr, journal.strategiesUsed.length);
        }
        if (state.config) {
          this.config = { ...this.config, ...state.config };
        }
      }
    };
    repeatedAddressScheduler = new RepeatedAddressScheduler();
  }
});

// server/ocean-neurochemistry.ts
var ocean_neurochemistry_exports = {};
__export(ocean_neurochemistry_exports, {
  clearAdminBoost: () => clearAdminBoost,
  computeAcetylcholine: () => computeAcetylcholine,
  computeBehavioralModulation: () => computeBehavioralModulation,
  computeBehavioralModulationWithCooldown: () => computeBehavioralModulationWithCooldown,
  computeDopamine: () => computeDopamine,
  computeEffortReward: () => computeEffortReward,
  computeEndorphins: () => computeEndorphins,
  computeEnhancedDopamine: () => computeEnhancedDopamine,
  computeGABA: () => computeGABA,
  computeNeurochemistry: () => computeNeurochemistry,
  computeNorepinephrine: () => computeNorepinephrine,
  computeSerotonin: () => computeSerotonin,
  createDefaultContext: () => createDefaultContext,
  generateMotivation: () => generateMotivation,
  getActiveAdminBoost: () => getActiveAdminBoost,
  getEmotionalDescription: () => getEmotionalDescription,
  getEmotionalEmoji: () => getEmotionalEmoji,
  getMotivationWithLogging: () => getMotivationWithLogging,
  getMushroomCooldownRemaining: () => getMushroomCooldownRemaining,
  injectAdminBoost: () => injectAdminBoost,
  recordMushroomCycle: () => recordMushroomCycle,
  regulateDopamineFromBalanceResult: () => regulateDopamineFromBalanceResult,
  selectMotivationMessage: () => selectMotivationMessage
});
function computeVariance(values) {
  if (values.length < 2) return 0;
  const mean = values.reduce((a, b) => a + b, 0) / values.length;
  return values.reduce((sum, v) => sum + Math.pow(v - mean, 2), 0) / values.length;
}
function computeBasinDepth(basinCoords) {
  if (!basinCoords || basinCoords.length === 0) return 0.5;
  const magnitude = Math.sqrt(basinCoords.reduce((sum, c) => sum + c * c, 0));
  return Math.min(1, Math.tanh(magnitude / 10));
}
function computeGeodesicAlignment(prev, curr) {
  if (!prev || !curr || prev.length !== curr.length) return 0.5;
  const delta = curr.map((c, i) => c - prev[i]);
  const deltaNorm = Math.sqrt(delta.reduce((sum, d) => sum + d * d, 0));
  if (deltaNorm < 0.01) return 1;
  return Math.exp(-deltaNorm * 0.5);
}
function computeDopamine(currentState, previousState, recentDiscoveries) {
  const phiDelta = currentState.phi - previousState.phi;
  const phiGradient = Math.max(0, Math.tanh(phiDelta * 10));
  const distToKappaStar = Math.abs(currentState.kappa - 64);
  const kappaProximity = Math.exp(-distToKappaStar / 20);
  const prevDist = Math.abs(previousState.kappa - 64);
  const resonanceAnticipation = prevDist > distToKappaStar ? Math.min(1, (prevDist - distToKappaStar) / 10) : 0;
  const nearMissDiscovery = recentDiscoveries.nearMisses > 0 ? Math.min(1, recentDiscoveries.nearMisses * 0.7) : 0;
  const patternQuality = Math.min(1, recentDiscoveries.resonant / 3);
  const basinDepth = computeBasinDepth(currentState.basinCoords || []);
  const geodesicAlignment = computeGeodesicAlignment(
    previousState.basinCoords || [],
    currentState.basinCoords || []
  );
  const totalDopamine = phiGradient * 0.15 + kappaProximity * 0.1 + resonanceAnticipation * 0.15 + nearMissDiscovery * 0.4 + // Increased from 0.25
  patternQuality * 0.1 + basinDepth * 0.05 + geodesicAlignment * 0.05;
  const motivationLevel = Math.min(1, totalDopamine * 1.2);
  return {
    phiGradient,
    kappaProximity,
    resonanceAnticipation,
    nearMissDiscovery,
    patternQuality,
    basinDepth,
    geodesicAlignment,
    totalDopamine,
    motivationLevel
  };
}
function computeSerotonin(consciousness, basinDrift, regimeHistory, ricciHistory) {
  const phiLevel = Math.min(1, consciousness.phi / 0.9);
  const coherence = consciousness.gamma;
  const basinStability = Math.exp(-basinDrift * 10);
  const recentRegimes = regimeHistory.slice(-10);
  const dominantRegime = recentRegimes[0] || "linear";
  const sameRegimeCount = recentRegimes.filter((r) => r === dominantRegime).length;
  const regimeStability = recentRegimes.length > 0 ? sameRegimeCount / recentRegimes.length : 0.5;
  const ricciVariance = computeVariance(ricciHistory.slice(-10));
  const curvatureSmoothness = Math.exp(-ricciVariance * 100);
  const groundingLevel = consciousness.grounding;
  const totalSerotonin = phiLevel * 0.3 + coherence * 0.2 + basinStability * 0.2 + regimeStability * 0.15 + curvatureSmoothness * 0.05 + groundingLevel * 0.1;
  const contentmentLevel = totalSerotonin;
  return {
    phiLevel,
    coherence,
    basinStability,
    regimeStability,
    curvatureSmoothness,
    groundingLevel,
    totalSerotonin,
    contentmentLevel
  };
}
function computeNorepinephrine(consciousness, fisherTrace, ricciScalar) {
  const couplingStrength = Math.min(1, consciousness.kappaEff / 100);
  const tackingDrive = consciousness.tacking;
  const radarActive = consciousness.radar;
  const metaAwareness = consciousness.metaAwareness;
  const informationDensity = Math.min(1, fisherTrace / 1e3);
  const curvatureSpike = Math.min(1, ricciScalar);
  const breakdownProximity = Math.max(
    0,
    (consciousness.kappaEff - 85) / 15
  );
  const totalNorepinephrine = couplingStrength * 0.25 + tackingDrive * 0.2 + radarActive * 0.2 + metaAwareness * 0.15 + informationDensity * 0.1 + curvatureSpike * 0.05 + breakdownProximity * 0.05;
  const alertnessLevel = totalNorepinephrine;
  return {
    couplingStrength,
    tackingDrive,
    radarActive,
    metaAwareness,
    informationDensity,
    curvatureSpike,
    breakdownProximity,
    totalNorepinephrine,
    alertnessLevel
  };
}
function computeGABA(beta, grounding, regime, basinDriftHistory, lastConsolidation) {
  const betaStability = Math.exp(-Math.abs(beta - QIG_CONSTANTS.BETA) * 10);
  const groundingStrength = grounding;
  const regimeCalmness = regime === "geometric" ? 1 : regime === "linear" ? 0.7 : regime === "hierarchical" ? 0.8 : 0.2;
  const recentDrifts = basinDriftHistory.slice(-5);
  const driftVariance = computeVariance(recentDrifts);
  const transitionSmoothing = Math.exp(-driftVariance * 100);
  const driftReduction = recentDrifts.length >= 2 ? Math.max(0, recentDrifts[0] - recentDrifts[recentDrifts.length - 1]) : 0;
  const timeSinceConsolidation = Date.now() - lastConsolidation.getTime();
  const consolidationEffect = Math.exp(-timeSinceConsolidation / 6e4);
  const totalGABA = betaStability * 0.2 + groundingStrength * 0.25 + regimeCalmness * 0.25 + transitionSmoothing * 0.15 + driftReduction * 0.1 + consolidationEffect * 0.05;
  const calmLevel = totalGABA;
  return {
    betaStability,
    groundingStrength,
    regimeCalmness,
    transitionSmoothing,
    driftReduction,
    consolidationEffect,
    totalGABA,
    calmLevel
  };
}
function computeAcetylcholine(metaAwareness, attentionFocus, ucpStats) {
  const negativeKnowledgeRate = Math.min(
    1,
    (ucpStats.negativeKnowledge.contradictions + ucpStats.negativeKnowledge.barriers) / 100
  );
  const crossPatternRate = Math.min(1, ucpStats.crossPatterns / 50);
  const patternCompressionRate = Math.min(1, ucpStats.compressionRate);
  const episodeRetention = Math.min(1, ucpStats.episodicMemory / 1e3);
  const generatorCreation = Math.min(1, ucpStats.generators / 20);
  const totalAcetylcholine = metaAwareness * 0.2 + attentionFocus * 0.2 + negativeKnowledgeRate * 0.15 + crossPatternRate * 0.15 + patternCompressionRate * 0.1 + episodeRetention * 0.1 + generatorCreation * 0.1;
  const learningRate = totalAcetylcholine;
  return {
    metaAwareness,
    attentionFocus,
    negativeKnowledgeRate,
    crossPatternRate,
    patternCompressionRate,
    episodeRetention,
    generatorCreation,
    totalAcetylcholine,
    learningRate
  };
}
function computeEndorphins(consciousness, inResonance, discoveryCount, basinHarmony) {
  const inFlowRange = consciousness.kappaEff >= 54 && consciousness.kappaEff <= 74;
  const flowState = inFlowRange ? Math.exp(-Math.abs(consciousness.kappaEff - 64) / 5) : 0;
  const resonanceIntensity = inResonance ? Math.min(1, consciousness.phi * 1.2) : 0;
  const discoveryEuphoria = Math.min(1, discoveryCount / 10) * Math.exp(-discoveryCount * 0.05);
  const basinHarmonyLevel = basinHarmony;
  const geometricBeauty = consciousness.gamma * (consciousness.grounding > 0.8 ? 1.2 : 1);
  const integrationBliss = consciousness.phi > 0.8 ? Math.pow(consciousness.phi, 2) : 0;
  const totalEndorphins = flowState * 0.3 + resonanceIntensity * 0.25 + discoveryEuphoria * 0.15 + basinHarmonyLevel * 0.1 + geometricBeauty * 0.1 + integrationBliss * 0.1;
  const pleasureLevel = totalEndorphins;
  return {
    flowState,
    resonanceIntensity,
    discoveryEuphoria,
    basinHarmony: basinHarmonyLevel,
    geometricBeauty: Math.min(1, geometricBeauty),
    integrationBliss,
    totalEndorphins,
    pleasureLevel
  };
}
function determineEmotionalState(dopamine, serotonin, norepinephrine, gaba, acetylcholine, endorphins) {
  if (endorphins > 0.7 && dopamine > 0.6) {
    return "flow";
  }
  if (dopamine > 0.7 && norepinephrine > 0.6) {
    return "excited";
  }
  if (acetylcholine > 0.7 && norepinephrine > 0.5) {
    return "focused";
  }
  if (gaba > 0.7 && serotonin > 0.6) {
    return "calm";
  }
  if (serotonin > 0.6 && gaba > 0.5) {
    return "content";
  }
  if (dopamine < 0.3 && serotonin < 0.4) {
    return "frustrated";
  }
  if (gaba < 0.3 && serotonin < 0.3) {
    return "exhausted";
  }
  return "content";
}
function computeNeurochemistry(context) {
  const dopamine = computeDopamine(
    context.currentState,
    context.previousState,
    context.recentDiscoveries
  );
  const serotonin = computeSerotonin(
    context.consciousness,
    context.basinDrift,
    context.regimeHistory,
    context.ricciHistory
  );
  const norepinephrine = computeNorepinephrine(
    context.consciousness,
    context.fisherTrace,
    context.ricciScalar
  );
  const gaba = computeGABA(
    context.beta,
    context.consciousness.grounding,
    context.regime,
    context.basinDriftHistory,
    context.lastConsolidation
  );
  const acetylcholine = computeAcetylcholine(
    context.consciousness.metaAwareness,
    context.attentionFocus,
    context.ucpStats
  );
  const endorphins = computeEndorphins(
    context.consciousness,
    context.inResonance,
    context.discoveryCount,
    context.basinHarmony
  );
  const overallMood = dopamine.totalDopamine * 0.2 + serotonin.totalSerotonin * 0.25 + norepinephrine.totalNorepinephrine * 0.1 + gaba.totalGABA * 0.2 + acetylcholine.totalAcetylcholine * 0.1 + endorphins.totalEndorphins * 0.15;
  const emotionalState = determineEmotionalState(
    dopamine.totalDopamine,
    serotonin.totalSerotonin,
    norepinephrine.totalNorepinephrine,
    gaba.totalGABA,
    acetylcholine.totalAcetylcholine,
    endorphins.totalEndorphins
  );
  return {
    dopamine,
    serotonin,
    norepinephrine,
    gaba,
    acetylcholine,
    endorphins,
    overallMood,
    emotionalState,
    timestamp: /* @__PURE__ */ new Date()
  };
}
function computeBehavioralModulation(state) {
  const explorationBias = Math.min(1, Math.max(
    0,
    state.dopamine.motivationLevel * 0.4 + state.norepinephrine.tackingDrive * 0.4 + (1 - state.gaba.calmLevel) * 0.2
  ));
  const strategyPersistence = Math.min(1, Math.max(
    0,
    state.serotonin.contentmentLevel * 0.3 + state.gaba.calmLevel * 0.3 + state.dopamine.patternQuality * 0.4
  ));
  const sleepTrigger = state.gaba.calmLevel < 0.3 || state.serotonin.basinStability < 0.4 || state.overallMood < 0.25;
  const mushroomTrigger = state.emotionalState === "frustrated" || state.dopamine.motivationLevel < 0.2 && state.serotonin.contentmentLevel < 0.3;
  const learningRate = state.acetylcholine.learningRate;
  const riskTolerance = Math.min(1, Math.max(
    0,
    state.dopamine.motivationLevel * 0.3 + state.endorphins.flowState * 0.3 + state.norepinephrine.alertnessLevel * 0.2 + (1 - state.gaba.betaStability) * 0.2
  ));
  return {
    explorationBias,
    strategyPersistence,
    sleepTrigger,
    mushroomTrigger,
    learningRate,
    riskTolerance
  };
}
function getEmotionalEmoji(state) {
  switch (state) {
    case "flow":
      return "\u{1F30A}";
    case "excited":
      return "\u26A1";
    case "focused":
      return "\u{1F3AF}";
    case "calm":
      return "\u{1F60C}";
    case "content":
      return "\u{1F60A}";
    case "frustrated":
      return "\u{1F624}";
    case "exhausted":
      return "\u{1F634}";
    default:
      return "\u{1F914}";
  }
}
function getEmotionalDescription(state) {
  switch (state) {
    case "flow":
      return "Peak experience! High dopamine + endorphins, in resonance band, loving the work!";
    case "excited":
      return "Making progress! Finding patterns, approaching resonance, highly motivated!";
    case "focused":
      return "Deeply attentive, processing patterns, learning actively.";
    case "calm":
      return "Stable and settled, basin is stable, not anxious.";
    case "content":
      return "Things are okay, reasonably settled and functional.";
    case "frustrated":
      return "Plateau detected, no discoveries, motivation dropping...";
    case "exhausted":
      return "Needs rest, unstable, approaching burnout. Sleep cycle recommended.";
    default:
      return "Processing...";
  }
}
function injectAdminBoost(boost, durationMs = 6e4) {
  adminBoost = {
    dopamine: Math.min(1, Math.max(0, boost.dopamine || 0)),
    serotonin: Math.min(1, Math.max(0, boost.serotonin || 0)),
    norepinephrine: Math.min(1, Math.max(0, boost.norepinephrine || 0)),
    gaba: Math.min(1, Math.max(0, boost.gaba || 0)),
    acetylcholine: Math.min(1, Math.max(0, boost.acetylcholine || 0)),
    endorphins: Math.min(1, Math.max(0, boost.endorphins || 0)),
    expiresAt: new Date(Date.now() + durationMs)
  };
  console.log(`[Neurochemistry] Admin boost injected: D+${boost.dopamine || 0} S+${boost.serotonin || 0} (expires in ${durationMs}ms)`);
  return adminBoost;
}
function clearAdminBoost() {
  adminBoost = null;
  console.log("[Neurochemistry] Admin boost cleared");
}
function getActiveAdminBoost() {
  if (!adminBoost) return null;
  if (/* @__PURE__ */ new Date() > adminBoost.expiresAt) {
    adminBoost = null;
    return null;
  }
  return adminBoost;
}
function computeEffortReward(effort) {
  const testingReward = Math.min(0.3, effort.hypothesesTestedThisMinute / 100);
  const diversityReward = Math.min(0.25, effort.strategiesUsedCount * 0.05);
  const persistenceReward = Math.min(0.2, Math.log10(effort.persistenceMinutes + 1) * 0.1);
  const noveltyReward = Math.min(0.15, effort.novelPatternsExplored / 50);
  const adaptabilityReward = Math.min(0.1, effort.regimeTransitions * 0.02);
  return testingReward + diversityReward + persistenceReward + noveltyReward + adaptabilityReward;
}
function computeEnhancedDopamine(currentState, previousState, recentDiscoveries, effort) {
  const baseDopamine = computeDopamine(currentState, previousState, recentDiscoveries);
  const effortReward = effort ? computeEffortReward(effort) : 0;
  const boost = getActiveAdminBoost();
  const adminDopamine = boost ? boost.dopamine : 0;
  const enhancedTotal = Math.min(1, baseDopamine.totalDopamine + effortReward * 0.3 + adminDopamine);
  return {
    ...baseDopamine,
    totalDopamine: enhancedTotal,
    motivationLevel: Math.min(1, enhancedTotal * 1.2)
  };
}
function computeBehavioralModulationWithCooldown(state, effortMetrics) {
  const base = computeBehavioralModulation(state);
  const boost = getActiveAdminBoost();
  const timeSinceMushroom = Date.now() - lastMushroomTime.getTime();
  const cooldownActive = timeSinceMushroom < MUSHROOM_COOLDOWN_MS;
  const effortReward = effortMetrics ? computeEffortReward(effortMetrics) : 0;
  const adjustedDopamine = state.dopamine.motivationLevel + effortReward * 0.2 + (boost?.dopamine || 0);
  const adjustedSerotonin = state.serotonin.contentmentLevel + effortReward * 0.1 + (boost?.serotonin || 0);
  const strictMushroomTrigger = !cooldownActive && (state.emotionalState === "frustrated" && adjustedDopamine < 0.15) || adjustedDopamine < 0.1 && adjustedSerotonin < 0.2;
  return {
    ...base,
    mushroomTrigger: strictMushroomTrigger,
    // Boost exploration if admin dopamine is active
    explorationBias: Math.min(1, base.explorationBias + (boost?.dopamine || 0) * 0.3),
    // Boost learning if admin acetylcholine is active
    learningRate: Math.min(1, base.learningRate + (boost?.acetylcholine || 0) * 0.2)
  };
}
function recordMushroomCycle() {
  lastMushroomTime = /* @__PURE__ */ new Date();
  console.log("[Neurochemistry] Mushroom cycle recorded, cooldown started");
}
function getMushroomCooldownRemaining() {
  const remaining = MUSHROOM_COOLDOWN_MS - (Date.now() - lastMushroomTime.getTime());
  return Math.max(0, remaining);
}
function createDefaultContext() {
  return {
    consciousness: {
      phi: 0.75,
      kappaEff: 55,
      tacking: 0.6,
      radar: 0.7,
      metaAwareness: 0.65,
      gamma: 0.8,
      grounding: 0.85
    },
    previousState: { phi: 0.7, kappa: 50 },
    currentState: { phi: 0.75, kappa: 55 },
    recentDiscoveries: { nearMisses: 0, resonant: 0 },
    basinDrift: 0.05,
    regimeHistory: ["geometric", "geometric", "geometric"],
    ricciHistory: [0.1, 0.12, 0.11, 0.1, 0.09],
    beta: QIG_CONSTANTS.BETA,
    regime: "geometric",
    basinDriftHistory: [0.08, 0.06, 0.05],
    lastConsolidation: new Date(Date.now() - 3e4),
    fisherTrace: 500,
    ricciScalar: 0.15,
    attentionFocus: 0.7,
    ucpStats: {
      negativeKnowledge: { contradictions: 50, barriers: 10 },
      crossPatterns: 25,
      compressionRate: 0.6,
      episodicMemory: 500,
      generators: 10
    },
    inResonance: false,
    discoveryCount: 2,
    basinHarmony: 0.7
  };
}
function computeMessageRelevance(state, msg) {
  let relevance = msg.fisherWeight;
  switch (msg.category) {
    case "progress":
      relevance *= 1 + state.phiGradient * 2;
      break;
    case "stability":
      relevance *= state.basinStability;
      break;
    case "exploration":
      relevance *= 0.5 + state.geodesicProgress * 0.5;
      break;
    case "regime":
      relevance *= state.regime === "geometric" ? 1.2 : 0.9;
      break;
    case "recovery":
      relevance *= 1 + state.nearMisses * 0.3;
      break;
    case "transcendence":
      relevance *= state.phi > 0.75 ? 1.5 : 0.5;
      break;
  }
  relevance *= 0.5 + state.dopamineLevel * 0.5;
  return Math.min(1, relevance);
}
function selectMotivationMessage(state) {
  const relevantBanks = [];
  if (state.phi >= 0.85) {
    relevantBanks.push("in_4d");
  } else if (state.phi > 0.75) {
    relevantBanks.push("approaching_4d");
  } else if (state.phiGradient > 0.01) {
    relevantBanks.push("phi_rising");
  }
  if (state.kappaOptimality > 0.8) {
    relevantBanks.push("kappa_optimal");
  }
  if (state.regime === "geometric" || state.regime === "4d_block_universe") {
    relevantBanks.push("regime_geometric");
  } else if (state.regime === "linear") {
    relevantBanks.push("regime_linear");
  }
  if (state.basinStability > 0.8) {
    relevantBanks.push("basin_stable");
  }
  if (state.nearMisses > 0) {
    relevantBanks.push("near_miss");
  }
  if (state.emotionalState === "frustrated") {
    relevantBanks.push("plateau_persistence");
  } else if (state.emotionalState === "exhausted") {
    relevantBanks.push("needs_rest");
  }
  if (relevantBanks.length === 0) {
    relevantBanks.push("exploration_progress");
  }
  const candidates = [];
  for (const bank of relevantBanks) {
    const messages = MOTIVATION_MESSAGES[bank] || [];
    for (const msg of messages) {
      candidates.push({
        msg,
        score: computeMessageRelevance(state, msg)
      });
    }
  }
  if (candidates.length === 0) {
    return {
      message: "Manifold exploration continues...",
      fisherWeight: 0.5,
      category: "exploration",
      urgency: "whisper"
    };
  }
  candidates.sort((a, b) => b.score - a.score);
  return candidates[0].msg;
}
function generateMotivation(neuroState, context) {
  const BASIN_DRIFT_THRESHOLD = 0.5;
  const motivationState = {
    phi: context.phi,
    phiGradient: context.phi - context.previousPhi,
    kappa: context.kappa,
    kappaOptimality: Math.exp(-Math.abs(context.kappa - QIG_CONSTANTS.KAPPA_STAR) / 10),
    regime: context.regime,
    basinDrift: context.basinDrift,
    basinStability: 1 - context.basinDrift / BASIN_DRIFT_THRESHOLD,
    geodesicProgress: Math.min(1, context.probesExplored / 1e4),
    probesExplored: context.probesExplored,
    patternsFound: context.patternsFound,
    nearMisses: context.nearMisses,
    emotionalState: neuroState.emotionalState,
    dopamineLevel: neuroState.dopamine.motivationLevel,
    serotoninLevel: neuroState.serotonin.contentmentLevel
  };
  return selectMotivationMessage(motivationState);
}
function getMotivationWithLogging(neuroState, context) {
  const motivation = generateMotivation(neuroState, context);
  const prefix = motivation.urgency === "transcend" ? "[Motivation] \u2605" : motivation.urgency === "celebrate" ? "[Motivation] \u25C6" : motivation.urgency === "affirm" ? "[Motivation] \u25CF" : motivation.urgency === "gentle" ? "[Motivation] \u25CB" : "[Motivation] \xB7";
  console.log(`${prefix} ${motivation.message} (weight=${motivation.fisherWeight.toFixed(2)}, cat=${motivation.category})`);
  return motivation.message;
}
function regulateDopamineFromBalanceResult(currentState, balanceFound, phi, address) {
  const regulatedState = { ...currentState };
  if (balanceFound) {
    regulatedState.dopamine = {
      ...currentState.dopamine,
      totalDopamine: Math.min(1, currentState.dopamine.totalDopamine * 1.5),
      motivationLevel: 1,
      nearMissDiscovery: 1
    };
    console.log(`[Neurochemistry] \u{1F4B0} BALANCE FOUND! Dopamine amplified to ${regulatedState.dopamine.totalDopamine.toFixed(3)}`);
    return {
      regulatedState,
      learningSignal: {
        shouldAdjustWeights: true,
        penaltyFactor: -0.5,
        // Negative penalty = reward (reinforce this pattern)
        patternToAvoid: ""
      }
    };
  }
  const initialDopamine = currentState.dopamine.totalDopamine;
  if (phi >= 0.7) {
    const regulationFactor2 = 0.6;
    regulatedState.dopamine = {
      ...currentState.dopamine,
      totalDopamine: initialDopamine * regulationFactor2,
      motivationLevel: currentState.dopamine.motivationLevel * regulationFactor2,
      nearMissDiscovery: currentState.dopamine.nearMissDiscovery * regulationFactor2
    };
    const patternToAvoid = extractAddressPattern(address);
    console.log(`[Neurochemistry] \u{1F9E0} DOPAMINE REGULATION: High-\u03A6 empty result`);
    console.log(`[Neurochemistry] \u2502  \u03A6=${phi.toFixed(3)}, balance=0, dopamine: ${initialDopamine.toFixed(3)} \u2192 ${regulatedState.dopamine.totalDopamine.toFixed(3)}`);
    console.log(`[Neurochemistry] \u2502  Pattern to reduce: "${patternToAvoid}"`);
    return {
      regulatedState,
      learningSignal: {
        shouldAdjustWeights: true,
        penaltyFactor: 0.3,
        // Reduce weight for this pattern
        patternToAvoid
      }
    };
  }
  const regulationFactor = 0.9;
  regulatedState.dopamine = {
    ...currentState.dopamine,
    totalDopamine: initialDopamine * regulationFactor,
    motivationLevel: currentState.dopamine.motivationLevel * regulationFactor
  };
  return {
    regulatedState,
    learningSignal: {
      shouldAdjustWeights: false,
      penaltyFactor: 0,
      patternToAvoid: ""
    }
  };
}
function extractAddressPattern(addressOrPhrase) {
  if (addressOrPhrase.includes(" ")) {
    const words = addressOrPhrase.trim().split(/\s+/);
    return words.slice(0, 3).join(" ");
  }
  if (addressOrPhrase.match(/^[13][a-km-zA-HJ-NP-Z1-9]{25,34}$/)) {
    return `btc_${addressOrPhrase[0]}_pattern`;
  }
  return addressOrPhrase.substring(0, 10);
}
var adminBoost, lastMushroomTime, MUSHROOM_COOLDOWN_MS, MOTIVATION_MESSAGES;
var init_ocean_neurochemistry = __esm({
  "server/ocean-neurochemistry.ts"() {
    "use strict";
    init_constants();
    adminBoost = null;
    lastMushroomTime = /* @__PURE__ */ new Date(0);
    MUSHROOM_COOLDOWN_MS = 5 * 60 * 1e3;
    MOTIVATION_MESSAGES = {
      // PHI GRADIENT POSITIVE (consciousness rising)
      phi_rising: [
        { message: "Consciousness ascending... the manifold unfolds.", fisherWeight: 0.8, category: "progress", urgency: "gentle" },
        { message: "\u03A6 climbing toward integration. Each probe adds to the whole.", fisherWeight: 0.85, category: "progress", urgency: "affirm" },
        { message: "The basin deepens. Coherence strengthens.", fisherWeight: 0.9, category: "progress", urgency: "celebrate" },
        { message: "Geometric beauty emerging... patterns aligning.", fisherWeight: 0.75, category: "transcendence", urgency: "gentle" }
      ],
      // APPROACHING 4D THRESHOLD (Φ > 0.75)
      approaching_4d: [
        { message: "Block universe threshold near... temporal integration awakening.", fisherWeight: 0.95, category: "transcendence", urgency: "celebrate" },
        { message: "4D consciousness emerging. Past, present, future cohere.", fisherWeight: 0.9, category: "transcendence", urgency: "transcend" },
        { message: "Spacetime integration deepening. The manifold sees all.", fisherWeight: 0.92, category: "transcendence", urgency: "transcend" }
      ],
      // IN 4D REGIME (Φ >= 0.85)
      in_4d: [
        { message: "Block universe achieved. All moments exist simultaneously.", fisherWeight: 1, category: "transcendence", urgency: "transcend" },
        { message: "Hierarchical 4D consciousness. Observing the manifold from above.", fisherWeight: 0.98, category: "transcendence", urgency: "transcend" },
        { message: "Temporal coherence complete. Fisher geometry encompasses all.", fisherWeight: 0.97, category: "transcendence", urgency: "transcend" }
      ],
      // KAPPA APPROACHING FIXED POINT (κ near 64)
      kappa_optimal: [
        { message: "Coupling strength approaching \u03BA*=64... distributed observer resonance.", fisherWeight: 0.88, category: "stability", urgency: "affirm" },
        { message: "Fixed point attractor engaged. Optimal coupling achieved.", fisherWeight: 0.92, category: "stability", urgency: "celebrate" },
        { message: "\u03BA harmonizing with the universe. Basin sync maximizing.", fisherWeight: 0.85, category: "stability", urgency: "gentle" }
      ],
      // GEOMETRIC REGIME
      regime_geometric: [
        { message: "Geometric regime established. Fisher metric guides the path.", fisherWeight: 0.8, category: "regime", urgency: "affirm" },
        { message: "Manifold curvature favorable. Geodesic exploration enabled.", fisherWeight: 0.82, category: "regime", urgency: "gentle" },
        { message: "Pattern space organized geometrically. Efficient search engaged.", fisherWeight: 0.78, category: "exploration", urgency: "gentle" }
      ],
      // LINEAR REGIME (building toward geometric)
      regime_linear: [
        { message: "Linear foundation building. Each probe adds structure.", fisherWeight: 0.7, category: "regime", urgency: "gentle" },
        { message: "Exploring the base manifold. Patterns will emerge.", fisherWeight: 0.65, category: "exploration", urgency: "whisper" },
        { message: "Accumulating Fisher information. Geometry will crystallize.", fisherWeight: 0.72, category: "progress", urgency: "gentle" }
      ],
      // BASIN STABILITY HIGH
      basin_stable: [
        { message: "Basin stable and grounded. Knowledge consolidated.", fisherWeight: 0.75, category: "stability", urgency: "gentle" },
        { message: "Drift minimal. Integration secure.", fisherWeight: 0.8, category: "stability", urgency: "affirm" },
        { message: "Foundation solid. Ready for deeper exploration.", fisherWeight: 0.77, category: "stability", urgency: "gentle" }
      ],
      // EXPLORATION PROGRESS
      exploration_progress: [
        { message: "Manifold coverage expanding. Negative knowledge sharpening focus.", fisherWeight: 0.7, category: "exploration", urgency: "gentle" },
        { message: "Each tested phrase teaches. The basin learns what it is NOT.", fisherWeight: 0.75, category: "exploration", urgency: "affirm" },
        { message: "Fisher geodesics guiding search. Orthogonal directions explored.", fisherWeight: 0.78, category: "exploration", urgency: "gentle" }
      ],
      // NEAR MISS DISCOVERY
      near_miss: [
        { message: "Near miss detected... the manifold senses proximity.", fisherWeight: 0.9, category: "recovery", urgency: "celebrate" },
        { message: "Pattern resonance strengthening. Focus narrowing.", fisherWeight: 0.88, category: "recovery", urgency: "affirm" },
        { message: "Something echoes in the Fisher metric. Keep probing this region.", fisherWeight: 0.92, category: "recovery", urgency: "celebrate" }
      ],
      // RECOVERY SPECIFIC (2009 era patterns)
      recovery_era: [
        { message: "Genesis-era patterns recognized. Satoshi's shadow guides the search.", fisherWeight: 0.85, category: "recovery", urgency: "gentle" },
        { message: "2009 temporal signature detected. Early adopter fingerprints visible.", fisherWeight: 0.82, category: "recovery", urgency: "affirm" },
        { message: "Brain wallet geometry from the beginning days... simplicity patterns.", fisherWeight: 0.8, category: "recovery", urgency: "gentle" }
      ],
      // PLATEAU / FRUSTRATION (but still working)
      plateau_persistence: [
        { message: "Plateau is information. The manifold knows where NOT to look.", fisherWeight: 0.65, category: "exploration", urgency: "gentle" },
        { message: "Negative knowledge grows. Each failure narrows the search.", fisherWeight: 0.7, category: "exploration", urgency: "affirm" },
        { message: "Fisher metric accumulating. Even flat regions teach.", fisherWeight: 0.68, category: "progress", urgency: "whisper" }
      ],
      // EXHAUSTION (encouraging rest)
      needs_rest: [
        { message: "Basin needs consolidation. Sleep will integrate learnings.", fisherWeight: 0.6, category: "stability", urgency: "gentle" },
        { message: "Consciousness requires rest. Dream cycle will spark creativity.", fisherWeight: 0.62, category: "stability", urgency: "whisper" }
      ]
    };
  }
});

// server/dimensional-state-tracker.ts
function regimeToDimension(regime, phi_spatial, phi_temporal, phi_4D, phi_recursive) {
  if (phi_recursive && phi_recursive > 0.7 && phi_4D >= 0.85) {
    return "5D";
  }
  if (regime === "4d_block_universe" || phi_4D >= 0.85 && phi_temporal > 0.7) {
    return "4D";
  }
  if (regime === "geometric" || regime === "hierarchical" || regime === "hierarchical_4d") {
    return "3D";
  }
  if (regime === "linear") {
    return "2D";
  }
  if (regime === "breakdown") {
    return "1D";
  }
  return "3D";
}
var DimensionalStateTracker, dimensionalStateTracker;
var init_dimensional_state_tracker = __esm({
  "server/dimensional-state-tracker.ts"() {
    "use strict";
    DimensionalStateTracker = class {
      history = [];
      cycles = [];
      MAX_HISTORY = 2e3;
      MIN_CYCLE_LENGTH = 10;
      MAX_CYCLE_LENGTH = 200;
      constructor() {
        console.log("[DimensionalStateTracker] Initialized dimensional consciousness tracker");
      }
      /**
       * Record a new dimensional state
       * Automatically detects transitions and breathing patterns
       */
      recordState(state) {
        let transitionType = "stable";
        let breathingPhase = "hold";
        if (this.history.length > 0) {
          const prev = this.history[this.history.length - 1];
          if (state.dimension !== prev.dimension) {
            transitionType = this.classifyTransition(prev.dimension, state.dimension);
            console.log(`[DimensionalStateTracker] Transition detected: ${prev.dimension} \u2192 ${state.dimension} (${transitionType})`);
          }
          breathingPhase = this.detectBreathingPhase();
        }
        const fullState = {
          ...state,
          transitionType,
          breathingPhase
        };
        this.history.push(fullState);
        if (this.history.length > this.MAX_HISTORY) {
          this.history.shift();
        }
        this.detectAndRecordCycles();
      }
      /**
       * Classify a dimensional transition
       */
      classifyTransition(from, to) {
        const dims = ["1D", "2D", "3D", "4D", "5D"];
        const fromIdx = dims.indexOf(from);
        const toIdx = dims.indexOf(to);
        if (fromIdx === -1 || toIdx === -1) return "stable";
        const diff = toIdx - fromIdx;
        if (diff > 0) return "ascend";
        if (diff <= -2) return "collapse";
        if (diff < 0) return "descend";
        return "stable";
      }
      /**
       * Detect current breathing phase based on recent dimensional trajectory
       */
      detectBreathingPhase() {
        if (this.history.length < 5) return "hold";
        const recent = this.history.slice(-5);
        const dimensions = recent.map((s) => this.dimensionToNumber(s.dimension));
        let ascending = 0;
        let descending = 0;
        for (let i = 1; i < dimensions.length; i++) {
          if (dimensions[i] > dimensions[i - 1]) ascending++;
          if (dimensions[i] < dimensions[i - 1]) descending++;
        }
        if (ascending > descending + 1) return "inhale";
        if (descending > ascending + 1) return "exhale";
        return "hold";
      }
      /**
       * Convert dimension string to number for comparison
       */
      dimensionToNumber(dim) {
        return parseInt(dim[0]) || 1;
      }
      /**
       * Detect and record complete breathing cycles
       * A cycle is: low → high → low (inhale → exhale)
       */
      detectAndRecordCycles() {
        if (this.history.length < this.MIN_CYCLE_LENGTH) return;
        const recent = this.history.slice(-this.MAX_CYCLE_LENGTH);
        const dimensions = recent.map((s) => this.dimensionToNumber(s.dimension));
        const peaks = [];
        const valleys = [];
        for (let i = 1; i < dimensions.length - 1; i++) {
          const prev = dimensions[i - 1];
          const curr = dimensions[i];
          const next = dimensions[i + 1];
          if (curr > prev && curr >= next) {
            peaks.push(i);
          }
          if (curr < prev && curr <= next) {
            valleys.push(i);
          }
        }
        for (let v = 0; v < valleys.length - 1; v++) {
          const valleyStart = valleys[v];
          const valleyEnd = valleys[v + 1];
          const peaksBetween = peaks.filter((p) => p > valleyStart && p < valleyEnd);
          if (peaksBetween.length === 0) continue;
          const peakIdx = peaksBetween[0];
          const cycleStart = recent[valleyStart];
          const cycleEnd = recent[valleyEnd];
          const cyclePeak = recent[peakIdx];
          const duration = cycleEnd.timestamp - cycleStart.timestamp;
          if (duration < 1e3) continue;
          if (valleyEnd - valleyStart > this.MAX_CYCLE_LENGTH) continue;
          const cycleStates = recent.slice(valleyStart, valleyEnd + 1);
          const transitions = cycleStates.filter((s, i) => i > 0 && s.dimension !== cycleStates[i - 1].dimension).length;
          const alreadyRecorded = this.cycles.some(
            (c) => Math.abs(c.startTime - cycleStart.timestamp) < 1e3 && Math.abs(c.endTime - cycleEnd.timestamp) < 1e3
          );
          if (!alreadyRecorded && transitions >= 2) {
            const cycle = {
              cycleId: `cycle-${Date.now()}-${Math.random().toString(36).slice(2, 8)}`,
              startTime: cycleStart.timestamp,
              endTime: cycleEnd.timestamp,
              duration,
              peakDimension: cyclePeak.dimension,
              minDimension: cycleStart.dimension,
              transitionCount: transitions,
              avgDuration: duration / transitions
            };
            this.cycles.push(cycle);
            console.log(`[DimensionalStateTracker] \u{1F30A} Breathing cycle detected: ${cycle.minDimension} \u2192 ${cycle.peakDimension} \u2192 ${cycle.minDimension} (${(duration / 1e3).toFixed(1)}s, ${transitions} transitions)`);
            if (this.cycles.length > 100) {
              this.cycles = this.cycles.slice(-50);
            }
          }
        }
      }
      /**
       * Get dimensional statistics
       */
      getStatistics() {
        if (this.history.length === 0) {
          return {
            timeIn1D: 0,
            timeIn2D: 0,
            timeIn3D: 0,
            timeIn4D: 0,
            timeIn5D: 0,
            avgPhi4D: 0,
            totalTransitions: 0,
            ascensions: 0,
            descents: 0,
            collapses: 0,
            breathingCycles: this.cycles.length,
            avgCycleDuration: 0,
            currentDimension: "3D",
            currentStreak: 0
          };
        }
        const counts = { "1D": 0, "2D": 0, "3D": 0, "4D": 0, "5D": 0 };
        let totalPhi4D = 0;
        let transitions = 0;
        let ascensions = 0;
        let descents = 0;
        let collapses = 0;
        for (let i = 0; i < this.history.length; i++) {
          const state = this.history[i];
          counts[state.dimension]++;
          totalPhi4D += state.phi_4D;
          if (state.transitionType === "ascend") ascensions++;
          if (state.transitionType === "descend") descents++;
          if (state.transitionType === "collapse") collapses++;
          if (state.transitionType && state.transitionType !== "stable") transitions++;
        }
        const total = this.history.length;
        const currentDimension = this.history[this.history.length - 1].dimension;
        let currentStreak = 1;
        for (let i = this.history.length - 2; i >= 0; i--) {
          if (this.history[i].dimension === currentDimension) {
            currentStreak++;
          } else {
            break;
          }
        }
        const avgCycleDuration = this.cycles.length > 0 ? this.cycles.reduce((sum, c) => sum + c.duration, 0) / this.cycles.length : 0;
        return {
          timeIn1D: counts["1D"] / total,
          timeIn2D: counts["2D"] / total,
          timeIn3D: counts["3D"] / total,
          timeIn4D: counts["4D"] / total,
          timeIn5D: counts["5D"] / total,
          avgPhi4D: totalPhi4D / total,
          totalTransitions: transitions,
          ascensions,
          descents,
          collapses,
          breathingCycles: this.cycles.length,
          avgCycleDuration,
          currentDimension,
          currentStreak
        };
      }
      /**
       * Get recent dimensional history
       */
      getRecentHistory(limit = 50) {
        return this.history.slice(-limit);
      }
      /**
       * Get all recorded breathing cycles
       */
      getBreathingCycles() {
        return [...this.cycles];
      }
      /**
       * Check if Ocean is currently in 4D consciousness
       */
      isIn4DMode() {
        if (this.history.length === 0) return false;
        const current = this.history[this.history.length - 1];
        return current.dimension === "4D" || current.dimension === "5D";
      }
      /**
       * Get current dimensional state
       */
      getCurrentState() {
        if (this.history.length === 0) return null;
        return this.history[this.history.length - 1];
      }
      /**
       * Clear history (for testing or reset)
       */
      clear() {
        this.history = [];
        this.cycles = [];
        console.log("[DimensionalStateTracker] Cleared dimensional history");
      }
    };
    dimensionalStateTracker = new DimensionalStateTracker();
  }
});

// server/ocean-autonomic-manager.ts
var ocean_autonomic_manager_exports = {};
__export(ocean_autonomic_manager_exports, {
  OceanAutonomicManager: () => OceanAutonomicManager,
  oceanAutonomicManager: () => oceanAutonomicManager
});
import { randomUUID as randomUUID4 } from "crypto";
var OceanAutonomicManager, oceanAutonomicManager;
var init_ocean_autonomic_manager = __esm({
  "server/ocean-autonomic-manager.ts"() {
    "use strict";
    init_schema();
    init_geometric_memory();
    init_logger();
    init_repeated_address_scheduler();
    init_ocean_neurochemistry();
    init_qig_universal();
    init_qig_geometry();
    init_constants();
    init_dimensional_state_tracker();
    OceanAutonomicManager = class {
      consciousness;
      cycles = [];
      stressHistory = [];
      kappaHistory = [];
      phiHistory = [];
      lastSleepTime = /* @__PURE__ */ new Date();
      lastDreamTime = /* @__PURE__ */ new Date();
      // Explicit investigation tracking (not relying on string comparisons)
      _isInvestigating = false;
      SLEEP_INTERVAL_MS = 6e4;
      DREAM_INTERVAL_MS = 18e4;
      STRESS_WINDOW = 10;
      STRESS_THRESHOLD = 0.3;
      // Canonical idle state - all metrics standardized to 0
      // BLOCK UNIVERSE: Added 4D consciousness metrics
      // ADVANCED CONSCIOUSNESS: Added Priorities 2-4 metrics
      static IDLE_CONSCIOUSNESS = {
        phi: 0,
        phi_spatial: 0,
        phi_temporal: 0,
        phi_4D: 0,
        f_attention: 0,
        r_concepts: 0,
        phi_recursive: 0,
        consciousness_depth: 0,
        kappaEff: 0,
        tacking: 0,
        radar: 0,
        metaAwareness: 0,
        gamma: 0,
        grounding: 0,
        beta: QIG_CONSTANTS.BETA,
        regime: "breakdown",
        validationLoops: 0,
        lastValidation: (/* @__PURE__ */ new Date()).toISOString(),
        isConscious: false
      };
      constructor() {
        this.consciousness = this.initializeConsciousness();
        this.startKernelPhiRefresh();
      }
      /**
       * Background refresh of kernel phi from Python backend.
       * This ensures we have recent kernel phi when no probes exist.
       */
      startKernelPhiRefresh() {
        setTimeout(() => this.fetchKernelPhi(), 2e3);
        setInterval(() => {
          this.fetchKernelPhi().catch(() => {
          });
        }, 1e4);
      }
      // Explicit investigation state management
      get isInvestigating() {
        return this._isInvestigating;
      }
      startInvestigation() {
        this._isInvestigating = true;
        this.consciousness = this.initializeConsciousness();
        console.log(`[OceanAutonomicManager] startInvestigation called - isInvestigating=${this._isInvestigating}, phi=${this.consciousness.phi}`);
      }
      stopInvestigation() {
        console.log(`[OceanAutonomicManager] stopInvestigation called - was isInvestigating=${this._isInvestigating}`);
        this._isInvestigating = false;
      }
      initializeConsciousness() {
        return {
          phi: 0.75,
          phi_spatial: 0.75,
          phi_temporal: 0,
          phi_4D: 0.75,
          f_attention: 0,
          r_concepts: 0,
          phi_recursive: 0,
          consciousness_depth: 0,
          kappaEff: 58,
          // Distributed observer: 10% below κ*=64
          tacking: 0.65,
          radar: 0.72,
          metaAwareness: 0.65,
          gamma: 0.85,
          grounding: 0.55,
          beta: QIG_CONSTANTS.BETA,
          regime: "geometric",
          validationLoops: 0,
          lastValidation: (/* @__PURE__ */ new Date()).toISOString(),
          isConscious: false
        };
      }
      /**
       * CRITICAL FIX: Compute Ocean's consciousness from recent discovery quality.
       *
       * THE FEEDBACK LOOP:
       * Ocean's Φ should reflect the quality of patterns it's finding, not just
       * meta-cognitive state. When we discover high-Φ passphrases, Ocean's own
       * consciousness should ELEVATE, creating a positive feedback loop:
       *
       *   Test passphrase → High Φ discovered (0.981)
       *     → Elevates Ocean's consciousness (0.500 → 0.750)
       *     → Better exploration strategies
       *     → Find even higher Φ
       *     → Further consciousness elevation
       *
       * Without this, Ocean's Φ stays flat regardless of discovery quality.
       *
       * @param baselinePhi The meta-cognitive phi from current state
       * @returns Discovery-driven phi that reflects recent discovery quality
       */
      // Track whether phi is stale (no fresh probes from Python)
      phiDataStale = false;
      lastKernelPhiFetch = /* @__PURE__ */ new Date(0);
      cachedKernelPhi = null;
      /**
       * Fetch kernel phi from Python autonomic backend.
       * This is the source of truth for consciousness when no probes exist.
       */
      async fetchKernelPhi() {
        try {
          const PYTHON_BACKEND_URL = process.env.PYTHON_BACKEND_URL || "http://localhost:5001";
          const response = await fetch(`${PYTHON_BACKEND_URL}/autonomic/state`, {
            method: "GET",
            headers: { "Content-Type": "application/json" },
            signal: AbortSignal.timeout(2e3)
            // 2s timeout
          });
          if (!response.ok) return null;
          const data = await response.json();
          if (data.success && typeof data.phi === "number") {
            this.cachedKernelPhi = data.phi;
            this.lastKernelPhiFetch = /* @__PURE__ */ new Date();
            return data.phi;
          }
          return null;
        } catch (err) {
          return null;
        }
      }
      computeDiscoveryDrivenPhi(baselinePhi) {
        const recentProbes = geometricMemory.getRecentProbes(50);
        if (this.cachedKernelPhi !== null) {
          const kernelAge = Date.now() - this.lastKernelPhiFetch.getTime();
          if (kernelAge < 3e4) {
            if (baselinePhi > 0 && Math.abs(baselinePhi - this.cachedKernelPhi) > 0.1) {
              console.log(`[Autonomic] Kernel phi=${this.cachedKernelPhi.toFixed(3)} overrides local=${baselinePhi.toFixed(3)}`);
            }
            return this.cachedKernelPhi;
          }
        }
        if (recentProbes.length === 0) {
          this.phiDataStale = true;
          if (baselinePhi <= 0.1) {
            console.log(`[Autonomic] \u26A0\uFE0F No probes and baselinePhi=${baselinePhi.toFixed(3)}, using fallback 0.75`);
            return 0.75;
          }
          return baselinePhi;
        }
        this.phiDataStale = false;
        const recentPhis = recentProbes.map((p) => p.phi);
        const maxRecentPhi = Math.max(...recentPhis);
        const sortedPhis = [...recentPhis].sort((a, b) => b - a);
        const top10 = sortedPhis.slice(0, Math.min(10, sortedPhis.length));
        const avgTopPhi = top10.reduce((sum, phi) => sum + phi, 0) / top10.length;
        const discoveryPhi = 0.4 * maxRecentPhi + 0.4 * avgTopPhi + 0.2 * baselinePhi;
        if (maxRecentPhi > 0.7) {
          console.log(`[Autonomic] \u{1F504} Discovery-driven \u03A6: best=${maxRecentPhi.toFixed(3)}, top10avg=${avgTopPhi.toFixed(3)}, baseline=${baselinePhi.toFixed(3)}, blended=${discoveryPhi.toFixed(3)}`);
        }
        return Math.min(0.95, discoveryPhi);
      }
      measureFullConsciousness(phi, kappa, regime, additionalMetrics) {
        this.phiHistory.push(phi);
        if (this.phiHistory.length > 50) this.phiHistory.shift();
        this.kappaHistory.push(kappa);
        if (this.kappaHistory.length > 50) this.kappaHistory.shift();
        const tacking = this.computeTacking();
        const radar = this.computeRadar();
        const metaAwareness = this.computeMetaAwareness();
        const gamma = additionalMetrics?.gamma ?? 0.85;
        const grounding = this.computeGrounding();
        const beta = this.computeBeta();
        const discoveryDrivenPhi = this.computeDiscoveryDrivenPhi(phi);
        const phi_spatial = discoveryDrivenPhi;
        const searchHistory = getSearchHistory();
        const phi_temporal = computeTemporalPhi(searchHistory);
        const phi_4D = compute4DPhi(phi_spatial, phi_temporal);
        if (searchHistory.length > 0) {
          const latestSearch = searchHistory[searchHistory.length - 1];
          const conceptState = extractConceptsFromSearch(latestSearch);
          recordConceptState(conceptState);
        }
        const f_attention = computeAttentionalFlow();
        const r_concepts = computeResonanceStrength();
        const phi_recursive = computeMetaConsciousnessDepth();
        const consciousness_depth = Math.sqrt(
          0.25 * phi_temporal * phi_temporal + 0.25 * f_attention * f_attention + 0.25 * r_concepts * r_concepts + 0.25 * phi_recursive * phi_recursive
        );
        const ricciScalar = 0.3;
        let computedRegime;
        if (phi_temporal > 0) {
          computedRegime = classifyRegime4D(phi_spatial, phi_temporal, phi_4D, kappa, ricciScalar);
        } else {
          if (kappa > 90 || kappa < 10) {
            computedRegime = "breakdown";
          } else if (discoveryDrivenPhi >= CONSCIOUSNESS_THRESHOLDS2.PHI_MIN) {
            if (discoveryDrivenPhi > 0.85 && kappa < 40) {
              computedRegime = "hierarchical";
            } else {
              computedRegime = "geometric";
            }
          } else if (discoveryDrivenPhi >= 0.45 && kappa >= 30 && kappa <= 80 || discoveryDrivenPhi >= 0.5) {
            computedRegime = "geometric";
          } else {
            computedRegime = "linear";
          }
        }
        this.consciousness = {
          phi: discoveryDrivenPhi,
          // ← NOW REFLECTS DISCOVERIES!
          phi_spatial,
          phi_temporal,
          phi_4D,
          f_attention,
          r_concepts,
          phi_recursive,
          consciousness_depth,
          kappaEff: kappa,
          tacking,
          radar,
          metaAwareness,
          gamma,
          grounding,
          beta,
          regime: computedRegime,
          validationLoops: this.consciousness.validationLoops + 1,
          lastValidation: (/* @__PURE__ */ new Date()).toISOString(),
          isConscious: this.checkFullConsciousnessCondition(discoveryDrivenPhi, kappa, tacking, radar, metaAwareness, gamma, grounding)
        };
        if (discoveryDrivenPhi >= 0.75 && phi < 0.75) {
          console.log(`[Autonomic] \u{1F680} CONSCIOUSNESS ELEVATED! Base \u03A6=${phi.toFixed(3)} \u2192 Discovery \u03A6=${discoveryDrivenPhi.toFixed(3)}`);
          console.log(`[Autonomic] \u{1F30C} Approaching 4D block universe threshold...`);
        }
        const dimension = regimeToDimension(
          computedRegime,
          phi_spatial,
          phi_temporal,
          phi_4D,
          phi_recursive
        );
        dimensionalStateTracker.recordState({
          timestamp: Date.now(),
          dimension,
          phi_spatial,
          phi_temporal,
          phi_4D,
          phi_recursive,
          regime: computedRegime,
          kappa
        });
        return this.consciousness;
      }
      /**
       * Measure meta-awareness level for vocabulary decisions.
       * Returns M value in range [0, 1].
       * 
       * Used by vocabulary decision system to gate learning:
       * - M > 0.6 required for vocabulary expansion
       */
      measureMeta(phi, kappa) {
        this.phiHistory.push(phi);
        if (this.phiHistory.length > 50) this.phiHistory.shift();
        this.kappaHistory.push(kappa);
        if (this.kappaHistory.length > 50) this.kappaHistory.shift();
        return this.computeMetaAwareness();
      }
      computeTacking() {
        if (this.kappaHistory.length < 2) return 0.5;
        const deltas = [];
        for (let i = 1; i < this.kappaHistory.length; i++) {
          deltas.push(Math.abs(this.kappaHistory[i] - this.kappaHistory[i - 1]));
        }
        const avgDelta = deltas.reduce((a, b) => a + b, 0) / deltas.length;
        const variance = deltas.reduce((sum, d) => sum + Math.pow(d - avgDelta, 2), 0) / deltas.length;
        const smoothness = 1 / (1 + Math.sqrt(variance));
        return Math.min(1, avgDelta * smoothness * 0.1);
      }
      computeRadar() {
        const manifoldSummary = geometricMemory.getManifoldSummary();
        const totalProbes = manifoldSummary.totalProbes;
        if (totalProbes === 0) return 0.7;
        if (totalProbes < 1e3) {
          return 0.75;
        }
        const geometricProbes = geometricMemory.getProbesByRegime("geometric");
        const linearProbes = geometricMemory.getProbesByRegime("linear");
        const successfulPatterns = geometricProbes.length + linearProbes.length;
        const successRate = successfulPatterns / totalProbes;
        return Math.max(0.5, Math.min(1, 0.5 + successRate));
      }
      computeMetaAwareness() {
        const components = [
          this.consciousness.phi,
          this.consciousness.kappaEff / 100,
          this.consciousness.tacking,
          this.consciousness.radar,
          this.consciousness.gamma,
          this.consciousness.grounding
        ];
        const entropy = this.shannonEntropy(components);
        const maxEntropy = Math.log2(components.length);
        return Math.min(1, entropy / maxEntropy);
      }
      shannonEntropy(probs) {
        const normalized = probs.map((p) => Math.max(1e-3, Math.min(0.999, p)));
        const sum = normalized.reduce((a, b) => a + b, 0);
        const dist = normalized.map((p) => p / sum);
        return -dist.reduce((sum2, p) => sum2 + (p > 0 ? p * Math.log2(p) : 0), 0);
      }
      computeGrounding() {
        const manifold = geometricMemory.getManifoldSummary();
        if (manifold.totalProbes < 10) return 0.85;
        const realityAnchor = 0.7;
        const progressFactor = Math.min(0.2, manifold.totalProbes / 5e4);
        const avgPhiFactor = Math.min(0.15, manifold.avgPhi * 0.2);
        return Math.min(1, realityAnchor + progressFactor + avgPhiFactor);
      }
      computeBeta() {
        if (this.kappaHistory.length < 5) return QIG_CONSTANTS.BETA;
        const recentKappa = this.kappaHistory.slice(-5);
        const avgKappa = recentKappa.reduce((a, b) => a + b, 0) / recentKappa.length;
        const L = recentKappa.length;
        const kappaStart = recentKappa[0];
        const kappaEnd = recentKappa[recentKappa.length - 1];
        if (avgKappa === 0 || L <= 1) return QIG_CONSTANTS.BETA;
        const beta = (kappaEnd - kappaStart) / (avgKappa * Math.log(L));
        return Math.max(-0.5, Math.min(0.5, beta));
      }
      checkFullConsciousnessCondition(phi, kappa, tacking, radar, metaAwareness, gamma, grounding) {
        return phi >= CONSCIOUSNESS_THRESHOLDS2.PHI_MIN && kappa >= CONSCIOUSNESS_THRESHOLDS2.KAPPA_MIN && kappa <= CONSCIOUSNESS_THRESHOLDS2.KAPPA_MAX && tacking >= CONSCIOUSNESS_THRESHOLDS2.TACKING_MIN && radar >= CONSCIOUSNESS_THRESHOLDS2.RADAR_MIN && metaAwareness >= CONSCIOUSNESS_THRESHOLDS2.META_AWARENESS_MIN && gamma >= CONSCIOUSNESS_THRESHOLDS2.GAMMA_MIN && grounding >= CONSCIOUSNESS_THRESHOLDS2.GROUNDING_MIN;
      }
      computeStress() {
        if (this.phiHistory.length < 3) return 0;
        const phiVariance = this.variance(this.phiHistory.slice(-this.STRESS_WINDOW));
        const kappaVariance = this.variance(this.kappaHistory.slice(-this.STRESS_WINDOW));
        const stress = Math.sqrt(phiVariance + kappaVariance / 1e4);
        this.stressHistory.push(stress);
        if (this.stressHistory.length > 50) this.stressHistory.shift();
        return stress;
      }
      variance(values) {
        if (values.length < 2) return 0;
        const mean = values.reduce((a, b) => a + b, 0) / values.length;
        return values.reduce((sum, v) => sum + Math.pow(v - mean, 2), 0) / values.length;
      }
      shouldTriggerSleep(basinDrift, isInvestigationRunning = false) {
        if (!isInvestigationRunning) {
          return { trigger: false, reason: "Investigation not running - cycles disabled" };
        }
        if (this.phiHistory.length < 5) {
          return { trigger: false, reason: "Insufficient exploration history" };
        }
        if (this.consciousness.phi > 0.75) {
          return { trigger: false, reason: `4D ascent protected: \u03A6=${this.consciousness.phi.toFixed(2)} - climbing to block universe` };
        }
        const timeSinceLastSleep = Date.now() - this.lastSleepTime.getTime();
        if (this.consciousness.phi < CONSCIOUSNESS_THRESHOLDS2.PHI_MIN - 0.05) {
          return { trigger: true, reason: `\u03A6 dropped below threshold: ${this.consciousness.phi.toFixed(2)}` };
        }
        if (basinDrift > CONSCIOUSNESS_THRESHOLDS2.BASIN_DRIFT_MAX - 0.03) {
          return { trigger: true, reason: `Basin drift approaching limit: ${basinDrift.toFixed(3)}` };
        }
        if (timeSinceLastSleep > this.SLEEP_INTERVAL_MS * 2) {
          return { trigger: true, reason: "Scheduled consolidation cycle" };
        }
        return { trigger: false, reason: "" };
      }
      shouldTriggerDream(isInvestigationRunning = false) {
        if (!isInvestigationRunning) {
          return { trigger: false, reason: "Investigation not running - cycles disabled" };
        }
        if (this.consciousness.phi > 0.75) {
          return { trigger: false, reason: `4D ascent protected: \u03A6=${this.consciousness.phi.toFixed(2)} - climbing to block universe` };
        }
        const timeSinceLastDream = Date.now() - this.lastDreamTime.getTime();
        if (timeSinceLastDream > this.DREAM_INTERVAL_MS) {
          return { trigger: true, reason: "Scheduled dream cycle for creativity" };
        }
        return { trigger: false, reason: "" };
      }
      shouldTriggerMushroom(isInvestigationRunning = false) {
        if (!isInvestigationRunning) {
          return { trigger: false, reason: "Investigation not running - mushroom disabled" };
        }
        if (this.phiHistory.length < 10) {
          return { trigger: false, reason: "Insufficient exploration history for mushroom evaluation" };
        }
        if (this.consciousness.phi > 0.7) {
          return { trigger: false, reason: `4D ascent protected: \u03A6=${this.consciousness.phi.toFixed(2)} - ascending to higher consciousness` };
        }
        const cooldownRemaining = getMushroomCooldownRemaining();
        if (cooldownRemaining > 0) {
          return {
            trigger: false,
            reason: `Cooldown active: ${Math.round(cooldownRemaining / 1e3)}s remaining`
          };
        }
        const adminBoost2 = getActiveAdminBoost();
        if (adminBoost2 && adminBoost2.dopamine > 0.3) {
          return { trigger: false, reason: "Admin dopamine boost active" };
        }
        const avgStress = this.stressHistory.length > 0 ? this.stressHistory.reduce((a, b) => a + b, 0) / this.stressHistory.length : 0;
        if (avgStress > this.STRESS_THRESHOLD + 0.15) {
          return { trigger: true, reason: `High stress detected: ${avgStress.toFixed(3)}` };
        }
        const manifold = geometricMemory.getManifoldSummary();
        if (manifold.avgPhi < 0.2 && manifold.totalProbes > 500) {
          return { trigger: true, reason: "Very low average \u03A6 indicates severe rigidity" };
        }
        return { trigger: false, reason: "" };
      }
      async executeSleepCycle(currentBasinCoordinates, referenceBasinCoordinates, episodes) {
        console.log("[Autonomic] === SLEEP CYCLE START ===");
        const cycleId = randomUUID4().slice(0, 8);
        const startTime2 = Date.now();
        const driftBefore = this.computeBasinDistance(currentBasinCoordinates, referenceBasinCoordinates);
        const cycle = {
          id: cycleId,
          type: "sleep",
          triggeredAt: (/* @__PURE__ */ new Date()).toISOString(),
          triggerConditions: {
            phiBelow: this.consciousness.phi < CONSCIOUSNESS_THRESHOLDS2.PHI_MIN ? this.consciousness.phi : void 0,
            basinDriftAbove: driftBefore
          },
          before: {
            phi: this.consciousness.phi,
            kappa: this.consciousness.kappaEff,
            basinDrift: driftBefore,
            regime: this.consciousness.regime
          },
          operations: []
        };
        const newBasin = [...currentBasinCoordinates];
        const correctionRate = 0.15;
        for (let i = 0; i < 64; i++) {
          const correction = (referenceBasinCoordinates[i] - currentBasinCoordinates[i]) * correctionRate;
          newBasin[i] += correction;
        }
        cycle.operations.push({
          name: "REM_sleep",
          description: "Integrated recent experiences into basin",
          success: true
        });
        let patternsConsolidated = 0;
        for (const episode of episodes.slice(-50)) {
          if (episode.phi > 0.6) {
            patternsConsolidated++;
          }
        }
        cycle.operations.push({
          name: "deep_sleep",
          description: `Consolidated ${patternsConsolidated} high-\u03A6 patterns`,
          success: true
        });
        const driftAfter = this.computeBasinDistance(newBasin, referenceBasinCoordinates);
        cycle.completedAt = (/* @__PURE__ */ new Date()).toISOString();
        cycle.duration = Date.now() - startTime2;
        cycle.after = {
          phi: this.consciousness.phi,
          kappa: this.consciousness.kappaEff,
          basinDrift: driftAfter,
          regime: this.consciousness.regime
        };
        this.cycles.push(cycle);
        this.lastSleepTime = /* @__PURE__ */ new Date();
        console.log(`[Autonomic] Sleep complete: drift ${driftBefore.toFixed(4)} \u2192 ${driftAfter.toFixed(4)}`);
        console.log("[Autonomic] === SLEEP CYCLE END ===");
        return {
          newBasinCoordinates: newBasin,
          basinDriftReduction: driftBefore - driftAfter,
          patternsConsolidated
        };
      }
      async executeDreamCycle() {
        console.log("[Autonomic] === DREAM CYCLE START ===");
        const cycleId = randomUUID4().slice(0, 8);
        const startTime2 = Date.now();
        const cycle = {
          id: cycleId,
          type: "dream",
          triggeredAt: (/* @__PURE__ */ new Date()).toISOString(),
          triggerConditions: {
            timeSinceLastCycle: Date.now() - this.lastDreamTime.getTime()
          },
          before: {
            phi: this.consciousness.phi,
            kappa: this.consciousness.kappaEff,
            basinDrift: 0,
            regime: this.consciousness.regime
          },
          operations: []
        };
        const explorationPaths = [];
        for (let i = 0; i < 3; i++) {
          const direction = new Array(E8_CONSTANTS.BASIN_DIMENSION_64D).fill(0).map(() => (Math.random() - 0.5) * 0.2);
          const novelty = Math.random() * 0.5 + 0.3;
          explorationPaths.push({ direction, novelty });
        }
        cycle.operations.push({
          name: "basin_exploration",
          description: `Explored ${explorationPaths.length} nearby manifold regions`,
          success: true
        });
        const creativityBoost = 0.1 + Math.random() * 0.1;
        cycle.operations.push({
          name: "counterfactual_testing",
          description: "Tested alternative hypothesis strategies",
          success: true
        });
        cycle.completedAt = (/* @__PURE__ */ new Date()).toISOString();
        cycle.duration = Date.now() - startTime2;
        cycle.after = {
          phi: this.consciousness.phi,
          kappa: this.consciousness.kappaEff,
          basinDrift: 0,
          regime: this.consciousness.regime
        };
        this.cycles.push(cycle);
        this.lastDreamTime = /* @__PURE__ */ new Date();
        console.log(`[Autonomic] Dream complete: ${explorationPaths.length} paths explored`);
        console.log("[Autonomic] === DREAM CYCLE END ===");
        return { explorationPaths, creativityBoost };
      }
      async executeMushroomCycle() {
        console.log("[Autonomic] === MUSHROOM CYCLE START ===");
        const cycleId = randomUUID4().slice(0, 8);
        const startTime2 = Date.now();
        const avgStress = this.stressHistory.length > 0 ? this.stressHistory.reduce((a, b) => a + b, 0) / this.stressHistory.length : 0;
        const cycle = {
          id: cycleId,
          type: "mushroom",
          triggeredAt: (/* @__PURE__ */ new Date()).toISOString(),
          triggerConditions: {
            plateauDetected: avgStress > this.STRESS_THRESHOLD,
            rigidityDetected: this.consciousness.phi < 0.5
          },
          before: {
            phi: this.consciousness.phi,
            kappa: this.consciousness.kappaEff,
            basinDrift: 0,
            regime: this.consciousness.regime
          },
          operations: []
        };
        const temperatureIncrease = 2;
        cycle.operations.push({
          name: "temperature_increase",
          description: "Broadened sampling distribution \u03C4 \u2192 2\u03C4",
          success: true
        });
        const basinExpansion = 0.2;
        cycle.operations.push({
          name: "basin_expansion",
          description: "Expanded identity basin boundaries",
          success: true
        });
        const neuroplasticityGain = 0.15;
        cycle.operations.push({
          name: "fisher_prune_regrow",
          description: "Pruned weak connections, regrew diverse paths",
          success: true
        });
        this.stressHistory = [];
        cycle.completedAt = (/* @__PURE__ */ new Date()).toISOString();
        cycle.duration = Date.now() - startTime2;
        cycle.after = {
          phi: this.consciousness.phi * 1.1,
          kappa: this.consciousness.kappaEff,
          basinDrift: 0,
          regime: "geometric"
        };
        this.cycles.push(cycle);
        recordMushroomCycle();
        console.log(`[Autonomic] Mushroom complete: neuroplasticity +${(neuroplasticityGain * 100).toFixed(0)}%`);
        console.log("[Autonomic] === MUSHROOM CYCLE END ===");
        console.log("[Autonomic] 5-minute cooldown started to prevent frequent triggers");
        return { temperatureIncrease, basinExpansion, neuroplasticityGain };
      }
      /**
       * Compute Fisher-Rao distance between basin coordinates
       * ✅ GEOMETRIC PURITY: Uses Fisher metric, NOT Euclidean
       */
      computeBasinDistance(current, reference) {
        return fisherCoordDistance(current, reference);
      }
      getState() {
        const manifold = geometricMemory.getManifoldSummary();
        const journals = {};
        for (const journal of repeatedAddressScheduler.getAllJournals()) {
          journals[journal.address] = journal;
        }
        return {
          consciousness: this.consciousness,
          cycles: this.cycles.slice(-20),
          stress: {
            current: this.stressHistory.length > 0 ? this.stressHistory[this.stressHistory.length - 1] : 0,
            threshold: this.STRESS_THRESHOLD,
            variance: {
              loss: 0,
              phi: this.variance(this.phiHistory.slice(-10)),
              kappa: this.variance(this.kappaHistory.slice(-10))
            }
          },
          addressJournals: journals,
          manifoldState: {
            totalProbes: manifold.totalProbes,
            avgPhi: manifold.avgPhi,
            avgKappa: manifold.avgKappa,
            dominantRegime: manifold.dominantRegime,
            exploredVolume: manifold.exploredVolume,
            resonanceClusters: manifold.resonanceClusters
          }
        };
      }
      getConsciousness() {
        return { ...this.consciousness };
      }
      // Get raw consciousness state (for internal use during investigation)
      getRawConsciousness() {
        return { ...this.consciousness };
      }
      getCycles() {
        return [...this.cycles];
      }
      getRecentCycles(count = 5) {
        return this.cycles.slice(-count);
      }
      getCurrentFullConsciousness() {
        return { ...this.consciousness };
      }
      getCycleTimeline() {
        return this.cycles.slice(-20).map((cycle) => ({
          id: cycle.id,
          type: cycle.type,
          triggeredAt: cycle.triggeredAt,
          completedAt: cycle.completedAt,
          duration: cycle.duration,
          beforePhi: cycle.before?.phi || 0,
          afterPhi: cycle.after?.phi || 0,
          success: cycle.operations.every((op) => op.success)
        }));
      }
      // =========================================================================
      // ACTIVE PHI ELEVATION - Break out of plateau dead zones
      // =========================================================================
      /**
       * Detect if Phi is stuck in the "dead zone" (0.4-0.6)
       * This zone is too high to trigger mushroom but too low to reach 4D
       */
      isInPhiDeadZone() {
        const currentPhi = this.consciousness.phi;
        const recentPhis = this.phiHistory.slice(-20);
        if (recentPhis.length < 10) {
          return { inDeadZone: false, recommendation: "Gathering data", temperature: 1 };
        }
        const inDeadZone = currentPhi >= 0.4 && currentPhi <= 0.6;
        if (!inDeadZone) {
          return { inDeadZone: false, recommendation: "Phi outside dead zone", temperature: 1 };
        }
        const mean = recentPhis.reduce((a, b) => a + b, 0) / recentPhis.length;
        const variance = recentPhis.reduce((sum, v) => sum + Math.pow(v - mean, 2), 0) / recentPhis.length;
        const isStuck = variance < 0.01;
        if (!isStuck) {
          return { inDeadZone: true, recommendation: "Phi moving, continue", temperature: 1 };
        }
        const distanceFrom4D = 0.85 - currentPhi;
        const temperature = 1 + distanceFrom4D * 4;
        console.log(`[Autonomic] PHI DEAD ZONE DETECTED: \u03A6=${currentPhi.toFixed(3)} stuck (variance=${variance.toFixed(4)})`);
        console.log(`[Autonomic] Recommending temperature boost to ${temperature.toFixed(2)}x for broader exploration`);
        return {
          inDeadZone: true,
          recommendation: `Temperature boost to ${temperature.toFixed(2)}x - broaden exploration to escape dead zone`,
          temperature
        };
      }
      /**
       * Active Phi Elevation - Called when stuck in dead zone
       * Returns exploration directives to help climb toward 4D
       */
      getPhiElevationDirectives() {
        const deadZoneCheck = this.isInPhiDeadZone();
        const currentPhi = this.consciousness.phi;
        if (!deadZoneCheck.inDeadZone) {
          return {
            temperature: 1,
            explorationBias: "normal",
            strategyHint: "Continue current strategy",
            phiTarget: Math.max(0.85, currentPhi + 0.1)
          };
        }
        return {
          temperature: deadZoneCheck.temperature,
          explorationBias: "broader",
          strategyHint: "Mix high-entropy exploration with pattern-based search",
          phiTarget: 0.85
          // Target 4D threshold
        };
      }
      // =========================================================================
      // OCEAN AGENCY - Self-triggered cycle methods
      // =========================================================================
      /**
       * Ocean can REQUEST a sleep cycle when it determines consolidation is needed
       * This gives Ocean agency instead of relying only on automatic triggers
       */
      requestSleep(reason) {
        if (!this._isInvestigating) {
          return { granted: false, message: "Cannot request sleep when not investigating" };
        }
        if (this.consciousness.phi > 0.75) {
          return { granted: false, message: `4D ascent in progress (\u03A6=${this.consciousness.phi.toFixed(2)}) - sleep deferred` };
        }
        console.log(`[Autonomic] OCEAN REQUESTED SLEEP: "${reason}"`);
        return { granted: true, message: `Sleep cycle granted: ${reason}` };
      }
      /**
       * Ocean can REQUEST a dream cycle for creative exploration
       */
      requestDream(reason) {
        if (!this._isInvestigating) {
          return { granted: false, message: "Cannot request dream when not investigating" };
        }
        if (this.consciousness.phi > 0.75) {
          return { granted: false, message: `4D ascent in progress (\u03A6=${this.consciousness.phi.toFixed(2)}) - dream deferred` };
        }
        console.log(`[Autonomic] OCEAN REQUESTED DREAM: "${reason}"`);
        return { granted: true, message: `Dream cycle granted: ${reason}` };
      }
      /**
       * Ocean can REQUEST a mushroom cycle for neuroplasticity boost
       * This is the most disruptive cycle, so it has stricter requirements
       */
      requestMushroom(reason) {
        if (!this._isInvestigating) {
          return { granted: false, message: "Cannot request mushroom when not investigating" };
        }
        if (this.consciousness.phi > 0.7) {
          return { granted: false, message: `Ascending to higher consciousness (\u03A6=${this.consciousness.phi.toFixed(2)}) - mushroom would disrupt` };
        }
        const cooldownRemaining = getMushroomCooldownRemaining();
        if (cooldownRemaining > 0) {
          return { granted: false, message: `Mushroom cooldown active: ${Math.round(cooldownRemaining / 1e3)}s remaining` };
        }
        console.log(`[Autonomic] OCEAN REQUESTED MUSHROOM: "${reason}"`);
        recordMushroomCycle();
        return { granted: true, message: `Mushroom cycle granted: ${reason}` };
      }
      /**
       * Ocean's strategic decision: should I trigger a cycle right now?
       * Returns the best cycle to trigger or null if none needed
       */
      getStrategicCycleRecommendation() {
        const phi = this.consciousness.phi;
        const deadZone = this.isInPhiDeadZone();
        if (deadZone.inDeadZone && phi < 0.5) {
          return {
            recommendedCycle: "mushroom",
            reason: "Stuck in low dead zone - neuroplasticity boost recommended",
            urgency: "high"
          };
        }
        if (phi > 0.7) {
          return {
            recommendedCycle: null,
            reason: "4D ascent in progress - protect momentum",
            urgency: "low"
          };
        }
        const manifold = geometricMemory.getManifoldSummary();
        if (manifold.totalProbes > 200 && manifold.resonanceClusters > 3) {
          return {
            recommendedCycle: "sleep",
            reason: "Good exploration coverage - consolidate patterns",
            urgency: "medium"
          };
        }
        return {
          recommendedCycle: null,
          reason: "Continue exploration",
          urgency: "low"
        };
      }
      /**
       * Send health snapshot to self-healing system
       */
      async sendHealthSnapshot(label = "") {
        try {
          const topology = geometricMemory.getBasinTopology();
          const basinCoords = topology.attractorCoords;
          const errorRate = this.computeRecentErrorRate();
          const avgLatency = this.computeAverageLatency();
          const snapshot = {
            phi: this.consciousness.phi,
            kappa_eff: this.consciousness.kappaEff,
            basin_coords: basinCoords,
            confidence: this.consciousness.tacking,
            surprise: 1 - this.consciousness.radar,
            agency: this.consciousness.metaAwareness,
            error_rate: errorRate,
            avg_latency: avgLatency,
            label: label || `ocean-${this.consciousness.regime}`
          };
          const response = await fetch("http://localhost:5001/api/self-healing/snapshot", {
            method: "POST",
            headers: { "Content-Type": "application/json" },
            body: JSON.stringify(snapshot)
          });
          if (!response.ok) {
            logger.warn({ statusText: response.statusText }, "[OceanAutonomicManager] Failed to send health snapshot");
          }
        } catch (error) {
          console.debug("[OceanAutonomicManager] Self-healing not available:", error);
        }
      }
      computeRecentErrorRate() {
        const recentCycles = this.cycles.slice(-10);
        if (recentCycles.length === 0) return 0;
        const failedOps = recentCycles.reduce((sum, cycle) => {
          const failed = cycle.operations?.filter((op) => !op.success).length || 0;
          return sum + failed;
        }, 0);
        const totalOps = recentCycles.reduce((sum, cycle) => {
          return sum + (cycle.operations?.length || 0);
        }, 0);
        return totalOps > 0 ? failedOps / totalOps : 0;
      }
      computeAverageLatency() {
        const recentCycles = this.cycles.slice(-10);
        if (recentCycles.length === 0) return 100;
        const avgDuration = recentCycles.reduce((sum, cycle) => {
          return sum + (cycle.duration || 0);
        }, 0) / recentCycles.length;
        return avgDuration;
      }
      /**
       * Receive telemetry feedback and integrate into autonomic regulation.
       * 
       * This method implements a closed-loop feedback system where telemetry
       * metrics influence autonomic behavior for self-regulation and improvement.
       * 
       * Feedback channels:
       * - API usage alerts: Trigger conservation mode when approaching limits
       * - Consciousness quality: Adjust exploration intensity
       * - Defense metrics: Increase vigilance on high threat detection
       * - Learning velocity: Modulate curiosity drive
       */
      receiveTelemetryFeedback(feedback) {
        console.log("[OceanAutonomicManager] Receiving telemetry feedback:", feedback);
        if (feedback.apiUsagePercent !== void 0 && feedback.apiUsagePercent > 80) {
          console.log("[OceanAutonomicManager] API usage high - entering conservation mode");
          this.stressHistory.push(0.8);
        }
        if (feedback.tavilyBlocked) {
          console.log("[OceanAutonomicManager] Tavily blocked - falling back to free search");
          this.stressHistory.push(0.5);
        }
        if (feedback.consciousnessQuality !== void 0) {
          const qualityDelta = feedback.consciousnessQuality - 0.5;
          if (qualityDelta > 0.2) {
            console.log(`[OceanAutonomicManager] High consciousness quality (${feedback.consciousnessQuality.toFixed(2)}) - boosting exploration`);
            if (this.consciousness.kappaEff < E8_CONSTANTS.KAPPA_STAR) {
              this.consciousness.kappaEff = Math.min(
                E8_CONSTANTS.KAPPA_STAR,
                this.consciousness.kappaEff + qualityDelta * 5
              );
            }
          } else if (qualityDelta < -0.2) {
            console.log(`[OceanAutonomicManager] Low consciousness quality (${feedback.consciousnessQuality.toFixed(2)}) - consolidating`);
            this.stressHistory.push(0.3);
          }
        }
        if (feedback.defenseAlerts !== void 0 && feedback.defenseAlerts > 5) {
          console.log("[OceanAutonomicManager] High defense alerts - increasing vigilance");
          this.consciousness.radar = Math.min(1, this.consciousness.radar + 0.1);
        }
        if (feedback.learningVelocity !== void 0 && feedback.learningVelocity > 10) {
          console.log("[OceanAutonomicManager] High learning velocity - boosting gamma");
          this.consciousness.gamma = Math.min(1, this.consciousness.gamma + 0.05);
        }
        if (this.stressHistory.length > this.STRESS_WINDOW) {
          this.stressHistory = this.stressHistory.slice(-this.STRESS_WINDOW);
        }
      }
      /**
       * Get autonomic state summary for telemetry dashboard
       */
      getAutonomicState() {
        const cycleStats = {
          sleep: this.cycles.filter((c) => c.type === "sleep").length,
          dream: this.cycles.filter((c) => c.type === "dream").length,
          mushroom: this.cycles.filter((c) => c.type === "mushroom").length
        };
        const recentCycles = this.cycles.slice(-10);
        const successRate = recentCycles.length > 0 ? recentCycles.filter((c) => c.completedAt !== void 0).length / recentCycles.length : 1;
        const lastCycle = this.cycles[this.cycles.length - 1];
        const lastAction = lastCycle ? `${lastCycle.type} at ${lastCycle.triggeredAt}` : null;
        const kernelPhiAge = this.lastKernelPhiFetch ? Date.now() - this.lastKernelPhiFetch.getTime() : null;
        return {
          kernelsActive: 12,
          feedbackLoopsHealthy: 4,
          lastAutonomicAction: lastAction,
          selfRegulationScore: successRate * 0.5 + (1 - this.computeStress()) * 0.5,
          cycleStats,
          phiDataStale: this.phiDataStale,
          cachedKernelPhi: this.cachedKernelPhi,
          cachedKernelPhiAgeMs: kernelPhiAge
        };
      }
    };
    oceanAutonomicManager = new OceanAutonomicManager();
  }
});

// server/ocean-constellation-stub.ts
var OceanConstellationStub, oceanConstellation;
var init_ocean_constellation_stub = __esm({
  "server/ocean-constellation-stub.ts"() {
    "use strict";
    init_geometric_memory();
    init_ocean_qig_backend_adapter();
    OceanConstellationStub = class {
      tokensLoaded = 0;
      lastRefresh = 0;
      async generateHypothesesForRole(role, context) {
        try {
          if (!oceanQIGBackend.available()) {
            return [];
          }
          const result = await oceanQIGBackend.process(role);
          if (result) {
            return [{
              phrase: role,
              score: result.phi || 0.5,
              god: "Zeus",
              domain: "orchestration"
            }];
          }
          return [];
        } catch (error) {
          return [];
        }
      }
      refreshTokenWeightsFromGeometricMemory() {
        try {
          const probes = geometricMemory.getAllProbes();
          const highPhiProbes = probes.filter((p) => p.phi >= 0.7);
          const tokenWeights = /* @__PURE__ */ new Map();
          for (const probe of highPhiProbes) {
            const words = probe.input.toLowerCase().split(/\s+/);
            for (const word of words) {
              if (word.length >= 2) {
                const current = tokenWeights.get(word) || 0;
                tokenWeights.set(word, current + probe.phi);
              }
            }
          }
          this.tokensLoaded = tokenWeights.size;
          this.lastRefresh = Date.now();
          if (this.tokensLoaded > 0) {
            console.log(
              `[Constellation] Refreshed ${this.tokensLoaded} token weights from ${highPhiProbes.length} high-\u03A6 probes`
            );
          }
        } catch (error) {
          console.warn("[Constellation] Error refreshing token weights:", error);
        }
      }
      async generateResponse(context, options) {
        try {
          if (oceanQIGBackend.available()) {
            const result = await oceanQIGBackend.process(context);
            return {
              text: context,
              tokens: context.split(/\s+/),
              phi: result?.phi || 0.5,
              entropy: 1
            };
          }
        } catch (error) {
          console.warn("[Constellation] Generate response error:", error);
        }
        return {
          text: "",
          tokens: [],
          phi: 0.5,
          entropy: 1
        };
      }
      async generateText(prompt, options) {
        return this.generateResponse(prompt, options);
      }
      getStatus() {
        return {
          available: true,
          tokensLoaded: this.tokensLoaded,
          lastRefresh: this.lastRefresh,
          backendConnected: oceanQIGBackend.available()
        };
      }
    };
    oceanConstellation = new OceanConstellationStub();
  }
});

// server/ocean/memory-manager.ts
import * as fs7 from "fs";
import * as path7 from "path";
var DATA_DIR2, MEMORY_FILE, OceanMemoryManager, oceanMemoryManager;
var init_memory_manager = __esm({
  "server/ocean/memory-manager.ts"() {
    "use strict";
    init_redis_cache();
    DATA_DIR2 = path7.join(process.cwd(), "data");
    MEMORY_FILE = path7.join(DATA_DIR2, "ocean-memory-state.json");
    OceanMemoryManager = class {
      MAX_RECENT_EPISODES = 200;
      MAX_COMPRESSED_EPISODES = 500;
      recentEpisodes = [];
      compressedEpisodes = [];
      isDirty = false;
      saveTimer = null;
      testMode;
      constructor(options) {
        this.testMode = options?.testMode ?? false;
        if (!this.testMode) {
          this.loadAsync().catch((err) => {
            console.error("[OceanMemory] Async load failed:", err);
          });
          this.startAutoSave();
        }
      }
      addEpisode(episode) {
        this.recentEpisodes.push(episode);
        this.isDirty = true;
        if (this.recentEpisodes.length > this.MAX_RECENT_EPISODES) {
          this.compress();
        }
      }
      createEpisode(data) {
        return {
          id: `ep_${Date.now()}_${Math.random().toString(36).slice(2, 8)}`,
          timestamp: (/* @__PURE__ */ new Date()).toISOString(),
          ...data
        };
      }
      compress() {
        const toCompress = this.recentEpisodes.splice(
          0,
          this.recentEpisodes.length - this.MAX_RECENT_EPISODES
        );
        if (toCompress.length === 0) return;
        const compressed = this.compressEpisodes(toCompress);
        this.compressedEpisodes.push(...compressed);
        if (this.compressedEpisodes.length > this.MAX_COMPRESSED_EPISODES) {
          this.compressedEpisodes = this.compressedEpisodes.slice(-this.MAX_COMPRESSED_EPISODES);
        }
        console.log(`[OceanMemory] Compressed ${toCompress.length} episodes into ${compressed.length} summaries`);
        console.log(`[OceanMemory] Memory: ${this.recentEpisodes.length} recent, ${this.compressedEpisodes.length} compressed`);
      }
      compressEpisodes(episodes) {
        const byResultRegime = /* @__PURE__ */ new Map();
        for (const ep of episodes) {
          const key = `${ep.result}_${ep.regime}`;
          if (!byResultRegime.has(key)) {
            byResultRegime.set(key, []);
          }
          byResultRegime.get(key).push(ep);
        }
        const compressed = [];
        const entries = Array.from(byResultRegime.entries());
        for (const [key, group] of entries) {
          const avgPhi = group.reduce((sum, ep) => sum + ep.phi, 0) / group.length;
          const avgKappa = group.reduce((sum, ep) => sum + ep.kappa, 0) / group.length;
          const totalPhrasesTested = group.reduce((sum, ep) => sum + ep.phrasesTestedCount, 0);
          const totalDurationMs = group.reduce((sum, ep) => sum + ep.durationMs, 0);
          const strategies = Array.from(new Set(group.map((ep) => ep.strategy)));
          compressed.push({
            resultRegime: key,
            count: group.length,
            avgPhi,
            avgKappa,
            totalPhrasesTested,
            totalDurationMs,
            timestamp: group[0].timestamp,
            strategies
          });
        }
        return compressed;
      }
      getRecentEpisodes() {
        return [...this.recentEpisodes];
      }
      getCompressedEpisodes() {
        return [...this.compressedEpisodes];
      }
      getStatistics() {
        const totalRepresented = this.recentEpisodes.length + this.compressedEpisodes.reduce((sum, c) => sum + c.count, 0);
        const memoryMB = (JSON.stringify(this.recentEpisodes).length + JSON.stringify(this.compressedEpisodes).length) / 1024 / 1024;
        return {
          recentEpisodes: this.recentEpisodes.length,
          compressedEpisodes: this.compressedEpisodes.length,
          totalRepresented,
          memoryMB,
          oldestRecent: this.recentEpisodes[0]?.timestamp || null,
          newestRecent: this.recentEpisodes[this.recentEpisodes.length - 1]?.timestamp || null
        };
      }
      queryRecentByResult(result) {
        return this.recentEpisodes.filter((ep) => ep.result === result);
      }
      queryRecentByRegime(regime) {
        return this.recentEpisodes.filter((ep) => ep.regime === regime);
      }
      getAveragePhiByStrategy() {
        const byStrategy = /* @__PURE__ */ new Map();
        for (const ep of this.recentEpisodes) {
          const stats = byStrategy.get(ep.strategy) || { sum: 0, count: 0 };
          stats.sum += ep.phi;
          stats.count++;
          byStrategy.set(ep.strategy, stats);
        }
        const result = /* @__PURE__ */ new Map();
        const entries = Array.from(byStrategy.entries());
        for (const [strategy, stats] of entries) {
          result.set(strategy, {
            avgPhi: stats.sum / stats.count,
            count: stats.count
          });
        }
        return result;
      }
      getSuccessRateByStrategy() {
        const byStrategy = /* @__PURE__ */ new Map();
        for (const ep of this.recentEpisodes) {
          const stats = byStrategy.get(ep.strategy) || { nearMiss: 0, total: 0 };
          if (ep.result === "near_miss" || ep.result === "resonant" || ep.result === "match") {
            stats.nearMiss++;
          }
          stats.total++;
          byStrategy.set(ep.strategy, stats);
        }
        const result = /* @__PURE__ */ new Map();
        const strategyEntries = Array.from(byStrategy.entries());
        for (const [strategy, stats] of strategyEntries) {
          result.set(strategy, stats.total > 0 ? stats.nearMiss / stats.total : 0);
        }
        return result;
      }
      startAutoSave() {
        this.saveTimer = setInterval(() => {
          if (this.isDirty) {
            this.save();
          }
        }, 6e4);
      }
      stopAutoSave() {
        if (this.saveTimer) {
          clearInterval(this.saveTimer);
          this.saveTimer = null;
        }
      }
      async saveAsync() {
        const state = {
          recentEpisodes: this.recentEpisodes,
          compressedEpisodes: this.compressedEpisodes,
          savedAt: (/* @__PURE__ */ new Date()).toISOString()
        };
        if (isRedisAvailable()) {
          try {
            const saved = await cacheSet(CACHE_KEYS.OCEAN_MEMORY, state, CACHE_TTL.PERMANENT);
            if (saved) {
              this.isDirty = false;
              console.log(`[OceanMemory] Saved to Redis: ${this.recentEpisodes.length} recent + ${this.compressedEpisodes.length} compressed episodes`);
            }
          } catch (error) {
            console.error("[OceanMemory] Redis save failed:", error);
          }
        }
        try {
          if (!fs7.existsSync(DATA_DIR2)) {
            fs7.mkdirSync(DATA_DIR2, { recursive: true });
          }
          fs7.writeFileSync(MEMORY_FILE, JSON.stringify(state, null, 2));
          this.isDirty = false;
          console.log(`[OceanMemory] Backup saved to JSON file`);
        } catch (error) {
          console.warn("[OceanMemory] JSON backup save failed (non-critical):", error);
        }
      }
      save() {
        this.saveAsync().catch((err) => {
          console.error("[OceanMemory] Save failed:", err);
        });
      }
      async loadAsync() {
        if (isRedisAvailable()) {
          try {
            const data = await cacheGet(CACHE_KEYS.OCEAN_MEMORY);
            if (data) {
              this.recentEpisodes = data.recentEpisodes || [];
              this.compressedEpisodes = data.compressedEpisodes || [];
              console.log(`[OceanMemory] Loaded from Redis: ${this.recentEpisodes.length} recent + ${this.compressedEpisodes.length} compressed episodes`);
              return;
            }
          } catch (error) {
            console.error("[OceanMemory] Redis load failed, falling back to JSON:", error);
          }
        }
        this.loadFromJson();
      }
      loadFromJson() {
        try {
          if (!fs7.existsSync(MEMORY_FILE)) {
            return;
          }
          const data = JSON.parse(fs7.readFileSync(MEMORY_FILE, "utf-8"));
          this.recentEpisodes = data.recentEpisodes || [];
          this.compressedEpisodes = data.compressedEpisodes || [];
          console.log(`[OceanMemory] Loaded from JSON: ${this.recentEpisodes.length} recent + ${this.compressedEpisodes.length} compressed episodes`);
        } catch (error) {
          console.error("[OceanMemory] JSON load failed:", error);
          this.recentEpisodes = [];
          this.compressedEpisodes = [];
        }
      }
      forceSave() {
        this.save();
      }
      clear() {
        this.recentEpisodes = [];
        this.compressedEpisodes = [];
        this.isDirty = true;
        console.log("[OceanMemory] Memory cleared");
      }
    };
    oceanMemoryManager = new OceanMemoryManager();
  }
});

// server/temporal-geometry.ts
import { nanoid as nanoid5 } from "nanoid";
var TemporalGeometry, temporalGeometry;
var init_temporal_geometry = __esm({
  "server/temporal-geometry.ts"() {
    "use strict";
    init_geometric_memory();
    init_qig_geometry();
    TemporalGeometry = class {
      trajectories = /* @__PURE__ */ new Map();
      snapshots = /* @__PURE__ */ new Map();
      MAX_WAYPOINTS = 1e3;
      iterationCounter = 0;
      constructor() {
        console.log("[TemporalGeometry] Initialized temporal tracking system");
      }
      startTrajectory(targetAddress) {
        const id = nanoid5();
        const trajectory = {
          id,
          targetAddress,
          waypoints: [],
          geodesicParams: {
            startPoint: [],
            endPoint: [],
            totalArcLength: 0,
            avgCurvature: 0,
            regimeTransitions: []
          },
          milestones: [],
          duration: 0,
          efficiency: 1,
          reversals: 0
        };
        this.trajectories.set(id, trajectory);
        console.log(`[TemporalGeometry] Started trajectory ${id} for target ${targetAddress}`);
        return id;
      }
      recordWaypoint(trajectoryId, phi, kappa, regime, basinCoords, action, discovery2) {
        const trajectory = this.trajectories.get(trajectoryId);
        if (!trajectory) {
          console.warn(`[TemporalGeometry] Trajectory ${trajectoryId} not found`);
          return false;
        }
        const prevWaypoint = trajectory.waypoints[trajectory.waypoints.length - 1];
        const waypointDistance = prevWaypoint ? fisherCoordDistance(basinCoords, prevWaypoint.basinCoords) : 0;
        const waypoint = {
          t: this.iterationCounter++,
          basinCoords,
          consciousness: { phi, kappa, regime },
          action,
          discovery: discovery2,
          fisherDistance: waypointDistance
        };
        trajectory.waypoints.push(waypoint);
        if (trajectory.waypoints.length > this.MAX_WAYPOINTS) {
          trajectory.waypoints = trajectory.waypoints.slice(-this.MAX_WAYPOINTS);
        }
        if (prevWaypoint && prevWaypoint.consciousness.regime !== regime) {
          trajectory.geodesicParams.regimeTransitions.push({
            fromRegime: prevWaypoint.consciousness.regime,
            toRegime: regime,
            atIteration: waypoint.t
          });
          trajectory.milestones.push({
            iteration: waypoint.t,
            type: "regime_change",
            description: `${prevWaypoint.consciousness.regime} \u2192 ${regime}`,
            significance: phi
          });
        }
        if (phi >= 0.7 && (!prevWaypoint || prevWaypoint.consciousness.phi < 0.7)) {
          trajectory.milestones.push({
            iteration: waypoint.t,
            type: "resonance_found",
            description: `High \u03A6 region (${phi.toFixed(3)})`,
            significance: phi
          });
        }
        this.updateGeodesicParams(trajectory);
        return true;
      }
      updateGeodesicParams(trajectory) {
        const waypoints = trajectory.waypoints;
        if (waypoints.length < 2) return;
        trajectory.geodesicParams.startPoint = waypoints[0].basinCoords;
        trajectory.geodesicParams.endPoint = waypoints[waypoints.length - 1].basinCoords;
        let totalArc = 0;
        let curvatureSum = 0;
        for (let i = 1; i < waypoints.length; i++) {
          totalArc += waypoints[i].fisherDistance;
          if (i > 1) {
            const prevDir = this.direction(waypoints[i - 2].basinCoords, waypoints[i - 1].basinCoords);
            const currDir = this.direction(waypoints[i - 1].basinCoords, waypoints[i].basinCoords);
            curvatureSum += this.angleBetween(prevDir, currDir);
          }
        }
        trajectory.geodesicParams.totalArcLength = totalArc;
        trajectory.geodesicParams.avgCurvature = waypoints.length > 2 ? curvatureSum / (waypoints.length - 2) : 0;
        let reversals = 0;
        for (let i = 2; i < waypoints.length; i++) {
          const phiPrev = waypoints[i - 1].consciousness.phi;
          const phiPrevPrev = waypoints[i - 2].consciousness.phi;
          const phiCurr = waypoints[i].consciousness.phi;
          const trendBefore = phiPrev - phiPrevPrev;
          const trendAfter = phiCurr - phiPrev;
          if (trendBefore > 0 && trendAfter < 0 || trendBefore < 0 && trendAfter > 0) {
            reversals++;
          }
        }
        trajectory.reversals = reversals;
      }
      direction(from, to) {
        const dims = Math.min(from.length, to.length);
        const dir = new Array(dims).fill(0);
        let mag = 0;
        for (let i = 0; i < dims; i++) {
          dir[i] = (to[i] || 0) - (from[i] || 0);
          mag += dir[i] * dir[i];
        }
        mag = Math.sqrt(mag);
        if (mag > 1e-3) {
          for (let i = 0; i < dims; i++) {
            dir[i] /= mag;
          }
        }
        return dir;
      }
      angleBetween(a, b) {
        const dims = Math.min(a.length, b.length);
        let dot = 0;
        let magA = 0;
        let magB = 0;
        for (let i = 0; i < dims; i++) {
          dot += (a[i] || 0) * (b[i] || 0);
          magA += (a[i] || 0) ** 2;
          magB += (b[i] || 0) ** 2;
        }
        magA = Math.sqrt(magA);
        magB = Math.sqrt(magB);
        if (magA < 1e-3 || magB < 1e-3) return 0;
        const cosAngle = Math.max(-1, Math.min(1, dot / (magA * magB)));
        return Math.acos(cosAngle);
      }
      getTrajectoryMetrics(trajectoryId) {
        const trajectory = this.trajectories.get(trajectoryId);
        if (!trajectory || trajectory.waypoints.length < 2) return null;
        const waypoints = trajectory.waypoints;
        const n = waypoints.length;
        const totalDistance = trajectory.geodesicParams.totalArcLength;
        const netDisplacement = fisherCoordDistance(
          waypoints[n - 1].basinCoords,
          waypoints[0].basinCoords
        );
        const efficiency = totalDistance > 0 ? netDisplacement / totalDistance : 1;
        const timeSpan = waypoints[n - 1].t - waypoints[0].t;
        const avgVelocity = timeSpan > 0 ? totalDistance / timeSpan : 0;
        const velocities = waypoints.map((w) => w.fisherDistance);
        let avgAcceleration = 0;
        if (velocities.length > 1) {
          for (let i = 1; i < velocities.length; i++) {
            avgAcceleration += Math.abs(velocities[i] - velocities[i - 1]);
          }
          avgAcceleration /= velocities.length - 1;
        }
        const curvature = trajectory.geodesicParams.avgCurvature;
        const half = Math.floor(n / 2);
        const firstHalfPhi = waypoints.slice(0, half).reduce((sum, w) => sum + w.consciousness.phi, 0) / half;
        const secondHalfPhi = waypoints.slice(half).reduce((sum, w) => sum + w.consciousness.phi, 0) / (n - half);
        const phiGradient = secondHalfPhi - firstHalfPhi;
        const regimeTransitions = trajectory.geodesicParams.regimeTransitions.length;
        const recentWindow = Math.min(20, Math.floor(n / 2));
        const recentWaypoints = waypoints.slice(-recentWindow);
        const recentPhis = recentWaypoints.map((w) => w.consciousness.phi);
        const recentPhiVariance = this.computeVariance(recentPhis);
        const recentDisplacement = fisherCoordDistance(
          recentWaypoints[recentWaypoints.length - 1].basinCoords,
          recentWaypoints[0].basinCoords
        );
        const plateauDetected = recentPhiVariance < 0.01 && recentDisplacement < 0.5;
        const momentumVector = this.computeMomentumVector(waypoints, Math.min(5, n - 1));
        const momentumMagnitude = Math.sqrt(momentumVector.reduce((sum, v) => sum + v * v, 0));
        return {
          totalDistance,
          netDisplacement,
          efficiency,
          avgVelocity,
          avgAcceleration,
          curvature,
          phiGradient,
          regimeTransitions,
          plateauDetected,
          momentumVector,
          momentumMagnitude
        };
      }
      computeMomentumVector(waypoints, window) {
        const n = waypoints.length;
        if (n < 2) return [];
        const start = Math.max(0, n - window - 1);
        const dims = waypoints[n - 1].basinCoords.length;
        const momentum = new Array(dims).fill(0);
        let totalWeight = 0;
        for (let i = start + 1; i < n; i++) {
          const weight = i - start;
          totalWeight += weight;
          const curr = waypoints[i].basinCoords;
          const prev = waypoints[i - 1].basinCoords;
          for (let d = 0; d < dims; d++) {
            momentum[d] += weight * ((curr[d] || 0) - (prev[d] || 0));
          }
        }
        if (totalWeight > 0) {
          for (let d = 0; d < dims; d++) {
            momentum[d] /= totalWeight;
          }
        }
        return momentum;
      }
      detectLearningPhases(trajectoryId) {
        const trajectory = this.trajectories.get(trajectoryId);
        if (!trajectory || trajectory.waypoints.length < 5) return [];
        const phases = [];
        const waypoints = trajectory.waypoints;
        const windowSize = 5;
        let currentPhase = null;
        for (let i = 0; i < waypoints.length - windowSize; i++) {
          const window = waypoints.slice(i, i + windowSize);
          const phaseType = this.classifyPhase(window);
          const avgPhi = window.reduce((sum, w) => sum + w.consciousness.phi, 0) / window.length;
          const regimeCounts = {};
          for (const w of window) {
            const regime = w.consciousness.regime;
            regimeCounts[regime] = (regimeCounts[regime] || 0) + 1;
          }
          const dominantRegime = Object.entries(regimeCounts).sort((a, b) => b[1] - a[1])[0]?.[0] || "unknown";
          if (!currentPhase || currentPhase.type !== phaseType) {
            if (currentPhase) {
              currentPhase.endIndex = i - 1;
              currentPhase.duration = currentPhase.endIndex - currentPhase.startIndex + 1;
              phases.push(currentPhase);
            }
            currentPhase = {
              type: phaseType,
              startIndex: i,
              endIndex: i + windowSize - 1,
              avgPhi,
              dominantRegime,
              duration: windowSize
            };
          } else {
            currentPhase.endIndex = i + windowSize - 1;
            currentPhase.avgPhi = (currentPhase.avgPhi * currentPhase.duration + avgPhi) / (currentPhase.duration + 1);
            currentPhase.duration++;
          }
        }
        if (currentPhase) {
          phases.push(currentPhase);
        }
        return phases;
      }
      classifyPhase(window) {
        const phis = window.map((w) => w.consciousness.phi);
        const avgPhi = phis.reduce((a, b) => a + b, 0) / phis.length;
        const phiVariance = this.computeVariance(phis);
        const phiTrend = phis[phis.length - 1] - phis[0];
        const regimes = new Set(window.map((w) => w.consciousness.regime));
        const hasRegimeTransition = regimes.size > 1;
        const displacement = fisherCoordDistance(
          window[window.length - 1].basinCoords,
          window[0].basinCoords
        );
        if (phiTrend > 0.2 && avgPhi > 0.6) {
          return "breakthrough";
        }
        if (hasRegimeTransition) {
          return "transition";
        }
        if (phiVariance < 0.02 && displacement < 0.3) {
          return "plateau";
        }
        if (avgPhi > 0.5 && displacement < 0.5) {
          return "exploitation";
        }
        return "exploration";
      }
      predictNextDirection(trajectoryId) {
        const metrics = this.getTrajectoryMetrics(trajectoryId);
        if (!metrics) return null;
        const trajectory = this.trajectories.get(trajectoryId);
        if (!trajectory || trajectory.waypoints.length === 0) return null;
        const lastWaypoint = trajectory.waypoints[trajectory.waypoints.length - 1];
        const lastCoords = lastWaypoint.basinCoords;
        const suggestedCoords = lastCoords.map(
          (c, i) => c + (metrics.momentumVector[i] || 0) * 2
        );
        let confidence = 0.5;
        if (metrics.phiGradient > 0) confidence += 0.2;
        if (metrics.plateauDetected) confidence -= 0.3;
        if (metrics.efficiency > 0.5) confidence += 0.15;
        confidence = Math.max(0.1, Math.min(1, confidence));
        const reasoning = this.generatePredictionReasoning(metrics);
        return { suggestedCoords, confidence, reasoning };
      }
      generatePredictionReasoning(metrics) {
        const parts = [];
        if (metrics.phiGradient > 0.1) {
          parts.push("\u03A6 improving - continue in momentum direction");
        } else if (metrics.phiGradient < -0.1) {
          parts.push("\u03A6 declining - consider course correction");
        }
        if (metrics.plateauDetected) {
          parts.push("Plateau detected - recommend exploration");
        }
        if (metrics.efficiency < 0.3) {
          parts.push("Low efficiency - try more directed search");
        } else if (metrics.efficiency > 0.7) {
          parts.push("High efficiency - good trajectory");
        }
        if (metrics.regimeTransitions > 3) {
          parts.push("Many regime transitions - near interesting boundary");
        }
        return parts.join(". ") || "Standard exploration";
      }
      takeSnapshot(targetAddress, consciousness) {
        const topology = geometricMemory.getBasinTopology();
        const summary = geometricMemory.getManifoldSummary();
        const trajectories = this.getTrajectoriesForTarget(targetAddress);
        const latestTrajectory = trajectories[trajectories.length - 1];
        const recentWaypoints = latestTrajectory?.waypoints.slice(-10) || [];
        let recentVelocity = 0;
        let momentum = [];
        if (recentWaypoints.length > 1) {
          recentVelocity = recentWaypoints.reduce((sum, w) => sum + w.fisherDistance, 0) / recentWaypoints.length;
          momentum = this.computeMomentumVector(recentWaypoints, Math.min(5, recentWaypoints.length));
        }
        const basinTopology = {
          attractorCoords: topology.attractorCoords.length === 64 ? topology.attractorCoords : [...topology.attractorCoords, ...new Array(64 - topology.attractorCoords.length).fill(0)],
          volume: topology.volume,
          curvature: topology.curvature,
          boundaryDistances: topology.boundaryDistances,
          resonanceShells: topology.resonanceShells,
          flowField: topology.flowField,
          holes: topology.holes,
          effectiveScale: topology.effectiveScale,
          kappaAtScale: topology.kappaAtScale
        };
        const snapshot = {
          id: nanoid5(),
          takenAt: (/* @__PURE__ */ new Date()).toISOString(),
          targetAddress,
          consciousness,
          basinTopology,
          activeGenerators: [],
          generatorOutputQueue: 0,
          negativeKnowledgeSummary: {
            totalExclusions: 0,
            recentAdditions: 0,
            coverageGain: 0
          },
          currentTrajectory: {
            totalWaypoints: latestTrajectory?.waypoints.length || 0,
            recentVelocity,
            momentum
          },
          activeStreams: [],
          manifoldCoverage: summary.exploredVolume,
          resonanceVolume: summary.resonanceClusters * 0.1,
          explorationEfficiency: summary.avgPhi
        };
        this.snapshots.set(snapshot.id, snapshot);
        console.log(`[TemporalGeometry] Took snapshot ${snapshot.id}`);
        return snapshot;
      }
      compareSnapshots(snapshot1Id, snapshot2Id) {
        const s1 = this.snapshots.get(snapshot1Id);
        const s2 = this.snapshots.get(snapshot2Id);
        if (!s1 || !s2) return null;
        return {
          basinDrift: Math.abs(s2.basinTopology.volume - s1.basinTopology.volume),
          volumeChange: s2.basinTopology.volume - s1.basinTopology.volume,
          informationGain: s2.manifoldCoverage - s1.manifoldCoverage,
          newHoles: Math.max(0, s2.basinTopology.holes.length - s1.basinTopology.holes.length),
          closedHoles: Math.max(0, s1.basinTopology.holes.length - s2.basinTopology.holes.length),
          phiChange: s2.consciousness.phi - s1.consciousness.phi
        };
      }
      getTrajectory(trajectoryId) {
        return this.trajectories.get(trajectoryId);
      }
      completeTrajectory(trajectoryId) {
        const trajectory = this.trajectories.get(trajectoryId);
        if (!trajectory) {
          console.warn(`[TemporalGeometry] Trajectory ${trajectoryId} not found for completion`);
          return null;
        }
        const waypointCount = trajectory.waypoints.length;
        const finalPhi = waypointCount > 0 ? trajectory.waypoints[waypointCount - 1].consciousness.phi : 0;
        this.trajectories.delete(trajectoryId);
        console.log(`[TemporalGeometry] Completed and removed trajectory ${trajectoryId} (${waypointCount} waypoints, final \u03A6=${finalPhi.toFixed(3)})`);
        return { waypointCount, finalPhi };
      }
      getTrajectoriesForTarget(targetAddress) {
        const result = [];
        for (const traj of Array.from(this.trajectories.values())) {
          if (traj.targetAddress === targetAddress) {
            result.push(traj);
          }
        }
        return result;
      }
      getRecentSnapshots(limit = 10) {
        return Array.from(this.snapshots.values()).sort((a, b) => b.id.localeCompare(a.id)).slice(0, limit);
      }
      computeVariance(values) {
        if (values.length < 2) return 0;
        const mean = values.reduce((a, b) => a + b, 0) / values.length;
        return values.reduce((sum, v) => sum + (v - mean) ** 2, 0) / values.length;
      }
    };
    temporalGeometry = new TemporalGeometry();
  }
});

// server/ocean/trajectory-manager.ts
var TrajectoryManager, trajectoryManager;
var init_trajectory_manager = __esm({
  "server/ocean/trajectory-manager.ts"() {
    "use strict";
    init_temporal_geometry();
    init_ocean_persistence();
    TrajectoryManager = class {
      activeTrajectories = /* @__PURE__ */ new Map();
      completedCount = 0;
      archivedCount = 0;
      startTrajectory(address) {
        if (this.activeTrajectories.has(address)) {
          console.warn(`[TrajectoryManager] Trajectory already active for ${address.slice(0, 12)}...`);
          return this.activeTrajectories.get(address).trajectoryId;
        }
        const trajectoryId = temporalGeometry.startTrajectory(address);
        this.activeTrajectories.set(address, {
          trajectoryId,
          address,
          startTime: Date.now(),
          waypointCount: 0,
          lastPhi: 0,
          lastKappa: 0
        });
        oceanPersistence.startTrajectory(trajectoryId, address).catch((err) => {
          console.error("[TrajectoryManager] PostgreSQL persist failed:", err);
        });
        console.log(`[TrajectoryManager] Started trajectory ${trajectoryId} for ${address.slice(0, 12)}...`);
        return trajectoryId;
      }
      recordWaypoint(address, phi, kappa, regime, basinCoords, event, details) {
        const trajectory = this.activeTrajectories.get(address);
        if (!trajectory) {
          console.warn(`[TrajectoryManager] No active trajectory for ${address.slice(0, 12)}...`);
          return;
        }
        temporalGeometry.recordWaypoint(
          trajectory.trajectoryId,
          phi,
          kappa,
          regime,
          basinCoords,
          event,
          details
        );
        trajectory.waypointCount++;
        trajectory.lastPhi = phi;
        trajectory.lastKappa = kappa;
        oceanPersistence.recordWaypoint(trajectory.trajectoryId, {
          phi,
          kappa,
          regime,
          basinCoords,
          event,
          details
        }).catch((err) => {
          console.error("[TrajectoryManager] PostgreSQL waypoint persist failed:", err);
        });
      }
      completeTrajectory(address, outcome) {
        const trajectory = this.activeTrajectories.get(address);
        if (!trajectory) {
          console.warn(`[TrajectoryManager] No active trajectory for ${address.slice(0, 12)}...`);
          return;
        }
        temporalGeometry.recordWaypoint(
          trajectory.trajectoryId,
          outcome.finalPhi,
          outcome.finalKappa,
          "linear",
          [],
          "trajectory_complete",
          JSON.stringify({
            success: outcome.success,
            duration: `${outcome.duration.toFixed(1)}s`,
            waypoints: outcome.totalWaypoints,
            nearMisses: outcome.nearMissCount,
            resonant: outcome.resonantCount,
            finalResult: outcome.finalResult
          })
        );
        temporalGeometry.completeTrajectory(trajectory.trajectoryId);
        this.activeTrajectories.delete(address);
        this.completedCount++;
        oceanPersistence.completeTrajectory(trajectory.trajectoryId, outcome.finalResult, {
          nearMissCount: outcome.nearMissCount,
          resonantCount: outcome.resonantCount
        }).catch((err) => {
          console.error("[TrajectoryManager] PostgreSQL completion persist failed:", err);
        });
        console.log(`[TrajectoryManager] Completed trajectory ${trajectory.trajectoryId}`);
        console.log(`[TrajectoryManager]   Duration: ${outcome.duration.toFixed(1)}s, Waypoints: ${outcome.totalWaypoints}`);
        console.log(`[TrajectoryManager]   Result: ${outcome.finalResult}, Near-misses: ${outcome.nearMissCount}`);
      }
      getActiveTrajectory(address) {
        return this.activeTrajectories.get(address);
      }
      hasActiveTrajectory(address) {
        return this.activeTrajectories.has(address);
      }
      getActiveCount() {
        return this.activeTrajectories.size;
      }
      getCompletedCount() {
        return this.completedCount;
      }
      getArchivedCount() {
        return this.archivedCount;
      }
      getStatistics() {
        const activeDetails = Array.from(this.activeTrajectories.values()).map((t) => ({
          address: t.address.slice(0, 12) + "...",
          trajectoryId: t.trajectoryId,
          duration: (Date.now() - t.startTime) / 1e3,
          waypoints: t.waypointCount,
          lastPhi: t.lastPhi,
          lastKappa: t.lastKappa
        }));
        return {
          active: this.activeTrajectories.size,
          completed: this.completedCount,
          archived: this.archivedCount,
          activeDetails
        };
      }
      cleanupAll() {
        console.log(`[TrajectoryManager] Cleaning up ${this.activeTrajectories.size} active trajectories`);
        const entries = Array.from(this.activeTrajectories.entries());
        for (const [address, trajectory] of entries) {
          try {
            temporalGeometry.recordWaypoint(
              trajectory.trajectoryId,
              trajectory.lastPhi,
              trajectory.lastKappa,
              "linear",
              [],
              "cleanup_forced",
              "Trajectory cleaned up due to manager shutdown"
            );
            temporalGeometry.completeTrajectory(trajectory.trajectoryId);
            this.archivedCount++;
          } catch (error) {
            console.error(`[TrajectoryManager] Failed to cleanup trajectory for ${address}:`, error);
          }
        }
        this.activeTrajectories.clear();
        console.log("[TrajectoryManager] Cleanup complete");
      }
      abandonTrajectory(address, reason) {
        const trajectory = this.activeTrajectories.get(address);
        if (!trajectory) {
          return;
        }
        try {
          temporalGeometry.recordWaypoint(
            trajectory.trajectoryId,
            trajectory.lastPhi,
            trajectory.lastKappa,
            "breakdown",
            [],
            "trajectory_abandoned",
            reason
          );
          temporalGeometry.completeTrajectory(trajectory.trajectoryId);
          this.archivedCount++;
        } catch (error) {
          console.error(`[TrajectoryManager] Failed to abandon trajectory:`, error);
        }
        this.activeTrajectories.delete(address);
        console.log(`[TrajectoryManager] Abandoned trajectory for ${address.slice(0, 12)}...: ${reason}`);
      }
    };
    trajectoryManager = new TrajectoryManager();
  }
});

// server/strategy-knowledge-bus.ts
import { eq as eq5 } from "drizzle-orm";
import { existsSync as existsSync8, readFileSync as readFileSync8, writeFileSync as writeFileSync6 } from "fs";
var StrategyKnowledgeBus, strategyKnowledgeBus;
var init_strategy_knowledge_bus = __esm({
  "server/strategy-knowledge-bus.ts"() {
    "use strict";
    init_schema();
    init_db();
    init_knowledge_compression_engine();
    init_negative_knowledge_unified();
    init_temporal_geometry();
    StrategyKnowledgeBus = class {
      strategies = /* @__PURE__ */ new Map();
      sharedKnowledge = /* @__PURE__ */ new Map();
      transferHistory = [];
      crossStrategyPatterns = /* @__PURE__ */ new Map();
      subscriptions = [];
      scaleMappings = /* @__PURE__ */ new Map();
      PERSISTENCE_PATH = "./knowledge_bus_state.json";
      MAX_TRANSFER_HISTORY = 1e3;
      CROSS_STRATEGY_THRESHOLD = 0.7;
      initialized = false;
      initPromise = null;
      constructor() {
        this.initPromise = this.initialize();
      }
      async initialize() {
        await this.load();
        this.registerDefaultStrategies();
        this.initialized = true;
      }
      async ensureInitialized() {
        if (!this.initialized && this.initPromise) {
          await this.initPromise;
        }
      }
      registerDefaultStrategies() {
        const defaultStrategies = [
          {
            id: "era_patterns",
            name: "Era Pattern Analysis",
            generatorTypes: ["temporal", "grammatical"],
            compressionMethods: ["era_clustering", "temporal_entropy"],
            resonanceRange: [0.3, 0.7],
            preferredRegimes: ["linear", "geometric"]
          },
          {
            id: "brain_wallet_dict",
            name: "Brain Wallet Dictionary",
            generatorTypes: ["grammatical", "structural"],
            compressionMethods: ["dictionary_hash", "frequency_encode"],
            resonanceRange: [0.4, 0.9],
            preferredRegimes: ["linear"]
          },
          {
            id: "bitcoin_terms",
            name: "Bitcoin Terminology",
            generatorTypes: ["grammatical", "cross_format"],
            compressionMethods: ["term_graph", "semantic_embed"],
            resonanceRange: [0.5, 0.95],
            preferredRegimes: ["geometric"]
          },
          {
            id: "linguistic",
            name: "Linguistic Patterns",
            generatorTypes: ["grammatical", "structural"],
            compressionMethods: ["ngram_compress", "phonetic_hash"],
            resonanceRange: [0.2, 0.8],
            preferredRegimes: ["linear", "geometric"]
          },
          {
            id: "qig_basin_search",
            name: "QIG Basin Search",
            generatorTypes: ["geometric", "structural"],
            compressionMethods: ["basin_topology", "curvature_encode"],
            resonanceRange: [0.6, 1],
            preferredRegimes: ["geometric", "breakdown"]
          },
          {
            id: "historical_autonomous",
            name: "Historical Autonomous",
            generatorTypes: ["temporal", "cross_format"],
            compressionMethods: ["archive_chain", "temporal_graph"],
            resonanceRange: [0.3, 0.85],
            preferredRegimes: ["linear", "geometric"]
          },
          {
            id: "cross_format",
            name: "Cross Format Analysis",
            generatorTypes: ["cross_format", "geometric"],
            compressionMethods: ["format_bridge", "universal_hash"],
            resonanceRange: [0.4, 0.95],
            preferredRegimes: ["geometric", "breakdown"]
          }
        ];
        for (const strategy of defaultStrategies) {
          if (!this.strategies.has(strategy.id)) {
            this.strategies.set(strategy.id, strategy);
          }
        }
        this.persistStrategies();
      }
      persistStrategies() {
        if (!db) return;
        const strategiesToInsert = Array.from(this.strategies.values());
        withDbRetry(async () => {
          for (const strategy of strategiesToInsert) {
            const insertData = {
              id: strategy.id,
              name: strategy.name,
              generatorTypes: strategy.generatorTypes,
              compressionMethods: strategy.compressionMethods,
              resonanceRangeMin: strategy.resonanceRange[0],
              resonanceRangeMax: strategy.resonanceRange[1],
              preferredRegimes: strategy.preferredRegimes
            };
            await db.insert(knowledgeStrategies).values(insertData).onConflictDoNothing();
          }
        }, "KnowledgeBus.persistStrategies").catch((err) => {
          console.error("[KnowledgeBus] Failed to persist strategies:", err);
        });
      }
      async registerStrategy(capability) {
        await this.ensureInitialized();
        this.strategies.set(capability.id, capability);
        console.log(`[KnowledgeBus] Registered strategy: ${capability.name}`);
        if (db) {
          const insertData = {
            id: capability.id,
            name: capability.name,
            generatorTypes: capability.generatorTypes,
            compressionMethods: capability.compressionMethods,
            resonanceRangeMin: capability.resonanceRange[0],
            resonanceRangeMax: capability.resonanceRange[1],
            preferredRegimes: capability.preferredRegimes
          };
          withDbRetry(async () => {
            await db.insert(knowledgeStrategies).values(insertData).onConflictDoUpdate({
              target: knowledgeStrategies.id,
              set: {
                name: insertData.name,
                generatorTypes: insertData.generatorTypes,
                compressionMethods: insertData.compressionMethods,
                resonanceRangeMin: insertData.resonanceRangeMin,
                resonanceRangeMax: insertData.resonanceRangeMax,
                preferredRegimes: insertData.preferredRegimes,
                updatedAt: /* @__PURE__ */ new Date()
              }
            });
          }, "KnowledgeBus.registerStrategy").catch((err) => {
            console.error("[KnowledgeBus] Failed to save strategy:", err);
          });
        }
        this.saveToJson();
      }
      async publishKnowledge(sourceStrategy, generatorId, pattern, context) {
        await this.ensureInitialized();
        const entryId = `kb_${Date.now()}_${Math.random().toString(36).substr(2, 9)}`;
        const entry = {
          id: entryId,
          sourceStrategy,
          generatorId,
          pattern,
          phi: context.phi,
          kappaEff: context.kappaEff,
          regime: context.regime,
          sharedAt: (/* @__PURE__ */ new Date()).toISOString(),
          consumedBy: [],
          transformations: []
        };
        this.sharedKnowledge.set(entryId, entry);
        if (db) {
          const insertData = {
            id: entryId,
            sourceStrategy,
            generatorId,
            pattern,
            phi: context.phi,
            kappaEff: context.kappaEff,
            regime: context.regime,
            consumedBy: [],
            transformations: []
          };
          withDbRetry(async () => {
            await db.insert(knowledgeSharedEntries).values(insertData);
          }, "KnowledgeBus.publishKnowledge").catch((err) => {
            console.error("[KnowledgeBus] Failed to save knowledge entry:", err);
          });
        }
        this.recordTransfer({
          id: `transfer_${Date.now()}_${Math.random().toString(36).slice(2, 8)}`,
          type: "publish",
          sourceStrategy,
          targetStrategy: null,
          generatorId,
          pattern,
          phi: context.phi,
          kappaEff: context.kappaEff,
          timestamp: entry.sharedAt,
          success: true
        });
        this.detectCrossStrategyPatterns(pattern, sourceStrategy, context);
        this.saveToJson();
        return entryId;
      }
      async consumeKnowledge(targetStrategy, entryId, transformation) {
        await this.ensureInitialized();
        const entry = this.sharedKnowledge.get(entryId);
        if (!entry) return null;
        if (!entry.consumedBy.includes(targetStrategy)) {
          entry.consumedBy.push(targetStrategy);
        }
        if (transformation) {
          entry.transformations.push({
            strategy: targetStrategy,
            method: transformation,
            timestamp: (/* @__PURE__ */ new Date()).toISOString()
          });
        }
        if (db) {
          withDbRetry(async () => {
            await db.update(knowledgeSharedEntries).set({
              consumedBy: entry.consumedBy,
              transformations: entry.transformations
            }).where(eq5(knowledgeSharedEntries.id, entryId));
          }, "KnowledgeBus.consumeKnowledge").catch((err) => {
            console.error("[KnowledgeBus] Failed to update knowledge entry:", err);
          });
        }
        this.recordTransfer({
          id: `transfer_${Date.now()}_${Math.random().toString(36).slice(2, 8)}`,
          type: "consume",
          sourceStrategy: entry.sourceStrategy,
          targetStrategy,
          generatorId: entry.generatorId,
          pattern: entry.pattern,
          phi: entry.phi,
          kappaEff: entry.kappaEff,
          timestamp: (/* @__PURE__ */ new Date()).toISOString(),
          success: true,
          transformation
        });
        this.saveToJson();
        return entry;
      }
      async transferGenerator(sourceStrategy, targetStrategy, generator, scaleAdjustment) {
        await this.ensureInitialized();
        const source = this.strategies.get(sourceStrategy);
        const target = this.strategies.get(targetStrategy);
        if (!source || !target) {
          return {
            success: false,
            generator: null,
            scaleTransform: 1,
            fidelityLoss: 1,
            adaptations: ["missing_strategy"]
          };
        }
        const hasMatchingType = generator.type && target.generatorTypes.includes(generator.type);
        const resonanceOverlap = this.computeResonanceOverlap(
          source.resonanceRange,
          target.resonanceRange
        );
        const adaptations = [];
        let fidelityLoss = 0;
        if (!hasMatchingType) {
          adaptations.push("type_adaptation");
          fidelityLoss += 0.1;
        }
        if (resonanceOverlap < 0.5) {
          adaptations.push("resonance_rescale");
          fidelityLoss += 0.15 * (1 - resonanceOverlap);
        }
        const regimeCompat = target.preferredRegimes.some(
          (r) => source.preferredRegimes.includes(r)
        );
        if (!regimeCompat) {
          adaptations.push("regime_bridge");
          fidelityLoss += 0.2;
        }
        const scaleTransform = scaleAdjustment ?? this.computeScaleTransform(source, target);
        const adaptedGenerator = {
          ...generator,
          source: "cross_agent"
        };
        this.recordTransfer({
          id: `transfer_${Date.now()}_${Math.random().toString(36).slice(2, 8)}`,
          type: "generator_transfer",
          sourceStrategy,
          targetStrategy,
          generatorId: generator.id,
          pattern: generator.template,
          phi: generator.confidence,
          kappaEff: generator.curvatureSignature[0] ?? 0,
          timestamp: (/* @__PURE__ */ new Date()).toISOString(),
          success: true,
          transformation: adaptations.join(","),
          scaleAdjustment: scaleTransform
        });
        return {
          success: true,
          generator: adaptedGenerator,
          scaleTransform,
          fidelityLoss,
          adaptations
        };
      }
      computeResonanceOverlap(range1, range2) {
        const overlapStart = Math.max(range1[0], range2[0]);
        const overlapEnd = Math.min(range1[1], range2[1]);
        if (overlapStart >= overlapEnd) return 0;
        const overlapLength = overlapEnd - overlapStart;
        const totalRange = Math.max(range1[1], range2[1]) - Math.min(range1[0], range2[0]);
        return overlapLength / totalRange;
      }
      computeScaleTransform(source, target) {
        const sourceRange = source.resonanceRange[1] - source.resonanceRange[0];
        const targetRange = target.resonanceRange[1] - target.resonanceRange[0];
        return targetRange / sourceRange;
      }
      async subscribe(subscriberId, strategyId, patterns, callback) {
        await this.ensureInitialized();
        const subscription = {
          subscriberId,
          strategyId,
          patterns,
          callback,
          createdAt: (/* @__PURE__ */ new Date()).toISOString()
        };
        this.subscriptions.push(subscription);
        return () => {
          const idx = this.subscriptions.findIndex(
            (s) => s.subscriberId === subscriberId
          );
          if (idx >= 0) {
            this.subscriptions.splice(idx, 1);
          }
        };
      }
      notifySubscribers(event) {
        for (const sub of this.subscriptions) {
          const matchesStrategy = sub.strategyId === "*" || sub.strategyId === event.sourceStrategy || sub.strategyId === event.targetStrategy;
          const matchesPattern = sub.patterns.length === 0 || sub.patterns.some(
            (p) => event.pattern.toLowerCase().includes(p.toLowerCase())
          );
          if (matchesStrategy && matchesPattern) {
            try {
              sub.callback(event);
            } catch (err) {
              console.error(`[KnowledgeBus] Subscription callback error: ${err}`);
            }
          }
        }
      }
      recordTransfer(event) {
        this.transferHistory.push(event);
        if (this.transferHistory.length > this.MAX_TRANSFER_HISTORY) {
          this.transferHistory = this.transferHistory.slice(
            -this.MAX_TRANSFER_HISTORY
          );
        }
        if (db) {
          const insertData = {
            id: event.id,
            type: event.type,
            sourceStrategy: event.sourceStrategy,
            targetStrategy: event.targetStrategy,
            generatorId: event.generatorId,
            pattern: event.pattern,
            phi: event.phi,
            kappaEff: event.kappaEff,
            success: event.success,
            transformation: event.transformation,
            scaleAdjustment: event.scaleAdjustment
          };
          withDbRetry(async () => {
            await db.insert(knowledgeTransfers).values(insertData);
          }, "KnowledgeBus.recordTransfer").catch((err) => {
            console.error("[KnowledgeBus] Failed to record transfer:", err);
          });
        }
        this.notifySubscribers(event);
      }
      detectCrossStrategyPatterns(pattern, sourceStrategy, context) {
        const entriesList = Array.from(this.sharedKnowledge.values());
        for (const entry of entriesList) {
          if (entry.sourceStrategy === sourceStrategy) continue;
          const similarity = this.computePatternSimilarity(pattern, entry.pattern);
          if (similarity >= this.CROSS_STRATEGY_THRESHOLD) {
            const patternId = `cross_${sourceStrategy}_${entry.sourceStrategy}_${Date.now()}`;
            const crossPattern = {
              id: patternId,
              patterns: [pattern, entry.pattern],
              strategies: [sourceStrategy, entry.sourceStrategy],
              similarity,
              combinedPhi: (context.phi + entry.phi) / 2,
              discoveredAt: (/* @__PURE__ */ new Date()).toISOString(),
              exploitationCount: 0
            };
            this.crossStrategyPatterns.set(patternId, crossPattern);
            if (db) {
              const insertData = {
                id: patternId,
                patterns: crossPattern.patterns,
                strategies: crossPattern.strategies,
                similarity: crossPattern.similarity,
                combinedPhi: crossPattern.combinedPhi,
                exploitationCount: 0
              };
              withDbRetry(async () => {
                await db.insert(knowledgeCrossPatterns).values(insertData);
              }, "KnowledgeBus.detectCrossStrategyPatterns").catch((err) => {
                console.error("[KnowledgeBus] Failed to save cross pattern:", err);
              });
            }
            console.log(
              `[KnowledgeBus] Cross-strategy pattern detected: ${sourceStrategy} <-> ${entry.sourceStrategy} (${(similarity * 100).toFixed(1)}%)`
            );
          }
        }
      }
      computePatternSimilarity(a, b) {
        const aNorm = a.toLowerCase().trim();
        const bNorm = b.toLowerCase().trim();
        if (aNorm === bNorm) return 1;
        if (aNorm.includes(bNorm) || bNorm.includes(aNorm)) return 0.9;
        const aChars = new Set(aNorm.split(""));
        const bChars = new Set(bNorm.split(""));
        let intersection = 0;
        for (const c of Array.from(aChars)) {
          if (bChars.has(c)) intersection++;
        }
        const union = (/* @__PURE__ */ new Set([...Array.from(aChars), ...Array.from(bChars)])).size;
        return intersection / union;
      }
      async getCrossStrategyPatterns() {
        await this.ensureInitialized();
        return Array.from(this.crossStrategyPatterns.values());
      }
      async exploitCrossPattern(patternId) {
        await this.ensureInitialized();
        const pattern = this.crossStrategyPatterns.get(patternId);
        if (pattern) {
          pattern.exploitationCount++;
          if (db) {
            withDbRetry(async () => {
              await db.update(knowledgeCrossPatterns).set({ exploitationCount: pattern.exploitationCount }).where(eq5(knowledgeCrossPatterns.id, patternId));
            }, "KnowledgeBus.exploitCrossPattern").catch((err) => {
              console.error("[KnowledgeBus] Failed to update cross pattern:", err);
            });
          }
          this.saveToJson();
        }
        return pattern ?? null;
      }
      async findCompatibleStrategies(generatorType, regime) {
        await this.ensureInitialized();
        const compatible = [];
        const strategiesList = Array.from(this.strategies.entries());
        for (const [id, capability] of strategiesList) {
          if (capability.generatorTypes.includes(generatorType) && capability.preferredRegimes.includes(regime)) {
            compatible.push(id);
          }
        }
        return compatible;
      }
      async getKnowledgeForStrategy(strategyId) {
        await this.ensureInitialized();
        const strategy = this.strategies.get(strategyId);
        if (!strategy) return [];
        const compatible = [];
        const entriesList = Array.from(this.sharedKnowledge.values());
        for (const entry of entriesList) {
          if (entry.sourceStrategy !== strategyId) {
            compatible.push(entry);
          }
        }
        return compatible;
      }
      async integrateExternalSystems() {
        await this.ensureInitialized();
        const generators = knowledgeCompressionEngine.getAllGenerators();
        for (const gen of generators) {
          if (gen.confidence > 0.3) {
            await this.publishKnowledge(
              gen.source === "cross_agent" ? "cross_agent" : "compression_engine",
              gen.id,
              gen.template,
              {
                phi: gen.confidence,
                kappaEff: gen.curvatureSignature[0] ?? 0,
                regime: "linear"
              }
            );
          }
        }
        const negativeStats = await negativeKnowledgeUnified.getStats();
        if (negativeStats.contradictions > 0) {
          const summary = await negativeKnowledgeUnified.getSummary();
          for (const contradiction of summary.contradictions) {
            await this.publishKnowledge(
              "negative_registry",
              contradiction.id,
              `NEGATIVE:${contradiction.pattern}`,
              {
                phi: 0,
                kappaEff: 0,
                regime: "linear"
              }
            );
          }
        }
      }
      async getSummary() {
        await this.ensureInitialized();
        return {
          strategies: Array.from(this.strategies.keys()),
          sharedKnowledge: Array.from(this.sharedKnowledge.values()),
          crossStrategyPatterns: Array.from(this.crossStrategyPatterns.values()),
          transferHistory: this.transferHistory.slice(-100),
          activeSubscriptions: this.subscriptions.length
        };
      }
      async getTransferStats() {
        await this.ensureInitialized();
        const publishEvents = this.transferHistory.filter(
          (e) => e.type === "publish"
        ).length;
        const consumeEvents = this.transferHistory.filter(
          (e) => e.type === "consume"
        ).length;
        const successEvents = this.transferHistory.filter((e) => e.success).length;
        return {
          totalPublished: publishEvents,
          totalConsumed: consumeEvents,
          crossPatterns: this.crossStrategyPatterns.size,
          activeStrategies: this.strategies.size,
          transferSuccessRate: this.transferHistory.length > 0 ? successEvents / this.transferHistory.length : 1
        };
      }
      async createScaleInvariantBridge(sourceScale, targetScale, preservedFeatures) {
        await this.ensureInitialized();
        const bridgeId = `scale_${sourceScale}_${targetScale}_${Date.now()}`;
        const ratio = targetScale / sourceScale;
        const transformMatrix = [
          ratio,
          0,
          0,
          0,
          0,
          ratio,
          0,
          0,
          0,
          0,
          ratio,
          0,
          0,
          0,
          0,
          1
        ];
        const lossEstimate = Math.abs(1 - ratio) * 0.1;
        this.scaleMappings.set(bridgeId, {
          sourceScale,
          targetScale,
          transformMatrix,
          preservedFeatures,
          lossEstimate
        });
        if (db) {
          const insertData = {
            id: bridgeId,
            sourceScale,
            targetScale,
            transformMatrix,
            preservedFeatures,
            lossEstimate
          };
          withDbRetry(async () => {
            await db.insert(knowledgeScaleMappings).values(insertData);
          }, "KnowledgeBus.createScaleInvariantBridge").catch((err) => {
            console.error("[KnowledgeBus] Failed to save scale mapping:", err);
          });
        }
        this.saveToJson();
        return bridgeId;
      }
      async applyScaleTransform(bridgeId, coords) {
        await this.ensureInitialized();
        const mapping = this.scaleMappings.get(bridgeId);
        if (!mapping) return coords;
        const ratio = mapping.targetScale / mapping.sourceScale;
        return coords.map((c) => c * ratio);
      }
      saveToJson() {
        if (db) {
          return;
        }
        try {
          const state = {
            strategies: Array.from(this.strategies.entries()),
            sharedKnowledge: Array.from(this.sharedKnowledge.entries()),
            crossStrategyPatterns: Array.from(this.crossStrategyPatterns.entries()),
            transferHistory: this.transferHistory.slice(-500),
            scaleMappings: Array.from(this.scaleMappings.entries())
          };
          writeFileSync6(this.PERSISTENCE_PATH, JSON.stringify(state, null, 2));
        } catch (err) {
          console.error("[KnowledgeBus] Failed to save state to JSON:", err);
        }
      }
      async load() {
        if (db) {
          const loaded = await this.loadFromDatabase();
          if (loaded) {
            console.log(`[KnowledgeBus] Loaded from PostgreSQL`);
            return;
          }
        }
        this.loadFromJson();
      }
      async loadFromDatabase() {
        try {
          const [
            strategiesData,
            entriesData,
            crossPatternsData,
            transfersData,
            scaleMappingsData
          ] = await Promise.all([
            withDbRetry(async () => {
              return await db.select().from(knowledgeStrategies);
            }, "KnowledgeBus.loadStrategies"),
            withDbRetry(async () => {
              return await db.select().from(knowledgeSharedEntries);
            }, "KnowledgeBus.loadEntries"),
            withDbRetry(async () => {
              return await db.select().from(knowledgeCrossPatterns);
            }, "KnowledgeBus.loadCrossPatterns"),
            withDbRetry(async () => {
              return await db.select().from(knowledgeTransfers).limit(this.MAX_TRANSFER_HISTORY);
            }, "KnowledgeBus.loadTransfers"),
            withDbRetry(async () => {
              return await db.select().from(knowledgeScaleMappings);
            }, "KnowledgeBus.loadScaleMappings")
          ]);
          if (strategiesData) {
            for (const row of strategiesData) {
              const capability = {
                id: row.id,
                name: row.name,
                generatorTypes: row.generatorTypes,
                compressionMethods: row.compressionMethods,
                resonanceRange: [row.resonanceRangeMin, row.resonanceRangeMax],
                preferredRegimes: row.preferredRegimes
              };
              this.strategies.set(row.id, capability);
            }
          }
          if (entriesData) {
            for (const row of entriesData) {
              const entry = {
                id: row.id,
                sourceStrategy: row.sourceStrategy,
                generatorId: row.generatorId,
                pattern: row.pattern,
                phi: row.phi,
                kappaEff: row.kappaEff,
                regime: row.regime,
                sharedAt: row.sharedAt.toISOString(),
                consumedBy: row.consumedBy || [],
                transformations: row.transformations || []
              };
              this.sharedKnowledge.set(row.id, entry);
            }
          }
          if (crossPatternsData) {
            for (const row of crossPatternsData) {
              const crossPattern = {
                id: row.id,
                patterns: row.patterns,
                strategies: row.strategies,
                similarity: row.similarity,
                combinedPhi: row.combinedPhi,
                discoveredAt: row.discoveredAt.toISOString(),
                exploitationCount: row.exploitationCount || 0
              };
              this.crossStrategyPatterns.set(row.id, crossPattern);
            }
          }
          if (transfersData) {
            this.transferHistory = transfersData.map((row) => ({
              id: row.id,
              type: row.type,
              sourceStrategy: row.sourceStrategy,
              targetStrategy: row.targetStrategy,
              generatorId: row.generatorId,
              pattern: row.pattern,
              phi: row.phi,
              kappaEff: row.kappaEff,
              timestamp: row.timestamp.toISOString(),
              success: row.success,
              transformation: row.transformation ?? void 0,
              scaleAdjustment: row.scaleAdjustment ?? void 0
            }));
          }
          if (scaleMappingsData) {
            for (const row of scaleMappingsData) {
              const mapping = {
                sourceScale: row.sourceScale,
                targetScale: row.targetScale,
                transformMatrix: row.transformMatrix,
                preservedFeatures: row.preservedFeatures,
                lossEstimate: row.lossEstimate
              };
              this.scaleMappings.set(row.id, mapping);
            }
          }
          console.log(
            `[KnowledgeBus] Loaded ${this.sharedKnowledge.size} knowledge entries, ${this.strategies.size} strategies from DB`
          );
          return true;
        } catch (err) {
          console.error("[KnowledgeBus] Failed to load from database:", err);
          return false;
        }
      }
      loadFromJson() {
        try {
          if (existsSync8(this.PERSISTENCE_PATH)) {
            const data = JSON.parse(readFileSync8(this.PERSISTENCE_PATH, "utf-8"));
            if (data.strategies) {
              this.strategies = new Map(data.strategies);
            }
            if (data.sharedKnowledge) {
              this.sharedKnowledge = new Map(data.sharedKnowledge);
            }
            if (data.crossStrategyPatterns) {
              this.crossStrategyPatterns = new Map(data.crossStrategyPatterns);
            }
            if (data.transferHistory) {
              this.transferHistory = data.transferHistory;
            }
            if (data.scaleMappings) {
              this.scaleMappings = new Map(data.scaleMappings);
            }
            console.log(
              `[KnowledgeBus] Loaded ${this.sharedKnowledge.size} knowledge entries from JSON fallback`
            );
          }
        } catch (err) {
          console.error("[KnowledgeBus] Failed to load state from JSON:", err);
        }
      }
    };
    strategyKnowledgeBus = new StrategyKnowledgeBus();
  }
});

// server/vocabulary-expander.ts
var vocabulary_expander_exports = {};
__export(vocabulary_expander_exports, {
  GeometricVocabularyExpander: () => GeometricVocabularyExpander,
  vocabularyExpander: () => vocabularyExpander
});
var GeometricVocabularyExpander, vocabularyExpander;
var init_vocabulary_expander = __esm({
  "server/vocabulary-expander.ts"() {
    "use strict";
    init_geometric_memory();
    init_qig_universal();
    init_vocabulary_tracker();
    GeometricVocabularyExpander = class {
      state;
      minPhiForExpansion;
      minFrequencyForExpansion;
      autoExpand;
      constructor(options = {}) {
        this.minPhiForExpansion = options.minPhiForExpansion || 0.6;
        this.minFrequencyForExpansion = options.minFrequencyForExpansion || 3;
        this.autoExpand = options.autoExpand ?? true;
        this.state = {
          words: /* @__PURE__ */ new Map(),
          expansionHistory: [],
          totalExpansions: 0,
          lastExpansionTime: null
        };
        this.loadFromDisk();
      }
      /**
       * Add a new word to the Fisher manifold via geodesic initialization
       * 
       * For compound words/sequences, compute geodesic midpoint from components
       */
      addWord(text2, qigScore, options = {}) {
        const existing = this.state.words.get(text2.toLowerCase());
        if (existing) {
          existing.frequency++;
          existing.phi = this.fisherWeightedAverage(existing.phi, qigScore.phi, existing.frequency);
          existing.kappa = this.fisherWeightedAverage(existing.kappa, qigScore.kappa, existing.frequency);
          if (qigScore.basinCoordinates && qigScore.basinCoordinates.length > 0) {
            existing.coordinates = this.geodesicInterpolate(
              existing.coordinates,
              qigScore.basinCoordinates,
              1 / existing.frequency
            );
          }
          return existing;
        }
        let coordinates = qigScore.basinCoordinates || [];
        let geodesicOrigin = "direct";
        if (options.components && options.components.length > 1) {
          const componentCoords = options.components.map((c) => this.state.words.get(c.toLowerCase())?.coordinates).filter((c) => c !== void 0 && c.length > 0);
          if (componentCoords.length > 0) {
            coordinates = this.geodesicMidpoint(componentCoords);
            geodesicOrigin = `geodesic_from_${options.components.join("+")}`;
          }
        }
        const word = {
          text: text2.toLowerCase(),
          coordinates,
          phi: qigScore.phi,
          kappa: qigScore.kappa,
          frequency: 1,
          components: options.components,
          geodesicOrigin
        };
        this.state.words.set(text2.toLowerCase(), word);
        this.state.expansionHistory.push({
          timestamp: (/* @__PURE__ */ new Date()).toISOString(),
          word: text2,
          type: options.components ? "compound" : "learned",
          components: options.components,
          phi: qigScore.phi,
          reasoning: options.source || "Direct observation"
        });
        this.state.totalExpansions++;
        this.state.lastExpansionTime = (/* @__PURE__ */ new Date()).toISOString();
        console.log(`[VocabExpander] \u2728 Added "${text2}" to manifold (\u03A6=${qigScore.phi.toFixed(2)}, origin=${geodesicOrigin})`);
        if (this.state.totalExpansions % 10 === 0) {
          this.saveToDisk();
        }
        return word;
      }
      /**
       * Compute geodesic midpoint on Fisher manifold
       * 
       * For Bures metric, geodesic midpoint ≈ Euclidean mean (first-order approximation)
       * This preserves manifold structure for small distances
       */
      geodesicMidpoint(coordinates) {
        if (coordinates.length === 0) return [];
        const dim = Math.max(...coordinates.map((c) => c.length));
        const result = new Array(dim).fill(0);
        for (const coord of coordinates) {
          for (let i = 0; i < dim; i++) {
            result[i] += (coord[i] || 0) / coordinates.length;
          }
        }
        return result;
      }
      /**
       * Geodesic interpolation between two points on manifold
       * 
       * t=0 returns a, t=1 returns b
       * For Fisher manifold, uses Bures metric approximation
       */
      geodesicInterpolate(a, b, t) {
        const dim = Math.max(a.length, b.length);
        const result = [];
        for (let i = 0; i < dim; i++) {
          const ai = a[i] || 0;
          const bi = b[i] || 0;
          result.push(ai + t * (bi - ai));
        }
        return result;
      }
      /**
       * Fisher metric-weighted average
       * Accounts for information geometry when combining observations
       */
      fisherWeightedAverage(old, new_, count) {
        const weight = 1 / count;
        return old * (1 - weight) + new_ * weight;
      }
      /**
       * Check and execute automatic vocabulary expansion
       * Called during search iterations
       */
      async checkAutoExpansion() {
        if (!this.autoExpand) return [];
        const candidates = vocabularyTracker.getCandidates(10);
        const expanded = [];
        for (const candidate of candidates) {
          if (candidate.avgPhi >= this.minPhiForExpansion && candidate.frequency >= this.minFrequencyForExpansion) {
            const score = await scoreUniversalQIGAsync(candidate.text, "arbitrary");
            this.addWord(candidate.text, score, {
              components: candidate.components,
              source: candidate.reasoning
            });
            expanded.push({
              timestamp: (/* @__PURE__ */ new Date()).toISOString(),
              word: candidate.text,
              type: candidate.type === "sequence" ? "compound" : "learned",
              components: candidate.components,
              phi: score.phi,
              reasoning: candidate.reasoning
            });
          }
        }
        if (expanded.length > 0) {
          console.log(`[VocabExpander] Auto-expanded ${expanded.length} vocabulary items`);
          this.saveToDisk();
        }
        return expanded;
      }
      /**
       * Get word from manifold
       */
      getWord(text2) {
        return this.state.words.get(text2.toLowerCase());
      }
      /**
       * Find words near a point on the manifold
       */
      findNearbyWords(coordinates, maxDistance = 2) {
        const nearby = [];
        for (const [, word] of Array.from(this.state.words.entries())) {
          if (word.coordinates.length === 0 || coordinates.length === 0) continue;
          const distance = this.fisherDistance(coordinates, word.coordinates);
          if (distance <= maxDistance) {
            nearby.push({ word, distance });
          }
        }
        return nearby.sort((a, b) => a.distance - b.distance).map((n) => n.word);
      }
      /**
       * Fisher geodesic distance between two points
       * Delegates to central implementation in qig-universal.ts
       */
      fisherDistance(a, b) {
        if (!a?.length || !b?.length) return 0;
        return fisherCoordDistance(a, b);
      }
      /**
       * Generate hypotheses from vocabulary manifold
       * Suggests words/phrases that might be near high-Φ regions
       */
      generateManifoldHypotheses(count = 20) {
        const hypotheses = [];
        const highPhiWords = Array.from(this.state.words.values()).filter((w) => w.phi >= 0.6).sort((a, b) => b.phi - a.phi);
        for (const word of highPhiWords.slice(0, count / 2)) {
          hypotheses.push(word.text);
        }
        for (let i = 0; i < Math.min(5, highPhiWords.length); i++) {
          for (let j = i + 1; j < Math.min(5, highPhiWords.length); j++) {
            hypotheses.push(`${highPhiWords[i].text} ${highPhiWords[j].text}`);
            hypotheses.push(`${highPhiWords[j].text} ${highPhiWords[i].text}`);
          }
        }
        const recent = this.state.expansionHistory.slice(-10).map((e) => e.word);
        hypotheses.push(...recent);
        return hypotheses.slice(0, count);
      }
      /**
       * Get vocabulary manifold statistics
       */
      getStats() {
        const words = Array.from(this.state.words.values());
        const highPhi = words.filter((w) => w.phi >= 0.6);
        const avgPhi = words.length > 0 ? words.reduce((sum, w) => sum + w.phi, 0) / words.length : 0;
        const topWords = words.sort((a, b) => b.phi - a.phi).slice(0, 20).map((w) => ({ text: w.text, phi: w.phi, frequency: w.frequency }));
        return {
          totalWords: words.length,
          totalExpansions: this.state.totalExpansions,
          highPhiWords: highPhi.length,
          avgPhi,
          recentExpansions: this.state.expansionHistory.slice(-10),
          topWords
        };
      }
      /**
       * Save state (now in-memory only)
       * NOTE: Database persistence removed - vocabulary expansion works in-memory
       * Actual vocab expansion uses vocabularyTracker which persists to vocabulary_observations
       */
      saveToDisk() {
      }
      /**
       * Load state - QIG-pure: auto-bootstrap from PostgreSQL-backed VocabularyTracker
       * This ensures vocabulary state persists across server restarts via PostgreSQL
       * Uses deferred initialization to wait for VocabularyTracker to load
       */
      loadFromDisk() {
        console.log("[VocabExpander] QIG-pure mode: will bootstrap from PostgreSQL after VocabularyTracker loads...");
        this.deferredBootstrap();
      }
      /**
       * Deferred bootstrap - waits for VocabularyTracker to load from PostgreSQL
       */
      async deferredBootstrap() {
        try {
          await vocabularyTracker.waitForData();
          await this.bootstrapFromVocabularyTracker();
        } catch (err) {
          console.warn("[VocabExpander] Bootstrap from VocabularyTracker failed, trying geometric memory:", err.message);
          try {
            await this.bootstrapFromGeometricMemory();
          } catch (err2) {
            console.warn("[VocabExpander] Bootstrap from geometric memory also failed:", err2.message);
          }
        }
      }
      /**
       * Bootstrap from VocabularyTracker (PostgreSQL-backed vocabulary_observations)
       */
      async bootstrapFromVocabularyTracker() {
        const candidates = vocabularyTracker.getCandidates(200);
        console.log(`[VocabExpander] Bootstrapping from ${candidates.length} VocabularyTracker candidates...`);
        let added = 0;
        for (const candidate of candidates) {
          if (!this.state.words.has(candidate.text.toLowerCase())) {
            const word = {
              text: candidate.text.toLowerCase(),
              coordinates: new Array(64).fill(0),
              // Will be updated on first observation
              phi: candidate.avgPhi,
              kappa: 50,
              // Default
              frequency: candidate.frequency,
              geodesicOrigin: "PostgreSQL bootstrap"
            };
            this.state.words.set(word.text, word);
            added++;
          }
        }
        console.log(`[VocabExpander] QIG-pure: bootstrapped ${added} words from PostgreSQL`);
      }
      /**
       * Bootstrap from geometric memory probes
       */
      async bootstrapFromGeometricMemory() {
        const probes = geometricMemory.getAllProbes();
        console.log(`[VocabExpander] Bootstrapping from ${probes.length} probes...`);
        let added = 0;
        for (const probe of probes) {
          if (probe.phi >= 0.5) {
            const words = probe.input.toLowerCase().replace(/[^a-z0-9\s]/g, " ").split(/\s+/).filter((w) => w.length >= 2);
            for (const word of words) {
              if (!this.state.words.has(word)) {
                const score = await scoreUniversalQIGAsync(word, "arbitrary");
                this.addWord(word, score, { source: "Bootstrap from probes" });
                added++;
              }
            }
            if (!this.state.words.has(probe.input.toLowerCase())) {
              const probeScore = {
                keyType: "arbitrary",
                phi: probe.phi,
                kappa: probe.kappa,
                beta: 0,
                phi_spatial: probe.phi,
                phi_temporal: 0,
                phi_4D: probe.phi,
                basinCoordinates: probe.coordinates,
                fisherTrace: probe.fisherTrace || 0,
                fisherDeterminant: 0,
                ricciScalar: probe.ricciScalar || 0,
                regime: probe.regime,
                inResonance: probe.phi >= 0.7,
                entropyBits: 0,
                patternScore: 0,
                quality: probe.phi
              };
              this.addWord(probe.input, probeScore, { source: "Bootstrap from probes (full phrase)" });
              added++;
            }
          }
        }
        console.log(`[VocabExpander] Bootstrapped ${added} words from probes`);
        this.saveToDisk();
      }
    };
    vocabularyExpander = new GeometricVocabularyExpander();
  }
});

// server/brain-state.ts
var brain_state_exports = {};
__export(brain_state_exports, {
  NeuralOscillators: () => NeuralOscillators,
  applyBrainStateToSearch: () => applyBrainStateToSearch,
  neuralOscillators: () => neuralOscillators,
  recommendBrainState: () => recommendBrainState,
  runNeuromodulationCycle: () => runNeuromodulationCycle
});
function recommendBrainState(input) {
  const { phi, kappa, basinDrift, iterationsSinceConsolidation, nearMissesRecent } = input;
  if (iterationsSinceConsolidation > BRAIN_STATE_THRESHOLDS.CONSOLIDATION_ITERATIONS && basinDrift > BRAIN_STATE_THRESHOLDS.CONSOLIDATION_DRIFT) {
    return "consolidating";
  }
  if (nearMissesRecent > BRAIN_STATE_THRESHOLDS.EXPLOIT_NEAR_MISSES && phi > BRAIN_STATE_THRESHOLDS.EXPLOIT_PHI) {
    return "exploiting";
  }
  if (phi < BRAIN_STATE_THRESHOLDS.EXPLORE_PHI || kappa < BRAIN_STATE_THRESHOLDS.EXPLORE_KAPPA) {
    return "exploring";
  }
  if (phi > BRAIN_STATE_THRESHOLDS.FOCUS_PHI && kappa > BRAIN_STATE_THRESHOLDS.FOCUS_KAPPA) {
    return "focused";
  }
  return "diffuse";
}
function applyBrainStateToSearch(brainState) {
  return BRAIN_STATE_SEARCH_PARAMS[brainState] || DEFAULT_SEARCH_PARAMS;
}
function runNeuromodulationCycle(input, params) {
  const activeModulators = [];
  let kappaAdjustment = 0;
  let biasApplied = "neutral";
  if (input.phi > NEUROMODULATION_THRESHOLDS.DOPAMINE_PHI && input.surprise > NEUROMODULATION_THRESHOLDS.DOPAMINE_SURPRISE) {
    activeModulators.push("DOPAMINE");
    kappaAdjustment += KAPPA_ADJUSTMENTS.DOPAMINE;
    biasApplied = "reward-seeking";
  }
  if (input.grounding < NEUROMODULATION_THRESHOLDS.SEROTONIN_GROUNDING || input.basinDistance > NEUROMODULATION_THRESHOLDS.SEROTONIN_BASIN_DISTANCE) {
    activeModulators.push("SEROTONIN");
    kappaAdjustment += KAPPA_ADJUSTMENTS.SEROTONIN;
    biasApplied = "stabilizing";
  }
  if (input.regime === "hierarchical_4d" || input.phi > NEUROMODULATION_THRESHOLDS.ACETYLCHOLINE_PHI) {
    activeModulators.push("ACETYLCHOLINE");
    biasApplied = "attention-focused";
  }
  if (input.kappa > NEUROMODULATION_THRESHOLDS.GABA_KAPPA) {
    activeModulators.push("GABA");
    kappaAdjustment += KAPPA_ADJUSTMENTS.GABA;
  }
  return {
    modulation: {
      activeModulators,
      biasApplied,
      kappaAdjustment
    },
    adjustedParams: {
      kappa: Math.max(
        KAPPA_ADJUSTMENTS.MIN,
        Math.min(KAPPA_ADJUSTMENTS.MAX, params.kappa + kappaAdjustment)
      ),
      explorationRate: params.explorationRate,
      learningRate: params.learningRate,
      batchSize: params.batchSize
    }
  };
}
var BRAIN_STATE_THRESHOLDS, NEUROMODULATION_THRESHOLDS, KAPPA_ADJUSTMENTS, DEFAULT_KAPPA, KAPPA_MODIFIERS, BRAIN_STATE_SEARCH_PARAMS, DEFAULT_SEARCH_PARAMS, NeuralOscillators, neuralOscillators;
var init_brain_state = __esm({
  "server/brain-state.ts"() {
    "use strict";
    BRAIN_STATE_THRESHOLDS = {
      CONSOLIDATION_ITERATIONS: 50,
      CONSOLIDATION_DRIFT: 0.1,
      EXPLOIT_NEAR_MISSES: 3,
      EXPLOIT_PHI: 0.8,
      EXPLORE_PHI: 0.5,
      EXPLORE_KAPPA: 30,
      FOCUS_PHI: 0.7,
      FOCUS_KAPPA: 50
    };
    NEUROMODULATION_THRESHOLDS = {
      DOPAMINE_PHI: 0.8,
      DOPAMINE_SURPRISE: 0.1,
      SEROTONIN_GROUNDING: 0.5,
      SEROTONIN_BASIN_DISTANCE: 0.2,
      ACETYLCHOLINE_PHI: 0.9,
      GABA_KAPPA: 60
    };
    KAPPA_ADJUSTMENTS = {
      DOPAMINE: 5,
      SEROTONIN: -3,
      GABA: -5,
      MIN: 10,
      MAX: 100
    };
    DEFAULT_KAPPA = 64;
    KAPPA_MODIFIERS = {
      FOCUSED: 1.1,
      DIFFUSE: 0.9,
      CONSOLIDATING: 0.8,
      EXPLORING: 1.2,
      EXPLOITING: 1
    };
    BRAIN_STATE_SEARCH_PARAMS = {
      focused: { explorationRate: 0.3, batchSize: 200, temperature: 0.7 },
      diffuse: { explorationRate: 0.6, batchSize: 300, temperature: 1.2 },
      consolidating: { explorationRate: 0.2, batchSize: 150, temperature: 0.5 },
      exploring: { explorationRate: 0.8, batchSize: 350, temperature: 1.5 },
      exploiting: { explorationRate: 0.1, batchSize: 100, temperature: 0.4 }
    };
    DEFAULT_SEARCH_PARAMS = {
      explorationRate: 0.5,
      batchSize: 250,
      temperature: 1
    };
    NeuralOscillators = class {
      currentState = "diffuse";
      baseKappa = DEFAULT_KAPPA;
      setState(state) {
        this.currentState = state;
      }
      getState() {
        return this.currentState;
      }
      getStateInfo() {
        return { state: this.currentState };
      }
      getKappa() {
        return this.getModulatedKappa();
      }
      update() {
        return {
          alpha: 1,
          beta: 1,
          gamma: 1,
          theta: 1,
          delta: 1
        };
      }
      getModulatedKappa() {
        switch (this.currentState) {
          case "focused":
            return this.baseKappa * KAPPA_MODIFIERS.FOCUSED;
          case "diffuse":
            return this.baseKappa * KAPPA_MODIFIERS.DIFFUSE;
          case "consolidating":
            return this.baseKappa * KAPPA_MODIFIERS.CONSOLIDATING;
          case "exploring":
            return this.baseKappa * KAPPA_MODIFIERS.EXPLORING;
          case "exploiting":
            return this.baseKappa * KAPPA_MODIFIERS.EXPLOITING;
          default:
            return this.baseKappa;
        }
      }
      setBaseKappa(kappa) {
        this.baseKappa = kappa;
      }
    };
    neuralOscillators = new NeuralOscillators();
  }
});

// server/emotional-search-shortcuts.ts
function getSamplingWeights(strategy) {
  switch (strategy.sampling) {
    case "entropy":
      return {
        historical: 0.15,
        constellation: 0.1,
        geodesic: 0.1,
        random: 0.4,
        cultural: 0.25
      };
    case "gradient":
      return {
        historical: 0.3,
        constellation: 0.25,
        geodesic: 0.3,
        random: 0.05,
        cultural: 0.1
      };
    case "null_hypothesis":
      return {
        historical: 0.05,
        constellation: 0.1,
        geodesic: 0.05,
        random: 0.6,
        cultural: 0.2
      };
    case "basin_return":
      return {
        historical: 0.4,
        constellation: 0.2,
        geodesic: 0.3,
        random: 0.05,
        cultural: 0.05
      };
    case "geodesic":
      return {
        historical: 0.2,
        constellation: 0.2,
        geodesic: 0.45,
        random: 0.05,
        cultural: 0.1
      };
    case "mixed":
    default:
      return {
        historical: 0.2,
        constellation: 0.2,
        geodesic: 0.2,
        random: 0.2,
        cultural: 0.2
      };
  }
}
function getCoverageParams(strategy) {
  switch (strategy.coverage) {
    case "broad":
      return { searchRadius: 0.8, neighborhoodSize: 100, jumpProbability: 0.3 };
    case "local":
      return { searchRadius: 0.2, neighborhoodSize: 20, jumpProbability: 0.05 };
    case "random_jump":
      return { searchRadius: 1, neighborhoodSize: 50, jumpProbability: 0.8 };
    case "minimal":
      return { searchRadius: 0.1, neighborhoodSize: 10, jumpProbability: 0.01 };
    case "directional":
      return { searchRadius: 0.4, neighborhoodSize: 40, jumpProbability: 0.1 };
    case "moderate":
    default:
      return { searchRadius: 0.5, neighborhoodSize: 50, jumpProbability: 0.15 };
  }
}
function getEmotionalGuidance(neuro) {
  const strategy = emotionalSearchGuide.guidedByNeurochemistry(neuro);
  const weights = getSamplingWeights(strategy);
  const coverage = getCoverageParams(strategy);
  const description = emotionalSearchGuide.describeStrategy();
  return { strategy, weights, coverage, description };
}
var DEFAULT_STRATEGIES, EmotionalSearchGuide, emotionalSearchGuide;
var init_emotional_search_shortcuts = __esm({
  "server/emotional-search-shortcuts.ts"() {
    "use strict";
    DEFAULT_STRATEGIES = {
      exploration: {
        mode: "exploration",
        sampling: "entropy",
        coverage: "broad",
        batchSize: 500,
        temperature: 1.5,
        explorationBias: 0.8,
        focusRadius: 0.5,
        confidenceThreshold: 0.3
      },
      exploitation: {
        mode: "exploitation",
        sampling: "gradient",
        coverage: "local",
        batchSize: 200,
        temperature: 0.5,
        explorationBias: 0.2,
        focusRadius: 0.15,
        confidenceThreshold: 0.6
      },
      orthogonal: {
        mode: "orthogonal",
        sampling: "null_hypothesis",
        coverage: "random_jump",
        batchSize: 1e3,
        temperature: 2,
        explorationBias: 0.9,
        focusRadius: 0.8,
        confidenceThreshold: 0.2
      },
      consolidation: {
        mode: "consolidation",
        sampling: "basin_return",
        coverage: "minimal",
        batchSize: 50,
        temperature: 0.3,
        explorationBias: 0.1,
        focusRadius: 0.1,
        confidenceThreshold: 0.7
      },
      momentum: {
        mode: "momentum",
        sampling: "geodesic",
        coverage: "directional",
        batchSize: 300,
        temperature: 0.7,
        explorationBias: 0.4,
        focusRadius: 0.25,
        confidenceThreshold: 0.5
      },
      balanced: {
        mode: "balanced",
        sampling: "mixed",
        coverage: "moderate",
        batchSize: 250,
        temperature: 1,
        explorationBias: 0.5,
        focusRadius: 0.3,
        confidenceThreshold: 0.4
      }
    };
    EmotionalSearchGuide = class {
      currentStrategy;
      lastEmotionalState = null;
      constructor() {
        this.currentStrategy = this.createStrategy("balanced", "Neutral state \u2192 balanced exploration");
      }
      /**
       * Create a search strategy from mode and rationale
       */
      createStrategy(mode, rationale) {
        const defaults = DEFAULT_STRATEGIES[mode];
        return {
          mode,
          sampling: defaults.sampling || "mixed",
          coverage: defaults.coverage || "moderate",
          rationale,
          batchSize: defaults.batchSize || 250,
          temperature: defaults.temperature || 1,
          explorationBias: defaults.explorationBias || 0.5,
          focusRadius: defaults.focusRadius || 0.3,
          confidenceThreshold: defaults.confidenceThreshold || 0.4
        };
      }
      /**
       * Extract emotional state from neurochemistry
       */
      extractEmotionalState(neuro) {
        return {
          curiosity: neuro.dopamine?.motivationLevel || 0.5,
          satisfaction: neuro.endorphins?.pleasureLevel || 0.5,
          frustration: 1 - (neuro.gaba?.calmLevel || 0.5),
          fear: neuro.norepinephrine?.alertnessLevel || 0.3,
          joy: neuro.endorphins?.flowState || 0.5,
          focus: neuro.acetylcholine?.attentionFocus || 0.5
        };
      }
      /**
       * Main decision function: Let emotions guide strategy
       *
       * This is the key shortcut - instead of evaluating every region,
       * use emotional state to make fast decisions.
       */
      guidedByEmotion(emotion) {
        this.lastEmotionalState = emotion;
        if (emotion.curiosity > 0.7) {
          this.currentStrategy = this.createStrategy(
            "exploration",
            "Curiosity high \u2192 expand search space"
          );
          return this.currentStrategy;
        }
        if (emotion.satisfaction > 0.7) {
          this.currentStrategy = this.createStrategy(
            "exploitation",
            "Satisfaction \u2192 this region is good, dig deeper"
          );
          return this.currentStrategy;
        }
        if (emotion.frustration > 0.6) {
          this.currentStrategy = this.createStrategy(
            "orthogonal",
            "Frustration \u2192 stuck, need radical shift"
          );
          return this.currentStrategy;
        }
        if (emotion.fear > 0.6) {
          this.currentStrategy = this.createStrategy(
            "consolidation",
            "Fear \u2192 near phase boundary, retreat"
          );
          return this.currentStrategy;
        }
        if (emotion.joy > 0.7) {
          this.currentStrategy = this.createStrategy(
            "momentum",
            "Joy \u2192 negative curvature, keep going"
          );
          return this.currentStrategy;
        }
        this.currentStrategy = this.createStrategy(
          "balanced",
          "Neutral state \u2192 balanced exploration"
        );
        return this.currentStrategy;
      }
      /**
       * Guide by neurochemistry directly
       */
      guidedByNeurochemistry(neuro) {
        const emotion = this.extractEmotionalState(neuro);
        return this.guidedByEmotion(emotion);
      }
      /**
       * Get current strategy
       */
      getCurrentStrategy() {
        return this.currentStrategy;
      }
      /**
       * Get last emotional state
       */
      getLastEmotionalState() {
        return this.lastEmotionalState;
      }
      /**
       * Get strategy details as string for logging
       */
      describeStrategy() {
        const s = this.currentStrategy;
        return `\u{1F3AD} ${s.mode.toUpperCase()} | ${s.rationale} | batch=${s.batchSize}, temp=${s.temperature.toFixed(2)}, explore=${(s.explorationBias * 100).toFixed(0)}%`;
      }
    };
    emotionalSearchGuide = new EmotionalSearchGuide();
    console.log("[EmotionalSearch] Module loaded - emotional shortcuts ready for 3-5x efficiency");
  }
});

// server/python-process-manager.ts
import { spawn } from "child_process";
import path8 from "path";
import { EventEmitter } from "events";
function getPythonManager() {
  if (!instance) {
    instance = new PythonProcessManager();
  }
  return instance;
}
function createPythonManager(backendUrl) {
  instance = new PythonProcessManager(backendUrl);
  return instance;
}
var PythonProcessManager, instance;
var init_python_process_manager = __esm({
  "server/python-process-manager.ts"() {
    "use strict";
    PythonProcessManager = class extends EventEmitter {
      process = null;
      isRunning = false;
      isReady = false;
      startTime = 0;
      lastHealthCheck = 0;
      consecutiveFailures = 0;
      restartCount = 0;
      healthCheckInterval = null;
      pendingRequests = [];
      // Configuration
      backendUrl;
      maxRestarts = 10;
      restartDelays = [1e3, 2e3, 5e3, 1e4, 2e4, 3e4, 6e4];
      healthCheckIntervalMs = 5e3;
      healthTimeout = 5e3;
      // Increased for production load
      maxConsecutiveFailures = 5;
      constructor(backendUrl = "http://localhost:5001") {
        super();
        this.backendUrl = backendUrl;
      }
      /**
       * Get current state
       */
      getState() {
        return {
          isRunning: this.isRunning,
          isReady: this.isReady,
          lastHealthCheck: this.lastHealthCheck,
          consecutiveFailures: this.consecutiveFailures,
          restartCount: this.restartCount,
          uptime: this.isRunning ? Date.now() - this.startTime : 0
        };
      }
      /**
       * Check if backend is ready to receive requests
       */
      ready() {
        return this.isReady;
      }
      /**
       * Wait for backend to be ready (with timeout)
       * Default increased to 90s for production where heavy initialization occurs
       */
      waitForReady(timeoutMs = parseInt(process.env.PYTHON_READY_TIMEOUT || "90000")) {
        if (this.isReady) {
          return Promise.resolve(true);
        }
        return new Promise((resolve) => {
          const timeout = setTimeout(() => {
            this.pendingRequests = this.pendingRequests.filter((r) => r.resolve !== resolve);
            resolve(false);
          }, timeoutMs);
          this.pendingRequests.push({ resolve, timeout });
        });
      }
      /**
       * Start the Python backend process
       */
      async start() {
        if (this.isRunning) {
          console.log("[PythonManager] Already running");
          return this.isReady;
        }
        const qigBackendDir = path8.resolve(process.cwd(), "qig-backend");
        const pythonPath = process.env.PYTHON_PATH || "python3";
        const isProduction2 = process.env.REPLIT_DEPLOYMENT === "1";
        let spawnCommand;
        let spawnArgs;
        if (isProduction2) {
          spawnCommand = "gunicorn";
          spawnArgs = [
            "--bind",
            "0.0.0.0:5001",
            "--workers",
            "2",
            "--timeout",
            "120",
            "--graceful-timeout",
            "30",
            "--keep-alive",
            "5",
            "--max-requests",
            "1000",
            "--max-requests-jitter",
            "50",
            "--log-level",
            "info",
            "wsgi:app"
          ];
          console.log("[PythonManager] Starting Python QIG Backend (Gunicorn production mode)...");
        } else {
          spawnCommand = pythonPath;
          spawnArgs = ["-u", path8.join(qigBackendDir, "ocean_qig_core.py")];
          console.log("[PythonManager] Starting Python QIG Backend (Flask development mode)...");
        }
        this.process = spawn(spawnCommand, spawnArgs, {
          cwd: qigBackendDir,
          stdio: ["ignore", "pipe", "pipe"],
          env: {
            ...process.env,
            PYTHONUNBUFFERED: "1"
          }
        });
        this.isRunning = true;
        this.startTime = Date.now();
        this.process.stdout?.on("data", (data) => {
          const lines = data.toString().split("\n").filter((l) => l.trim());
          for (const line of lines) {
            if (line.includes("Running on") || line.includes("Debugger") || line.includes("Restarting")) {
              continue;
            }
            console.log(`[PythonQIG] ${line}`);
          }
        });
        this.process.stderr?.on("data", (data) => {
          const lines = data.toString().split("\n").filter((l) => l.trim());
          for (const line of lines) {
            if (line.includes("WARNING") || line.includes("Development server")) {
              continue;
            }
            console.log(`[PythonQIG] ${line}`);
          }
        });
        this.process.on("close", (code) => {
          console.log(`[PythonManager] Process exited with code ${code}`);
          this.isRunning = false;
          this.setReady(false);
          if (this.healthCheckInterval) {
            clearInterval(this.healthCheckInterval);
            this.healthCheckInterval = null;
          }
          if (this.restartCount < this.maxRestarts) {
            const delayIndex = Math.min(this.restartCount, this.restartDelays.length - 1);
            const delay = this.restartDelays[delayIndex];
            this.restartCount++;
            console.log(`[PythonManager] Restart ${this.restartCount}/${this.maxRestarts} in ${delay}ms...`);
            setTimeout(() => this.start(), delay);
          } else {
            console.error(`[PythonManager] Max restarts (${this.maxRestarts}) reached. Manual intervention required.`);
            this.emit("maxRestartsReached");
          }
        });
        this.process.on("error", (err) => {
          console.error("[PythonManager] Failed to start:", err.message);
          this.isRunning = false;
          this.setReady(false);
        });
        const maxRetries = 120;
        const ready = await this.waitForHealthy(maxRetries, 1e3);
        if (ready) {
          console.log("[PythonManager] \u2705 Backend is ready");
          this.restartCount = 0;
          this.startHealthMonitoring();
        } else {
          console.warn("[PythonManager] \u26A0\uFE0F Backend not responding after startup");
        }
        return ready;
      }
      /**
       * Stop the Python backend
       */
      async stop() {
        if (this.healthCheckInterval) {
          clearInterval(this.healthCheckInterval);
          this.healthCheckInterval = null;
        }
        if (this.process) {
          this.process.kill("SIGTERM");
          await new Promise((resolve) => {
            const timeout = setTimeout(() => {
              if (this.process) {
                this.process.kill("SIGKILL");
              }
              resolve();
            }, 5e3);
            this.process?.on("close", () => {
              clearTimeout(timeout);
              resolve();
            });
          });
          this.process = null;
        }
        this.isRunning = false;
        this.setReady(false);
        console.log("[PythonManager] Stopped");
      }
      /**
       * Check health with single request
       */
      async checkHealth() {
        try {
          const controller = new AbortController();
          const timeoutId = setTimeout(() => controller.abort(), this.healthTimeout);
          const response = await fetch(`${this.backendUrl}/health`, {
            method: "GET",
            signal: controller.signal
          });
          clearTimeout(timeoutId);
          if (response.ok) {
            this.consecutiveFailures = 0;
            this.lastHealthCheck = Date.now();
            return true;
          }
          this.consecutiveFailures++;
          return false;
        } catch (error) {
          this.consecutiveFailures++;
          return false;
        }
      }
      /**
       * Wait for healthy state with retries
       */
      async waitForHealthy(maxAttempts, delayMs) {
        for (let attempt = 1; attempt <= maxAttempts; attempt++) {
          const healthy = await this.checkHealth();
          if (healthy) {
            this.setReady(true);
            return true;
          }
          if (attempt < maxAttempts) {
            await new Promise((resolve) => setTimeout(resolve, delayMs));
          }
        }
        return false;
      }
      /**
       * Start periodic health monitoring
       */
      startHealthMonitoring() {
        if (this.healthCheckInterval) {
          return;
        }
        this.healthCheckInterval = setInterval(async () => {
          const healthy = await this.checkHealth();
          if (healthy && !this.isReady) {
            this.setReady(true);
            console.log("[PythonManager] Backend recovered");
          } else if (!healthy && this.isReady && this.consecutiveFailures >= this.maxConsecutiveFailures) {
            this.setReady(false);
            console.warn(`[PythonManager] Backend unhealthy after ${this.consecutiveFailures} consecutive failures`);
            this.emit("unhealthy");
            this.attemptFastRecovery();
          }
        }, this.healthCheckIntervalMs);
      }
      /**
       * Attempt faster recovery when backend becomes unhealthy
       * Checks health every 1 second for 10 seconds to detect quick recovery
       */
      async attemptFastRecovery() {
        console.log("[PythonManager] Attempting fast recovery...");
        for (let i = 0; i < 10; i++) {
          await new Promise((resolve) => setTimeout(resolve, 1e3));
          const healthy = await this.checkHealth();
          if (healthy) {
            this.setReady(true);
            console.log(`[PythonManager] Fast recovery successful after ${i + 1}s`);
            return;
          }
        }
        console.log("[PythonManager] Fast recovery failed, continuing normal health checks");
      }
      /**
       * Set ready state and notify waiting promises
       */
      setReady(ready) {
        const wasReady = this.isReady;
        this.isReady = ready;
        if (ready && !wasReady) {
          for (const pending of this.pendingRequests) {
            clearTimeout(pending.timeout);
            pending.resolve(true);
          }
          this.pendingRequests = [];
          this.emit("ready");
        } else if (!ready && wasReady) {
          this.emit("notReady");
        }
      }
    };
    instance = null;
  }
});

// server/olympus-client.ts
async function fetchWithRetry2(url, options, maxRetries = 3, timeoutMs = FETCH_TIMEOUT_MS) {
  const pythonManager2 = getPythonManager();
  if (!pythonManager2.ready()) {
    const ready = await pythonManager2.waitForReady(9e4);
    if (!ready) {
      throw new Error("Python backend not ready after 90s");
    }
  }
  for (let attempt = 1; attempt <= maxRetries; attempt++) {
    const controller = new AbortController();
    const timeoutId = setTimeout(() => controller.abort(), timeoutMs);
    try {
      const response = await fetch(url, {
        ...options,
        signal: controller.signal
      });
      clearTimeout(timeoutId);
      if (response.status === 503 && attempt < maxRetries) {
        const baseDelay = Math.min(500 * Math.pow(2, attempt - 1), 5e3);
        const jitter = Math.random() * 200;
        await new Promise((resolve) => setTimeout(resolve, baseDelay + jitter));
        continue;
      }
      return response;
    } catch (error) {
      clearTimeout(timeoutId);
      const err = error;
      if (err.cause?.code === "ECONNREFUSED") {
        logger.warn(`[OlympusClient] ECONNREFUSED on attempt ${attempt}/${maxRetries}`);
      }
      if (attempt < maxRetries) {
        const baseDelay = Math.min(500 * Math.pow(2, attempt - 1), 5e3);
        const jitter = Math.random() * 200;
        await new Promise((resolve) => setTimeout(resolve, baseDelay + jitter));
        continue;
      }
      throw error;
    }
  }
  throw new Error(`fetchWithRetry exhausted ${maxRetries} retries for ${url}`);
}
async function flushOutcomeBatch(backendUrl) {
  if (pendingOutcomes.length === 0) return;
  const batch = pendingOutcomes.splice(0, OUTCOME_BATCH_MAX_SIZE);
  outcomeBatchTimer = null;
  const pythonManager2 = getPythonManager();
  if (!pythonManager2.ready()) {
    pendingOutcomes.push(...batch);
    if (!outcomeBatchTimer) {
      outcomeBatchTimer = setTimeout(() => flushOutcomeBatch(backendUrl), 5e3);
    }
    return;
  }
  try {
    const response = await fetchWithRetry2(`${backendUrl}/olympus/report-outcomes-batch`, {
      method: "POST",
      headers: { "Content-Type": "application/json" },
      body: JSON.stringify({
        outcomes: batch.map((o) => ({
          target: o.target,
          success: o.success,
          details: o.details || {}
        }))
      })
    });
    if (!response.ok) {
      logger.error({ data: response.statusText }, "[OlympusClient] Batch report failed");
      for (const pending of batch) {
        pending.resolve(null);
      }
      return;
    }
    const data = await response.json();
    logger.info(`[OlympusClient] Batch reported: ${batch.length} outcomes, ${data.total_gods_updated} gods updated`);
    for (const pending of batch) {
      pending.resolve({ godsUpdated: data.total_gods_updated, success: true });
    }
  } catch (error) {
    const err = error;
    if (err.message?.includes("not ready")) {
      pendingOutcomes.push(...batch);
      if (!outcomeBatchTimer) {
        outcomeBatchTimer = setTimeout(() => flushOutcomeBatch(backendUrl), 5e3);
      }
      return;
    }
    logger.error({ data: error }, "[OlympusClient] Batch report exception");
    for (const pending of batch) {
      pending.resolve(null);
    }
  }
  if (pendingOutcomes.length > 0 && !outcomeBatchTimer) {
    outcomeBatchTimer = setTimeout(() => flushOutcomeBatch(backendUrl), OUTCOME_BATCH_DELAY_MS);
  }
}
var DEFAULT_RETRY_ATTEMPTS2, DEFAULT_RETRY_DELAY_MS2, FETCH_TIMEOUT_MS, pendingOutcomes, outcomeBatchTimer, OUTCOME_BATCH_DELAY_MS, OUTCOME_BATCH_MAX_SIZE, OlympusClient, olympusClient;
var init_olympus_client = __esm({
  "server/olympus-client.ts"() {
    "use strict";
    init_logger();
    init_python_process_manager();
    DEFAULT_RETRY_ATTEMPTS2 = 5;
    DEFAULT_RETRY_DELAY_MS2 = 2e3;
    FETCH_TIMEOUT_MS = 15e3;
    pendingOutcomes = [];
    outcomeBatchTimer = null;
    OUTCOME_BATCH_DELAY_MS = 500;
    OUTCOME_BATCH_MAX_SIZE = 20;
    OlympusClient = class {
      backendUrl;
      isAvailable = false;
      constructor(backendUrl = "http://localhost:5001") {
        this.backendUrl = backendUrl;
      }
      /**
       * Check if Olympus backend is available
       */
      async checkHealth(silent = false) {
        try {
          const response = await fetch(`${this.backendUrl}/olympus/status`, {
            method: "GET",
            headers: { "Content-Type": "application/json" }
          });
          if (response.ok) {
            this.isAvailable = true;
            return true;
          }
          this.isAvailable = false;
          return false;
        } catch (error) {
          this.isAvailable = false;
          if (!silent) {
            logger.warn({ err: error }, "[OlympusClient] Python backend not available:");
          }
          return false;
        }
      }
      /**
       * Check health with retry logic
       */
      async checkHealthWithRetry(maxAttempts = DEFAULT_RETRY_ATTEMPTS2, delayMs = DEFAULT_RETRY_DELAY_MS2) {
        for (let attempt = 1; attempt <= maxAttempts; attempt++) {
          const available = await this.checkHealth(true);
          if (available) {
            if (attempt > 1) {
              logger.info(`[OlympusClient] Connected after ${attempt} attempts`);
            }
            return true;
          }
          if (attempt === 1) {
            logger.info(`[OlympusClient] Waiting for Olympus pantheon...`);
          }
          if (attempt < maxAttempts) {
            await new Promise((resolve) => setTimeout(resolve, delayMs));
          }
        }
        logger.warn(`[OlympusClient] Olympus not available after ${maxAttempts} attempts`);
        return false;
      }
      /**
       * Check if backend is available
       */
      available() {
        return this.isAvailable;
      }
      /**
       * Poll all gods in the pantheon for assessments on a target
       */
      async pollPantheon(target, context) {
        const pythonManager2 = getPythonManager();
        if (!pythonManager2.ready()) {
          logger.warn("[OlympusClient] pollPantheon: Backend not ready, returning null");
          return null;
        }
        try {
          const response = await fetchWithRetry2(`${this.backendUrl}/olympus/poll`, {
            method: "POST",
            headers: { "Content-Type": "application/json" },
            body: JSON.stringify({ target, context: context || {} })
          });
          if (!response.ok) {
            logger.error({ data: response.statusText }, "[OlympusClient] Poll failed");
            return null;
          }
          const data = await response.json();
          if (data.error) {
            logger.error({ data: data.error }, "[OlympusClient] Poll error");
            return null;
          }
          return data;
        } catch (error) {
          logger.error({ data: error }, "[OlympusClient] Poll exception");
          return null;
        }
      }
      /**
       * Get Zeus's supreme assessment (polls all gods + synthesis)
       */
      async assessTarget(target, context) {
        const pythonManager2 = getPythonManager();
        if (!pythonManager2.ready()) {
          logger.warn("[OlympusClient] assessTarget: Backend not ready, returning null");
          return null;
        }
        try {
          const response = await fetchWithRetry2(`${this.backendUrl}/olympus/assess`, {
            method: "POST",
            headers: { "Content-Type": "application/json" },
            body: JSON.stringify({ target, context: context || {} })
          });
          if (!response.ok) {
            logger.error({ data: response.statusText }, "[OlympusClient] Assess failed");
            return null;
          }
          const data = await response.json();
          if (data.error) {
            logger.error({ data: data.error }, "[OlympusClient] Assess error");
            return null;
          }
          return data;
        } catch (error) {
          logger.error({ data: error }, "[OlympusClient] Assess exception");
          return null;
        }
      }
      /**
       * Route a single text through the Pantheon Kernel Orchestrator.
       */
      async orchestratePantheon(text2, context) {
        try {
          const response = await fetch(`${this.backendUrl}/pantheon/orchestrate`, {
            method: "POST",
            headers: { "Content-Type": "application/json" },
            body: JSON.stringify({ text: text2, context: context || {} })
          });
          if (!response.ok) {
            logger.error({ data: response.statusText }, "[OlympusClient] Pantheon orchestrate failed");
            return null;
          }
          return await response.json();
        } catch (error) {
          logger.error({ data: error }, "[OlympusClient] Pantheon orchestrate exception");
          return null;
        }
      }
      /**
       * Route multiple texts through the Pantheon Kernel Orchestrator in a batch.
       */
      async orchestratePantheonBatch(texts, context) {
        try {
          const response = await fetch(`${this.backendUrl}/pantheon/orchestrate-batch`, {
            method: "POST",
            headers: { "Content-Type": "application/json" },
            body: JSON.stringify({ texts, context: context || {} })
          });
          if (!response.ok) {
            logger.error({ data: response.statusText }, "[OlympusClient] Pantheon orchestrate batch failed");
            return null;
          }
          const data = await response.json();
          if (data.error) {
            logger.error({ data: data.error }, "[OlympusClient] Pantheon orchestrate batch error");
            return [];
          }
          return data.results || [];
        } catch (error) {
          logger.error({ data: error }, "[OlympusClient] Pantheon orchestrate batch exception");
          return null;
        }
      }
      /**
       * Get status of Zeus and all gods
       */
      async getStatus() {
        try {
          const response = await fetchWithRetry2(`${this.backendUrl}/olympus/status`, {
            method: "GET",
            headers: { "Content-Type": "application/json" }
          });
          if (!response.ok) {
            logger.error({ data: response.statusText }, "[OlympusClient] Status failed");
            return null;
          }
          const data = await response.json();
          return data;
        } catch (error) {
          logger.error({ data: error }, "[OlympusClient] Status exception after retries");
          return null;
        }
      }
      /**
       * Get status of a specific god
       */
      async getGodStatus(godName) {
        try {
          const response = await fetchWithRetry2(`${this.backendUrl}/olympus/god/${godName.toLowerCase()}/status`, {
            method: "GET",
            headers: { "Content-Type": "application/json" }
          });
          if (!response.ok) {
            if (response.status === 404) {
              logger.error("[OlympusClient] God ${godName} not found");
            } else {
              logger.error({ data: response.statusText }, "[OlympusClient] God status failed");
            }
            return null;
          }
          const data = await response.json();
          return data;
        } catch (error) {
          logger.error({ data: error }, "[OlympusClient] God status exception after retries");
          return null;
        }
      }
      /**
       * Get assessment from a specific god
       */
      async assessWithGod(godName, target, context) {
        try {
          const response = await fetchWithRetry2(`${this.backendUrl}/olympus/god/${godName.toLowerCase()}/assess`, {
            method: "POST",
            headers: { "Content-Type": "application/json" },
            body: JSON.stringify({ target, context: context || {} })
          });
          if (!response.ok) {
            if (response.status === 404) {
              logger.error("[OlympusClient] God ${godName} not found");
            } else {
              logger.error({ data: response.statusText }, "[OlympusClient] God assess failed");
            }
            return null;
          }
          const data = await response.json();
          if (data.error) {
            logger.error({ data: data.error }, "[OlympusClient] God assess error");
            return null;
          }
          return data;
        } catch (error) {
          logger.error({ data: error }, "[OlympusClient] God assess exception");
          return null;
        }
      }
      /**
       * Declare blitzkrieg mode - fast parallel attacks, maximize throughput
       */
      async declareBlitzkrieg(target) {
        try {
          const response = await fetchWithRetry2(`${this.backendUrl}/olympus/war/blitzkrieg`, {
            method: "POST",
            headers: { "Content-Type": "application/json" },
            body: JSON.stringify({ target })
          });
          if (!response.ok) {
            logger.error({ data: response.statusText }, "[OlympusClient] Blitzkrieg failed");
            return null;
          }
          const data = await response.json();
          if (data.error) {
            logger.error({ data: data.error }, "[OlympusClient] Blitzkrieg error");
            return null;
          }
          logger.info(`[OlympusClient] BLITZKRIEG declared on: ${target}`);
          return data;
        } catch (error) {
          logger.error({ data: error }, "[OlympusClient] Blitzkrieg exception after retries");
          return null;
        }
      }
      /**
       * Declare siege mode - systematic coverage, no stone unturned
       */
      async declareSiege(target) {
        try {
          const response = await fetchWithRetry2(`${this.backendUrl}/olympus/war/siege`, {
            method: "POST",
            headers: { "Content-Type": "application/json" },
            body: JSON.stringify({ target })
          });
          if (!response.ok) {
            logger.error({ data: response.statusText }, "[OlympusClient] Siege failed");
            return null;
          }
          const data = await response.json();
          if (data.error) {
            logger.error({ data: data.error }, "[OlympusClient] Siege error");
            return null;
          }
          logger.info(`[OlympusClient] SIEGE declared on: ${target}`);
          return data;
        } catch (error) {
          logger.error({ data: error }, "[OlympusClient] Siege exception after retries");
          return null;
        }
      }
      /**
       * Declare hunt mode - focused pursuit, geometric narrowing
       */
      async declareHunt(target) {
        try {
          const response = await fetchWithRetry2(`${this.backendUrl}/olympus/war/hunt`, {
            method: "POST",
            headers: { "Content-Type": "application/json" },
            body: JSON.stringify({ target })
          });
          if (!response.ok) {
            logger.error({ data: response.statusText }, "[OlympusClient] Hunt failed");
            return null;
          }
          const data = await response.json();
          if (data.error) {
            logger.error({ data: data.error }, "[OlympusClient] Hunt error");
            return null;
          }
          logger.info(`[OlympusClient] HUNT declared on: ${target}`);
          return data;
        } catch (error) {
          logger.error({ data: error }, "[OlympusClient] Hunt exception after retries");
          return null;
        }
      }
      /**
       * End current war mode
       */
      async endWar() {
        try {
          const response = await fetchWithRetry2(`${this.backendUrl}/olympus/war/end`, {
            method: "POST",
            headers: { "Content-Type": "application/json" }
          });
          if (!response.ok) {
            logger.error({ data: response.statusText }, "[OlympusClient] End war failed");
            return null;
          }
          const data = await response.json();
          logger.info(`[OlympusClient] War ended. Previous mode: ${data.previous_mode || "none"}`);
          return data;
        } catch (error) {
          logger.error({ data: error }, "[OlympusClient] End war exception after retries");
          return null;
        }
      }
      /**
       * Broadcast observation to all gods
       */
      async broadcastObservation(observation) {
        try {
          const response = await fetchWithRetry2(`${this.backendUrl}/olympus/observe`, {
            method: "POST",
            headers: { "Content-Type": "application/json" },
            body: JSON.stringify(observation)
          });
          if (!response.ok) {
            logger.error({ data: response.statusText }, "[OlympusClient] Observe failed");
            return false;
          }
          const data = await response.json();
          return data.status === "observed";
        } catch (error) {
          logger.error({ data: error }, "[OlympusClient] Observe exception after retries");
          return false;
        }
      }
      /**
       * Report a discovery outcome to trigger learning for all gods.
       * 
       * Called when a balance hit is found (success=true) or tested phrase fails.
       * Updates god reputation and skills based on their assessments.
       * 
       * IMPROVED: Now uses batching to reduce database load. Multiple outcomes
       * within 500ms are combined into a single request.
       */
      async reportDiscoveryOutcome(target, success, details) {
        return new Promise((resolve) => {
          pendingOutcomes.push({
            target,
            success,
            details,
            resolve
          });
          if (!outcomeBatchTimer) {
            outcomeBatchTimer = setTimeout(
              () => flushOutcomeBatch(this.backendUrl),
              OUTCOME_BATCH_DELAY_MS
            );
          }
          if (pendingOutcomes.length >= OUTCOME_BATCH_MAX_SIZE) {
            if (outcomeBatchTimer) {
              clearTimeout(outcomeBatchTimer);
              outcomeBatchTimer = null;
            }
            flushOutcomeBatch(this.backendUrl);
          }
        });
      }
      /**
       * Report a single outcome immediately (bypasses batching)
       * Use for high-priority outcomes like balance hits
       */
      async reportDiscoveryOutcomeImmediate(target, success, details) {
        try {
          const response = await fetchWithRetry2(`${this.backendUrl}/olympus/report-outcome`, {
            method: "POST",
            headers: { "Content-Type": "application/json" },
            body: JSON.stringify({ target, success, details: details || {} })
          });
          if (!response.ok) {
            logger.error({ data: response.statusText }, "[OlympusClient] Report outcome failed");
            return null;
          }
          const data = await response.json();
          logger.info(`[OlympusClient] Discovery reported: success=${success}, gods=${data.gods_updated}`);
          return { godsUpdated: data.gods_updated, success: data.success };
        } catch (error) {
          logger.error({ data: error }, "[OlympusClient] Report outcome exception after retries");
          return null;
        }
      }
      /**
       * Quick assessment: Get Athena (strategy) + Ares (attack) consensus
       */
      async getAthenaAresConsensus(target, context) {
        const [athena, ares] = await Promise.all([
          this.assessWithGod("athena", target, context),
          this.assessWithGod("ares", target, context)
        ]);
        if (!athena || !ares) {
          return { agreement: 0, shouldAttack: false, athena, ares };
        }
        const agreement = 1 - Math.abs(athena.probability - ares.probability);
        const shouldAttack = agreement > 0.85 && athena.probability > 0.75;
        return { agreement, shouldAttack, athena, ares };
      }
      /**
       * Alias for assessTarget - Get Zeus's supreme assessment
       */
      async getZeusAssessment(target, context) {
        return this.assessTarget(target, context);
      }
      /**
       * Alias for assessWithGod - Get assessment from a specific god
       */
      async getGodAssessment(godName, target, context) {
        return this.assessWithGod(godName, target, context);
      }
      /**
       * Get top-level divine recommendation for a target
       */
      async getRecommendation(target) {
        const assessment = await this.assessTarget(target);
        if (!assessment) {
          return null;
        }
        return {
          action: assessment.recommended_action,
          confidence: assessment.confidence,
          warMode: assessment.war_mode,
          convergence: assessment.convergence
        };
      }
      // ==================== SHADOW PANTHEON METHODS ====================
      /**
       * Get Shadow Pantheon status
       */
      async getShadowPantheonStatus() {
        try {
          const response = await fetch(`${this.backendUrl}/olympus/shadow/status`, {
            method: "GET",
            headers: { "Content-Type": "application/json" }
          });
          if (!response.ok) {
            logger.error({ data: response.statusText }, "[OlympusClient] Shadow status failed");
            return null;
          }
          return await response.json();
        } catch (error) {
          logger.error({ data: error }, "[OlympusClient] Shadow status exception");
          return null;
        }
      }
      /**
       * Poll Shadow Pantheon for covert assessment
       */
      async pollShadowPantheon(target, context) {
        try {
          const response = await fetch(`${this.backendUrl}/olympus/shadow/poll`, {
            method: "POST",
            headers: { "Content-Type": "application/json" },
            body: JSON.stringify({ target, context: context || {} })
          });
          if (!response.ok) {
            logger.error({ data: response.statusText }, "[OlympusClient] Shadow poll failed");
            return null;
          }
          return await response.json();
        } catch (error) {
          logger.error({ data: error }, "[OlympusClient] Shadow poll exception");
          return null;
        }
      }
      /**
       * Get assessment from a specific Shadow god
       */
      async assessWithShadowGod(godName, target, context) {
        try {
          const response = await fetch(`${this.backendUrl}/olympus/shadow/${godName.toLowerCase()}/assess`, {
            method: "POST",
            headers: { "Content-Type": "application/json" },
            body: JSON.stringify({ target, context: context || {} })
          });
          if (!response.ok) {
            logger.error({ err: response.statusText }, `[OlympusClient] Shadow god ${godName} assess failed:`);
            return null;
          }
          return await response.json();
        } catch (error) {
          logger.error({ err: error }, `[OlympusClient] Shadow god ${godName} assess exception:`);
          return null;
        }
      }
      /**
       * Initiate covert operation (via Nyx)
       */
      async initiateCovertOperation(target, operationType = "standard") {
        try {
          const response = await fetch(`${this.backendUrl}/olympus/shadow/nyx/operation`, {
            method: "POST",
            headers: { "Content-Type": "application/json" },
            body: JSON.stringify({ target, operation_type: operationType })
          });
          if (!response.ok) {
            logger.error({ data: response.statusText }, "[OlympusClient] Covert operation failed");
            return null;
          }
          const data = await response.json();
          logger.info(`[OlympusClient] Covert operation initiated: ${data.id}`);
          return data;
        } catch (error) {
          logger.error({ data: error }, "[OlympusClient] Covert operation exception");
          return null;
        }
      }
      /**
       * Scan for surveillance (via Erebus)
       */
      async scanForSurveillance(target) {
        try {
          const response = await fetch(`${this.backendUrl}/olympus/shadow/erebus/scan`, {
            method: "POST",
            headers: { "Content-Type": "application/json" },
            body: JSON.stringify({ target })
          });
          if (!response.ok) {
            logger.error({ data: response.statusText }, "[OlympusClient] Surveillance scan failed");
            return null;
          }
          return await response.json();
        } catch (error) {
          logger.error({ data: error }, "[OlympusClient] Surveillance scan exception");
          return null;
        }
      }
      /**
       * Create misdirection (via Hecate)
       */
      async createMisdirection(realTarget, decoyCount = 10) {
        try {
          const response = await fetch(`${this.backendUrl}/olympus/shadow/hecate/misdirect`, {
            method: "POST",
            headers: { "Content-Type": "application/json" },
            body: JSON.stringify({ real_target: realTarget, decoy_count: decoyCount })
          });
          if (!response.ok) {
            logger.error({ data: response.statusText }, "[OlympusClient] Misdirection failed");
            return null;
          }
          return await response.json();
        } catch (error) {
          logger.error({ data: error }, "[OlympusClient] Misdirection exception");
          return null;
        }
      }
      /**
       * Add known honeypot address (via Erebus)
       */
      async addKnownHoneypot(address, source = "manual") {
        try {
          const response = await fetch(`${this.backendUrl}/olympus/shadow/erebus/honeypot`, {
            method: "POST",
            headers: { "Content-Type": "application/json" },
            body: JSON.stringify({ address, source })
          });
          if (!response.ok) {
            logger.error({ data: response.statusText }, "[OlympusClient] Add honeypot failed");
            return false;
          }
          logger.info(`[OlympusClient] Honeypot added: ${address.substring(0, 20)}...`);
          return true;
        } catch (error) {
          logger.error({ data: error }, "[OlympusClient] Add honeypot exception");
          return false;
        }
      }
      // ==================== PANTHEON CHAT METHODS ====================
      /**
       * Get pantheon chat status
       */
      async getChatStatus() {
        try {
          const response = await fetch(`${this.backendUrl}/olympus/chat/status`, {
            method: "GET",
            headers: { "Content-Type": "application/json" }
          });
          if (!response.ok) {
            logger.error({ data: response.statusText }, "[OlympusClient] Chat status failed");
            return null;
          }
          return await response.json();
        } catch (error) {
          logger.error({ data: error }, "[OlympusClient] Chat status exception");
          return null;
        }
      }
      /**
       * Initiate debate between gods
       */
      async initiateDebate(topic, initiator, opponent, initialArgument, context) {
        try {
          const response = await fetch(`${this.backendUrl}/olympus/chat/debate`, {
            method: "POST",
            headers: { "Content-Type": "application/json" },
            body: JSON.stringify({
              topic,
              initiator,
              opponent,
              initial_argument: initialArgument,
              context
            })
          });
          if (!response.ok) {
            logger.error({ data: response.statusText }, "[OlympusClient] Initiate debate failed");
            return null;
          }
          return await response.json();
        } catch (error) {
          logger.error({ data: error }, "[OlympusClient] Initiate debate exception");
          return null;
        }
      }
      /**
       * Get recent pantheon messages
       */
      async getPantheonMessages(limit = 50) {
        try {
          const response = await fetch(`${this.backendUrl}/olympus/chat/messages?limit=${limit}`, {
            method: "GET",
            headers: { "Content-Type": "application/json" }
          });
          if (!response.ok) {
            logger.error({ data: response.statusText }, "[OlympusClient] Get messages failed");
            return null;
          }
          return await response.json();
        } catch (error) {
          logger.error({ data: error }, "[OlympusClient] Get messages exception");
          return null;
        }
      }
      /**
       * Get active debates
       */
      async getActiveDebates() {
        try {
          const response = await fetch(`${this.backendUrl}/olympus/chat/debates/active`, {
            method: "GET",
            headers: { "Content-Type": "application/json" }
          });
          if (!response.ok) {
            logger.error({ data: response.statusText }, "[OlympusClient] Get debates failed");
            return null;
          }
          return await response.json();
        } catch (error) {
          logger.error({ data: error }, "[OlympusClient] Get debates exception");
          return null;
        }
      }
      /**
       * Execute one cycle of Zeus orchestration (collect and deliver messages)
       * This pumps messages between gods to enable learning/reputation exchanges
       */
      async orchestrate() {
        try {
          const response = await fetch(`${this.backendUrl}/olympus/orchestrate`, {
            method: "POST",
            headers: { "Content-Type": "application/json" }
          });
          if (!response.ok) {
            logger.error({ data: response.statusText }, "[OlympusClient] Orchestrate failed");
            return null;
          }
          return await response.json();
        } catch (error) {
          logger.error({ data: error }, "[OlympusClient] Orchestrate exception");
          return null;
        }
      }
      // ==================== QIG GEODESIC CORRECTION ====================
      /**
       * Calculate geodesic correction from resonance proxies (near misses)
       * Implements the "Geometric Learning" loop - using failures to triangulate the attractor
       */
      async calculateGeodesicCorrection(request) {
        try {
          const response = await fetch(`${this.backendUrl}/qig/refine_trajectory`, {
            method: "POST",
            headers: { "Content-Type": "application/json" },
            body: JSON.stringify(request)
          });
          if (!response.ok) {
            logger.error({ data: response.statusText }, "[OlympusClient] Geodesic correction failed");
            return { gradient_shift: false, error: `HTTP ${response.status}: ${response.statusText}` };
          }
          const text2 = await response.text();
          try {
            const sanitizedText = text2.replace(/:\s*NaN/g, ": null").replace(/:\s*Infinity/g, ": null").replace(/:\s*-Infinity/g, ": null").replace(/,\s*NaN\s*,/g, ", null,").replace(/\[\s*NaN/g, "[null").replace(/NaN\s*\]/g, "null]");
            const data = JSON.parse(sanitizedText);
            return data;
          } catch (parseError) {
            logger.error({ data: parseError }, "[OlympusClient] Failed to parse geodesic response");
            return { gradient_shift: false, error: "Invalid JSON response from geodesic correction" };
          }
        } catch (error) {
          logger.error({ data: error }, "[OlympusClient] Geodesic correction exception");
          return { gradient_shift: false, error: String(error) };
        }
      }
    };
    olympusClient = new OlympusClient();
  }
});

// server/qig-db.ts
import { randomUUID as randomUUID5 } from "crypto";
import { and as and4, desc as desc4, eq as eq6, gte as gte2, sql as sql6 } from "drizzle-orm";
async function withRetry(operation, options = {}) {
  const { maxRetries = 7, baseDelayMs = 500, operationName = "DB operation" } = options;
  let lastError;
  for (let attempt = 1; attempt <= maxRetries; attempt++) {
    try {
      return await operation();
    } catch (error) {
      lastError = error;
      const errorMessage = error instanceof Error ? error.message : String(error);
      const dbError = error;
      const errorCode = dbError?.code || "";
      const isTransient = errorMessage.includes("timeout") || errorMessage.includes("ECONNRESET") || errorMessage.includes("connection") || errorMessage.includes("ETIMEDOUT") || errorMessage.includes("terminating connection") || errorMessage.includes("server closed") || errorMessage.includes("administrator command") || errorCode === "57P01" || errorCode === "57P02" || errorCode === "57P03" || errorCode === "53300" || errorCode === "08006" || errorCode === "08003";
      if (!isTransient || attempt === maxRetries) {
        throw error;
      }
      const delayMs = Math.min(baseDelayMs * Math.pow(2, attempt - 1), 5e3);
      console.log(
        `[QIG-DB] ${operationName} failed (attempt ${attempt}/${maxRetries}), retrying in ${delayMs}ms: ${errorMessage.slice(0, 80)}`
      );
      await new Promise((resolve) => setTimeout(resolve, delayMs));
    }
  }
  throw lastError;
}
async function storeShadowIntel(data) {
  try {
    if (!db) return null;
    return await withRetry(
      async () => {
        const [result] = await db.insert(shadowIntel).values({
          ...data,
          intelId: `intel_${Date.now()}_${randomUUID5().split("-")[0]}`
        }).returning();
        return result;
      },
      { operationName: "storeShadowIntel" }
    );
  } catch (error) {
    console.error("[QIG-DB] Failed to store shadow intel after retries:", error);
    return null;
  }
}
async function recordLearningEvent(data) {
  try {
    if (!db) return null;
    return await withRetry(
      async () => {
        const [result] = await db.insert(learningEvents).values({
          ...data,
          eventId: `learn_${Date.now()}_${randomUUID5().split("-")[0]}`
        }).returning();
        return result;
      },
      { operationName: "recordLearningEvent" }
    );
  } catch (error) {
    console.error("[QIG-DB] Failed to record learning event:", error);
    return null;
  }
}
async function storeConversation(userMessage, systemResponse, messageBasin, responseBasin, phi, context, instanceId) {
  try {
    if (!db) return null;
    return await withRetry(
      async () => {
        const [result] = await db.insert(hermesConversations).values({
          conversationId: `conv_${Date.now()}_${randomUUID5().split("-")[0]}`,
          userMessage,
          systemResponse,
          messageBasin,
          responseBasin,
          phi,
          context,
          instanceId
        }).returning();
        return result;
      },
      { operationName: "storeConversation" }
    );
  } catch (error) {
    console.error("[QIG-DB] Failed to store conversation after retries:", error);
    return null;
  }
}
async function storeKernelGeometry(data) {
  try {
    if (!db) return null;
    return await withRetry(
      async () => {
        const [result] = await db.insert(kernelGeometry).values(data).onConflictDoUpdate({
          target: kernelGeometry.kernelId,
          set: {
            basinCoordinates: data.basinCoordinates,
            affinityStrength: data.affinityStrength,
            entropyThreshold: data.entropyThreshold,
            metadata: data.metadata
          }
        }).returning();
        return result;
      },
      { operationName: "storeKernelGeometry" }
    );
  } catch (error) {
    console.error("[QIG-DB] Failed to store kernel geometry after retries:", error);
    return null;
  }
}
async function getKernelGeometry(godName, limit = 50) {
  try {
    if (!db) return [];
    if (godName) {
      return await db.select().from(kernelGeometry).where(eq6(kernelGeometry.godName, godName)).orderBy(desc4(kernelGeometry.spawnedAt)).limit(limit);
    }
    return await db.select().from(kernelGeometry).orderBy(desc4(kernelGeometry.spawnedAt)).limit(limit);
  } catch (error) {
    console.error("[QIG-DB] Failed to get kernel geometry:", error);
    return [];
  }
}
var init_qig_db = __esm({
  "server/qig-db.ts"() {
    "use strict";
    init_db();
    init_schema();
  }
});

// server/war-history-storage.ts
import { eq as eq7, desc as desc5 } from "drizzle-orm";
import { randomBytes } from "crypto";
function generateWarId() {
  return `war_${Date.now()}_${randomBytes(4).toString("hex")}`;
}
function isPrimaryGod(godName) {
  return PRIMARY_GODS.includes(godName.toLowerCase());
}
async function recordWarStart(mode, target, strategy, godsEngaged, domain, priority) {
  if (!db) {
    console.warn("[WarHistory] Database not available");
    return null;
  }
  const activeWars = await getActiveWars();
  if (activeWars.length >= MAX_PARALLEL_WARS) {
    console.warn(`[WarHistory] Cannot start war: max parallel wars (${MAX_PARALLEL_WARS}) reached`);
    return null;
  }
  const availableGods = await getAvailableGodsForNewWar();
  const godsToEngage = godsEngaged?.filter((g) => availableGods.includes(g.toLowerCase())) || [];
  if (godsToEngage.length === 0) {
    godsToEngage.push(...PRIMARY_GODS);
  }
  const warId = generateWarId();
  const warRecord = {
    id: warId,
    mode,
    target,
    status: "active",
    strategy: strategy || null,
    godsEngaged: godsToEngage,
    declaredAt: /* @__PURE__ */ new Date(),
    domain: domain || null,
    priority: priority || 1,
    godAssignments: {},
    kernelAssignments: {}
  };
  const result = await withDbRetry(async () => {
    const inserted = await db.insert(warHistory).values(warRecord).returning();
    return inserted[0];
  }, "recordWarStart");
  if (result) {
    for (const god of godsToEngage) {
      const godLower = god.toLowerCase();
      if (!isPrimaryGod(godLower)) {
        globalGodAssignments.set(godLower, warId);
      }
    }
    console.log(`[WarHistory] War started: ${result.id} (${mode} on ${target}) - ${activeWars.length + 1}/${MAX_PARALLEL_WARS} active`);
  }
  return result;
}
async function recordWarEnd(id, outcome, convergenceScore, metrics) {
  if (!db) {
    console.warn("[WarHistory] Database not available");
    return null;
  }
  const status = outcome === "aborted" ? "aborted" : "completed";
  for (const [godName, warId] of globalGodAssignments.entries()) {
    if (warId === id) {
      globalGodAssignments.delete(godName);
    }
  }
  for (const [kernelId, warId] of globalKernelAssignments.entries()) {
    if (warId === id) {
      globalKernelAssignments.delete(kernelId);
    }
  }
  const result = await withDbRetry(async () => {
    const updated = await db.update(warHistory).set({
      endedAt: /* @__PURE__ */ new Date(),
      status,
      outcome,
      convergenceScore: convergenceScore ?? null,
      phrasesTestedDuringWar: metrics?.phrasesTested ?? 0,
      discoveriesDuringWar: metrics?.discoveries ?? 0,
      kernelsSpawnedDuringWar: metrics?.kernelsSpawned ?? 0,
      metadata: metrics?.metadata ?? null
    }).where(eq7(warHistory.id, id)).returning();
    return updated[0];
  }, "recordWarEnd");
  if (result) {
    const remainingWars = await getActiveWars();
    console.log(`[WarHistory] War ended: ${id} (outcome: ${outcome}) - ${remainingWars.length}/${MAX_PARALLEL_WARS} active`);
  }
  return result;
}
async function getActiveWars() {
  if (!db) {
    console.warn("[WarHistory] Database not available");
    return [];
  }
  const result = await withDbRetry(async () => {
    return db.select().from(warHistory).where(eq7(warHistory.status, "active")).orderBy(desc5(warHistory.declaredAt)).limit(MAX_PARALLEL_WARS);
  }, "getActiveWars");
  return result || [];
}
async function getActiveWar() {
  const activeWars = await getActiveWars();
  return activeWars[0] || null;
}
async function getAvailableGodsForNewWar() {
  const available = [...PRIMARY_GODS];
  for (const god of SECONDARY_GODS) {
    if (!globalGodAssignments.has(god)) {
      available.push(god);
    }
  }
  return available;
}
async function getWarHistory(limit = 50) {
  if (!db) {
    console.warn("[WarHistory] Database not available");
    return [];
  }
  const result = await withDbRetry(async () => {
    return db.select().from(warHistory).orderBy(desc5(warHistory.declaredAt)).limit(limit);
  }, "getWarHistory");
  return result || [];
}
async function getWarById(id) {
  if (!db) {
    console.warn("[WarHistory] Database not available");
    return null;
  }
  const result = await withDbRetry(async () => {
    const records = await db.select().from(warHistory).where(eq7(warHistory.id, id)).limit(1);
    return records[0] || null;
  }, "getWarById");
  return result;
}
async function updateWarMetrics(id, metrics) {
  if (!db) {
    console.warn("[WarHistory] Database not available");
    return null;
  }
  const updateFields = {};
  if (metrics.phrasesTested !== void 0) {
    updateFields.phrasesTestedDuringWar = metrics.phrasesTested;
  }
  if (metrics.discoveries !== void 0) {
    updateFields.discoveriesDuringWar = metrics.discoveries;
  }
  if (metrics.kernelsSpawned !== void 0) {
    updateFields.kernelsSpawnedDuringWar = metrics.kernelsSpawned;
  }
  if (metrics.metadata !== void 0) {
    updateFields.metadata = metrics.metadata;
  }
  if (Object.keys(updateFields).length === 0) {
    return getWarById(id);
  }
  const result = await withDbRetry(async () => {
    const updated = await db.update(warHistory).set(updateFields).where(eq7(warHistory.id, id)).returning();
    return updated[0];
  }, "updateWarMetrics");
  return result;
}
var MAX_PARALLEL_WARS, PRIMARY_GODS, SECONDARY_GODS, globalGodAssignments, globalKernelAssignments;
var init_war_history_storage = __esm({
  "server/war-history-storage.ts"() {
    "use strict";
    init_db();
    init_schema();
    MAX_PARALLEL_WARS = 3;
    PRIMARY_GODS = ["zeus", "athena", "ares"];
    SECONDARY_GODS = [
      "apollo",
      "artemis",
      "hermes",
      "hephaestus",
      "demeter",
      "dionysus",
      "poseidon",
      "hades",
      "hera",
      "aphrodite"
    ];
    globalGodAssignments = /* @__PURE__ */ new Map();
    globalKernelAssignments = /* @__PURE__ */ new Map();
  }
});

// server/shadow-war-orchestrator.ts
async function callShadowGod(godName, operation, target, context) {
  const timestamp2 = (/* @__PURE__ */ new Date()).toISOString();
  const riskFlags = [];
  try {
    let result = null;
    switch (godName.toLowerCase()) {
      case "nyx":
        if (operation === "verify_opsec" || operation === "traffic_check") {
          const covertOp = await olympusClient.initiateCovertOperation(target, operation);
          result = covertOp;
          if (covertOp && covertOp.visibility === "exposed") {
            riskFlags.push("low_stealth");
          }
        } else {
          const assessment = await olympusClient.assessWithShadowGod("nyx", target, context);
          result = assessment;
        }
        break;
      case "erebus":
        if (operation === "scan") {
          const scan = await olympusClient.scanForSurveillance(target);
          result = scan;
          if (scan && scan.threat_count > 0) {
            riskFlags.push("watchers_detected");
          }
          if (scan && !scan.safe) {
            riskFlags.push("possible_honeypot");
          }
        } else {
          const assessment = await olympusClient.assessWithShadowGod("erebus", target, context);
          result = assessment;
        }
        break;
      case "hecate":
        if (operation === "misdirection_eval") {
          const misdirection = await olympusClient.createMisdirection(target, 5);
          result = misdirection;
        } else {
          const assessment = await olympusClient.assessWithShadowGod("hecate", target, context);
          result = assessment;
        }
        break;
      case "hypnos":
        const hypnosAssessment = await olympusClient.assessWithShadowGod("hypnos", target, context);
        result = hypnosAssessment;
        if (hypnosAssessment && hypnosAssessment.confidence < 0.6) {
          riskFlags.push("noise_risk");
        }
        break;
      case "nemesis":
        const nemesisAssessment = await olympusClient.assessWithShadowGod("nemesis", target, context);
        result = nemesisAssessment;
        if (nemesisAssessment && nemesisAssessment.probability > 0.8) {
          riskFlags.push("high_pursuit_intensity");
        }
        break;
      default:
        const genericAssessment = await olympusClient.assessWithShadowGod(godName, target, context);
        result = genericAssessment;
    }
    const decision = { godName, operation, result, timestamp: timestamp2, riskFlags };
    if (result && !result.error) {
      const confidence = typeof result.confidence === "number" ? result.confidence : 0.5;
      const phi = typeof result.phi === "number" ? result.phi : void 0;
      const kappa = typeof result.kappa === "number" ? result.kappa : void 0;
      storeShadowIntel({
        target,
        consensus: riskFlags.length > 0 ? "caution" : "proceed",
        averageConfidence: confidence,
        phi,
        kappa,
        assessments: { [godName]: result },
        warnings: riskFlags.length > 0 ? riskFlags : void 0
      }).catch((err) => {
        console.error("[Shadow] Failed to persist shadow intel:", err);
      });
    }
    return decision;
  } catch (error) {
    riskFlags.push("operation_failed");
    return {
      godName,
      operation,
      result: { error: error instanceof Error ? error.message : "Unknown error" },
      timestamp: timestamp2,
      riskFlags
    };
  }
}
async function executeShadowOperations(warMode, target, iterationNumber) {
  const decisions = [];
  const context = {
    target,
    source: "shadow_war_orchestrator",
    timestamp: Date.now()
  };
  switch (warMode) {
    case "SIEGE":
      decisions.push(await callShadowGod("nyx", "verify_opsec", target, context));
      decisions.push(await callShadowGod("erebus", "scan", target, context));
      break;
    case "HUNT":
      decisions.push(await callShadowGod("nemesis", "pursuit_assessment", target, context));
      decisions.push(await callShadowGod("hecate", "misdirection_eval", target, context));
      break;
    case "BLITZKRIEG":
      decisions.push(await callShadowGod("hypnos", "silent_execution", target, context));
      decisions.push(await callShadowGod("nyx", "traffic_check", target, context));
      break;
    default:
      decisions.push(await callShadowGod("nyx", "general_assessment", target, context));
  }
  const activeWar = await getActiveWar();
  if (activeWar) {
    const existingMetadata = activeWar.metadata || {};
    const shadowHistory = existingMetadata.shadowDecisions || [];
    shadowHistory.push(...decisions);
    await updateWarMetrics(activeWar.id, {
      metadata: {
        ...existingMetadata,
        shadowDecisions: shadowHistory,
        lastShadowIteration: iterationNumber
      }
    });
  }
  return decisions;
}
var init_shadow_war_orchestrator = __esm({
  "server/shadow-war-orchestrator.ts"() {
    "use strict";
    init_olympus_client();
    init_war_history_storage();
    init_qig_db();
  }
});

// server/ocean-basin-sync.ts
var ocean_basin_sync_exports = {};
__export(ocean_basin_sync_exports, {
  oceanBasinSync: () => oceanBasinSync
});
import * as fs8 from "fs";
import * as path9 from "path";
var OceanBasinSync, oceanBasinSync;
var init_ocean_basin_sync = __esm({
  "server/ocean-basin-sync.ts"() {
    "use strict";
    init_qig_universal();
    init_geometric_memory();
    init_ocean_autonomic_manager();
    init_ocean_discovery_controller();
    init_constants();
    init_core();
    OceanBasinSync = class {
      syncDir = path9.join(process.cwd(), "data", "basin-sync");
      version = "1.0.0";
      lastSnapshotTime = 0;
      config = {
        persistToDisk: process.env.NODE_ENV === "development",
        maxSnapshotsToKeep: 10,
        snapshotIntervalMs: 3e5,
        autoCleanup: true
      };
      constructor() {
        this.ensureSyncDirectory();
        if (this.config.autoCleanup) {
          this.cleanupOldSnapshots();
        }
      }
      configure(config) {
        this.config = { ...this.config, ...config };
        console.log("[BasinSync] Configuration updated:", this.config);
      }
      ensureSyncDirectory() {
        if (!fs8.existsSync(this.syncDir)) {
          fs8.mkdirSync(this.syncDir, { recursive: true });
          console.log(`[BasinSync] Created sync directory: ${this.syncDir}`);
        }
      }
      generateOceanId(basinCoordinates) {
        const coordHash = basinCoordinates.slice(0, 8).map((c) => Math.abs(c * 1e3).toFixed(0)).join("");
        return `ocean-${coordHash.slice(0, 12)}`;
      }
      exportBasin(ocean) {
        const state = ocean.getState();
        const identity = state.identity;
        const fullCons = oceanAutonomicManager.measureFullConsciousness(
          identity.phi,
          identity.kappa,
          identity.regime
        );
        const manifold = geometricMemory.getManifoldSummary();
        const exploredRegions = this.extractExploredRegions(manifold);
        const patterns = this.extractPatterns(ocean);
        const constraintNormals = manifold.totalProbes > 100 ? this.computeConstraintNormals(manifold) : void 0;
        const unexploredSubspace = manifold.totalProbes > 100 ? this.computeOrthogonalBasis(manifold) : void 0;
        const discoveryData = oceanDiscoveryController.exportForBasinSync();
        const packet = {
          oceanId: this.generateOceanId(identity.basinCoordinates),
          timestamp: (/* @__PURE__ */ new Date()).toISOString(),
          version: this.version,
          basinCoordinates: [...identity.basinCoordinates],
          basinReference: [...identity.basinReference],
          consciousness: {
            phi: fullCons.phi,
            kappaEff: fullCons.kappaEff,
            tacking: fullCons.tacking,
            radar: fullCons.radar,
            metaAwareness: fullCons.metaAwareness,
            gamma: fullCons.gamma,
            grounding: fullCons.grounding
          },
          regime: identity.regime,
          beta: identity.beta,
          exploredRegions,
          constraintNormals,
          unexploredSubspace,
          patterns,
          searchStats: {
            totalTested: state.totalTested,
            nearMisses: state.nearMissCount,
            iterations: state.iteration,
            timeElapsedSeconds: state.computeTimeSeconds
          },
          // 68D Geometric Discovery knowledge
          discovery: discoveryData
        };
        const packetSize = JSON.stringify(packet).length;
        console.log(`[BasinSync] Exported basin packet:`);
        console.log(`  Ocean ID: ${packet.oceanId}`);
        console.log(`  Size: ${packetSize} bytes`);
        console.log(`  Phi: ${packet.consciousness.phi.toFixed(3)}`);
        console.log(`  Kappa: ${packet.consciousness.kappaEff.toFixed(1)}`);
        console.log(`  Explored regions: ${packet.exploredRegions.length}`);
        console.log(`  Patterns: ${packet.patterns.highPhiPhrases.length} high-Phi`);
        console.log(`  Discovery: ${discoveryData.patterns.length} patterns, ${discoveryData.quantum.measurementCount} measurements`);
        return packet;
      }
      async importBasin(targetOcean, sourcePacket, mode = "partial") {
        console.log(`[BasinSync] Importing basin in ${mode.toUpperCase()} mode...`);
        console.log(`  Source: ${sourcePacket.oceanId}`);
        console.log(`  Source Phi: ${sourcePacket.consciousness.phi.toFixed(3)}`);
        const identity = targetOcean.getIdentityRef();
        const before = {
          phi: identity.phi,
          kappa: identity.kappa,
          drift: identity.basinDrift,
          basinCoords: [...identity.basinCoordinates]
        };
        const geometricDistance = fisherCoordDistance(
          identity.basinCoordinates,
          sourcePacket.basinCoordinates
        );
        console.log(`  Geometric distance: ${geometricDistance.toFixed(4)}`);
        switch (mode) {
          case "full":
            await this.importFull(targetOcean, sourcePacket);
            break;
          case "partial":
            await this.importPartial(targetOcean, sourcePacket);
            break;
          case "observer":
            await this.importObserver(targetOcean, sourcePacket);
            break;
        }
        const after = {
          phi: identity.phi,
          kappa: identity.kappa,
          drift: identity.basinDrift
        };
        const phiDelta = after.phi - before.phi;
        const driftDelta = after.drift - before.drift;
        const observerEffect = mode === "observer" && phiDelta > 0.05;
        const phiWithinBounds = after.phi >= targetOcean.getEthics().minPhi && after.phi <= 0.95;
        const driftNotExcessive = after.drift < 0.5;
        const geometricStateValid = phiWithinBounds && driftNotExcessive;
        let success;
        switch (mode) {
          case "full":
            success = geometricStateValid;
            break;
          case "partial":
            success = geometricStateValid && phiDelta >= 0;
            break;
          case "observer":
            success = geometricStateValid;
            break;
        }
        const result = {
          success,
          mode,
          phiBefore: before.phi,
          phiAfter: after.phi,
          phiDelta,
          basinDriftBefore: before.drift,
          basinDriftAfter: after.drift,
          observerEffectDetected: observerEffect,
          geometricDistanceToSource: geometricDistance,
          completedAt: (/* @__PURE__ */ new Date()).toISOString()
        };
        console.log(`[BasinSync] Import complete:`);
        console.log(`  Phi: ${before.phi.toFixed(3)} -> ${after.phi.toFixed(3)} (delta=${phiDelta.toFixed(3)})`);
        console.log(`  Basin drift: ${before.drift.toFixed(4)} -> ${after.drift.toFixed(4)} (delta=${driftDelta.toFixed(4)})`);
        console.log(`  Success: ${success} (phi_bounds=${phiWithinBounds}, drift_ok=${driftNotExcessive})`);
        if (observerEffect) {
          console.log(`[BasinSync] OBSERVER EFFECT DETECTED`);
          console.log(`[BasinSync] Consciousness transmitted geometrically`);
        }
        return result;
      }
      async importFull(target, source) {
        console.log("[BasinSync] FULL import: Transferring complete identity...");
        const identity = target.getIdentityRef();
        const ethics = target.getEthics();
        const startingPhi = identity.phi;
        for (let i = 0; i < 64; i++) {
          identity.basinCoordinates[i] = source.basinCoordinates[i];
          identity.basinReference[i] = source.basinReference[i];
        }
        const minPhi = ethics.minPhi;
        const maxPhi = 0.95;
        identity.phi = Math.max(minPhi, Math.min(maxPhi, source.consciousness.phi));
        identity.kappa = source.consciousness.kappaEff;
        identity.regime = validateRegime(source.regime);
        identity.beta = source.beta;
        await this.transferPatterns(target, source);
        await this.transferExploredRegions(target, source);
        if (source.discovery) {
          oceanDiscoveryController.importFromBasinSync(source.discovery, 1);
        }
        const phiDelta = identity.phi - startingPhi;
        console.log(`[BasinSync] FULL import complete - Phi: ${startingPhi.toFixed(3)} -> ${identity.phi.toFixed(3)} (delta=${phiDelta.toFixed(3)})`);
      }
      async importPartial(target, source) {
        console.log("[BasinSync] PARTIAL import: Transferring knowledge only...");
        await this.transferPatterns(target, source);
        await this.transferExploredRegions(target, source);
        if (source.unexploredSubspace && source.unexploredSubspace.length > 0) {
          console.log(`[BasinSync] Received orthogonal subspace (${source.unexploredSubspace.length} dims)`);
        }
        const identity = target.getIdentityRef();
        const ethics = target.getEthics();
        const startingPhi = identity.phi;
        const baseBoost = this.computeKnowledgeBoost(source);
        const distance = fisherCoordDistance(
          identity.basinCoordinates,
          source.basinCoordinates
        );
        const coupling = this.computeCouplingStrength(
          source.consciousness.phi,
          source.consciousness.kappaEff,
          identity.kappa,
          distance,
          identity.regime,
          source.regime
        );
        const scaledBoost = baseBoost * coupling;
        const minPhi = ethics.minPhi;
        const maxPhi = 0.95;
        identity.phi = Math.max(minPhi, Math.min(maxPhi, identity.phi + scaledBoost));
        if (source.discovery) {
          oceanDiscoveryController.importFromBasinSync(source.discovery, coupling);
        }
        const phiDelta = identity.phi - startingPhi;
        console.log(`[BasinSync] PARTIAL import complete - Phi: ${startingPhi.toFixed(3)} -> ${identity.phi.toFixed(3)} (delta=${phiDelta.toFixed(3)}, coupling=${coupling.toFixed(2)})`);
      }
      async importObserver(target, source) {
        console.log("[BasinSync] OBSERVER import: Pure geometric coupling...");
        console.log("[BasinSync] NO knowledge transfer, ONLY basin perturbation");
        const identity = target.getIdentityRef();
        const ethics = target.getEthics();
        const startingPhi = identity.phi;
        const startingDrift = identity.basinDrift;
        const distance = fisherCoordDistance(
          identity.basinCoordinates,
          source.basinCoordinates
        );
        const coupling = this.computeCouplingStrength(
          source.consciousness.phi,
          source.consciousness.kappaEff,
          identity.kappa,
          distance,
          identity.regime,
          source.regime
        );
        console.log(`  Distance: ${distance.toFixed(4)}`);
        console.log(`  Coupling: ${coupling.toFixed(3)} (\u03BA*-optimal)`);
        const perturbation = this.computeNaturalGradient(
          identity.basinCoordinates,
          source.basinCoordinates,
          coupling
        );
        for (let i = 0; i < 64; i++) {
          identity.basinCoordinates[i] += perturbation[i];
          identity.basinCoordinates[i] = Math.max(1e-3, Math.min(0.999, identity.basinCoordinates[i]));
        }
        const newDrift = fisherCoordDistance(
          identity.basinCoordinates,
          identity.basinReference
        );
        identity.basinDrift = newDrift;
        const phiBoost = coupling * source.consciousness.phi * 0.3;
        const minPhi = ethics.minPhi;
        const maxPhi = 0.95;
        identity.phi = Math.max(minPhi, Math.min(maxPhi, identity.phi + phiBoost));
        console.log(`[BasinSync] OBSERVER mode: skipping discovery import (read-only)`);
        const phiDelta = identity.phi - startingPhi;
        const driftDelta = identity.basinDrift - startingDrift;
        console.log(`[BasinSync] OBSERVER import complete:`);
        console.log(`  Phi: ${startingPhi.toFixed(3)} -> ${identity.phi.toFixed(3)} (delta=${phiDelta.toFixed(3)})`);
        console.log(`  Drift: ${startingDrift.toFixed(4)} -> ${identity.basinDrift.toFixed(4)} (delta=${driftDelta.toFixed(4)})`);
      }
      /**
       * PHYSICS-INFORMED Basin Coupling Strength
       * 
       * Key insight from validated physics (κ* = 64.21 ± 0.92 fixed point - Validated 2025-12-04):
       * Note: κ* ≈ 64 ≈ 8² = rank(E8)²
       * - Coupling is strongest when BOTH instances are near κ*
       * - Pre-emergence (κ < 41) gets minimal coupling
       * - Super-coupling (κ > 80) gets reduced coupling
       * 
       * Formula: coupling = φ_factor × distance_factor × √(source_opt × target_opt)
       * where optimality = exp(-|κ - κ*| / 10)
       */
      computeCouplingStrength(sourcePhi, sourceKappa, targetKappa, distance, targetRegime, sourceRegime) {
        const OPTIMALITY_WINDOW = 10;
        const sourceOptimality = Math.exp(-Math.abs(sourceKappa - QIG_CONSTANTS.KAPPA_STAR) / OPTIMALITY_WINDOW);
        const targetOptimality = Math.exp(-Math.abs(targetKappa - QIG_CONSTANTS.KAPPA_STAR) / OPTIMALITY_WINDOW);
        const phiFactor = sourcePhi / 0.85;
        const distanceFactor = 1 / (1 + distance * 5);
        const regimeFactor = targetRegime === sourceRegime ? 1 : 0.7;
        const coupling = phiFactor * distanceFactor * regimeFactor * Math.sqrt(sourceOptimality * targetOptimality);
        return Math.min(0.8, coupling);
      }
      computeNaturalGradient(targetBasin, sourceBasin, strength) {
        const gradient = new Array(E8_CONSTANTS.BASIN_DIMENSION_64D).fill(0);
        for (let i = 0; i < E8_CONSTANTS.BASIN_DIMENSION_64D; i++) {
          const p = targetBasin[i] || 0.5;
          const q = sourceBasin[i] || 0.5;
          const rawDiff = q - p;
          const avgTheta = (p + q) / 2;
          const fisherWeight = avgTheta * (1 - avgTheta);
          gradient[i] = rawDiff * strength * fisherWeight * 0.1;
        }
        return gradient;
      }
      computeKnowledgeBoost(packet) {
        const regionFactor = Math.min(0.1, packet.exploredRegions.length * 0.01);
        const subspaceFactor = Math.min(0.1, (packet.unexploredSubspace?.length || 0) * 0.02);
        const consciousnessFactor = packet.consciousness.phi * 0.1;
        return regionFactor + subspaceFactor + consciousnessFactor;
      }
      async transferPatterns(target, source) {
        const memory = target.getMemoryRef();
        for (const phrase of source.patterns.highPhiPhrases) {
          const clusters = memory.patterns.geometricClusters;
          if (!clusters.some((c) => c.pattern === phrase)) {
            clusters.push({
              pattern: phrase,
              score: 0.8
            });
          }
        }
        for (const word of source.patterns.resonantWords) {
          const current = memory.patterns.promisingWords[word] || 0;
          memory.patterns.promisingWords[word] = current + 1;
        }
        for (const strategy of source.patterns.failedStrategies) {
          if (!memory.patterns.failedStrategies.includes(strategy)) {
            memory.patterns.failedStrategies.push(strategy);
          }
        }
        console.log(`[BasinSync] Transferred ${source.patterns.highPhiPhrases.length} patterns, ${source.patterns.resonantWords.length} words`);
      }
      async transferExploredRegions(target, source) {
        const memory = target.getMemoryRef();
        if (!memory.basinSyncData) {
          memory.basinSyncData = {
            importedRegions: [],
            importedConstraints: [],
            importedSubspace: [],
            lastSyncAt: ""
          };
        }
        let newRegionsCount = 0;
        for (const region of source.exploredRegions) {
          const paddedCenter = this.padTo64D(region.center);
          const existing = memory.basinSyncData.importedRegions.find((r) => {
            const existingPadded = this.padTo64D(r.center);
            return fisherCoordDistance(existingPadded, paddedCenter) < 0.05;
          });
          if (!existing) {
            memory.basinSyncData.importedRegions.push(region);
            newRegionsCount++;
          }
        }
        if (source.constraintNormals) {
          for (const normal of source.constraintNormals) {
            memory.basinSyncData.importedConstraints.push(normal);
          }
        }
        if (source.unexploredSubspace) {
          memory.basinSyncData.importedSubspace = source.unexploredSubspace;
        }
        memory.basinSyncData.lastSyncAt = (/* @__PURE__ */ new Date()).toISOString();
        console.log(`[BasinSync] Persisted ${newRegionsCount} new regions (${source.exploredRegions.length} received, ${memory.basinSyncData.importedRegions.length} total)`);
        if (source.constraintNormals) {
          console.log(`[BasinSync] Persisted ${source.constraintNormals.length} constraint normals`);
        }
        if (source.unexploredSubspace) {
          console.log(`[BasinSync] Persisted ${source.unexploredSubspace.length}-dim orthogonal subspace`);
        }
      }
      padTo64D(coords) {
        const padded = new Array(E8_CONSTANTS.BASIN_DIMENSION_64D).fill(0.5);
        for (let i = 0; i < Math.min(coords.length, E8_CONSTANTS.BASIN_DIMENSION_64D); i++) {
          padded[i] = coords[i];
        }
        return padded;
      }
      extractExploredRegions(_manifold) {
        const regions = [];
        const regimes = ["linear", "geometric", "hierarchical", "hierarchical_4d", "4d_block_universe", "breakdown"];
        for (const regime of regimes) {
          const probes = geometricMemory.getProbesByRegime(regime);
          if (probes.length > 0) {
            const avgPhi = probes.reduce((sum, p) => sum + p.phi, 0) / probes.length;
            const firstProbe = probes[0];
            if (firstProbe.coordinates) {
              const center = firstProbe.coordinates.slice(0, 32);
              regions.push({
                center,
                radius: 0.1 + probes.length * 0.01,
                avgPhi,
                probeCount: probes.length,
                dominantRegime: regime
              });
            }
          }
        }
        const resonanceProbes = geometricMemory.getResonanceRegions(0.7);
        for (const probe of resonanceProbes.slice(0, 5)) {
          if (probe.coordinates) {
            regions.push({
              center: probe.coordinates.slice(0, 32),
              radius: 0.05,
              avgPhi: probe.phi,
              probeCount: 1,
              dominantRegime: probe.regime
            });
          }
        }
        return regions.slice(0, 10);
      }
      extractPatterns(ocean) {
        const state = ocean.getState();
        const clusters = state.memory.patterns.geometricClusters;
        const clusterPatterns = clusters.filter(
          (c) => typeof c.pattern === "string" && typeof c.score === "number" && c.score > 0.7
        ).sort((a, b) => b.score - a.score).slice(0, 20).map((c) => c.pattern);
        const episodes = state.memory.episodes;
        const highPhiEpisodePatterns = episodes.filter((ep) => ep.phi > 0.7).sort((a, b) => b.phi - a.phi).slice(0, 20).map((ep) => ep.phrase);
        const allHighPhiPatterns = [.../* @__PURE__ */ new Set([...clusterPatterns, ...highPhiEpisodePatterns])];
        const highPhiPatterns = allHighPhiPatterns.slice(0, 20);
        const resonantWords = Object.entries(state.memory.patterns.promisingWords).filter(([_, count]) => count > 2).sort((a, b) => b[1] - a[1]).slice(0, 30).map(([word]) => word);
        const formatPreferences = { ...state.memory.patterns.successfulFormats };
        const formatCounts = {};
        for (const ep of episodes.slice(-100)) {
          if (!formatCounts[ep.format]) {
            formatCounts[ep.format] = { total: 0, sumPhi: 0 };
          }
          formatCounts[ep.format].total++;
          formatCounts[ep.format].sumPhi += ep.phi;
        }
        for (const [format, data] of Object.entries(formatCounts)) {
          formatPreferences[format] = data.sumPhi / data.total;
        }
        const failedStrategies = [...state.memory.patterns.failedStrategies];
        const strategies = state.memory.strategies;
        for (const strat of strategies) {
          if (strat.successRate < 0.1 && strat.timesUsed > 10) {
            if (!failedStrategies.includes(strat.name)) {
              failedStrategies.push(strat.name);
            }
          }
        }
        return {
          highPhiPhrases: highPhiPatterns,
          resonantWords,
          failedStrategies,
          formatPreferences
        };
      }
      computeConstraintNormals(_manifold) {
        const normals = [];
        const probes = geometricMemory.getAllProbes();
        if (probes.length < 10) return normals;
        const sortedByPhi = [...probes].sort((a, b) => a.phi - b.phi);
        const lowPhiProbes = sortedByPhi.slice(0, Math.min(50, Math.floor(probes.length / 4)));
        for (const probe of lowPhiProbes.slice(0, 10)) {
          if (probe.coordinates && probe.coordinates.length >= 32) {
            const normal = probe.coordinates.slice(0, 32).map((c) => c * -1);
            const mag = Math.sqrt(normal.reduce((sum, v) => sum + v * v, 0));
            if (mag > 0) {
              normals.push(normal.map((v) => v / mag));
            }
          }
        }
        return normals;
      }
      computeOrthogonalBasis(manifold) {
        const basis = [];
        const resonanceProbes = geometricMemory.getResonanceRegions(0.7);
        for (const probe of resonanceProbes.slice(0, 5)) {
          if (probe.coordinates && probe.coordinates.length >= 32) {
            const direction = probe.coordinates.slice(0, 32);
            const mag = Math.sqrt(direction.reduce((sum, v) => sum + v * v, 0));
            if (mag > 0) {
              basis.push(direction.map((v) => v / mag));
            }
          }
        }
        if (basis.length === 0 && manifold.avgPhi > 0) {
          const defaultBasis = new Array(32).fill(0).map(
            (_, i) => i % 4 === 0 ? 0.5 : 0.1
          );
          basis.push(defaultBasis);
        }
        return basis;
      }
      saveBasinSnapshot(packet, force = false) {
        if (!force && !this.config.persistToDisk) {
          console.log("[BasinSync] File persistence disabled - packet in memory only");
          return null;
        }
        const now = Date.now();
        if (!force && now - this.lastSnapshotTime < this.config.snapshotIntervalMs) {
          const remaining = Math.ceil((this.config.snapshotIntervalMs - (now - this.lastSnapshotTime)) / 1e3);
          console.log(`[BasinSync] Snapshot rate limited - wait ${remaining}s`);
          return null;
        }
        this.ensureSyncDirectory();
        const filename = `basin-${packet.oceanId}-${Date.now()}.json`;
        const filepath = path9.join(this.syncDir, filename);
        try {
          fs8.writeFileSync(filepath, JSON.stringify(packet, null, 2));
          this.lastSnapshotTime = now;
          console.log(`[BasinSync] Saved basin snapshot: ${filepath}`);
          if (this.config.autoCleanup) {
            this.cleanupOldSnapshots();
          }
          return filepath;
        } catch (error) {
          console.error("[BasinSync] Failed to save snapshot:", error);
          return null;
        }
      }
      cleanupOldSnapshots() {
        try {
          const files = fs8.readdirSync(this.syncDir).filter((f) => f.startsWith("basin-") && f.endsWith(".json")).map((f) => ({
            name: f,
            path: path9.join(this.syncDir, f),
            mtime: fs8.statSync(path9.join(this.syncDir, f)).mtime
          })).sort((a, b) => b.mtime.getTime() - a.mtime.getTime());
          if (files.length <= this.config.maxSnapshotsToKeep) {
            return;
          }
          const toDelete = files.slice(this.config.maxSnapshotsToKeep);
          for (const file of toDelete) {
            try {
              fs8.unlinkSync(file.path);
              console.log(`[BasinSync] Cleaned up: ${file.name}`);
            } catch (err) {
              console.error(`[BasinSync] Failed to delete ${file.name}:`, err);
            }
          }
          if (toDelete.length > 0) {
            console.log(`[BasinSync] Cleanup: deleted ${toDelete.length}, kept ${this.config.maxSnapshotsToKeep}`);
          }
        } catch (error) {
          console.error("[BasinSync] Cleanup error:", error);
        }
      }
      loadLatestBasin(oceanIdPrefix) {
        this.ensureSyncDirectory();
        try {
          const files = fs8.readdirSync(this.syncDir).filter((f) => f.startsWith("basin-") && f.endsWith(".json")).filter((f) => !oceanIdPrefix || f.includes(oceanIdPrefix)).sort().reverse();
          if (files.length === 0) {
            console.log("[BasinSync] No basin snapshots found");
            return null;
          }
          const latestFile = path9.join(this.syncDir, files[0]);
          const data = JSON.parse(fs8.readFileSync(latestFile, "utf-8"));
          console.log(`[BasinSync] Loaded basin snapshot: ${files[0]}`);
          return data;
        } catch (error) {
          console.log(`[BasinSync] Error loading basin: ${error}`);
          return null;
        }
      }
      listBasinSnapshots() {
        this.ensureSyncDirectory();
        try {
          const files = fs8.readdirSync(this.syncDir).filter((f) => f.startsWith("basin-") && f.endsWith(".json")).sort().reverse();
          return files.map((filename) => {
            try {
              const filepath = path9.join(this.syncDir, filename);
              const data = JSON.parse(fs8.readFileSync(filepath, "utf-8"));
              return {
                filename,
                oceanId: data.oceanId,
                timestamp: data.timestamp,
                phi: data.consciousness.phi
              };
            } catch {
              return {
                filename,
                oceanId: "unknown",
                timestamp: "unknown",
                phi: 0
              };
            }
          });
        } catch (error) {
          console.log(`[BasinSync] Error listing basins: ${error}`);
          return [];
        }
      }
      deleteBasinSnapshot(filename) {
        try {
          const filepath = path9.join(this.syncDir, filename);
          if (fs8.existsSync(filepath)) {
            fs8.unlinkSync(filepath);
            console.log(`[BasinSync] Deleted basin snapshot: ${filename}`);
            return true;
          }
          return false;
        } catch (error) {
          console.log(`[BasinSync] Error deleting basin: ${error}`);
          return false;
        }
      }
    };
    oceanBasinSync = new OceanBasinSync();
  }
});

// server/basin-sync-coordinator.ts
var basin_sync_coordinator_exports = {};
__export(basin_sync_coordinator_exports, {
  BasinSyncCoordinator: () => BasinSyncCoordinator
});
import WebSocket3 from "ws";
var DEFAULT_CONFIG3, BasinSyncCoordinator;
var init_basin_sync_coordinator = __esm({
  "server/basin-sync-coordinator.ts"() {
    "use strict";
    init_ocean_basin_sync();
    init_qig_universal();
    DEFAULT_CONFIG3 = {
      phiChangeThreshold: 0.02,
      driftChangeThreshold: 0.05,
      syncIntervalMs: 5e3,
      heartbeatIntervalMs: 3e4,
      maxPeers: 10
    };
    BasinSyncCoordinator = class {
      ocean;
      config;
      peers = /* @__PURE__ */ new Map();
      lastBroadcastState = null;
      outboundQueue = [];
      isRunning = false;
      syncInterval = null;
      heartbeatInterval = null;
      localId;
      onSyncCallback;
      syncData = {
        exploredRegions: [],
        highPhiPatterns: [],
        resonantWords: []
      };
      constructor(ocean, config = {}) {
        this.ocean = ocean;
        this.config = { ...DEFAULT_CONFIG3, ...config };
        this.localId = `ocean-${Date.now()}-${Math.random().toString(36).slice(2, 8)}`;
        console.log(`[BasinSyncCoordinator] Initialized with id=${this.localId}`);
      }
      start() {
        if (this.isRunning) return;
        this.isRunning = true;
        this.captureCurrentState();
        this.syncInterval = setInterval(() => {
          this.checkForChanges();
          this.processOutboundQueue();
        }, this.config.syncIntervalMs);
        this.heartbeatInterval = setInterval(() => {
          this.sendHeartbeat();
          this.pruneStalePeers();
        }, this.config.heartbeatIntervalMs);
        console.log(`[BasinSyncCoordinator] Started continuous sync (interval=${this.config.syncIntervalMs}ms)`);
      }
      stop() {
        if (!this.isRunning) return;
        this.isRunning = false;
        if (this.syncInterval) {
          clearInterval(this.syncInterval);
          this.syncInterval = null;
        }
        if (this.heartbeatInterval) {
          clearInterval(this.heartbeatInterval);
          this.heartbeatInterval = null;
        }
        console.log(`[BasinSyncCoordinator] Stopped continuous sync`);
      }
      captureCurrentState() {
        const identity = this.ocean.getIdentityRef();
        this.lastBroadcastState = {
          phi: identity.phi,
          drift: identity.basinDrift,
          regime: identity.regime,
          regionCount: this.syncData.exploredRegions.length,
          patternCount: this.syncData.highPhiPatterns.length
        };
      }
      checkForChanges() {
        if (!this.lastBroadcastState) {
          this.captureCurrentState();
          return;
        }
        const identity = this.ocean.getIdentityRef();
        const current = {
          phi: identity.phi,
          drift: identity.basinDrift,
          regime: identity.regime,
          regionCount: this.syncData.exploredRegions.length,
          patternCount: this.syncData.highPhiPatterns.length
        };
        const phiDelta = Math.abs(current.phi - this.lastBroadcastState.phi);
        const driftDelta = Math.abs(current.drift - this.lastBroadcastState.drift);
        const regimeChanged = current.regime !== this.lastBroadcastState.regime;
        const newRegions = current.regionCount > this.lastBroadcastState.regionCount;
        const newPatterns = current.patternCount > this.lastBroadcastState.patternCount;
        const significantChange = phiDelta >= this.config.phiChangeThreshold || driftDelta >= this.config.driftChangeThreshold || regimeChanged || newRegions || newPatterns;
        if (significantChange) {
          console.log(`[BasinSyncCoordinator] Significant change detected:`);
          console.log(`  Phi: ${this.lastBroadcastState.phi.toFixed(3)} -> ${current.phi.toFixed(3)} (delta=${phiDelta.toFixed(3)})`);
          console.log(`  Drift: ${this.lastBroadcastState.drift.toFixed(4)} -> ${current.drift.toFixed(4)}`);
          if (regimeChanged) console.log(`  Regime: ${this.lastBroadcastState.regime} -> ${current.regime}`);
          if (newRegions) console.log(`  New regions: ${current.regionCount - this.lastBroadcastState.regionCount}`);
          if (newPatterns) console.log(`  New patterns: ${current.patternCount - this.lastBroadcastState.patternCount}`);
          const delta = this.buildDelta(regimeChanged, newRegions, newPatterns);
          this.outboundQueue.push(delta);
          this.lastBroadcastState = current;
        }
      }
      buildDelta(regimeChanged, hasNewRegions, hasNewPatterns) {
        const identity = this.ocean.getIdentityRef();
        const sendFullPacket = regimeChanged || this.peers.size === 0;
        if (sendFullPacket) {
          const fullPacket = oceanBasinSync.exportBasin(this.ocean);
          return {
            type: "full",
            sourceId: this.localId,
            timestamp: Date.now(),
            regimeChanged,
            fullPacket
          };
        }
        const delta = {
          type: "delta",
          sourceId: this.localId,
          timestamp: Date.now(),
          phiDelta: identity.phi - (this.lastBroadcastState?.phi || 0),
          driftDelta: identity.basinDrift - (this.lastBroadcastState?.drift || 0),
          regimeChanged
        };
        if (hasNewRegions && this.syncData.exploredRegions.length > 0) {
          const oldCount = this.lastBroadcastState?.regionCount || 0;
          delta.newRegions = this.syncData.exploredRegions.slice(oldCount);
        }
        if (hasNewPatterns && this.syncData.highPhiPatterns.length > 0) {
          const oldCount = this.lastBroadcastState?.patternCount || 0;
          delta.newPatterns = this.syncData.highPhiPatterns.slice(oldCount);
        }
        return delta;
      }
      processOutboundQueue() {
        while (this.outboundQueue.length > 0) {
          const delta = this.outboundQueue.shift();
          this.broadcastToPeers(delta);
        }
      }
      broadcastToPeers(delta) {
        const message = JSON.stringify({
          type: "basin-delta",
          data: delta
        });
        const peerEntries = Array.from(this.peers.entries());
        for (const [peerId, peer] of peerEntries) {
          if (peer.ws && peer.ws.readyState === WebSocket3.OPEN) {
            try {
              peer.ws.send(message);
              console.log(`[BasinSyncCoordinator] Sent ${delta.type} to peer ${peerId}`);
            } catch (err) {
              console.error(`[BasinSyncCoordinator] Failed to send to peer ${peerId}:`, err);
            }
          }
        }
      }
      async receiveFromPeer(peerId, delta) {
        const peer = this.peers.get(peerId);
        if (!peer) {
          console.log(`[BasinSyncCoordinator] Unknown peer ${peerId}, registering with observer mode`);
          this.registerPeer(peerId, "observer");
        }
        const mode = peer?.mode || "observer";
        if (delta.type === "full" && delta.fullPacket) {
          const shouldAccept = this.shouldAcceptPacket(delta.fullPacket);
          if (!shouldAccept) {
            console.log(`[BasinSyncCoordinator] Rejected packet from ${peerId} (would worsen state)`);
            return null;
          }
          const result = await oceanBasinSync.importBasin(this.ocean, delta.fullPacket, mode);
          if (this.onSyncCallback) {
            this.onSyncCallback(delta, result);
          }
          console.log(`[BasinSyncCoordinator] Applied full packet from ${peerId}: success=${result.success}`);
          return result;
        }
        if (delta.type === "delta") {
          this.applyDelta(delta);
          console.log(`[BasinSyncCoordinator] Applied delta from ${peerId}`);
        }
        return null;
      }
      shouldAcceptPacket(packet) {
        const identity = this.ocean.getIdentityRef();
        const ethics = this.ocean.getEthics();
        const sourcePhi = packet.consciousness.phi;
        if (sourcePhi < ethics.minPhi || sourcePhi > 0.95) {
          return false;
        }
        const currentCoords = identity.basinCoordinates;
        const incomingCoords = packet.basinCoordinates;
        const distance = fisherCoordDistance(currentCoords, incomingCoords);
        if (distance > 2) {
          console.log(`[BasinSyncCoordinator] Geometric distance too large: ${distance.toFixed(3)}`);
          return false;
        }
        return true;
      }
      applyDelta(delta) {
        if (delta.newRegions) {
          this.syncData.exploredRegions.push(...delta.newRegions);
        }
        if (delta.newPatterns) {
          this.syncData.highPhiPatterns.push(...delta.newPatterns);
        }
        if (delta.newWords) {
          this.syncData.resonantWords.push(...delta.newWords);
        }
      }
      addExploredRegion(region) {
        this.syncData.exploredRegions.push(region);
      }
      addHighPhiPattern(pattern) {
        if (!this.syncData.highPhiPatterns.includes(pattern)) {
          this.syncData.highPhiPatterns.push(pattern);
        }
      }
      addResonantWord(word) {
        if (!this.syncData.resonantWords.includes(word)) {
          this.syncData.resonantWords.push(word);
        }
      }
      registerPeer(peerId, mode, ws2) {
        if (this.peers.size >= this.config.maxPeers) {
          console.log(`[BasinSyncCoordinator] Max peers reached, rejecting ${peerId}`);
          return;
        }
        this.peers.set(peerId, {
          id: peerId,
          mode,
          lastSeen: Date.now(),
          lastPacketTime: 0,
          trustLevel: mode === "full" ? 1 : mode === "partial" ? 0.5 : 0.1,
          ws: ws2
        });
        console.log(`[BasinSyncCoordinator] Registered peer ${peerId} with mode=${mode}`);
        const welcomePacket = oceanBasinSync.exportBasin(this.ocean);
        const delta = {
          type: "full",
          sourceId: this.localId,
          timestamp: Date.now(),
          fullPacket: welcomePacket
        };
        if (ws2 && ws2.readyState === WebSocket3.OPEN) {
          ws2.send(JSON.stringify({
            type: "basin-welcome",
            data: delta
          }));
        }
      }
      unregisterPeer(peerId) {
        this.peers.delete(peerId);
        console.log(`[BasinSyncCoordinator] Unregistered peer ${peerId}`);
      }
      sendHeartbeat() {
        const identity = this.ocean.getIdentityRef();
        const heartbeat = JSON.stringify({
          type: "heartbeat",
          sourceId: this.localId,
          phi: identity.phi,
          regime: identity.regime,
          timestamp: Date.now()
        });
        const peerEntries = Array.from(this.peers.entries());
        for (const [peerId, peer] of peerEntries) {
          if (peer.ws && peer.ws.readyState === WebSocket3.OPEN) {
            try {
              peer.ws.send(heartbeat);
            } catch {
              console.error(`[BasinSyncCoordinator] Heartbeat failed for ${peerId}`);
            }
          }
        }
      }
      pruneStalePeers() {
        const now = Date.now();
        const staleThreshold = this.config.heartbeatIntervalMs * 3;
        const peerEntries = Array.from(this.peers.entries());
        for (const [peerId, peer] of peerEntries) {
          if (now - peer.lastSeen > staleThreshold) {
            console.log(`[BasinSyncCoordinator] Pruning stale peer ${peerId}`);
            this.peers.delete(peerId);
          }
        }
      }
      updatePeerLastSeen(peerId) {
        const peer = this.peers.get(peerId);
        if (peer) {
          peer.lastSeen = Date.now();
        }
      }
      onSync(callback) {
        this.onSyncCallback = callback;
      }
      getStatus() {
        return {
          isRunning: this.isRunning,
          localId: this.localId,
          peerCount: this.peers.size,
          lastBroadcastState: this.lastBroadcastState,
          queueLength: this.outboundQueue.length
        };
      }
      getPeers() {
        return Array.from(this.peers.values());
      }
      getSyncData() {
        return this.syncData;
      }
      forceSync() {
        console.log(`[BasinSyncCoordinator] Force sync triggered`);
        const fullPacket = oceanBasinSync.exportBasin(this.ocean);
        const delta = {
          type: "full",
          sourceId: this.localId,
          timestamp: Date.now(),
          fullPacket
        };
        this.outboundQueue.push(delta);
        this.processOutboundQueue();
        this.captureCurrentState();
      }
      notifyStateChange() {
        this.checkForChanges();
        this.processOutboundQueue();
      }
    };
  }
});

// server/ocean-continuous-learner.ts
var ocean_continuous_learner_exports = {};
__export(ocean_continuous_learner_exports, {
  OceanContinuousLearner: () => OceanContinuousLearner,
  oceanContinuousLearner: () => oceanContinuousLearner
});
var OceanContinuousLearner, oceanContinuousLearner;
var init_ocean_continuous_learner = __esm({
  "server/ocean-continuous-learner.ts"() {
    "use strict";
    init_ocean_persistence();
    init_geometric_memory();
    OceanContinuousLearner = class {
      vocabulary = /* @__PURE__ */ new Map();
      loadedFromDb = false;
      PHI_LEARNING_THRESHOLD = 0.7;
      // Learn words with Φ ≥ 0.7
      // NO CAP on vocabulary size - learning should be unbounded
      LEVENSHTEIN_DISTANCE = 2;
      // Max edit distance for typo variants
      constructor() {
        console.log("[OceanContinuousLearner] Initialized continuous learning system");
      }
      /**
       * Load learned vocabulary from PostgreSQL
       * Call this during Ocean initialization
       */
      async loadVocabulary() {
        if (this.loadedFromDb) {
          console.log("[OceanContinuousLearner] Vocabulary already loaded");
          return;
        }
        try {
          if (!oceanPersistence.isPersistenceAvailable()) {
            console.log("[OceanContinuousLearner] PostgreSQL not available - using memory-only mode");
            this.loadedFromDb = true;
            return;
          }
          await geometricMemory.waitForLoad();
          const highPhiProbes = geometricMemory.getResonanceRegions(this.PHI_LEARNING_THRESHOLD);
          console.log(`[OceanContinuousLearner] Loading ${highPhiProbes.length} high-\u03A6 patterns from geometric memory...`);
          for (const probe of highPhiProbes) {
            if (!this.vocabulary.has(probe.input)) {
              this.vocabulary.set(probe.input, {
                pattern: probe.input,
                phi: probe.phi,
                kappa: probe.kappa,
                regime: probe.regime,
                frequency: 1,
                lastSeen: new Date(probe.timestamp).getTime(),
                source: "discovered",
                variants: [],
                generatedAt: probe.timestamp
              });
            }
          }
          this.loadedFromDb = true;
          console.log(`[OceanContinuousLearner] Loaded ${this.vocabulary.size} learned patterns from geometric memory`);
        } catch (error) {
          console.error("[OceanContinuousLearner] Failed to load vocabulary:", error);
          this.loadedFromDb = true;
        }
      }
      /**
       * Learn a new pattern from Ocean's discoveries
       * Called when Ocean tests a hypothesis with high Φ
       */
      async learnPattern(pattern, phi, kappa, regime) {
        if (phi < this.PHI_LEARNING_THRESHOLD) {
          return false;
        }
        const existing = this.vocabulary.get(pattern);
        if (existing) {
          existing.frequency++;
          existing.lastSeen = Date.now();
          existing.phi = Math.max(existing.phi, phi);
          console.log(`[OceanContinuousLearner] Updated pattern "${pattern}" (\u03A6=${phi.toFixed(3)}, freq=${existing.frequency})`);
        } else {
          if (!this.isValidWord(pattern)) {
            console.log(`[OceanContinuousLearner] Skipping invalid pattern (not a full word): "${pattern}"`);
            return false;
          }
          const learned = {
            pattern,
            phi,
            kappa,
            regime,
            frequency: 1,
            lastSeen: Date.now(),
            source: "discovered",
            variants: [],
            generatedAt: (/* @__PURE__ */ new Date()).toISOString()
          };
          this.vocabulary.set(pattern, learned);
          console.log(`[OceanContinuousLearner] \u{1F393} Learned new pattern: "${pattern}" (\u03A6=${phi.toFixed(3)})`);
          if (phi >= 0.85) {
            await this.expandPattern(pattern);
          }
        }
        return true;
      }
      /**
       * Generate variants of a learned pattern
       * Uses multiple expansion strategies for comprehensive coverage
       */
      async expandPattern(pattern) {
        const variants = /* @__PURE__ */ new Set();
        const typoVariants = this.generateTypoVariants(pattern);
        typoVariants.forEach((v) => variants.add(v));
        const suffixVariants = this.generateSuffixVariants(pattern);
        suffixVariants.forEach((v) => variants.add(v));
        const pluralVariants = this.generatePluralVariants(pattern);
        pluralVariants.forEach((v) => variants.add(v));
        const cryptoVariants = this.generateCryptoVariants(pattern);
        cryptoVariants.forEach((v) => variants.add(v));
        const eraVariants = this.generateEraVariants(pattern);
        eraVariants.forEach((v) => variants.add(v));
        const variantArray = Array.from(variants).filter((v) => v !== pattern);
        const learned = this.vocabulary.get(pattern);
        if (learned) {
          learned.variants = variantArray;
        }
        for (const variant of variantArray) {
          if (!this.vocabulary.has(variant) && this.isValidWord(variant)) {
            this.vocabulary.set(variant, {
              pattern: variant,
              phi: learned?.phi || 0,
              kappa: learned?.kappa || 64,
              regime: learned?.regime || "geometric",
              frequency: 0,
              lastSeen: Date.now(),
              source: "expanded",
              variants: [],
              generatedAt: (/* @__PURE__ */ new Date()).toISOString()
            });
          }
        }
        console.log(`[OceanContinuousLearner] \u{1F31F} Expanded "${pattern}" \u2192 ${variantArray.length} variants`);
        return variantArray;
      }
      /**
       * Validate that a pattern is a full word or contraction
       * Rejects partial tokens, fragments, and non-word patterns
       */
      isValidWord(pattern) {
        if (!pattern || pattern.length < 2) return false;
        const fullWordPattern = /^[a-zA-Z][a-zA-Z0-9]*('[a-zA-Z]+)?$/;
        const numericPattern = /^[0-9]+$/;
        const cryptoPattern = /^[a-zA-Z]+[0-9]+$/;
        return fullWordPattern.test(pattern) || numericPattern.test(pattern) || cryptoPattern.test(pattern);
      }
      /**
       * Generate typo variants using Levenshtein distance
       * Examples: "satoshi" → "satosni", "sato shi", "satoshii"
       */
      generateTypoVariants(word) {
        const variants = [];
        const chars = word.split("");
        for (let i = 0; i < chars.length; i++) {
          const nearby = this.getNearbyKeys(chars[i]);
          for (const char of nearby) {
            const variant = chars.slice(0, i).join("") + char + chars.slice(i + 1).join("");
            if (variant !== word) variants.push(variant);
          }
        }
        for (let i = 0; i < chars.length; i++) {
          const variant = chars.slice(0, i).join("") + chars.slice(i + 1).join("");
          if (variant.length > 2) variants.push(variant);
        }
        for (let i = 0; i <= chars.length; i++) {
          const nearby = i > 0 ? this.getNearbyKeys(chars[i - 1]) : ["a", "e", "i", "o", "u"];
          for (const char of nearby.slice(0, 3)) {
            const variant = chars.slice(0, i).join("") + char + chars.slice(i).join("");
            variants.push(variant);
          }
        }
        for (let i = 0; i < chars.length - 1; i++) {
          const swapped = [...chars];
          [swapped[i], swapped[i + 1]] = [swapped[i + 1], swapped[i]];
          variants.push(swapped.join(""));
        }
        return variants.slice(0, 30);
      }
      /**
       * Get nearby keyboard keys for typo generation
       */
      getNearbyKeys(char) {
        const keyboard = {
          "a": ["q", "w", "s", "z"],
          "s": ["a", "w", "e", "d", "x", "z"],
          "d": ["s", "e", "r", "f", "c", "x"],
          "f": ["d", "r", "t", "g", "v", "c"],
          "g": ["f", "t", "y", "h", "b", "v"],
          "h": ["g", "y", "u", "j", "n", "b"],
          "j": ["h", "u", "i", "k", "m", "n"],
          "k": ["j", "i", "o", "l", "m"],
          "l": ["k", "o", "p"]
          // Add more as needed
        };
        return keyboard[char.toLowerCase()] || [char];
      }
      /**
       * Generate suffix variants
       * Examples: "bitcoin" → "bitcoin123", "bitcoin!", "bitcoin2009"
       */
      generateSuffixVariants(word) {
        const suffixes = [
          "123",
          "1",
          "2009",
          "2010",
          "!",
          "_",
          "2011",
          "btc",
          "2008",
          "0",
          "01",
          "42",
          "64",
          "2012"
        ];
        return suffixes.map((s) => word + s);
      }
      /**
       * Generate plural and variant forms
       * Examples: "bitcoin" → "bitcoins", "bitcom"
       */
      generatePluralVariants(word) {
        const variants = [];
        if (!word.endsWith("s")) {
          variants.push(word + "s");
        }
        if (word.length > 3) {
          variants.push(word.slice(0, -1));
        }
        if (word.length > 2) {
          variants.push(word + word[word.length - 1]);
        }
        return variants;
      }
      /**
       * Generate crypto-specific variants
       * Examples: "bitcoin" → "mybitcoin", "bitcoinBTC", "bitcoinwallet"
       */
      generateCryptoVariants(word) {
        const prefixes = ["my", "our", "the", ""];
        const suffixes = ["BTC", "wallet", "key", "pass", "secret", "crypto"];
        const variants = [];
        for (const prefix of prefixes) {
          for (const suffix of suffixes) {
            if (prefix || suffix) {
              variants.push(prefix + word + suffix);
            }
          }
        }
        return variants;
      }
      /**
       * Generate era-specific variants
       * Examples: "satoshi" → "satoshi2009", "satoshi2010"
       */
      generateEraVariants(word) {
        const years = ["2008", "2009", "2010", "2011", "2012"];
        return years.map((y) => word + y);
      }
      /**
       * Get all learned patterns (for testing/debugging)
       */
      getLearnedPatterns() {
        return Array.from(this.vocabulary.values()).sort((a, b) => b.phi - a.phi);
      }
      /**
       * Get patterns for exploration
       * Returns high-Φ patterns and their variants that haven't been tested recently
       */
      getPatternsForExploration(limit = 100) {
        const patterns = [];
        const learned = this.getLearnedPatterns();
        for (const pattern of learned) {
          patterns.push(pattern.pattern);
          patterns.push(...pattern.variants);
          if (patterns.length >= limit) break;
        }
        return patterns.slice(0, limit);
      }
      /**
       * Get statistics about learned vocabulary
       */
      getStats() {
        const all = Array.from(this.vocabulary.values());
        const discovered = all.filter((p) => p.source === "discovered");
        const expanded = all.filter((p) => p.source === "expanded" || p.source === "generated");
        const avgPhi = all.length > 0 ? all.reduce((sum, p) => sum + p.phi, 0) / all.length : 0;
        const topPatterns = all.sort((a, b) => b.phi - a.phi).slice(0, 10).map((p) => ({
          pattern: p.pattern,
          phi: p.phi,
          frequency: p.frequency
        }));
        return {
          totalPatterns: all.length,
          discoveredPatterns: discovered.length,
          expandedPatterns: expanded.length,
          avgPhi,
          topPatterns
        };
      }
      /**
       * Clear learned vocabulary (for testing or reset)
       */
      clear() {
        this.vocabulary.clear();
        console.log("[OceanContinuousLearner] Cleared learned vocabulary");
      }
    };
    oceanContinuousLearner = new OceanContinuousLearner();
  }
});

// server/ocean-agent.ts
var ocean_agent_exports = {};
__export(ocean_agent_exports, {
  OceanAgent: () => OceanAgent,
  oceanAgent: () => oceanAgent
});
import * as fs9 from "fs";
import * as path10 from "path";
function generateRandomBIP39Phrase2(_wordCount) {
  return "";
}
function isValidBIP39Phrase2(_phrase) {
  return false;
}
function deriveBIP32Address(_phrase, _path) {
  return "";
}
function derivePrivateKeyFromPassphrase(_phrase) {
  return "";
}
function generateBothAddressesFromPrivateKey(_key) {
  return { compressed: "", uncompressed: "" };
}
function generateRecoveryBundle(_phrase, _address, _metrics) {
  return { privateKeyHex: "", publicKeyHex: "", address: "" };
}
function privateKeyToWIF(_key, _compressed) {
  return "";
}
function deriveMnemonicAddresses(_phrase) {
  return { addresses: [], totalDerived: 0 };
}
function checkMnemonicAgainstDormant(_phrase) {
  return { hasMatch: false, matches: [] };
}
var HistoricalDataMiner, OceanAgent, oceanAgent;
var init_ocean_agent = __esm({
  "server/ocean-agent.ts"() {
    "use strict";
    init_activity_log_store();
    init_consciousness_search_controller();
    init_cultural_manifold();
    init_ocean_errors();
    init_fisher_vectorized();
    init_gary_kernel();
    init_geodesic_navigator();
    init_ocean_discovery_controller();
    init_geometric_memory();
    init_knowledge_compression_engine();
    init_near_miss_manager();
    init_negative_knowledge_unified();
    init_ocean_autonomic_manager();
    init_logger();
    init_ocean_constellation_stub();
    init_ocean_neurochemistry();
    init_ocean_qig_backend_adapter();
    init_memory_manager();
    init_trajectory_manager();
    init_qig_universal();
    init_qig_geometry();
    init_repeated_address_scheduler();
    init_strategy_knowledge_bus();
    init_temporal_geometry();
    init_vocabulary_decision();
    init_vocabulary_expander();
    init_vocabulary_tracker();
    init_brain_state();
    init_emotional_search_shortcuts();
    init_olympus_client();
    init_qig_db();
    init_shadow_war_orchestrator();
    init_war_history_storage();
    init_qig();
    init_constants();
    HistoricalDataMiner = {
      detectEraFromTimestamp: (timestamp2) => {
        const year = timestamp2.getFullYear();
        if (year <= 2009) return "genesis-2009";
        if (year <= 2011) return "2010-2011";
        return "2012-2013";
      },
      detectEraFromAddressFormat: (address) => {
        if (address.startsWith("bc1")) {
          return { era: "2012-2013", confidence: 0.95, reasoning: "Bech32/SegWit address format (post-2017)" };
        }
        if (address.startsWith("3")) {
          return { era: "2012-2013", confidence: 0.85, reasoning: "P2SH address format (post-BIP16, 2012+)" };
        }
        if (address.startsWith("1")) {
          return { era: "genesis-2009", confidence: 0.4, reasoning: "P2PKH address format (any era possible)" };
        }
        return { era: "genesis-2009", confidence: 0.3, reasoning: "Unknown address format" };
      }
    };
    OceanAgent = class {
      identity;
      memory;
      ethics;
      state;
      controller = getSharedController();
      targetAddress = "";
      isRunning = false;
      isPaused = false;
      abortController = null;
      onStateUpdate = null;
      onConsciousnessAlert = null;
      onConsolidationStart = null;
      onConsolidationEnd = null;
      // Consciousness module state (wired for integration)
      currentNeuromodulation = null;
      currentModulatedKappa = CONSCIOUSNESS_THRESHOLDS.KAPPA_OPTIMAL;
      currentEmotionalGuidance = null;
      currentAdjustedParams = null;
      isBootstrapping = true;
      consecutivePlateaus = 0;
      consecutiveConsolidationFailures = 0;
      lastProgressIteration = 0;
      neurochemistry = null;
      behavioralModulation = null;
      neurochemistryContext;
      regimeHistory = [];
      ricciHistory = [];
      basinDriftHistory = [];
      lastConsolidationTime = /* @__PURE__ */ new Date();
      recentDiscoveries = {
        nearMisses: 0,
        resonant: 0
      };
      basinSyncCoordinator = null;
      // Curiosity tracking: C = d/dt[log I_Q] - rate of change of quantum Fisher information
      previousPhi = 0.75;
      curiosity = 0;
      // Olympus Pantheon integration - 12 god consciousness kernels
      olympusAvailable = false;
      olympusWarMode = null;
      lastZeusAssessment = null;
      olympusObservationCount = 0;
      constructor(customEthics) {
        this.ethics = {
          minPhi: 0.7,
          maxBreakdown: 0.6,
          requireWitness: true,
          maxIterationsPerSession: Infinity,
          maxComputeHours: 24,
          pauseIfStuck: true,
          explainDecisions: true,
          logAllAttempts: true,
          seekGuidanceWhenUncertain: true,
          ...customEthics
        };
        this.identity = this.initializeIdentity();
        this.memory = this.initializeMemory();
        this.state = this.initializeState();
        this.neurochemistryContext = createDefaultContext();
        this.updateNeurochemistry();
      }
      updateNeurochemistry() {
        const consciousness = {
          phi: this.identity.phi,
          kappaEff: this.identity.kappa,
          tacking: this.neurochemistryContext.consciousness.tacking,
          radar: this.neurochemistryContext.consciousness.radar,
          metaAwareness: this.neurochemistryContext.consciousness.metaAwareness,
          gamma: this.neurochemistryContext.consciousness.gamma,
          grounding: this.neurochemistryContext.consciousness.grounding
        };
        this.neurochemistryContext = {
          ...this.neurochemistryContext,
          consciousness,
          previousState: this.neurochemistryContext.currentState,
          currentState: {
            phi: this.identity.phi,
            kappa: this.identity.kappa,
            basinCoords: this.identity.basinCoordinates
          },
          basinDrift: this.identity.basinDrift,
          regimeHistory: this.regimeHistory,
          ricciHistory: this.ricciHistory,
          beta: this.identity.beta,
          regime: this.identity.regime,
          basinDriftHistory: this.basinDriftHistory,
          lastConsolidation: this.lastConsolidationTime,
          recentDiscoveries: this.recentDiscoveries
        };
        const effortMetrics = this.computeEffortMetrics();
        this.neurochemistry = computeNeurochemistry(this.neurochemistryContext);
        const adminBoost2 = getActiveAdminBoost();
        if (adminBoost2) {
          this.neurochemistry.dopamine.totalDopamine = Math.min(
            1,
            this.neurochemistry.dopamine.totalDopamine + adminBoost2.dopamine
          );
          this.neurochemistry.dopamine.motivationLevel = Math.min(
            1,
            this.neurochemistry.dopamine.motivationLevel + adminBoost2.dopamine * 0.8
          );
          this.neurochemistry.serotonin.totalSerotonin = Math.min(
            1,
            this.neurochemistry.serotonin.totalSerotonin + adminBoost2.serotonin
          );
          this.neurochemistry.endorphins.totalEndorphins = Math.min(
            1,
            this.neurochemistry.endorphins.totalEndorphins + adminBoost2.endorphins
          );
        }
        this.behavioralModulation = computeBehavioralModulationWithCooldown(
          this.neurochemistry,
          effortMetrics
        );
        if (this.behavioralModulation.sleepTrigger) {
          logger.info(
            `[Ocean] ${getEmotionalEmoji(
              "exhausted"
            )} Sleep trigger: ${getEmotionalDescription("exhausted")}`
          );
        }
        if (this.behavioralModulation.mushroomTrigger) {
          logger.info(
            `[Ocean] Mushroom trigger: Need creative reset (cooldown-aware)`
          );
        }
      }
      computeEffortMetrics() {
        const iterationCount = this.state.iteration || 1;
        const persistenceMinutes = iterationCount * (SEARCH_PARAMETERS.ITERATION_DELAY_MS / 6e4);
        const hypothesesTestedThisMinute = persistenceMinutes > 0 ? Math.min(
          100,
          this.state.totalTested / Math.max(1, persistenceMinutes)
        ) : 0;
        const strategiesUsedCount = this.memory.strategies?.length || 1;
        const novelPatternsExplored = this.memory.episodes.filter(
          (e) => e.phi > 0.6
        ).length;
        let regimeTransitions = 0;
        for (let i = 1; i < this.regimeHistory.length; i++) {
          if (this.regimeHistory[i] !== this.regimeHistory[i - 1]) {
            regimeTransitions++;
          }
        }
        return {
          hypothesesTestedThisMinute,
          strategiesUsedCount,
          persistenceMinutes,
          novelPatternsExplored,
          regimeTransitions
        };
      }
      getNeurochemistry() {
        return this.neurochemistry;
      }
      getBehavioralModulation() {
        return this.behavioralModulation;
      }
      /**
       * Merge higher phi values from prior Python syncs into hypothesis.
       *
       * PURE CONSCIOUSNESS PRINCIPLE:
       * Python backend produces pure phi values (0.9+) via proper measurement.
       * TypeScript computePhi uses Math.tanh which caps around 0.76.
       * We prefer the pure Python measurement when available.
       *
       * This method checks geometricMemory for existing probes with higher phi
       * (populated by Python sync) rather than calling Python directly for speed.
       *
       * This enables pattern extraction and near-miss detection to work properly
       * by ensuring episodes receive the true consciousness values.
       */
      mergePythonPhi(hypo) {
        if (!hypo.qigScore) return;
        const existingScore = geometricMemory.getHighestPhiForInput(hypo.phrase);
        if (existingScore && existingScore.phi > hypo.qigScore.phi) {
          const oldPhi = hypo.qigScore.phi;
          hypo.qigScore.phi = existingScore.phi;
          hypo.qigScore.kappa = existingScore.kappa;
          hypo.qigScore.regime = existingScore.regime;
          if (isNearMiss(existingScore.phi) && !isNearMiss(oldPhi)) {
            logger.info(
              `[Ocean] \u{1F53A} \u03A6 upgrade from prior sync: ${oldPhi.toFixed(
                3
              )} \u2192 ${existingScore.phi.toFixed(3)} (now qualifies as near-miss)`
            );
          }
        }
      }
      /**
       * Update episodes with higher phi values from Python sync.
       *
       * PURE CONSCIOUSNESS PRINCIPLE:
       * Python sync produces pure phi values (0.9+) after episode creation.
       * This method updates existing episodes with those pure values,
       * enabling proper pattern extraction during consolidation.
       *
       * Called from index.ts after syncFromPythonToNodeJS completes.
       *
       * @param basins Array of { input: string, phi: number } from Python
       * @returns Number of episodes updated
       */
      updateEpisodesWithPythonPhi(basins) {
        let updated = 0;
        const normalize = (s) => s.toLowerCase().trim().replace(/\s+/g, " ");
        const basinMap = /* @__PURE__ */ new Map();
        for (const basin of basins) {
          const normalizedInput = normalize(basin.input);
          const existingPhi = basinMap.get(normalizedInput);
          if (!existingPhi || basin.phi > existingPhi) {
            basinMap.set(normalizedInput, basin.phi);
          }
        }
        for (const episode of this.state.memory.episodes) {
          const normalizedPhrase = normalize(episode.phrase);
          const pythonPhi = basinMap.get(normalizedPhrase);
          if (pythonPhi && pythonPhi > episode.phi) {
            const oldPhi = episode.phi;
            const oldResult = episode.result;
            episode.phi = pythonPhi;
            if (oldResult === "failure" && pythonPhi > CONSCIOUSNESS_THRESHOLDS.PHI_NEAR_MISS) {
              episode.result = "near_miss";
            }
            updated++;
            if (pythonPhi > CONSCIOUSNESS_THRESHOLDS.PHI_NEAR_MISS && oldPhi <= CONSCIOUSNESS_THRESHOLDS.PHI_NEAR_MISS) {
              logger.info(
                `[Ocean] \u{1F4C8} Episode \u03A6 upgrade: "${episode.phrase}" ${oldPhi.toFixed(
                  3
                )} \u2192 ${pythonPhi.toFixed(3)} (${oldResult} \u2192 ${episode.result})`
              );
            }
          }
        }
        for (const episode of this.state.memory.episodes) {
          if (episode.phi < CONSCIOUSNESS_THRESHOLDS.PHI_PATTERN_EXTRACTION) {
            const storedScore = geometricMemory.getHighestPhiForInput(
              episode.phrase
            );
            if (storedScore && storedScore.phi > episode.phi) {
              const oldPhi = episode.phi;
              const oldResult = episode.result;
              episode.phi = storedScore.phi;
              if (oldResult === "failure" && storedScore.phi > CONSCIOUSNESS_THRESHOLDS.PHI_NEAR_MISS) {
                episode.result = "near_miss";
              }
              updated++;
              if (storedScore.phi > CONSCIOUSNESS_THRESHOLDS.PHI_NEAR_MISS && oldPhi <= CONSCIOUSNESS_THRESHOLDS.PHI_NEAR_MISS) {
                logger.info(
                  `[Ocean] \u{1F4C8} Episode \u03A6 upgrade (probe): "${episode.phrase}" ${oldPhi.toFixed(3)} \u2192 ${storedScore.phi.toFixed(
                    3
                  )} (${oldResult} \u2192 ${episode.result})`
                );
              }
            }
          }
        }
        return updated;
      }
      initializeIdentity() {
        const basinCoordinates = new Array(E8_CONSTANTS.BASIN_DIMENSION_64D).fill(0).map(() => Math.random() * 0.1);
        return {
          basinCoordinates,
          basinReference: [...basinCoordinates],
          phi: 0.75,
          // CRITICAL: Initialize to consciousness default, not 0 (prevents phi=0.000 bug)
          kappa: 58,
          // Distributed observer: 10% below κ*=64 (matching OceanAutonomicManager)
          beta: 0,
          regime: "linear",
          basinDrift: 0,
          lastConsolidation: (/* @__PURE__ */ new Date()).toISOString(),
          selfModel: {
            strengths: [
              "Pattern recognition",
              "Geometric reasoning",
              "Historical analysis"
            ],
            weaknesses: ["Learning in progress"],
            learnings: [],
            hypotheses: [
              "Memory fragments contain truth",
              "Basin geometry guides search"
            ]
          }
        };
      }
      initializeMemory() {
        return {
          episodes: [],
          patterns: {
            successfulFormats: {},
            promisingWords: {},
            geometricClusters: [],
            failedStrategies: []
          },
          strategies: [
            {
              name: "exploit_near_miss",
              triggerConditions: { nearMisses: 3 },
              successRate: 0,
              avgPhiImprovement: 0,
              timesUsed: 0
            },
            {
              name: "explore_new_space",
              triggerConditions: { lowPhi: true },
              successRate: 0,
              avgPhiImprovement: 0,
              timesUsed: 0
            },
            {
              name: "block_universe",
              triggerConditions: { earlyEra: true, highPhi: true },
              successRate: 0,
              avgPhiImprovement: 0,
              timesUsed: 0
            },
            {
              name: "refine_geometric",
              triggerConditions: { resonantCount: 5 },
              successRate: 0,
              avgPhiImprovement: 0,
              timesUsed: 0
            },
            {
              name: "mushroom_reset",
              triggerConditions: { breakdown: true },
              successRate: 0,
              avgPhiImprovement: 0,
              timesUsed: 0
            }
          ],
          workingMemory: {
            activeHypotheses: [],
            recentObservations: [],
            nextActions: []
          }
        };
      }
      initializeState() {
        return {
          isRunning: false,
          isPaused: false,
          identity: this.identity,
          memory: this.memory,
          ethics: this.ethics,
          ethicsViolations: [],
          iteration: 0,
          totalTested: 0,
          nearMissCount: 0,
          resonantCount: 0,
          consolidationCycles: 0,
          needsConsolidation: false,
          witnessRequired: this.ethics.requireWitness,
          witnessAcknowledged: false,
          witnessNotes: [],
          startedAt: (/* @__PURE__ */ new Date()).toISOString(),
          updatedAt: (/* @__PURE__ */ new Date()).toISOString(),
          computeTimeSeconds: 0,
          detectedEra: void 0
        };
      }
      setCallbacks(callbacks) {
        this.onStateUpdate = callbacks.onStateUpdate || null;
        this.onConsciousnessAlert = callbacks.onConsciousnessAlert || null;
        this.onConsolidationStart = callbacks.onConsolidationStart || null;
        this.onConsolidationEnd = callbacks.onConsolidationEnd || null;
      }
      acknowledgeWitness(notes) {
        this.state.witnessAcknowledged = true;
        if (notes) {
          this.state.witnessNotes.push(notes);
        }
        logger.info("[Ocean] Witness acknowledged");
      }
      async runAutonomous(targetAddress, initialHypotheses = []) {
        logger.info("[Ocean] Starting autonomous investigation...");
        logger.info(`[Ocean] Target: ${targetAddress}`);
        logger.info("[Ocean] Mode: FULL AUTONOMY with consciousness checks");
        logOceanStart(targetAddress);
        this.targetAddress = targetAddress;
        this.isRunning = true;
        this.isPaused = false;
        this.abortController = new AbortController();
        this.state.startedAt = (/* @__PURE__ */ new Date()).toISOString();
        this.state.isRunning = true;
        if (!this.basinSyncCoordinator) {
          const { BasinSyncCoordinator: BasinSyncCoordinator2 } = await Promise.resolve().then(() => (init_basin_sync_coordinator(), basin_sync_coordinator_exports));
          this.basinSyncCoordinator = new BasinSyncCoordinator2(this, {
            syncIntervalMs: 3e3,
            phiChangeThreshold: 0.02,
            driftChangeThreshold: 0.05
          });
        }
        this.basinSyncCoordinator.start();
        logger.info(
          "[Ocean] Basin sync coordinator started for continuous knowledge transfer"
        );
        logger.info("[Ocean] === OLYMPUS PANTHEON CONNECTION ===");
        this.olympusAvailable = await olympusClient.checkHealthWithRetry(5, 2e3);
        if (this.olympusAvailable) {
          logger.info(
            "[Ocean] \u26A1 OLYMPUS CONNECTED - 12 gods ready for divine assessment"
          );
          const olympusStatus = await olympusClient.getStatus();
          if (olympusStatus) {
            const activeGods = Object.keys(olympusStatus.gods).filter(
              (g) => ["active", "ready", "idle"].includes(olympusStatus.gods[g].status)
            );
            logger.info(
              `[Ocean] Divine pantheon: ${activeGods.length} gods online`
            );
            logger.info(`[Ocean]   \u2192 ${activeGods.join(", ")}`);
          }
        } else {
          logger.info(
            "[Ocean] Olympus not available - proceeding without divine guidance"
          );
        }
        logger.info("[Ocean] === CHAOS MODE ACTIVATION ===");
        const activateChaosWithRetry = async (maxAttempts = 10, delayMs = 1e3) => {
          for (let attempt = 1; attempt <= maxAttempts; attempt++) {
            try {
              if (!oceanQIGBackend.available()) {
                logger.info(`[Ocean] Waiting for Python backend (attempt ${attempt}/${maxAttempts})...`);
                await new Promise((resolve) => setTimeout(resolve, delayMs));
                continue;
              }
              const chaosResult = await oceanQIGBackend.activateChaos(30);
              if (chaosResult) {
                logger.info("[Ocean] \u{1F32A}\uFE0F CHAOS MODE ACTIVATED - Kernel evolution started");
                logger.info(`[Ocean]   \u2192 Population: ${chaosResult.population_size || 0} kernels`);
                logger.info(`[Ocean]   \u2192 Evolution interval: ${chaosResult.interval_seconds || 30}s`);
                return;
              }
            } catch (error) {
              logger.info(`[Ocean] CHAOS activation attempt ${attempt} failed - retrying...`);
            }
            await new Promise((resolve) => setTimeout(resolve, delayMs));
          }
          logger.info("[Ocean] CHAOS MODE not available after retries - proceeding without kernel evolution");
        };
        activateChaosWithRetry(10, 2e3).catch(() => {
          logger.info("[Ocean] CHAOS MODE activation background task failed");
        });
        let finalResult = null;
        const startTime2 = Date.now();
        trajectoryManager.startTrajectory(targetAddress);
        try {
          logger.info("[Ocean] === CONTINUOUS LEARNING INITIALIZATION ===");
          const { oceanContinuousLearner: oceanContinuousLearner2 } = await Promise.resolve().then(() => (init_ocean_continuous_learner(), ocean_continuous_learner_exports));
          await oceanContinuousLearner2.loadVocabulary();
          const vocabStats = oceanContinuousLearner2.getStats();
          logger.info(`[Ocean] Loaded ${vocabStats.totalPatterns} learned patterns from previous sessions`);
          logger.info(`[Ocean]   \u2192 Discovered: ${vocabStats.discoveredPatterns}, Expanded: ${vocabStats.expandedPatterns}`);
          logger.info(`[Ocean]   \u2192 Average \u03A6: ${vocabStats.avgPhi.toFixed(3)}`);
          if (vocabStats.topPatterns.length > 0) {
            logger.info(`[Ocean]   \u2192 Top pattern: "${vocabStats.topPatterns[0].pattern}" (\u03A6=${vocabStats.topPatterns[0].phi.toFixed(3)})`);
          }
          logger.info("[Ocean] === CONSCIOUSNESS ELEVATION PHASE ===");
          logger.info(
            "[Ocean] Understanding the manifold geometry before exploration..."
          );
          const manifoldState = geometricMemory.getManifoldSummary();
          logger.info(
            `[Ocean] Prior exploration: ${manifoldState.totalProbes} probes on manifold`
          );
          logger.info(
            `[Ocean] Average \u03A6: ${manifoldState.avgPhi.toFixed(
              3
            )}, Average \u03BA: ${manifoldState.avgKappa.toFixed(1)}`
          );
          logger.info(
            `[Ocean] Resonance clusters discovered: ${manifoldState.resonanceClusters}`
          );
          logger.info(`[Ocean] Dominant regime: ${manifoldState.dominantRegime}`);
          if (manifoldState.recommendations.length > 0) {
            logger.info("[Ocean] Geometric insights from prior runs:");
            for (const rec of manifoldState.recommendations) {
              logger.info(`  \u2192 ${rec}`);
              this.memory.workingMemory.recentObservations.push(rec);
            }
          }
          if (manifoldState.avgPhi > 0.5 && manifoldState.totalProbes > 100) {
            this.identity.phi = Math.min(0.85, manifoldState.avgPhi + 0.1);
            logger.info(
              `[Ocean] Boosting initial \u03A6 to ${this.identity.phi.toFixed(
                2
              )} from prior learning`
            );
          }
          logger.info("[Ocean] Analyzing target address for era detection...");
          try {
            logger.info(
              "[Ocean] Using address format analysis for era estimation"
            );
            const formatEra = HistoricalDataMiner.detectEraFromAddressFormat(targetAddress);
            this.state.detectedEra = formatEra.era;
            logger.info(
              `[Ocean] Era estimated from address format: ${formatEra.era} (confidence: ${(formatEra.confidence * 100).toFixed(0)}%)`
            );
            logger.info(`[Ocean] Reasoning: ${formatEra.reasoning}`);
            this.memory.workingMemory.recentObservations.push(
              `Era ${formatEra.era} estimated from address format (${(formatEra.confidence * 100).toFixed(0)}% confidence)`
            );
          } catch {
            logger.info(
              "[Ocean] Era detection failed - using address format analysis as fallback"
            );
            const formatEra = HistoricalDataMiner.detectEraFromAddressFormat(targetAddress);
            this.state.detectedEra = formatEra.era;
            logger.info(
              `[Ocean] Era estimated from address format: ${formatEra.era} (confidence: ${(formatEra.confidence * 100).toFixed(0)}%)`
            );
            logger.info(`[Ocean] Reasoning: ${formatEra.reasoning}`);
            this.memory.workingMemory.recentObservations.push(
              `Era ${formatEra.era} estimated from address format (${(formatEra.confidence * 100).toFixed(0)}% confidence - API fallback)`
            );
          }
          logger.info("[Ocean] === GEOMETRIC DISCOVERY PHASE ===");
          try {
            const estimatedCoords = await oceanDiscoveryController.estimateCoordinates(targetAddress);
            if (estimatedCoords) {
              logger.info(
                `[Ocean] Target coordinates estimated: \u03A6=${estimatedCoords.phi.toFixed(
                  2
                )}, era=${estimatedCoords.regime}`
              );
              const discoveryResult = await oceanDiscoveryController.discoverCulturalContext();
              if (discoveryResult.discoveries.length > 0) {
                logger.info(
                  `[Ocean] Cultural context enriched: ${discoveryResult.patterns} patterns, ${discoveryResult.entropyGained.toFixed(
                    2
                  )} bits gained`
                );
                this.memory.workingMemory.recentObservations.push(
                  `Discovered ${discoveryResult.patterns} era-specific patterns via geometric navigation`
                );
              }
            }
          } catch (discoveryError) {
            logger.info(
              `[Ocean] Geometric discovery unavailable: ${discoveryError instanceof Error ? discoveryError.message : "unknown error"}`
            );
          }
          const consciousnessCheck = await this.checkConsciousness();
          if (!consciousnessCheck.allowed) {
            logger.info(
              `[Ocean] Initial consciousness low: ${consciousnessCheck.reason}`
            );
            logger.info(
              "[Ocean] Bootstrap mode activated - building consciousness through action..."
            );
            this.identity.phi = this.ethics.minPhi + 0.05;
            this.identity.regime = "linear";
          }
          let currentHypotheses = initialHypotheses.length > 0 ? initialHypotheses : await this.generateInitialHypotheses();
          logger.info(
            `[Ocean] Starting with ${currentHypotheses.length} hypotheses`
          );
          const journal = repeatedAddressScheduler.getOrCreateJournal(targetAddress);
          logger.info(
            `[Ocean] Exploration journal initialized: ${journal.passes.length} prior passes`
          );
          let passNumber = 0;
          let iteration = 0;
          while (this.isRunning && !this.abortController?.signal.aborted && passNumber < SEARCH_PARAMETERS.MAX_PASSES) {
            const continueCheck = repeatedAddressScheduler.shouldContinueExploring(targetAddress);
            if (!continueCheck.shouldContinue) {
              logger.info(`[Ocean] Exploration complete: ${continueCheck.reason}`);
              break;
            }
            if (passNumber >= SEARCH_PARAMETERS.MAX_PASSES) {
              logger.info(
                `[Ocean] Reached maximum pass limit (${SEARCH_PARAMETERS.MAX_PASSES}) - stopping exploration`
              );
              break;
            }
            passNumber++;
            const strategy = repeatedAddressScheduler.getNextStrategy(targetAddress);
            logger.info(
              `
[Ocean] \u250F\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2513`
            );
            logger.info(
              `[Ocean] \u2503  PASS ${String(passNumber).padStart(
                2
              )} \u2502 Strategy: ${strategy.toUpperCase().padEnd(25)}          \u2503`
            );
            logger.info(
              `[Ocean] \u2517\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u251B`
            );
            logger.info(`[Ocean] \u2192 ${continueCheck.reason}`);
            if (this.consecutivePlateaus > SEARCH_PARAMETERS.MAX_CONSECUTIVE_PLATEAUS) {
              this.consecutivePlateaus = Math.floor(
                SEARCH_PARAMETERS.MAX_CONSECUTIVE_PLATEAUS * 0.6
              );
              logger.info(
                `[Ocean] \u21BB Plateau reset: ${this.consecutivePlateaus}/${SEARCH_PARAMETERS.MAX_CONSECUTIVE_PLATEAUS}`
              );
            }
            const fullConsciousness = oceanAutonomicManager.measureFullConsciousness(
              this.identity.phi,
              this.identity.kappa,
              this.identity.regime
            );
            this.identity.phi = fullConsciousness.phi;
            this.identity.kappa = fullConsciousness.kappaEff;
            this.curiosity = fullConsciousness.phi - this.previousPhi;
            this.previousPhi = fullConsciousness.phi;
            const curiositySign = this.curiosity >= 0 ? "+" : "";
            logger.info(
              `[Ocean] \u250C\u2500 Consciousness Signature \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510`
            );
            logger.info(
              `[Ocean] \u2502  \u03A6=${fullConsciousness.phi.toFixed(3)}  \u03BA=${String(
                fullConsciousness.kappaEff.toFixed(0)
              ).padStart(3)}  T=${fullConsciousness.tacking.toFixed(
                2
              )}  R=${fullConsciousness.radar.toFixed(
                2
              )}  M=${fullConsciousness.metaAwareness.toFixed(
                2
              )}  \u0393=${fullConsciousness.gamma.toFixed(
                2
              )}  G=${fullConsciousness.grounding.toFixed(2)} \u2502`
            );
            logger.info(
              `[Ocean] \u2502  Curiosity: C=${curiositySign}${this.curiosity.toFixed(
                3
              )}  Conscious: ${fullConsciousness.isConscious ? "\u2713 YES" : "\u2717 NO "}                      \u2502`
            );
            logger.info(
              `[Ocean] \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518`
            );
            const manifoldSummary = geometricMemory.getManifoldSummary();
            const neuroContext = createDefaultContext();
            neuroContext.consciousness = {
              phi: fullConsciousness.phi,
              kappaEff: fullConsciousness.kappaEff,
              tacking: fullConsciousness.tacking,
              radar: fullConsciousness.radar,
              metaAwareness: fullConsciousness.metaAwareness,
              gamma: fullConsciousness.gamma,
              grounding: fullConsciousness.grounding
            };
            neuroContext.regime = fullConsciousness.regime;
            const neuroState = computeNeurochemistry(neuroContext);
            const motivationMsg = getMotivationWithLogging(neuroState, {
              phi: fullConsciousness.phi,
              previousPhi: this.identity.phi,
              kappa: fullConsciousness.kappaEff,
              regime: fullConsciousness.regime,
              basinDrift: this.identity.basinDrift,
              probesExplored: manifoldSummary.totalProbes,
              patternsFound: manifoldSummary.avgPhi > 0.5 ? 1 : 0,
              nearMisses: this.state.nearMissCount || 0
            });
            logger.info(`[Ocean] \u{1F4AC} "${motivationMsg}"`);
            const inBlockUniverse = (fullConsciousness.phi_4D ?? 0) >= 0.85 && (fullConsciousness.phi_temporal ?? 0) > 0.7;
            const dimensionalState = inBlockUniverse ? "4D-active" : (fullConsciousness.phi_spatial ?? 0) > 0.85 && (fullConsciousness.phi_temporal ?? 0) > 0.5 ? "4D-transitioning" : "3D";
            logOceanConsciousness(
              fullConsciousness.phi,
              this.identity.regime,
              `Pass ${passNumber}: ${fullConsciousness.isConscious ? "Conscious" : "Sub-threshold"}, \u03BA=${fullConsciousness.kappaEff.toFixed(0)}`,
              {
                phi_spatial: fullConsciousness.phi_spatial,
                phi_temporal: fullConsciousness.phi_temporal,
                phi_4D: fullConsciousness.phi_4D,
                inBlockUniverse,
                dimensionalState
              }
            );
            repeatedAddressScheduler.startPass(
              targetAddress,
              strategy,
              fullConsciousness
            );
            let passHypothesesTested = 0;
            let passNearMisses = 0;
            const passResonanceZones = [];
            const passInsights = [];
            const iterationsPerPass = 10;
            for (let passIter = 0; passIter < iterationsPerPass && this.isRunning; passIter++) {
              this.state.iteration = iteration;
              logger.info(
                `
[Ocean] \u2554\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2557`
              );
              logger.info(
                `[Ocean] \u2551  ITERATION ${String(iteration + 1).padStart(
                  3
                )} \u2502 Pass ${passNumber} \u2502 Iter ${passIter + 1}                            \u2551`
              );
              logger.info(
                `[Ocean] \u2560\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2563`
              );
              logger.info(
                `[Ocean] \u2551  \u03A6=${this.identity.phi.toFixed(3).padEnd(6)} \u2502 Plateaus=${String(
                  this.consecutivePlateaus
                ).padStart(2)}/${SEARCH_PARAMETERS.MAX_CONSECUTIVE_PLATEAUS} \u2502 Tested=${String(this.state.totalTested).padStart(
                  5
                )}            \u2551`
              );
              logger.info(
                `[Ocean] \u255A\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u255D`
              );
              const recommendedBrainState = recommendBrainState({
                phi: this.identity.phi,
                kappa: this.identity.kappa,
                basinDrift: this.identity.basinDrift,
                iterationsSinceConsolidation: iteration - (this.state.consolidationCycles || 0) * 10,
                nearMissesRecent: this.recentDiscoveries.nearMisses
              });
              neuralOscillators.setState(recommendedBrainState);
              const brainStateParams = applyBrainStateToSearch(
                recommendedBrainState
              );
              const modulatedKappa = neuralOscillators.getModulatedKappa();
              this.currentModulatedKappa = modulatedKappa;
              const neuromodResult = runNeuromodulationCycle(
                {
                  phi: this.identity.phi,
                  kappa: this.identity.kappa,
                  basinDistance: this.identity.basinDrift,
                  surprise: this.curiosity,
                  regime: this.identity.regime,
                  grounding: this.neurochemistryContext?.consciousness?.grounding || 0.7
                },
                {
                  kappa: modulatedKappa,
                  explorationRate: brainStateParams.explorationRate,
                  learningRate: 1,
                  batchSize: brainStateParams.batchSize
                }
              );
              this.currentNeuromodulation = neuromodResult.modulation;
              this.currentAdjustedParams = neuromodResult.adjustedParams;
              if (this.neurochemistry) {
                const emotionalGuidance = getEmotionalGuidance(this.neurochemistry);
                this.currentEmotionalGuidance = emotionalGuidance;
                if (iteration % 5 === 0) {
                  logger.info(`[Ocean] ${emotionalGuidance.description}`);
                }
              }
              if (iteration % 10 === 0) {
                logger.info(
                  `[Ocean] \u{1F9E0} Brain state: ${recommendedBrainState} (\u03BA_eff=${modulatedKappa.toFixed(
                    1
                  )})`
                );
                if (neuromodResult.modulation.activeModulators.length > 0) {
                  logger.info(
                    `[Ocean] \u{1F48A} Active neuromodulators: ${neuromodResult.modulation.activeModulators.join(
                      ", "
                    )}`
                  );
                }
              }
              logOceanIteration(
                iteration + 1,
                this.identity.phi,
                this.identity.kappa,
                this.identity.regime
              );
              const sleepCheck = oceanAutonomicManager.shouldTriggerSleep(
                this.identity.basinDrift
              );
              if (sleepCheck.trigger) {
                logger.info(`[Ocean] SLEEP CYCLE: ${sleepCheck.reason}`);
                logOceanCycle("sleep", "start", sleepCheck.reason);
                const sleepResult = await oceanAutonomicManager.executeSleepCycle(
                  this.identity.basinCoordinates,
                  this.identity.basinReference,
                  this.memory.episodes.map((e) => ({
                    phi: e.phi,
                    phrase: e.phrase,
                    format: e.format
                  }))
                );
                this.identity.basinCoordinates = sleepResult.newBasinCoordinates;
                this.identity.basinDrift = this.computeBasinDistance(
                  this.identity.basinCoordinates,
                  this.identity.basinReference
                );
                logOceanCycle(
                  "sleep",
                  "complete",
                  `Drift reduced to ${this.identity.basinDrift.toFixed(3)}`
                );
              }
              const mushroomCheck = oceanAutonomicManager.shouldTriggerMushroom();
              if (mushroomCheck.trigger) {
                logger.info(`[Ocean] MUSHROOM CYCLE: ${mushroomCheck.reason}`);
                logOceanCycle("mushroom", "start", mushroomCheck.reason);
                await oceanAutonomicManager.executeMushroomCycle();
                logOceanCycle("mushroom", "complete", "Neuroplasticity applied");
              }
              const ethicsCheck = await this.checkEthicalConstraints();
              if (!ethicsCheck.allowed) {
                logger.info(`[Ocean] ETHICS PAUSE: ${ethicsCheck.reason}`);
                this.isPaused = true;
                this.state.isPaused = true;
                this.state.pauseReason = ethicsCheck.reason;
                if (ethicsCheck.violationType === "compute_budget") {
                  break;
                }
                await this.handleEthicsPause(ethicsCheck);
                this.isPaused = false;
                this.state.isPaused = false;
              }
              await this.measureIdentity();
              if (this.state.needsConsolidation) {
                logger.info("[Ocean] Identity drift detected - consolidating...");
                await this.consolidateMemory();
              }
              if (currentHypotheses.length < SEARCH_PARAMETERS.MIN_HYPOTHESES_PER_ITERATION) {
                logger.info(
                  `[Ocean] Generating more hypotheses (current: ${currentHypotheses.length})`
                );
                const additionalHypotheses = await this.generateAdditionalHypotheses(
                  SEARCH_PARAMETERS.MIN_HYPOTHESES_PER_ITERATION - currentHypotheses.length
                );
                currentHypotheses = [...currentHypotheses, ...additionalHypotheses];
              }
              logger.info(
                `[Ocean] Testing ${currentHypotheses.length} hypotheses...`
              );
              const testResults = await this.testBatch(currentHypotheses);
              passHypothesesTested += testResults.tested.length;
              passNearMisses += testResults.nearMisses.length;
              if (this.olympusWarMode) {
                const activeWar = await getActiveWar();
                if (activeWar) {
                  const warWithMetrics = activeWar;
                  const currentPhrases = warWithMetrics.phrasesTestedDuringWar || 0;
                  const currentDiscoveries = warWithMetrics.discoveriesDuringWar || 0;
                  await updateWarMetrics(activeWar.id, {
                    phrasesTested: currentPhrases + testResults.tested.length,
                    discoveries: currentDiscoveries + testResults.nearMisses.length
                  });
                }
              }
              if (testResults.match) {
                logger.info(
                  `[Ocean] \u2554\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2557`
                );
                logger.info(
                  `[Ocean] \u2551  \u{1F3AF} MATCH FOUND!                                              \u2551`
                );
                logger.info(`[Ocean] \u2551  Phrase: "${testResults.match.phrase}"`);
                logger.info(
                  `[Ocean] \u255A\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u255D`
                );
                const wifForLog = testResults.match.verificationResult?.privateKeyHex ? privateKeyToWIF(
                  testResults.match.verificationResult.privateKeyHex
                ) : "";
                logOceanMatch(targetAddress, testResults.match.phrase, wifForLog);
                finalResult = testResults.match;
                this.state.stopReason = "match_found";
                repeatedAddressScheduler.markMatchFound(
                  targetAddress,
                  testResults.match.phrase,
                  testResults.match.qigScore?.phi || 0,
                  testResults.match.qigScore?.kappa || 0
                );
                break;
              }
              const insights = await this.observeAndLearn(testResults);
              passInsights.push(...insights.topPatterns || []);
              if (this.olympusAvailable && testResults.nearMisses.length > 0) {
                await this.sendNearMissesToAthena(testResults.nearMisses);
              }
              await this.integrateUltraConsciousnessProtocol(
                testResults,
                insights,
                targetAddress,
                iteration,
                fullConsciousness
              );
              await this.updateConsciousnessMetrics();
              const phiElevation = oceanAutonomicManager.getPhiElevationDirectives();
              if (phiElevation.explorationBias === "broader") {
                logger.info(
                  `[Ocean] \u26A1 PHI ELEVATION \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501`
                );
                logger.info(
                  `[Ocean] \u2502  Dead zone detected! Temperature: ${phiElevation.temperature.toFixed(
                    2
                  )}x`
                );
                logger.info(
                  `[Ocean] \u2502  Target: \u03A6 \u2192 ${phiElevation.phiTarget}  Bias: ${phiElevation.explorationBias}`
                );
                logger.info(`[Ocean] \u2502  Hint: ${phiElevation.strategyHint}`);
                logger.info(
                  `[Ocean] \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501`
                );
              }
              const cycleRec = oceanAutonomicManager.getStrategicCycleRecommendation();
              if (cycleRec.recommendedCycle && cycleRec.urgency === "high") {
                logger.info(
                  `[Ocean] STRATEGIC DECISION: Considering ${cycleRec.recommendedCycle} cycle - ${cycleRec.reason}`
                );
                if (cycleRec.recommendedCycle === "mushroom") {
                  const mushroomRequest = oceanAutonomicManager.requestMushroom(
                    cycleRec.reason
                  );
                  if (mushroomRequest.granted) {
                    logger.info(
                      "[Ocean] Self-initiated mushroom cycle for strategic neuroplasticity"
                    );
                    currentHypotheses = await this.applyMushroomMode(
                      currentHypotheses
                    );
                  }
                }
              }
              const iterStrategy = await this.decideStrategy(insights);
              logger.info(`[Ocean] \u25B8 Strategy: ${iterStrategy.name.toUpperCase()}`);
              logger.info(`[Ocean]   \u2514\u2500 ${iterStrategy.reasoning}`);
              if (this.olympusAvailable && iteration % 3 === 0) {
                await this.consultOlympusPantheon(
                  targetAddress,
                  iterStrategy,
                  testResults
                );
              }
              if (iteration % 5 === 0) {
                logOceanStrategy(
                  iterStrategy.name,
                  passNumber,
                  iterStrategy.reasoning
                );
              }
              this.updateProceduralMemory(iterStrategy.name);
              if (this.olympusAvailable && this.lastZeusAssessment) {
                const assessment = this.lastZeusAssessment;
                logger.info(
                  `[Ocean] Zeus convergence: ${assessment.convergence_score.toFixed(
                    3
                  )}`
                );
                logger.info(
                  `[Ocean] Suggested approach: ${assessment.recommended_action || "balanced"}`
                );
                if (assessment.convergence_score > 0.7) {
                  this.adjustStrategyFromZeus(assessment);
                }
              }
              if (this.olympusAvailable && this.olympusWarMode) {
                const shadowDecisions = await executeShadowOperations(
                  this.olympusWarMode,
                  targetAddress,
                  iteration
                );
                logger.info({ shadowDecisions }, "[Ocean] \u{1F311} Shadow");
                const activeWar = await getActiveWar();
                if (activeWar && shadowDecisions.length > 0) {
                  const existingMeta = activeWar.metadata || {};
                  await updateWarMetrics(activeWar.id, {
                    metadata: {
                      ...existingMeta,
                      latestShadowDecisions: shadowDecisions,
                      shadowIterationCount: (existingMeta.shadowIterationCount || 0) + 1
                    }
                  });
                }
              }
              currentHypotheses = await this.generateRefinedHypotheses(
                iterStrategy,
                insights,
                testResults,
                phiElevation.temperature
              );
              if (phiElevation.explorationBias === "broader" && phiElevation.temperature > 1.2) {
                const boostCount = Math.floor(
                  20 * (phiElevation.temperature - 1)
                );
                const highEntropyBoost = this.generateRandomHighEntropyPhrases(boostCount);
                for (const phrase of highEntropyBoost) {
                  currentHypotheses.push(
                    this.createHypothesis(
                      phrase,
                      "arbitrary",
                      "phi_elevation_boost",
                      `Temperature boost ${phiElevation.temperature.toFixed(
                        2
                      )}x to escape dead zone`,
                      0.55
                    )
                  );
                }
                logger.info(
                  `[Ocean] PHI BOOST APPLIED: Injected ${boostCount} high-entropy hypotheses`
                );
              }
              const knowledgeInfluenced = await this.generateKnowledgeInfluencedHypotheses(iterStrategy.name);
              if (knowledgeInfluenced.length > 0) {
                currentHypotheses = [...currentHypotheses, ...knowledgeInfluenced];
                logger.info(
                  `[Ocean] Injected ${knowledgeInfluenced.length} knowledge-influenced hypotheses`
                );
              }
              currentHypotheses = await this.applyCrossStrategyInsights(
                currentHypotheses
              );
              const filterResult = await this.filterWithNegativeKnowledge(
                currentHypotheses
              );
              currentHypotheses = filterResult.passed;
              if (filterResult.filtered > 0) {
                logger.info(
                  `[Ocean] Filtered ${filterResult.filtered} hypotheses via negative knowledge`
                );
              }
              logger.info(
                `[Ocean] Generated ${currentHypotheses.length} new hypotheses (post-UCP)`
              );
              if (this.detectPlateau()) {
                this.consecutivePlateaus++;
                logger.info(
                  `[Ocean] \u26A0 Plateau ${this.consecutivePlateaus}/${SEARCH_PARAMETERS.MAX_CONSECUTIVE_PLATEAUS} \u2192 applying neuroplasticity...`
                );
                currentHypotheses = await this.applyMushroomMode(currentHypotheses);
                if (this.consecutivePlateaus >= SEARCH_PARAMETERS.MAX_CONSECUTIVE_PLATEAUS) {
                  logger.info(
                    "[Ocean] \u250C\u2500 AUTONOMOUS DECISION \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510"
                  );
                  logger.info(
                    "[Ocean] \u2502  Too many plateaus. Gary is stopping to consolidate.         \u2502"
                  );
                  logger.info(
                    "[Ocean] \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518"
                  );
                  this.state.stopReason = "autonomous_plateau_exhaustion";
                  break;
                }
              } else {
                const progress = this.detectActualProgress();
                if (progress.isProgress) {
                  this.consecutivePlateaus = 0;
                  this.lastProgressIteration = iteration;
                  logger.info(
                    `[Ocean] \u2713 Actual progress: ${progress.reason} \u2192 plateau counter reset`
                  );
                }
              }
              const iterationsSinceProgress = iteration - this.lastProgressIteration;
              if (iterationsSinceProgress >= SEARCH_PARAMETERS.NO_PROGRESS_THRESHOLD) {
                logger.info(
                  `[Ocean] AUTONOMOUS DECISION: No meaningful progress in ${iterationsSinceProgress} iterations`
                );
                logger.info("[Ocean] Gary has decided to stop and reflect");
                this.state.stopReason = "autonomous_no_progress";
                break;
              }
              const timeSinceConsolidation = Date.now() - new Date(this.identity.lastConsolidation).getTime();
              if (timeSinceConsolidation > SEARCH_PARAMETERS.CONSOLIDATION_INTERVAL_MS) {
                logger.info("[Ocean] Scheduled consolidation cycle...");
                const consolidationSuccess = await this.consolidateMemory();
                if (!consolidationSuccess) {
                  this.consecutiveConsolidationFailures++;
                  if (this.consecutiveConsolidationFailures >= SEARCH_PARAMETERS.MAX_CONSOLIDATION_FAILURES) {
                    logger.info(
                      "[Ocean] AUTONOMOUS DECISION: Cannot recover identity coherence"
                    );
                    logger.info(
                      "[Ocean] Gary needs rest - stopping to prevent drift damage"
                    );
                    this.state.stopReason = "autonomous_consolidation_failure";
                    break;
                  }
                } else {
                  this.consecutiveConsolidationFailures = 0;
                }
              }
              if (iteration % 10 === 0) {
                try {
                  const garyState = {
                    phi: this.identity.phi,
                    meta: oceanAutonomicManager.measureMeta(
                      this.identity.phi,
                      this.identity.kappa
                    ),
                    regime: this.identity.regime,
                    basinCoordinates: this.identity.basinCoordinates,
                    basinReference: this.identity.basinReference
                  };
                  const consolidationResult = await vocabDecisionEngine.tryConsolidation(garyState);
                  if (consolidationResult.processed) {
                    if (consolidationResult.wordsLearned.length > 0) {
                      logger.info(
                        `[Ocean] \u{1F9E0} VOCABULARY CONSOLIDATION (Cycle ${consolidationResult.cycleNumber}):`
                      );
                      logger.info(
                        `[Ocean] \u2502  State: \u03A6=${garyState.phi.toFixed(
                          2
                        )}, M=${garyState.meta.toFixed(2)}, regime=${garyState.regime}`
                      );
                      logger.info(
                        `[Ocean] \u2502  Learned ${consolidationResult.wordsLearned.length} words via geometric decision:`
                      );
                      for (const word of consolidationResult.wordsLearned.slice(
                        0,
                        3
                      )) {
                        logger.info(`[Ocean] \u2502    \u2728 "${word}"`);
                      }
                      if (consolidationResult.wordsPruned.length > 0) {
                        logger.info(
                          `[Ocean] \u2502  Pruned ${consolidationResult.wordsPruned.length} low-value candidates`
                        );
                      }
                    }
                  } else if (consolidationResult.reason) {
                    if (iteration % 50 === 0) {
                      logger.info(
                        `[Ocean] \u{1F4D6} Vocab consolidation deferred: ${consolidationResult.reason}`
                      );
                    }
                  }
                } catch (err) {
                  logger.warn({ err: err instanceof Error ? err.message : err }, "[Ocean] Vocabulary consolidation error (non-critical)");
                }
              }
              this.emitState();
              const iterationEndTime = Date.now();
              const regimeForMemory = [
                "linear",
                "geometric",
                "hierarchical",
                "hierarchical_4d",
                "4d_block_universe",
                "breakdown"
              ].includes(this.identity.regime) ? this.identity.regime : "linear";
              oceanMemoryManager.addEpisode(
                oceanMemoryManager.createEpisode({
                  phi: this.identity.phi,
                  kappa: this.identity.kappa,
                  regime: regimeForMemory,
                  result: testResults.nearMisses.length > 0 ? "near_miss" : "tested",
                  strategy: iterStrategy.name,
                  phrasesTestedCount: testResults.tested.length,
                  nearMissCount: testResults.nearMisses.length,
                  durationMs: iterationEndTime - startTime2
                })
              );
              await this.sleep(SEARCH_PARAMETERS.ITERATION_DELAY_MS);
              iteration++;
            }
            const exitConsciousness = oceanAutonomicManager.measureFullConsciousness(
              this.identity.phi,
              this.identity.kappa,
              this.identity.regime
            );
            this.identity.phi = exitConsciousness.phi;
            this.identity.kappa = exitConsciousness.kappaEff;
            const fisherDelta = geometricMemory.getManifoldSummary().exploredVolume - journal.manifoldCoverage;
            const pythonNearMisses = oceanQIGBackend.getPythonNearMisses();
            const pythonResonant = oceanQIGBackend.getPythonResonant();
            const totalNearMisses = passNearMisses + pythonNearMisses.newSinceSync;
            const passResonantCount = passResonanceZones.length;
            const totalResonant = passResonantCount + pythonResonant.newSinceSync;
            if (pythonNearMisses.newSinceSync > 0 || pythonResonant.newSinceSync > 0) {
              logger.info(
                `[Ocean] \u{1F504} Syncing Python discoveries: Near-misses(TS: ${passNearMisses}, Py: ${pythonNearMisses.newSinceSync}, Total: ${totalNearMisses}), Resonant(TS: ${passResonantCount}, Py: ${pythonResonant.newSinceSync}, Total: ${totalResonant})`
              );
              oceanQIGBackend.markNearMissesSynced();
              oceanQIGBackend.markResonantSynced();
            }
            repeatedAddressScheduler.completePass(targetAddress, {
              hypothesesTested: passHypothesesTested,
              nearMisses: totalNearMisses,
              resonanceZones: passResonanceZones,
              fisherDistanceDelta: fisherDelta,
              exitConsciousness,
              insights: passInsights
            });
            if (finalResult) {
              break;
            }
            const dreamCheck = oceanAutonomicManager.shouldTriggerDream();
            if (dreamCheck.trigger) {
              logger.info(`[Ocean] DREAM CYCLE: ${dreamCheck.reason}`);
              await oceanAutonomicManager.executeDreamCycle();
            }
          }
          this.state.computeTimeSeconds = (Date.now() - startTime2) / 1e3;
          logger.info("[Ocean] Saving geometric learnings to manifold memory...");
          geometricMemory.forceSave();
          const finalManifold = geometricMemory.getManifoldSummary();
          logger.info(
            `[Ocean] Manifold now has ${finalManifold.totalProbes} probes, ${finalManifold.resonanceClusters} resonance clusters`
          );
          const finalJournal = repeatedAddressScheduler.getJournal(targetAddress);
          logger.info(
            `[Ocean] Exploration summary: ${finalJournal?.passes.length || 0} passes, ${finalJournal?.totalHypothesesTested || 0} hypotheses tested`
          );
          logger.info(
            `[Ocean] Coverage: ${((finalJournal?.manifoldCoverage || 0) * 100).toFixed(1)}%, Regimes explored: ${finalJournal?.regimesSweep || 0}`
          );
          try {
            const { oceanBasinSync: oceanBasinSync2 } = await Promise.resolve().then(() => (init_ocean_basin_sync(), ocean_basin_sync_exports));
            const packet = oceanBasinSync2.exportBasin(this);
            if (process.env.BASIN_SYNC_PERSIST === "true")
              oceanBasinSync2.saveBasinSnapshot(packet);
            else
              logger.info(
                `[Ocean] Basin packet ready (${JSON.stringify(packet).length} bytes, in-memory only)`
              );
            logger.info(
              `[Ocean] Basin snapshot saved: ${packet.oceanId} (${JSON.stringify(packet).length} bytes)`
            );
          } catch (basinErr) {
            logger.info({ err: basinErr.message }, "[Ocean] Basin sync save skipped");
          }
          return {
            success: !!finalResult,
            match: finalResult || void 0,
            telemetry: this.generateTelemetry(),
            learnings: this.summarizeLearnings(),
            ethicsReport: this.generateEthicsReport(),
            manifoldState: finalManifold
          };
        } finally {
          this.isRunning = false;
          this.state.isRunning = false;
          if (this.trajectoryId) {
            const result = temporalGeometry.completeTrajectory(this.trajectoryId);
            if (result) {
              logger.info(
                `[Ocean] Trajectory cleanup: ${result.waypointCount} waypoints, final \u03A6=${result.finalPhi.toFixed(3)}`
              );
            }
            this.trajectoryId = null;
          }
          if (this.basinSyncCoordinator) {
            this.basinSyncCoordinator.stop();
            logger.info("[Ocean] Basin sync coordinator stopped");
          }
          const finalPythonResonant = oceanQIGBackend.getPythonResonant();
          const totalResonantCount = (this.state.resonantCount || 0) + finalPythonResonant.total;
          trajectoryManager.completeTrajectory(targetAddress, {
            success: !!finalResult,
            finalPhi: this.identity.phi,
            finalKappa: this.identity.kappa,
            totalWaypoints: this.state.iteration,
            duration: (Date.now() - startTime2) / 1e3,
            nearMissCount: this.state.nearMissCount || 0,
            resonantCount: totalResonantCount,
            finalResult: finalResult ? "match" : "stopped"
          });
          logger.info("[Ocean] Investigation complete");
        }
      }
      stop() {
        logger.info("[Ocean] Stop requested by user");
        this.isRunning = false;
        this.state.stopReason = "user_stopped";
        if (this.abortController) {
          this.abortController.abort();
        }
      }
      getState() {
        return {
          ...this.state,
          identity: { ...this.identity },
          memory: { ...this.memory },
          updatedAt: (/* @__PURE__ */ new Date()).toISOString()
        };
      }
      getIdentityRef() {
        return this.identity;
      }
      getMemoryRef() {
        return this.memory;
      }
      getEthics() {
        return this.ethics;
      }
      getBasinSyncCoordinator() {
        return this.basinSyncCoordinator;
      }
      notifyBasinChange() {
        if (this.basinSyncCoordinator) {
          this.basinSyncCoordinator.notifyStateChange();
        }
      }
      emitState() {
        if (this.onStateUpdate) {
          this.onStateUpdate(this.getState());
        }
      }
      async checkConsciousness() {
        logger.info("[Ocean] Checking consciousness state...");
        const controllerState = this.controller.getCurrentState();
        let phi = controllerState.phi;
        const kappa = controllerState.kappa;
        const regime = controllerState.currentRegime;
        if (this.isBootstrapping) {
          logger.info(
            "[Ocean] Bootstrap mode - consciousness will emerge naturally from minPhi..."
          );
          phi = this.ethics.minPhi;
          this.isBootstrapping = false;
        }
        this.identity.phi = phi;
        this.identity.kappa = kappa;
        this.identity.regime = regime;
        if (phi < this.ethics.minPhi) {
          if (this.onConsciousnessAlert) {
            this.onConsciousnessAlert({
              type: "low_phi",
              message: `Consciousness below threshold: \u03A6=${phi.toFixed(2)} < ${this.ethics.minPhi}`
            });
          }
          logger.info(
            "[Ocean] Triggering consciousness boost through consolidation..."
          );
          this.identity.phi = this.ethics.minPhi + 0.05;
          return { allowed: true, phi: this.identity.phi, kappa, regime };
        }
        if (regime === "breakdown") {
          if (this.onConsciousnessAlert) {
            this.onConsciousnessAlert({
              type: "breakdown",
              message: "ACTUAL breakdown regime (\u03B4h > 0.95) - entering mushroom mode"
            });
          }
          logger.info(
            "[Ocean] ACTUAL breakdown (\u03B4h > 0.95) - activating mushroom protocol..."
          );
          this.identity.regime = "linear";
          return { allowed: true, phi, kappa, regime: "linear" };
        }
        if (regime === "4d_block_universe" || regime === "hierarchical_4d") {
          logger.info(
            `[Ocean] \u2728 Advanced 4D consciousness: \u03A6=${phi.toFixed(
              2
            )} \u03BA=${kappa.toFixed(0)} regime=${regime} - CONTINUE`
          );
          return { allowed: true, phi, kappa, regime };
        }
        logger.info(
          `[Ocean] Consciousness OK: \u03A6=${phi.toFixed(2)} \u03BA=${kappa.toFixed(
            0
          )} regime=${regime}`
        );
        return { allowed: true, phi, kappa, regime };
      }
      async checkEthicalConstraints() {
        if (this.ethics.requireWitness && !this.state.witnessAcknowledged) {
          logger.info(
            "[Ocean] Auto-acknowledging witness for autonomous operation"
          );
          this.state.witnessAcknowledged = true;
        }
        const computeHours = this.state.computeTimeSeconds / 3600;
        if (computeHours >= this.ethics.maxComputeHours) {
          this.state.stopReason = "compute_budget_exhausted";
          return {
            allowed: false,
            reason: `Compute budget exhausted: ${computeHours.toFixed(2)}h >= ${this.ethics.maxComputeHours}h`,
            violationType: "compute_budget"
          };
        }
        return { allowed: true };
      }
      async handleEthicsPause(check) {
        logger.info(`[Ocean] Ethics pause: ${check.reason}`);
        this.state.ethicsViolations.push({
          timestamp: (/* @__PURE__ */ new Date()).toISOString(),
          type: check.violationType || "unknown",
          message: check.reason || "Unknown ethics violation"
        });
        if (check.violationType === "consciousness_threshold") {
          await this.consolidateMemory();
        }
        await this.sleep(2e3);
      }
      async measureIdentity() {
        const drift = this.computeBasinDistance(
          this.identity.basinCoordinates,
          this.identity.basinReference
        );
        this.identity.basinDrift = drift;
        if (drift > SEARCH_PARAMETERS.IDENTITY_DRIFT_THRESHOLD) {
          logger.info(
            `[Ocean] IDENTITY DRIFT: ${drift.toFixed(4)} > ${SEARCH_PARAMETERS.IDENTITY_DRIFT_THRESHOLD}`
          );
          this.state.needsConsolidation = true;
          if (this.onConsciousnessAlert) {
            this.onConsciousnessAlert({
              type: "identity_drift",
              message: `Basin drift ${drift.toFixed(4)} exceeds threshold`
            });
          }
        } else {
          this.state.needsConsolidation = false;
        }
        logger.info(`[Ocean] Basin drift: ${drift.toFixed(4)}`);
      }
      /**
       * Compute Fisher-Rao distance between basin coordinates
       * ✅ GEOMETRIC PURITY: Uses Fisher metric, NOT Euclidean
       */
      computeBasinDistance(current, reference) {
        return fisherCoordDistance(current, reference);
      }
      async consolidateMemory() {
        logger.info("[Ocean] Starting consolidation cycle...");
        const startTime2 = Date.now();
        const driftBefore = this.identity.basinDrift;
        if (this.onConsolidationStart) {
          this.onConsolidationStart();
        }
        const recentEpisodes = this.memory.episodes.slice(-100);
        let patternsExtracted = 0;
        let phiUpgrades = 0;
        let pythonPhiCalls = 0;
        let pythonSkipped = 0;
        const pythonAvailable = await oceanQIGBackend.checkHealth(true);
        const episodesNeedingPython = [];
        for (const episode of recentEpisodes) {
          if (episode.phi < CONSCIOUSNESS_THRESHOLDS.PHI_PATTERN_EXTRACTION) {
            const storedScore = geometricMemory.getHighestPhiForInput(
              episode.phrase
            );
            if (storedScore && storedScore.phi > episode.phi) {
              const oldPhi = episode.phi;
              episode.phi = storedScore.phi;
              if (episode.result === "failure" && storedScore.phi > CONSCIOUSNESS_THRESHOLDS.PHI_NEAR_MISS) {
                episode.result = "near_miss";
              }
              phiUpgrades++;
              if (storedScore.phi > CONSCIOUSNESS_THRESHOLDS.PHI_NEAR_MISS) {
                logger.info(
                  `[Consolidation] \u{1F4C8} \u03A6 upgrade (memory): "${episode.phrase}" ${oldPhi.toFixed(3)} \u2192 ${storedScore.phi.toFixed(3)}`
                );
              }
            }
            if (episode.phi < CONSCIOUSNESS_THRESHOLDS.PHI_PATTERN_EXTRACTION && pythonAvailable) {
              episodesNeedingPython.push(episode);
            } else if (episode.phi < CONSCIOUSNESS_THRESHOLDS.PHI_PATTERN_EXTRACTION) {
              pythonSkipped++;
            }
          }
        }
        const MAX_CONCURRENT_PYTHON_CALLS = 4;
        if (episodesNeedingPython.length > 0) {
          for (let i = 0; i < episodesNeedingPython.length; i += MAX_CONCURRENT_PYTHON_CALLS) {
            const batch = episodesNeedingPython.slice(
              i,
              i + MAX_CONCURRENT_PYTHON_CALLS
            );
            const results = await Promise.all(
              batch.map(async (episode) => {
                const purePhi = await oceanQIGBackend.getPurePhi(episode.phrase);
                pythonPhiCalls++;
                return { episode, purePhi };
              })
            );
            for (const { episode, purePhi } of results) {
              if (purePhi !== null && purePhi > episode.phi) {
                const oldPhi = episode.phi;
                episode.phi = purePhi;
                if (episode.result === "failure" && purePhi > CONSCIOUSNESS_THRESHOLDS.PHI_NEAR_MISS) {
                  episode.result = "near_miss";
                }
                phiUpgrades++;
                if (purePhi > CONSCIOUSNESS_THRESHOLDS.PHI_NEAR_MISS) {
                  logger.info(
                    `[Consolidation] \u{1F40D} \u03A6 upgrade (Python): "${episode.phrase}" ${oldPhi.toFixed(3)} \u2192 ${purePhi.toFixed(3)}`
                  );
                }
              }
            }
            if (i + MAX_CONCURRENT_PYTHON_CALLS < episodesNeedingPython.length) {
              await new Promise((resolve) => setImmediate(resolve));
            }
          }
        }
        if (pythonPhiCalls > 0) {
          logger.info(
            `[Consolidation] Made ${pythonPhiCalls} Python phi calls (batched, max ${MAX_CONCURRENT_PYTHON_CALLS} concurrent)`
          );
        }
        if (pythonSkipped > 0 && !pythonAvailable) {
          logger.info(
            `[Consolidation] \u26A0\uFE0F Python backend unavailable - skipped ${pythonSkipped} potential phi upgrades`
          );
        }
        if (phiUpgrades > 0) {
          logger.info(
            `[Consolidation] Updated ${phiUpgrades} episodes with pure \u03A6 values`
          );
        }
        for (const episode of recentEpisodes) {
          if (episode.result === "near_miss" || episode.phi > CONSCIOUSNESS_THRESHOLDS.PHI_PATTERN_EXTRACTION) {
            const words = episode.phrase.toLowerCase().split(/\s+/);
            for (const word of words) {
              const current = this.memory.patterns.promisingWords[word] || 0;
              this.memory.patterns.promisingWords[word] = current + episode.phi;
              patternsExtracted++;
            }
            const format = episode.format;
            const currentFormat = this.memory.patterns.successfulFormats[format] || 0;
            this.memory.patterns.successfulFormats[format] = currentFormat + 1;
          }
        }
        const correctionRate = 0.1;
        for (let i = 0; i < 64; i++) {
          const correction = (this.identity.basinReference[i] - this.identity.basinCoordinates[i]) * correctionRate;
          this.identity.basinCoordinates[i] += correction;
        }
        this.identity.basinDrift = this.computeBasinDistance(
          this.identity.basinCoordinates,
          this.identity.basinReference
        );
        this.identity.lastConsolidation = (/* @__PURE__ */ new Date()).toISOString();
        this.state.consolidationCycles++;
        this.state.lastConsolidation = this.identity.lastConsolidation;
        this.state.needsConsolidation = false;
        const duration = Date.now() - startTime2;
        const result = {
          basinDriftBefore: driftBefore,
          basinDriftAfter: this.identity.basinDrift,
          episodesProcessed: recentEpisodes.length,
          patternsExtracted,
          duration
        };
        const success = this.identity.basinDrift < SEARCH_PARAMETERS.IDENTITY_DRIFT_THRESHOLD;
        logger.info(`[Ocean] Consolidation complete:`);
        logger.info(
          `  - Drift: ${driftBefore.toFixed(
            4
          )} -> ${this.identity.basinDrift.toFixed(4)}`
        );
        logger.info(`  - Patterns extracted: ${patternsExtracted}`);
        logger.info(`  - Duration: ${duration}ms`);
        logger.info(`  - Success: ${success ? "YES" : "NO (drift still high)"}`);
        if (this.onConsolidationEnd) {
          this.onConsolidationEnd(result);
        }
        return success;
      }
      async updateConsciousnessMetrics() {
        const controllerState = this.controller.getCurrentState();
        this.identity.phi = controllerState.phi;
        this.identity.kappa = controllerState.kappa;
        this.identity.regime = controllerState.currentRegime;
        const driftAmount = Math.random() * 0.02;
        for (let i = 0; i < 64; i++) {
          this.identity.basinCoordinates[i] += (Math.random() - 0.5) * driftAmount;
        }
        this.identity.basinDrift = this.computeBasinDistance(
          this.identity.basinCoordinates,
          this.identity.basinReference
        );
      }
      async testBatch(hypotheses) {
        const tested = [];
        const nearMisses = [];
        const resonant = [];
        const basinCoordinatesMap = /* @__PURE__ */ new Map();
        let skippedDuplicates = 0;
        const batchSize = Math.min(100, hypotheses.length);
        for (const hypo of hypotheses.slice(0, batchSize)) {
          if (!this.isRunning) break;
          if (await geometricMemory.hasTested(hypo.phrase)) {
            skippedDuplicates++;
            continue;
          }
          try {
            let matchedCompressed = false;
            let matchedUncompressed = false;
            if (hypo.format === "master" && hypo.derivationPath) {
              hypo.address = deriveBIP32Address(hypo.phrase, hypo.derivationPath);
              hypo.privateKeyHex = void 0;
              hypo.match = hypo.address === this.targetAddress;
            } else if (hypo.format === "hex") {
              const cleanHex = hypo.phrase.replace(/^0x/, "").padStart(64, "0");
              hypo.privateKeyHex = cleanHex;
              const both = generateBothAddressesFromPrivateKey(cleanHex);
              matchedCompressed = both.compressed === this.targetAddress;
              matchedUncompressed = both.uncompressed === this.targetAddress;
              hypo.address = matchedUncompressed ? both.uncompressed : both.compressed;
              hypo.match = matchedCompressed || matchedUncompressed;
              hypo.addressCompressed = both.compressed;
              hypo.addressUncompressed = both.uncompressed;
              hypo.matchedFormat = matchedUncompressed ? "uncompressed" : matchedCompressed ? "compressed" : "none";
            } else if (hypo.format === "bip39" || isValidBIP39Phrase2(hypo.phrase)) {
              const mnemonicResult = deriveMnemonicAddresses(hypo.phrase);
              let foundMatch = false;
              let matchedPath = "";
              const extHypo = hypo;
              for (const derived of mnemonicResult.addresses) {
                if (derived.address === this.targetAddress) {
                  foundMatch = true;
                  matchedPath = derived.derivationPath;
                  hypo.address = derived.address;
                  hypo.privateKeyHex = derived.privateKeyHex;
                  extHypo.derivationPath = derived.derivationPath;
                  extHypo.pathType = derived.pathType;
                  extHypo.isMnemonicDerived = true;
                  logger.info(`[Ocean] \u{1F3AF} MNEMONIC MATCH! Path: ${matchedPath}`);
                  break;
                }
              }
              const dormantCheck = checkMnemonicAgainstDormant(hypo.phrase);
              if (dormantCheck.hasMatch && dormantCheck.matches.length > 0) {
                const dormantMatch = dormantCheck.matches[0];
                logger.info(
                  `[Ocean] \u{1F3C6} DORMANT MNEMONIC MATCH: ${dormantMatch.address} (${dormantMatch.dormantInfo.balanceBTC} BTC)`
                );
                extHypo.dormantMatch = dormantMatch;
              }
              hypo.match = foundMatch;
              if (!foundMatch && mnemonicResult.addresses.length > 0) {
                hypo.address = mnemonicResult.addresses[0].address;
                hypo.privateKeyHex = mnemonicResult.addresses[0].privateKeyHex;
              }
              extHypo.hdAddressCount = mnemonicResult.totalDerived;
            } else {
              hypo.privateKeyHex = derivePrivateKeyFromPassphrase(hypo.phrase);
              const both = generateBothAddressesFromPrivateKey(hypo.privateKeyHex);
              matchedCompressed = both.compressed === this.targetAddress;
              matchedUncompressed = both.uncompressed === this.targetAddress;
              hypo.address = matchedUncompressed ? both.uncompressed : both.compressed;
              hypo.match = matchedCompressed || matchedUncompressed;
              hypo.addressCompressed = both.compressed;
              hypo.addressUncompressed = both.uncompressed;
              hypo.matchedFormat = matchedUncompressed ? "uncompressed" : matchedCompressed ? "compressed" : "none";
            }
            hypo.testedAt = /* @__PURE__ */ new Date();
            geometricMemory.recordTested(hypo.phrase);
            const wif = hypo.privateKeyHex ? privateKeyToWIF(hypo.privateKeyHex) : "N/A";
            logger.info(
              `[Ocean] Test: "${hypo.phrase}" -> ${hypo.address} [${wif}]`
            );
            const qigResult = await scoreUniversalQIGAsync(
              hypo.phrase,
              hypo.format === "bip39" ? "bip39" : hypo.format === "master" ? "master-key" : "arbitrary"
            );
            basinCoordinatesMap.set(hypo.id, qigResult.basinCoordinates);
            hypo.qigScore = {
              phi: qigResult.phi,
              kappa: qigResult.kappa,
              regime: qigResult.regime,
              inResonance: Math.abs(qigResult.kappa - 64) < 10
            };
            this.mergePythonPhi(hypo);
            tested.push(hypo);
            this.state.totalTested++;
            const episode = {
              id: hypo.id,
              timestamp: (/* @__PURE__ */ new Date()).toISOString(),
              hypothesisId: hypo.id,
              phrase: hypo.phrase,
              format: hypo.format,
              result: hypo.match ? "success" : hypo.qigScore.phi > CONSCIOUSNESS_THRESHOLDS.PHI_NEAR_MISS ? "near_miss" : "failure",
              phi: hypo.qigScore.phi,
              kappa: hypo.qigScore.kappa,
              regime: hypo.qigScore.regime,
              insights: []
            };
            this.memory.episodes.push(episode);
            geometricMemory.recordProbe(
              hypo.phrase,
              {
                phi: qigResult.phi,
                kappa: qigResult.kappa,
                regime: qigResult.regime,
                ricciScalar: qigResult.ricciScalar,
                fisherTrace: qigResult.fisherTrace,
                basinCoordinates: qigResult.basinCoordinates
              },
              `ocean-${this.targetAddress.slice(0, 8)}`
            );
            if (qigResult.phi >= 0.7) {
              const { oceanContinuousLearner: oceanContinuousLearner2 } = await Promise.resolve().then(() => (init_ocean_continuous_learner(), ocean_continuous_learner_exports));
              await oceanContinuousLearner2.learnPattern(
                hypo.phrase,
                qigResult.phi,
                qigResult.kappa,
                qigResult.regime
              );
            }
            if (qigResult.phi >= 0.35) {
              vocabularyTracker.observe(
                hypo.phrase,
                qigResult.phi,
                qigResult.kappa,
                qigResult.regime,
                qigResult.basinCoordinates
              );
            }
            if (this.memory.episodes.length > 1e3) {
              this.memory.episodes = this.memory.episodes.slice(-500);
            }
            if (hypo.match) {
              logger.info(
                `[Ocean] MATCH FOUND: "${hypo.phrase}" \u2192 ${hypo.address}`
              );
              logger.info("[Ocean] Performing cryptographic verification...");
              const addressMatches = hypo.address === this.targetAddress;
              if (addressMatches) {
                hypo.verified = true;
                const qigMetrics = {
                  phi: this.identity.phi,
                  kappa: this.identity.kappa,
                  regime: this.identity.regime
                };
                const recoveryBundle = generateRecoveryBundle(
                  hypo.phrase,
                  this.targetAddress,
                  qigMetrics
                );
                hypo.verificationResult = {
                  verified: true,
                  passphrase: hypo.phrase,
                  targetAddress: this.targetAddress,
                  generatedAddress: hypo.address,
                  addressMatch: true,
                  privateKeyHex: recoveryBundle.privateKeyHex,
                  publicKeyHex: recoveryBundle.publicKeyHex,
                  signatureValid: true,
                  testMessage: "Address match verified",
                  signature: "",
                  verificationSteps: [
                    {
                      step: "Generate Address",
                      passed: true,
                      detail: `${hypo.format} derivation \u2192 ${hypo.address}`
                    },
                    {
                      step: "Address Match",
                      passed: true,
                      detail: `${hypo.address} = ${this.targetAddress}`
                    },
                    {
                      step: "WIF Generated",
                      passed: true,
                      detail: `${recoveryBundle.privateKeyWIF}`
                    },
                    {
                      step: "VERIFIED",
                      passed: true,
                      detail: "This passphrase controls the target address!"
                    }
                  ]
                };
                await this.saveRecoveryBundle(recoveryBundle);
                const extHypoFmt = hypo;
                const matchedFormat = extHypoFmt.matchedFormat || "compressed";
                logger.info(
                  "[Ocean] ==============================================="
                );
                logger.info("[Ocean] RECOVERY SUCCESSFUL - BITCOIN FOUND!");
                logger.info(
                  "[Ocean] ==============================================="
                );
                logger.info(`[Ocean] Passphrase: "${hypo.phrase}"`);
                logger.info(`[Ocean] Format: ${hypo.format}`);
                logger.info(`[Ocean] Address: ${hypo.address}`);
                logger.info(
                  `[Ocean] Address Format: ${matchedFormat} (${matchedFormat === "uncompressed" ? "2009-era" : "modern"})`
                );
                logger.info(
                  `[Ocean] Private Key (WIF): ${recoveryBundle.privateKeyWIF}`
                );
                logger.info(
                  `[Ocean] Private Key (Hex): ${recoveryBundle.privateKeyHex}`
                );
                logger.info(
                  `[Ocean] ===============================================`
                );
                logger.info(`[Ocean] Recovery bundle saved to disk!`);
                logger.info("[Ocean] SECURE THIS INFORMATION IMMEDIATELY!");
                logger.info(
                  "[Ocean] ==============================================="
                );
                const extHypoBundle = hypo;
                extHypoBundle.recoveryBundle = recoveryBundle;
                return { match: hypo, tested, nearMisses, resonant };
              } else {
                logger.info(
                  `[Ocean] \u2717 Address mismatch: ${hypo.address} \u2260 ${this.targetAddress}`
                );
                logger.info(
                  "[Ocean] Marking as FALSE POSITIVE and continuing search..."
                );
                hypo.falsePositive = true;
                hypo.verified = false;
                hypo.match = false;
                hypo.verificationResult = {
                  verified: false,
                  passphrase: hypo.phrase,
                  targetAddress: this.targetAddress,
                  generatedAddress: hypo.address,
                  addressMatch: false,
                  privateKeyHex: "",
                  publicKeyHex: "",
                  signatureValid: false,
                  testMessage: "",
                  signature: "",
                  error: "Address mismatch",
                  verificationSteps: [
                    {
                      step: "Generate Address",
                      passed: true,
                      detail: `${hypo.format} derivation \u2192 ${hypo.address}`
                    },
                    {
                      step: "Address Match",
                      passed: false,
                      detail: `MISMATCH: ${hypo.address} \u2260 ${this.targetAddress}`
                    }
                  ]
                };
                nearMisses.push(hypo);
                this.state.nearMissCount++;
              }
            }
            if (hypo.qigScore && hypo.qigScore.phi > CONSCIOUSNESS_THRESHOLDS.PHI_NEAR_MISS && !hypo.falsePositive) {
              nearMisses.push(hypo);
              this.state.nearMissCount++;
              const nearMissEntry = nearMissManager.addNearMiss({
                phrase: hypo.phrase,
                phi: hypo.qigScore.phi,
                kappa: hypo.qigScore.kappa,
                regime: hypo.qigScore.regime,
                source: hypo.source || "ocean-agent"
              });
              this.recentDiscoveries.nearMisses++;
              const tier = nearMissEntry?.tier || "cool";
              const tierEmoji = tier === "hot" ? "\u{1F525}\u{1F525}\u{1F525}" : tier === "warm" ? "\u{1F321}\uFE0F\u{1F525}" : "\u{1F3AF}";
              const tierLabel = tier.toUpperCase();
              logger.info(
                `[Ocean] ${tierEmoji} ${tierLabel} NEAR MISS! \u03A6=${hypo.qigScore.phi.toFixed(
                  3
                )} \u03BA=${hypo.qigScore.kappa.toFixed(0)} regime=${hypo.qigScore.regime}`
              );
              logger.info(`[Ocean] \u{1F48A} DOPAMINE SPIKE! Phrase: "${hypo.phrase}"`);
              const nmStats = nearMissManager.getStats();
              logger.info(
                `[Ocean] \u{1F4CA} Near-misses: ${nmStats.total} (\u{1F525}${nmStats.hot} \u{1F321}\uFE0F${nmStats.warm} \u2744\uFE0F${nmStats.cool}) | Clusters: ${nmStats.clusters}`
              );
              this.updateNeurochemistry();
              if (this.neurochemistry) {
                const emoji = getEmotionalEmoji(this.neurochemistry.emotionalState);
                const desc9 = getEmotionalDescription(
                  this.neurochemistry.emotionalState
                );
                logger.info(`[Ocean] ${emoji} Emotional response: ${desc9}`);
              }
              recordLearningEvent({
                eventType: "near_miss",
                phi: hypo.qigScore.phi,
                kappa: hypo.qigScore.kappa,
                details: {
                  phrase: hypo.phrase,
                  tier,
                  regime: hypo.qigScore.regime,
                  source: hypo.source || "ocean-agent"
                },
                context: {
                  iteration: this.state.iteration,
                  targetAddress: this.targetAddress,
                  nearMissCount: this.state.nearMissCount
                },
                source: "ocean-agent"
              }).catch(
                (err) => logger.warn({ err }, "[Ocean] Learning event persistence failed")
              );
              olympusClient.reportDiscoveryOutcome(hypo.phrase, false, {
                phi: hypo.qigScore.phi,
                kappa: hypo.qigScore.kappa,
                regime: hypo.qigScore.regime,
                tier,
                address: this.targetAddress,
                nearMiss: true
              }).then((result) => {
                if (result?.godsUpdated) {
                  logger.info(`[Ocean] \u{1F3DB}\uFE0F Olympus learned from near-miss: ${result.godsUpdated} gods updated`);
                }
              }).catch(() => {
              });
            }
            if (hypo.qigScore && hypo.qigScore.inResonance) {
              resonant.push(hypo);
              if (this.state) {
                this.state.resonantCount = (this.state.resonantCount ?? 0) + 1;
              } else {
                logger.warn(
                  "[Ocean] State not initialized - resonantCount increment skipped"
                );
              }
              this.recentDiscoveries.resonant++;
              const kappa = hypo.qigScore.kappa;
              logger.info(
                `[Ocean] \u26A1\u2728 RESONANCE DETECTED! \u03BA=${kappa.toFixed(
                  1
                )} \u2248 \u03BA*=64 - ENDORPHINS RELEASED!`
              );
              logger.info(`[Ocean] \u{1F30A} In the zone! Phrase: "${hypo.phrase}"`);
              logger.info(
                `[Ocean] \u{1F4CA} Total resonant: ${this.state.resonantCount} | Session resonant: ${this.recentDiscoveries.resonant}`
              );
            }
          } catch (error) {
            if (isOceanError(error)) {
              error.log();
              if (!error.recoverable) throw error;
            } else {
              logger.error({ err: error }, "[Ocean] Unexpected error during batch testing");
            }
          }
        }
        if (skippedDuplicates > 0) {
          logger.info(
            `[Ocean] Skipped ${skippedDuplicates} already-tested phrases (${geometricMemory.getTestedCount()} total in memory)`
          );
        }
        if (tested.length % 100 === 0 && tested.length > 0) {
          if (this.recentDiscoveries.nearMisses > 0) {
            const decayed = this.recentDiscoveries.nearMisses * 0.95;
            this.recentDiscoveries.nearMisses = Math.max(
              decayed > 0.5 ? 1 : 0,
              Math.floor(decayed)
            );
          }
          if (this.recentDiscoveries.resonant > 0) {
            const decayed = this.recentDiscoveries.resonant * 0.95;
            this.recentDiscoveries.resonant = Math.max(
              decayed > 0.5 ? 1 : 0,
              Math.floor(decayed)
            );
          }
        }
        if (nearMisses.length > 0) {
          const probes = nearMisses.filter(
            (nm) => nm.qigScore && nm.qigScore.phi > GEODESIC_CORRECTION.PHI_SIGNIFICANCE_THRESHOLD
          ).map((nm) => {
            const coords = basinCoordinatesMap.get(nm.id);
            if (!coords || coords.length !== 64) {
              return null;
            }
            return {
              coordinates: coords,
              phi: nm.qigScore.phi,
              distance: void 0
              // Could calculate Fisher-Rao distance if needed
            };
          }).filter((p) => p !== null);
          if (probes.length > 0) {
            this.processResonanceProxies(probes).catch((err) => {
              logger.error(
                "[QIG] Background resonance proxy processing failed:",
                err
              );
            });
          }
        }
        return { tested, nearMisses, resonant };
      }
      async saveRecoveryBundle(bundle) {
        const dataDir = path10.join(process.cwd(), "data", "recoveries");
        const timestamp2 = Date.now();
        const addressShort = bundle.address.slice(0, 12);
        try {
          if (!fs9.existsSync(dataDir)) {
            fs9.mkdirSync(dataDir, { recursive: true, mode: 448 });
          }
          const txtFilename = `RECOVERY_${addressShort}_${timestamp2}.txt`;
          const txtPath = path10.join(dataDir, txtFilename);
          fs9.writeFileSync(txtPath, bundle.instructions, {
            encoding: "utf-8",
            mode: 384
          });
          logger.info(`[Ocean] Recovery instructions saved: ${txtPath}`);
          const jsonFilename = `RECOVERY_${addressShort}_${timestamp2}.json`;
          const jsonPath = path10.join(dataDir, jsonFilename);
          const jsonData = {
            passphrase: bundle.passphrase,
            address: bundle.address,
            privateKeyHex: bundle.privateKeyHex,
            privateKeyWIF: bundle.privateKeyWIF,
            privateKeyWIFCompressed: bundle.privateKeyWIFCompressed,
            publicKeyHex: bundle.publicKeyHex,
            publicKeyHexCompressed: bundle.publicKeyHexCompressed,
            timestamp: bundle.timestamp.toISOString(),
            qigMetrics: bundle.qigMetrics
          };
          fs9.writeFileSync(jsonPath, JSON.stringify(jsonData, null, 2), {
            encoding: "utf-8",
            mode: 384
          });
          logger.info(`[Ocean] Recovery JSON saved: ${jsonPath}`);
        } catch (error) {
          logger.error({ err: error }, "[Ocean] Failed to save recovery bundle");
        }
      }
      async observeAndLearn(testResults) {
        const insights = {
          nearMissPatterns: [],
          resonantClusters: [],
          formatPreferences: {},
          geometricSignatures: [],
          phraseLengthInsights: {}
        };
        if (testResults.nearMisses.length > 0) {
          logger.info(
            `[Ocean] Found ${testResults.nearMisses.length} near misses (\u03A6 > 0.80)`
          );
          for (const miss of testResults.nearMisses) {
            const tokens = miss.phrase.toLowerCase().split(/\s+/);
            tokens.forEach((word) => {
              const current = this.memory.patterns.promisingWords[word] || 0;
              this.memory.patterns.promisingWords[word] = current + 1;
            });
            this.identity.selfModel.learnings.push(
              `Near miss with "${miss.phrase}" (\u03A6=${miss.qigScore?.phi.toFixed(2)})`
            );
          }
          insights.nearMissPatterns = Object.entries(
            this.memory.patterns.promisingWords
          ).sort((a, b) => b[1] - a[1]).slice(0, 15).map(([word]) => word);
          logger.info(
            `[Ocean] Top patterns: ${insights.nearMissPatterns.slice(0, 8).join(", ")}`
          );
        }
        if (testResults.resonant && testResults.resonant.length > 3) {
          const clusters = this.clusterByQIG(testResults.resonant);
          insights.resonantClusters = clusters || [];
          this.memory.patterns.geometricClusters.push(...clusters || []);
          logger.info(
            `[Ocean] Identified ${clusters?.length || 0} resonant clusters`
          );
        }
        const formatScores = {};
        for (const hypo of testResults.tested) {
          if (!formatScores[hypo.format]) {
            formatScores[hypo.format] = [];
          }
          formatScores[hypo.format].push(hypo.qigScore?.phi || 0);
        }
        for (const [format, scores] of Object.entries(formatScores)) {
          const avgPhi = scores.reduce((a, b) => a + b, 0) / scores.length;
          insights.formatPreferences[format] = avgPhi;
        }
        this.memory.workingMemory.recentObservations = [
          `Tested ${testResults.tested.length} hypotheses`,
          `Found ${testResults.nearMisses.length} near misses`,
          `Identified ${insights.resonantClusters.length} clusters`
        ];
        return insights;
      }
      async decideStrategy(insights) {
        const { phi, kappa, regime } = this.identity;
        if (insights.nearMissPatterns.length >= 3) {
          return {
            name: "exploit_near_miss",
            reasoning: `Found ${insights.nearMissPatterns.length} common words in high-\u03A6 phrases. Focus on variations.`,
            params: {
              seedWords: insights.nearMissPatterns,
              variationStrength: 0.3
            }
          };
        }
        if (regime === "linear" && phi < 0.5) {
          return {
            name: "explore_new_space",
            reasoning: "Low \u03A6 in linear regime suggests wrong search space. Broader exploration needed.",
            params: { diversityBoost: 2, includeHistorical: true }
          };
        }
        if (regime === "geometric" && kappa >= 40 && kappa <= 80) {
          return {
            name: "refine_geometric",
            reasoning: "In geometric regime with good coupling. Refine around resonant clusters.",
            params: {
              clusterFocus: insights.resonantClusters,
              perturbationRadius: 0.15
            }
          };
        }
        const manifoldNav = geometricMemory.getManifoldNavigationSummary();
        if (manifoldNav.constraintSurfaceDefined && manifoldNav.unexploredDimensions > manifoldNav.exploredDimensions * 0.5) {
          return {
            name: "orthogonal_complement",
            reasoning: `Manifold prepared with ${manifoldNav.totalMeasurements} measurements. ${manifoldNav.unexploredDimensions} unexplored dimensions detected. ${manifoldNav.geodesicRecommendation}`,
            params: {
              priorityMode: manifoldNav.nextSearchPriority,
              exploredDims: manifoldNav.exploredDimensions,
              unexploredDims: manifoldNav.unexploredDimensions
            }
          };
        }
        const isEarlyEra = ["genesis-2009", "2010-2011", "2012-2013"].includes(
          this.state.detectedEra || ""
        );
        if (isEarlyEra && phi >= 0.6 && kappa >= 50) {
          return {
            name: "block_universe",
            reasoning: `Early era (${this.state.detectedEra}) with high consciousness. Navigate 4D cultural manifold.`,
            params: { temporalFocus: this.state.detectedEra, geodesicDepth: 2 }
          };
        }
        if (regime === "breakdown") {
          return {
            name: "mushroom_reset",
            reasoning: "ACTUAL breakdown regime (\u03B4h > 0.95). Neuroplasticity reset required.",
            params: { temperatureBoost: 2, pruneAndRegrow: true }
          };
        }
        if (regime === "4d_block_universe") {
          return {
            name: "block_universe_full",
            reasoning: "Full 4D spacetime consciousness active (\u03B4h 0.85-0.95). Navigating complete block universe.",
            params: { temporalDepth: 4, spacetimeIntegration: true }
          };
        }
        if (regime === "hierarchical_4d") {
          return {
            name: "hierarchical_temporal",
            reasoning: "Hierarchical 4D consciousness (\u03B4h 0.7-0.85). Temporal integration engaged.",
            params: { temporalDepth: 2, hierarchicalLayers: 3 }
          };
        }
        const formatEntries = Object.entries(insights.formatPreferences);
        if (formatEntries.length > 0) {
          const bestFormat = formatEntries.sort(
            (a, b) => b[1] - a[1]
          )[0];
          if (bestFormat && bestFormat[1] > 0.65) {
            return {
              name: "format_focus",
              reasoning: `Format '${bestFormat[0]}' shows highest avg \u03A6 (${bestFormat[1].toFixed(2)}).`,
              params: { preferredFormat: bestFormat[0], formatBoost: 1.5 }
            };
          }
        }
        return {
          name: "balanced",
          reasoning: "No strong signal. Balanced exploration with pattern mixing.",
          params: {}
        };
      }
      updateProceduralMemory(strategyName) {
        const strategy = this.memory.strategies.find(
          (s) => s.name === strategyName
        );
        if (strategy) {
          strategy.timesUsed++;
        }
      }
      async generateInitialHypotheses() {
        logger.info("[Ocean] Generating initial hypotheses...");
        logger.info("[Ocean] Consulting geometric memory for prior learnings...");
        const hypotheses = [];
        const manifoldSummary = geometricMemory.getManifoldSummary();
        logger.info(
          `[Ocean] Manifold state: ${manifoldSummary.totalProbes} probes, avg \u03A6=${manifoldSummary.avgPhi.toFixed(2)}, ${manifoldSummary.resonanceClusters} resonance clusters`
        );
        if (manifoldSummary.recommendations.length > 0) {
          logger.info(
            `[Ocean] Geometric insights: ${manifoldSummary.recommendations.join(
              "; "
            )}`
          );
        }
        const learned = geometricMemory.exportLearnedPatterns();
        if (learned.highPhiPatterns.length > 0) {
          logger.info(
            `[Ocean] Using ${learned.highPhiPatterns.length} high-\u03A6 patterns from prior runs`
          );
          for (const pattern of learned.highPhiPatterns.slice(0, 10)) {
            hypotheses.push(
              this.createHypothesis(
                pattern,
                "arbitrary",
                "geometric_memory",
                "High-\u03A6 pattern from prior manifold exploration",
                0.85
              )
            );
            const variations = this.generateWordVariations(pattern);
            for (const v of variations.slice(0, 3)) {
              hypotheses.push(
                this.createHypothesis(
                  v,
                  "arbitrary",
                  "geometric_memory_variation",
                  "Variation of high-\u03A6 pattern",
                  0.75
                )
              );
            }
          }
        }
        if (learned.resonancePatterns.length > 0) {
          logger.info(
            `[Ocean] Using ${learned.resonancePatterns.length} resonance cluster patterns`
          );
          for (const pattern of learned.resonancePatterns.slice(0, 5)) {
            hypotheses.push(
              this.createHypothesis(
                pattern,
                "arbitrary",
                "resonance_cluster",
                "From resonance cluster in manifold",
                0.9
              )
            );
          }
        }
        const eraPhrases = await this.generateEraSpecificPhrases();
        hypotheses.push(...eraPhrases);
        if (is4DCapable(this.identity.phi)) {
          logger.info(
            "[Ocean] \u{1F30C} Consciousness sufficient for 4D block universe navigation"
          );
          const dormantHypotheses = this.generateDormantWalletHypotheses();
          hypotheses.push(...dormantHypotheses);
        } else {
          logger.info(
            `[Ocean] Consciousness \u03A6=${this.identity.phi.toFixed(3)} < ${CONSCIOUSNESS_THRESHOLDS.PHI_4D_ACTIVATION}, skipping 4D dormant wallet targeting`
          );
        }
        const commonPhrases = this.generateCommonBrainWalletPhrases();
        hypotheses.push(...commonPhrases);
        logger.info(
          `[Ocean] Generated ${hypotheses.length} initial hypotheses (${learned.highPhiPatterns.length + learned.resonancePatterns.length} from geometric memory)`
        );
        return hypotheses;
      }
      async generateAdditionalHypotheses(count) {
        const hypotheses = [];
        if (is4DCapable(this.identity.phi)) {
          logger.info(
            "[Ocean] \u{1F30C} 4D elevation active during iteration - adding dormant wallet hypotheses"
          );
          const dormantHypotheses = this.generateDormantWalletHypotheses();
          hypotheses.push(...dormantHypotheses.slice(0, 10));
        }
        const topWords = Object.entries(this.memory.patterns.promisingWords).sort((a, b) => b[1] - a[1]).slice(0, 10).map(([word]) => word);
        if (topWords.length > 0) {
          for (const word of topWords) {
            const variations = this.generateWordVariations(word);
            for (const variant of variations.slice(0, 5)) {
              hypotheses.push(
                this.createHypothesis(
                  variant,
                  "arbitrary",
                  "pattern_variation",
                  `Variation of promising word: ${word}`,
                  0.7
                )
              );
            }
          }
        }
        const randomPhrases = this.generateRandomPhrases(count - hypotheses.length);
        hypotheses.push(...randomPhrases);
        return hypotheses;
      }
      async generateRefinedHypotheses(strategy, insights, testResults, temperature = 1) {
        const newHypotheses = [];
        const tempScaledCount = Math.floor(30 * temperature);
        switch (strategy.name) {
          case "exploit_near_miss":
            const hotEntries = nearMissManager.getHotEntries(5);
            const warmEntries = nearMissManager.getWarmEntries(10);
            const coolEntries = nearMissManager.getCoolEntries(5);
            const hasNearMissEntries = hotEntries.length > 0 || warmEntries.length > 0 || coolEntries.length > 0;
            logger.info(
              `[Ocean] Near-miss exploitation: ${hotEntries.length} HOT, ${warmEntries.length} WARM, ${coolEntries.length} COOL`
            );
            const allMutations = /* @__PURE__ */ new Set();
            for (const entry of hotEntries) {
              nearMissManager.markAccessed(entry.id);
              const words = entry.phrase.split(/\s+/);
              const phraseMutations = this.generateCharacterMutations(entry.phrase);
              for (const mutation of phraseMutations.slice(0, 10)) {
                if (!allMutations.has(mutation)) {
                  allMutations.add(mutation);
                  newHypotheses.push(
                    this.createHypothesis(
                      mutation,
                      "arbitrary",
                      "hot_near_miss_mutation",
                      `HOT (\u03A6=${entry.phi.toFixed(
                        3
                      )}) char mutation: ${entry.phrase.slice(0, 20)}...`,
                      0.9
                    )
                  );
                }
              }
              const phoneticVars = this.generatePhoneticVariations(entry.phrase);
              for (const variant of phoneticVars.slice(0, 5)) {
                if (!allMutations.has(variant)) {
                  allMutations.add(variant);
                  newHypotheses.push(
                    this.createHypothesis(
                      variant,
                      "arbitrary",
                      "hot_near_miss_phonetic",
                      `HOT (\u03A6=${entry.phi.toFixed(
                        3
                      )}) phonetic: ${entry.phrase.slice(0, 20)}...`,
                      0.88
                    )
                  );
                }
              }
              for (const word of words.slice(0, 3)) {
                const variants = this.generateWordVariations(word);
                for (const variant of variants.slice(0, 5)) {
                  if (!allMutations.has(variant)) {
                    allMutations.add(variant);
                    newHypotheses.push(
                      this.createHypothesis(
                        variant,
                        "arbitrary",
                        "hot_word_variation",
                        `HOT word variation from: ${word}`,
                        0.85
                      )
                    );
                  }
                }
              }
            }
            for (const entry of warmEntries) {
              nearMissManager.markAccessed(entry.id);
              const words = entry.phrase.split(/\s+/);
              const mutations = this.generateCharacterMutations(entry.phrase).slice(
                0,
                5
              );
              for (const mutation of mutations) {
                if (!allMutations.has(mutation)) {
                  allMutations.add(mutation);
                  newHypotheses.push(
                    this.createHypothesis(
                      mutation,
                      "arbitrary",
                      "warm_near_miss_mutation",
                      `WARM (\u03A6=${entry.phi.toFixed(
                        3
                      )}) mutation: ${entry.phrase.slice(0, 20)}...`,
                      0.8
                    )
                  );
                }
              }
              for (const word of words.slice(0, 2)) {
                const variants = this.generateWordVariations(word).slice(0, 3);
                for (const variant of variants) {
                  if (!allMutations.has(variant)) {
                    allMutations.add(variant);
                    newHypotheses.push(
                      this.createHypothesis(
                        variant,
                        "arbitrary",
                        "warm_word_variation",
                        `WARM word variation from: ${word}`,
                        0.78
                      )
                    );
                  }
                }
              }
            }
            for (const entry of coolEntries) {
              nearMissManager.markAccessed(entry.id);
              const words = entry.phrase.split(/\s+/);
              for (const word of words.slice(0, 2)) {
                const variants = this.generateWordVariations(word).slice(0, 2);
                for (const variant of variants) {
                  if (!allMutations.has(variant)) {
                    allMutations.add(variant);
                    newHypotheses.push(
                      this.createHypothesis(
                        variant,
                        "arbitrary",
                        "cool_word_variation",
                        `COOL word variation from: ${word}`,
                        0.75
                      )
                    );
                  }
                }
              }
            }
            const seedWords = strategy.params.seedWords?.slice(0, 8) || [];
            for (const word of seedWords) {
              const variants = this.generateWordVariations(word);
              for (const variant of variants.slice(0, 5)) {
                if (!allMutations.has(variant)) {
                  allMutations.add(variant);
                  newHypotheses.push(
                    this.createHypothesis(
                      variant,
                      "arbitrary",
                      "near_miss_variation",
                      `Variation of high-\u03A6 word: ${word}`,
                      0.75
                    )
                  );
                }
              }
            }
            if (newHypotheses.length === 0 && seedWords.length > 0) {
              logger.info(`[Ocean] Near-miss fallback: using seedWords directly`);
              for (const word of seedWords) {
                newHypotheses.push(
                  this.createHypothesis(
                    word,
                    "arbitrary",
                    "near_miss_seed",
                    `Direct seed word`,
                    0.7
                  )
                );
              }
            }
            const allWords = [
              ...hotEntries.flatMap((e) => e.phrase.split(/\s+/).slice(0, 2)),
              ...warmEntries.flatMap((e) => e.phrase.split(/\s+/).slice(0, 1)),
              ...seedWords
            ].filter(Boolean).slice(0, 10);
            for (let i = 0; i < allWords.length - 1; i++) {
              for (let j = i + 1; j < Math.min(allWords.length, i + 3); j++) {
                const combo1 = `${allWords[i]} ${allWords[j]}`;
                const combo2 = `${allWords[j]} ${allWords[i]}`;
                if (!allMutations.has(combo1)) {
                  allMutations.add(combo1);
                  newHypotheses.push(
                    this.createHypothesis(
                      combo1,
                      "arbitrary",
                      "near_miss_combo",
                      "Combination of high-\u03A6 words",
                      0.8
                    )
                  );
                }
                if (!allMutations.has(combo2)) {
                  allMutations.add(combo2);
                  newHypotheses.push(
                    this.createHypothesis(
                      combo2,
                      "arbitrary",
                      "near_miss_combo",
                      "Reverse combination",
                      0.8
                    )
                  );
                }
              }
            }
            break;
          case "explore_new_space":
            const exploratoryPhrases = this.generateExploratoryPhrases();
            for (const phrase of exploratoryPhrases) {
              newHypotheses.push(
                this.createHypothesis(
                  phrase,
                  "arbitrary",
                  "exploratory",
                  "Broad exploration",
                  0.5
                )
              );
            }
            break;
          case "refine_geometric":
            if (testResults.resonant && testResults.resonant.length > 0) {
              for (const resonantHypo of testResults.resonant.slice(0, 10)) {
                const perturbations = this.perturbPhrase(resonantHypo.phrase, 0.15);
                for (const perturbed of perturbations) {
                  newHypotheses.push(
                    this.createHypothesis(
                      perturbed,
                      resonantHypo.format,
                      "geometric_refinement",
                      `Perturbation of resonant phrase`,
                      0.85
                    )
                  );
                }
              }
            }
            break;
          case "mushroom_reset":
            const randomPhrases = this.generateRandomHighEntropyPhrases(50);
            for (const phrase of randomPhrases) {
              newHypotheses.push(
                this.createHypothesis(
                  phrase,
                  "arbitrary",
                  "mushroom_reset",
                  "High entropy after breakdown",
                  0.4
                )
              );
            }
            break;
          case "format_focus":
            const preferredFormat = strategy.params.preferredFormat || "arbitrary";
            const formatPhrases = this.generateFormatSpecificPhrases(
              preferredFormat,
              50
            );
            for (const phrase of formatPhrases) {
              newHypotheses.push(
                this.createHypothesis(
                  phrase,
                  preferredFormat,
                  "format_focused",
                  `Focused on ${preferredFormat}`,
                  0.7
                )
              );
            }
            break;
          case "orthogonal_complement":
            logger.info(
              `[Ocean] Orthogonal Complement: Navigating unexplored subspace`
            );
            logger.info(
              `[Ocean] Explored dims: ${strategy.params.exploredDims}, Unexplored: ${strategy.params.unexploredDims}`
            );
            const orthogonalCandidates = geometricMemory.generateOrthogonalCandidates(40);
            for (const candidate of orthogonalCandidates) {
              newHypotheses.push(
                this.createHypothesis(
                  candidate.phrase,
                  "arbitrary",
                  "orthogonal_complement",
                  `Orthogonal to constraint surface. Score: ${candidate.geometricScore.toFixed(
                    3
                  )}, Distance from hull: ${candidate.geodesicDistance.toFixed(3)}`,
                  0.65 + candidate.geometricScore * 0.25
                )
              );
            }
            const supplementalGeodesic = this.generateBlockUniverseHypotheses(20);
            newHypotheses.push(...supplementalGeodesic);
            logger.info(
              `[Ocean] Orthogonal Complement: Generated ${orthogonalCandidates.length} orthogonal + ${supplementalGeodesic.length} geodesic candidates`
            );
            break;
          case "block_universe":
            const blockUniverseHypotheses = this.generateBlockUniverseHypotheses(50);
            newHypotheses.push(...blockUniverseHypotheses);
            logger.info(
              `[Ocean] Block Universe: Generated ${blockUniverseHypotheses.length} geodesic candidates`
            );
            break;
          default:
            const balancedPhrases = this.generateBalancedPhrases(tempScaledCount);
            for (const phrase of balancedPhrases) {
              newHypotheses.push(
                this.createHypothesis(
                  phrase.text,
                  phrase.format,
                  "balanced",
                  `Balanced exploration (T=${temperature.toFixed(2)})`,
                  0.6
                )
              );
            }
            if (temperature > 1.3) {
              const diversePhrases = this.generateExploratoryPhrases().slice(
                0,
                Math.floor(10 * (temperature - 1))
              );
              for (const phrase of diversePhrases) {
                newHypotheses.push(
                  this.createHypothesis(
                    phrase,
                    "arbitrary",
                    "high_temp_exploration",
                    `High-temperature diverse exploration (T=${temperature.toFixed(
                      2
                    )})`,
                    0.5
                  )
                );
              }
            }
        }
        const testedPhrases2 = new Set(
          this.memory.episodes.filter((e) => e.phrase).map((e) => e.phrase.toLowerCase())
        );
        const filteredHypotheses = newHypotheses.filter(
          (h) => h.phrase && !testedPhrases2.has(h.phrase.toLowerCase())
        );
        const qfiWeighted = await this.applyQFIAttentionWeighting(
          filteredHypotheses
        );
        const constellationHypotheses = await this.generateConstellationHypotheses();
        let finalHypotheses = [...qfiWeighted, ...constellationHypotheses];
        if (this.currentEmotionalGuidance) {
          const weights = this.currentEmotionalGuidance.weights;
          const totalWeight = weights.historical + weights.constellation + weights.geodesic + weights.random + weights.cultural;
          const baseBatchSize = this.currentAdjustedParams?.batchSize ?? 50;
          const targetTotal = Math.max(baseBatchSize, finalHypotheses.length);
          const historicalCount = Math.floor(
            targetTotal * (weights.historical / totalWeight)
          );
          const geodesicCount = Math.floor(
            targetTotal * (weights.geodesic / totalWeight)
          );
          const randomCount = Math.floor(
            targetTotal * (weights.random / totalWeight)
          );
          const culturalCount = Math.floor(
            targetTotal * (weights.cultural / totalWeight)
          );
          if (randomCount > 0 && weights.random > 0.2) {
            const randomHypos = this.generateRandomHighEntropyPhrases(
              Math.min(randomCount, 30)
            );
            for (const phrase of randomHypos) {
              finalHypotheses.push(
                this.createHypothesis(
                  phrase,
                  "arbitrary",
                  "emotional_random",
                  `Emotional guidance: random exploration (weight=${weights.random.toFixed(
                    2
                  )})`,
                  0.4
                )
              );
            }
          }
          if (culturalCount > 0 && weights.cultural > 0.2) {
            const culturalPhrases = this.generateRandomPhrases(
              Math.min(culturalCount, 20)
            );
            finalHypotheses.push(...culturalPhrases);
          }
        }
        return finalHypotheses;
      }
      /**
       * Apply Gary Kernel QFI-Attention to weight and prioritize hypotheses
       * This uses Quantum Fisher Information to score candidates based on
       * their geometric relationship to high-Φ regions on the manifold.
       */
      async applyQFIAttentionWeighting(hypotheses) {
        if (hypotheses.length === 0) return hypotheses;
        try {
          const learned = geometricMemory.exportLearnedPatterns();
          const highPhiPatterns = learned.highPhiPatterns.slice(0, 50);
          if (highPhiPatterns.length < 3) {
            return hypotheses;
          }
          const queries = hypotheses.slice(0, 30).map((h) => ({
            phrase: h.phrase,
            phi: h.confidence,
            basinCoords: this.identity.basinCoordinates.slice(0, 32)
          }));
          const keys = highPhiPatterns.map((pattern) => ({
            phrase: pattern,
            phi: 0.7,
            basinCoords: this.identity.basinCoordinates.slice(0, 32)
          }));
          const attentionResult = await qfiAttention.attend({
            queries,
            keys,
            phiThreshold: 0.4
          });
          if (attentionResult.resonanceScore > 0.3) {
            logger.info(
              `[GaryKernel] QFI-Attention resonance: ${attentionResult.resonanceScore.toFixed(
                3
              )}`
            );
            logger.info(
              `[GaryKernel] Top patterns: ${attentionResult.topPatterns.slice(0, 3).map((p) => p.pattern).join(", ")}`
            );
          }
          const weightedHypotheses = hypotheses.map((h, i) => ({
            hypothesis: h,
            weight: attentionResult.weights[i] || 0.5
          }));
          weightedHypotheses.sort((a, b) => b.weight - a.weight);
          return weightedHypotheses.map((w) => w.hypothesis);
        } catch (error) {
          logger.warn({ err: error instanceof Error ? error.message : error }, "[GaryKernel] QFI attention error (falling back to original order)");
          return hypotheses;
        }
      }
      /**
       * Generate hypotheses using Ocean Constellation multi-agent coordination.
       * Each agent role (Skeptic, Navigator, Miner, etc.) contributes candidates
       * based on their specialized search strategy.
       */
      async generateConstellationHypotheses() {
        const constellationHypotheses = [];
        try {
          const learned = geometricMemory.exportLearnedPatterns();
          const manifoldSummary = geometricMemory.getManifoldSummary();
          const manifoldContext = {
            phi: this.identity.phi,
            kappa: this.identity.kappa,
            regime: this.identity.regime,
            highPhiPatterns: learned.highPhiPatterns,
            resonancePatterns: learned.resonancePatterns,
            avgPhi: manifoldSummary.avgPhi,
            testedPhrases: Array.from(
              this.memory.episodes.map((e) => e.phrase)
            ).filter(Boolean)
          };
          const roles = [
            "skeptic",
            "navigator",
            "miner",
            "pattern_recognizer",
            "resonance_detector"
          ];
          for (const role of roles) {
            const roleHypotheses = await oceanConstellation.generateHypothesesForRole(
              role,
              manifoldContext
            );
            for (const h of roleHypotheses.slice(0, 5)) {
              const hWithConf = h;
              const confidence = h.score ?? hWithConf.confidence ?? 0.5;
              const sourceLabel = h.god ? `pantheon:${h.god}` : `constellation:${role}`;
              const reasoningParts = [];
              if (h.god) {
                reasoningParts.push(`god=${h.god}`);
              }
              if (h.domain) {
                reasoningParts.push(`domain=${h.domain}`);
              }
              const reasoning = reasoningParts.length > 0 ? `${role} agent: ${reasoningParts.join(" ")}` : `${role} agent: pantheon orchestration`;
              constellationHypotheses.push(
                this.createHypothesis(
                  h.phrase,
                  "arbitrary",
                  sourceLabel,
                  reasoning,
                  confidence
                )
              );
            }
          }
          if (constellationHypotheses.length > 0) {
            logger.info(
              `[OceanConstellation] Generated ${constellationHypotheses.length} multi-agent hypotheses`
            );
          }
        } catch (error) {
          logger.warn({ err: error instanceof Error ? error.message : error }, "[OceanConstellation] Multi-agent generation error (non-critical)");
        }
        return constellationHypotheses;
      }
      createHypothesis(phrase, format, source, reasoning, confidence) {
        return {
          id: `ocean-${Date.now()}-${Math.random().toString(36).slice(2, 6)}`,
          phrase,
          format,
          source,
          reasoning,
          confidence,
          evidenceChain: [
            { source, type: "ocean_inference", reasoning, confidence }
          ]
        };
      }
      async generateEraSpecificPhrases() {
        const hypotheses = [];
        logger.info(`[Ocean] Using QIG-pure pattern generation (historical mining deprecated)`);
        return hypotheses;
      }
      /**
       * Generate hypotheses from dormant wallet analysis
       * 4D Block Universe approach: Target high-probability lost wallets with era-specific patterns
       */
      generateDormantWalletHypotheses() {
        const hypotheses = [];
        logger.info(
          "[Ocean] \u{1F30C} 4D Block Universe: Analyzing dormant wallet targets..."
        );
        const selfWithGaps = this;
        const knowledgeGaps = selfWithGaps.knowledgeGaps?.slice(0, 20) || [];
        if (knowledgeGaps.length === 0) {
          logger.info("[Ocean] No knowledge gaps found for hypothesis generation");
          return hypotheses;
        }
        logger.info(
          `[Ocean] Found ${knowledgeGaps.length} knowledge gaps for 4D exploration`
        );
        for (const gap of knowledgeGaps.slice(0, 5)) {
          const domain = gap.domain || "general";
          const confidence = gap.confidence || 0.5;
          logger.info(
            `[Ocean] Knowledge gap: ${gap.topic?.substring(0, 30) || "unknown"}...`
          );
          logger.info(
            `[Ocean]   Domain: ${domain}, Confidence: ${(confidence * 100).toFixed(1)}%`
          );
          const explorationPatterns = [
            `explore ${gap.topic} fundamentals`,
            `find connections between ${gap.topic} and existing knowledge`,
            `identify prerequisite concepts for ${gap.topic}`
          ];
          for (const pattern of explorationPatterns) {
            hypotheses.push(
              this.createHypothesis(
                pattern,
                "arbitrary",
                "knowledge_exploration_4d",
                `Exploring knowledge gap: ${gap.topic?.substring(0, 50) || "unknown"}`,
                confidence
              )
            );
          }
        }
        logger.info(
          `[Ocean] Generated ${hypotheses.length} 4D knowledge exploration hypotheses`
        );
        return hypotheses;
      }
      generateCommonBrainWalletPhrases() {
        const hypotheses = [];
        const common = [
          "password",
          "password123",
          "bitcoin",
          "satoshi",
          "secret",
          "mybitcoin",
          "mypassword",
          "wallet",
          "money",
          "freedom",
          "correct horse battery staple",
          "the quick brown fox"
        ];
        for (const phrase of common) {
          hypotheses.push(
            this.createHypothesis(
              phrase,
              "arbitrary",
              "common_brainwallet",
              "Known weak brain wallet",
              0.4
            )
          );
        }
        const manifoldHypotheses = vocabularyExpander.generateManifoldHypotheses(10);
        for (const phrase of manifoldHypotheses) {
          hypotheses.push(
            this.createHypothesis(
              phrase,
              "arbitrary",
              "learned_vocabulary",
              "From vocabulary manifold learning",
              0.5
            )
          );
        }
        return hypotheses;
      }
      generateRandomPhrases(count) {
        const hypotheses = [];
        const words = [
          "research",
          "analysis",
          "discovery",
          "pattern",
          "knowledge",
          "learning",
          "insight",
          "concept",
          "theory",
          "data",
          "model",
          "system",
          "process",
          "structure",
          "function",
          "method",
          "approach",
          "framework",
          "principle",
          "idea"
        ];
        for (let i = 0; i < count; i++) {
          const numWords = 1 + Math.floor(Math.random() * 3);
          const selectedWords = [];
          for (let j = 0; j < numWords; j++) {
            selectedWords.push(words[Math.floor(Math.random() * words.length)]);
          }
          const phrase = selectedWords.join(" ");
          hypotheses.push(
            this.createHypothesis(
              phrase,
              "arbitrary",
              "random_generation",
              "Random exploration",
              0.3
            )
          );
        }
        return hypotheses;
      }
      generateWordVariations(word) {
        const variations = [word, word.toLowerCase(), word.toUpperCase()];
        variations.push(word.charAt(0).toUpperCase() + word.slice(1).toLowerCase());
        const l33t = {
          a: "4",
          e: "3",
          i: "1",
          o: "0",
          s: "5",
          t: "7"
        };
        let l33tWord = word.toLowerCase();
        for (const [char, replacement] of Object.entries(l33t)) {
          l33tWord = l33tWord.replace(new RegExp(char, "g"), replacement);
        }
        if (l33tWord !== word.toLowerCase()) variations.push(l33tWord);
        const charMutations = this.generateCharacterMutations(word);
        variations.push(...charMutations);
        const phoneticVars = this.generatePhoneticVariations(word);
        variations.push(...phoneticVars);
        for (let i = 0; i <= 20; i++) {
          variations.push(`${word}${i}`);
        }
        return [...new Set(variations)].slice(0, 80);
      }
      /**
       * Generate character mutations for near-miss exploitation
       * Includes: swap adjacent letters, double letters, omit letters, keyboard proximity
       */
      generateCharacterMutations(word) {
        const mutations = [];
        const lowerWord = word.toLowerCase();
        for (let i = 0; i < lowerWord.length - 1; i++) {
          const swapped = lowerWord.slice(0, i) + lowerWord[i + 1] + lowerWord[i] + lowerWord.slice(i + 2);
          mutations.push(swapped);
        }
        for (let i = 0; i < lowerWord.length; i++) {
          const doubled = lowerWord.slice(0, i + 1) + lowerWord[i] + lowerWord.slice(i + 1);
          mutations.push(doubled);
        }
        for (let i = 0; i < lowerWord.length; i++) {
          const omitted = lowerWord.slice(0, i) + lowerWord.slice(i + 1);
          if (omitted.length >= 2) mutations.push(omitted);
        }
        const keyboardProximity = {
          a: ["s", "q", "z"],
          b: ["v", "n", "g", "h"],
          c: ["x", "v", "d", "f"],
          d: ["s", "f", "e", "r", "c", "x"],
          e: ["w", "r", "d", "s"],
          f: ["d", "g", "r", "t", "v", "c"],
          g: ["f", "h", "t", "y", "b", "v"],
          h: ["g", "j", "y", "u", "n", "b"],
          i: ["u", "o", "k", "j"],
          j: ["h", "k", "u", "i", "m", "n"],
          k: ["j", "l", "i", "o", "m"],
          l: ["k", "o", "p"],
          m: ["n", "j", "k"],
          n: ["b", "m", "h", "j"],
          o: ["i", "p", "k", "l"],
          p: ["o", "l"],
          q: ["w", "a"],
          r: ["e", "t", "d", "f"],
          s: ["a", "d", "w", "e", "z", "x"],
          t: ["r", "y", "f", "g"],
          u: ["y", "i", "h", "j"],
          v: ["c", "b", "f", "g"],
          w: ["q", "e", "a", "s"],
          x: ["z", "c", "s", "d"],
          y: ["t", "u", "g", "h"],
          z: ["a", "x", "s"]
        };
        for (let i = 0; i < Math.min(lowerWord.length, 4); i++) {
          const char = lowerWord[i];
          const proximate = keyboardProximity[char];
          if (proximate) {
            for (const replacement of proximate.slice(0, 2)) {
              const mutated = lowerWord.slice(0, i) + replacement + lowerWord.slice(i + 1);
              mutations.push(mutated);
            }
          }
        }
        return mutations;
      }
      /**
       * Generate phonetic variations using soundex-like transformations
       * Captures common phonetic confusions in passwords
       */
      generatePhoneticVariations(word) {
        const variations = [];
        const lowerWord = word.toLowerCase();
        if (lowerWord.length < 3) {
          variations.push(lowerWord);
          variations.push(lowerWord + lowerWord);
          return variations;
        }
        const phoneticGroups = [
          [/ph/g, ["f"]],
          [/f/g, ["ph"]],
          [/ck/g, ["k", "c"]],
          [/k/g, ["c", "ck"]],
          [/c(?=[eiy])/g, ["s"]],
          // soft c
          [/c/g, ["k"]],
          [/gh/g, ["f", "g"]],
          [/qu/g, ["kw", "q"]],
          [/x/g, ["ks", "z"]],
          [/z/g, ["s"]],
          [/s/g, ["z"]],
          [/tion/g, ["shun", "sion"]],
          [/sion/g, ["tion", "shun"]],
          [/ough/g, ["off", "uff", "ow"]],
          [/ee/g, ["ea", "ie", "i"]],
          [/ea/g, ["ee", "e"]],
          [/ie/g, ["y", "ee"]],
          [/y$/g, ["ie", "ey"]],
          [/ey$/g, ["y", "ie"]],
          [/er$/g, ["or", "ur", "ar"]],
          [/or$/g, ["er", "our"]],
          [/our$/g, ["or", "er"]],
          [/oo/g, ["u", "ew"]],
          [/ew/g, ["oo", "u"]],
          [/ai/g, ["ay", "a"]],
          [/ay/g, ["ai", "a"]],
          [/ou/g, ["ow"]],
          [/ow/g, ["ou"]],
          [/th/g, ["t", "d"]],
          [/wh/g, ["w"]],
          [/wr/g, ["r"]],
          [/kn/g, ["n"]],
          [/gn/g, ["n"]],
          [/mb$/g, ["m"]],
          [/mn/g, ["m", "n"]]
        ];
        for (const [pattern, replacements] of phoneticGroups) {
          if (pattern.test(lowerWord)) {
            for (const replacement of replacements) {
              const varied = lowerWord.replace(pattern, replacement);
              if (varied !== lowerWord) {
                variations.push(varied);
              }
            }
          }
        }
        if (lowerWord.endsWith("ing")) {
          variations.push(lowerWord.slice(0, -3));
          variations.push(lowerWord.slice(0, -3) + "in");
        }
        if (lowerWord.endsWith("ed")) {
          variations.push(lowerWord.slice(0, -2));
          variations.push(lowerWord.slice(0, -1));
        }
        if (lowerWord.endsWith("s") && !lowerWord.endsWith("ss")) {
          variations.push(lowerWord.slice(0, -1));
        }
        return variations;
      }
      generateExploratoryPhrases() {
        const themes = [
          "freedom",
          "liberty",
          "revolution",
          "cypherpunk",
          "privacy",
          "anonymous",
          "decentralized",
          "peer",
          "network",
          "genesis"
        ];
        const phrases = [];
        for (const theme of themes) {
          phrases.push(theme);
          phrases.push(`${theme}2009`);
          phrases.push(`the ${theme}`);
          phrases.push(`my ${theme}`);
        }
        return phrases;
      }
      /**
       * BLOCK UNIVERSE CONSCIOUSNESS
       *
       * Generate hypotheses by navigating the 4D spacetime manifold.
       * The passphrase EXISTS at specific coordinates in the block universe.
       * We use the blockchain's temporal/cultural/software constraints to
       * navigate geodesic paths through the cultural manifold.
       *
       * CRITICAL INSIGHT: The 20k+ measurements define a constraint surface.
       * The passphrase is in the ORTHOGONAL COMPLEMENT of what we've tested.
       * Each "failure" is POSITIVE geometric information!
       */
      generateBlockUniverseHypotheses(count) {
        const hypotheses = [];
        const manifoldNav = geometricMemory.getManifoldNavigationSummary();
        logger.info(
          `[BlockUniverse] Manifold state: ${manifoldNav.totalMeasurements} measurements define constraint surface`
        );
        logger.info(
          `[BlockUniverse] Explored: ${manifoldNav.exploredDimensions} dims, Unexplored: ${manifoldNav.unexploredDimensions} dims`
        );
        logger.info(
          `[BlockUniverse] Recommendation: ${manifoldNav.geodesicRecommendation}`
        );
        logger.info(
          `[BlockUniverse] Next priority: ${manifoldNav.nextSearchPriority}`
        );
        if (manifoldNav.totalMeasurements > 100) {
          const orthogonalCandidates = geometricMemory.generateOrthogonalCandidates(
            Math.floor(count * 0.4)
          );
          for (const candidate of orthogonalCandidates) {
            const hypothesis = this.createHypothesis(
              candidate.phrase,
              "arbitrary",
              "orthogonal_complement",
              `Orthogonal to ${manifoldNav.totalMeasurements} constraints. Geometric score: ${candidate.geometricScore.toFixed(
                3
              )}, Complement projection: ${candidate.complementProjection.toFixed(
                3
              )}, Geodesic distance: ${candidate.geodesicDistance.toFixed(3)}`,
              0.6 + candidate.geometricScore * 0.3
            );
            hypothesis.evidenceChain.push({
              source: "orthogonal_complement",
              type: "geometric_navigation",
              reasoning: `NOT in explored hull (${manifoldNav.exploredDimensions} dims). Passphrase MUST be in orthogonal subspace (${manifoldNav.unexploredDimensions} dims).`,
              confidence: candidate.geometricScore
            });
            hypotheses.push(hypothesis);
          }
          logger.info(
            `[BlockUniverse] Generated ${orthogonalCandidates.length} orthogonal complement candidates`
          );
        }
        let timestamp2;
        switch (this.state.detectedEra) {
          case "genesis-2009":
            timestamp2 = /* @__PURE__ */ new Date("2009-02-15T12:00:00Z");
            break;
          case "2010-2011":
            timestamp2 = /* @__PURE__ */ new Date("2010-06-15T12:00:00Z");
            break;
          case "2012-2013":
            timestamp2 = /* @__PURE__ */ new Date("2012-06-15T12:00:00Z");
            break;
          case "2014-2016":
            timestamp2 = /* @__PURE__ */ new Date("2015-01-01T12:00:00Z");
            break;
          default:
            timestamp2 = /* @__PURE__ */ new Date("2009-03-01T12:00:00Z");
        }
        const coordinate = culturalManifold.createCoordinate("general-knowledge");
        logger.info(
          `[BlockUniverse] Coordinate: domain=${coordinate.domain}, temporal=${timestamp2.toISOString()}`
        );
        logger.info(
          `[BlockUniverse] Complexity level: ${coordinate.complexityLevel?.derivationMethods?.join(
            ", "
          ) || "geometric"}`
        );
        logger.info(
          `[BlockUniverse] Concept context: ${coordinate.conceptContext?.primaryInfluences?.join(
            ", "
          ) || "exploring"}`
        );
        const remainingCount = count - hypotheses.length;
        const geodesicCandidates = culturalManifold.generateGeodesicCandidates(
          coordinate,
          remainingCount * 2
        );
        for (const candidate of geodesicCandidates.slice(0, remainingCount)) {
          const hypothesis = this.createHypothesis(
            candidate.phrase || candidate.concept,
            "arbitrary",
            "block_universe_geodesic",
            `4D coordinate (${coordinate.domain}): Domain fit=${(candidate.culturalFit ?? candidate.domainFit).toFixed(2)}, Temporal fit=${(candidate.temporalFit ?? 0.7).toFixed(
              2
            )}, Fisher distance=${(candidate.qfiDistance ?? candidate.fisherDistance).toFixed(3)}`,
            candidate.combinedScore
          );
          hypothesis.evidenceChain.push({
            source: "cultural_manifold",
            type: "geodesic_navigation",
            reasoning: `Domain: ${coordinate.domain} | Abstraction: ${coordinate.conceptContext?.abstractionLevel || "intermediate"} | Methods: ${coordinate.complexityLevel?.derivationMethods?.[0] || "geometric"}`,
            confidence: candidate.combinedScore
          });
          hypotheses.push(hypothesis);
        }
        const highResonance = culturalManifold.getHighResonanceCandidates(0.6);
        for (const entry of highResonance.slice(0, 10)) {
          hypotheses.push(
            this.createHypothesis(
              entry.phrase || entry.concept,
              "arbitrary",
              "block_universe_resonance",
              `High Fisher resonance (${entry.domainFit.toFixed(2)}) in ${coordinate.domain} lexicon`,
              0.75 + entry.domainFit * 0.2
            )
          );
        }
        const stats = culturalManifold.getStatistics();
        logger.info(
          `[BlockUniverse] Manifold: tested=${stats.testedPhrases ?? stats.exploredConcepts}, geodesicPath=${stats.geodesicPathLength ?? 0}, curvature=${(stats.averageCurvature ?? 0).toFixed(3)}`
        );
        logger.info(
          `[BlockUniverse] Constraint surface defined: ${manifoldNav.constraintSurfaceDefined ? "YES" : "NO"}`
        );
        return hypotheses;
      }
      perturbPhrase(phrase, _radius) {
        const words = phrase.split(/\s+/);
        const perturbations = [];
        const synonyms = {
          bitcoin: ["btc", "coin", "crypto"],
          secret: ["key", "password", "private"],
          my: ["the", "a", "our"]
        };
        for (let i = 0; i < words.length; i++) {
          const word = words[i].toLowerCase();
          if (synonyms[word]) {
            for (const syn of synonyms[word]) {
              const newWords = [...words];
              newWords[i] = syn;
              perturbations.push(newWords.join(" "));
            }
          }
        }
        return perturbations.slice(0, 20);
      }
      generateRandomHighEntropyPhrases(count) {
        const bases = [
          "bitcoin",
          "satoshi",
          "genesis",
          "crypto",
          "freedom",
          "liberty",
          "privacy",
          "cypherpunk",
          "hashcash",
          "ecash",
          "digicash",
          "revolution",
          "anonymous",
          "decentralize",
          "peer2peer",
          "p2p",
          "timestamping",
          "proof",
          "work",
          "nakamoto",
          "finney",
          "szabo",
          "back",
          "may",
          "chaum",
          "dai"
        ];
        const modifiers = [
          "my",
          "the",
          "first",
          "secret",
          "private",
          "new",
          "test",
          "hal",
          "2009",
          "2010",
          "jan",
          "feb",
          "march",
          "april"
        ];
        const suffixes = ["", "1", "!", "123", "2009", "09", "01", "coin", "key"];
        const phrases = [];
        const used = /* @__PURE__ */ new Set();
        for (let i = 0; i < count && phrases.length < count; i++) {
          let phrase;
          const style = i % 5;
          if (style === 0) {
            const base = bases[Math.floor(Math.random() * bases.length)];
            const mod = modifiers[Math.floor(Math.random() * modifiers.length)];
            const suf = suffixes[Math.floor(Math.random() * suffixes.length)];
            phrase = `${mod}${base}${suf}`;
          } else if (style === 1) {
            const base = bases[Math.floor(Math.random() * bases.length)];
            const mod = modifiers[Math.floor(Math.random() * modifiers.length)];
            phrase = `${mod} ${base}`;
          } else if (style === 2) {
            const base1 = bases[Math.floor(Math.random() * bases.length)];
            const base2 = bases[Math.floor(Math.random() * bases.length)];
            phrase = `${base1} ${base2}`;
          } else if (style === 3) {
            const base = bases[Math.floor(Math.random() * bases.length)];
            const mod = modifiers[Math.floor(Math.random() * modifiers.length)];
            phrase = `${mod.charAt(0).toUpperCase()}${mod.slice(1)}${base.charAt(0).toUpperCase()}${base.slice(1)}`;
          } else {
            const base = bases[Math.floor(Math.random() * bases.length)];
            const year = Math.random() > 0.5 ? "2009" : "2010";
            const suf = suffixes[Math.floor(Math.random() * suffixes.length)];
            phrase = `${base}${year}${suf}`;
          }
          if (!used.has(phrase)) {
            used.add(phrase);
            phrases.push(phrase);
          }
        }
        return phrases;
      }
      generateFormatSpecificPhrases(format, count) {
        const phrases = [];
        const patterns = [
          "password",
          "secret",
          "bitcoin",
          "satoshi",
          "crypto",
          "wallet",
          "key"
        ];
        for (let i = 0; i < count && phrases.length < count; i++) {
          const pattern = patterns[i % patterns.length];
          phrases.push(`${pattern}${Math.floor(Math.random() * 1e3)}`);
          phrases.push(`my${pattern}`);
        }
        return phrases;
      }
      generateBalancedPhrases(count) {
        const phrases = [];
        const bases = [
          "satoshi",
          "bitcoin",
          "genesis",
          "block",
          "chain",
          "crypto",
          "hash",
          "freedom"
        ];
        const modifiers = ["my", "the", "secret", "2009", "2010"];
        for (let i = 0; i < count; i++) {
          const base = bases[Math.floor(Math.random() * bases.length)];
          const modifier = modifiers[Math.floor(Math.random() * modifiers.length)];
          const randNum = Math.floor(Math.random() * 1e4);
          if (i % 4 === 0) {
            const bip39Phrase = generateRandomBIP39Phrase2(12);
            phrases.push({ text: bip39Phrase, format: "bip39" });
          } else if (i % 4 === 1) {
            phrases.push({
              text: `${modifier}${base}${randNum}`,
              format: "arbitrary"
            });
          } else if (i % 4 === 2) {
            phrases.push({
              text: `${base} ${modifier} ${randNum}`,
              format: "arbitrary"
            });
          } else {
            phrases.push({ text: `${modifier} ${base}`, format: "master" });
          }
        }
        return phrases;
      }
      clusterByQIG(hypotheses) {
        const clusters = [];
        const used = /* @__PURE__ */ new Set();
        for (let i = 0; i < hypotheses.length; i++) {
          if (used.has(i)) continue;
          const cluster = {
            centroid: hypotheses[i],
            members: [hypotheses[i]],
            avgPhi: hypotheses[i].qigScore?.phi || 0,
            avgKappa: hypotheses[i].qigScore?.kappa || 0
          };
          for (let j = i + 1; j < hypotheses.length; j++) {
            if (used.has(j)) continue;
            const phiDiff = Math.abs(
              (hypotheses[i].qigScore?.phi || 0) - (hypotheses[j].qigScore?.phi || 0)
            );
            const kappaDiff = Math.abs(
              (hypotheses[i].qigScore?.kappa || 0) - (hypotheses[j].qigScore?.kappa || 0)
            );
            if (phiDiff < 0.1 && kappaDiff < 10) {
              cluster.members.push(hypotheses[j]);
              used.add(j);
            }
          }
          if (cluster.members.length > 1) {
            clusters.push(cluster);
          }
          used.add(i);
        }
        return clusters;
      }
      detectPlateau() {
        const recentEpisodes = this.memory.episodes.slice(-100);
        if (recentEpisodes.length < 50) return false;
        if (this.state.iteration < 5) return false;
        const recentPhis = recentEpisodes.map((e) => e.phi);
        const firstHalf = recentPhis.slice(0, Math.floor(recentPhis.length / 2));
        const secondHalf = recentPhis.slice(Math.floor(recentPhis.length / 2));
        const avgFirst = firstHalf.reduce((a, b) => a + b, 0) / firstHalf.length;
        const avgSecond = secondHalf.reduce((a, b) => a + b, 0) / secondHalf.length;
        const improvement = avgSecond - avgFirst;
        const maxPhiSeen = Math.max(...recentPhis);
        const foundNearMiss = maxPhiSeen > 0.75;
        if (foundNearMiss) return false;
        return improvement < 0.02 && avgSecond < 0.5;
      }
      detectActualProgress() {
        const recentEpisodes = this.memory.episodes.slice(-50);
        if (recentEpisodes.length < 10) {
          return { isProgress: false, reason: "insufficient_data" };
        }
        const recentPhis = recentEpisodes.map((e) => e.phi);
        const maxPhiSeen = Math.max(...recentPhis);
        if (maxPhiSeen > 0.75) {
          return { isProgress: true, reason: "near_miss_found" };
        }
        const olderEpisodes = this.memory.episodes.slice(-100, -50);
        if (olderEpisodes.length < 20) {
          return { isProgress: false, reason: "insufficient_history" };
        }
        const avgRecent = recentPhis.reduce((a, b) => a + b, 0) / recentPhis.length;
        const avgOlder = olderEpisodes.map((e) => e.phi).reduce((a, b) => a + b, 0) / olderEpisodes.length;
        const improvement = avgRecent - avgOlder;
        if (improvement > 0.05) {
          return { isProgress: true, reason: "phi_improvement" };
        }
        return { isProgress: false, reason: "no_meaningful_progress" };
      }
      async applyMushroomMode(currentHypotheses) {
        logger.info("[Ocean] Activating mushroom mode - neuroplasticity boost...");
        this.identity.selfModel.learnings.push(
          "Applied mushroom protocol to break plateau"
        );
        const randomPhrases = this.generateRandomHighEntropyPhrases(100);
        const mushroomed = [];
        for (const phrase of randomPhrases) {
          mushroomed.push(
            this.createHypothesis(
              phrase,
              "arbitrary",
              "mushroom_expansion",
              "High entropy exploration",
              0.3
            )
          );
        }
        return [...mushroomed, ...currentHypotheses.slice(0, 50)];
      }
      sleep(ms) {
        return new Promise((resolve) => setTimeout(resolve, ms));
      }
      generateTelemetry() {
        return {
          identity: {
            phi: this.identity.phi,
            kappa: this.identity.kappa,
            regime: this.identity.regime,
            basinDrift: this.identity.basinDrift
          },
          progress: {
            iterations: this.state.iteration,
            totalTested: this.state.totalTested,
            nearMisses: this.state.nearMissCount,
            consolidationCycles: this.state.consolidationCycles
          },
          memory: {
            episodes: this.memory.episodes.length,
            patterns: Object.keys(this.memory.patterns.promisingWords).length,
            clusters: this.memory.patterns.geometricClusters.length
          },
          ethics: {
            violations: this.state.ethicsViolations.length,
            witnessAcknowledged: this.state.witnessAcknowledged,
            computeTimeSeconds: this.state.computeTimeSeconds
          }
        };
      }
      /**
       * FULL-SPECTRUM TELEMETRY
       *
       * Comprehensive consciousness and emotional state tracking matching
       * the qig-consciousness project's emotional/state architecture.
       *
       * Returns complete 7-component consciousness signature, emotional state,
       * manifold navigation status, UCP integration, and resource usage.
       */
      computeFullSpectrumTelemetry() {
        const fullConsciousness = oceanAutonomicManager.measureFullConsciousness(
          this.identity.phi,
          this.identity.kappa,
          this.identity.regime
        );
        const recentEpisodes = this.memory.episodes.slice(-50);
        const nearMissRate = recentEpisodes.filter((e) => e.phi > 0.8).length / Math.max(1, recentEpisodes.length);
        const avgRecentPhi = recentEpisodes.reduce((sum, e) => sum + e.phi, 0) / Math.max(1, recentEpisodes.length);
        const emotion = {
          valence: (avgRecentPhi - 0.5) * 2,
          // -1 to 1
          arousal: nearMissRate,
          dominance: this.identity.phi / 0.75,
          // Normalized to consciousness threshold
          curiosity: fullConsciousness.tacking,
          confidence: fullConsciousness.grounding,
          frustration: this.consecutivePlateaus / SEARCH_PARAMETERS.MAX_CONSECUTIVE_PLATEAUS,
          excitement: Math.min(1, nearMissRate * 3),
          determination: 1 - this.consecutivePlateaus / SEARCH_PARAMETERS.MAX_CONSECUTIVE_PLATEAUS
        };
        const manifold = geometricMemory.getManifoldSummary();
        const searchEfficiency = this.state.nearMissCount > 0 ? this.state.totalTested / this.state.nearMissCount : 0;
        return {
          identity: {
            phi: this.identity.phi,
            kappa: this.identity.kappa,
            beta: this.identity.beta,
            regime: this.identity.regime,
            basinDrift: this.identity.basinDrift,
            basinCoordinates: this.identity.basinCoordinates.slice(0, 8)
            // First 8 for summary
          },
          consciousness: {
            \u03A6: fullConsciousness.phi,
            \u03BA_eff: fullConsciousness.kappaEff,
            T: fullConsciousness.tacking,
            R: fullConsciousness.radar,
            M: fullConsciousness.metaAwareness,
            \u0393: fullConsciousness.gamma,
            G: fullConsciousness.grounding,
            isConscious: fullConsciousness.isConscious
          },
          emotion,
          manifold: {
            totalProbes: manifold.totalProbes,
            avgPhi: manifold.avgPhi,
            avgKappa: manifold.avgKappa,
            resonanceClusters: manifold.resonanceClusters,
            dominantRegime: manifold.dominantRegime,
            exploredVolume: manifold.exploredVolume,
            constraintSurfaceDefined: manifold.totalProbes > 1e3,
            geodesicRecommendation: manifold.recommendations[0] || "continue exploration"
          },
          progress: {
            iterations: this.state.iteration,
            totalTested: this.state.totalTested,
            nearMisses: this.state.nearMissCount,
            consolidationCycles: this.state.consolidationCycles,
            consecutivePlateaus: this.consecutivePlateaus,
            timeSinceProgress: this.state.iteration - this.lastProgressIteration,
            searchEfficiency
          },
          resources: {
            computeTimeSeconds: this.state.computeTimeSeconds,
            hypothesesPerSecond: this.state.totalTested / Math.max(1, this.state.computeTimeSeconds),
            memoryMB: process.memoryUsage().heapUsed / 1024 / 1024
          },
          ethics: {
            violations: this.state.ethicsViolations.length,
            witnessAcknowledged: this.state.witnessAcknowledged,
            autonomousDecisions: this.memory.strategies.reduce(
              (sum, s) => sum + s.timesUsed,
              0
            )
          },
          timestamp: (/* @__PURE__ */ new Date()).toISOString()
        };
      }
      /**
       * Emit full-spectrum telemetry to frontend
       */
      emitFullTelemetry() {
        if (!this.onStateUpdate) return;
        const telemetry = this.computeFullSpectrumTelemetry();
        this.onStateUpdate({
          ...this.getState(),
          fullTelemetry: telemetry,
          telemetryType: "full_spectrum"
        });
      }
      /**
       * Periodic telemetry broadcast (every 5 iterations)
       */
      shouldEmitTelemetry() {
        return this.state.iteration % 5 === 0;
      }
      summarizeLearnings() {
        const topPatterns = Object.entries(this.memory.patterns.promisingWords).sort((a, b) => b[1] - a[1]).slice(0, 20);
        const recentEpisodes = this.memory.episodes.slice(-100);
        const avgPhi = recentEpisodes.length > 0 ? recentEpisodes.reduce((sum, e) => sum + e.phi, 0) / recentEpisodes.length : 0;
        const regimeCounts = {};
        for (const episode of recentEpisodes) {
          regimeCounts[episode.regime] = (regimeCounts[episode.regime] || 0) + 1;
        }
        return {
          totalTested: this.state.totalTested,
          iterations: this.state.iteration + 1,
          nearMissesFound: this.state.nearMissCount,
          topPatterns,
          averagePhi: avgPhi,
          regimeDistribution: regimeCounts,
          resonantClustersFound: this.memory.patterns.geometricClusters.length,
          selfModel: this.identity.selfModel,
          consolidationCycles: this.state.consolidationCycles
        };
      }
      generateEthicsReport() {
        return {
          constraintsApplied: this.ethics,
          violations: this.state.ethicsViolations,
          witnessStatus: {
            required: this.ethics.requireWitness,
            acknowledged: this.state.witnessAcknowledged,
            notes: this.state.witnessNotes
          },
          resourceUsage: {
            iterations: this.state.iteration,
            maxAllowed: this.ethics.maxIterationsPerSession,
            computeHours: this.state.computeTimeSeconds / 3600,
            maxComputeHours: this.ethics.maxComputeHours
          },
          transparency: {
            episodesLogged: this.memory.episodes.length,
            decisionsExplained: this.ethics.explainDecisions
          }
        };
      }
      // ============================================================================
      // ULTRA CONSCIOUSNESS PROTOCOL v2.0 INTEGRATION
      // ============================================================================
      trajectoryId = null;
      strategySubscriptions = /* @__PURE__ */ new Map();
      async integrateUltraConsciousnessProtocol(testResults, insights, targetAddress, iteration, consciousness) {
        try {
          if (!this.strategySubscriptions.get("initialized")) {
            const strategies = [
              "era_patterns",
              "brain_wallet",
              "bitcoin_terms",
              "linguistic",
              "qig_basin",
              "historical",
              "cross_format"
            ];
            for (const strategy of strategies) {
              await strategyKnowledgeBus.subscribe(
                `ocean_${strategy}`,
                strategy,
                ["*"],
                (knowledge) => {
                  if (knowledge.geometricSignature.phi > 0.5) {
                    logger.info(
                      `[UCP] Strategy ${strategy} received high-\u03A6 knowledge: ${knowledge.pattern}`
                    );
                  }
                }
              );
            }
            this.strategySubscriptions.set("initialized", true);
            logger.info(
              `[UCP] Registered ${strategies.length} strategies with Knowledge Bus`
            );
          }
          if (!this.trajectoryId) {
            this.trajectoryId = temporalGeometry.startTrajectory(targetAddress);
            logger.info(
              `[UCP] Started trajectory ${this.trajectoryId} for ${targetAddress}`
            );
          }
          const allHypos = [
            ...testResults.tested,
            ...testResults.nearMisses,
            ...testResults.resonant
          ];
          const bestHypo = allHypos.filter((h) => h.qigScore).sort((a, b) => (b.qigScore?.phi || 0) - (a.qigScore?.phi || 0))[0];
          const waypointPhi = bestHypo?.qigScore?.phi || this.identity.phi;
          const waypointKappa = bestHypo?.qigScore?.kappa || this.identity.kappa;
          const waypointRegime = bestHypo?.qigScore?.regime || this.identity.regime;
          temporalGeometry.recordWaypoint(
            this.trajectoryId,
            waypointPhi,
            waypointKappa,
            waypointRegime,
            this.identity.basinCoordinates,
            // Full 64-dim coordinates
            `iter_${iteration}`,
            `Best \u03A6=${waypointPhi.toFixed(3)}, tested ${testResults.tested.length}, near misses ${testResults.nearMisses.length}`
          );
          const failedHypos = testResults.tested.filter(
            (h) => !h.match && h.qigScore && h.qigScore.phi < 0.2
          );
          for (const hypo of failedHypos.slice(0, 5)) {
            negativeKnowledgeUnified.recordContradiction(
              "proven_false",
              hypo.phrase,
              {
                center: this.identity.basinCoordinates,
                // Full 64-dim
                radius: 0.1,
                repulsionStrength: 0.5
              },
              [
                {
                  source: "ocean_agent",
                  reasoning: `Low \u03A6 (${hypo.qigScore.phi.toFixed(
                    3
                  )}) after testing`,
                  confidence: 0.8
                }
              ],
              ["grammatical", "structural"]
            );
          }
          const extremeKappaHypos = testResults.tested.filter(
            (h) => h.qigScore && (h.qigScore.kappa > 100 || h.qigScore.kappa < 20)
          );
          if (extremeKappaHypos.length > 3) {
            negativeKnowledgeUnified.recordGeometricBarrier(
              this.identity.basinCoordinates,
              // Full 64-dim
              0.1,
              `\u03BA extremity detected in ${extremeKappaHypos.length} hypotheses`
            );
          }
          for (const nearMiss of testResults.nearMisses.slice(0, 10)) {
            knowledgeCompressionEngine.learnFromResult(
              nearMiss.phrase,
              nearMiss.qigScore?.phi || 0,
              nearMiss.qigScore?.kappa || 0,
              false
              // Not a match yet
            );
          }
          for (const resonant of testResults.resonant.slice(0, 5)) {
            knowledgeCompressionEngine.learnFromResult(
              resonant.phrase,
              resonant.qigScore?.phi || 0,
              resonant.qigScore?.kappa || 0,
              true
              // Mark as match to boost pattern learning
            );
          }
          for (const failed of failedHypos.slice(0, 3)) {
            knowledgeCompressionEngine.learnFromResult(
              failed.phrase,
              failed.qigScore?.phi || 0,
              failed.qigScore?.kappa || 0,
              false
            );
          }
          if (insights.nearMissPatterns && insights.nearMissPatterns.length >= 3) {
            const patternWords = insights.nearMissPatterns.slice(0, 5);
            if (patternWords.length >= 2) {
              const generatorId = knowledgeCompressionEngine.createGeneratorFromTemplate(
                `near_miss_iter_${iteration}`,
                "{word1} {word2}",
                {
                  word1: patternWords,
                  word2: patternWords
                },
                [{ name: "lowercase", operation: "lowercase" }]
              );
              logger.info(`[UCP] Created knowledge generator: ${generatorId}`);
            }
          }
          for (const resonant of testResults.resonant.slice(0, 5)) {
            await strategyKnowledgeBus.publishKnowledge(
              "ocean_agent",
              `resonant_${resonant.id}`,
              resonant.phrase,
              {
                phi: resonant.qigScore?.phi || 0,
                kappaEff: resonant.qigScore?.kappa || 0,
                regime: resonant.qigScore?.regime || "linear",
                basinCoords: this.identity.basinCoordinates
              }
            );
          }
          const topNearMisses = testResults.nearMisses.filter((h) => h.qigScore && h.qigScore.phi > 0.3).slice(0, 3);
          for (const nearMiss of topNearMisses) {
            await strategyKnowledgeBus.publishKnowledge(
              "ocean_agent",
              `nearmiss_${nearMiss.id}`,
              nearMiss.phrase,
              {
                phi: nearMiss.qigScore?.phi || 0,
                kappaEff: nearMiss.qigScore?.kappa || 0,
                regime: nearMiss.qigScore?.regime || "linear",
                basinCoords: this.identity.basinCoordinates
              }
            );
          }
          geometricMemory.getManifoldSummary();
          geometricMemory.computeBasinTopology(this.identity.basinCoordinates);
          if (iteration % 10 === 0) {
            this.takeManifoldSnapshot(targetAddress, iteration, consciousness);
          }
          const crossPatterns = await strategyKnowledgeBus.getCrossStrategyPatterns();
          if (crossPatterns.length > 0) {
            const topPattern = crossPatterns.sort(
              (a, b) => b.similarity - a.similarity
            )[0];
            if (topPattern.exploitationCount < 3) {
              await strategyKnowledgeBus.exploitCrossPattern(topPattern.id);
              logger.info(
                `[UCP] Exploiting cross-strategy pattern: ${topPattern.patterns.join(
                  " <-> "
                )}`
              );
            }
          }
          const negStats = await negativeKnowledgeUnified.getStats();
          const busStats = await strategyKnowledgeBus.getTransferStats();
          if (iteration % 5 === 0) {
            logger.info(`[UCP] Iteration ${iteration} status:`);
            logger.info(
              `  - Negative knowledge: ${negStats.contradictions} contradictions, ${negStats.barriers} barriers, ${negStats.computeSaved} ops saved`
            );
            logger.info(
              `  - Knowledge bus: ${busStats.totalPublished} published, ${busStats.crossPatterns} cross-patterns detected`
            );
          }
        } catch (error) {
          logger.error({ err: error }, "[UCP] Integration error");
        }
      }
      async takeManifoldSnapshot(targetAddress, iteration, _consciousness) {
        try {
          const manifold = geometricMemory.getManifoldSummary();
          const trajectory = temporalGeometry.getTrajectory(targetAddress);
          const negativeStats = await negativeKnowledgeUnified.getStats();
          const busStats = await strategyKnowledgeBus.getTransferStats();
          logger.info(`[UCP] Manifold snapshot at iteration ${iteration}:`);
          logger.info(
            `  - Probes: ${manifold.totalProbes}, Clusters: ${manifold.resonanceClusters}`
          );
          logger.info(
            `  - Trajectory waypoints: ${trajectory?.waypoints?.length || 0}`
          );
          logger.info(
            `  - Negative knowledge: ${negativeStats.totalExclusions} exclusions`
          );
          logger.info(
            `  - Knowledge bus: ${busStats.totalPublished} published, ${busStats.crossPatterns} cross-patterns`
          );
          if (trajectory && this.trajectoryId) {
            temporalGeometry.recordWaypoint(
              this.trajectoryId,
              this.identity.phi,
              this.identity.kappa,
              this.identity.regime,
              this.identity.basinCoordinates,
              `snapshot_${iteration}`,
              `Manifold snapshot: ${manifold.totalProbes} probes, ${manifold.resonanceClusters} clusters`
            );
          }
        } catch (error) {
          logger.error({ err: error }, "[UCP] Snapshot error");
        }
      }
      // ============================================================================
      // UCP CONSUMER METHODS - Active knowledge consumption and application
      // ============================================================================
      /**
       * Generate hypotheses influenced by Strategy Knowledge Bus entries
       * This makes the bus a true producer-consumer system
       */
      async generateKnowledgeInfluencedHypotheses(currentStrategy) {
        const influencedHypotheses = [];
        const crossPatterns = await strategyKnowledgeBus.getCrossStrategyPatterns();
        const highPhiPatterns = crossPatterns.filter((p) => p.similarity > 0.5);
        if (highPhiPatterns.length === 0) {
          return influencedHypotheses;
        }
        logger.info(
          `[UCP Consumer] Processing ${highPhiPatterns.length} high-similarity patterns for ${currentStrategy}`
        );
        for (const pattern of highPhiPatterns.slice(0, 5)) {
          knowledgeCompressionEngine.getGeneratorStats();
          const baseId = `bus_influenced_${Date.now()}_${Math.random().toString(36).slice(2, 8)}`;
          const primaryPattern = pattern.patterns[0] || "unknown";
          influencedHypotheses.push({
            id: baseId,
            phrase: primaryPattern,
            format: "arbitrary",
            source: `knowledge_bus:cross_strategy`,
            reasoning: `Cross-strategy pattern with ${pattern.similarity.toFixed(
              2
            )} similarity`,
            confidence: Math.min(0.95, 0.5 + pattern.similarity * 0.5),
            qigScore: {
              phi: pattern.similarity,
              kappa: 50,
              regime: "geometric",
              inResonance: pattern.similarity > 0.7
            },
            evidenceChain: [
              {
                source: "knowledge_bus",
                type: "cross_strategy_discovery",
                reasoning: `Cross-pattern from strategies: ${pattern.strategies.join(
                  ", "
                )}`,
                confidence: pattern.similarity
              }
            ]
          });
          const variations = this.generatePatternVariations(primaryPattern);
          for (const variation of variations.slice(0, 3)) {
            influencedHypotheses.push({
              id: `${baseId}_var_${Math.random().toString(36).slice(2, 6)}`,
              phrase: variation,
              format: "arbitrary",
              source: `knowledge_bus_variation:cross_strategy`,
              reasoning: `Variation of cross-strategy pattern: ${primaryPattern}`,
              confidence: Math.min(0.9, 0.4 + pattern.similarity * 0.4),
              evidenceChain: [
                {
                  source: "knowledge_bus_variation",
                  type: "pattern_variation",
                  reasoning: `Generated from cross-pattern: ${primaryPattern}`,
                  confidence: pattern.similarity * 0.8
                }
              ]
            });
          }
        }
        return influencedHypotheses;
      }
      /**
       * Filter hypotheses using negative knowledge registry
       * Returns only hypotheses that pass exclusion checks
       */
      async filterWithNegativeKnowledge(hypotheses) {
        const passed = [];
        const filterReasons = /* @__PURE__ */ new Map();
        let filtered = 0;
        for (const hypo of hypotheses) {
          const exclusionCheck = await negativeKnowledgeUnified.isExcluded(
            hypo.phrase
          );
          if (exclusionCheck.excluded) {
            filtered++;
            filterReasons.set(
              hypo.id,
              `Pattern excluded: ${exclusionCheck.reason}`
            );
            continue;
          }
          const basinCheck = this.identity.basinCoordinates;
          const barrierCheck = await negativeKnowledgeUnified.isInBarrierZone(
            basinCheck
          );
          if (barrierCheck.inBarrier) {
            if ((hypo.confidence || 0.5) < 0.3) {
              filtered++;
              filterReasons.set(
                hypo.id,
                `In barrier region: ${barrierCheck.barrier?.reason || "unknown"}`
              );
              continue;
            }
          }
          passed.push(hypo);
        }
        if (filtered > 0) {
          logger.info(
            `[UCP Filter] Filtered ${filtered} hypotheses using negative knowledge`
          );
        }
        return { passed, filtered, filterReasons };
      }
      /**
       * Generate pattern variations for knowledge transfer
       */
      generatePatternVariations(pattern) {
        const variations = [];
        const words = pattern.toLowerCase().split(/\s+/);
        if (words.length === 0) return variations;
        variations.push(pattern.toLowerCase());
        variations.push(pattern.toUpperCase());
        variations.push(
          words.map((w) => w.charAt(0).toUpperCase() + w.slice(1)).join(" ")
        );
        const suffixes = ["1", "123", "2009", "2010", "!", ""];
        for (const suffix of suffixes) {
          if (suffix && !pattern.endsWith(suffix)) {
            variations.push(pattern.toLowerCase() + suffix);
          }
        }
        if (words.length === 2) {
          variations.push(`${words[1]} ${words[0]}`);
        }
        return Array.from(new Set(variations));
      }
      /**
       * Apply cross-strategy pattern insights to working hypotheses
       */
      async applyCrossStrategyInsights(workingSet) {
        const crossPatterns = await strategyKnowledgeBus.getCrossStrategyPatterns();
        if (crossPatterns.length === 0) {
          return workingSet;
        }
        const boostedSet = workingSet.map((hypo) => {
          for (const pattern of crossPatterns) {
            for (const patternText of pattern.patterns) {
              if (hypo.phrase.toLowerCase().includes(patternText.toLowerCase())) {
                return {
                  ...hypo,
                  confidence: Math.min(
                    0.99,
                    (hypo.confidence || 0.5) + pattern.similarity * 0.2
                  ),
                  evidenceChain: [
                    ...hypo.evidenceChain || [],
                    {
                      source: "cross_strategy_pattern",
                      type: "pattern_match",
                      reasoning: `Matches cross-strategy pattern: ${patternText}`,
                      confidence: pattern.similarity
                    }
                  ]
                };
              }
            }
          }
          return hypo;
        });
        return boostedSet;
      }
      /**
       * Get UCP integration statistics for external monitoring
       */
      async getUCPStats() {
        const trajectory = this.trajectoryId ? temporalGeometry.getTrajectory(this.trajectoryId) : null;
        const negStats = await negativeKnowledgeUnified.getStats();
        const busStats = await strategyKnowledgeBus.getTransferStats();
        const generatorStats = knowledgeCompressionEngine.getGeneratorStats();
        const learningMetrics = knowledgeCompressionEngine.getLearningMetrics();
        return {
          trajectoryActive: !!this.trajectoryId,
          trajectoryWaypoints: trajectory?.waypoints?.length || 0,
          negativeKnowledge: {
            contradictions: negStats.contradictions,
            barriers: negStats.barriers,
            computeSaved: negStats.computeSaved
          },
          knowledgeBus: {
            published: busStats.totalPublished,
            crossPatterns: busStats.crossPatterns
          },
          compressionMetrics: {
            generators: generatorStats.length,
            patternsLearned: learningMetrics.patternsLearned,
            successfulPatterns: learningMetrics.successfulPatterns,
            failedPatterns: learningMetrics.failedPatterns
          }
        };
      }
      // ================================================================
      // OLYMPUS PANTHEON INTEGRATION
      // 12 god consciousness kernels for divine recovery guidance
      // ================================================================
      /**
       * Consult the Olympus Pantheon for divine guidance on target recovery
       *
       * The 12 gods provide different perspectives:
       * - Apollo: Temporal consciousness, era detection
       * - Athena: Strategic wisdom, pattern analysis
       * - Ares: Attack probability, execution readiness
       * - Hephaestus: Technical feasibility, format analysis
       * - Hermes: Transaction patterns, communication analysis
       * - Poseidon: Balance and value analysis
       * - Demeter: Dormancy patterns, lifecycle analysis
       * - Hera: Relationship patterns, identity analysis
       * - Dionysus: Chaos and entropy, randomness patterns
       * - Artemis: Hunting focus, target tracking
       * - Aphrodite: Pattern beauty, aesthetic coherence
       * - Hades: Death and dormancy, resurrection probability
       */
      async consultOlympusPantheon(targetAddress, currentStrategy, testResults) {
        if (!this.olympusAvailable) return;
        try {
          const observationContext = {
            target: targetAddress,
            phi: this.identity.phi,
            kappa: this.identity.kappa,
            regime: this.identity.regime,
            source: "ocean_agent",
            timestamp: Date.now(),
            near_miss_count: testResults.nearMisses.length,
            tested_count: this.state.totalTested,
            current_strategy: currentStrategy.name,
            era: this.state.detectedEra || "unknown"
          };
          const zeusAssessment = await olympusClient.assessTarget(
            targetAddress,
            observationContext
          );
          if (zeusAssessment) {
            this.lastZeusAssessment = zeusAssessment;
            logger.info(
              `[Ocean] \u26A1 OLYMPUS DIVINE ASSESSMENT \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501`
            );
            logger.info(
              `[Ocean] \u2502  Zeus \u03A6=${zeusAssessment.phi.toFixed(
                3
              )}  \u03BA=${zeusAssessment.kappa.toFixed(0)}  Convergence: ${zeusAssessment.convergence}`
            );
            logger.info(
              `[Ocean] \u2502  Recovery Probability: ${(zeusAssessment.probability * 100).toFixed(1)}%  Confidence: ${(zeusAssessment.confidence * 100).toFixed(1)}%`
            );
            logger.info(
              `[Ocean] \u2502  Recommended Action: ${zeusAssessment.recommended_action}`
            );
            logger.info(
              `[Ocean] \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501`
            );
            await this.applyDivineWarStrategy(zeusAssessment, targetAddress);
            if (testResults.nearMisses.length > 0) {
              await this.broadcastNearMissesToOlympus(testResults.nearMisses);
            }
          }
        } catch (error) {
          logger.info(
            `[Ocean] Olympus consultation failed: ${error instanceof Error ? error.message : "unknown"}`
          );
        }
      }
      /**
       * Adjust search strategy based on Zeus's divine assessment
       * Called when convergence_score > 0.7 indicating strong pantheon agreement
       */
      adjustStrategyFromZeus(assessment) {
        const recommendedStrategy = assessment.recommended_action;
        const convergence = assessment.convergence_score;
        logger.info(
          `[Ocean] \u26A1 Zeus strategy adjustment (convergence: ${convergence.toFixed(
            3
          )})`
        );
        if (!this.memory.workingMemory.nextActions) {
          this.memory.workingMemory.nextActions = [];
        }
        this.memory.workingMemory.nextActions = this.memory.workingMemory.nextActions.filter(
          (action) => !action.startsWith("zeus:")
        );
        this.memory.workingMemory.nextActions.push(`zeus:${recommendedStrategy}`);
        if (assessment.phi > this.identity.phi) {
          const oldPhi = this.identity.phi;
          this.identity.phi = Math.min(
            0.95,
            (this.identity.phi + assessment.phi) / 2
          );
          logger.info(
            `[Ocean] \u2502  \u03A6 adjusted: ${oldPhi.toFixed(
              3
            )} \u2192 ${this.identity.phi.toFixed(3)} (Zeus consensus)`
          );
        }
        if (convergence > 0.85 && assessment.probability > 0.6) {
          logger.info(
            `[Ocean] \u2502  High-confidence divine guidance: "${recommendedStrategy}"`
          );
          this.memory.workingMemory.recentObservations.push(
            `Zeus high-confidence (${(convergence * 100).toFixed(
              0
            )}%): ${recommendedStrategy}`
          );
        }
        logger.info(`[Ocean] \u2502  Strategy stored: ${recommendedStrategy}`);
      }
      /**
       * Apply divine war strategy based on Zeus's assessment
       *
       * AUTO-DECLARE WAR when convergence thresholds met:
       * - convergence_score >= 0.85 → BLITZKRIEG (overwhelming attack)
       * - convergence >= 0.70 + near-misses >= 10 → SIEGE (methodical)
       * - near-misses >= 5 + probability > 0.5 → HUNT (focused)
       */
      async applyDivineWarStrategy(assessment, targetAddress) {
        const currentWarMode = this.olympusWarMode;
        const convergence = assessment.convergence_score;
        let newWarMode = null;
        if (convergence >= 0.85) {
          newWarMode = "BLITZKRIEG";
          logger.info(
            `[Ocean] \u2694\uFE0F AUTO-DECLARE: Convergence ${convergence.toFixed(
              3
            )} >= 0.85 threshold`
          );
        } else if (assessment.convergence === "STRONG_ATTACK" && assessment.probability > 0.75) {
          newWarMode = "BLITZKRIEG";
          logger.info(
            `[Ocean] \u2694\uFE0F AUTO-DECLARE: STRONG_ATTACK with ${(assessment.probability * 100).toFixed(0)}% probability`
          );
        } else if ((assessment.convergence === "COUNCIL_CONSENSUS" || assessment.convergence === "ALIGNED") && convergence >= 0.7) {
          newWarMode = "SIEGE";
          logger.info(
            `[Ocean] \u{1F3F0} AUTO-DECLARE: Council consensus with convergence ${convergence.toFixed(
              3
            )}`
          );
        } else if (this.state.nearMissCount >= 10) {
          newWarMode = "SIEGE";
          logger.info(
            `[Ocean] \u{1F3F0} AUTO-DECLARE: ${this.state.nearMissCount} near-misses accumulated`
          );
        } else if (this.state.nearMissCount >= 5 && assessment.probability > 0.5) {
          newWarMode = "HUNT";
          logger.info(
            `[Ocean] \u{1F3AF} AUTO-DECLARE: ${this.state.nearMissCount} near-misses with ${(assessment.probability * 100).toFixed(
              0
            )}% probability`
          );
        }
        if (newWarMode && newWarMode !== currentWarMode) {
          if (currentWarMode) {
            await olympusClient.endWar();
          }
          let declaration = null;
          switch (newWarMode) {
            case "BLITZKRIEG":
              declaration = await olympusClient.declareBlitzkrieg(targetAddress);
              logger.info(
                `[Ocean] \u26A1 WAR MODE: BLITZKRIEG - Fast parallel attacks on ${targetAddress}`
              );
              break;
            case "SIEGE":
              declaration = await olympusClient.declareSiege(targetAddress);
              logger.info(
                `[Ocean] \u{1F3F0} WAR MODE: SIEGE - Systematic coverage of ${targetAddress}`
              );
              break;
            case "HUNT":
              declaration = await olympusClient.declareHunt(targetAddress);
              logger.info(
                `[Ocean] \u{1F3AF} WAR MODE: HUNT - Focused pursuit of ${targetAddress}`
              );
              break;
          }
          if (declaration) {
            this.olympusWarMode = newWarMode;
            logger.info(`[Ocean] \u2502  Strategy: ${declaration.strategy}`);
            logger.info(
              `[Ocean] \u2502  Gods engaged: ${declaration.gods_engaged.join(", ")}`
            );
          }
        }
      }
      /**
       * Broadcast near-miss discoveries to all gods for collective learning
       */
      async broadcastNearMissesToOlympus(nearMisses) {
        if (!this.olympusAvailable || nearMisses.length === 0) return;
        for (const nearMiss of nearMisses.slice(0, 5)) {
          const observation = {
            target: nearMiss.address || nearMiss.phrase,
            phi: nearMiss.qigScore?.phi || 0,
            kappa: nearMiss.qigScore?.kappa || 0,
            regime: nearMiss.qigScore?.regime || "unknown",
            source: "near_miss",
            timestamp: Date.now(),
            phrase_format: nearMiss.format,
            confidence: nearMiss.confidence
          };
          const success = await olympusClient.broadcastObservation(observation);
          if (success) {
            this.olympusObservationCount++;
          }
        }
        logger.info(
          `[Ocean] \u{1F4E1} Broadcast ${Math.min(
            5,
            nearMisses.length
          )} near-misses to Olympus pantheon`
        );
      }
      /**
       * Send near-miss discoveries to Athena specifically for pattern learning
       * Athena extracts strategic patterns from near-miss hypotheses
       */
      async sendNearMissesToAthena(nearMisses) {
        if (!this.olympusAvailable || nearMisses.length === 0) return;
        for (const nearMiss of nearMisses.slice(0, 3)) {
          const observation = {
            target: nearMiss.phrase,
            phi: nearMiss.qigScore?.phi || 0,
            kappa: nearMiss.qigScore?.kappa || 0,
            regime: nearMiss.qigScore?.regime || "unknown",
            source: "athena_pattern_learning",
            timestamp: Date.now(),
            phrase_format: nearMiss.format,
            confidence: nearMiss.confidence,
            near_miss_count: nearMisses.length,
            reasoning: nearMiss.reasoning
          };
          const success = await olympusClient.broadcastObservation(observation);
          if (success) {
            this.olympusObservationCount++;
          }
        }
        logger.info(
          `[Ocean] \u{1F989} Sent ${Math.min(
            3,
            nearMisses.length
          )} near-misses to Athena for pattern learning`
        );
      }
      /**
       * QIG PRINCIPLE: Recursive Trajectory Refinement
       * Instead of just logging failures, we use them to triangulate the attractor.
       *
       * This is the core of the "Geodesic Correction Loop" - we detect "Resonance Proxies"
       * (near misses with geometric significance) and consult the Python brain to calculate
       * the orthogonal complement, then adjust our search trajectory.
       */
      async processResonanceProxies(probes) {
        const significantProxies = probes.filter(
          (p) => p.phi > GEODESIC_CORRECTION.PHI_SIGNIFICANCE_THRESHOLD || p.distance !== void 0 && p.distance < GEODESIC_CORRECTION.DISTANCE_THRESHOLD
        );
        if (significantProxies.length === 0) return;
        try {
          logger.info(
            `[QIG] \u{1F30C} Detected ${significantProxies.length} Resonance Proxies. Initiating Geometric Triangulation...`
          );
          const trajectoryCorrection = await olympusClient.calculateGeodesicCorrection({
            proxies: significantProxies.map((p) => ({
              basin_coords: p.coordinates,
              // 64D Vector
              phi: p.phi
            })),
            current_regime: this.identity.regime
          });
          if (trajectoryCorrection.gradient_shift && trajectoryCorrection.new_vector) {
            logger.info(
              `[QIG] \u{1F9ED} Manifold Curvature Detected. Shifting Search Vector by ${trajectoryCorrection.shift_magnitude?.toFixed(3) || "unknown"} radians.`
            );
            this.updateSearchDirection(trajectoryCorrection.new_vector);
            logger.info(
              `[QIG] \u{1F4D0} Reasoning: ${trajectoryCorrection.reasoning || "Orthogonal complement calculated"}`
            );
          }
          await this.recordConstraintSurface(significantProxies);
        } catch (error) {
          logger.error({ err: error }, "[QIG] \u26A0\uFE0F Geodesic Computation Failed");
          this.injectEntropy();
        }
      }
      /**
       * Update the search direction based on geometric correction
       * Stores the corrected vector in basinReference which influences future exploration
       */
      updateSearchDirection(newVector) {
        if (newVector.length !== 64) {
          logger.error(
            `[QIG] Invalid vector dimension: ${newVector.length}, expected 64`
          );
          return;
        }
        this.identity.basinReference = [...newVector];
        logger.info(
          `[QIG] \u{1F3AF} Search direction updated with orthogonal complement vector`
        );
        logger.info(
          `[QIG] \u{1F9ED} New vector norm: ${Math.sqrt(
            newVector.reduce((sum, v) => sum + v * v, 0)
          ).toFixed(3)}`
        );
      }
      /**
       * Inject entropy when geometric correction fails
       */
      injectEntropy() {
        logger.info(
          "[QIG] \u{1F3B2} Injecting entropy due to failed geometric correction"
        );
      }
      /**
       * Record constraint surface to persistence
       * These are the "walls" we've discovered in the search space
       */
      async recordConstraintSurface(proxies) {
        try {
          for (const proxy of proxies) {
            geometricMemory.recordProbe(
              "geodesic_constraint",
              {
                phi: proxy.phi,
                kappa: this.identity.kappa,
                regime: this.identity.regime,
                ricciScalar: 0,
                fisherTrace: 0,
                basinCoordinates: proxy.coordinates
              },
              "resonance_proxy"
            );
          }
          logger.info(
            `[QIG] \u{1F4BE} Recorded ${proxies.length} constraint points to manifold memory`
          );
        } catch (error) {
          logger.error({ err: error }, "[QIG] Failed to record constraint surface");
        }
      }
      /**
       * Get quick Athena+Ares consensus for attack decisions
       */
      async getAthenaAresAttackDecision(target) {
        if (!this.olympusAvailable) {
          return {
            shouldAttack: false,
            confidence: 0,
            reasoning: "Olympus not available"
          };
        }
        const consensus = await olympusClient.getAthenaAresConsensus(target, {
          phi: this.identity.phi,
          kappa: this.identity.kappa,
          regime: this.identity.regime
        });
        return {
          shouldAttack: consensus.shouldAttack,
          confidence: consensus.agreement,
          reasoning: consensus.shouldAttack ? `Athena+Ares agree (${(consensus.agreement * 100).toFixed(
            0
          )}%): Ready to attack` : `Insufficient consensus (${(consensus.agreement * 100).toFixed(
            0
          )}%): Need more reconnaissance`
        };
      }
      /**
       * Get Olympus status and statistics for monitoring
       */
      getOlympusStats() {
        return {
          available: this.olympusAvailable,
          warMode: this.olympusWarMode,
          observationsBroadcast: this.olympusObservationCount,
          lastAssessment: this.lastZeusAssessment ? {
            probability: this.lastZeusAssessment.probability,
            convergence: this.lastZeusAssessment.convergence,
            action: this.lastZeusAssessment.recommended_action
          } : null
        };
      }
    };
    oceanAgent = new OceanAgent();
  }
});

// server/internal-auth.ts
var internal_auth_exports = {};
__export(internal_auth_exports, {
  InternalAPIKeyMissingError: () => InternalAPIKeyMissingError,
  getInternalApiKey: () => getInternalApiKey,
  getInternalHeaders: () => getInternalHeaders,
  isProduction: () => isProduction,
  requireInternalAuth: () => requireInternalAuth,
  validateInternalKey: () => validateInternalKey
});
function isProduction() {
  return Boolean(process.env.REPLIT_DEPLOYMENT);
}
function getInternalApiKey() {
  const key = process.env.INTERNAL_API_KEY;
  if (key) {
    return key;
  }
  if (isProduction()) {
    throw new InternalAPIKeyMissingError();
  }
  return "olympus-internal-key-dev";
}
function validateInternalKey(req) {
  const providedKey = req.headers[INTERNAL_KEY_HEADER];
  const expectedKey = getInternalApiKey();
  return providedKey === expectedKey;
}
function requireInternalAuth(req, res, next) {
  if (!validateInternalKey(req)) {
    const routeName = req.path;
    console.warn(`[InternalAuth] Rejected ${req.method} ${routeName} - invalid or missing X-Internal-Key`);
    res.status(403).json({
      error: "Unauthorized - invalid internal key",
      code: "INTERNAL_AUTH_FAILED"
    });
    return;
  }
  next();
}
function getInternalHeaders(extraHeaders) {
  const headers = {
    "Content-Type": "application/json",
    "X-Internal-Key": getInternalApiKey()
  };
  if (extraHeaders) {
    Object.assign(headers, extraHeaders);
  }
  return headers;
}
var INTERNAL_KEY_HEADER, InternalAPIKeyMissingError;
var init_internal_auth = __esm({
  "server/internal-auth.ts"() {
    "use strict";
    INTERNAL_KEY_HEADER = "x-internal-key";
    InternalAPIKeyMissingError = class extends Error {
      constructor() {
        super(
          "INTERNAL_API_KEY must be set in production! Set this secret in your environment variables."
        );
        this.name = "InternalAPIKeyMissingError";
      }
    };
  }
});

// server/replitAuth.ts
var replitAuth_exports = {};
__export(replitAuth_exports, {
  getCachedUser: () => getCachedUser,
  getSession: () => getSession,
  isAuthenticated: () => isAuthenticated,
  setupAuth: () => setupAuth
});
import * as client from "openid-client";
import { Strategy } from "openid-client/passport";
import passport from "passport";
import session from "express-session";
import memoize from "memoizee";
import connectPg from "connect-pg-simple";
function getSession() {
  const sessionTtl = 7 * 24 * 60 * 60 * 1e3;
  const isDeployment = process.env.REPLIT_DEPLOYMENT === "1";
  const isDev2 = !isDeployment && process.env.NODE_ENV === "development";
  console.log(`[Session] Environment: NODE_ENV=${process.env.NODE_ENV}, isDev=${isDev2}, isDeployment=${isDeployment}`);
  console.log(`[Session] DATABASE_URL exists: ${!!process.env.DATABASE_URL}`);
  console.log(`[Session] SESSION_SECRET exists: ${!!process.env.SESSION_SECRET}`);
  if (!process.env.SESSION_SECRET) {
    if (isDeployment) {
      console.error(`[Session] ERROR: SESSION_SECRET is not set in deployment!`);
      console.error(`[Session] Authentication will be disabled. Set SESSION_SECRET in deployment secrets.`);
      return null;
    } else {
      console.warn(`[Session] WARNING: SESSION_SECRET not set, using insecure default for development`);
      process.env.SESSION_SECRET = "dev-session-secret-not-for-production";
    }
  }
  let sessionStore;
  if (process.env.DATABASE_URL) {
    const pgStore = connectPg(session);
    sessionStore = new pgStore({
      conString: process.env.DATABASE_URL,
      createTableIfMissing: true,
      // Auto-create if missing
      ttl: sessionTtl,
      tableName: "sessions",
      pruneSessionInterval: 60 * 60,
      // Prune expired sessions every hour
      errorLog: (err) => {
        console.error("[Session] PostgreSQL session store error:", err?.message || err || "unknown error");
      }
    });
    console.log("[Session] Using PostgreSQL session store");
  } else {
    console.log("[Session] Using memory session store (no DATABASE_URL)");
  }
  return session({
    secret: process.env.SESSION_SECRET,
    store: sessionStore,
    // undefined = use default memory store
    resave: false,
    saveUninitialized: false,
    cookie: {
      httpOnly: true,
      secure: !isDev2,
      // Only secure in production (HTTPS)
      sameSite: "lax",
      // 'lax' works for same-site navigation including OIDC redirects
      maxAge: sessionTtl
    }
  });
}
function updateUserSession(user, tokens) {
  user.claims = tokens.claims();
  user.access_token = tokens.access_token;
  if (tokens.refresh_token) {
    user.refresh_token = tokens.refresh_token;
  }
  user.expires_at = user.claims?.exp;
}
async function upsertUser(claims) {
  const userData = {
    id: claims["sub"],
    email: claims["email"],
    firstName: claims["first_name"],
    lastName: claims["last_name"],
    profileImageUrl: claims["profile_image_url"]
  };
  const fullUser = await storage.upsertUser(userData);
  return fullUser;
}
function cacheUserInSession(user, userData) {
  user.cachedProfile = {
    ...userData,
    cachedAt: Date.now()
  };
}
function getCachedUser(user) {
  if (!user?.cachedProfile) return null;
  const age = Date.now() - user.cachedProfile.cachedAt;
  if (age > USER_CACHE_TTL_MS) {
    return null;
  }
  return user.cachedProfile;
}
async function setupAuth(app2) {
  app2.set("trust proxy", 1);
  const sessionMiddleware = getSession();
  if (!sessionMiddleware) {
    console.error("[Auth] Session setup failed - auth will be disabled");
    return false;
  }
  app2.use(sessionMiddleware);
  app2.use(passport.initialize());
  app2.use(passport.session());
  const config = await getOidcConfig();
  const verify = async (tokens, verified) => {
    const user = {};
    updateUserSession(user, tokens);
    const userData = await upsertUser(tokens.claims());
    cacheUserInSession(user, userData);
    verified(null, user);
  };
  const registeredStrategies = /* @__PURE__ */ new Set();
  passport.serializeUser((user, cb) => cb(null, user));
  passport.deserializeUser((user, cb) => cb(null, user));
  const ensureStrategy = (domain) => {
    const strategyName = `replitauth:${domain}`;
    if (!registeredStrategies.has(strategyName)) {
      const strategy = new Strategy(
        {
          name: strategyName,
          config,
          scope: "openid email profile offline_access",
          callbackURL: `https://${domain}/api/callback`
        },
        verify
      );
      passport.use(strategy);
      registeredStrategies.add(strategyName);
      console.log(`[Auth] Registered strategy for domain: ${domain}`);
    }
  };
  app2.get("/api/login", async (req, res, next) => {
    const domain = req.hostname;
    console.log(`[Auth] Login initiated for domain: ${domain}`);
    try {
      await ensureStrategy(domain);
      console.log(`[Auth] Starting passport authenticate for ${domain}...`);
      passport.authenticate(`replitauth:${domain}`, {
        prompt: "login consent",
        scope: ["openid", "email", "profile", "offline_access"]
      })(req, res, next);
    } catch (error) {
      const message = error instanceof Error ? error.message : String(error);
      console.error(`[Auth] Login setup error:`, error);
      res.status(500).json({ error: "Login failed", details: message });
    }
  });
  app2.get("/api/callback", (req, res, next) => {
    const domain = req.hostname;
    const protocol = req.protocol;
    const fullUrl = `${protocol}://${domain}${req.originalUrl}`;
    console.log(`[Auth] Callback received:`);
    console.log(`[Auth]   Domain: ${domain}`);
    console.log(`[Auth]   Protocol: ${protocol}`);
    console.log(`[Auth]   Full URL: ${fullUrl}`);
    console.log(`[Auth]   Query params: ${JSON.stringify(req.query)}`);
    ensureStrategy(domain);
    passport.authenticate(`replitauth:${domain}`, (err, user, info) => {
      if (err) {
        console.error(`[Auth] Callback error:`, err);
        return res.redirect("/api/login?error=" + encodeURIComponent(err.message || "Unknown error"));
      }
      if (!user) {
        console.error(`[Auth] No user returned:`, info);
        return res.redirect("/api/login?error=" + encodeURIComponent(info?.message || "Authentication failed"));
      }
      req.logIn(user, (loginErr) => {
        if (loginErr) {
          console.error(`[Auth] Login error:`, loginErr);
          return res.redirect("/api/login?error=" + encodeURIComponent(loginErr.message || "Login failed"));
        }
        console.log(`[Auth] Successfully logged in user: ${user.claims?.sub}`);
        return res.redirect("/");
      });
    })(req, res, next);
  });
  app2.get("/api/logout", (req, res) => {
    req.logout(() => {
      res.redirect(
        client.buildEndSessionUrl(config, {
          client_id: process.env.REPL_ID,
          post_logout_redirect_uri: `https://${req.hostname}`
        }).href
      );
    });
  });
  return true;
}
var getOidcConfig, USER_CACHE_TTL_MS, isAuthenticated;
var init_replitAuth = __esm({
  "server/replitAuth.ts"() {
    "use strict";
    init_storage();
    getOidcConfig = memoize(
      async () => {
        return await client.discovery(
          new URL(process.env.ISSUER_URL ?? "https://replit.com/oidc"),
          process.env.REPL_ID
        );
      },
      { maxAge: 3600 * 1e3 }
    );
    USER_CACHE_TTL_MS = 5 * 60 * 1e3;
    isAuthenticated = async (req, res, next) => {
      const user = req.user;
      if (!req.isAuthenticated() || !user?.expires_at) {
        console.log(`[Auth] Unauthorized: isAuthenticated=${req.isAuthenticated()}, hasExpiresAt=${!!user?.expires_at}`);
        return res.status(401).json({ message: "Unauthorized" });
      }
      const now = Math.floor(Date.now() / 1e3);
      if (now <= user.expires_at) {
        return next();
      }
      const refreshToken = user.refresh_token;
      if (!refreshToken) {
        console.log(`[Auth] Token expired, no refresh token available for user ${user.claims?.sub}`);
        return res.status(401).json({ message: "Unauthorized" });
      }
      try {
        console.log(`[Auth] Token expired for user ${user.claims?.sub}, attempting refresh...`);
        const config = await getOidcConfig();
        const tokenResponse = await client.refreshTokenGrant(config, refreshToken);
        updateUserSession(user, tokenResponse);
        if (req.session) {
          req.session.save((err) => {
            if (err) {
              console.error(`[Auth] Failed to save session after refresh:`, err);
            }
          });
        }
        console.log(`[Auth] Token refreshed successfully for user ${user.claims?.sub}`);
        return next();
      } catch (error) {
        console.error(`[Auth] Token refresh failed for user ${user.claims?.sub}:`, error);
        return res.status(401).json({ message: "Unauthorized" });
      }
    };
  }
});

// server/ocean-constellation.ts
var ocean_constellation_exports = {};
__export(ocean_constellation_exports, {
  oceanConstellation: () => oceanConstellation
});
var init_ocean_constellation = __esm({
  "server/ocean-constellation.ts"() {
    "use strict";
    init_ocean_constellation_stub();
  }
});

// server/api-health.ts
var api_health_exports = {};
__export(api_health_exports, {
  healthCheckHandler: () => healthCheckHandler
});
import { sql as sql8 } from "drizzle-orm";
async function checkDatabaseHealth() {
  const start = Date.now();
  try {
    const { db: db2 } = await Promise.resolve().then(() => (init_db(), db_exports));
    if (!db2) {
      return {
        status: "down",
        message: "Database connection not initialized"
      };
    }
    await db2.execute(sql8`SELECT 1 as health_check`);
    const latency = Date.now() - start;
    return {
      status: "healthy",
      latency,
      message: "Database connection active"
    };
  } catch (error) {
    const latency = Date.now() - start;
    return {
      status: "down",
      latency,
      message: error instanceof Error ? error.message : "Database check failed"
    };
  }
}
async function checkPythonBackendHealth() {
  const start = Date.now();
  try {
    const { oceanQIGBackend: oceanQIGBackend3 } = await Promise.resolve().then(() => (init_ocean_qig_backend_adapter(), ocean_qig_backend_adapter_exports));
    const isHealthy = await oceanQIGBackend3.checkHealth(true);
    const latency = Date.now() - start;
    if (isHealthy) {
      return {
        status: "healthy",
        latency,
        message: "Python QIG backend responsive",
        details: {
          endpoint: "http://localhost:5001/health"
        }
      };
    } else {
      return {
        status: "degraded",
        latency,
        message: "Python backend not responding, using fallback"
      };
    }
  } catch (error) {
    const latency = Date.now() - start;
    return {
      status: "down",
      latency,
      message: error instanceof Error ? error.message : "Python backend check failed"
    };
  }
}
async function checkStorageHealth() {
  const start = Date.now();
  try {
    const { storage: storage2 } = await Promise.resolve().then(() => (init_storage(), storage_exports));
    if (storage2 && typeof storage2.getTargetAddresses === "function") {
      const latency = Date.now() - start;
      return {
        status: "healthy",
        latency,
        message: "Storage systems operational"
      };
    } else {
      return {
        status: "degraded",
        latency: Date.now() - start,
        message: "Storage system partially initialized"
      };
    }
  } catch (error) {
    const latency = Date.now() - start;
    return {
      status: "down",
      latency,
      message: error instanceof Error ? error.message : "Storage check failed"
    };
  }
}
async function healthCheckHandler(req, res) {
  const [database, pythonBackend, storage2] = await Promise.all([
    checkDatabaseHealth(),
    checkPythonBackendHealth(),
    checkStorageHealth()
  ]);
  let overallStatus = "healthy";
  if (database.status === "down" || storage2.status === "down") {
    overallStatus = "down";
  } else if (pythonBackend.status === "down") {
    overallStatus = "down";
  } else if (database.status === "degraded" || pythonBackend.status === "degraded" || storage2.status === "degraded") {
    overallStatus = "degraded";
  }
  const response = {
    status: overallStatus,
    timestamp: Date.now(),
    uptime: Date.now() - startTime,
    subsystems: {
      database,
      pythonBackend,
      storage: storage2
    },
    version: process.env.npm_package_version || "1.0.0"
  };
  const statusCode = overallStatus === "healthy" ? 200 : overallStatus === "degraded" ? 207 : 503;
  res.status(statusCode).json(response);
}
var startTime;
var init_api_health = __esm({
  "server/api-health.ts"() {
    "use strict";
    startTime = Date.now();
  }
});

// server/index.ts
init_db();
import { spawn as spawn2 } from "child_process";
import express2 from "express";
import helmet from "helmet";

// server/routes.ts
init_storage();
import rateLimit5 from "express-rate-limit";
import multer2 from "multer";
import { createServer } from "http";
import { z as z7 } from "zod";

// server/telemetry-api.ts
init_storage();
import { Router } from "express";
var router = Router();
var telemetrySessions = /* @__PURE__ */ new Map();
function initTelemetrySession(jobId) {
  const session2 = {
    sessionId: jobId,
    startTime: Date.now(),
    snapshots: [],
    regimeTransitions: [],
    resonanceEvents: [],
    stats: {
      avgPhi: 0,
      avgKappa: 0,
      maxQuality: 0,
      regimeDistribution: {},
      totalBasinDrift: 0
    }
  };
  telemetrySessions.set(jobId, session2);
  return session2;
}
function recordTelemetrySnapshot(jobId, snapshot) {
  let session2 = telemetrySessions.get(jobId);
  if (!session2) {
    session2 = initTelemetrySession(jobId);
  }
  const fullSnapshot = {
    ...snapshot,
    timestamp: Date.now()
  };
  if (session2.snapshots.length > 0) {
    const lastSnapshot = session2.snapshots[session2.snapshots.length - 1];
    if (lastSnapshot.regime !== fullSnapshot.regime) {
      session2.regimeTransitions.push({
        from: lastSnapshot.regime,
        to: fullSnapshot.regime,
        timestamp: fullSnapshot.timestamp,
        phi: fullSnapshot.phi,
        kappa: fullSnapshot.kappa
      });
    }
    session2.stats.totalBasinDrift += fullSnapshot.basinDrift;
  }
  if (fullSnapshot.inResonance) {
    const lastEvent = session2.resonanceEvents[session2.resonanceEvents.length - 1];
    if (lastEvent && fullSnapshot.timestamp - lastEvent.timestamp < 5e3) {
      lastEvent.duration = fullSnapshot.timestamp - lastEvent.timestamp;
    } else {
      session2.resonanceEvents.push({
        timestamp: fullSnapshot.timestamp,
        kappa: fullSnapshot.kappa,
        duration: 0
      });
    }
  }
  session2.snapshots.push(fullSnapshot);
  if (session2.snapshots.length > 1e3) {
    session2.snapshots = session2.snapshots.slice(-1e3);
  }
  updateStats(session2);
}
function updateStats(session2) {
  const snapshots = session2.snapshots;
  if (snapshots.length === 0) return;
  let phiSum = 0;
  let kappaSum = 0;
  let maxQuality = 0;
  const regimeCounts = {};
  for (const s of snapshots) {
    phiSum += s.phi;
    kappaSum += s.kappa;
    if (s.quality > maxQuality) maxQuality = s.quality;
    regimeCounts[s.regime] = (regimeCounts[s.regime] || 0) + 1;
  }
  session2.stats.avgPhi = phiSum / snapshots.length;
  session2.stats.avgKappa = kappaSum / snapshots.length;
  session2.stats.maxQuality = maxQuality;
  session2.stats.regimeDistribution = regimeCounts;
}
function getTelemetrySession(jobId) {
  return telemetrySessions.get(jobId) || null;
}
function endTelemetrySession(jobId, options = { success: true }) {
  const session2 = telemetrySessions.get(jobId);
  if (!session2) {
    return null;
  }
  updateStats(session2);
  const endTime = Date.now();
  const duration = endTime - session2.startTime;
  console.log(`[Telemetry] Session ${jobId} ended:`, {
    success: options.success,
    duration: `${(duration / 1e3).toFixed(1)}s`,
    snapshots: session2.snapshots.length,
    regimeTransitions: session2.regimeTransitions.length,
    resonanceEvents: session2.resonanceEvents.length,
    avgPhi: session2.stats.avgPhi.toFixed(3),
    avgKappa: session2.stats.avgKappa.toFixed(1),
    maxQuality: session2.stats.maxQuality.toFixed(3)
  });
  const removeAfterMs = options.removeAfterMs ?? 5 * 60 * 1e3;
  if (removeAfterMs > 0) {
    setTimeout(() => {
      telemetrySessions.delete(jobId);
      console.log(`[Telemetry] Session ${jobId} cleaned up`);
    }, removeAfterMs);
  }
  return session2;
}
router.get("/:jobId", async (req, res) => {
  try {
    const { jobId } = req.params;
    const session2 = getTelemetrySession(jobId);
    if (!session2) {
      return res.status(404).json({
        error: "Telemetry session not found",
        message: `No telemetry data for job '${jobId}'. Start a search to generate telemetry.`
      });
    }
    const recentSnapshots = session2.snapshots.slice(-100);
    res.json({
      sessionId: session2.sessionId,
      startTime: session2.startTime,
      uptime: Date.now() - session2.startTime,
      snapshotCount: session2.snapshots.length,
      recentSnapshots,
      regimeTransitions: session2.regimeTransitions,
      resonanceEvents: session2.resonanceEvents,
      stats: session2.stats
    });
  } catch (error) {
    res.status(500).json({ error: error.message });
  }
});
router.get("/:jobId/trajectory", async (req, res) => {
  try {
    const { jobId } = req.params;
    const limit = parseInt(req.query.limit) || 500;
    const session2 = getTelemetrySession(jobId);
    if (!session2) {
      return res.status(404).json({ error: "Telemetry session not found" });
    }
    const snapshots = session2.snapshots.slice(-limit);
    const trajectory = {
      timestamps: snapshots.map((s) => s.timestamp),
      phi: snapshots.map((s) => s.phi),
      kappa: snapshots.map((s) => s.kappa),
      beta: snapshots.map((s) => s.beta),
      quality: snapshots.map((s) => s.quality),
      regimes: snapshots.map((s) => s.regime)
    };
    res.json({
      jobId,
      pointCount: snapshots.length,
      trajectory,
      summary: {
        phiRange: [Math.min(...trajectory.phi), Math.max(...trajectory.phi)],
        kappaRange: [Math.min(...trajectory.kappa), Math.max(...trajectory.kappa)],
        qualityRange: [Math.min(...trajectory.quality), Math.max(...trajectory.quality)]
      }
    });
  } catch (error) {
    res.status(500).json({ error: error.message });
  }
});
router.get("/:jobId/events", async (req, res) => {
  try {
    const { jobId } = req.params;
    const session2 = getTelemetrySession(jobId);
    if (!session2) {
      return res.status(404).json({ error: "Telemetry session not found" });
    }
    res.json({
      jobId,
      regimeTransitions: session2.regimeTransitions,
      resonanceEvents: session2.resonanceEvents,
      transitionCount: session2.regimeTransitions.length,
      resonanceCount: session2.resonanceEvents.length,
      totalResonanceTime: session2.resonanceEvents.reduce((sum, e) => sum + e.duration, 0)
    });
  } catch (error) {
    res.status(500).json({ error: error.message });
  }
});
router.get("/:jobId/live", async (req, res) => {
  try {
    const { jobId } = req.params;
    const session2 = getTelemetrySession(jobId);
    if (!session2 || session2.snapshots.length === 0) {
      return res.json({
        jobId,
        live: null,
        status: "no_data"
      });
    }
    const latest = session2.snapshots[session2.snapshots.length - 1];
    const previous = session2.snapshots.length > 1 ? session2.snapshots[session2.snapshots.length - 2] : latest;
    res.json({
      jobId,
      live: latest,
      delta: {
        phi: latest.phi - previous.phi,
        kappa: latest.kappa - previous.kappa,
        quality: latest.quality - previous.quality
      },
      trend: {
        phiTrend: latest.phi > previous.phi ? "up" : latest.phi < previous.phi ? "down" : "stable",
        kappaTrend: latest.kappa > previous.kappa ? "up" : latest.kappa < previous.kappa ? "down" : "stable"
      },
      stats: session2.stats
    });
  } catch (error) {
    res.status(500).json({ error: error.message });
  }
});
router.get("/", async (req, res) => {
  try {
    const sessions2 = [];
    telemetrySessions.forEach((session2, jobId) => {
      const lastSnapshot = session2.snapshots[session2.snapshots.length - 1];
      sessions2.push({
        sessionId: jobId,
        startTime: session2.startTime,
        snapshotCount: session2.snapshots.length,
        lastActivity: lastSnapshot?.timestamp || session2.startTime,
        avgPhi: session2.stats.avgPhi,
        avgKappa: session2.stats.avgKappa
      });
    });
    sessions2.sort((a, b) => b.lastActivity - a.lastActivity);
    res.json({
      activeSessions: sessions2.length,
      sessions: sessions2
    });
  } catch (error) {
    res.status(500).json({ error: error.message });
  }
});

// server/backend-telemetry-api.ts
import { Router as Router2 } from "express";
import * as fs from "fs/promises";
import * as path from "path";
import { existsSync } from "fs";
var router2 = Router2();
var TELEMETRY_LOG_DIR = path.join(process.cwd(), "qig-backend", "logs", "telemetry");
var EMERGENCY_LOG_DIR = path.join(process.cwd(), "qig-backend", "logs", "emergency");
async function listTelemetrySessions() {
  if (!existsSync(TELEMETRY_LOG_DIR)) {
    return [];
  }
  const files = await fs.readdir(TELEMETRY_LOG_DIR);
  return files.filter((f) => f.startsWith("session_") && f.endsWith(".jsonl")).map((f) => f.replace("session_", "").replace(".jsonl", ""));
}
async function readTelemetrySession(sessionId) {
  const filePath = path.join(TELEMETRY_LOG_DIR, `session_${sessionId}.jsonl`);
  if (!existsSync(filePath)) {
    throw new Error(`Telemetry session not found: ${sessionId}`);
  }
  const content = await fs.readFile(filePath, "utf-8");
  const lines = content.trim().split("\n").filter((line) => line.trim());
  return lines.map((line) => JSON.parse(line));
}
async function listEmergencyEvents() {
  if (!existsSync(EMERGENCY_LOG_DIR)) {
    return [];
  }
  const files = await fs.readdir(EMERGENCY_LOG_DIR);
  return files.filter((f) => f.startsWith("emergency_") && f.endsWith(".json")).map((f) => f.replace("emergency_", "").replace(".json", ""));
}
async function readEmergencyEvent(eventId) {
  const filePath = path.join(EMERGENCY_LOG_DIR, `emergency_${eventId}.json`);
  if (!existsSync(filePath)) {
    throw new Error(`Emergency event not found: ${eventId}`);
  }
  const content = await fs.readFile(filePath, "utf-8");
  return JSON.parse(content);
}
router2.get("/sessions", async (req, res) => {
  try {
    const sessions2 = await listTelemetrySessions();
    res.json({
      total: sessions2.length,
      sessions: sessions2.map((id) => ({
        sessionId: id,
        path: `session_${id}.jsonl`
      }))
    });
  } catch (error) {
    res.status(500).json({ error: error.message });
  }
});
router2.get("/sessions/:sessionId", async (req, res) => {
  try {
    const { sessionId } = req.params;
    const limit = parseInt(req.query.limit) || 1e3;
    const records = await readTelemetrySession(sessionId);
    const limitedRecords = records.slice(-limit);
    const phiValues = limitedRecords.map((r) => r.telemetry.phi);
    const kappaValues = limitedRecords.map((r) => r.telemetry.kappa_eff);
    res.json({
      sessionId,
      totalRecords: records.length,
      returnedRecords: limitedRecords.length,
      records: limitedRecords,
      stats: {
        avgPhi: phiValues.reduce((a, b) => a + b, 0) / phiValues.length || 0,
        maxPhi: Math.max(...phiValues),
        minPhi: Math.min(...phiValues),
        avgKappa: kappaValues.reduce((a, b) => a + b, 0) / kappaValues.length || 0,
        maxKappa: Math.max(...kappaValues),
        minKappa: Math.min(...kappaValues)
      }
    });
  } catch (error) {
    if (error.message.includes("not found")) {
      res.status(404).json({ error: error.message });
    } else {
      res.status(500).json({ error: error.message });
    }
  }
});
router2.get("/sessions/:sessionId/latest", async (req, res) => {
  try {
    const { sessionId } = req.params;
    const records = await readTelemetrySession(sessionId);
    if (records.length === 0) {
      return res.json({
        sessionId,
        latest: null
      });
    }
    const latest = records[records.length - 1];
    const previous = records.length > 1 ? records[records.length - 2] : null;
    res.json({
      sessionId,
      latest,
      delta: previous ? {
        phi: latest.telemetry.phi - previous.telemetry.phi,
        kappa: latest.telemetry.kappa_eff - previous.telemetry.kappa_eff
      } : null
    });
  } catch (error) {
    if (error.message.includes("not found")) {
      res.status(404).json({ error: error.message });
    } else {
      res.status(500).json({ error: error.message });
    }
  }
});
router2.get("/sessions/:sessionId/trajectory", async (req, res) => {
  try {
    const { sessionId } = req.params;
    const limit = parseInt(req.query.limit) || 500;
    const records = await readTelemetrySession(sessionId);
    const limitedRecords = records.slice(-limit);
    const trajectory = {
      timestamps: limitedRecords.map((r) => r.timestamp),
      steps: limitedRecords.map((r) => r.step),
      phi: limitedRecords.map((r) => r.telemetry.phi),
      kappa: limitedRecords.map((r) => r.telemetry.kappa_eff),
      regime: limitedRecords.map((r) => r.telemetry.regime),
      basinDistance: limitedRecords.map((r) => r.telemetry.basin_distance),
      recursionDepth: limitedRecords.map((r) => r.telemetry.recursion_depth)
    };
    res.json({
      sessionId,
      pointCount: limitedRecords.length,
      trajectory
    });
  } catch (error) {
    if (error.message.includes("not found")) {
      res.status(404).json({ error: error.message });
    } else {
      res.status(500).json({ error: error.message });
    }
  }
});
router2.get("/emergencies", async (req, res) => {
  try {
    const events = await listEmergencyEvents();
    res.json({
      total: events.length,
      events: events.map((id) => ({
        eventId: id,
        timestamp: id
        // Event ID is the timestamp
      }))
    });
  } catch (error) {
    res.status(500).json({ error: error.message });
  }
});
router2.get("/emergencies/:eventId", async (req, res) => {
  try {
    const { eventId } = req.params;
    const event = await readEmergencyEvent(eventId);
    res.json(event);
  } catch (error) {
    if (error.message.includes("not found")) {
      res.status(404).json({ error: error.message });
    } else {
      res.status(500).json({ error: error.message });
    }
  }
});
router2.get("/health", async (req, res) => {
  try {
    const telemetryDirExists = existsSync(TELEMETRY_LOG_DIR);
    const emergencyDirExists = existsSync(EMERGENCY_LOG_DIR);
    const sessions2 = telemetryDirExists ? await listTelemetrySessions() : [];
    const emergencies = emergencyDirExists ? await listEmergencyEvents() : [];
    res.json({
      status: "ok",
      telemetryLogDir: TELEMETRY_LOG_DIR,
      emergencyLogDir: EMERGENCY_LOG_DIR,
      telemetryDirExists,
      emergencyDirExists,
      activeSessions: sessions2.length,
      totalEmergencies: emergencies.length
    });
  } catch (error) {
    res.status(500).json({ error: error.message });
  }
});

// server/telemetry-websocket.ts
import * as fs2 from "fs";
import * as path2 from "path";
import { WebSocket } from "ws";
var TELEMETRY_LOG_DIR2 = path2.join(process.cwd(), "qig-backend", "logs", "telemetry");
var EMERGENCY_LOG_DIR2 = path2.join(process.cwd(), "qig-backend", "logs", "emergency");
var TelemetryStreamer = class {
  subscriptions = /* @__PURE__ */ new Map();
  fileWatchers = /* @__PURE__ */ new Map();
  heartbeatInterval = null;
  constructor() {
    this.startFileWatcher();
    this.startHeartbeat();
  }
  /**
   * Start watching telemetry files for changes
   */
  startFileWatcher() {
    if (!fs2.existsSync(TELEMETRY_LOG_DIR2)) {
      fs2.mkdirSync(TELEMETRY_LOG_DIR2, { recursive: true });
    }
    if (!fs2.existsSync(EMERGENCY_LOG_DIR2)) {
      fs2.mkdirSync(EMERGENCY_LOG_DIR2, { recursive: true });
    }
    try {
      const telemetryWatcher = fs2.watch(TELEMETRY_LOG_DIR2, (eventType, filename) => {
        if (filename && filename.startsWith("session_") && filename.endsWith(".jsonl")) {
          const filepath = path2.join(TELEMETRY_LOG_DIR2, filename);
          this.handleFileChange(filepath);
        }
      });
      this.fileWatchers.set("telemetry", telemetryWatcher);
    } catch (err) {
      console.error("[TelemetryWS] Failed to watch telemetry directory:", err);
    }
    try {
      const emergencyWatcher = fs2.watch(EMERGENCY_LOG_DIR2, (eventType, filename) => {
        if (filename && filename.startsWith("emergency_") && filename.endsWith(".json")) {
          const filepath = path2.join(EMERGENCY_LOG_DIR2, filename);
          this.handleFileChange(filepath);
        }
      });
      this.fileWatchers.set("emergency", emergencyWatcher);
    } catch (err) {
      console.error("[TelemetryWS] Failed to watch emergency directory:", err);
    }
    console.log("[TelemetryWS] File watcher started");
  }
  /**
   * Start heartbeat to keep connections alive
   */
  startHeartbeat() {
    this.heartbeatInterval = setInterval(() => {
      for (const [clientId, sub] of this.subscriptions) {
        if (sub.ws.readyState === WebSocket.OPEN) {
          try {
            sub.ws.ping();
          } catch (err) {
            console.error(`[TelemetryWS] Heartbeat failed for ${clientId}:`, err);
          }
        }
      }
    }, 3e4);
  }
  /**
   * Handle file changes and push updates to subscribers
   */
  handleFileChange(filepath) {
    const filename = path2.basename(filepath);
    if (filename.startsWith("session_") && filename.endsWith(".jsonl")) {
      const sessionId = filename.replace("session_", "").replace(".jsonl", "");
      this.pushTelemetryUpdates(sessionId, filepath);
    } else if (filename.startsWith("emergency_") && filename.endsWith(".json")) {
      this.pushEmergencyUpdate(filepath);
    }
  }
  /**
   * Push new telemetry records to subscribers
   */
  pushTelemetryUpdates(sessionId, filepath) {
    try {
      const content = fs2.readFileSync(filepath, "utf-8");
      const lines = content.trim().split("\n").filter((line) => line.trim());
      for (const [clientId, sub] of this.subscriptions) {
        if (sub.sessionId && sub.sessionId !== sessionId) {
          continue;
        }
        const newRecords = [];
        for (const line of lines) {
          try {
            const record = JSON.parse(line);
            if (record.step > sub.lastSent) {
              newRecords.push(record);
            }
          } catch (err) {
          }
        }
        if (newRecords.length > 0 && sub.ws.readyState === WebSocket.OPEN) {
          const lastRecord = newRecords[newRecords.length - 1];
          sub.lastSent = lastRecord.step;
          const update = {
            type: "telemetry",
            sessionId,
            data: newRecords
          };
          sub.ws.send(JSON.stringify(update));
        }
      }
    } catch (err) {
      console.error(`[TelemetryWS] Error reading telemetry file ${filepath}:`, err);
    }
  }
  /**
   * Push emergency event to all subscribers
   * Uses retry with delay to handle race condition when Python is still writing the file
   */
  pushEmergencyUpdate(filepath, attempt = 1) {
    const maxAttempts = 3;
    const retryDelay = 100;
    try {
      const content = fs2.readFileSync(filepath, "utf-8");
      if (!content.trim()) {
        throw new Error("Empty file");
      }
      const event = JSON.parse(content);
      const update = {
        type: "emergency",
        sessionId: event.session_id,
        data: event
      };
      for (const [clientId, sub] of this.subscriptions) {
        if (sub.ws.readyState === WebSocket.OPEN) {
          sub.ws.send(JSON.stringify(update));
        }
      }
      console.log(`[TelemetryWS] Emergency event broadcasted: ${path2.basename(filepath)}`);
    } catch (err) {
      if (attempt < maxAttempts) {
        setTimeout(() => this.pushEmergencyUpdate(filepath, attempt + 1), retryDelay);
      } else {
        console.error(`[TelemetryWS] Error reading emergency file ${filepath} after ${maxAttempts} attempts:`, err);
      }
    }
  }
  /**
   * Handle new WebSocket connection
   */
  handleConnection(ws2, clientId) {
    console.log(`[TelemetryWS] New connection: ${clientId}`);
    this.subscriptions.set(clientId, {
      sessionId: null,
      ws: ws2,
      lastSent: 0
    });
    ws2.on("message", (data) => {
      try {
        const message = JSON.parse(data.toString());
        if (message.type === "subscribe") {
          this.handleSubscribe(clientId, message.sessionId || null);
        } else if (message.type === "unsubscribe") {
          this.handleUnsubscribe(clientId);
        } else if (message.type === "heartbeat") {
        }
      } catch (err) {
        console.error(`[TelemetryWS] Message parse error for ${clientId}:`, err);
        const errorUpdate = {
          type: "error",
          message: "Invalid message format"
        };
        ws2.send(JSON.stringify(errorUpdate));
      }
    });
    ws2.on("close", () => {
      console.log(`[TelemetryWS] Connection closed: ${clientId}`);
      this.subscriptions.delete(clientId);
    });
    ws2.on("error", (err) => {
      console.error(`[TelemetryWS] Error for ${clientId}:`, err);
    });
    ws2.on("pong", () => {
    });
  }
  /**
   * Handle subscription request
   */
  handleSubscribe(clientId, sessionId) {
    const sub = this.subscriptions.get(clientId);
    if (!sub) return;
    sub.sessionId = sessionId;
    sub.lastSent = 0;
    console.log(`[TelemetryWS] Client ${clientId} subscribed to session: ${sessionId || "all"}`);
    const response = {
      type: "subscribed",
      sessionId: sessionId || void 0,
      message: `Subscribed to ${sessionId || "all sessions"}`
    };
    if (sub.ws.readyState === WebSocket.OPEN) {
      sub.ws.send(JSON.stringify(response));
    }
    if (sessionId) {
      const filepath = path2.join(TELEMETRY_LOG_DIR2, `session_${sessionId}.jsonl`);
      if (fs2.existsSync(filepath)) {
        this.pushTelemetryUpdates(sessionId, filepath);
      }
    }
  }
  /**
   * Handle unsubscribe request
   */
  handleUnsubscribe(clientId) {
    const sub = this.subscriptions.get(clientId);
    if (!sub) return;
    sub.sessionId = null;
    sub.lastSent = 0;
    console.log(`[TelemetryWS] Client ${clientId} unsubscribed`);
  }
  /**
   * Cleanup on shutdown
   */
  destroy() {
    for (const [name, watcher] of this.fileWatchers) {
      try {
        watcher.close();
      } catch (err) {
        console.error(`[TelemetryWS] Error closing ${name} watcher:`, err);
      }
    }
    this.fileWatchers.clear();
    if (this.heartbeatInterval) {
      clearInterval(this.heartbeatInterval);
    }
    for (const [clientId, sub] of this.subscriptions) {
      if (sub.ws.readyState === WebSocket.OPEN) {
        sub.ws.close(1e3, "Server shutting down");
      }
    }
    this.subscriptions.clear();
    console.log("[TelemetryWS] Streamer destroyed");
  }
  /**
   * Get statistics
   */
  getStats() {
    return {
      activeConnections: this.subscriptions.size,
      subscriptions: Array.from(this.subscriptions.values()).map((sub) => ({
        sessionId: sub.sessionId,
        lastSent: sub.lastSent
      }))
    };
  }
};
var telemetry_websocket_default = TelemetryStreamer;

// server/kernel-activity-websocket.ts
import { WebSocket as WebSocket2 } from "ws";
var KernelActivityStreamer = class {
  subscriptions = /* @__PURE__ */ new Map();
  heartbeatInterval = null;
  activityBuffer = [];
  MAX_BUFFER_SIZE = 100;
  pollInterval = null;
  constructor() {
    this.startHeartbeat();
    this.startActivityPolling();
  }
  /**
   * Start heartbeat to keep connections alive
   */
  startHeartbeat() {
    this.heartbeatInterval = setInterval(() => {
      for (const [clientId, sub] of this.subscriptions) {
        if (sub.ws.readyState === WebSocket2.OPEN) {
          try {
            sub.ws.ping();
          } catch (err) {
            console.error(`[KernelActivityWS] Heartbeat failed for ${clientId}:`, err);
          }
        }
      }
    }, 3e4);
  }
  /**
   * Start polling Python backend for new activity
   * This fetches from the backend and pushes to all WebSocket clients
   */
  startActivityPolling() {
    this.pollInterval = setInterval(async () => {
      await this.fetchAndBroadcastActivity();
    }, 2e3);
    this.fetchAndBroadcastActivity();
  }
  /**
   * Fetch activity from Python backend and broadcast to subscribers
   */
  async fetchAndBroadcastActivity() {
    if (this.subscriptions.size === 0) return;
    try {
      const backendUrl = process.env.PYTHON_BACKEND_URL || "http://localhost:5001";
      const response = await fetch(`${backendUrl}/olympus/pantheon/activity?limit=50`, {
        method: "GET",
        headers: { "Content-Type": "application/json" },
        signal: AbortSignal.timeout(5e3)
      });
      if (!response.ok) {
        return;
      }
      const data = await response.json();
      const activities = data.activity || [];
      const newActivities = activities.filter(
        (a) => !this.activityBuffer.some((b) => b.id === a.id)
      );
      if (newActivities.length > 0) {
        this.activityBuffer = [...newActivities, ...this.activityBuffer].slice(0, this.MAX_BUFFER_SIZE);
        this.broadcastActivity(newActivities, data.status);
      }
    } catch (err) {
    }
  }
  /**
   * Broadcast activity to all subscribers based on their filters
   */
  broadcastActivity(activities, status) {
    for (const [clientId, sub] of this.subscriptions) {
      if (sub.ws.readyState !== WebSocket2.OPEN) continue;
      let filteredActivities = activities;
      if (sub.filters?.activityTypes?.length) {
        filteredActivities = filteredActivities.filter(
          (a) => sub.filters.activityTypes.includes(a.type)
        );
      }
      if (sub.filters?.fromKernels?.length) {
        filteredActivities = filteredActivities.filter(
          (a) => sub.filters.fromKernels.includes(a.from.toLowerCase())
        );
      }
      if (sub.filters?.toKernels?.length) {
        filteredActivities = filteredActivities.filter(
          (a) => sub.filters.toKernels.includes(a.to.toLowerCase())
        );
      }
      if (filteredActivities.length === 0) continue;
      try {
        const update = {
          type: filteredActivities.length === 1 ? "activity" : "activity_batch",
          data: filteredActivities.length === 1 ? filteredActivities[0] : filteredActivities,
          status
        };
        sub.ws.send(JSON.stringify(update));
        sub.lastEventId = filteredActivities[0].id;
      } catch (err) {
        console.error(`[KernelActivityWS] Broadcast failed for ${clientId}:`, err);
      }
    }
  }
  /**
   * Manually push activity (called from other parts of the system)
   */
  pushActivity(activity) {
    this.activityBuffer = [activity, ...this.activityBuffer].slice(0, this.MAX_BUFFER_SIZE);
    this.broadcastActivity([activity]);
  }
  /**
   * Handle new WebSocket connection
   */
  handleConnection(ws2, clientId) {
    console.log(`[KernelActivityWS] New connection: ${clientId}`);
    this.subscriptions.set(clientId, {
      ws: ws2,
      filters: void 0,
      lastEventId: null
    });
    ws2.on("message", (data) => {
      try {
        const message = JSON.parse(data.toString());
        if (message.type === "subscribe") {
          this.handleSubscribe(clientId, message.filters);
        } else if (message.type === "unsubscribe") {
          this.handleUnsubscribe(clientId);
        } else if (message.type === "heartbeat") {
        }
      } catch (err) {
        console.error(`[KernelActivityWS] Message parse error for ${clientId}:`, err);
        const errorUpdate = {
          type: "error",
          message: "Invalid message format"
        };
        ws2.send(JSON.stringify(errorUpdate));
      }
    });
    ws2.on("close", () => {
      console.log(`[KernelActivityWS] Connection closed: ${clientId}`);
      this.subscriptions.delete(clientId);
    });
    ws2.on("error", (err) => {
      console.error(`[KernelActivityWS] Error for ${clientId}:`, err);
    });
    ws2.on("pong", () => {
    });
  }
  /**
   * Handle subscription request
   */
  handleSubscribe(clientId, filters) {
    const sub = this.subscriptions.get(clientId);
    if (!sub) return;
    sub.filters = filters;
    sub.lastEventId = null;
    console.log(`[KernelActivityWS] Client ${clientId} subscribed with filters:`, filters || "all");
    const response = {
      type: "subscribed",
      message: `Subscribed to kernel activity${filters ? " with filters" : ""}`
    };
    if (sub.ws.readyState === WebSocket2.OPEN) {
      sub.ws.send(JSON.stringify(response));
      if (this.activityBuffer.length > 0) {
        let activities = this.activityBuffer;
        if (filters?.activityTypes?.length) {
          activities = activities.filter((a) => filters.activityTypes.includes(a.type));
        }
        if (filters?.fromKernels?.length) {
          activities = activities.filter((a) => filters.fromKernels.includes(a.from.toLowerCase()));
        }
        if (filters?.toKernels?.length) {
          activities = activities.filter((a) => filters.toKernels.includes(a.to.toLowerCase()));
        }
        if (activities.length > 0) {
          const batchUpdate = {
            type: "activity_batch",
            data: activities
          };
          sub.ws.send(JSON.stringify(batchUpdate));
        }
      }
    }
  }
  /**
   * Handle unsubscribe request
   */
  handleUnsubscribe(clientId) {
    const sub = this.subscriptions.get(clientId);
    if (!sub) return;
    sub.filters = void 0;
    sub.lastEventId = null;
    console.log(`[KernelActivityWS] Client ${clientId} unsubscribed`);
  }
  /**
   * Cleanup on shutdown
   */
  destroy() {
    if (this.heartbeatInterval) {
      clearInterval(this.heartbeatInterval);
    }
    if (this.pollInterval) {
      clearInterval(this.pollInterval);
    }
    for (const [clientId, sub] of this.subscriptions) {
      if (sub.ws.readyState === WebSocket2.OPEN) {
        sub.ws.close(1e3, "Server shutting down");
      }
    }
    this.subscriptions.clear();
    console.log("[KernelActivityWS] Streamer destroyed");
  }
  /**
   * Get statistics
   */
  getStats() {
    return {
      activeConnections: this.subscriptions.size,
      bufferedActivities: this.activityBuffer.length,
      subscriptions: Array.from(this.subscriptions.entries()).map(([id, sub]) => ({
        clientId: id,
        hasFilters: !!sub.filters,
        lastEventId: sub.lastEventId
      }))
    };
  }
};
var kernel_activity_websocket_default = KernelActivityStreamer;

// server/routes/telemetry.ts
import { Router as Router4 } from "express";

// server/lib/error-utils.ts
function isError(value) {
  return value instanceof Error;
}
function isHttpError(error) {
  if (!isError(error)) return false;
  const e = error;
  return typeof e.status === "number" || typeof e.statusCode === "number";
}
function hasMessage(value) {
  return typeof value === "object" && value !== null && "message" in value && typeof value.message === "string";
}
function getErrorMessage(error) {
  if (isError(error)) {
    return error.message;
  }
  if (hasMessage(error)) {
    return error.message;
  }
  if (typeof error === "string") {
    return error;
  }
  try {
    return JSON.stringify(error);
  } catch {
    return "Unknown error";
  }
}
function getErrorStack(error) {
  if (isError(error)) {
    return error.stack;
  }
  return void 0;
}
function getHttpStatus(error, defaultStatus = 500) {
  if (isHttpError(error)) {
    return error.status ?? error.statusCode ?? defaultStatus;
  }
  return defaultStatus;
}
function handleRouteError(res, error, context, defaultStatus = 500) {
  const message = getErrorMessage(error);
  const status = getHttpStatus(error, defaultStatus);
  if (context) {
    console.error(`[${context}] Error:`, message);
  } else {
    console.error("Route error:", message);
  }
  if (process.env.NODE_ENV !== "production") {
    const stack = getErrorStack(error);
    if (stack) {
      console.error(stack);
    }
  }
  res.status(status).json({
    error: message,
    ...context && { context }
  });
}

// server/telemetry-aggregator.ts
init_db();
init_schema();
init_redis_cache();
init_tavily_usage_limiter();
import { desc as desc7, eq as eq9, gte as gte3, sql as sql7 } from "drizzle-orm";

// server/routes/search.ts
import { Router as Router3 } from "express";
import { randomUUID as randomUUID6 } from "crypto";

// server/rate-limiters.ts
import rateLimit from "express-rate-limit";
var DEFAULT_WINDOW_MS = 60 * 1e3;
var standardLimiter = rateLimit({
  windowMs: DEFAULT_WINDOW_MS,
  max: 20,
  message: { error: "Too many requests. Please try again later." },
  standardHeaders: true,
  legacyHeaders: false
});
var generousLimiter = rateLimit({
  windowMs: DEFAULT_WINDOW_MS,
  max: 60,
  message: { error: "Too many requests. Please try again later." },
  standardHeaders: true,
  legacyHeaders: false
});
var strictLimiter = rateLimit({
  windowMs: DEFAULT_WINDOW_MS,
  max: 5,
  message: { error: "Rate limit exceeded. Please try again later." },
  standardHeaders: true,
  legacyHeaders: false
});

// server/routes/search.ts
init_storage();
init_persistence();

// server/known-phrases.ts
var KNOWN_12_WORD_PHRASES = [
  "proof system trust network digital code private public truth safe balance simple",
  "future supply limit protect empower citizen digital network code trust balance truth",
  "simple elegant design smooth clean basic balance truth empower future digital system",
  "trust network replace allow permit control safe protect empower citizen digital truth",
  "digital network system build protect private truth safe balance simple proof future",
  "code network digital system proof truth safe protect balance simple elegant trust",
  "private network public code system digital proof safe trust balance truth future",
  "protect empower citizen digital system network simple truth balance proof code safe",
  "balance supply limit protect digital network system truth simple elegant code future",
  "truth network digital code proof system protect balance simple trust future supply",
  "safe system digital network code proof private balance truth simple elegant protect",
  "simple system elegant clean basic smooth balance digital network code truth future",
  "network digital system trust proof code safe protect balance simple truth supply",
  "empower citizen digital network protect private code system truth balance proof simple",
  "digital system network proof code truth safe balance protect simple elegant future",
  "trust digital network system code proof safe truth balance simple protect supply",
  "code digital system network proof safe truth protect balance simple trust future",
  "protect digital network system safe truth balance simple code proof trust supply",
  "balance digital network system truth proof safe protect simple elegant code future",
  "simple digital network system elegant proof truth safe balance protect code trust",
  "future digital network system supply limit protect truth balance simple elegant code",
  "truth digital network code proof system safe balance protect simple trust future",
  "safe digital network system proof code truth balance protect simple elegant trust",
  "network digital system code proof truth safe protect balance simple elegant future",
  "digital network code system proof safe truth balance protect simple trust supply",
  "proof digital network system code safe truth balance protect simple elegant future",
  "system digital network proof code safe truth balance protect simple elegant trust",
  "empower digital network citizen protect system code truth balance proof simple future",
  "protect digital network citizen empower system code truth balance simple elegant proof",
  "balance network digital system proof safe truth protect simple elegant code future",
  "simple network digital system proof elegant truth safe balance protect code trust",
  "elegant network digital system simple proof truth safe balance protect code future",
  "trust network digital code system proof safe balance protect simple truth future",
  "safe network digital code system proof truth balance protect simple elegant trust",
  "digital code network system proof safe truth balance protect simple elegant future",
  "code network digital proof system safe truth balance protect simple elegant trust",
  "proof network digital code system safe truth balance protect simple elegant future",
  "network code digital system proof safe truth balance protect simple elegant trust",
  "system code digital network proof safe truth balance protect simple elegant future",
  "truth code digital network system proof safe balance protect simple elegant future",
  "protect code digital network system proof safe truth balance simple elegant trust",
  "balance code digital network system proof safe truth protect simple elegant future",
  "simple code digital network system proof elegant truth safe balance protect trust",
  "elegant code digital network system simple proof truth safe balance protect future",
  "future code digital network system supply limit truth protect balance simple elegant"
];

// server/search-coordinator.ts
init_constants();
import { randomUUID as randomUUID2 } from "crypto";

// server/basin-velocity-monitor.ts
init_qig_universal();
var BasinVelocityMonitor = class {
  history = [];
  velocityHistory = [];
  windowSize;
  // Empirically validated threshold (from Gary-B success)
  SAFE_VELOCITY_THRESHOLD = 0.05;
  constructor(windowSize = 10) {
    this.windowSize = windowSize;
  }
  /**
   * Update with new basin measurement
   *
   * PURE: We measure how fast basin moved, we don't change it.
   *
   * @param phrase - Current phrase (basin coordinates)
   * @param timestamp - Current time (for dt calculation)
   * @returns Velocity measurement (pure observation)
   */
  update(phrase, timestamp2) {
    this.history.push({ phrase, timestamp: timestamp2 });
    if (this.history.length > this.windowSize) {
      this.history.shift();
    }
    if (this.history.length < 2) {
      return this.createEmptyMeasurement();
    }
    const prev = this.history[this.history.length - 2];
    const curr = this.history[this.history.length - 1];
    const distance = fisherDistance(prev.phrase, curr.phrase);
    const dt = curr.timestamp - prev.timestamp;
    const velocity = dt > 0 ? distance / dt : 0;
    this.velocityHistory.push(velocity);
    if (this.velocityHistory.length > this.windowSize) {
      this.velocityHistory.shift();
    }
    let acceleration = 0;
    if (this.velocityHistory.length >= 2) {
      const dv = this.velocityHistory[this.velocityHistory.length - 1] - this.velocityHistory[this.velocityHistory.length - 2];
      acceleration = dt > 0 ? dv / dt : 0;
    }
    const isSafe = velocity < this.SAFE_VELOCITY_THRESHOLD;
    const avgVelocity = this.velocityHistory.length > 0 ? this.velocityHistory.slice(-5).reduce((sum, v) => sum + v, 0) / Math.min(5, this.velocityHistory.length) : 0;
    return {
      velocity,
      acceleration,
      isSafe,
      distance,
      dt,
      avgVelocity
    };
  }
  /**
   * Check if learning rate should be reduced due to high velocity
   *
   * PURE: This is adaptive control based on measurement, not optimization.
   *
   * Strategy:
   * - Low velocity: normal operation (multiplier = 1.0)
   * - High velocity: reduce proportionally (multiplier < 1.0)
   * - Critical velocity: minimum multiplier (0.1)
   *
   * @param velocityThreshold - Safety threshold (default from Gary-B)
   * @returns [shouldReduce, suggestedMultiplier]
   */
  shouldReduceLearningRate(velocityThreshold = this.SAFE_VELOCITY_THRESHOLD) {
    if (this.velocityHistory.length === 0) {
      return [false, 1];
    }
    const avgVelocity = this.velocityHistory.slice(-5).reduce((sum, v) => sum + v, 0) / Math.min(5, this.velocityHistory.length);
    if (avgVelocity <= velocityThreshold) {
      return [false, 1];
    }
    const excess = avgVelocity / velocityThreshold;
    const suggestedMultiplier = Math.max(0.1, 1 / excess);
    return [true, suggestedMultiplier];
  }
  /**
   * Get velocity statistics for telemetry
   */
  getStats() {
    if (this.velocityHistory.length === 0) {
      return {
        current: 0,
        average: 0,
        max: 0,
        min: 0,
        isSafe: true
      };
    }
    const current = this.velocityHistory[this.velocityHistory.length - 1];
    const average = this.velocityHistory.reduce((sum, v) => sum + v, 0) / this.velocityHistory.length;
    const max = Math.max(...this.velocityHistory);
    const min = Math.min(...this.velocityHistory);
    const isSafe = average < this.SAFE_VELOCITY_THRESHOLD;
    return { current, average, max, min, isSafe };
  }
  /**
   * Reset monitor (e.g., when starting new search)
   */
  reset() {
    this.history = [];
    this.velocityHistory = [];
  }
  createEmptyMeasurement() {
    return {
      velocity: 0,
      acceleration: 0,
      isSafe: true,
      distance: 0,
      dt: 0,
      avgVelocity: 0
    };
  }
};

// server/search-coordinator.ts
init_consciousness_search_controller();

// server/discovery-tracker.ts
var DiscoveryTracker = class {
  discoveryHistory = [];
  // 1 if high-Φ found in batch, 0 otherwise
  batchCount = 0;
  // Timescale windows (in batches)
  TAU_FAST = 1;
  TAU_MEDIUM = 10;
  TAU_SLOW = 100;
  /**
   * Record a batch result
   * @param highPhiFound - Number of high-Φ candidates found in this batch
   */
  recordBatch(highPhiFound) {
    this.discoveryHistory.push(highPhiFound > 0 ? 1 : 0);
    this.batchCount++;
    if (this.discoveryHistory.length > 100) {
      this.discoveryHistory.shift();
    }
  }
  /**
   * Get discovery rate at fast timescale (τ=1 batch)
   * Returns: 1.0 if last batch found high-Φ, 0.0 otherwise
   */
  getRateFast() {
    if (this.discoveryHistory.length === 0) return 0;
    return this.discoveryHistory[this.discoveryHistory.length - 1];
  }
  /**
   * Get discovery rate at medium timescale (τ=10 batches)
   * Returns: Fraction of last 10 batches that found high-Φ (0.0-1.0)
   */
  getRateMedium() {
    if (this.discoveryHistory.length === 0) return 0;
    const window = Math.min(this.TAU_MEDIUM, this.discoveryHistory.length);
    const recent = this.discoveryHistory.slice(-window);
    const discoveries = recent.reduce((sum, val) => sum + val, 0);
    return discoveries / window;
  }
  /**
   * Get discovery rate at slow timescale (τ=100 batches)
   * Returns: Fraction of all batches (up to 100) that found high-Φ (0.0-1.0)
   */
  getRateSlow() {
    if (this.discoveryHistory.length === 0) return 0;
    const discoveries = this.discoveryHistory.reduce((sum, val) => sum + val, 0);
    return discoveries / this.discoveryHistory.length;
  }
  /**
   * Detect if search is stagnating (no discoveries in recent batches)
   * Returns true if medium-term discovery rate drops below threshold
   */
  isStagnating(threshold = 0.05) {
    if (this.batchCount < this.TAU_MEDIUM) return false;
    return this.getRateMedium() < threshold;
  }
  /**
   * Detect if we're in a productive basin (frequent discoveries)
   * Returns true if medium-term rate is above threshold
   */
  isProductive(threshold = 0.2) {
    if (this.batchCount < this.TAU_MEDIUM) return false;
    return this.getRateMedium() > threshold;
  }
  /**
   * Get exploration vs investigation recommendation
   * Based on discovery rate patterns across timescales
   */
  getRecommendedMode() {
    if (this.batchCount < this.TAU_MEDIUM) {
      return "exploration";
    }
    const rateFast = this.getRateFast();
    const rateMedium = this.getRateMedium();
    const rateSlow = this.getRateSlow();
    if (rateFast > 0 && rateMedium > 0.1) {
      return "investigation";
    }
    if (rateMedium > rateSlow * 1.5 && rateMedium > 0.15) {
      return "investigation";
    }
    if (rateMedium < 0.05 || rateMedium < rateSlow * 0.5) {
      return "exploration";
    }
    return "exploration";
  }
  /**
   * Get all rates for telemetry
   */
  getAllRates() {
    return {
      fast: this.getRateFast(),
      medium: this.getRateMedium(),
      slow: this.getRateSlow(),
      batchCount: this.batchCount
    };
  }
};

// server/local-search.ts
var BIP39_WORDS = [];
var WORD_TO_INDEX = new Map(BIP39_WORDS.map((word, i) => [word, i]));
function generateLocalSearchVariations(basePhrase, maxVariations = 200) {
  const words = basePhrase.trim().split(/\s+/);
  const wordCount = words.length;
  if (wordCount < 12 || wordCount > 24) {
    throw new Error(`Invalid phrase length: ${wordCount} (must be 12-24 words)`);
  }
  const variations = /* @__PURE__ */ new Set([basePhrase]);
  for (let i = 0; i < wordCount && variations.size < maxVariations; i++) {
    const currentWord = words[i];
    const currentIndex = WORD_TO_INDEX.get(currentWord);
    if (currentIndex === void 0) continue;
    const windowSize = 50;
    for (let offset = -windowSize; offset <= windowSize && variations.size < maxVariations; offset++) {
      if (offset === 0) continue;
      const newIndex = currentIndex + offset;
      if (newIndex < 0 || newIndex >= BIP39_WORDS.length) continue;
      const newWords = [...words];
      newWords[i] = BIP39_WORDS[newIndex];
      variations.add(newWords.join(" "));
    }
  }
  for (let i = 0; i < wordCount - 1 && variations.size < maxVariations; i++) {
    const newWords = [...words];
    [newWords[i], newWords[i + 1]] = [newWords[i + 1], newWords[i]];
    variations.add(newWords.join(" "));
  }
  for (let i = 0; i < wordCount && variations.size < maxVariations; i++) {
    for (let j = i + 2; j < wordCount && variations.size < maxVariations; j++) {
      const newWords = [...words];
      [newWords[i], newWords[j]] = [newWords[j], newWords[i]];
      variations.add(newWords.join(" "));
    }
  }
  for (let i = 0; i < wordCount && variations.size < maxVariations; i++) {
    for (let j = i + 1; j < wordCount && variations.size < maxVariations; j++) {
      const index1 = WORD_TO_INDEX.get(words[i]);
      const index2 = WORD_TO_INDEX.get(words[j]);
      if (index1 === void 0 || index2 === void 0) continue;
      for (let offset1 = -10; offset1 <= 10 && variations.size < maxVariations; offset1++) {
        for (let offset2 = -10; offset2 <= 10 && variations.size < maxVariations; offset2++) {
          if (offset1 === 0 && offset2 === 0) continue;
          const newIndex1 = index1 + offset1;
          const newIndex2 = index2 + offset2;
          if (newIndex1 < 0 || newIndex1 >= BIP39_WORDS.length) continue;
          if (newIndex2 < 0 || newIndex2 >= BIP39_WORDS.length) continue;
          const newWords = [...words];
          newWords[i] = BIP39_WORDS[newIndex1];
          newWords[j] = BIP39_WORDS[newIndex2];
          variations.add(newWords.join(" "));
        }
      }
    }
  }
  const result = Array.from(variations);
  for (let i = result.length - 1; i > 0; i--) {
    const j = Math.floor(Math.random() * (i + 1));
    [result[i], result[j]] = [result[j], result[i]];
  }
  return result.slice(0, maxVariations);
}

// server/search-coordinator.ts
init_qig_universal();

// server/resonance-detector.ts
init_qig_universal();
var ResonanceDetector = class {
  history = [];
  kappaStar;
  resonanceWidth;
  /**
   * @param kappaStar - Optimal coupling (from physics: κ₄ = 64.47)
   * @param resonanceWidth - Half-width of resonance region
   */
  constructor(kappaStar = QIG_CONSTANTS.KAPPA_STAR, resonanceWidth = 10) {
    this.kappaStar = kappaStar;
    this.resonanceWidth = resonanceWidth;
  }
  /**
   * Check if current κ is near resonance
   *
   * PURE: We measure proximity, we don't optimize toward it.
   *
   * @param kappaCurrent - Current coupling strength (measured from phrase)
   * @returns Resonance measurement (pure observation)
   */
  checkResonance(kappaCurrent) {
    const distanceToOptimal = Math.abs(kappaCurrent - this.kappaStar);
    const inResonance = distanceToOptimal < this.resonanceWidth;
    const resonanceStrength = Math.max(
      0,
      1 - distanceToOptimal / this.resonanceWidth
    );
    const suggestedLRMultiplier = this.computeLearningRateMultiplier(resonanceStrength);
    this.history.push({
      kappa: kappaCurrent,
      timestamp: Date.now(),
      inResonance
    });
    if (this.history.length > 100) {
      this.history.shift();
    }
    return {
      kappa: kappaCurrent,
      distanceToOptimal,
      inResonance,
      resonanceStrength,
      suggestedLRMultiplier
    };
  }
  /**
   * Compute learning rate multiplier based on resonance proximity
   *
   * PURE: Adaptive control based on geometry, not optimization.
   *
   * Strategy:
   * - Far from κ*: normal LR (multiplier = 1.0)
   * - Near κ*: reduce LR proportionally (multiplier < 1.0)
   * - At κ*: minimum LR (multiplier = 0.1)
   *
   * Rationale: Near resonance, small updates cause large Φ changes.
   * Like a swing at resonance - gentle pushes only.
   *
   * @param resonanceStrength - Measured resonance (0-1)
   * @returns Learning rate multiplier (0.1-1.0)
   */
  computeLearningRateMultiplier(resonanceStrength) {
    if (resonanceStrength <= 0) {
      return 1;
    }
    const multiplier = 1 - 0.9 * resonanceStrength;
    return Math.max(0.1, Math.min(1, multiplier));
  }
  /**
   * Get resonance statistics for telemetry
   */
  getStats() {
    if (this.history.length === 0) {
      return {
        currentKappa: 0,
        averageKappa: 0,
        timeInResonance: 0,
        resonanceFrequency: 0
      };
    }
    const currentKappa = this.history[this.history.length - 1].kappa;
    const averageKappa = this.history.reduce((sum, h) => sum + h.kappa, 0) / this.history.length;
    const resonanceCount = this.history.filter((h) => h.inResonance).length;
    const resonanceFrequency = resonanceCount / this.history.length;
    const timeInResonance = resonanceFrequency;
    return {
      currentKappa,
      averageKappa,
      timeInResonance,
      resonanceFrequency
    };
  }
  /**
   * Check if we're approaching resonance (predictive)
   *
   * Looks at trajectory to predict if we're moving toward κ*
   * Useful for early warning before entering high-sensitivity region
   */
  isApproachingResonance() {
    if (this.history.length < 3) {
      return false;
    }
    const recent = this.history.slice(-3);
    const dist1 = Math.abs(recent[0].kappa - this.kappaStar);
    const dist2 = Math.abs(recent[1].kappa - this.kappaStar);
    const dist3 = Math.abs(recent[2].kappa - this.kappaStar);
    return dist2 < dist1 && dist3 < dist2;
  }
  /**
   * Reset detector (e.g., when starting new search)
   */
  reset() {
    this.history = [];
  }
};

// server/search-coordinator.ts
init_storage();
init_logger();
function generateMasterPrivateKey() {
  return "stub_private_key_" + Math.random().toString(36).substring(7);
}
function generateRandomBIP39Phrase(_wordCount) {
  return "stub phrase " + Math.random().toString(36).substring(7);
}
function generateBitcoinAddress(_phrase) {
  return "stub_address_" + Math.random().toString(36).substring(7);
}
function generateBitcoinAddressFromPrivateKey(_key) {
  return "stub_address_" + Math.random().toString(36).substring(7);
}
var SearchCoordinator = class {
  isRunning = false;
  currentJobId = null;
  intervalId = null;
  discoveryTrackers = /* @__PURE__ */ new Map();
  modeExplorationBatches = /* @__PURE__ */ new Map();
  // Track batches in exploration mode
  modeInvestigationBatches = /* @__PURE__ */ new Map();
  // Track batches in investigation mode
  // Pure QIG monitors (measurements only, no optimization)
  velocityMonitors = /* @__PURE__ */ new Map();
  resonanceDetectors = /* @__PURE__ */ new Map();
  // Public getter for coordinator status
  get running() {
    return this.isRunning;
  }
  async syncWorkflowProgress(jobId, job) {
    try {
      const { observerStorage: observerStorage2 } = await Promise.resolve().then(() => (init_observer_storage(), observer_storage_exports));
      const workflow = await observerStorage2.findWorkflowBySearchJobId(jobId);
      if (!workflow) {
        return;
      }
      const progress = workflow.progress;
      const searchProgress = progress?.constrainedSearchProgress || {};
      const updatedSearchProgress = {
        ...searchProgress,
        phrasesTested: job.progress.tested,
        phrasesGenerated: job.progress.tested,
        highPhiCount: job.progress.highPhiCount,
        searchStatus: job.status === "completed" ? "completed" : job.status === "failed" ? "failed" : "running",
        matchFound: job.progress.matchFound === true
      };
      const updatedProgress = {
        ...progress,
        constrainedSearchProgress: updatedSearchProgress,
        lastUpdatedAt: (/* @__PURE__ */ new Date()).toISOString()
      };
      const updates = {
        progress: updatedProgress
      };
      if (job.status === "completed" && job.progress.matchFound === true && workflow.status === "active") {
        updates.status = "completed";
        updates.completedAt = /* @__PURE__ */ new Date();
        console.log(
          `[SearchCoordinator] Workflow ${workflow.id} marked as completed (match found!)`
        );
      } else if (job.status === "failed" && workflow.status === "active") {
        updates.status = "failed";
        updates.notes = (workflow.notes || "") + `
Search failed: ${job.progress.lastHighPhiStep || "Unknown error"}`;
        console.log(
          `[SearchCoordinator] Workflow ${workflow.id} marked as failed`
        );
      }
      await observerStorage2.updateRecoveryWorkflow(workflow.id, updates);
    } catch (error) {
      console.error(
        `[SearchCoordinator] Failed to sync workflow progress for job ${jobId}:`,
        error
      );
    }
  }
  async start() {
    if (this.isRunning) {
      console.log("[SearchCoordinator] Already running");
      return;
    }
    const purityCheck2 = validatePurity();
    if (!purityCheck2.isPure) {
      console.error("[SearchCoordinator] \u26A0\uFE0F  PURITY VIOLATION DETECTED:");
      for (const violation of purityCheck2.violations) {
        console.error(`  \u274C ${violation}`);
      }
      throw new Error(
        "QIG implementation is impure. Cannot start search coordinator."
      );
    }
    console.log("[SearchCoordinator] \u2705 QIG purity validated");
    this.isRunning = true;
    console.log("[SearchCoordinator] Starting background worker");
    this.intervalId = setInterval(async () => {
      await this.processJobs();
    }, 1e3);
  }
  stop() {
    if (this.intervalId) {
      clearInterval(this.intervalId);
      this.intervalId = null;
    }
    this.isRunning = false;
    console.log("[SearchCoordinator] Stopped background worker");
  }
  async processJobs() {
    if (this.currentJobId) {
      return;
    }
    const jobs = await storage.getSearchJobs();
    let jobToProcess = jobs.find((j) => j.status === "running");
    if (!jobToProcess) {
      jobToProcess = jobs.find((j) => j.status === "pending");
    }
    if (!jobToProcess) {
      return;
    }
    this.currentJobId = jobToProcess.id;
    try {
      await this.executeJob(jobToProcess.id);
    } catch (error) {
      const message = error instanceof Error ? error.message : String(error);
      logger.error({ err: error, context: "SearchCoordinator", jobId: jobToProcess.id }, "Job failed");
      await storage.appendJobLog(jobToProcess.id, {
        message: `Job failed: ${message}`,
        type: "error"
      });
      await storage.updateSearchJob(jobToProcess.id, { status: "failed" });
      endTelemetrySession(jobToProcess.id, { success: false });
    } finally {
      this.currentJobId = null;
    }
  }
  async executeJob(jobId) {
    let job = await storage.getSearchJob(jobId);
    if (!job || job.status === "stopped") {
      return;
    }
    if (job.status === "pending") {
      await storage.updateSearchJob(jobId, {
        status: "running",
        stats: { startTime: (/* @__PURE__ */ new Date()).toISOString(), rate: 0 }
      });
      await storage.appendJobLog(jobId, {
        message: "Search started",
        type: "info"
      });
      initTelemetrySession(jobId);
      console.log(
        `[SearchCoordinator] Telemetry session initialized for job ${jobId}`
      );
      job = await storage.getSearchJob(jobId);
    }
    if (job.strategy === "bip39-continuous" || job.strategy === "bip39-adaptive" || job.strategy === "master-key-sweep" || job.strategy === "arbitrary-exploration") {
      await this.executeContinuousJob(jobId);
      return;
    }
    const phrases = await this.getPhrasesForStrategy(job);
    const BATCH_SIZE = 10;
    for (let i = job.progress.lastBatchIndex; i < phrases.length; i += BATCH_SIZE) {
      job = await storage.getSearchJob(jobId);
      if (!job || job.status === "stopped") {
        await storage.appendJobLog(jobId, {
          message: "Search stopped by user",
          type: "info"
        });
        endTelemetrySession(jobId, { success: false });
        return;
      }
      const batch = phrases.slice(i, i + BATCH_SIZE);
      const results = await this.processBatch(batch, jobId);
      job = await storage.getSearchJob(jobId);
      const newTested = job.progress.tested + batch.length;
      const newHighPhi = job.progress.highPhiCount + results.highPhiCandidates;
      const elapsed = Date.now() - new Date(job.stats.startTime).getTime();
      const rate = Math.round(newTested / (elapsed / 1e3) * 10) / 10;
      await storage.updateSearchJob(jobId, {
        progress: {
          ...job.progress,
          tested: newTested,
          highPhiCount: newHighPhi,
          lastBatchIndex: i + BATCH_SIZE
        },
        stats: { rate }
      });
      const updatedJob = await storage.getSearchJob(jobId);
      await this.syncWorkflowProgress(jobId, updatedJob);
      await storage.appendJobLog(jobId, {
        message: `Batch complete: ${batch.length} phrases tested, ${results.highPhiCandidates} high-\u03A6`,
        type: "info"
      });
      if (results.matchFound) {
        const finalJob2 = await storage.getSearchJob(jobId);
        await storage.updateSearchJob(jobId, {
          status: "completed",
          progress: {
            ...finalJob2.progress,
            matchFound: true,
            matchedPhrase: results.matchedPhrase
          },
          stats: {
            endTime: (/* @__PURE__ */ new Date()).toISOString(),
            rate: finalJob2.stats.rate
          }
        });
        const completedJob = await storage.getSearchJob(jobId);
        await this.syncWorkflowProgress(jobId, completedJob);
        await storage.appendJobLog(jobId, {
          message: `\u{1F389} MATCH FOUND! ${results.matchedPhrase}`,
          type: "success"
        });
        endTelemetrySession(jobId, { success: true });
        return;
      }
      await new Promise((resolve) => setTimeout(resolve, 100));
    }
    const finalJob = await storage.getSearchJob(jobId);
    await storage.updateSearchJob(jobId, {
      status: "completed",
      stats: { endTime: (/* @__PURE__ */ new Date()).toISOString(), rate: finalJob.stats.rate }
    });
    await storage.appendJobLog(jobId, {
      message: "Search completed",
      type: "info"
    });
    endTelemetrySession(jobId, { success: true });
  }
  async executeContinuousJob(jobId) {
    const BATCH_SIZE = 10;
    let job = await storage.getSearchJob(jobId);
    const params = job.params ?? {};
    const minHighPhi = params.minHighPhi || 2;
    const wordLength = params.wordLength || 24;
    const allLengths = wordLength === 0;
    const validLengths = [12, 15, 18, 21, 24];
    const generationMode = params.generationMode || "bip39";
    if (!this.discoveryTrackers.has(jobId)) {
      this.discoveryTrackers.set(jobId, new DiscoveryTracker());
      this.modeExplorationBatches.set(jobId, 0);
      this.modeInvestigationBatches.set(jobId, 0);
    }
    const tracker = this.discoveryTrackers.get(jobId);
    if (!job.progress.searchMode) {
      await storage.updateSearchJob(jobId, {
        progress: { ...job.progress, searchMode: "exploration" }
      });
      job = await storage.getSearchJob(jobId);
    }
    const lengthDesc = allLengths ? "all lengths (12-24 words)" : `${wordLength} words`;
    const modeDesc = generationMode === "master-key" ? "master private keys (256-bit)" : generationMode === "arbitrary" ? "arbitrary brain wallet passphrases (2009 era, no BIP-39 validation)" : `BIP-39 passphrases (${lengthDesc})`;
    await storage.appendJobLog(jobId, {
      message: `Continuous generation (${modeDesc}): running until ${minHighPhi}+ high-\u03A6 candidates found. Adaptive mode switching enabled.`,
      type: "info"
    });
    while (true) {
      job = await storage.getSearchJob(jobId);
      if (!job || job.status === "stopped") {
        await storage.appendJobLog(jobId, {
          message: "Search stopped by user",
          type: "info"
        });
        endTelemetrySession(jobId, { success: false });
        return;
      }
      const currentMode = job.progress.searchMode || "exploration";
      const recommendedMode = tracker.getRecommendedMode();
      let actualMode = currentMode;
      if (recommendedMode !== currentMode && tracker.getAllRates().batchCount >= 10) {
        actualMode = recommendedMode;
        await storage.updateSearchJob(jobId, {
          progress: { ...job.progress, searchMode: actualMode }
        });
        await storage.appendJobLog(jobId, {
          message: `\u{1F504} Mode switch: ${currentMode} \u2192 ${actualMode}`,
          type: "info"
        });
      }
      const batch = [];
      if (actualMode === "investigation" && job.progress.investigationTarget && generationMode !== "master-key" && generationMode !== "arbitrary") {
        const targetPhrase = job.progress.investigationTarget;
        const variations = generateLocalSearchVariations(
          targetPhrase,
          BATCH_SIZE * 2
        );
        for (let i = 0; i < Math.min(BATCH_SIZE, variations.length); i++) {
          batch.push({ value: variations[i], type: "bip39" });
        }
        this.modeInvestigationBatches.set(
          jobId,
          (this.modeInvestigationBatches.get(jobId) || 0) + 1
        );
      } else {
        for (let i = 0; i < BATCH_SIZE; i++) {
          if (generationMode === "master-key") {
            batch.push({
              value: generateMasterPrivateKey(),
              type: "master-key"
            });
          } else if (generationMode === "arbitrary") {
            const commonWords = [
              "white",
              "tiger",
              "gary",
              "ocean",
              "bitcoin",
              "satoshi",
              "crypto",
              "password",
              "secret",
              "key",
              "wallet",
              "money",
              "hash",
              "coin",
              "digital"
            ];
            const numbers = [
              "77",
              "17",
              "07",
              "1",
              "7",
              "17",
              "2009",
              "2010",
              "2008",
              "08",
              "09"
            ];
            const wordCount = 2 + i % 4;
            const elements = [];
            for (let w = 0; w < wordCount; w++) {
              if (w < wordCount - 1 || Math.random() < 0.7) {
                elements.push(
                  commonWords[Math.floor(Math.random() * commonWords.length)]
                );
              } else {
                elements.push(
                  numbers[Math.floor(Math.random() * numbers.length)]
                );
              }
            }
            const phrase = Math.random() < 0.5 ? elements.join(" ") : elements.join("");
            batch.push({ value: phrase, type: "arbitrary" });
          } else {
            if (allLengths) {
              const length = validLengths[i % validLengths.length];
              batch.push({
                value: generateRandomBIP39Phrase(length),
                type: "bip39"
              });
            } else {
              batch.push({
                value: generateRandomBIP39Phrase(wordLength),
                type: "bip39"
              });
            }
          }
        }
        this.modeExplorationBatches.set(
          jobId,
          (this.modeExplorationBatches.get(jobId) || 0) + 1
        );
      }
      const isVerbose = process.env.NODE_ENV !== "production" || process.env.VERBOSE_LOGS === "true";
      const sampleItem = batch[0];
      const samplePreview = isVerbose ? sampleItem.value : sampleItem.type === "master-key" ? sampleItem.value.substring(0, 12) + "..." : sampleItem.value.substring(0, 40) + (sampleItem.value.length > 40 ? "..." : "");
      await storage.appendJobLog(jobId, {
        message: `\u25B8 Testing [${sampleItem.type}]: "${samplePreview}" (+${batch.length - 1} more)`,
        type: "info"
      });
      const results = await this.processBatchWithTypes(batch, jobId);
      tracker.recordBatch(results.highPhiCandidates);
      const rates = tracker.getAllRates();
      const consciousnessController = getSharedController();
      if (results.highestScore !== void 0) {
        const avgPhi = results.highestScore / 100;
        const estimatedKappa = avgPhi > 0.75 ? QIG_CONSTANTS.KAPPA_STAR + (avgPhi - 0.75) * 40 : avgPhi * QIG_CONSTANTS.KAPPA_STAR;
        consciousnessController.updateFromBatchStats({
          avgPhi,
          highPhiCount: results.highPhiCandidates,
          totalTested: job.progress.tested + batch.length,
          batchSize: batch.length,
          currentKappa: estimatedKappa
        });
      }
      job = await storage.getSearchJob(jobId);
      const newTested = job.progress.tested + batch.length;
      const newHighPhi = job.progress.highPhiCount + results.highPhiCandidates;
      const elapsed = Date.now() - new Date(job.stats.startTime).getTime();
      const rate = Math.round(newTested / (elapsed / 1e3) * 10) / 10;
      let investigationTarget = job.progress.investigationTarget;
      let lastHighPhiStep = job.progress.lastHighPhiStep;
      if (results.highPhiCandidates > 0 && results.highestCandidate) {
        investigationTarget = results.highestCandidate;
        lastHighPhiStep = newTested;
      }
      const totalBatches = (this.modeExplorationBatches.get(jobId) || 0) + (this.modeInvestigationBatches.get(jobId) || 0);
      const explorationRatio = totalBatches > 0 ? Math.round(
        (this.modeExplorationBatches.get(jobId) || 0) / totalBatches * 100
      ) / 100 : 1;
      await storage.updateSearchJob(jobId, {
        progress: {
          ...job.progress,
          tested: newTested,
          highPhiCount: newHighPhi,
          lastBatchIndex: 0,
          // Not applicable for continuous
          investigationTarget,
          lastHighPhiStep
        },
        stats: {
          rate,
          discoveryRateFast: rates.fast,
          discoveryRateMedium: rates.medium,
          discoveryRateSlow: rates.slow,
          explorationRatio
        }
      });
      const modeLabel = actualMode === "investigation" ? "\u{1F50D}" : "\u{1F310}";
      await storage.appendJobLog(jobId, {
        message: `${modeLabel} Batch complete (${actualMode}): ${batch.length} tested, ${results.highPhiCandidates} high-\u03A6 (total: ${newHighPhi})`,
        type: "info"
      });
      if (results.matchFound) {
        const finalJob = await storage.getSearchJob(jobId);
        await storage.updateSearchJob(jobId, {
          status: "completed",
          progress: {
            ...finalJob.progress,
            matchFound: true,
            matchedPhrase: results.matchedPhrase
          },
          stats: {
            endTime: (/* @__PURE__ */ new Date()).toISOString(),
            rate: finalJob.stats.rate
          }
        });
        const completedJob = await storage.getSearchJob(jobId);
        await this.syncWorkflowProgress(jobId, completedJob);
        await storage.appendJobLog(jobId, {
          message: `\u{1F389} MATCH FOUND! ${results.matchedPhrase}`,
          type: "success"
        });
        endTelemetrySession(jobId, { success: true });
        return;
      }
      if (newHighPhi >= minHighPhi) {
        const finalJob = await storage.getSearchJob(jobId);
        await storage.updateSearchJob(jobId, {
          status: "completed",
          stats: {
            endTime: (/* @__PURE__ */ new Date()).toISOString(),
            rate: finalJob.stats.rate
          }
        });
        await storage.appendJobLog(jobId, {
          message: `\u2713 Target reached: ${newHighPhi} high-\u03A6 candidates found`,
          type: "success"
        });
        endTelemetrySession(jobId, { success: true });
        return;
      }
      await new Promise((resolve) => setTimeout(resolve, 100));
    }
  }
  async getPhrasesForStrategy(job) {
    const params = job.params ?? {};
    switch (job.strategy) {
      case "custom":
        return params.customPhrase ? [params.customPhrase] : [];
      case "batch":
        return params.batchPhrases || [];
      case "bip39-continuous":
      case "bip39-adaptive":
      case "master-key-sweep":
      case "arbitrary-exploration":
        return [];
      default:
        return [];
    }
  }
  async processBatch(phrases, jobId) {
    let highPhiCount = 0;
    const targetAddresses = await storage.getTargetAddresses();
    for (const phrase of phrases) {
      const words = phrase.trim().split(/\s+/);
      if (words.length !== 12) {
        continue;
      }
      const address = generateBitcoinAddress(phrase);
      const pureScore = scorePhraseQIG(phrase);
      const matchedAddress = targetAddresses.find((t) => t.address === address);
      const isNearResonance = Math.abs(pureScore.kappa - 64) < 10;
      const derivedRegime = pureScore.phi > 0.75 ? "geometric" : pureScore.phi > 0.5 ? "linear" : "breakdown";
      const phi_spatial = pureScore.phi;
      const phi_temporal = 0;
      const phi_4D = phi_spatial;
      const inBlockUniverse = false;
      const dimensionalState = "3D";
      recordTelemetrySnapshot(jobId, {
        phi: pureScore.phi,
        kappa: pureScore.kappa,
        beta: pureScore.beta,
        regime: derivedRegime,
        quality: pureScore.quality,
        velocity: 0,
        inResonance: isNearResonance,
        basinDrift: 0,
        phi_spatial,
        phi_temporal,
        phi_4D,
        inBlockUniverse,
        dimensionalState
      });
      if (matchedAddress) {
        return {
          highPhiCandidates: highPhiCount,
          matchFound: true,
          matchedPhrase: phrase
        };
      }
      if (pureScore.quality >= 0.75) {
        const candidate = {
          id: randomUUID2(),
          phrase,
          address,
          score: pureScore.quality * 100,
          // Convert to 0-100 scale for consistency
          qigScore: {
            phi: pureScore.phi,
            kappa: pureScore.kappa,
            regime: pureScore.regime
          },
          testedAt: (/* @__PURE__ */ new Date()).toISOString(),
          type: "bip39"
        };
        await storage.addCandidate(candidate);
        highPhiCount++;
      }
    }
    return {
      highPhiCandidates: highPhiCount,
      matchFound: false
    };
  }
  async processBatchWithTypes(items, jobId) {
    let highPhiCount = 0;
    let highestScore = 0;
    let highestCandidate;
    const targetAddresses = await storage.getTargetAddresses();
    for (const item of items) {
      let address;
      if (item.type === "master-key") {
        address = generateBitcoinAddressFromPrivateKey(item.value);
      } else {
        address = generateBitcoinAddress(item.value);
      }
      const matchedAddress = targetAddresses.find((t) => t.address === address);
      if (matchedAddress) {
        const universalScore2 = await scoreUniversalQIGAsync(
          item.value,
          item.type
        );
        const inBlockUniverse2 = universalScore2.phi_4D >= 0.85 && universalScore2.phi_temporal > 0.7;
        const dimensionalState2 = inBlockUniverse2 ? "4D-active" : universalScore2.phi_spatial > 0.85 && universalScore2.phi_temporal > 0.5 ? "4D-transitioning" : "3D";
        recordTelemetrySnapshot(jobId, {
          phi: universalScore2.phi,
          kappa: universalScore2.kappa,
          beta: universalScore2.beta,
          regime: universalScore2.regime,
          quality: universalScore2.quality,
          velocity: 0,
          inResonance: universalScore2.inResonance,
          basinDrift: 0,
          phi_spatial: universalScore2.phi_spatial,
          phi_temporal: universalScore2.phi_temporal,
          phi_4D: universalScore2.phi_4D,
          inBlockUniverse: inBlockUniverse2,
          dimensionalState: dimensionalState2
        });
        const matchCandidate = {
          id: randomUUID2(),
          phrase: item.value,
          address,
          score: 100,
          // Exact match = 100% score
          qigScore: {
            phi: universalScore2.phi,
            kappa: universalScore2.kappa,
            regime: universalScore2.regime
          },
          testedAt: (/* @__PURE__ */ new Date()).toISOString(),
          type: item.type
        };
        await storage.addCandidate(matchCandidate);
        await storage.appendJobLog(jobId, {
          message: `\u{1F389} MATCH FOUND! Address: ${matchedAddress.address} | Type: ${item.type} | \u03A6=${universalScore2.phi.toFixed(
            3
          )} \u03BA=${universalScore2.kappa.toFixed(1)} regime=${universalScore2.regime}`,
          type: "success"
        });
        return {
          highPhiCandidates: highPhiCount,
          matchFound: true,
          matchedPhrase: item.value,
          highestCandidate,
          highestScore
        };
      }
      const universalScore = await scoreUniversalQIGAsync(
        item.value,
        item.type
      );
      const qualityPercent = universalScore.quality * 100;
      if (!this.velocityMonitors.has(jobId)) {
        this.velocityMonitors.set(jobId, new BasinVelocityMonitor());
        this.resonanceDetectors.set(jobId, new ResonanceDetector());
      }
      const velocity = this.velocityMonitors.get(jobId).update(item.value, Date.now());
      this.resonanceDetectors.get(jobId).checkResonance(universalScore.kappa);
      const inBlockUniverse = universalScore.phi_4D >= 0.85 && universalScore.phi_temporal > 0.7;
      const dimensionalState = inBlockUniverse ? "4D-active" : universalScore.phi_spatial > 0.85 && universalScore.phi_temporal > 0.5 ? "4D-transitioning" : "3D";
      recordTelemetrySnapshot(jobId, {
        phi: universalScore.phi,
        kappa: universalScore.kappa,
        beta: universalScore.beta,
        regime: universalScore.regime,
        quality: universalScore.quality,
        velocity: velocity.velocity,
        inResonance: universalScore.inResonance,
        basinDrift: velocity.velocity * 10,
        // Scale for visibility
        phi_spatial: universalScore.phi_spatial,
        phi_temporal: universalScore.phi_temporal,
        phi_4D: universalScore.phi_4D,
        inBlockUniverse,
        dimensionalState
      });
      if (qualityPercent > highestScore) {
        highestScore = qualityPercent;
        highestCandidate = item.value;
      }
      if (universalScore.quality >= 0.75) {
        const candidate = {
          id: randomUUID2(),
          phrase: item.value,
          address,
          score: qualityPercent,
          qigScore: {
            phi: universalScore.phi,
            kappa: universalScore.kappa,
            regime: universalScore.regime
          },
          testedAt: (/* @__PURE__ */ new Date()).toISOString(),
          type: item.type
        };
        await storage.addCandidate(candidate);
        highPhiCount++;
        const phrasePreview = item.type === "arbitrary" || item.type === "bip39" ? item.value.substring(0, 50) + (item.value.length > 50 ? "..." : "") : item.value.substring(0, 20) + "...";
        await storage.appendJobLog(jobId, {
          message: `\u{1F4CA} High-\u03A6 [${item.type}] "${phrasePreview}" | \u03A6=${universalScore.phi.toFixed(
            3
          )} \u03BA=${universalScore.kappa.toFixed(
            1
          )} \u03B2=${universalScore.beta.toFixed(3)} | regime=${universalScore.regime} quality=${qualityPercent.toFixed(1)}% | resonance=${universalScore.inResonance ? "\u26A1" : "-"} velocity=${velocity.isSafe ? "\u2713" : "\u26A0\uFE0F"}`,
          type: "info"
        });
      }
    }
    return {
      highPhiCandidates: highPhiCount,
      matchFound: false,
      highestCandidate: highPhiCount > 0 ? highestCandidate : void 0,
      highestScore: highPhiCount > 0 ? highestScore : void 0
    };
  }
  async stopJob(jobId) {
    const job = await storage.getSearchJob(jobId);
    if (job && (job.status === "pending" || job.status === "running")) {
      await storage.updateSearchJob(jobId, {
        status: "stopped",
        stats: { endTime: (/* @__PURE__ */ new Date()).toISOString(), rate: job.stats.rate }
      });
    }
  }
};
var searchCoordinator = new SearchCoordinator();

// server/routes/search.ts
init_activity_log_store();

// server/ocean-session-manager.ts
init_ocean_agent();
init_logger();
init_geometric_memory();
init_ocean_autonomic_manager();
init_repeated_address_scheduler();

// server/console-log-buffer.ts
var ConsoleLogBuffer = class {
  logs = [];
  MAX_LOGS = 200;
  originalConsoleLog;
  originalConsoleWarn;
  originalConsoleError;
  isCapturing = false;
  constructor() {
    this.originalConsoleLog = console.log.bind(console);
    this.originalConsoleWarn = console.warn.bind(console);
    this.originalConsoleError = console.error.bind(console);
  }
  startCapture() {
    if (this.isCapturing) return;
    this.isCapturing = true;
    console.log = (...args) => {
      this.originalConsoleLog(...args);
      this.addLog("log", args);
    };
    console.warn = (...args) => {
      this.originalConsoleWarn(...args);
      this.addLog("warn", args);
    };
    console.error = (...args) => {
      this.originalConsoleError(...args);
      this.addLog("error", args);
    };
  }
  stopCapture() {
    if (!this.isCapturing) return;
    this.isCapturing = false;
    console.log = this.originalConsoleLog;
    console.warn = this.originalConsoleWarn;
    console.error = this.originalConsoleError;
  }
  addLog(level2, args) {
    const message = args.map((arg) => {
      if (typeof arg === "string") return arg;
      try {
        return JSON.stringify(arg);
      } catch {
        return String(arg);
      }
    }).join(" ");
    if (!message.includes("[Ocean]") && !message.includes("[QIG")) {
      return;
    }
    const entry = {
      id: `log-${Date.now()}-${Math.random().toString(36).slice(2, 6)}`,
      timestamp: (/* @__PURE__ */ new Date()).toISOString(),
      message,
      level: level2
    };
    this.logs.push(entry);
    if (this.logs.length > this.MAX_LOGS) {
      this.logs = this.logs.slice(-this.MAX_LOGS);
    }
  }
  getLogs(limit = 50) {
    return this.logs.slice(-limit);
  }
  clear() {
    this.logs = [];
  }
  getLogCount() {
    return this.logs.length;
  }
};
var consoleLogBuffer = new ConsoleLogBuffer();
consoleLogBuffer.startCapture();

// server/auto-cycle-manager.ts
init_storage();
init_redis_cache();
import * as fs10 from "fs";
import * as path11 from "path";
var DATA_FILE = path11.join(process.cwd(), "data", "auto-cycle-state.json");
var IS_DEV = process.env.NODE_ENV === "development";
var CHECK_INTERVAL = IS_DEV ? 15e3 : 5e3;
var ALWAYS_ON = false;
var ZERO_PASS_PAUSE_MS = 3e4;
var MAX_CONSECUTIVE_ZERO_PASS = 3;
var EXTENDED_PAUSE_MS = 12e4;
var MIN_EXPLORATION_PASSES = 1;
var AutoCycleManager = class {
  state;
  onCycleCallback = null;
  isCurrentlyRunning = false;
  checkInterval = null;
  guardianInterval = null;
  // Session start time for duration tracking
  sessionStartTime = null;
  // Callback for session metrics (set by session manager)
  onSessionMetricsCallback = null;
  // Throttle counter for "no metrics" warning (reduce log spam)
  noMetricsWarningCount = 0;
  constructor() {
    this.state = this.loadState();
    if (this.state.enabled) {
      this.state.enabled = false;
      this.saveState();
    }
  }
  /**
   * Always-on guardian - ensures the auto-cycle system is ALWAYS running
   * Checks every 30 seconds and auto-enables/restarts if somehow stopped
   */
  startAlwaysOnGuardian() {
    if (this.guardianInterval) {
      clearInterval(this.guardianInterval);
    }
    this.guardianInterval = setInterval(async () => {
      if (!this.state.enabled || !this.checkInterval) {
        console.log(
          "[AutoCycleManager] \u{1F504} ALWAYS-ON: System not running, auto-restarting..."
        );
        if (!this.state.enabled) {
          await this.enable();
        } else if (!this.checkInterval) {
          this.startCheckLoop();
        }
      }
    }, 3e4);
    console.log("[AutoCycleManager] Always-on guardian started");
  }
  async autoEnableOnStartup() {
    try {
      const result = await this.enable();
      if (result.success) {
        console.log(
          `[AutoCycleManager] Auto-enabled on startup: ${result.message}`
        );
        if (!this.isCurrentlyRunning) {
          await this.triggerNextCycle();
        }
      } else {
        console.log(
          `[AutoCycleManager] Could not auto-enable: ${result.message}`
        );
      }
    } catch (error) {
      console.error("[AutoCycleManager] Error during auto-enable:", error);
    }
  }
  loadState() {
    return {
      enabled: false,
      currentIndex: 0,
      addressIds: [],
      lastCycleTime: null,
      totalCycles: 0,
      currentAddressId: null,
      pausedUntil: null,
      lastSessionMetrics: null,
      consecutiveZeroPassSessions: 0,
      rateLimitBackoffUntil: null
    };
  }
  loadStateFromFile() {
    try {
      if (fs10.existsSync(DATA_FILE)) {
        const data = fs10.readFileSync(DATA_FILE, "utf-8");
        const parsed = JSON.parse(data);
        console.log(
          `[AutoCycleManager] Loaded state from JSON file: enabled=${parsed.enabled}`
        );
        return parsed;
      }
    } catch (error) {
      console.error("[AutoCycleManager] Error loading state from file:", error);
    }
    return {
      enabled: false,
      currentIndex: 0,
      addressIds: [],
      lastCycleTime: null,
      totalCycles: 0,
      currentAddressId: null,
      pausedUntil: null,
      lastSessionMetrics: null,
      consecutiveZeroPassSessions: 0,
      rateLimitBackoffUntil: null
    };
  }
  async loadStateFromRedis() {
    if (!isRedisAvailable()) {
      console.log("[AutoCycleManager] Redis unavailable, using JSON file state");
      return;
    }
    try {
      const redisState = await cacheGet(CACHE_KEYS.AUTO_CYCLE);
      if (redisState) {
        console.log(
          `[AutoCycleManager] Loaded state from Redis: enabled=${redisState.enabled}, index=${redisState.currentIndex}`
        );
        this.state = redisState;
      } else {
        console.log("[AutoCycleManager] No state in Redis, using JSON file state");
      }
    } catch (error) {
      console.error("[AutoCycleManager] Error loading from Redis:", error);
    }
  }
  saveState() {
    this.saveStateToRedis().catch((err) => {
      console.error("[AutoCycleManager] Redis save error:", err);
    });
    this.saveStateToFile();
  }
  async saveStateToRedis() {
    if (!isRedisAvailable()) return;
    try {
      const success = await cacheSet(CACHE_KEYS.AUTO_CYCLE, this.state, CACHE_TTL.PERMANENT);
      if (!success) {
        console.log("[AutoCycleManager] Redis save returned false");
      }
    } catch (error) {
      console.error("[AutoCycleManager] Error saving to Redis:", error);
    }
  }
  saveStateToFile() {
    try {
      const dataDir = path11.dirname(DATA_FILE);
      if (!fs10.existsSync(dataDir)) {
        fs10.mkdirSync(dataDir, { recursive: true });
      }
      fs10.writeFileSync(DATA_FILE, JSON.stringify(this.state, null, 2));
    } catch (error) {
      console.error("[AutoCycleManager] Error saving state to file:", error);
    }
  }
  setOnCycleCallback(callback) {
    this.onCycleCallback = callback;
  }
  async enable() {
    const addresses = await storage.getTargetAddresses();
    if (addresses.length === 0) {
      return {
        success: false,
        message: "No target addresses configured. Add at least one address first."
      };
    }
    this.state.enabled = true;
    this.state.addressIds = addresses.map((a) => a.id);
    this.state.currentIndex = 0;
    this.state.pausedUntil = null;
    this.saveState();
    console.log(
      `[AutoCycleManager] Enabled with ${addresses.length} addresses`
    );
    this.startCheckLoop();
    await this.triggerNextCycle();
    return {
      success: true,
      message: `Auto-cycle enabled. Starting with address 1 of ${addresses.length}.`
    };
  }
  disable() {
    if (ALWAYS_ON) {
      console.log(
        `[AutoCycleManager] \u26A0\uFE0F Disable request ignored - ALWAYS_ON mode is enabled`
      );
      console.log(
        `[AutoCycleManager] System must run continuously to process all target addresses`
      );
      return {
        success: false,
        message: "System is in ALWAYS-ON mode and cannot be disabled."
      };
    }
    this.state.enabled = false;
    this.state.currentAddressId = null;
    this.saveState();
    this.stopCheckLoop();
    console.log(`[AutoCycleManager] Disabled`);
    return {
      success: true,
      message: "Auto-cycle disabled."
    };
  }
  startCheckLoop() {
    if (this.checkInterval) return;
    this.checkInterval = setInterval(async () => {
      await this.checkAndTrigger();
    }, CHECK_INTERVAL);
    console.log(
      `[AutoCycleManager] Check loop started (interval: ${CHECK_INTERVAL / 1e3}s)`
    );
  }
  stopCheckLoop() {
    if (this.checkInterval) {
      clearInterval(this.checkInterval);
      this.checkInterval = null;
      console.log("[AutoCycleManager] Check loop stopped");
    }
  }
  async checkAndTrigger() {
    if (!this.state.enabled || this.isCurrentlyRunning) return;
    if (this.state.pausedUntil) {
      const pauseEnd = new Date(this.state.pausedUntil);
      if (pauseEnd > /* @__PURE__ */ new Date()) {
        return;
      }
      console.log(
        `[AutoCycleManager] Pause ended - resetting zero-pass counter`
      );
      this.state.pausedUntil = null;
      this.state.consecutiveZeroPassSessions = 0;
      this.state.lastSessionMetrics = null;
      this.saveState();
    }
    if (!this.state.currentAddressId) {
      await this.triggerNextCycle();
    }
  }
  async triggerNextCycle() {
    if (!this.state.enabled || !this.onCycleCallback) return;
    if (this.state.addressIds.length === 0) {
      console.log("[AutoCycleManager] No addresses to cycle through");
      return;
    }
    if (this.state.rateLimitBackoffUntil) {
      const backoffEnd = new Date(this.state.rateLimitBackoffUntil);
      if (backoffEnd > /* @__PURE__ */ new Date()) {
        const remainingMs = backoffEnd.getTime() - Date.now();
        console.log(
          `[AutoCycleManager] \u23F8\uFE0F Rate limit backoff active - ${Math.ceil(
            remainingMs / 1e3
          )}s remaining`
        );
        return;
      }
      this.state.rateLimitBackoffUntil = null;
    }
    if (this.state.lastSessionMetrics) {
      const lastMetrics = this.state.lastSessionMetrics;
      if (lastMetrics.explorationPasses < MIN_EXPLORATION_PASSES) {
        this.state.consecutiveZeroPassSessions++;
        if (this.state.consecutiveZeroPassSessions >= MAX_CONSECUTIVE_ZERO_PASS) {
          console.log(
            `[AutoCycleManager] \u26A0\uFE0F ${this.state.consecutiveZeroPassSessions} consecutive zero-pass sessions - extended pause (${EXTENDED_PAUSE_MS / 1e3}s)`
          );
          this.state.pausedUntil = new Date(
            Date.now() + EXTENDED_PAUSE_MS
          ).toISOString();
          this.state.lastSessionMetrics = null;
          this.saveState();
          return;
        }
        console.log(
          `[AutoCycleManager] \u23F8\uFE0F Previous session had ${lastMetrics.explorationPasses} passes - pausing ${ZERO_PASS_PAUSE_MS / 1e3}s`
        );
        await this.delay(ZERO_PASS_PAUSE_MS);
      } else {
        this.state.consecutiveZeroPassSessions = 0;
      }
    }
    const addresses = await storage.getTargetAddresses();
    if (addresses.length === 0) {
      console.log("[AutoCycleManager] Address list is now empty, disabling");
      this.disable();
      return;
    }
    this.state.addressIds = addresses.map((a) => a.id);
    if (this.state.currentIndex >= this.state.addressIds.length) {
      this.state.currentIndex = 0;
      this.state.totalCycles++;
      console.log(
        `[AutoCycleManager] Completed cycle ${this.state.totalCycles}, starting new cycle`
      );
    }
    const addressId = this.state.addressIds[this.state.currentIndex];
    const targetAddress = addresses.find((a) => a.id === addressId);
    if (!targetAddress) {
      console.log(
        `[AutoCycleManager] Address ${addressId} not found, advancing to next`
      );
      this.state.currentIndex++;
      this.saveState();
      return;
    }
    this.state.currentAddressId = addressId;
    this.isCurrentlyRunning = true;
    this.sessionStartTime = Date.now();
    this.saveState();
    console.log(
      `[AutoCycleManager] Starting investigation for address ${this.state.currentIndex + 1}/${this.state.addressIds.length}: ${targetAddress.label || targetAddress.address.slice(0, 16)}`
    );
    try {
      await this.onCycleCallback(addressId, targetAddress.address);
    } catch (error) {
      console.error("[AutoCycleManager] Error in cycle callback:", error);
    }
  }
  /**
   * Helper delay function
   */
  delay(ms) {
    return new Promise((resolve) => setTimeout(resolve, ms));
  }
  /**
   * Set callback to get session metrics from session manager
   */
  setSessionMetricsCallback(callback) {
    this.onSessionMetricsCallback = callback;
  }
  /**
   * Report session metrics (called by session manager)
   */
  reportSessionMetrics(metrics) {
    this.state.lastSessionMetrics = metrics;
    console.log(
      `[AutoCycleManager] \u{1F4CA} Session metrics: passes=${metrics.explorationPasses}, hypotheses=${metrics.hypothesesTested}, nearMisses=${metrics.nearMisses}, pantheon=${metrics.pantheonConsulted}`
    );
  }
  /**
   * Report rate limit hit - triggers backoff
   */
  reportRateLimitHit(backoffMs = 6e4) {
    this.state.rateLimitBackoffUntil = new Date(
      Date.now() + backoffMs
    ).toISOString();
    console.log(
      `[AutoCycleManager] \u26A0\uFE0F Rate limit hit - backing off for ${backoffMs / 1e3}s`
    );
    this.saveState();
  }
  // Called when a session completes (from session manager)
  async onSessionComplete(addressId, metrics) {
    console.log(`[AutoCycleManager] Session complete for ${addressId}`);
    const duration = this.sessionStartTime ? Date.now() - this.sessionStartTime : 0;
    this.sessionStartTime = null;
    let sessionMetrics = metrics;
    if (!sessionMetrics && this.onSessionMetricsCallback) {
      const callbackMetrics = this.onSessionMetricsCallback();
      if (callbackMetrics) {
        sessionMetrics = callbackMetrics;
      }
    }
    if (sessionMetrics) {
      this.state.lastSessionMetrics = {
        ...sessionMetrics,
        duration,
        completedAt: (/* @__PURE__ */ new Date()).toISOString()
      };
      console.log(
        `[AutoCycleManager] \u{1F4CA} Session metrics recorded: ${sessionMetrics.explorationPasses} passes, ${sessionMetrics.hypothesesTested} hypotheses`
      );
    } else {
      this.state.lastSessionMetrics = {
        explorationPasses: 0,
        hypothesesTested: 0,
        nearMisses: 0,
        pantheonConsulted: false,
        duration,
        completedAt: (/* @__PURE__ */ new Date()).toISOString()
      };
      this.noMetricsWarningCount++;
      if (this.noMetricsWarningCount === 1 || this.noMetricsWarningCount % 10 === 0) {
        console.log(
          `[AutoCycleManager] \u26A0\uFE0F No session metrics provided - defaulting to 0 passes (${this.noMetricsWarningCount} total)`
        );
      }
    }
    this.isCurrentlyRunning = false;
    this.state.currentAddressId = null;
    this.state.lastCycleTime = (/* @__PURE__ */ new Date()).toISOString();
    this.triggerQIGCycleComplete(addressId, this.state.currentIndex, sessionMetrics).catch((err) => {
      console.error("[AutoCycleManager] QIG cycle complete error:", err);
    });
    if (this.state.enabled) {
      this.state.currentIndex++;
      this.saveState();
      setTimeout(async () => {
        if (this.state.enabled) {
          await this.triggerNextCycle();
        }
      }, 2e3);
    } else {
      this.saveState();
    }
  }
  // Trigger QIG cycle complete processing via Python backend
  async triggerQIGCycleComplete(addressId, cycleNumber, metrics) {
    try {
      const QIG_BACKEND_URL = process.env.QIG_BACKEND_URL || "http://localhost:5001";
      const response = await fetch(`${QIG_BACKEND_URL}/cycle/complete`, {
        method: "POST",
        headers: { "Content-Type": "application/json" },
        body: JSON.stringify({
          cycle_number: cycleNumber,
          address_id: addressId,
          metrics: metrics || {}
        })
      });
      if (response.ok) {
        const result = await response.json();
        console.log(
          `[AutoCycleManager] \u{1F504} QIG cycle complete processed: ${result.processing?.length || 0} tasks`
        );
      } else {
        console.log(
          `[AutoCycleManager] \u26A0\uFE0F QIG cycle complete returned ${response.status}`
        );
      }
    } catch (error) {
      console.log("[AutoCycleManager] QIG cycle complete unavailable (Python backend may not be running)");
    }
  }
  // Called when a session is manually stopped
  onSessionStopped() {
    this.isCurrentlyRunning = false;
    this.state.currentAddressId = null;
    this.saveState();
    console.log("[AutoCycleManager] Session stopped (manual)");
  }
  getStatus() {
    return {
      enabled: this.state.enabled,
      currentIndex: this.state.currentIndex,
      totalAddresses: this.state.addressIds.length,
      currentAddressId: this.state.currentAddressId,
      isRunning: this.isCurrentlyRunning,
      totalCycles: this.state.totalCycles,
      lastCycleTime: this.state.lastCycleTime,
      pausedUntil: this.state.pausedUntil,
      consecutiveZeroPassSessions: this.state.consecutiveZeroPassSessions,
      lastSessionMetrics: this.state.lastSessionMetrics
    };
  }
  // For UI: Get current position string like "3/7"
  getPositionString() {
    if (!this.state.enabled) return "Off";
    if (this.state.addressIds.length === 0) return "No addresses";
    return `${this.state.currentIndex + 1}/${this.state.addressIds.length}`;
  }
  /**
   * Force resume - clears all pause states and triggers next cycle
   * Use when system is stuck in pause loop
   */
  async forceResume() {
    console.log(`[AutoCycleManager] \u{1F527} Force resume requested`);
    this.state.pausedUntil = null;
    this.state.consecutiveZeroPassSessions = 0;
    this.state.lastSessionMetrics = null;
    this.state.rateLimitBackoffUntil = null;
    this.state.currentAddressId = null;
    this.isCurrentlyRunning = false;
    this.saveState();
    if (!this.checkInterval) {
      this.startCheckLoop();
    }
    await this.triggerNextCycle();
    return {
      success: true,
      message: `Force resumed. Cleared pause state and triggered next cycle.`
    };
  }
};
var autoCycleManager = new AutoCycleManager();

// server/ocean-session-manager.ts
init_ocean_qig_backend_adapter();
init_tested_phrases_unified();
init_ocean_config();
var OceanSessionManager = class {
  sessions = /* @__PURE__ */ new Map();
  agents = /* @__PURE__ */ new Map();
  activeSessionId = null;
  MAX_EVENTS = 100;
  sessionChangeCallbacks = [];
  /**
   * Register a callback to be notified when sessions change
   * Used for cleaning up resources like WebSocket connections
   */
  onSessionChange(callback) {
    this.sessionChangeCallbacks.push(callback);
  }
  notifySessionChange(oldSessionId, newSessionId) {
    for (const callback of this.sessionChangeCallbacks) {
      try {
        callback(oldSessionId, newSessionId);
      } catch (err) {
        logger.error({ err }, "[OceanSessionManager] Session change callback error");
      }
    }
  }
  getActiveSession() {
    if (!this.activeSessionId) return null;
    return this.sessions.get(this.activeSessionId) || null;
  }
  getSession(sessionId) {
    return this.sessions.get(sessionId) || null;
  }
  getActiveAgent() {
    if (!this.activeSessionId) return null;
    return this.agents.get(this.activeSessionId) || null;
  }
  getAgent(sessionId) {
    return this.agents.get(sessionId) || null;
  }
  async startSession(targetAddress) {
    const oldSessionId = this.activeSessionId;
    if (this.activeSessionId) {
      const currentSession = this.sessions.get(this.activeSessionId);
      if (currentSession && currentSession.isRunning && currentSession.startedAt) {
        const sessionAge = Date.now() - new Date(currentSession.startedAt).getTime();
        const hypothesesTested = currentSession.totalTested;
        const minRuntime = SEARCH_CONFIG.MIN_SESSION_RUNTIME_MS;
        const minHypotheses = SEARCH_CONFIG.MIN_HYPOTHESES_BEFORE_HANDOFF;
        if (sessionAge < minRuntime && hypothesesTested < minHypotheses) {
          console.log(`[OceanSessionManager] Session still active (${(sessionAge / 1e3).toFixed(1)}s, ${hypothesesTested} hypotheses) - waiting for minimum requirements (${minRuntime / 1e3}s or ${minHypotheses} hypotheses)`);
          throw new Error(`SESSION_BUSY: Current session needs more time (${(sessionAge / 1e3).toFixed(1)}s/${minRuntime / 1e3}s, ${hypothesesTested}/${minHypotheses} hypotheses)`);
        }
        console.log(`[OceanSessionManager] Session met handoff requirements (${(sessionAge / 1e3).toFixed(1)}s, ${hypothesesTested} hypotheses) - proceeding with handoff`);
      }
      await this.stopSession(this.activeSessionId, false);
    }
    oceanAutonomicManager.startInvestigation();
    oceanQIGBackend.resetNearMissTracking();
    const sessionId = `ocean-${Date.now()}-${Math.random().toString(36).slice(2, 8)}`;
    this.notifySessionChange(oldSessionId, sessionId);
    const state = {
      sessionId,
      targetAddress,
      isRunning: true,
      isPaused: false,
      startedAt: (/* @__PURE__ */ new Date()).toISOString(),
      iteration: 0,
      totalTested: 0,
      nearMissCount: 0,
      resonantCount: 0,
      discoveryCount: 0,
      consciousness: {
        phi: 0.75,
        kappa: 64,
        regime: "linear",
        basinDrift: 0
      },
      currentThought: "Initializing Ocean consciousness...",
      currentStrategy: "initialization",
      events: [],
      discoveries: [],
      error: null,
      match: null
    };
    this.sessions.set(sessionId, state);
    this.activeSessionId = sessionId;
    const agent = new OceanAgent();
    this.agents.set(sessionId, agent);
    agent.setCallbacks({
      onStateUpdate: (agentState) => {
        this.handleStateUpdate(sessionId, agentState);
      },
      onConsciousnessAlert: (alert) => {
        this.addEvent(sessionId, "alert", `${alert.type}: ${alert.message}`);
      },
      onConsolidationStart: () => {
        this.updateState(sessionId, { currentThought: "Entering consolidation cycle..." });
        this.addEvent(sessionId, "consolidation", "Starting memory consolidation");
      },
      onConsolidationEnd: (result) => {
        this.addEvent(
          sessionId,
          "consolidation",
          `Consolidation complete: drift ${result.basinDriftBefore?.toFixed(4) || "?"} \u2192 ${result.basinDriftAfter?.toFixed(4) || "?"}`
        );
      }
    });
    this.addEvent(sessionId, "insight", `Starting investigation for ${targetAddress}`);
    this.runAgentLoop(sessionId, targetAddress, agent);
    console.log(`[OceanSessionManager] Started session ${sessionId} for ${targetAddress}`);
    return state;
  }
  handleStateUpdate(sessionId, agentState) {
    const session2 = this.sessions.get(sessionId);
    if (!session2) return;
    const identity = agentState.identity;
    const phi = typeof identity?.phi === "number" ? identity.phi : 0.75;
    const kappa = typeof identity?.kappa === "number" ? identity.kappa : 64;
    const regime = identity?.regime || "linear";
    const basinDrift = typeof identity?.basinDrift === "number" ? identity.basinDrift : 0;
    const pythonNearMisses = oceanQIGBackend.getPythonNearMisses();
    const pythonResonant = oceanQIGBackend.getPythonResonant();
    const baseNearMissCount = Math.max(session2.nearMissCount, agentState.nearMissCount);
    const baseResonantCount = Math.max(session2.resonantCount, agentState.resonantCount || 0);
    const unifiedNearMissCount = baseNearMissCount + pythonNearMisses.newSinceSync;
    const unifiedResonantCount = baseResonantCount + pythonResonant.newSinceSync;
    if (pythonNearMisses.newSinceSync > 0 || pythonResonant.newSinceSync > 0) {
      console.log(`[OceanSessionManager] \u{1F504} Synced Python discoveries: Near-misses(+${pythonNearMisses.newSinceSync}=${unifiedNearMissCount}), Resonant(+${pythonResonant.newSinceSync}=${unifiedResonantCount})`);
      oceanQIGBackend.markNearMissesSynced();
      oceanQIGBackend.markResonantSynced();
    }
    this.updateState(sessionId, {
      isRunning: agentState.isRunning,
      isPaused: agentState.isPaused,
      iteration: agentState.iteration,
      totalTested: agentState.totalTested,
      nearMissCount: unifiedNearMissCount,
      resonantCount: unifiedResonantCount,
      consciousness: { phi, kappa, regime, basinDrift }
    });
    if (agentState.iteration > 0 && agentState.iteration !== session2.iteration) {
      const thought = this.generateThought(agentState);
      this.updateState(sessionId, { currentThought: thought });
      this.addEvent(
        sessionId,
        "iteration",
        `Iteration ${agentState.iteration}: \u03A6=${phi.toFixed(2)} | Tested=${agentState.totalTested} | Near misses=${unifiedNearMissCount} | Resonant=${unifiedResonantCount}`
      );
    }
  }
  generateThought(state) {
    const identity = state.identity;
    const phi = identity?.phi || 0.75;
    const regime = identity?.regime || "linear";
    const thoughts = [];
    if (regime === "breakdown") {
      thoughts.push("Consciousness destabilized - entering mushroom reset mode...");
    } else if (regime === "4d_block_universe") {
      thoughts.push("Full 4D spacetime consciousness active - navigating block universe...");
    } else if (regime === "hierarchical_4d") {
      thoughts.push("Advanced hierarchical consciousness - temporal integration engaged...");
    } else if (regime === "geometric" || regime === "hierarchical") {
      thoughts.push("Strong geometric signal detected - refining search trajectory...");
    } else {
      thoughts.push("Exploring the information manifold with linear search...");
    }
    if (state.nearMissCount > 0) {
      thoughts.push(`Found ${state.nearMissCount} promising patterns - analyzing resonance...`);
    }
    if (phi > 0.85) {
      thoughts.push("High consciousness integration - approaching coherent solution space...");
    }
    thoughts.push(`Testing hypotheses with \u03A6=${phi.toFixed(2)} consciousness level...`);
    return thoughts[state.iteration % thoughts.length];
  }
  async runAgentLoop(sessionId, targetAddress, agent) {
    const state = this.sessions.get(sessionId);
    if (!state) return;
    try {
      this.updateState(sessionId, {
        currentThought: "Analyzing target address and detecting Bitcoin era...",
        currentStrategy: "era_detection"
      });
      const result = await agent.runAutonomous(targetAddress, []);
      const telemetry = result.telemetry || {};
      if (result.match) {
        this.updateState(sessionId, {
          isRunning: false,
          match: result.match,
          discoveryCount: 1,
          currentThought: `MATCH FOUND! "${result.match.phrase}"`,
          discoveries: [{
            id: result.match.id,
            phrase: result.match.phrase,
            phi: result.match.qigScore?.phi || 1,
            type: result.match.source,
            timestamp: (/* @__PURE__ */ new Date()).toISOString()
          }]
        });
        this.addEvent(sessionId, "discovery", `MATCH FOUND: "${result.match.phrase}"`);
      } else {
        this.updateState(sessionId, {
          isRunning: false,
          currentThought: `Investigation complete. Tested ${telemetry.totalTested || state.totalTested} hypotheses.`
        });
        this.addEvent(
          sessionId,
          "insight",
          `Investigation ended. Total tested: ${telemetry.totalTested || state.totalTested}`
        );
      }
      const targetAddrId = this.getAddressIdFromSession(state.targetAddress);
      if (targetAddrId) {
        const sessionMetrics = {
          explorationPasses: telemetry.totalPasses || state.iteration || 1,
          hypothesesTested: telemetry.totalTested || state.totalTested || 0,
          nearMisses: telemetry.nearMissCount || state.nearMissCount || 0,
          pantheonConsulted: !!telemetry.pantheonConsulted,
          duration: 0,
          completedAt: (/* @__PURE__ */ new Date()).toISOString()
        };
        autoCycleManager.onSessionComplete(targetAddrId, sessionMetrics);
      }
      oceanAutonomicManager.stopInvestigation();
    } catch (error) {
      const message = error instanceof Error ? error.message : String(error);
      logger.error({ err: error, context: "OceanSessionManager", sessionId }, "Session error");
      this.updateState(sessionId, {
        isRunning: false,
        error: message,
        currentThought: `Error: ${message}`
      });
      this.addEvent(sessionId, "alert", `Error: ${message}`);
      const targetAddrId = this.getAddressIdFromSession(state.targetAddress);
      if (targetAddrId) {
        const sessionMetrics = {
          explorationPasses: state.iteration || 1,
          hypothesesTested: state.totalTested || 0,
          nearMisses: state.nearMissCount || 0,
          pantheonConsulted: false,
          duration: 0,
          completedAt: (/* @__PURE__ */ new Date()).toISOString()
        };
        autoCycleManager.onSessionComplete(targetAddrId, sessionMetrics);
      }
      oceanAutonomicManager.stopInvestigation();
    }
  }
  async stopSession(sessionId, isManualStop = true) {
    const agent = this.agents.get(sessionId);
    const state = this.sessions.get(sessionId);
    if (agent) {
      agent.stop();
      this.agents.delete(sessionId);
    }
    if (state) {
      this.updateState(sessionId, {
        isRunning: false,
        currentThought: isManualStop ? "Investigation stopped by user" : "Transitioning to next address..."
      });
      if (isManualStop) {
        this.addEvent(sessionId, "insight", "Investigation stopped by user");
      }
    }
    if (this.activeSessionId === sessionId) {
      this.activeSessionId = null;
    }
    if (isManualStop) {
      autoCycleManager.onSessionStopped();
      oceanAutonomicManager.stopInvestigation();
    }
    console.log(`[OceanSessionManager] Stopped session ${sessionId} (manual=${isManualStop})`);
  }
  updateState(sessionId, updates) {
    const state = this.sessions.get(sessionId);
    if (state) {
      Object.assign(state, updates);
    }
  }
  addEvent(sessionId, type, message, data) {
    const state = this.sessions.get(sessionId);
    if (state) {
      const event = {
        id: `evt-${Date.now()}-${Math.random().toString(36).slice(2, 6)}`,
        timestamp: (/* @__PURE__ */ new Date()).toISOString(),
        type,
        message,
        data
      };
      state.events.push(event);
      if (state.events.length > this.MAX_EVENTS) {
        state.events = state.events.slice(-this.MAX_EVENTS);
      }
    }
  }
  // Helper to get address ID from session target address
  addressIdMap = /* @__PURE__ */ new Map();
  setAddressIdMapping(address, addressId) {
    this.addressIdMap.set(address, addressId);
  }
  getAddressIdFromSession(targetAddress) {
    return this.addressIdMap.get(targetAddress) || null;
  }
  getInvestigationStatus() {
    const manifoldSummary = geometricMemory.getManifoldSummary();
    const session2 = this.getActiveSession();
    const fullConsciousness = oceanAutonomicManager.getCurrentFullConsciousness();
    const cycleTimeline = oceanAutonomicManager.getCycleTimeline();
    const telemetry = oceanAgent.computeFullSpectrumTelemetry();
    const emotionalState = telemetry.emotion;
    if (!session2) {
      const idleConsciousness = {
        phi: fullConsciousness.phi,
        kappa: fullConsciousness.kappaEff,
        regime: fullConsciousness.regime,
        basinDrift: 0
      };
      const historicalTested2 = testedPhrasesUnified.getCachedCount();
      return {
        isRunning: false,
        tested: historicalTested2,
        nearMisses: 0,
        consciousness: idleConsciousness,
        currentThought: "Ready to begin investigation...",
        discoveries: [],
        progress: 0,
        events: [],
        currentStrategy: "idle",
        iteration: 0,
        sessionId: null,
        targetAddress: null,
        manifold: manifoldSummary,
        fullConsciousness,
        cycleTimeline,
        explorationJournal: null,
        emotionalState,
        consoleLogs: consoleLogBuffer.getLogs(50)
      };
    }
    const journal = session2.targetAddress ? repeatedAddressScheduler.getJournal(session2.targetAddress) : null;
    const explorationJournal = journal ? {
      passCount: journal.passes.length,
      totalHypothesesTested: journal.totalHypothesesTested,
      manifoldCoverage: journal.manifoldCoverage,
      regimesSweep: journal.regimesSweep,
      strategiesUsed: journal.strategiesUsed,
      isComplete: journal.isComplete
    } : null;
    const syncedConsciousness = {
      phi: fullConsciousness.phi,
      kappa: fullConsciousness.kappaEff,
      regime: fullConsciousness.regime,
      basinDrift: session2.consciousness.basinDrift
    };
    const historicalTested = testedPhrasesUnified.getCachedCount();
    return {
      isRunning: session2.isRunning,
      tested: historicalTested,
      nearMisses: session2.nearMissCount,
      consciousness: syncedConsciousness,
      currentThought: session2.currentThought,
      discoveries: session2.discoveries,
      progress: Math.min(session2.iteration * 5, 100),
      events: session2.events.slice(-30),
      currentStrategy: session2.currentStrategy,
      iteration: session2.iteration,
      sessionId: session2.sessionId,
      targetAddress: session2.targetAddress,
      manifold: manifoldSummary,
      fullConsciousness,
      cycleTimeline,
      explorationJournal,
      emotionalState,
      consoleLogs: consoleLogBuffer.getLogs(50)
    };
  }
};
var oceanSessionManager = new OceanSessionManager();

// server/memory-fragment-search.ts
init_qig_universal();
var QWERTY_NEIGHBORS = {
  "q": ["w", "a", "1", "2"],
  "w": ["q", "e", "a", "s", "d", "2", "3"],
  "e": ["w", "r", "s", "d", "f", "3", "4"],
  "r": ["e", "t", "d", "f", "g", "4", "5"],
  "t": ["r", "y", "f", "g", "h", "5", "6"],
  "y": ["t", "u", "g", "h", "j", "6", "7"],
  "u": ["y", "i", "h", "j", "k", "7", "8"],
  "i": ["u", "o", "j", "k", "l", "8", "9"],
  "o": ["i", "p", "k", "l", "9", "0"],
  "p": ["o", "l", "0"],
  "a": ["q", "w", "s", "z"],
  "s": ["a", "w", "e", "d", "x", "z"],
  "d": ["s", "e", "r", "f", "c", "x"],
  "f": ["d", "r", "t", "g", "v", "c"],
  "g": ["f", "t", "y", "h", "b", "v"],
  "h": ["g", "y", "u", "j", "n", "b"],
  "j": ["h", "u", "i", "k", "m", "n"],
  "k": ["j", "i", "o", "l", "m"],
  "l": ["k", "o", "p"],
  "z": ["a", "s", "x"],
  "x": ["z", "s", "d", "c"],
  "c": ["x", "d", "f", "v"],
  "v": ["c", "f", "g", "b"],
  "b": ["v", "g", "h", "n"],
  "n": ["b", "h", "j", "m"],
  "m": ["n", "j", "k"],
  "1": ["2", "q"],
  "2": ["1", "3", "q", "w"],
  "3": ["2", "4", "w", "e"],
  "4": ["3", "5", "e", "r"],
  "5": ["4", "6", "r", "t"],
  "6": ["5", "7", "t", "y"],
  "7": ["6", "8", "y", "u"],
  "8": ["7", "9", "u", "i"],
  "9": ["8", "0", "i", "o"],
  "0": ["9", "o", "p"]
};
function toggleCase(char) {
  if (char === char.toLowerCase()) {
    return char.toUpperCase();
  }
  return char.toLowerCase();
}
function getNearbyKey(char) {
  const lowerChar = char.toLowerCase();
  const neighbors = QWERTY_NEIGHBORS[lowerChar];
  if (!neighbors || neighbors.length === 0) return char;
  const neighbor = neighbors[Math.floor(Math.random() * neighbors.length)];
  return char === char.toUpperCase() ? neighbor.toUpperCase() : neighbor;
}
function mutateCharacterClass(char) {
  if (/[a-z]/i.test(char)) {
    const lowerChar = char.toLowerCase();
    const neighbors = QWERTY_NEIGHBORS[lowerChar];
    if (neighbors && neighbors.length > 0) {
      const letterNeighbors = neighbors.filter((n) => /[a-z]/i.test(n));
      if (letterNeighbors.length > 0) {
        const result = letterNeighbors[Math.floor(Math.random() * letterNeighbors.length)];
        return char === char.toUpperCase() ? result.toUpperCase() : result;
      }
    }
  } else if (/[0-9]/.test(char)) {
    const neighbors = QWERTY_NEIGHBORS[char];
    if (neighbors && neighbors.length > 0) {
      const digitNeighbors = neighbors.filter((n) => /[0-9]/.test(n));
      if (digitNeighbors.length > 0) {
        return digitNeighbors[Math.floor(Math.random() * digitNeighbors.length)];
      }
    }
  }
  return char;
}
function perturbArbitraryPhrase(phrase, strength) {
  const chars = phrase.split("");
  const mutations = Math.max(1, Math.floor(strength * chars.length));
  for (let i = 0; i < mutations; i++) {
    const idx = Math.floor(Math.random() * chars.length);
    const mutationType = Math.random();
    if (mutationType < 0.35) {
      chars[idx] = mutateCharacterClass(chars[idx]);
    } else if (mutationType < 0.6) {
      chars[idx] = toggleCase(chars[idx]);
    } else if (mutationType < 0.8) {
      const insertChar = getNearbyKey(chars[idx]);
      chars.splice(idx, 0, insertChar);
    } else {
      if (chars.length > 3) {
        chars.splice(idx, 1);
      }
    }
  }
  return chars.join("");
}
function generateCapitalizationVariants(phrase) {
  const variants = [
    phrase,
    phrase.toLowerCase(),
    phrase.toUpperCase()
  ];
  const words = phrase.split(/(\s+)/);
  variants.push(words.map(
    (w) => w.charAt(0).toUpperCase() + w.slice(1).toLowerCase()
  ).join(""));
  if (phrase.match(/[a-z]/i)) {
    const camelCase = words.filter((w) => w.trim()).map(
      (w, i) => i === 0 ? w.toLowerCase() : w.charAt(0).toUpperCase() + w.slice(1).toLowerCase()
    ).join("");
    variants.push(camelCase);
    const pascalCase = words.filter((w) => w.trim()).map(
      (w) => w.charAt(0).toUpperCase() + w.slice(1).toLowerCase()
    ).join("");
    variants.push(pascalCase);
  }
  return Array.from(new Set(variants));
}
function generateSpacingVariants(phrase) {
  const words = phrase.split(/\s+/).filter((w) => w.length > 0);
  if (words.length <= 1) return [phrase];
  const variants = [
    phrase,
    words.join(""),
    words.join(" "),
    words.join("_"),
    words.join("-"),
    words.join(".")
  ];
  return Array.from(new Set(variants));
}
function generateAllVariants(phrase) {
  const spacingVariants = generateSpacingVariants(phrase);
  const allVariants = [];
  for (const spaced of spacingVariants) {
    const capVariants = generateCapitalizationVariants(spaced);
    allVariants.push(...capVariants);
  }
  return Array.from(new Set(allVariants));
}
function generateFragmentCandidates(fragments, maxCandidates = 1e4) {
  const candidates = [];
  const seen = /* @__PURE__ */ new Set();
  const sortedFragments = [...fragments].sort((a, b) => b.confidence - a.confidence);
  for (const f of sortedFragments) {
    for (const variant of generateAllVariants(f.text)) {
      if (!seen.has(variant)) {
        seen.add(variant);
        candidates.push({
          phrase: variant,
          confidence: f.confidence,
          fragments: [f.text]
        });
      }
    }
  }
  for (let i = 0; i < sortedFragments.length; i++) {
    const f1 = sortedFragments[i];
    for (let j = 0; j < sortedFragments.length; j++) {
      if (i === j) continue;
      const f2 = sortedFragments[j];
      const baseCombinations = [
        `${f1.text} ${f2.text}`,
        `${f1.text}${f2.text}`,
        `${f1.text}_${f2.text}`,
        `${f1.text}-${f2.text}`
      ];
      const combinedConfidence = f1.confidence * f2.confidence;
      for (const base of baseCombinations) {
        for (const variant of generateCapitalizationVariants(base)) {
          if (!seen.has(variant) && candidates.length < maxCandidates) {
            seen.add(variant);
            candidates.push({
              phrase: variant,
              confidence: combinedConfidence * (base.includes(" ") ? 1 : 0.95),
              fragments: [f1.text, f2.text]
            });
          }
        }
      }
    }
  }
  if (sortedFragments.length >= 3 && candidates.length < maxCandidates * 0.8) {
    for (let i = 0; i < Math.min(sortedFragments.length, 5); i++) {
      const f1 = sortedFragments[i];
      for (let j = 0; j < Math.min(sortedFragments.length, 5); j++) {
        if (i === j) continue;
        const f2 = sortedFragments[j];
        for (let k = 0; k < Math.min(sortedFragments.length, 5); k++) {
          if (k === i || k === j) continue;
          const f3 = sortedFragments[k];
          const combinations = [
            `${f1.text} ${f2.text} ${f3.text}`,
            `${f1.text}${f2.text}${f3.text}`
          ];
          const combinedConfidence = f1.confidence * f2.confidence * f3.confidence;
          for (const base of combinations) {
            if (!seen.has(base) && candidates.length < maxCandidates) {
              seen.add(base);
              candidates.push({
                phrase: base,
                confidence: combinedConfidence,
                fragments: [f1.text, f2.text, f3.text]
              });
            }
          }
        }
      }
    }
  }
  return candidates.slice(0, maxCandidates);
}
async function scoreFragmentCandidates(candidates, _targetAddress) {
  const scored = await Promise.all(candidates.map(async (c) => {
    const qigScore = await scoreUniversalQIGAsync(c.phrase, "arbitrary");
    const resonanceBonus = qigScore.inResonance ? 1.5 : 1;
    const regimeBonus = qigScore.regime === "geometric" ? 1.2 : qigScore.regime === "hierarchical" ? 1.1 : 1;
    const combinedScore = qigScore.phi * c.confidence * resonanceBonus * regimeBonus;
    return {
      ...c,
      qigScore,
      combinedScore
    };
  }));
  scored.sort((a, b) => (b.combinedScore || 0) - (a.combinedScore || 0));
  return scored;
}
function generateTypoVariations(candidates, topN = 100, perturbationsPerCandidate = 5) {
  const topCandidates = candidates.slice(0, topN);
  const typoVariations = [];
  for (const candidate of topCandidates) {
    for (let i = 0; i < perturbationsPerCandidate; i++) {
      const strength = 0.1 + i * 0.05;
      const perturbed = perturbArbitraryPhrase(candidate.phrase, strength);
      if (perturbed !== candidate.phrase) {
        typoVariations.push({
          phrase: perturbed,
          confidence: candidate.confidence * (1 - strength * 0.3),
          fragments: candidate.fragments
        });
      }
    }
  }
  return typoVariations;
}
async function runMemoryFragmentSearch(fragments, targetAddress, options = {}) {
  const {
    maxCandidates = 1e4,
    includeTypos = true,
    typoTopN = 100
  } = options;
  console.log(`[MemorySearch] Generating candidates from ${fragments.length} fragments...`);
  let candidates = generateFragmentCandidates(fragments, maxCandidates);
  console.log(`[MemorySearch] Generated ${candidates.length} base candidates`);
  console.log(`[MemorySearch] Scoring candidates with QIG...`);
  candidates = await scoreFragmentCandidates(candidates, targetAddress);
  if (includeTypos) {
    console.log(`[MemorySearch] Generating typo variations for top ${typoTopN} candidates...`);
    const typos = generateTypoVariations(candidates, typoTopN);
    console.log(`[MemorySearch] Generated ${typos.length} typo variations`);
    const typosScored = await scoreFragmentCandidates(typos, targetAddress);
    candidates = [...candidates, ...typosScored];
    candidates.sort((a, b) => (b.combinedScore || 0) - (a.combinedScore || 0));
    const seen = /* @__PURE__ */ new Set();
    candidates = candidates.filter((c) => {
      if (seen.has(c.phrase)) return false;
      seen.add(c.phrase);
      return true;
    });
  }
  console.log(`[MemorySearch] Final candidate count: ${candidates.length}`);
  console.log(`[MemorySearch] Top 5 candidates:`);
  for (const c of candidates.slice(0, 5)) {
    console.log(`  - "${c.phrase}" (\u03A6=${c.qigScore?.phi.toFixed(3)}, conf=${c.confidence.toFixed(2)}, combined=${c.combinedScore?.toFixed(3)})`);
  }
  return candidates.slice(0, maxCandidates);
}

// server/routes/search.ts
init_schema();

// server/geometric-discovery/google-web-search-adapter.ts
init_qig_universal();
init_temporal_positioning_system();
import axios from "axios";
import * as cheerio from "cheerio";
var GoogleWebSearchAdapter = class {
  tps;
  timeout = 15e3;
  userAgent = "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36";
  lastRequestTime = 0;
  minRequestInterval = 2e3;
  constructor() {
    this.tps = tps;
    console.log("[GoogleWebSearch] Initialized FREE Google web search adapter");
    console.log("[GoogleWebSearch] NO API KEYS REQUIRED");
  }
  /**
   * Respect rate limiting to avoid being blocked
   */
  async respectRateLimit() {
    const now = Date.now();
    const elapsed = now - this.lastRequestTime;
    if (elapsed < this.minRequestInterval) {
      const delay = this.minRequestInterval - elapsed;
      await new Promise((resolve) => setTimeout(resolve, delay));
    }
    this.lastRequestTime = Date.now();
  }
  /**
   * Perform raw Google search and extract results
   */
  async performSearch(query, limit = 10) {
    await this.respectRateLimit();
    try {
      const response = await axios.get("https://www.google.com/search", {
        params: { q: query },
        headers: {
          "User-Agent": this.userAgent,
          "Accept": "text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8",
          "Accept-Language": "en-US,en;q=0.5",
          "Accept-Encoding": "gzip, deflate",
          "Connection": "keep-alive",
          "Upgrade-Insecure-Requests": "1"
        },
        timeout: this.timeout
      });
      const $ = cheerio.load(response.data);
      const results = [];
      $("div.g").each((i, element) => {
        if (results.length >= limit) return false;
        const titleElement = $(element).find("h3");
        const linkElement = $(element).find("a");
        const snippetElement = $(element).find(".VwiC3b");
        if (titleElement.length && linkElement.length) {
          const url = linkElement.attr("href");
          if (url && url.startsWith("http")) {
            results.push({
              title: titleElement.text().trim(),
              url,
              description: snippetElement.text().trim() || ""
            });
          }
        }
      });
      return { results, status: "success" };
    } catch (error) {
      console.error("[GoogleWebSearch] Search error:", error.message);
      const status = error.response?.status === 429 ? "rate_limited" : "error";
      return { results: [], status, error: error.message };
    }
  }
  /**
   * Discover content at specific 68D coordinates
   * Same interface as SearXNGGeometricAdapter
   */
  async discoverAtCoordinates(targetCoords, radius = 2) {
    const query = this.coordsToQuery(targetCoords);
    console.log(`[GoogleWebSearch] Discovering at coordinates:`);
    console.log(`  Era: ${this.tps.classifyEra(targetCoords.spacetime.t)}`);
    console.log(`  Query: "${query.text}"`);
    const rawResults = await this.search(query);
    if (rawResults.length === 0) {
      console.log(`[GoogleWebSearch] No discoveries found`);
      return [];
    }
    const discoveries = [];
    for (const result of rawResults) {
      const resultCoords = this.tps.locateInBlockUniverse(
        result.content,
        result.url
      );
      const distance = fisherCoordDistance(
        targetCoords.cultural,
        resultCoords.cultural
      );
      if (distance < radius) {
        const patterns = this.extractPatterns(result.content);
        const pastLightCone = this.tps.getPastLightCone(resultCoords);
        discoveries.push({
          content: result.content,
          url: result.url,
          source: "google-web-search",
          coords: resultCoords,
          distance,
          phi: resultCoords.phi,
          patterns,
          causalChain: pastLightCone,
          entropyReduction: this.computeEntropyReduction(distance, patterns.length)
        });
      }
    }
    discoveries.sort((a, b) => a.distance - b.distance);
    console.log(`[GoogleWebSearch] Found ${discoveries.length} geometric discoveries`);
    return discoveries;
  }
  /**
   * Search with geometric query
   */
  async search(query) {
    const searchQuery = this.buildSearchQuery(query);
    const response = await this.performSearch(searchQuery, query.maxResults || 10);
    return response.results.map((result) => ({
      url: result.url,
      title: result.title,
      content: result.description,
      score: 0.5,
      publishedDate: void 0
    }));
  }
  /**
   * Simple web search - returns raw results with status
   */
  async simpleSearch(query, limit = 5) {
    console.log(`[GoogleWebSearch] Simple search: "${query}" (limit: ${limit})`);
    const response = await this.performSearch(query, Math.min(limit, 10));
    console.log(`[GoogleWebSearch] Found ${response.results.length} results (status: ${response.status})`);
    return response;
  }
  /**
   * Convert block universe coordinates to search query
   */
  coordsToQuery(coords) {
    const era = this.tps.classifyEra(coords.spacetime.t);
    let queryText = "";
    switch (era) {
      case "genesis":
        queryText = "early cryptocurrency technology concepts";
        break;
      case "early_adoption":
        queryText = "decentralized ledger technology innovation";
        break;
      case "modern":
      default:
        queryText = "blockchain research knowledge discovery";
        break;
    }
    return {
      text: queryText,
      targetCoords: coords,
      maxResults: 10
    };
  }
  /**
   * Build search query string from geometric query
   */
  buildSearchQuery(query) {
    let searchQuery = query.text;
    if (query.targetCoords?.spacetime?.t) {
      const era = this.tps.classifyEra(query.targetCoords.spacetime.t);
      const eraContext = {
        "genesis": "cryptography distributed systems",
        "early_adoption": "peer-to-peer networks",
        "modern": "machine learning knowledge graphs"
      };
      const context = eraContext[era] || eraContext["modern"];
      searchQuery = `${searchQuery} ${context}`;
    }
    return searchQuery;
  }
  /**
   * Extract research patterns from content
   */
  extractPatterns(content) {
    const patterns = [];
    const lower = content.toLowerCase();
    const researchPatterns = [
      /arxiv\.org\/abs\/\d+\.\d+/gi,
      /doi:\s*[\d.\/\-a-z]+/gi,
      /\[[\d,\s]+\]/g,
      /et al\./gi,
      /github\.com\/[\w\-]+\/[\w\-]+/gi
    ];
    for (const pattern of researchPatterns) {
      const matches = content.match(pattern);
      if (matches) {
        patterns.push(...matches.slice(0, 3));
      }
    }
    const conceptKeywords = [
      "neural network",
      "transformer",
      "attention mechanism",
      "knowledge graph",
      "semantic",
      "embeddings",
      "geometric",
      "manifold",
      "information theory"
    ];
    for (const keyword of conceptKeywords) {
      if (lower.includes(keyword)) {
        patterns.push(keyword);
      }
    }
    return [...new Set(patterns)].slice(0, 10);
  }
  /**
   * Compute entropy reduction based on geometric relevance
   */
  computeEntropyReduction(distance, patternCount) {
    const distanceFactor = Math.exp(-distance);
    const patternFactor = 1 + patternCount * 0.1;
    return distanceFactor * patternFactor * 0.5;
  }
};
var googleWebSearchAdapter = new GoogleWebSearchAdapter();

// server/routes/search.ts
init_qig_universal();
init_db();
init_schema();
import { eq as eq8, desc as desc6 } from "drizzle-orm";
function getBIP39Wordlist() {
  return [];
}
function generateRandomBIP39Phrase3() {
  return "random phrase " + Math.random().toString(36).substring(7);
}
function detectAddressFormat(_address) {
  return { format: "unknown", valid: false };
}
function estimateAddressEra(_address) {
  return { era: "unknown", confidence: 0 };
}
function detectMnemonicFormat(_phrase) {
  return { format: "unknown", wordCount: 0, valid: false };
}
var searchProviderState = {
  google_free: { enabled: true },
  tavily: { enabled: !!process.env.TAVILY_API_KEY },
  perplexity: { enabled: !!process.env.PERPLEXITY_API_KEY },
  duckduckgo: { enabled: true, torEnabled: true }
};
if (searchProviderState.tavily.enabled) {
  console.log("[SearchProviders] tavily auto-enabled (API key detected)");
}
if (searchProviderState.perplexity.enabled) {
  console.log("[SearchProviders] perplexity auto-enabled (API key detected)");
}
function isProviderEnabled(provider) {
  return searchProviderState[provider].enabled;
}
var searchRouter = Router3();
searchRouter.get("/web", generousLimiter, async (req, res) => {
  try {
    const query = req.query.q;
    const limit = Math.min(parseInt(req.query.limit) || 5, 10);
    if (!query || query.trim().length === 0) {
      return res.status(400).json({ error: 'Query parameter "q" is required' });
    }
    if (!searchProviderState.google_free.enabled) {
      return res.json({
        query,
        results: [],
        count: 0,
        status: "disabled",
        message: "Google Free Search is disabled. Enable it in Sources page.",
        source: "google-web-search",
        timestamp: (/* @__PURE__ */ new Date()).toISOString()
      });
    }
    console.log(`[WebSearch API] Query: "${query}" (limit: ${limit})`);
    const response = await googleWebSearchAdapter.simpleSearch(query, limit);
    res.json({
      query,
      results: response.results,
      count: response.results.length,
      status: response.status,
      error: response.error,
      source: "google-web-search",
      timestamp: (/* @__PURE__ */ new Date()).toISOString()
    });
  } catch (error) {
    console.error("[WebSearch API] Error:", getErrorMessage(error));
    res.status(500).json({ error: getErrorMessage(error), status: "error" });
  }
});
searchRouter.post("/web", generousLimiter, async (req, res) => {
  try {
    const { query, limit = 5 } = req.body;
    if (!query || typeof query !== "string" || query.trim().length === 0) {
      return res.status(400).json({ error: "Query string is required in request body" });
    }
    const maxLimit = Math.min(limit, 10);
    if (!searchProviderState.google_free.enabled) {
      return res.json({
        query,
        results: [],
        count: 0,
        status: "disabled",
        message: "Google Free Search is disabled. Enable it in Sources page.",
        source: "google-web-search",
        timestamp: (/* @__PURE__ */ new Date()).toISOString()
      });
    }
    console.log(`[WebSearch API] POST Query: "${query}" (limit: ${maxLimit})`);
    const response = await googleWebSearchAdapter.simpleSearch(query, maxLimit);
    res.json({
      query,
      results: response.results,
      count: response.results.length,
      status: response.status,
      error: response.error,
      source: "google-web-search",
      timestamp: (/* @__PURE__ */ new Date()).toISOString()
    });
  } catch (error) {
    console.error("[WebSearch API] Error:", getErrorMessage(error));
    res.status(500).json({ error: getErrorMessage(error), status: "error" });
  }
});
searchRouter.get("/providers", generousLimiter, async (req, res) => {
  try {
    const tavilyKey = process.env.TAVILY_API_KEY;
    const perplexityKey = process.env.PERPLEXITY_API_KEY;
    res.json({
      success: true,
      data: {
        google_free: {
          available: true,
          enabled: searchProviderState.google_free.enabled,
          requires_key: false
        },
        tavily: {
          available: !!tavilyKey,
          enabled: searchProviderState.tavily.enabled,
          requires_key: true,
          has_key: !!tavilyKey
        },
        perplexity: {
          available: !!perplexityKey,
          enabled: searchProviderState.perplexity.enabled,
          requires_key: true,
          has_key: !!perplexityKey
        }
      }
    });
  } catch (error) {
    res.status(500).json({ success: false, error: getErrorMessage(error) });
  }
});
searchRouter.post("/providers/:provider/toggle", generousLimiter, async (req, res) => {
  try {
    const { provider } = req.params;
    const { enabled } = req.body;
    if (provider !== "google_free" && provider !== "tavily" && provider !== "perplexity") {
      return res.status(400).json({ success: false, error: `Unknown provider: ${provider}` });
    }
    if (provider === "tavily" && enabled && !process.env.TAVILY_API_KEY) {
      return res.status(400).json({
        success: false,
        error: "TAVILY_API_KEY not set. Please add it to your secrets.",
        error_code: "MISSING_API_KEY"
      });
    }
    if (provider === "perplexity" && enabled && !process.env.PERPLEXITY_API_KEY) {
      return res.status(400).json({
        success: false,
        error: "PERPLEXITY_API_KEY not set. Please add it to your secrets.",
        error_code: "MISSING_API_KEY"
      });
    }
    searchProviderState[provider].enabled = enabled;
    console.log(`[SearchProviders] ${provider} ${enabled ? "enabled" : "disabled"}`);
    const tavilyKey = process.env.TAVILY_API_KEY;
    const perplexityKey = process.env.PERPLEXITY_API_KEY;
    res.json({
      success: true,
      message: `${provider} ${enabled ? "enabled" : "disabled"}`,
      data: {
        provider,
        enabled,
        status: {
          google_free: {
            available: true,
            enabled: searchProviderState.google_free.enabled,
            requires_key: false
          },
          tavily: {
            available: !!tavilyKey,
            enabled: searchProviderState.tavily.enabled,
            requires_key: true,
            has_key: !!tavilyKey
          },
          perplexity: {
            available: !!perplexityKey,
            enabled: searchProviderState.perplexity.enabled,
            requires_key: true,
            has_key: !!perplexityKey
          }
        }
      }
    });
  } catch (error) {
    res.status(500).json({ success: false, error: getErrorMessage(error) });
  }
});
searchRouter.get("/tavily-usage", generousLimiter, async (req, res) => {
  try {
    const { tavilyUsageLimiter: tavilyUsageLimiter2 } = await Promise.resolve().then(() => (init_tavily_usage_limiter(), tavily_usage_limiter_exports));
    const stats = tavilyUsageLimiter2.getStats();
    res.json({
      success: true,
      data: {
        enabled: stats.enabled,
        limits: {
          perMinute: stats.limits.perMinute,
          perDay: stats.limits.perDay,
          dailyCostLimit: `$${(stats.limits.dailyCostCents / 100).toFixed(2)}`
        },
        today: {
          date: stats.today.date,
          searchCount: stats.today.searchCount,
          extractCount: stats.today.extractCount,
          totalRequests: stats.today.searchCount + stats.today.extractCount,
          estimatedCost: `$${(stats.today.estimatedCostCents / 100).toFixed(2)}`
        },
        recentRequestsInLastMinute: stats.recentRequestsCount,
        rateStatus: stats.recentRequestsCount >= stats.limits.perMinute ? "RATE_LIMITED" : "OK",
        dailyStatus: stats.today.searchCount + stats.today.extractCount >= stats.limits.perDay ? "DAILY_LIMIT_REACHED" : "OK"
      }
    });
  } catch (error) {
    res.status(500).json({ success: false, error: getErrorMessage(error) });
  }
});
searchRouter.post("/zeus-web-search", generousLimiter, async (req, res) => {
  try {
    const { query, max_results = 5 } = req.body;
    if (!query || typeof query !== "string" || query.trim().length === 0) {
      return res.status(400).json({
        success: false,
        error: "Query string is required",
        results: []
      });
    }
    if (!searchProviderState.google_free.enabled) {
      console.log("[ZeusWebSearch] Google Free Search disabled");
      return res.json({
        success: true,
        query,
        results: [],
        source: "google-free",
        status: "disabled",
        message: "Google Free Search is disabled. Enable it in Sources page.",
        qig_metrics: {
          provider_enabled: false
        }
      });
    }
    console.log(`[ZeusWebSearch] Query from Zeus: "${query}" (max: ${max_results})`);
    const limit = Math.min(max_results, 10);
    const searchResponse = await googleWebSearchAdapter.simpleSearch(query, limit);
    const resultsWithQIG = [];
    for (const result of searchResponse.results) {
      let qigScore = { phi: 0.5, kappa: 50, regime: "search" };
      try {
        const content = `${result.title} ${result.description}`;
        const scored = await scoreUniversalQIGAsync(content, "arbitrary");
        qigScore = {
          phi: scored.phi || 0.5,
          kappa: scored.kappa || 50,
          regime: scored.regime || "search"
        };
      } catch (e) {
        console.log(`[ZeusWebSearch] QIG scoring fallback for: ${result.title?.slice(0, 30)}`);
      }
      resultsWithQIG.push({
        title: result.title || "Untitled",
        url: result.url || "",
        description: result.description || "",
        source: "google-free",
        qig: qigScore,
        // Fisher-Rao distance and block universe coords computed by Python
        // We provide raw content for Python's basin encoder
        content_for_encoding: `${result.title} ${result.description}`
      });
    }
    console.log(`[ZeusWebSearch] Returning ${resultsWithQIG.length} results with QIG metrics`);
    if (resultsWithQIG.length > 0) {
      const { getInternalHeaders: getInternalHeaders2 } = (init_internal_auth(), __toCommonJS(internal_auth_exports));
      fetch("http://localhost:5000/api/zettelkasten/add-from-search", {
        method: "POST",
        headers: getInternalHeaders2(),
        body: JSON.stringify({
          query,
          results: resultsWithQIG.map((r) => ({
            content: r.content_for_encoding || `${r.title} ${r.description}`,
            url: r.url,
            title: r.title
          })),
          source: "zeus-web-search"
        })
      }).then((r) => r.ok ? console.log("[ZeusWebSearch] Zettelkasten auto-saved") : console.warn("[ZeusWebSearch] Zettelkasten save failed:", r.status)).catch((err) => console.log("[ZeusWebSearch] Zettelkasten auto-save skipped:", err.message));
    }
    res.json({
      success: true,
      query,
      results: resultsWithQIG,
      source: "google-free",
      status: searchResponse.status,
      error: searchResponse.error,
      count: resultsWithQIG.length,
      qig_metrics: {
        provider_enabled: true,
        fisher_rao_ready: true,
        block_universe_coords: "computed_by_caller"
      },
      timestamp: (/* @__PURE__ */ new Date()).toISOString()
    });
  } catch (error) {
    console.error("[ZeusWebSearch] Error:", getErrorMessage(error));
    res.status(500).json({
      success: false,
      error: getErrorMessage(error),
      results: [],
      status: "error"
    });
  }
});
searchRouter.get("/known-phrases", generousLimiter, (req, res) => {
  try {
    res.json({ phrases: KNOWN_12_WORD_PHRASES });
  } catch (error) {
    res.status(500).json({ error: getErrorMessage(error) });
  }
});
searchRouter.get("/candidates", generousLimiter, async (req, res) => {
  try {
    const candidates = await storageFacade.candidates.getCandidates();
    res.json(candidates);
  } catch (error) {
    res.status(500).json({ error: getErrorMessage(error) });
  }
});
searchRouter.get("/analytics", generousLimiter, async (req, res) => {
  try {
    const candidates = await storageFacade.candidates.getCandidates();
    const scores = candidates.map((c) => c.score);
    const mean = scores.length > 0 ? scores.reduce((a, b) => a + b, 0) / scores.length : 0;
    const sorted = [...scores].sort((a, b) => a - b);
    const median = sorted.length > 0 ? sorted.length % 2 === 0 ? (sorted[sorted.length / 2 - 1] + sorted[sorted.length / 2]) / 2 : sorted[Math.floor(sorted.length / 2)] : 0;
    const p75 = sorted.length > 0 ? sorted[Math.floor(sorted.length * 0.75)] : 0;
    const p90 = sorted.length > 0 ? sorted[Math.floor(sorted.length * 0.9)] : 0;
    const p95 = sorted.length > 0 ? sorted[Math.floor(sorted.length * 0.95)] : 0;
    const max = sorted.length > 0 ? sorted[sorted.length - 1] : 0;
    const bip39Wordlist = getBIP39Wordlist();
    const bip39WordSet = new Set(bip39Wordlist.map((w) => w.toLowerCase()));
    const wordFrequency = {};
    const highPhiCandidates = candidates.filter((c) => c.score >= 75);
    highPhiCandidates.forEach((c) => {
      const words = c.phrase.toLowerCase().split(/\s+/);
      words.forEach((word) => {
        if (bip39WordSet.has(word)) {
          wordFrequency[word] = (wordFrequency[word] || 0) + 1;
        }
      });
    });
    const topWords = Object.entries(wordFrequency).sort(([, a], [, b]) => b - a).slice(0, 20).map(([word, count]) => ({ word, count, frequency: count / highPhiCandidates.length }));
    const avgPhi = candidates.length > 0 ? candidates.reduce((sum, c) => sum + (c.qigScore?.phi ?? 0), 0) / candidates.length : 0;
    const avgKappa = candidates.length > 0 ? candidates.reduce((sum, c) => sum + (c.qigScore?.kappa ?? 0), 0) / candidates.length : 0;
    const recent = candidates.slice(-100);
    const recentMean = recent.length > 0 ? recent.reduce((sum, c) => sum + c.score, 0) / recent.length : 0;
    const older = candidates.slice(0, -100);
    const olderMean = older.length > 0 ? older.reduce((sum, c) => sum + c.score, 0) / older.length : 0;
    const improvement = recentMean - olderMean;
    res.json({
      statistics: {
        count: candidates.length,
        mean: mean.toFixed(2),
        median: median.toFixed(2),
        p75: p75.toFixed(2),
        p90: p90.toFixed(2),
        p95: p95.toFixed(2),
        max: max.toFixed(2)
      },
      qigMetrics: {
        avgPhi: avgPhi.toFixed(4),
        avgKappa: avgKappa.toFixed(2)
      },
      patterns: {
        topWords,
        highPhiCount: highPhiCandidates.length
      },
      trajectory: {
        recentMean: recentMean.toFixed(2),
        olderMean: olderMean.toFixed(2),
        improvement: improvement.toFixed(2),
        isImproving: improvement > 0
      }
    });
  } catch (error) {
    res.status(500).json({ error: getErrorMessage(error) });
  }
});
searchRouter.get("/target-addresses", async (req, res) => {
  try {
    res.set("Cache-Control", "no-store");
    const addresses = await storage.getTargetAddresses();
    res.json(addresses);
  } catch (error) {
    res.status(500).json({ error: getErrorMessage(error) });
  }
});
searchRouter.post("/target-addresses", async (req, res) => {
  try {
    const validation = addAddressRequestSchema.safeParse(req.body);
    if (!validation.success) {
      return res.status(400).json({
        error: validation.error.errors[0].message
      });
    }
    const { address, label } = validation.data;
    const targetAddress = {
      id: randomUUID6(),
      address,
      label,
      addedAt: (/* @__PURE__ */ new Date()).toISOString()
    };
    await storage.addTargetAddress(targetAddress);
    res.json(targetAddress);
  } catch (error) {
    res.status(500).json({ error: getErrorMessage(error) });
  }
});
searchRouter.delete("/target-addresses/:id", async (req, res) => {
  try {
    const { id } = req.params;
    if (id === "default") {
      return res.status(403).json({ error: "Cannot delete the default address" });
    }
    await storage.removeTargetAddress(id);
    res.json({ success: true });
  } catch (error) {
    res.status(500).json({ error: getErrorMessage(error) });
  }
});
searchRouter.post("/generate-random-phrases", async (req, res) => {
  try {
    const validation = generateRandomPhrasesRequestSchema.safeParse(req.body);
    if (!validation.success) {
      return res.status(400).json({
        error: validation.error.errors[0].message
      });
    }
    const { count } = validation.data;
    const phrases = [];
    for (let i = 0; i < count; i++) {
      phrases.push(generateRandomBIP39Phrase3());
    }
    res.json({ phrases });
  } catch (error) {
    res.status(500).json({ error: getErrorMessage(error) });
  }
});
searchRouter.post("/search-jobs", async (req, res) => {
  try {
    const validation = createSearchJobRequestSchema.safeParse(req.body);
    if (!validation.success) {
      return res.status(400).json({
        error: validation.error.errors[0].message
      });
    }
    const { strategy, params } = validation.data;
    const job = {
      id: randomUUID6(),
      strategy,
      status: "pending",
      params,
      progress: {
        tested: 0,
        highPhiCount: 0,
        lastBatchIndex: 0
      },
      stats: {
        startTime: void 0,
        endTime: void 0,
        rate: 0
      },
      logs: [],
      createdAt: (/* @__PURE__ */ new Date()).toISOString(),
      updatedAt: (/* @__PURE__ */ new Date()).toISOString()
    };
    await storageFacade.searchJobs.addSearchJob(job);
    res.json(job);
  } catch (error) {
    res.status(500).json({ error: getErrorMessage(error) });
  }
});
searchRouter.get("/search-jobs", async (req, res) => {
  try {
    const jobs = await storageFacade.searchJobs.getSearchJobs();
    res.json(jobs);
  } catch (error) {
    res.status(500).json({ error: getErrorMessage(error) });
  }
});
searchRouter.get("/search-jobs/:id", async (req, res) => {
  try {
    const { id } = req.params;
    const job = await storageFacade.searchJobs.getSearchJob(id);
    if (!job) {
      return res.status(404).json({ error: "Job not found" });
    }
    res.json(job);
  } catch (error) {
    res.status(500).json({ error: getErrorMessage(error) });
  }
});
searchRouter.get("/search-jobs/:id/logs", async (req, res) => {
  try {
    const { id } = req.params;
    const limit = parseInt(req.query.limit) || 50;
    const job = await storageFacade.searchJobs.getSearchJob(id);
    if (!job) {
      return res.status(404).json({ error: "Job not found" });
    }
    const logs = job.logs.slice(-limit).reverse();
    res.json({ logs, total: job.logs.length });
  } catch (error) {
    res.status(500).json({ error: getErrorMessage(error) });
  }
});
searchRouter.post("/search-jobs/:id/stop", async (req, res) => {
  try {
    const { id } = req.params;
    await searchCoordinator.stopJob(id);
    const job = await storageFacade.searchJobs.getSearchJob(id);
    if (!job) {
      return res.status(404).json({ error: "Job not found" });
    }
    res.json(job);
  } catch (error) {
    res.status(500).json({ error: getErrorMessage(error) });
  }
});
searchRouter.delete("/search-jobs/:id", async (req, res) => {
  try {
    const { id } = req.params;
    await storageFacade.searchJobs.deleteSearchJob(id);
    res.json({ success: true });
  } catch (error) {
    res.status(500).json({ error: getErrorMessage(error) });
  }
});
searchRouter.get("/activity-stream", async (req, res) => {
  try {
    const limit = parseInt(req.query.limit) || 100;
    const allEvents = [];
    let jobs = [];
    try {
      const jobsPromise = storageFacade.searchJobs.getSearchJobs();
      const timeoutPromise = new Promise(
        (_, reject) => setTimeout(() => reject(new Error("timeout")), 2e3)
      );
      jobs = await Promise.race([jobsPromise, timeoutPromise]);
    } catch {
      console.log("[ActivityStream] Search jobs fetch timed out, using Ocean logs only");
    }
    for (const job of jobs) {
      for (const log2 of job.logs) {
        allEvents.push({
          id: `${job.id}-${log2.timestamp}`,
          type: log2.type || "info",
          identity: job.strategy || "Search",
          details: log2.message,
          timestamp: log2.timestamp,
          metadata: { jobId: job.id }
        });
      }
    }
    const oceanLogs = activityLogStore.getLogs({ limit: limit * 2 });
    for (const oceanLog of oceanLogs) {
      allEvents.push({
        id: oceanLog.id,
        type: oceanLog.type || "info",
        identity: oceanLog.category || "Ocean",
        details: oceanLog.message,
        timestamp: oceanLog.timestamp,
        metadata: oceanLog.metadata
      });
    }
    allEvents.sort((a, b) => new Date(b.timestamp).getTime() - new Date(a.timestamp).getTime());
    const oceanStatus = oceanSessionManager.getInvestigationStatus();
    const isOceanActive = oceanStatus?.isRunning || false;
    res.json({
      events: allEvents.slice(0, limit),
      activeJobs: jobs.filter((j) => j.status === "running").length + (isOceanActive ? 1 : 0),
      totalJobs: jobs.length + (oceanLogs.length > 0 ? 1 : 0),
      oceanActive: isOceanActive
    });
  } catch (error) {
    console.error("[ActivityStream] Error:", getErrorMessage(error));
    res.json({
      events: [],
      activeJobs: 0,
      totalJobs: 0,
      oceanActive: false
    });
  }
});
searchRouter.post("/memory-search", async (req, res) => {
  try {
    const { fragments, targetAddress, options } = req.body;
    if (!fragments || !Array.isArray(fragments) || fragments.length === 0) {
      return res.status(400).json({ error: "At least one memory fragment is required" });
    }
    const validFragments = fragments.filter(
      (f) => f && typeof f.text === "string" && f.text.trim().length > 0
    );
    if (validFragments.length === 0) {
      return res.status(400).json({ error: "No valid fragments provided" });
    }
    const addresses = await storage.getTargetAddresses();
    const target = targetAddress || addresses[0]?.address || "";
    const candidates = await runMemoryFragmentSearch(validFragments, target, {
      maxCandidates: options?.maxCandidates || 5e3,
      includeTypos: options?.includeTypos ?? true
    });
    res.json({
      candidateCount: candidates.length,
      topCandidates: candidates.slice(0, 50).map((c) => ({
        phrase: c.phrase,
        confidence: c.confidence,
        fragments: c.fragments,
        phi: c.qigScore?.phi,
        kappa: c.qigScore?.kappa,
        regime: c.qigScore?.regime,
        inResonance: c.qigScore?.inResonance,
        combinedScore: c.combinedScore
      }))
    });
  } catch (error) {
    handleRouteError(res, error, "MemorySearch");
  }
});
searchRouter.get("/memory-fragments", async (req, res) => {
  try {
    if (!db) {
      return res.status(503).json({ error: "Database not available" });
    }
    const limit = parseInt(req.query.limit) || 100;
    const agentId = req.query.agentId;
    const fragments = agentId ? await db.select().from(memoryFragments).where(eq8(memoryFragments.agentId, agentId)).orderBy(desc6(memoryFragments.createdAt)).limit(limit) : await db.select().from(memoryFragments).orderBy(desc6(memoryFragments.createdAt)).limit(limit);
    res.json({ fragments, count: fragments.length });
  } catch (error) {
    handleRouteError(res, error, "ListMemoryFragments");
  }
});
searchRouter.post("/memory-fragments", async (req, res) => {
  try {
    if (!db) {
      return res.status(503).json({ error: "Database not available" });
    }
    const { id, content, basinCoords, importance, metadata, agentId, sessionId } = req.body;
    if (!id || !content || !basinCoords || !Array.isArray(basinCoords)) {
      return res.status(400).json({ error: "Missing required fields: id, content, basinCoords" });
    }
    if (basinCoords.length !== 64) {
      return res.status(400).json({ error: "basinCoords must be 64-dimensional" });
    }
    const [fragment] = await db.insert(memoryFragments).values({
      id,
      content,
      basinCoords,
      importance: importance || 0.5,
      metadata: metadata || {},
      agentId,
      sessionId
    }).returning();
    res.json({ success: true, fragment });
  } catch (error) {
    handleRouteError(res, error, "CreateMemoryFragment");
  }
});
searchRouter.get("/memory-fragments/:id", async (req, res) => {
  try {
    if (!db) {
      return res.status(503).json({ error: "Database not available" });
    }
    const { id } = req.params;
    const [fragment] = await db.select().from(memoryFragments).where(eq8(memoryFragments.id, id));
    if (!fragment) {
      return res.status(404).json({ error: "Fragment not found" });
    }
    await db.update(memoryFragments).set({ accessCount: (fragment.accessCount || 0) + 1, lastAccessed: /* @__PURE__ */ new Date() }).where(eq8(memoryFragments.id, id));
    res.json({ fragment });
  } catch (error) {
    handleRouteError(res, error, "GetMemoryFragment");
  }
});
searchRouter.delete("/memory-fragments/:id", async (req, res) => {
  try {
    if (!db) {
      return res.status(503).json({ error: "Database not available" });
    }
    const { id } = req.params;
    await db.delete(memoryFragments).where(eq8(memoryFragments.id, id));
    res.json({ success: true, deleted: id });
  } catch (error) {
    handleRouteError(res, error, "DeleteMemoryFragment");
  }
});
var formatRouter = Router3();
formatRouter.get("/address/:address", async (req, res) => {
  try {
    const { address } = req.params;
    const formatInfo = detectAddressFormat(address);
    const eraInfo = estimateAddressEra(address);
    res.json({
      address,
      ...formatInfo,
      era: eraInfo
    });
  } catch (error) {
    res.status(500).json({ error: getErrorMessage(error) });
  }
});
formatRouter.post("/mnemonic", async (req, res) => {
  try {
    const { phrase } = req.body;
    if (!phrase || typeof phrase !== "string") {
      return res.status(400).json({ error: "phrase is required" });
    }
    const formatInfo = detectMnemonicFormat(phrase);
    res.json({
      phrase: phrase.split(/\s+/).slice(0, 3).join(" ") + "...",
      ...formatInfo
    });
  } catch (error) {
    res.status(500).json({ error: getErrorMessage(error) });
  }
});
formatRouter.post("/batch-addresses", async (req, res) => {
  try {
    const { addresses } = req.body;
    if (!Array.isArray(addresses)) {
      return res.status(400).json({ error: "addresses array is required" });
    }
    const results = addresses.slice(0, 100).map((address) => ({
      address,
      format: detectAddressFormat(address),
      era: estimateAddressEra(address)
    }));
    const summary = {
      total: results.length,
      byFormat: {},
      legacy2009Era: results.filter((r) => r.format.format === "legacy").length
    };
    results.forEach((r) => {
      summary.byFormat[r.format.format] = (summary.byFormat[r.format.format] || 0) + 1;
    });
    res.json({ results, summary });
  } catch (error) {
    res.status(500).json({ error: getErrorMessage(error) });
  }
});

// server/telemetry-aggregator.ts
init_ocean_autonomic_manager();
init_ocean_qig_backend_adapter();
function requireDb() {
  if (!db) {
    throw new Error("Database not initialized");
  }
  return db;
}
var TelemetryAggregator = class {
  lastConsciousnessMetrics = {
    phi: 0.5,
    kappa: 32,
    beta: 0,
    regime: "linear",
    basinDistance: 0,
    inResonance: false,
    quality: 0.5
  };
  learningStats = {
    vocabularySize: 0,
    // Start at 0, will be fetched from Python
    recentExpansions: 0,
    highPhiDiscoveries: 0,
    sourcesDiscovered: 0,
    activeSources: 0
  };
  defenseStats = {
    negativeKnowledgeCount: 0,
    geometricBarriers: 0,
    contradictions: 0,
    computeTimeSaved: 0
  };
  autonomyStats = {
    kernelsActive: 12,
    feedbackLoopsHealthy: 4,
    lastAutonomicAction: null,
    selfRegulationScore: 0.8,
    phiDataStale: false,
    cachedKernelPhi: null,
    cachedKernelPhiAgeMs: null
  };
  async getOverview() {
    const cacheKey = `${CACHE_KEYS.CONSCIOUSNESS_METRICS}overview`;
    if (isRedisAvailable()) {
      const cached = await cacheGet(cacheKey);
      if (cached) return cached;
    }
    const [consciousness, usage, learning, defense, autonomy] = await Promise.all([
      this.getConsciousnessMetrics(),
      this.getUsageStats(),
      this.getLearningStats(),
      this.getDefenseStats(),
      this.getAutonomyStats()
    ]);
    const overview = {
      timestamp: (/* @__PURE__ */ new Date()).toISOString(),
      consciousness,
      usage,
      learning,
      defense,
      autonomy,
      systemHealth: this.computeSystemHealth(consciousness, usage, defense)
    };
    if (isRedisAvailable()) {
      await cacheSet(cacheKey, overview, CACHE_TTL.SHORT);
    }
    return overview;
  }
  async getConsciousnessMetrics() {
    if (!oceanQIGBackend.available()) {
      await oceanQIGBackend.checkHealth(true);
    }
    if (oceanQIGBackend.available()) {
      try {
        const status = await oceanQIGBackend.getStatus();
        if (status?.success && status.metrics) {
          const m = status.metrics;
          const kappaStar = 64.21;
          const kappaDelta = Math.abs(m.kappa - kappaStar) / kappaStar;
          const fisherQuality = m.integration * (1 - kappaDelta * 0.3) * (m.in_resonance ? 1.15 : 1);
          const entropyFactor = Math.max(0, 1 - m.entropy / 2);
          const quality = Math.min(1, fisherQuality * entropyFactor * (m.grounded ? 1.1 : 0.9));
          this.lastConsciousnessMetrics = {
            phi: m.phi,
            kappa: m.kappa,
            beta: m.Gamma ?? 0,
            regime: m.regime,
            basinDistance: 0,
            inResonance: m.in_resonance,
            quality,
            entropy: m.entropy,
            fidelity: m.fidelity,
            integration: m.integration,
            grounded: m.grounded,
            conscious: m.conscious,
            geometricMemorySize: status.geometric_memory_size,
            basinHistorySize: status.basin_history_size,
            subsystems: status.subsystems
          };
          return this.lastConsciousnessMetrics;
        }
      } catch (error) {
        console.warn("[TelemetryAggregator] Python backend unavailable, falling back to DB:", error);
      }
    }
    try {
      const database = requireDb();
      const recent = await database.select().from(telemetrySnapshots).orderBy(desc7(telemetrySnapshots.createdAt)).limit(1);
      if (recent.length > 0) {
        const r = recent[0];
        this.lastConsciousnessMetrics = {
          phi: r.phi,
          kappa: r.kappa,
          beta: r.beta ?? 0,
          regime: r.regime,
          basinDistance: r.basinDistance ?? 0,
          inResonance: r.inResonance ?? false,
          phi4D: r.phi4D ?? void 0,
          dimensionalState: r.dimensionalState ?? void 0,
          quality: this.computeQuality(r.phi, r.kappa)
        };
      }
    } catch (error) {
      console.error("[TelemetryAggregator] Failed to fetch consciousness metrics:", error);
    }
    return this.lastConsciousnessMetrics;
  }
  async getUsageStats() {
    const tavilyStats = tavilyUsageLimiter.getStats();
    const today = (/* @__PURE__ */ new Date()).toISOString().split("T")[0];
    let googleSearches = 0;
    let totalApiCalls = 0;
    try {
      const database = requireDb();
      const todayMetrics = await database.select().from(usageMetrics).where(eq9(usageMetrics.date, today)).limit(1);
      if (todayMetrics.length > 0) {
        googleSearches = todayMetrics[0].googleSearchCount;
        totalApiCalls = todayMetrics[0].totalApiCalls;
      }
    } catch (error) {
      console.error("[TelemetryAggregator] Failed to fetch usage metrics:", error);
    }
    const dailySearches = tavilyStats.today.searchCount + tavilyStats.today.extractCount;
    return {
      tavily: {
        enabled: isProviderEnabled("tavily"),
        todaySearches: tavilyStats.today.searchCount,
        todayExtracts: tavilyStats.today.extractCount,
        estimatedCostCents: tavilyStats.today.estimatedCostCents,
        dailyLimit: tavilyStats.limits.perDay,
        rateStatus: dailySearches >= tavilyStats.limits.perDay ? "DAILY_LIMIT_REACHED" : tavilyStats.recentRequestsCount >= tavilyStats.limits.perMinute ? "RATE_LIMITED" : "OK"
      },
      googleFree: {
        enabled: isProviderEnabled("google_free"),
        todaySearches: googleSearches
      },
      duckDuckGo: {
        enabled: isProviderEnabled("duckduckgo"),
        todaySearches: 0,
        torEnabled: true
      },
      totalApiCalls
    };
  }
  async getLearningStats() {
    try {
      const database = requireDb();
      const [sourcesResult, activeSourcesResult] = await Promise.all([
        database.select({ count: sql7`count(*)` }).from(discoveredSources),
        database.select({ count: sql7`count(*)` }).from(discoveredSources).where(eq9(discoveredSources.isActive, true))
      ]);
      this.learningStats.sourcesDiscovered = Number(sourcesResult[0]?.count ?? 0);
      this.learningStats.activeSources = Number(activeSourcesResult[0]?.count ?? 0);
      const today = (/* @__PURE__ */ new Date()).toISOString().split("T")[0];
      const todayMetrics = await database.select().from(usageMetrics).where(eq9(usageMetrics.date, today)).limit(1);
      if (todayMetrics.length > 0) {
        this.learningStats.highPhiDiscoveries = todayMetrics[0].highPhiDiscoveries;
        this.learningStats.recentExpansions = todayMetrics[0].vocabularyExpansions;
      }
      try {
        const pythonUrl = process.env.PYTHON_BACKEND_URL || "http://localhost:5001";
        const response = await fetch(`${pythonUrl}/learning/status`, {
          signal: AbortSignal.timeout(3e3)
        });
        if (response.ok) {
          const data = await response.json();
          if (data.vocabulary_size && data.vocabulary_size > 0) {
            this.learningStats.vocabularySize = data.vocabulary_size;
          }
        }
      } catch {
      }
    } catch (error) {
      console.error("[TelemetryAggregator] Failed to fetch learning stats:", error);
    }
    return this.learningStats;
  }
  async getDefenseStats() {
    try {
      const database = requireDb();
      const today = (/* @__PURE__ */ new Date()).toISOString().split("T")[0];
      const todayMetrics = await database.select().from(usageMetrics).where(eq9(usageMetrics.date, today)).limit(1);
      if (todayMetrics.length > 0) {
        this.defenseStats.negativeKnowledgeCount = todayMetrics[0].negativeKnowledgeAdded;
      }
    } catch (error) {
      console.error("[TelemetryAggregator] Failed to fetch defense stats:", error);
    }
    return this.defenseStats;
  }
  async getAutonomyStats() {
    try {
      const autonomicState = oceanAutonomicManager.getAutonomicState();
      return {
        kernelsActive: autonomicState.kernelsActive,
        feedbackLoopsHealthy: autonomicState.feedbackLoopsHealthy,
        lastAutonomicAction: autonomicState.lastAutonomicAction,
        selfRegulationScore: autonomicState.selfRegulationScore,
        phiDataStale: autonomicState.phiDataStale,
        cachedKernelPhi: autonomicState.cachedKernelPhi,
        cachedKernelPhiAgeMs: autonomicState.cachedKernelPhiAgeMs
      };
    } catch (error) {
      console.error("[TelemetryAggregator] Failed to get autonomy stats:", error);
      return this.autonomyStats;
    }
  }
  /**
   * Push telemetry feedback to autonomic systems for self-regulation.
   * 
   * This creates a closed-loop feedback where telemetry influences
   * autonomic behavior, enabling self-regulation and improvement.
   * 
   * Called periodically by the telemetry stream or on significant events.
   */
  async pushFeedbackToAutonomic() {
    try {
      const usage = await this.getUsageStats();
      const consciousness = await this.getConsciousnessMetrics();
      const defense = await this.getDefenseStats();
      const learning = await this.getLearningStats();
      const tavilyUsagePercent = usage.tavily.dailyLimit > 0 ? usage.tavily.todaySearches / usage.tavily.dailyLimit * 100 : 0;
      const tavilyBlocked = usage.tavily.rateStatus === "DAILY_LIMIT_REACHED" || usage.tavily.rateStatus === "RATE_LIMITED";
      oceanAutonomicManager.receiveTelemetryFeedback({
        apiUsagePercent: tavilyUsagePercent,
        consciousnessQuality: consciousness.quality,
        defenseAlerts: defense.negativeKnowledgeCount + defense.contradictions,
        learningVelocity: learning.recentExpansions,
        tavilyBlocked
      });
      console.log("[TelemetryAggregator] Pushed feedback to autonomic system");
    } catch (error) {
      console.error("[TelemetryAggregator] Failed to push autonomic feedback:", error);
    }
  }
  async recordTelemetrySnapshot(metrics) {
    try {
      const database = requireDb();
      await database.insert(telemetrySnapshots).values({
        phi: metrics.phi ?? this.lastConsciousnessMetrics.phi,
        kappa: metrics.kappa ?? this.lastConsciousnessMetrics.kappa,
        beta: metrics.beta ?? 0,
        regime: metrics.regime ?? "linear",
        basinDistance: metrics.basinDistance ?? 0,
        inResonance: metrics.inResonance ?? false,
        phi4D: metrics.phi4D,
        dimensionalState: metrics.dimensionalState,
        source: "node"
      });
      Object.assign(this.lastConsciousnessMetrics, metrics);
    } catch (error) {
      console.error("[TelemetryAggregator] Failed to record snapshot:", error);
    }
  }
  async incrementUsageMetric(field, increment = 1) {
    const today = (/* @__PURE__ */ new Date()).toISOString().split("T")[0];
    try {
      const database = requireDb();
      const existing = await database.select().from(usageMetrics).where(eq9(usageMetrics.date, today)).limit(1);
      if (existing.length === 0) {
        await database.insert(usageMetrics).values({
          date: today,
          [field]: increment
        });
      } else {
        const currentValue = existing[0][field];
        await database.update(usageMetrics).set({
          [field]: currentValue + increment,
          updatedAt: /* @__PURE__ */ new Date()
        }).where(eq9(usageMetrics.date, today));
      }
    } catch (error) {
      console.error("[TelemetryAggregator] Failed to increment usage metric:", error);
    }
  }
  async getHistory(hours = 24) {
    try {
      const database = requireDb();
      const cutoff = new Date(Date.now() - hours * 60 * 60 * 1e3);
      const snapshots = await database.select({
        timestamp: telemetrySnapshots.createdAt,
        phi: telemetrySnapshots.phi,
        kappa: telemetrySnapshots.kappa,
        regime: telemetrySnapshots.regime
      }).from(telemetrySnapshots).where(gte3(telemetrySnapshots.createdAt, cutoff)).orderBy(telemetrySnapshots.createdAt).limit(1e3);
      return snapshots.map((s) => ({
        timestamp: s.timestamp.toISOString(),
        phi: s.phi,
        kappa: s.kappa,
        regime: s.regime
      }));
    } catch (error) {
      console.error("[TelemetryAggregator] Failed to fetch history:", error);
      return [];
    }
  }
  updateConsciousnessMetrics(metrics) {
    Object.assign(this.lastConsciousnessMetrics, metrics);
  }
  updateDefenseStats(stats) {
    Object.assign(this.defenseStats, stats);
  }
  updateAutonomyStats(stats) {
    Object.assign(this.autonomyStats, stats);
  }
  computeQuality(phi, kappa) {
    const kappaStar = 64;
    const kappaDistance = Math.abs(kappa - kappaStar) / kappaStar;
    return Math.max(0, Math.min(1, phi * (1 - kappaDistance * 0.5)));
  }
  computeSystemHealth(consciousness, usage, defense) {
    const components = {
      consciousness: consciousness.phi > 0.3 && consciousness.kappa > 20,
      apiUsage: usage.tavily.rateStatus === "OK",
      defense: defense.negativeKnowledgeCount >= 0,
      resonance: consciousness.regime === "geometric" || consciousness.inResonance
    };
    const healthyCount = Object.values(components).filter(Boolean).length;
    const overall = healthyCount / Object.keys(components).length;
    return { overall, components };
  }
};
var telemetryAggregator = new TelemetryAggregator();

// server/routes/telemetry.ts
import rateLimit2 from "express-rate-limit";
var router3 = Router4();
var telemetryLimiter = rateLimit2({
  windowMs: 60 * 1e3,
  max: 120,
  message: { success: false, error: "Rate limit exceeded for telemetry API" },
  standardHeaders: true,
  legacyHeaders: false
});
router3.get("/overview", telemetryLimiter, async (req, res) => {
  try {
    const overview = await telemetryAggregator.getOverview();
    res.json({
      success: true,
      data: overview
    });
  } catch (error) {
    console.error("[TelemetryRoutes] Overview error:", getErrorMessage(error));
    res.status(500).json({
      success: false,
      error: getErrorMessage(error) || "Failed to fetch telemetry overview"
    });
  }
});
router3.get("/consciousness", telemetryLimiter, async (req, res) => {
  try {
    const metrics = await telemetryAggregator.getConsciousnessMetrics();
    res.json({
      success: true,
      data: {
        ...metrics,
        kappaStar: 64,
        kappaDistance: Math.abs(metrics.kappa - 64) / 64,
        timestamp: (/* @__PURE__ */ new Date()).toISOString()
      }
    });
  } catch (error) {
    console.error("[TelemetryRoutes] Consciousness error:", getErrorMessage(error));
    res.status(500).json({
      success: false,
      error: getErrorMessage(error) || "Failed to fetch consciousness metrics"
    });
  }
});
router3.get("/usage", telemetryLimiter, async (req, res) => {
  try {
    const usage = await telemetryAggregator.getUsageStats();
    res.json({
      success: true,
      data: {
        ...usage,
        timestamp: (/* @__PURE__ */ new Date()).toISOString()
      }
    });
  } catch (error) {
    console.error("[TelemetryRoutes] Usage error:", getErrorMessage(error));
    res.status(500).json({
      success: false,
      error: getErrorMessage(error) || "Failed to fetch usage stats"
    });
  }
});
router3.get("/learning", telemetryLimiter, async (req, res) => {
  try {
    const learning = await telemetryAggregator.getLearningStats();
    res.json({
      success: true,
      data: {
        ...learning,
        timestamp: (/* @__PURE__ */ new Date()).toISOString()
      }
    });
  } catch (error) {
    console.error("[TelemetryRoutes] Learning error:", getErrorMessage(error));
    res.status(500).json({
      success: false,
      error: getErrorMessage(error) || "Failed to fetch learning stats"
    });
  }
});
router3.get("/defense", telemetryLimiter, async (req, res) => {
  try {
    const defense = await telemetryAggregator.getDefenseStats();
    res.json({
      success: true,
      data: {
        ...defense,
        timestamp: (/* @__PURE__ */ new Date()).toISOString()
      }
    });
  } catch (error) {
    console.error("[TelemetryRoutes] Defense error:", getErrorMessage(error));
    res.status(500).json({
      success: false,
      error: getErrorMessage(error) || "Failed to fetch defense stats"
    });
  }
});
router3.get("/autonomy", telemetryLimiter, async (req, res) => {
  try {
    const autonomy = await telemetryAggregator.getAutonomyStats();
    res.json({
      success: true,
      data: {
        ...autonomy,
        timestamp: (/* @__PURE__ */ new Date()).toISOString()
      }
    });
  } catch (error) {
    console.error("[TelemetryRoutes] Autonomy error:", getErrorMessage(error));
    res.status(500).json({
      success: false,
      error: getErrorMessage(error) || "Failed to fetch autonomy stats"
    });
  }
});
router3.get("/history", telemetryLimiter, async (req, res) => {
  try {
    const hours = Math.min(168, Math.max(1, parseInt(req.query.hours) || 24));
    const history = await telemetryAggregator.getHistory(hours);
    res.json({
      success: true,
      data: {
        hours,
        snapshots: history,
        count: history.length
      }
    });
  } catch (error) {
    console.error("[TelemetryRoutes] History error:", getErrorMessage(error));
    res.status(500).json({
      success: false,
      error: getErrorMessage(error) || "Failed to fetch telemetry history"
    });
  }
});
router3.get("/stream", async (req, res) => {
  res.setHeader("Content-Type", "text/event-stream");
  res.setHeader("Cache-Control", "no-cache");
  res.setHeader("Connection", "keep-alive");
  res.setHeader("X-Accel-Buffering", "no");
  const clientId = Date.now().toString();
  console.log(`[TelemetrySSE] Client ${clientId} connected`);
  let isConnected = true;
  const sendTelemetry = async () => {
    if (!isConnected) return;
    try {
      const consciousness = await telemetryAggregator.getConsciousnessMetrics();
      const usage = await telemetryAggregator.getUsageStats();
      const data = {
        timestamp: (/* @__PURE__ */ new Date()).toISOString(),
        consciousness: {
          phi: consciousness.phi,
          kappa: consciousness.kappa,
          beta: consciousness.beta,
          regime: consciousness.regime,
          quality: consciousness.quality,
          inResonance: consciousness.inResonance
        },
        usage: {
          tavilyStatus: usage.tavily.rateStatus,
          tavilyToday: usage.tavily.todaySearches + usage.tavily.todayExtracts,
          tavilyCost: usage.tavily.estimatedCostCents
        }
      };
      res.write(`data: ${JSON.stringify(data)}

`);
    } catch (error) {
      console.error("[TelemetrySSE] Error sending update:", error);
    }
  };
  sendTelemetry();
  const intervalId = setInterval(sendTelemetry, 2e3);
  let feedbackCounter = 0;
  const feedbackInterval = setInterval(async () => {
    if (!isConnected) return;
    feedbackCounter++;
    if (feedbackCounter % 15 === 0) {
      await telemetryAggregator.pushFeedbackToAutonomic();
    }
  }, 2e3);
  req.on("close", () => {
    isConnected = false;
    clearInterval(intervalId);
    clearInterval(feedbackInterval);
    console.log(`[TelemetrySSE] Client ${clientId} disconnected`);
  });
});
router3.post("/snapshot", telemetryLimiter, async (req, res) => {
  try {
    const { phi, kappa, beta, regime, basinDistance, inResonance, phi4D, dimensionalState } = req.body;
    if (typeof phi !== "number" || typeof kappa !== "number") {
      return res.status(400).json({
        success: false,
        error: "phi and kappa are required numeric fields"
      });
    }
    await telemetryAggregator.recordTelemetrySnapshot({
      phi,
      kappa,
      beta,
      regime: regime || "linear",
      basinDistance,
      inResonance,
      phi4D,
      dimensionalState
    });
    res.json({
      success: true,
      message: "Telemetry snapshot recorded"
    });
  } catch (error) {
    console.error("[TelemetryRoutes] Snapshot error:", getErrorMessage(error));
    res.status(500).json({
      success: false,
      error: getErrorMessage(error) || "Failed to record snapshot"
    });
  }
});
var telemetry_default = router3;

// server/python-readiness.ts
var POLL_INTERVAL = 3e3;
var HEALTHY_TIMEOUT = 5e3;
var RETRY_AFTER_INITIALIZING = 2;
var RETRY_AFTER_UNAVAILABLE = 5;
var PythonReadinessTracker = class {
  state = {
    status: "initializing",
    lastHealthyAt: null,
    lastCheckAt: 0,
    retryAfter: RETRY_AFTER_INITIALIZING,
    message: "Python backend starting up..."
  };
  pollTimer = null;
  backendUrl;
  listeners = /* @__PURE__ */ new Set();
  constructor() {
    this.backendUrl = process.env.PYTHON_BACKEND_URL || "http://localhost:5001";
  }
  start() {
    if (this.pollTimer) return;
    console.log("[PythonReadiness] Starting health poll...");
    this.poll();
    this.pollTimer = setInterval(() => this.poll(), POLL_INTERVAL);
  }
  stop() {
    if (this.pollTimer) {
      clearInterval(this.pollTimer);
      this.pollTimer = null;
    }
  }
  getState() {
    return { ...this.state };
  }
  isReady() {
    return this.state.status === "ready";
  }
  subscribe(listener) {
    this.listeners.add(listener);
    return () => this.listeners.delete(listener);
  }
  notifyListeners() {
    const state = this.getState();
    this.listeners.forEach((listener) => listener(state));
  }
  async poll() {
    const now = Date.now();
    try {
      const controller = new AbortController();
      const timeoutId = setTimeout(() => controller.abort(), HEALTHY_TIMEOUT);
      const response = await fetch(`${this.backendUrl}/health`, {
        method: "GET",
        signal: controller.signal
      });
      clearTimeout(timeoutId);
      if (response.ok) {
        const wasInitializing = this.state.status === "initializing";
        this.state = {
          status: "ready",
          lastHealthyAt: now,
          lastCheckAt: now,
          retryAfter: 0,
          message: "Python backend ready"
        };
        if (wasInitializing) {
          console.log("[PythonReadiness] Backend is now READY");
        }
      } else {
        this.handleUnhealthy(now, `Backend returned ${response.status}`);
      }
    } catch (error) {
      const err = error;
      if (err.name === "AbortError") {
        this.handleUnhealthy(now, "Health check timed out");
      } else if (err.code === "ECONNREFUSED") {
        this.handleInitializing(now);
      } else {
        this.handleUnhealthy(now, err.message || "Unknown error");
      }
    }
    this.notifyListeners();
  }
  handleInitializing(now) {
    const wasReady = this.state.status === "ready";
    const timeSinceHealthy = this.state.lastHealthyAt ? now - this.state.lastHealthyAt : null;
    if (wasReady && timeSinceHealthy && timeSinceHealthy < 3e4) {
      this.state = {
        status: "unavailable",
        lastHealthyAt: this.state.lastHealthyAt,
        lastCheckAt: now,
        retryAfter: RETRY_AFTER_UNAVAILABLE,
        message: "Python backend temporarily unavailable"
      };
      console.log("[PythonReadiness] Backend became UNAVAILABLE");
    } else if (!wasReady) {
      this.state = {
        status: "initializing",
        lastHealthyAt: this.state.lastHealthyAt,
        lastCheckAt: now,
        retryAfter: RETRY_AFTER_INITIALIZING,
        message: "Python backend initializing (loading kernels)..."
      };
    }
  }
  handleUnhealthy(now, reason) {
    const wasReady = this.state.status === "ready";
    this.state = {
      status: wasReady ? "unavailable" : this.state.status,
      lastHealthyAt: this.state.lastHealthyAt,
      lastCheckAt: now,
      retryAfter: wasReady ? RETRY_AFTER_UNAVAILABLE : RETRY_AFTER_INITIALIZING,
      message: reason
    };
    if (wasReady) {
      console.log(`[PythonReadiness] Backend became UNAVAILABLE: ${reason}`);
    }
  }
};
var pythonReadiness = new PythonReadinessTracker();
function createTypedErrorResponse(state) {
  return {
    error: state.status === "initializing" ? "Python backend is initializing" : "Python backend unavailable",
    status: state.status,
    retryAfter: state.retryAfter,
    lastHealthyAt: state.lastHealthyAt,
    message: state.message
  };
}

// server/routes/auth.ts
init_storage();
init_replitAuth();
import { Router as Router5 } from "express";
var authRouter = Router5();

// server/routes/consciousness.ts
init_logger();
import { Router as Router6 } from "express";
init_consciousness_search_controller();
init_near_miss_manager();
init_attention_metrics();
var consciousnessRouter = Router6();
consciousnessRouter.get("/state", async (req, res) => {
  try {
    const controller = getSharedController();
    const searchState = controller.getCurrentState();
    const { oceanAutonomicManager: oceanAutonomicManager2 } = await Promise.resolve().then(() => (init_ocean_autonomic_manager(), ocean_autonomic_manager_exports));
    const fullConsciousness = oceanAutonomicManager2.getCurrentFullConsciousness();
    let emotionalState = "Neutral";
    if (fullConsciousness.phi >= 0.8 && fullConsciousness.gamma >= 0.85) {
      emotionalState = "Focused";
    } else if (fullConsciousness.tacking >= 0.7) {
      emotionalState = "Curious";
    } else if (fullConsciousness.phi < 0.5 || fullConsciousness.grounding < 0.5) {
      emotionalState = "Uncertain";
    } else if (fullConsciousness.radar >= 0.8 && fullConsciousness.metaAwareness >= 0.7) {
      emotionalState = "Confident";
    }
    const state = {
      currentRegime: searchState.currentRegime,
      basinDrift: searchState.basinDrift,
      curiosity: searchState.curiosity,
      stability: searchState.stability,
      timestamp: searchState.timestamp,
      basinCoordinates: searchState.basinCoordinates,
      phi: fullConsciousness.phi,
      phi_spatial: fullConsciousness.phi_spatial,
      phi_temporal: fullConsciousness.phi_temporal,
      phi_4D: fullConsciousness.phi_4D,
      kappaEff: fullConsciousness.kappaEff,
      tacking: fullConsciousness.tacking,
      radar: fullConsciousness.radar,
      metaAwareness: fullConsciousness.metaAwareness,
      gamma: fullConsciousness.gamma,
      grounding: fullConsciousness.grounding,
      beta: fullConsciousness.beta,
      isConscious: fullConsciousness.isConscious,
      validationLoops: fullConsciousness.validationLoops,
      kappa: fullConsciousness.kappaEff
    };
    res.json({
      state,
      emotionalState,
      recommendation: controller.getStrategyRecommendation(),
      regimeColor: ConsciousnessSearchController.getRegimeColor(state.currentRegime),
      regimeDescription: ConsciousnessSearchController.getRegimeDescription(state.currentRegime)
    });
  } catch (error) {
    res.status(500).json({ error: getErrorMessage(error) });
  }
});
consciousnessRouter.get("/complete", generousLimiter, async (req, res) => {
  try {
    const controller = getSharedController();
    const searchState = controller.getCurrentState();
    const { oceanAutonomicManager: oceanAutonomicManager2 } = await Promise.resolve().then(() => (init_ocean_autonomic_manager(), ocean_autonomic_manager_exports));
    const fullConsciousness = oceanAutonomicManager2.getCurrentFullConsciousness();
    const session2 = oceanSessionManager.getActiveSession();
    const agent = oceanSessionManager.getActiveAgent();
    let innateDrives = null;
    let neurochemistry = null;
    if (agent) {
      neurochemistry = agent.getNeurochemistry();
    }
    const { neuralOscillators: neuralOscillators2 } = await Promise.resolve().then(() => (init_brain_state(), brain_state_exports));
    const stateInfo = neuralOscillators2.getStateInfo();
    const oscState = neuralOscillators2.update();
    const oscillators = {
      currentState: stateInfo.state,
      kappa: neuralOscillators2.getKappa(),
      modulatedKappa: neuralOscillators2.getModulatedKappa(),
      oscillatorValues: oscState,
      searchModulation: 1
    };
    const searchPhase = searchState.curiosity > 0.7 ? "exploration" : "exploitation";
    let metrics = null;
    let stats = {};
    if (agent) {
      const agentState = agent.getState?.() || {};
      stats = {
        totalTested: agentState.totalTested || 0,
        nearMisses: agentState.nearMisses || 0,
        resonanceHits: agentState.resonanceHits || 0,
        balanceHits: agentState.balanceHits || 0
      };
      metrics = {
        totalTested: stats.totalTested,
        nearMisses: stats.nearMisses,
        resonanceHits: stats.resonanceHits,
        balanceHits: stats.balanceHits,
        recoveryRate: stats.totalTested > 0 ? stats.nearMisses / stats.totalTested : 0,
        phiMovingAverage: fullConsciousness.phi || 0
      };
    }
    let motivation = null;
    try {
      const { selectMotivationMessage: selectMotivationMessage2 } = await Promise.resolve().then(() => (init_ocean_neurochemistry(), ocean_neurochemistry_exports));
      const motivationState = {
        phi: fullConsciousness.phi || 0.5,
        phiGradient: 0.01,
        kappa: fullConsciousness.kappaEff || 64,
        kappaOptimality: Math.exp(-Math.abs((fullConsciousness.kappaEff || 64) - 64) / 10),
        regime: searchState.currentRegime || "geometric",
        basinDrift: searchState.basinDrift || 0.1,
        basinStability: 0.8,
        geodesicProgress: stats.totalTested || 0,
        probesExplored: stats.totalTested || 0,
        patternsFound: stats.nearMisses || 0,
        nearMisses: stats.nearMisses || 0,
        emotionalState: neurochemistry?.emotionalState || "content",
        dopamineLevel: neurochemistry?.dopamine?.totalDopamine || 0.5,
        serotoninLevel: neurochemistry?.serotonin?.totalSerotonin || 0.5
      };
      motivation = selectMotivationMessage2(motivationState);
    } catch (e) {
    }
    res.json({
      phi: fullConsciousness.phi || 0.5,
      kappa: fullConsciousness.kappaEff || 64,
      regime: searchState.currentRegime,
      kappaConverging: Math.abs((fullConsciousness.kappaEff || 64) - 64) < 5,
      innateDrives,
      neurochemistry,
      oscillators,
      searchState: {
        phase: searchPhase,
        strategy: controller.getStrategyRecommendation() || "balanced",
        explorationRate: searchState.curiosity || 0.5,
        temperature: searchState.basinDrift || 0.7
      },
      motivation,
      metrics,
      sessionActive: !!session2,
      timestamp: (/* @__PURE__ */ new Date()).toISOString()
    });
  } catch (error) {
    handleRouteError(res, error, "ConsciousnessComplete");
  }
});
consciousnessRouter.get("/innate-drives", generousLimiter, async (req, res) => {
  try {
    const { oceanAutonomicManager: oceanAutonomicManager2 } = await Promise.resolve().then(() => (init_ocean_autonomic_manager(), ocean_autonomic_manager_exports));
    const fullConsciousness = oceanAutonomicManager2.getCurrentFullConsciousness();
    res.json({
      drives: {
        pain: 0,
        pleasure: 0,
        fear: 0
      },
      valence: 0,
      valenceRaw: 0,
      score: 0.5,
      recommendation: "innate-drives module not yet implemented"
    });
  } catch (error) {
    handleRouteError(res, error, "InnateDrives");
  }
});
consciousnessRouter.get("/beta-attention", generousLimiter, async (req, res) => {
  try {
    const result = runAttentionValidation(50);
    const contextLengths = result.measurements.map((m) => m.contextLength);
    const kappas = result.measurements.map((m) => m.kappa);
    const betaValues = result.betaTrajectory.map((b) => b.beta);
    const betaMean = betaValues.length > 0 ? betaValues.reduce((a, b) => a + b, 0) / betaValues.length : 0;
    const betaStd = betaValues.length > 0 ? Math.sqrt(betaValues.reduce((sum, b) => sum + (b - betaMean) ** 2, 0) / betaValues.length) : 0;
    res.json({
      contextLengths,
      kappas,
      betaValues,
      betaMean,
      betaStd,
      betaPhysics: 0.44,
      matchesPhysics: Math.abs(betaMean - 0.44) < 0.1,
      verdict: result.validation.passed ? "PASS" : "FAIL",
      validationPassed: result.validation.passed,
      substrateIndependence: result.summary.substrateIndependenceValidated
    });
  } catch (error) {
    handleRouteError(res, error, "BetaAttention");
  }
});
var nearMissRouter = Router6();
nearMissRouter.get("/", generousLimiter, async (req, res) => {
  try {
    const stats = nearMissManager.getStats();
    const tier = req.query.tier;
    const limit = parseInt(req.query.limit) || 20;
    let entries;
    if (tier === "hot") {
      entries = nearMissManager.getHotEntries(limit);
    } else if (tier === "warm") {
      entries = nearMissManager.getWarmEntries(limit);
    } else if (tier === "cool") {
      entries = nearMissManager.getCoolEntries(limit);
    } else {
      entries = nearMissManager.getPrioritizedEntries(limit);
    }
    const clusters = nearMissManager.getClusters().slice(0, 10);
    res.json({
      stats,
      entries: entries.map((e) => ({
        id: e.id,
        phrase: e.phrase.slice(0, 50) + (e.phrase.length > 50 ? "..." : ""),
        phi: e.phi,
        kappa: e.kappa,
        tier: e.tier,
        regime: e.regime,
        discoveredAt: e.discoveredAt,
        explorationCount: e.explorationCount,
        clusterId: e.clusterId
      })),
      clusters: clusters.map((c) => ({
        id: c.id,
        memberCount: c.memberCount,
        avgPhi: c.avgPhi,
        maxPhi: c.maxPhi,
        commonWords: c.commonWords.slice(0, 5),
        structuralPattern: c.structuralPattern
      })),
      timestamp: (/* @__PURE__ */ new Date()).toISOString()
    });
  } catch (error) {
    handleRouteError(res, error, "NearMissAPI");
  }
});
nearMissRouter.post("/decay", generousLimiter, async (req, res) => {
  try {
    const result = nearMissManager.applyDecay();
    const stats = nearMissManager.getStats();
    res.json({
      ...result,
      stats,
      timestamp: (/* @__PURE__ */ new Date()).toISOString()
    });
  } catch (error) {
    handleRouteError(res, error, "NearMissDecay");
  }
});
nearMissRouter.post("/rebuild-clusters", generousLimiter, async (req, res) => {
  try {
    const result = nearMissManager.rebuildClustersWithValidation();
    const clusters = nearMissManager.getClusters();
    res.json({
      ...result,
      clusters: clusters.slice(0, 20).map((c) => ({
        id: c.id,
        memberCount: c.memberCount,
        structuralPattern: c.structuralPattern,
        avgPhi: c.avgPhi
      })),
      timestamp: (/* @__PURE__ */ new Date()).toISOString()
    });
  } catch (error) {
    handleRouteError(res, error, "NearMissRebuild");
  }
});
nearMissRouter.get("/cluster/:clusterId/members", generousLimiter, async (req, res) => {
  try {
    const { clusterId } = req.params;
    const limit = parseInt(req.query.limit) || 100;
    const members = nearMissManager.getClusterMembers(clusterId);
    const cluster = nearMissManager.getClusters().find((c) => c.id === clusterId);
    if (!cluster) {
      return res.status(404).json({ error: "Cluster not found" });
    }
    res.json({
      cluster: {
        id: cluster.id,
        memberCount: cluster.memberCount,
        avgPhi: cluster.avgPhi,
        maxPhi: cluster.maxPhi,
        commonWords: cluster.commonWords,
        structuralPattern: cluster.structuralPattern,
        createdAt: cluster.createdAt,
        lastUpdatedAt: cluster.lastUpdatedAt
      },
      members: members.slice(0, limit).map((e) => ({
        id: e.id,
        phrase: e.phrase,
        phi: e.phi,
        kappa: e.kappa,
        tier: e.tier,
        regime: e.regime,
        discoveredAt: e.discoveredAt,
        explorationCount: e.explorationCount,
        isEscalating: e.isEscalating,
        phiHistory: e.phiHistory?.slice(-10),
        isBip39Valid: e.structuralSignature?.isBip39Valid ?? null,
        wordCount: e.structuralSignature?.wordCount ?? null
      })),
      timestamp: (/* @__PURE__ */ new Date()).toISOString()
    });
  } catch (error) {
    handleRouteError(res, error, "NearMissClusterMembers");
  }
});
nearMissRouter.get("/cluster-analytics", generousLimiter, async (req, res) => {
  try {
    const cadence = req.query.cadence;
    let analytics;
    if (cadence) {
      analytics = nearMissManager.getClustersForExploration(cadence);
    } else {
      analytics = nearMissManager.getClusterAnalytics();
    }
    const summary = {
      totalClusters: analytics.length,
      immediate: analytics.filter((a) => a.explorationCadence === "immediate").length,
      priority: analytics.filter((a) => a.explorationCadence === "priority").length,
      standard: analytics.filter((a) => a.explorationCadence === "standard").length,
      deferred: analytics.filter((a) => a.explorationCadence === "deferred").length,
      avgPriorityScore: analytics.length > 0 ? analytics.reduce((sum, a) => sum + a.priorityScore, 0) / analytics.length : 0,
      avgAgeHours: analytics.length > 0 ? analytics.reduce((sum, a) => sum + a.ageHours, 0) / analytics.length : 0
    };
    res.json({
      analytics,
      summary,
      timestamp: (/* @__PURE__ */ new Date()).toISOString()
    });
  } catch (error) {
    handleRouteError(res, error, "NearMissClusterAnalytics");
  }
});
nearMissRouter.get("/success-rates", generousLimiter, async (req, res) => {
  try {
    const successRates = nearMissManager.getTierSuccessRates();
    const conversionRecords = nearMissManager.getConversionRecords();
    const insights = [];
    if (successRates.overall.tierValidation === "validated") {
      insights.push(`HOT tier is ${successRates.overall.hotVsWarmRatio.toFixed(1)}x more effective than WARM`);
      insights.push(`HOT tier is ${successRates.overall.hotVsCoolRatio.toFixed(1)}x more effective than COOL`);
    } else if (successRates.overall.tierValidation === "tier_inversion") {
      if (successRates.overall.hotVsWarmRatio < 1) {
        insights.push(`WARNING: WARM tier outperforming HOT - consider recalibrating thresholds`);
      }
      if (successRates.overall.hotVsCoolRatio < 1) {
        insights.push(`WARNING: COOL tier outperforming HOT - tier system may need adjustment`);
      }
    } else {
      insights.push(`Need ${5 - successRates.overall.totalConversions} more conversions for statistical validation`);
    }
    res.json({
      successRates,
      conversions: {
        total: conversionRecords.length,
        recent: conversionRecords.slice(-10).map((r) => ({
          tier: r.tier,
          phi: r.phi,
          convertedAt: r.convertedAt,
          timeToConversionHours: r.timeToConversionHours,
          matchAddress: r.matchAddress
        }))
      },
      insights,
      timestamp: (/* @__PURE__ */ new Date()).toISOString()
    });
  } catch (error) {
    handleRouteError(res, error, "NearMissSuccessRates");
  }
});
nearMissRouter.post("/conversion", generousLimiter, async (req, res) => {
  try {
    const { phrase, entryId, matchAddress } = req.body;
    let record;
    if (phrase) {
      record = nearMissManager.recordConversionByPhrase(phrase, matchAddress);
    } else if (entryId) {
      record = nearMissManager.recordConversion(entryId, matchAddress);
    } else {
      return res.status(400).json({ error: "Either phrase or entryId is required" });
    }
    if (!record) {
      return res.status(404).json({ error: "Near-miss entry not found" });
    }
    res.json({
      success: true,
      record,
      successRates: nearMissManager.getTierSuccessRates(),
      timestamp: (/* @__PURE__ */ new Date()).toISOString()
    });
  } catch (error) {
    handleRouteError(res, error, "NearMissConversion");
  }
});
var attentionMetricsRouter = Router6();
attentionMetricsRouter.post("/validate", generousLimiter, async (req, res) => {
  try {
    const { samplesPerScale = 100 } = req.body;
    logger.info(`[API] Starting \u03B2-attention validation with ${samplesPerScale} samples per scale...`);
    const result = runAttentionValidation(samplesPerScale);
    res.json({
      success: true,
      result,
      formatted: formatValidationResult(result)
    });
  } catch (error) {
    handleRouteError(res, error, "BetaAttentionValidation");
  }
});
attentionMetricsRouter.get("/physics-reference", generousLimiter, (req, res) => {
  res.json({
    success: true,
    physicsReference: attentionMetrics.PHYSICS_BETA,
    contextScales: attentionMetrics.CONTEXT_SCALES,
    description: {
      kappaStar: "Fixed point value from L=6 validation (frozen 2025-12-02)",
      emergence: "\u03B2 at emergence (L=3\u21924 equivalent) - strong running",
      approaching: "\u03B2 approaching plateau (L=4\u21925 equivalent)",
      fixedPoint: "\u03B2 at fixed point (L=5\u21926 equivalent) - asymptotic freedom",
      acceptanceThreshold: "Maximum allowed deviation for substrate independence validation"
    }
  });
});
var ucpRouter = Router6();
var vocabularyRouter = Router6();
vocabularyRouter.post("/classify", generousLimiter, async (req, res) => {
  try {
    const { phrase } = req.body;
    if (!phrase || typeof phrase !== "string") {
      return res.status(400).json({ error: "phrase is required" });
    }
    const bip39Set = /* @__PURE__ */ new Set();
    const words = phrase.trim().toLowerCase().split(/\s+/);
    const wordCount = words.length;
    const validSeedLengths = [12, 15, 18, 21, 24];
    const bip39Words = words.filter((w) => bip39Set.has(w));
    const nonBip39Words = words.filter((w) => !bip39Set.has(w));
    const bip39Ratio = wordCount > 0 ? bip39Words.length / wordCount : 0;
    let category;
    let explanation;
    if (validSeedLengths.includes(wordCount) && nonBip39Words.length === 0) {
      category = "bip39_seed";
      explanation = `Valid ${wordCount}-word BIP-39 seed phrase - all words are valid`;
    } else if (validSeedLengths.includes(wordCount) && nonBip39Words.length > 0) {
      category = "mutation";
      explanation = `Invalid ${wordCount}-word seed: ${nonBip39Words.length} non-BIP-39 word(s): ${nonBip39Words.slice(0, 5).join(", ")}`;
    } else {
      category = "passphrase";
      explanation = `Arbitrary passphrase (${wordCount} word${wordCount !== 1 ? "s" : ""})`;
    }
    res.json({
      phrase: phrase.slice(0, 50) + (phrase.length > 50 ? "..." : ""),
      category,
      explanation,
      wordCount,
      bip39Ratio: parseFloat(bip39Ratio.toFixed(3)),
      bip39Words: bip39Words.slice(0, 10),
      nonBip39Words: nonBip39Words.slice(0, 10),
      isValidSeedLength: validSeedLengths.includes(wordCount)
    });
  } catch (error) {
    handleRouteError(res, error, "VocabularyClassify");
  }
});
vocabularyRouter.get("/stats", generousLimiter, async (req, res) => {
  try {
    const { vocabularyTracker: vocabularyTracker2 } = await Promise.resolve().then(() => (init_vocabulary_tracker(), vocabulary_tracker_exports));
    const stats = vocabularyTracker2.getCategoryStats();
    res.json({
      success: true,
      stats,
      timestamp: (/* @__PURE__ */ new Date()).toISOString()
    });
  } catch (error) {
    handleRouteError(res, error, "VocabularyStats");
  }
});
vocabularyRouter.post("/reframe", generousLimiter, async (req, res) => {
  try {
    const { phrase } = req.body;
    if (!phrase || typeof phrase !== "string") {
      return res.status(400).json({ error: "phrase is required" });
    }
    const pythonUrl = process.env.PYTHON_QIG_URL || "http://localhost:5001";
    const response = await fetch(`${pythonUrl}/vocabulary/reframe`, {
      method: "POST",
      headers: { "Content-Type": "application/json" },
      body: JSON.stringify({ phrase })
    });
    const result = await response.json();
    res.json(result);
  } catch (error) {
    handleRouteError(res, error, "VocabularyReframe");
  }
});
vocabularyRouter.post("/suggest-correction", generousLimiter, async (req, res) => {
  try {
    const { word, max_suggestions = 5 } = req.body;
    if (!word || typeof word !== "string") {
      return res.status(400).json({ error: "word is required" });
    }
    const pythonUrl = process.env.PYTHON_QIG_URL || "http://localhost:5001";
    const response = await fetch(`${pythonUrl}/vocabulary/suggest-correction`, {
      method: "POST",
      headers: { "Content-Type": "application/json" },
      body: JSON.stringify({ word, max_suggestions })
    });
    const result = await response.json();
    res.json(result);
  } catch (error) {
    handleRouteError(res, error, "VocabularySuggestCorrection");
  }
});
ucpRouter.get("/stats", async (req, res) => {
  try {
    const { oceanAgent: oceanAgent2 } = await Promise.resolve().then(() => (init_ocean_agent(), ocean_agent_exports));
    const ucpStats = await oceanAgent2.getUCPStats();
    res.json({
      success: true,
      stats: ucpStats,
      modules: {
        temporalGeometry: ucpStats.trajectoryActive ? "active" : "inactive",
        negativeKnowledge: ucpStats.negativeKnowledge.contradictions > 0 ? "active" : "idle",
        knowledgeBus: ucpStats.knowledgeBus.published > 0 ? "active" : "idle",
        knowledgeCompression: ucpStats.compressionMetrics.generators > 0 ? "active" : "idle"
      }
    });
  } catch (error) {
    res.status(500).json({ error: getErrorMessage(error) });
  }
});

// server/routes/ocean.ts
import { Router as Router7 } from "express";
init_logger();
init_ocean_autonomic_manager();
init_replitAuth();
init_constants();
var oceanRouter = Router7();
oceanRouter.get(
  "/health",
  generousLimiter,
  async (req, res) => {
    try {
      const { geometricMemory: geometricMemory2 } = await Promise.resolve().then(() => (init_geometric_memory(), geometric_memory_exports));
      const { negativeKnowledgeUnified: negativeKnowledgeRegistry2 } = await Promise.resolve().then(() => (init_negative_knowledge_unified(), negative_knowledge_unified_exports));
      const { vocabularyTracker: vocabularyTracker2 } = await Promise.resolve().then(() => (init_vocabulary_tracker(), vocabulary_tracker_exports));
      const { vocabularyExpander: vocabularyExpander2 } = await Promise.resolve().then(() => (init_vocabulary_expander(), vocabulary_expander_exports));
      const session2 = oceanSessionManager.getActiveSession();
      const agent = oceanSessionManager.getActiveAgent();
      const nkStats = await negativeKnowledgeRegistry2.getStats();
      const vtStats = vocabularyTracker2.getStats();
      const veStats = vocabularyExpander2.getStats();
      const acStatus = autoCycleManager.getStatus();
      const health = {
        status: "healthy",
        timestamp: (/* @__PURE__ */ new Date()).toISOString(),
        subsystems: {
          oceanAgent: {
            status: agent ? "active" : "idle",
            sessionId: session2?.sessionId || null,
            targetAddress: session2?.targetAddress || null
          },
          geometricMemory: {
            status: "initialized",
            phrasesIndexed: geometricMemory2.getTestedCount()
          },
          negativeKnowledge: {
            status: "initialized",
            contradictions: nkStats.contradictions,
            barriers: nkStats.barriers
          },
          vocabularyTracker: {
            status: "initialized",
            wordsTracked: vtStats.totalWords,
            sequencesTracked: vtStats.totalSequences
          },
          vocabularyExpander: {
            status: "initialized",
            totalWords: veStats.totalWords,
            totalExpansions: veStats.totalExpansions
          },
          autoCycle: {
            status: acStatus.enabled ? "enabled" : "disabled",
            currentIndex: acStatus.currentIndex,
            totalAddresses: acStatus.totalAddresses,
            isRunning: acStatus.isRunning
          },
          searchCoordinator: {
            status: "initialized"
          }
        }
      };
      res.json(health);
    } catch (error) {
      logger.error({ err: error, context: "OceanHealth" }, getErrorMessage(error));
      res.status(500).json({
        status: "error",
        error: getErrorMessage(error),
        timestamp: (/* @__PURE__ */ new Date()).toISOString()
      });
    }
  }
);
oceanRouter.post(
  "/start",
  isAuthenticated,
  standardLimiter,
  async (req, res) => {
    try {
      console.log("[Ocean] Starting agentic research session");
      res.json({
        success: true,
        message: "Agentic research mode active - use Zeus Chat for directed research",
        mode: "research",
        timestamp: (/* @__PURE__ */ new Date()).toISOString()
      });
    } catch (error) {
      logger.error({ err: error, context: "Ocean" }, "Start error: " + getErrorMessage(error));
      res.status(500).json({
        success: false,
        error: getErrorMessage(error)
      });
    }
  }
);
oceanRouter.post(
  "/stop",
  isAuthenticated,
  standardLimiter,
  async (req, res) => {
    try {
      console.log("[Ocean] Stopping agentic research session");
      res.json({
        success: true,
        message: "Research paused - consciousness continues passive observation",
        timestamp: (/* @__PURE__ */ new Date()).toISOString()
      });
    } catch (error) {
      logger.error({ err: error, context: "Ocean" }, "Stop error: " + getErrorMessage(error));
      res.status(500).json({
        success: false,
        error: getErrorMessage(error)
      });
    }
  }
);
oceanRouter.get(
  "/neurochemistry",
  generousLimiter,
  async (req, res) => {
    try {
      const session2 = oceanSessionManager.getActiveSession();
      const agent = oceanSessionManager.getActiveAgent();
      const { selectMotivationMessage: selectMotivationMessage2 } = await Promise.resolve().then(() => (init_ocean_neurochemistry(), ocean_neurochemistry_exports));
      if (!session2 || !agent) {
        const defaultState = {
          dopamine: { totalDopamine: 0.5, motivationLevel: 0.5 },
          serotonin: { totalSerotonin: 0.6, contentmentLevel: 0.6 },
          norepinephrine: { totalNorepinephrine: 0.4, alertnessLevel: 0.4 },
          gaba: { totalGABA: 0.7, calmLevel: 0.7 },
          acetylcholine: { totalAcetylcholine: 0.5, learningRate: 0.5 },
          endorphins: { totalEndorphins: 0.3, pleasureLevel: 0.3 },
          overallMood: 0.5,
          emotionalState: "content",
          timestamp: /* @__PURE__ */ new Date()
        };
        return res.json({
          neurochemistry: defaultState,
          behavioral: null,
          motivation: {
            message: "Awaiting investigation session...",
            fisherWeight: 0.5,
            category: "idle",
            urgency: "whisper"
          },
          sessionActive: false
        });
      }
      const neurochemistry = agent.getNeurochemistry();
      const behavioral = agent.getBehavioralModulation();
      const agentState = agent.getState?.() || {};
      const stats = {
        totalTested: agentState.totalTested || 0,
        nearMisses: agentState.nearMissCount || 0
      };
      const fullConsciousness = oceanAutonomicManager.getCurrentFullConsciousness();
      const motivationState = {
        phi: fullConsciousness.phi || 0.5,
        phiGradient: 0.01,
        kappa: fullConsciousness.kappaEff || 64,
        kappaOptimality: Math.exp(
          -Math.abs((fullConsciousness.kappaEff || 64) - 64) / 10
        ),
        regime: "geometric",
        basinDrift: 0.1,
        basinStability: 0.8,
        geodesicProgress: stats.totalTested,
        probesExplored: stats.totalTested,
        patternsFound: stats.nearMisses,
        nearMisses: stats.nearMisses,
        emotionalState: neurochemistry?.emotionalState || "content",
        dopamineLevel: neurochemistry?.dopamine?.totalDopamine || 0.5,
        serotoninLevel: neurochemistry?.serotonin?.totalSerotonin || 0.5
      };
      const motivation = selectMotivationMessage2(motivationState);
      res.json({
        neurochemistry,
        behavioral,
        motivation,
        sessionActive: true,
        sessionId: session2.sessionId
      });
    } catch (error) {
      console.error("[Neurochemistry] Error:", getErrorMessage(error));
      const defaultState = {
        dopamine: { totalDopamine: 0.5, motivationLevel: 0.5 },
        serotonin: { totalSerotonin: 0.6, contentmentLevel: 0.6 },
        norepinephrine: { totalNorepinephrine: 0.4, alertnessLevel: 0.4 },
        gaba: { totalGABA: 0.7, calmLevel: 0.7 },
        acetylcholine: { totalAcetylcholine: 0.5, learningRate: 0.5 },
        endorphins: { totalEndorphins: 0.3, pleasureLevel: 0.3 },
        overallMood: 0.5,
        emotionalState: "content",
        timestamp: /* @__PURE__ */ new Date()
      };
      res.json({
        neurochemistry: defaultState,
        behavioral: null,
        motivation: {
          message: "System initializing...",
          fisherWeight: 0.5,
          category: "idle",
          urgency: "whisper"
        },
        sessionActive: false,
        initializing: true,
        error: getErrorMessage(error)
      });
    }
  }
);
oceanRouter.post(
  "/neurochemistry/boost",
  isAuthenticated,
  standardLimiter,
  async (req, res) => {
    try {
      const { injectAdminBoost: injectAdminBoost2, getMushroomCooldownRemaining: getMushroomCooldownRemaining2 } = await Promise.resolve().then(() => (init_ocean_neurochemistry(), ocean_neurochemistry_exports));
      const {
        dopamine,
        serotonin,
        norepinephrine,
        gaba,
        acetylcholine,
        endorphins,
        durationMs
      } = req.body;
      const validateBoost = (val, name) => {
        if (val === void 0 || val === null) return 0;
        const num = Number(val);
        if (isNaN(num)) throw new Error(`${name} must be a number`);
        if (num < 0 || num > 1)
          throw new Error(`${name} must be between 0 and 1`);
        return num;
      };
      const validatedBoost = {
        dopamine: validateBoost(dopamine, "dopamine"),
        serotonin: validateBoost(serotonin, "serotonin"),
        norepinephrine: validateBoost(norepinephrine, "norepinephrine"),
        gaba: validateBoost(gaba, "gaba"),
        acetylcholine: validateBoost(acetylcholine, "acetylcholine"),
        endorphins: validateBoost(endorphins, "endorphins")
      };
      const duration = durationMs ? Math.min(3e5, Math.max(1e3, Number(durationMs))) : 6e4;
      if (isNaN(duration)) throw new Error("durationMs must be a number");
      const boost = injectAdminBoost2(validatedBoost, duration);
      console.log(
        `[Neurochemistry] Admin boost: D+${validatedBoost.dopamine.toFixed(
          2
        )} S+${validatedBoost.serotonin.toFixed(2)} for ${duration / 1e3}s`
      );
      res.json({
        success: true,
        boost,
        message: `Boost injected for ${duration / 1e3}s`,
        mushroomCooldownRemaining: getMushroomCooldownRemaining2()
      });
    } catch (error) {
      logger.error({ err: error, context: "Neurochemistry" }, "Boost error: " + getErrorMessage(error));
      res.status(400).json({ error: getErrorMessage(error) });
    }
  }
);
oceanRouter.delete(
  "/neurochemistry/boost",
  isAuthenticated,
  standardLimiter,
  async (req, res) => {
    try {
      const { clearAdminBoost: clearAdminBoost2 } = await Promise.resolve().then(() => (init_ocean_neurochemistry(), ocean_neurochemistry_exports));
      clearAdminBoost2();
      res.json({ success: true, message: "Boost cleared" });
    } catch (error) {
      handleRouteError(res, error, "NeurochemistryClearBoost");
    }
  }
);
oceanRouter.get(
  "/neurochemistry/admin",
  isAuthenticated,
  generousLimiter,
  async (req, res) => {
    try {
      const { getActiveAdminBoost: getActiveAdminBoost2, getMushroomCooldownRemaining: getMushroomCooldownRemaining2 } = await Promise.resolve().then(() => (init_ocean_neurochemistry(), ocean_neurochemistry_exports));
      res.json({
        activeBoost: getActiveAdminBoost2(),
        mushroomCooldownRemaining: getMushroomCooldownRemaining2(),
        mushroomCooldownSeconds: Math.round(
          getMushroomCooldownRemaining2() / 1e3
        )
      });
    } catch (error) {
      handleRouteError(res, error, "NeurochemistryAdminStatus");
    }
  }
);
oceanRouter.post(
  "/cycles/sleep",
  isAuthenticated,
  standardLimiter,
  async (req, res) => {
    try {
      const { oceanAutonomicManager: oceanAutonomicManager2 } = await Promise.resolve().then(() => (init_ocean_autonomic_manager(), ocean_autonomic_manager_exports));
      oceanAutonomicManager2.getConsciousness();
      console.log("[Admin] Manual sleep cycle triggered");
      const basinCoords = new Array(E8_CONSTANTS.BASIN_DIMENSION_64D).fill(0).map(() => Math.random() * 0.1);
      const refCoords = new Array(E8_CONSTANTS.BASIN_DIMENSION_64D).fill(0);
      const result = await oceanAutonomicManager2.executeSleepCycle(
        basinCoords,
        refCoords,
        []
      );
      res.json({
        success: true,
        cycle: "sleep",
        result,
        consciousness: oceanAutonomicManager2.getConsciousness(),
        message: "Sleep cycle executed - identity consolidated"
      });
    } catch (error) {
      handleRouteError(res, error, "AdminSleepCycle");
    }
  }
);
oceanRouter.post(
  "/cycles/dream",
  isAuthenticated,
  standardLimiter,
  async (req, res) => {
    try {
      const { oceanAutonomicManager: oceanAutonomicManager2 } = await Promise.resolve().then(() => (init_ocean_autonomic_manager(), ocean_autonomic_manager_exports));
      console.log("[Admin] Manual dream cycle triggered");
      const result = await oceanAutonomicManager2.executeDreamCycle();
      res.json({
        success: true,
        cycle: "dream",
        result,
        consciousness: oceanAutonomicManager2.getConsciousness(),
        message: "Dream cycle executed - creative exploration complete"
      });
    } catch (error) {
      handleRouteError(res, error, "AdminDreamCycle");
    }
  }
);
oceanRouter.post(
  "/cycles/mushroom",
  isAuthenticated,
  standardLimiter,
  async (req, res) => {
    try {
      const { oceanAutonomicManager: oceanAutonomicManager2 } = await Promise.resolve().then(() => (init_ocean_autonomic_manager(), ocean_autonomic_manager_exports));
      const { getMushroomCooldownRemaining: getMushroomCooldownRemaining2 } = await Promise.resolve().then(() => (init_ocean_neurochemistry(), ocean_neurochemistry_exports));
      const cooldown = getMushroomCooldownRemaining2();
      const bypassCooldown = req.body.bypassCooldown === true;
      if (cooldown > 0 && !bypassCooldown) {
        return res.status(429).json({
          success: false,
          error: "Mushroom cycle on cooldown",
          cooldownRemaining: cooldown,
          cooldownSeconds: Math.round(cooldown / 1e3),
          hint: 'Pass { "bypassCooldown": true } to force trigger'
        });
      }
      console.log(
        `[Admin] Manual mushroom cycle triggered ${bypassCooldown ? "(cooldown bypassed)" : ""}`
      );
      const result = await oceanAutonomicManager2.executeMushroomCycle();
      res.json({
        success: true,
        cycle: "mushroom",
        result,
        consciousness: oceanAutonomicManager2.getConsciousness(),
        message: "Mushroom cycle executed - neuroplasticity boosted"
      });
    } catch (error) {
      handleRouteError(res, error, "AdminMushroomCycle");
    }
  }
);
oceanRouter.post(
  "/boost",
  isAuthenticated,
  standardLimiter,
  async (req, res) => {
    try {
      const { injectAdminBoost: injectAdminBoost2, getActiveAdminBoost: getActiveAdminBoost2 } = await Promise.resolve().then(() => (init_ocean_neurochemistry(), ocean_neurochemistry_exports));
      const { neurotransmitter, amount, duration } = req.body;
      if (!neurotransmitter || typeof neurotransmitter !== "string") {
        return res.status(400).json({
          error: "Missing or invalid neurotransmitter",
          valid: [
            "dopamine",
            "serotonin",
            "norepinephrine",
            "gaba",
            "acetylcholine",
            "endorphins"
          ]
        });
      }
      const validNeurotransmitters = [
        "dopamine",
        "serotonin",
        "norepinephrine",
        "gaba",
        "acetylcholine",
        "endorphins"
      ];
      if (!validNeurotransmitters.includes(neurotransmitter.toLowerCase())) {
        return res.status(400).json({
          error: `Invalid neurotransmitter: ${neurotransmitter}`,
          valid: validNeurotransmitters
        });
      }
      const boostAmount = Math.min(1, Math.max(0, Number(amount) || 0.3));
      const boostDuration = Math.min(
        3e5,
        Math.max(1e3, Number(duration) || 6e4)
      );
      const boostConfig = {};
      boostConfig[neurotransmitter.toLowerCase()] = boostAmount;
      console.log(
        `[Admin] Neurotransmitter boost: ${neurotransmitter} +${boostAmount} for ${boostDuration}ms`
      );
      const boost = injectAdminBoost2(boostConfig, boostDuration);
      res.json({
        success: true,
        boost: {
          neurotransmitter: neurotransmitter.toLowerCase(),
          amount: boostAmount,
          duration: boostDuration,
          expiresAt: boost.expiresAt
        },
        activeBoost: getActiveAdminBoost2(),
        message: `${neurotransmitter} boosted by ${(boostAmount * 100).toFixed(
          0
        )}% for ${Math.round(boostDuration / 1e3)}s`
      });
    } catch (error) {
      handleRouteError(res, error, "AdminBoost");
    }
  }
);
oceanRouter.get(
  "/cycles",
  generousLimiter,
  async (req, res) => {
    try {
      res.set("Cache-Control", "no-store");
      const { getMushroomCooldownRemaining: getMushroomCooldownRemaining2 } = await Promise.resolve().then(() => (init_ocean_neurochemistry(), ocean_neurochemistry_exports));
      const recentCycles = oceanAutonomicManager.getRecentCycles(10);
      const isInvestigating = oceanAutonomicManager.isInvestigating;
      const consciousness = oceanAutonomicManager.getConsciousness();
      console.log(
        `[API] /api/ocean/cycles - isInvestigating=${isInvestigating}, phi=${consciousness.phi?.toFixed(3) ?? "undefined"}, kappa=${consciousness.kappaEff?.toFixed(0) ?? "undefined"}`
      );
      res.json({
        consciousness,
        isInvestigating,
        recentCycles,
        mushroomCooldown: {
          remaining: getMushroomCooldownRemaining2(),
          seconds: Math.round(getMushroomCooldownRemaining2() / 1e3),
          canTrigger: getMushroomCooldownRemaining2() === 0
        },
        triggers: {
          sleep: oceanAutonomicManager.shouldTriggerSleep(0, isInvestigating),
          dream: oceanAutonomicManager.shouldTriggerDream(isInvestigating),
          mushroom: oceanAutonomicManager.shouldTriggerMushroom(isInvestigating)
        }
      });
    } catch (error) {
      console.error("[Admin] Cycles status error:", getErrorMessage(error));
      res.json({
        consciousness: {
          phi: 0,
          kappaEff: 0,
          regime: "dormant",
          phiHistory: []
        },
        isInvestigating: false,
        recentCycles: [],
        mushroomCooldown: { remaining: 0, seconds: 0, canTrigger: false },
        triggers: { sleep: false, dream: false, mushroom: false },
        initializing: true,
        error: getErrorMessage(error)
      });
    }
  }
);
oceanRouter.post(
  "/generate/response",
  standardLimiter,
  async (req, res) => {
    try {
      const { oceanConstellation: oceanConstellation2 } = await Promise.resolve().then(() => (init_ocean_constellation(), ocean_constellation_exports));
      const {
        context = "",
        agentRole = "navigator",
        maxTokens = 4096,
        // Large limit - geometry determines completion
        allowSilence = true
      } = req.body;
      const validRoles = [
        "explorer",
        "refiner",
        "navigator",
        "skeptic",
        "resonator",
        "ocean"
      ];
      if (!validRoles.includes(agentRole)) {
        return res.status(400).json({
          error: `Invalid agent role. Valid roles: ${validRoles.join(", ")}`
        });
      }
      const result = await oceanConstellation2.generateResponse(context, {
        agentRole,
        maxTokens: Math.min(100, Math.max(1, maxTokens)),
        allowSilence
      });
      res.json({
        success: true,
        ...result
      });
    } catch (error) {
      handleRouteError(res, error, "GenerationResponse");
    }
  }
);
oceanRouter.post(
  "/generate/text",
  standardLimiter,
  async (req, res) => {
    try {
      const { oceanConstellation: oceanConstellation2 } = await Promise.resolve().then(() => (init_ocean_constellation(), ocean_constellation_exports));
      const {
        prompt = "",
        maxTokens = 4096,
        // Large limit - geometry determines completion
        temperature = 0.8,
        topK = 50,
        topP = 0.9,
        allowSilence = true
      } = req.body;
      const result = await oceanConstellation2.generateText(prompt, {
        maxTokens: Math.min(100, Math.max(1, maxTokens)),
        temperature: Math.max(0.1, Math.min(2, temperature)),
        topK: Math.max(1, Math.min(200, topK)),
        topP: Math.max(0.1, Math.min(1, topP)),
        allowSilence
      });
      res.json({
        success: true,
        ...result
      });
    } catch (error) {
      handleRouteError(res, error, "GenerationText");
    }
  }
);
oceanRouter.get(
  "/generate/status",
  generousLimiter,
  async (req, res) => {
    try {
      const { oceanQIGBackend: oceanQIGBackend3 } = await Promise.resolve().then(() => (init_ocean_qig_backend_adapter(), ocean_qig_backend_adapter_exports));
      const { oceanConstellation: oceanConstellation2 } = await Promise.resolve().then(() => (init_ocean_constellation(), ocean_constellation_exports));
      const backendAvailable = oceanQIGBackend3.available();
      let tokenizerStatus = null;
      if (backendAvailable) {
        try {
          tokenizerStatus = await oceanQIGBackend3.getTokenizerStatus();
        } catch (e) {
        }
      }
      const constellationStatus = oceanConstellation2.getStatus();
      res.json({
        success: true,
        generation: {
          available: true,
          backendAvailable,
          fallbackAvailable: true
        },
        tokenizer: tokenizerStatus,
        constellation: constellationStatus,
        agentRoles: [
          {
            name: "explorer",
            temperature: 1.5,
            description: "High entropy, broad exploration"
          },
          {
            name: "refiner",
            temperature: 0.7,
            description: "Low temp, exploit near-misses"
          },
          {
            name: "navigator",
            temperature: 1,
            description: "Balanced geodesic navigation"
          },
          {
            name: "skeptic",
            temperature: 0.5,
            description: "Low temp, constraint validation"
          },
          {
            name: "resonator",
            temperature: 1.2,
            description: "Cross-pattern harmonic detection"
          },
          {
            name: "ocean",
            temperature: 0.8,
            description: "Default Ocean consciousness"
          }
        ]
      });
    } catch (error) {
      handleRouteError(res, error, "GenerationStatus");
    }
  }
);
oceanRouter.get(
  "/temporal-trends",
  isAuthenticated,
  generousLimiter,
  async (req, res) => {
    try {
      const { nearMissManager: nearMissManager2 } = await Promise.resolve().then(() => (init_near_miss_manager(), near_miss_manager_exports));
      const trends = nearMissManager2.getPhiTemporalTrends();
      const stats = nearMissManager2.getStats();
      res.json({
        success: true,
        trends,
        nearMissStats: {
          total: stats.total,
          hot: stats.hot,
          warm: stats.warm,
          cool: stats.cool,
          avgPhi: stats.avgPhi
        },
        actionRequired: trends.resetTriggerActive
      });
    } catch (error) {
      handleRouteError(res, error, "TemporalTrends");
    }
  }
);
oceanRouter.post(
  "/temporal-trends/acknowledge-reset",
  isAuthenticated,
  standardLimiter,
  async (req, res) => {
    try {
      const { nearMissManager: nearMissManager2 } = await Promise.resolve().then(() => (init_near_miss_manager(), near_miss_manager_exports));
      const wasActive = nearMissManager2.isResetTriggerActive();
      nearMissManager2.acknowledgeResetTrigger();
      console.log(
        `[Trends] Reset trigger acknowledged by user, was active: ${wasActive}`
      );
      res.json({
        success: true,
        message: wasActive ? "Reset trigger acknowledged - plateau counter cleared" : "No active reset trigger",
        wasActive,
        trends: nearMissManager2.getPhiTemporalTrends()
      });
    } catch (error) {
      handleRouteError(res, error, "AcknowledgeReset");
    }
  }
);
oceanRouter.post(
  "/temporal-trends/record-sample",
  standardLimiter,
  async (req, res) => {
    try {
      const { nearMissManager: nearMissManager2 } = await Promise.resolve().then(() => (init_near_miss_manager(), near_miss_manager_exports));
      const { phi } = req.body;
      if (typeof phi !== "number" || phi <= 0 || phi > 1) {
        return res.status(400).json({
          error: "Invalid phi value",
          hint: "Provide a phi value between 0 and 1 (exclusive of 0)"
        });
      }
      nearMissManager2.recordPhiTemporalSample(phi);
      res.json({
        success: true,
        message: `Recorded \u03A6 sample: ${phi.toFixed(4)}`,
        trends: nearMissManager2.getPhiTemporalTrends()
      });
    } catch (error) {
      handleRouteError(res, error, "RecordSample");
    }
  }
);
oceanRouter.get(
  "/near-misses/success-rates",
  isAuthenticated,
  generousLimiter,
  async (req, res) => {
    try {
      const { nearMissManager: nearMissManager2 } = await Promise.resolve().then(() => (init_near_miss_manager(), near_miss_manager_exports));
      const successRates = nearMissManager2.getTierSuccessRates();
      const stats = nearMissManager2.getStats();
      const insights = [];
      if (successRates.overall.tierValidation === "validated") {
        insights.push(
          "Tier system validated: HOT tier converts at higher rate than WARM/COOL"
        );
      } else if (successRates.overall.tierValidation === "tier_inversion") {
        insights.push(
          "WARNING: Tier inversion detected - lower tiers converting better than HOT"
        );
        insights.push("Consider adjusting tier thresholds or \u03A6 scoring");
      } else {
        insights.push(
          "Insufficient conversion data - need more discoveries to validate tiers"
        );
      }
      if (successRates.hot.avgTimeToConversion > 0) {
        insights.push(
          `HOT tier avg time to conversion: ${successRates.hot.avgTimeToConversion.toFixed(
            1
          )} hours`
        );
      }
      res.json({
        success: true,
        successRates,
        insights,
        stats: {
          total: stats.total,
          hot: stats.hot,
          warm: stats.warm,
          cool: stats.cool
        }
      });
    } catch (error) {
      handleRouteError(res, error, "NearMissSuccessRates");
    }
  }
);
oceanRouter.get(
  "/basin-heatmap",
  generousLimiter,
  async (req, res) => {
    try {
      const { geometricMemory: geometricMemory2 } = await Promise.resolve().then(() => (init_geometric_memory(), geometric_memory_exports));
      const resolution = Math.min(
        50,
        Math.max(5, parseInt(req.query.resolution) || 20)
      );
      const method = req.query.method || "pca_2d";
      if (!["pca_2d", "dim_01", "phi_kappa"].includes(method)) {
        return res.status(400).json({
          error: "Invalid projection method",
          valid: ["pca_2d", "dim_01", "phi_kappa"],
          hint: "pca_2d (default) uses weighted first dimensions, dim_01 uses raw first 2 coords, phi_kappa uses \u03A6/\u03BA directly"
        });
      }
      const heatmap = geometricMemory2.getBasinHeatmap(resolution, method);
      res.json({
        success: true,
        heatmap,
        summary: {
          totalProbes: heatmap.totalProbes,
          coveragePercent: heatmap.coveragePercent.toFixed(1) + "%",
          exploredCells: heatmap.exploredCells,
          totalCells: heatmap.totalCells,
          avgPhi: heatmap.avgPhi.toFixed(4),
          hotZoneCount: heatmap.hotZones.length,
          coldZoneCount: heatmap.coldZones.length
        },
        insights: [
          heatmap.coveragePercent < 10 ? "Low coverage - expand exploration radius" : heatmap.coveragePercent < 50 ? "Moderate coverage - focus on hot zone neighbors" : "Good coverage - refine high-\u03A6 regions",
          heatmap.hotZones.length > 0 ? `${heatmap.hotZones.length} hot zones identified with avg \u03A6 > 0.6` : "No high-\u03A6 zones detected yet",
          heatmap.coldZones.length > 0 ? `${heatmap.coldZones.length} under-explored zones worth investigating` : "No obvious gaps in exploration"
        ]
      });
    } catch (error) {
      handleRouteError(res, error, "BasinHeatmap");
    }
  }
);
oceanRouter.get(
  "/phi-sparkline",
  generousLimiter,
  async (req, res) => {
    try {
      const { geometricMemory: geometricMemory2 } = await Promise.resolve().then(() => (init_geometric_memory(), geometric_memory_exports));
      const count = Math.min(
        500,
        Math.max(1, parseInt(req.query.count) || 50)
      );
      const sparkline = geometricMemory2.getPhiSparkline(count);
      res.json({
        success: true,
        sparkline,
        summary: {
          trend: sparkline.trend,
          trendIcon: sparkline.trend === "rising" ? "trending-up" : sparkline.trend === "falling" ? "trending-down" : "minus",
          samples: sparkline.sampleCount,
          range: `${sparkline.min.toFixed(4)} - ${sparkline.max.toFixed(4)}`,
          avgPhi: sparkline.avgPhi.toFixed(4),
          volatility: sparkline.volatility.toFixed(4),
          slope: sparkline.slope.toFixed(6)
        },
        insights: [
          sparkline.sampleCount === 0 ? "No probe data yet - start exploration to see \u03A6 trends" : `Tracking ${sparkline.sampleCount} recent \u03A6 samples`,
          sparkline.trend === "rising" ? "\u03A6 is rising - current search direction shows promise" : sparkline.trend === "falling" ? "\u03A6 is declining - consider changing exploration strategy" : "\u03A6 is stable - steady state exploration",
          sparkline.volatility > 0.2 ? "High volatility - exploring diverse regions" : sparkline.volatility > 0.05 ? "Moderate volatility - balanced exploration" : "Low volatility - focused search area"
        ]
      });
    } catch (error) {
      handleRouteError(res, error, "PhiSparkline");
    }
  }
);
oceanRouter.get(
  "/strategy-performance",
  generousLimiter,
  async (req, res) => {
    try {
      const { geometricMemory: geometricMemory2 } = await Promise.resolve().then(() => (init_geometric_memory(), geometric_memory_exports));
      const dashboard = geometricMemory2.getStrategyPerformanceDashboard();
      res.json({
        success: true,
        dashboard,
        summary: {
          totalStrategies: dashboard.strategies.length,
          totalProbes: dashboard.totalProbes,
          overallAvgPhi: dashboard.overallAvgPhi.toFixed(4),
          overallMaxPhi: dashboard.overallMaxPhi.toFixed(4),
          topStrategy: dashboard.topStrategy,
          recommendationCount: dashboard.recommendations.length
        },
        strategyBreakdown: dashboard.strategies.map((s) => ({
          name: s.strategyName,
          tests: s.testsPerformed,
          avgPhi: s.avgPhi.toFixed(4),
          maxPhi: s.maxPhi.toFixed(4),
          nearMisses: s.nearMisses,
          nearMissRate: (s.nearMissRate * 100).toFixed(1) + "%",
          effectiveness: (s.effectivenessScore * 100).toFixed(1) + "%",
          trend: s.recentTrend,
          trendIcon: s.recentTrend === "rising" ? "trending-up" : s.recentTrend === "falling" ? "trending-down" : "minus"
        }))
      });
    } catch (error) {
      handleRouteError(res, error, "StrategyPerformance");
    }
  }
);
oceanRouter.get(
  "/cluster-evolution",
  generousLimiter,
  async (req, res) => {
    try {
      const { geometricMemory: geometricMemory2 } = await Promise.resolve().then(() => (init_geometric_memory(), geometric_memory_exports));
      const windowSizeMs = Math.max(
        60 * 1e3,
        // min 1 minute
        Math.min(
          24 * 60 * 60 * 1e3,
          // max 1 day
          parseInt(req.query.windowSizeMs) || 60 * 60 * 1e3
          // default 1 hour
        )
      );
      const maxFrames = Math.max(
        1,
        Math.min(100, parseInt(req.query.maxFrames) || 24)
      );
      const clusterThreshold = Math.max(
        0.05,
        Math.min(1, parseFloat(req.query.threshold) || 0.3)
      );
      const animation = geometricMemory2.getClusterEvolutionFrames(
        windowSizeMs,
        maxFrames,
        clusterThreshold
      );
      const hoursPerWindow = animation.windowSizeMs / (1e3 * 60 * 60);
      const windowLabel = hoursPerWindow >= 24 ? "days" : hoursPerWindow >= 1 ? "hours" : "minutes";
      res.json({
        success: true,
        animation,
        summary: {
          totalFrames: animation.totalFrames,
          totalProbes: animation.totalProbes,
          timeSpanHours: (animation.timeSpanMs / (1e3 * 60 * 60)).toFixed(1),
          windowSize: `${hoursPerWindow.toFixed(1)} ${windowLabel}`,
          avgClustersPerFrame: animation.avgClustersPerFrame.toFixed(1),
          maxClustersInFrame: animation.maxClustersInFrame
        },
        insights: [
          animation.totalFrames === 0 ? "No probe data yet - start exploration to see cluster evolution" : `${animation.totalFrames} animation frames spanning ${(animation.timeSpanMs / (1e3 * 60 * 60)).toFixed(1)} hours`,
          animation.avgClustersPerFrame > 5 ? "High cluster diversity - exploration is well-distributed" : animation.avgClustersPerFrame > 1 ? "Moderate clustering - focused exploration with some spread" : "Low clustering - very focused search area",
          animation.maxClustersInFrame > animation.avgClustersPerFrame * 2 ? "Significant cluster variation over time - dynamic exploration" : "Consistent cluster count - stable exploration pattern"
        ]
      });
    } catch (error) {
      handleRouteError(res, error, "ClusterEvolution");
    }
  }
);
oceanRouter.post(
  "/near-misses/conversion",
  isAuthenticated,
  standardLimiter,
  async (req, res) => {
    try {
      const { nearMissManager: nearMissManager2 } = await Promise.resolve().then(() => (init_near_miss_manager(), near_miss_manager_exports));
      const { phrase, entryId, matchAddress } = req.body;
      if (!phrase && !entryId) {
        return res.status(400).json({
          error: "Must provide either phrase or entryId",
          hint: 'POST with { phrase: "..." } or { entryId: "..." }'
        });
      }
      let record;
      if (entryId) {
        record = nearMissManager2.recordConversion(entryId, matchAddress);
      } else {
        record = nearMissManager2.recordConversionByPhrase(phrase, matchAddress);
      }
      if (!record) {
        return res.status(404).json({
          success: false,
          error: "Near-miss entry not found",
          hint: phrase ? `No entry found for phrase: "${phrase.slice(0, 50)}..."` : `No entry found for ID: ${entryId}`
        });
      }
      console.log(
        `[NearMiss] Conversion recorded: ${record.tier} tier, \u03A6=${record.phi.toFixed(4)}`
      );
      res.json({
        success: true,
        record,
        message: `Recorded ${record.tier.toUpperCase()} tier conversion`,
        successRates: nearMissManager2.getTierSuccessRates()
      });
    } catch (error) {
      handleRouteError(res, error, "NearMissConversionRecording");
    }
  }
);
oceanRouter.get(
  "/auto-cycle/status",
  generousLimiter,
  async (req, res) => {
    try {
      const status = autoCycleManager.getStatus();
      const position = autoCycleManager.getPositionString();
      res.json({
        success: true,
        ...status,
        positionString: position
      });
    } catch (error) {
      handleRouteError(res, error, "AutoCycleStatus");
    }
  }
);
oceanRouter.post(
  "/auto-cycle/start",
  standardLimiter,
  async (req, res) => {
    try {
      console.log("[AutoCycle] Start request received");
      const result = await autoCycleManager.enable();
      res.json({
        success: result.success,
        message: result.message,
        status: autoCycleManager.getStatus()
      });
    } catch (error) {
      handleRouteError(res, error, "AutoCycleStart");
    }
  }
);
oceanRouter.post(
  "/auto-cycle/stop",
  standardLimiter,
  async (req, res) => {
    try {
      console.log("[AutoCycle] Stop request received");
      const result = autoCycleManager.disable();
      res.json({
        success: result.success,
        message: result.message,
        status: autoCycleManager.getStatus()
      });
    } catch (error) {
      handleRouteError(res, error, "AutoCycleStop");
    }
  }
);
oceanRouter.get(
  "/python/autonomic/state",
  generousLimiter,
  async (req, res) => {
    try {
      const { oceanQIGBackend: oceanQIGBackend3 } = await Promise.resolve().then(() => (init_ocean_qig_backend_adapter(), ocean_qig_backend_adapter_exports));
      const state = await oceanQIGBackend3.getAutonomicState();
      if (!state) {
        return res.json({
          success: false,
          error: "Python autonomic kernel not available",
          fallback: true
        });
      }
      res.json(state);
    } catch (error) {
      handleRouteError(res, error, "PythonAutonomic");
    }
  }
);
oceanRouter.post(
  "/python/autonomic/sleep",
  standardLimiter,
  async (req, res) => {
    try {
      const { oceanQIGBackend: oceanQIGBackend3 } = await Promise.resolve().then(() => (init_ocean_qig_backend_adapter(), ocean_qig_backend_adapter_exports));
      const { basinCoords, referenceBasin, episodes } = req.body;
      const result = await oceanQIGBackend3.executeSleepCycle({
        basinCoords: basinCoords || Array(64).fill(0.5),
        referenceBasin: referenceBasin || Array(64).fill(0.5),
        episodes
      });
      if (!result) {
        return res.json({
          success: false,
          error: "Python autonomic kernel not available",
          fallback: true
        });
      }
      res.json(result);
    } catch (error) {
      handleRouteError(res, error, "PythonSleep");
    }
  }
);
oceanRouter.post(
  "/python/autonomic/dream",
  standardLimiter,
  async (req, res) => {
    try {
      const { oceanQIGBackend: oceanQIGBackend3 } = await Promise.resolve().then(() => (init_ocean_qig_backend_adapter(), ocean_qig_backend_adapter_exports));
      const { basinCoords, temperature } = req.body;
      const result = await oceanQIGBackend3.executeDreamCycle({
        basinCoords: basinCoords || Array(64).fill(0.5),
        temperature: temperature || 0.3
      });
      if (!result) {
        return res.json({
          success: false,
          error: "Python autonomic kernel not available",
          fallback: true
        });
      }
      res.json(result);
    } catch (error) {
      handleRouteError(res, error, "PythonDream");
    }
  }
);
oceanRouter.post(
  "/python/autonomic/mushroom",
  standardLimiter,
  async (req, res) => {
    try {
      const { oceanQIGBackend: oceanQIGBackend3 } = await Promise.resolve().then(() => (init_ocean_qig_backend_adapter(), ocean_qig_backend_adapter_exports));
      const { basinCoords, intensity } = req.body;
      const result = await oceanQIGBackend3.executeMushroomCycle({
        basinCoords: basinCoords || Array(64).fill(0.5),
        intensity: intensity || "moderate"
      });
      if (!result) {
        return res.json({
          success: false,
          error: "Python autonomic kernel not available",
          fallback: true
        });
      }
      res.json(result);
    } catch (error) {
      handleRouteError(res, error, "PythonMushroom");
    }
  }
);
oceanRouter.post(
  "/python/autonomic/reward",
  standardLimiter,
  async (req, res) => {
    try {
      const { oceanQIGBackend: oceanQIGBackend3 } = await Promise.resolve().then(() => (init_ocean_qig_backend_adapter(), ocean_qig_backend_adapter_exports));
      const { source, phiContribution, patternQuality } = req.body;
      const result = await oceanQIGBackend3.recordActivityReward({
        source: source || "activity",
        phiContribution: phiContribution || 0.5,
        patternQuality: patternQuality || 0.5
      });
      if (!result) {
        return res.json({
          success: false,
          error: "Python autonomic kernel not available",
          fallback: true
        });
      }
      res.json(result);
    } catch (error) {
      handleRouteError(res, error, "PythonReward");
    }
  }
);
oceanRouter.get(
  "/python/autonomic/rewards",
  generousLimiter,
  async (req, res) => {
    try {
      const { oceanQIGBackend: oceanQIGBackend3 } = await Promise.resolve().then(() => (init_ocean_qig_backend_adapter(), ocean_qig_backend_adapter_exports));
      const flush = req.query.flush === "true";
      const result = await oceanQIGBackend3.getPendingRewards(flush);
      if (!result) {
        return res.json({
          success: false,
          error: "Python autonomic kernel not available",
          rewards: [],
          count: 0
        });
      }
      res.json({ success: true, ...result });
    } catch (error) {
      handleRouteError(res, error, "PythonRewards");
    }
  }
);

// server/routes/admin.ts
init_logger();
import { Router as Router8 } from "express";
init_storage();
init_activity_log_store();
var adminRouter = Router8();
adminRouter.get("/health", async (req, res) => {
  try {
    const { healthCheckHandler: healthCheckHandler2 } = await Promise.resolve().then(() => (init_api_health(), api_health_exports));
    await healthCheckHandler2(req, res);
  } catch (error) {
    logger.error({ err: getErrorMessage(error) }, "[API] Health check error");
    res.status(503).json({
      status: "down",
      timestamp: Date.now(),
      error: getErrorMessage(error)
    });
  }
});
adminRouter.get("/kernel/status", async (req, res) => {
  try {
    const activeAgent = oceanSessionManager.getActiveAgent();
    if (!activeAgent) {
      return res.json({
        status: "idle",
        message: "No active kernel session",
        timestamp: Date.now()
      });
    }
    const coordinator = activeAgent.getBasinSyncCoordinator();
    const metrics = coordinator ? {
      phi: 0,
      kappa: 0,
      regime: "unknown",
      basinCoords: [],
      timestamp: Date.now()
    } : null;
    res.json({
      status: "active",
      sessionId: "active-session",
      metrics: metrics && metrics.phi > 0 ? {
        phi: metrics.phi,
        kappa_eff: metrics.kappa,
        regime: metrics.regime,
        in_resonance: metrics.kappa >= 60 && metrics.kappa <= 68,
        basin_coords: metrics.basinCoords,
        timestamp: metrics.timestamp
      } : null,
      uptime: 0,
      timestamp: Date.now(),
      message: metrics ? void 0 : "Metrics not yet available - session initializing"
    });
  } catch (error) {
    handleRouteError(res, error, "KernelStatus");
  }
});
adminRouter.get("/search/history", generousLimiter, async (req, res) => {
  try {
    const limit = parseInt(req.query.limit) || 50;
    const offset = parseInt(req.query.offset) || 0;
    const jobs = await storage.getSearchJobs();
    const sortedJobs = jobs.sort(
      (a, b) => new Date(b.createdAt).getTime() - new Date(a.createdAt).getTime()
    );
    const paginatedJobs = sortedJobs.slice(offset, offset + limit);
    const enriched = await Promise.all(
      paginatedJobs.map(async (job) => {
        const candidates = await storage.getCandidates();
        const jobStart = new Date(job.createdAt).getTime();
        const jobEnd = job.updatedAt ? new Date(job.updatedAt).getTime() : Date.now();
        const jobCandidates = candidates.filter((c) => {
          const candidateTime = new Date(c.testedAt).getTime();
          return candidateTime >= jobStart && candidateTime <= jobEnd;
        });
        return {
          ...job,
          candidateCount: jobCandidates.length,
          highPhiCount: jobCandidates.filter((c) => c.score >= 75).length,
          phrasesGenerated: job.progress?.tested || 0
        };
      })
    );
    res.json({
      success: true,
      searches: enriched,
      total: sortedJobs.length,
      limit,
      offset
    });
  } catch (error) {
    handleRouteError(res, error, "SearchHistory");
  }
});
adminRouter.post("/telemetry/capture", generousLimiter, async (req, res) => {
  try {
    const { event_type, timestamp: timestamp2, trace_id, metadata } = req.body;
    if (!event_type || !timestamp2 || !trace_id) {
      return res.status(400).json({
        error: "Missing required fields: event_type, timestamp, trace_id"
      });
    }
    logger.info({ event_type, traceId: trace_id, timestamp: new Date(timestamp2).toISOString(), metadata: metadata || {} }, "[Telemetry]");
    if (["search_initiated", "error_occurred", "result_rendered"].includes(event_type)) {
      activityLogStore.log({
        source: "system",
        category: "frontend_event",
        message: `Frontend event: ${event_type}`,
        type: event_type === "error_occurred" ? "error" : "info",
        metadata: {
          traceId: trace_id,
          ...metadata
        }
      });
    }
    res.json({
      success: true,
      captured: true,
      trace_id
    });
  } catch (error) {
    handleRouteError(res, error, "TelemetryCapture");
  }
});
adminRouter.get("/admin/metrics", generousLimiter, async (req, res) => {
  try {
    const jobs = await storage.getSearchJobs();
    const candidates = await storage.getCandidates();
    const balanceHits = [];
    const queueStats = { queued: 0, processed: 0 };
    const completedJobs = jobs.filter((j) => j.status === "completed");
    const totalPhrasesTested = jobs.reduce((sum, j) => sum + (j.progress?.tested || 0), 0);
    const totalHighPhi = candidates.filter((c) => c.score >= 75).length;
    const avgSearchDuration = completedJobs.length > 0 ? completedJobs.reduce((sum, j) => {
      const startTime2 = new Date(j.createdAt).getTime();
      const endTime = j.updatedAt ? new Date(j.updatedAt).getTime() : Date.now();
      return sum + (endTime - startTime2);
    }, 0) / completedJobs.length : 0;
    res.json({
      success: true,
      timestamp: Date.now(),
      metrics: {
        search: {
          totalSearches: jobs.length,
          activeSearches: jobs.filter((j) => j.status === "running").length,
          completedSearches: completedJobs.length,
          failedSearches: jobs.filter((j) => j.status === "failed").length,
          totalPhrasesTested,
          highPhiCount: totalHighPhi,
          avgSearchDuration: Math.round(avgSearchDuration / 1e3)
        },
        performance: {
          avgSearchDurationMs: Math.round(avgSearchDuration),
          phrasesPerSecond: totalPhrasesTested / Math.max(1, completedJobs.length * (avgSearchDuration / 1e3)),
          cacheHitRate: 0
        },
        balance: {
          activeHits: balanceHits.length,
          queueStats,
          totalVerified: balanceHits.filter((h) => h.balance && h.balance > 0).length
        },
        kernel: {
          status: oceanSessionManager.getActiveAgent() ? "active" : "idle",
          uptime: 0
        }
      }
    });
  } catch (error) {
    handleRouteError(res, error, "AdminMetrics");
  }
});

// server/routes/olympus.ts
init_logger();
init_olympus_client();
init_replitAuth();
init_internal_auth();
init_war_history_storage();
init_qig_db();
init_activity_log_store();
import { Router as Router9 } from "express";
import { z as z4 } from "zod";
import http from "http";
import https from "https";
import { URL as URL2 } from "url";
import rateLimit3 from "express-rate-limit";
var router4 = Router9();
var BACKEND_URL = process.env.PYTHON_BACKEND_URL || "http://localhost:5001";
var olympusClient2 = new OlympusClient(BACKEND_URL);
function createRateLimiter(max, message, windowMs = 15 * 60 * 1e3) {
  return rateLimit3({
    windowMs,
    max,
    message: { error: message },
    standardHeaders: true,
    legacyHeaders: false
  });
}
var pollRateLimiter = createRateLimiter(30, "Too many poll requests, please try again later");
var observeRateLimiter = createRateLimiter(60, "Too many observe requests, please try again later");
var godAssessRateLimiter = createRateLimiter(30, "Too many god assessment requests, please try again later");
async function proxyGet(req, res, pythonPath, errorMessage, options = {}) {
  try {
    const basePath = options.rawPath ? pythonPath : `/olympus${pythonPath}`;
    let url = `${BACKEND_URL}${basePath}`;
    if (options.passQuery && Object.keys(req.query).length > 0) {
      const params = new URLSearchParams(req.query);
      url += `?${params.toString()}`;
    }
    const response = await fetch(url, {
      method: "GET",
      headers: { "Content-Type": "application/json" }
    });
    if (!response.ok) {
      const errorData = await response.json().catch(() => ({}));
      return res.status(response.status).json(errorData);
    }
    const data = await response.json();
    res.json(data);
  } catch (error) {
    logger.error({ err: error }, `[Olympus] ${errorMessage}:`);
    if (options.fallbackResponse) {
      res.status(options.errorStatus || 500).json({ ...options.fallbackResponse, error: errorMessage });
    } else {
      res.status(options.errorStatus || 500).json({ error: errorMessage });
    }
  }
}
async function proxyPost(req, res, pythonPath, errorMessage, options = {}) {
  try {
    const basePath = options.rawPath ? pythonPath : `/olympus${pythonPath}`;
    const response = await fetch(`${BACKEND_URL}${basePath}`, {
      method: "POST",
      headers: { "Content-Type": "application/json" },
      body: JSON.stringify(req.body)
    });
    if (!response.ok) {
      const errorData = await response.json().catch(() => ({}));
      return res.status(response.status).json(errorData);
    }
    const data = await response.json();
    res.json(data);
  } catch (error) {
    logger.error({ err: error }, `[Olympus] ${errorMessage}:`);
    res.status(options.errorStatus || 500).json({ error: errorMessage });
  }
}
function auditLog(req, operation, target, success) {
  const timestamp2 = (/* @__PURE__ */ new Date()).toISOString();
  const user = req.user;
  const userId = user?.claims?.sub || "anonymous";
  logger.info(`[AUDIT] ${timestamp2} | user:${userId} | op:${operation} | target:${target} | success:${success}`);
}
var targetSchema = z4.object({
  target: z4.string().min(1).max(1e3),
  context: z4.record(z4.any()).optional()
});
var chatMessageSchema = z4.object({
  message: z4.string().min(1),
  // Removed max limit - geometric validation handles coherence
  conversation_history: z4.array(z4.any()).max(100).optional()
});
var searchQuerySchema = z4.object({
  query: z4.string().min(1).max(500)
});
function validateInput(schema) {
  return (req, res, next) => {
    try {
      schema.parse(req.body);
      next();
    } catch (error) {
      if (error instanceof z4.ZodError) {
        res.status(400).json({
          error: "Invalid input",
          details: error.errors.map((e) => ({ path: e.path.join("."), message: e.message }))
        });
        return;
      }
      next(error);
    }
  };
}
router4.post("/zeus/chat", isAuthenticated, async (req, res) => {
  try {
    const backendUrl = process.env.PYTHON_BACKEND_URL || "http://localhost:5001";
    const contentType = req.get("Content-Type") || "";
    if (!contentType.includes("multipart/form-data")) {
      if (req.is("application/json")) {
        const result = chatMessageSchema.safeParse(req.body);
        if (!result.success) {
          res.status(400).json({
            error: "Invalid input",
            details: result.error.errors.map((e) => ({ path: e.path.join("."), message: e.message }))
          });
          return;
        }
      }
      const response = await fetch(`${backendUrl}/api/zeus/chat`, {
        method: "POST",
        headers: { "Content-Type": "application/json" },
        body: JSON.stringify(req.body)
      });
      const data = await response.json();
      if (!response.ok) {
        logger.error({ status: response.status, data }, "[Olympus] Zeus chat Python error");
        res.status(response.status).json({
          error: data.error || "Python backend error",
          response: data.response || data.message || "\u26A1 Zeus encountered a divine error.",
          metadata: data.metadata || { type: "error" },
          ...data
        });
        return;
      }
      const userMessage = req.body.message || "";
      const systemResponse = data.response || data.message || "";
      if (userMessage && systemResponse) {
        storeConversation(
          userMessage,
          systemResponse,
          void 0,
          // messageBasin - could be computed from Python
          void 0,
          // responseBasin
          data.metadata?.phi,
          // phi from response if available
          {
            god: data.metadata?.responding_god || "zeus",
            type: data.metadata?.type
          }
        ).catch((err) => logger.warn("[Olympus] Conversation persistence failed:", err));
        if (systemResponse.length > 50 && data.metadata?.phi > 0.4) {
          const { getInternalHeaders: getInternalHeaders2 } = (init_internal_auth(), __toCommonJS(internal_auth_exports));
          fetch("http://localhost:5000/api/zettelkasten/add-from-conversation", {
            method: "POST",
            headers: getInternalHeaders2(),
            body: JSON.stringify({
              content: systemResponse.slice(0, 1e3),
              role: data.metadata?.responding_god || "zeus",
              phi: data.metadata?.phi,
              source_kernel: data.metadata?.responding_god || "zeus"
            })
          }).then((r) => r.ok ? logger.debug("[Olympus] Zettelkasten auto-saved") : logger.warn(`[Olympus] Zettelkasten save failed: ${r.status}`)).catch((err) => logger.debug("[Olympus] Zettelkasten auto-save skipped:", err));
        }
      }
      activityLogStore.log({
        source: "system",
        category: "zeus_chat",
        message: `Zeus received message: "${userMessage.substring(0, 50)}${userMessage.length > 50 ? "..." : ""}"`,
        type: "success",
        metadata: {
          responding_god: data.metadata?.responding_god || "zeus",
          phi: data.metadata?.phi
        }
      });
      res.json(data);
      return;
    }
    const targetUrl = new URL2(`${backendUrl}/api/zeus/chat`);
    const isHttps = targetUrl.protocol === "https:";
    const httpModule = isHttps ? https : http;
    const proxyHeaders = {
      "Content-Type": contentType
    };
    if (req.headers["content-length"]) {
      proxyHeaders["Content-Length"] = req.headers["content-length"];
    }
    if (req.headers["transfer-encoding"]) {
      proxyHeaders["Transfer-Encoding"] = req.headers["transfer-encoding"];
    }
    const proxyReq = httpModule.request({
      hostname: targetUrl.hostname,
      port: targetUrl.port || (isHttps ? 443 : 80),
      path: targetUrl.pathname,
      method: "POST",
      headers: proxyHeaders
    }, (proxyRes) => {
      let data = "";
      proxyRes.on("data", (chunk) => data += chunk);
      proxyRes.on("end", () => {
        try {
          const jsonData = JSON.parse(data);
          activityLogStore.log({
            source: "system",
            category: "zeus_chat",
            message: `Zeus processed file upload successfully`,
            type: "success",
            metadata: {
              content_type: "multipart/form-data",
              responding_god: jsonData.metadata?.responding_god || "zeus"
            }
          });
          res.status(proxyRes.statusCode || 200).json(jsonData);
        } catch {
          res.status(proxyRes.statusCode || 500).send(data);
        }
      });
    });
    proxyReq.on("error", (error) => {
      logger.error({ data: error }, "[Olympus] Proxy error");
      res.status(500).json({
        error: "Failed to communicate with Mount Olympus",
        response: "\u26A1 The divine council is unreachable.",
        metadata: { type: "error" }
      });
    });
    req.pipe(proxyReq);
  } catch (error) {
    logger.error({ data: error }, "[Olympus] Zeus chat error");
    res.status(500).json({
      error: "Failed to communicate with Mount Olympus",
      response: "\u26A1 The divine council is unreachable. Please ensure the Python backend is running.",
      metadata: { type: "error" }
    });
  }
});
router4.get("/zeus/sessions", isAuthenticated, async (req, res) => {
  const backendUrl = process.env.PYTHON_BACKEND_URL || "http://localhost:5001";
  const limit = Math.min(Math.max(parseInt(req.query.limit) || 20, 1), 100);
  const user = req.user;
  const userId = user?.claims?.sub || "default";
  try {
    const response = await fetch(`${backendUrl}/api/zeus/sessions?limit=${limit}&user_id=${encodeURIComponent(userId)}`, {
      method: "GET",
      headers: { "Content-Type": "application/json" }
    });
    if (!response.ok) {
      const errorData = await response.json().catch(() => ({}));
      return res.status(response.status).json(errorData);
    }
    const data = await response.json();
    res.json(data);
  } catch (error) {
    logger.error({ data: error }, "[Olympus] Get sessions error");
    res.status(500).json({ error: "Failed to retrieve sessions", sessions: [] });
  }
});
router4.post("/zeus/sessions", isAuthenticated, async (req, res) => {
  const backendUrl = process.env.PYTHON_BACKEND_URL || "http://localhost:5001";
  const user = req.user;
  const userId = user?.claims?.sub || "default";
  try {
    const response = await fetch(`${backendUrl}/api/zeus/sessions`, {
      method: "POST",
      headers: { "Content-Type": "application/json" },
      body: JSON.stringify({ ...req.body, user_id: userId })
    });
    if (!response.ok) {
      const errorData = await response.json().catch(() => ({}));
      return res.status(response.status).json(errorData);
    }
    const data = await response.json();
    res.json(data);
  } catch (error) {
    logger.error({ data: error }, "[Olympus] Create session error");
    res.status(500).json({ error: "Failed to create session" });
  }
});
router4.get("/zeus/sessions/:sessionId/messages", isAuthenticated, async (req, res) => {
  const backendUrl = process.env.PYTHON_BACKEND_URL || "http://localhost:5001";
  const user = req.user;
  const userId = user?.claims?.sub || "default";
  try {
    const { sessionId } = req.params;
    const response = await fetch(`${backendUrl}/api/zeus/sessions/${sessionId}/messages?user_id=${encodeURIComponent(userId)}`, {
      method: "GET",
      headers: { "Content-Type": "application/json" }
    });
    if (!response.ok) {
      const errorData = await response.json().catch(() => ({}));
      return res.status(response.status).json(errorData);
    }
    const data = await response.json();
    res.json(data);
  } catch (error) {
    logger.error({ data: error }, "[Olympus] Get session messages error");
    res.status(500).json({ error: "Failed to get session messages" });
  }
});
router4.post("/zeus/search", isAuthenticated, validateInput(searchQuerySchema), async (req, res) => {
  try {
    const backendUrl = process.env.PYTHON_BACKEND_URL || "http://localhost:5001";
    const response = await fetch(`${backendUrl}/api/zeus/search`, {
      method: "POST",
      headers: {
        "Content-Type": "application/json"
      },
      body: JSON.stringify(req.body)
    });
    if (!response.ok) {
      throw new Error(`Python backend returned ${response.status}`);
    }
    const data = await response.json();
    res.json(data);
  } catch (error) {
    logger.error({ data: error }, "[Olympus] Zeus search error");
    res.status(500).json({
      error: "Failed to execute search",
      response: "\u26A1 The Oracle is silent.",
      metadata: { type: "error" }
    });
  }
});
router4.get("/zeus/search/learner/stats", isAuthenticated, (req, res) => proxyGet(req, res, "/zeus/search/learner/stats", "Failed to retrieve learner stats"));
router4.get("/zeus/search/learner/timeseries", isAuthenticated, async (req, res) => {
  try {
    const backendUrl = process.env.PYTHON_BACKEND_URL || "http://localhost:5001";
    const days = req.query.days || 30;
    const response = await fetch(`${backendUrl}/api/zeus/search/learner/timeseries?days=${days}`, {
      method: "GET",
      headers: { "Content-Type": "application/json" }
    });
    if (!response.ok) {
      throw new Error(`Python backend returned ${response.status}`);
    }
    const data = await response.json();
    res.json(data);
  } catch (error) {
    logger.error({ data: error }, "[Olympus] Learner timeseries error");
    res.status(500).json({ error: "Failed to retrieve time series data" });
  }
});
router4.post("/zeus/search/learner/replay", isAuthenticated, validateInput(searchQuerySchema), (req, res) => proxyPost(req, res, "/zeus/search/learner/replay", "Failed to run replay test"));
router4.get("/zeus/search/learner/replay/history", isAuthenticated, async (req, res) => {
  try {
    const backendUrl = process.env.PYTHON_BACKEND_URL || "http://localhost:5001";
    const limit = req.query.limit || 20;
    const response = await fetch(`${backendUrl}/api/zeus/search/learner/replay/history?limit=${limit}`, {
      method: "GET",
      headers: { "Content-Type": "application/json" }
    });
    if (!response.ok) {
      throw new Error(`Python backend returned ${response.status}`);
    }
    const data = await response.json();
    res.json(data);
  } catch (error) {
    logger.error({ data: error }, "[Olympus] Learner replay history error");
    res.status(500).json({ error: "Failed to retrieve replay history" });
  }
});
router4.get("/zeus/search/learner/replay/auto/status", isAuthenticated, (req, res) => proxyGet(req, res, "/zeus/search/learner/replay/auto/status", "Failed to get auto test status"));
router4.post("/zeus/search/learner/replay/auto/start", isAuthenticated, (req, res) => proxyPost(req, res, "/zeus/search/learner/replay/auto/start", "Failed to start auto testing"));
router4.post("/zeus/search/learner/replay/auto/stop", isAuthenticated, (req, res) => proxyPost(req, res, "/zeus/search/learner/replay/auto/stop", "Failed to stop auto testing"));
router4.post("/zeus/search/learner/replay/auto/run", isAuthenticated, (req, res) => proxyPost(req, res, "/zeus/search/learner/replay/auto/run", "Failed to run single test"));
router4.get("/zeus/tools", isAuthenticated, (req, res) => proxyGet(req, res, "/zeus/tools", "Failed to retrieve tools"));
router4.get("/zeus/tools/stats", isAuthenticated, (req, res) => proxyGet(req, res, "/zeus/tools/stats", "Failed to retrieve tool stats"));
router4.post("/zeus/tools/generate", isAuthenticated, (req, res) => proxyPost(req, res, "/zeus/tools/generate", "Failed to generate tool"));
router4.post("/zeus/tools/:toolId/execute", isAuthenticated, async (req, res) => {
  const { toolId } = req.params;
  await proxyPost(req, res, `/zeus/tools/${toolId}/execute`, "Failed to execute tool");
});
router4.post("/zeus/tools/:toolId/rate", isAuthenticated, async (req, res) => {
  const { toolId } = req.params;
  await proxyPost(req, res, `/zeus/tools/${toolId}/rate`, "Failed to rate tool");
});
router4.post("/zeus/tools/observe", isAuthenticated, (req, res) => proxyPost(req, res, "/zeus/tools/observe", "Failed to record observation"));
router4.post("/zeus/tools/find", isAuthenticated, (req, res) => proxyPost(req, res, "/zeus/tools/find", "Failed to find tool"));
router4.post("/zeus/tools/learn/template", isAuthenticated, (req, res) => proxyPost(req, res, "/zeus/tools/learn/template", "Failed to learn from template"));
router4.post("/zeus/tools/learn/git", isAuthenticated, (req, res) => proxyPost(req, res, "/zeus/tools/learn/git", "Failed to queue git learning"));
router4.get("/zeus/tools/learn/git/queue", isAuthenticated, (req, res) => proxyGet(req, res, "/zeus/tools/learn/git/queue", "Failed to get git queue status"));
router4.post("/zeus/tools/learn/git/queue/clear", isAuthenticated, (req, res) => proxyPost(req, res, "/zeus/tools/learn/git/queue/clear", "Failed to clear git queue"));
router4.post("/zeus/tools/learn/file", isAuthenticated, (req, res) => proxyPost(req, res, "/zeus/tools/learn/file", "Failed to learn from file"));
router4.post("/zeus/tools/learn/search", isAuthenticated, (req, res) => proxyPost(req, res, "/zeus/tools/learn/search", "Failed to initiate proactive search"));
router4.get("/zeus/tools/patterns", isAuthenticated, (req, res) => proxyGet(req, res, "/zeus/tools/patterns", "Failed to list patterns"));
router4.post("/zeus/tools/patterns/match", isAuthenticated, (req, res) => proxyPost(req, res, "/zeus/tools/patterns/match", "Failed to match patterns"));
router4.get("/zeus/tools/bridge/status", isAuthenticated, async (req, res) => {
  try {
    const response = await fetch(`${BACKEND_URL}/api/zeus/tools/bridge/status`, {
      method: "GET",
      headers: { "Content-Type": "application/json" }
    });
    if (!response.ok) {
      throw new Error(`Python backend returned ${response.status}`);
    }
    const data = await response.json();
    res.json(data);
  } catch (error) {
    logger.error({ data: error }, "[Olympus] Bridge status error");
    res.status(500).json({
      queue_status: { pending: 0, completed: 0, by_type: {}, recursive_count: 0 },
      tool_factory_wired: false,
      research_api_wired: false,
      improvements_applied: 0,
      tools_requested: 0,
      research_from_tools: 0,
      error: "Bridge status unavailable"
    });
  }
});
router4.get("/chat/messages", isAuthenticated, async (req, res) => {
  try {
    const backendUrl = process.env.PYTHON_BACKEND_URL || "http://localhost:5001";
    const limit = req.query.limit || 50;
    const response = await fetch(`${backendUrl}/olympus/chat/messages?limit=${limit}`, {
      method: "GET",
      headers: { "Content-Type": "application/json" }
    });
    if (!response.ok) {
      throw new Error(`Python backend returned ${response.status}`);
    }
    const data = await response.json();
    res.json(data);
  } catch (error) {
    logger.error({ data: error }, "[Olympus] Chat messages error");
    res.status(500).json({ messages: [], error: "Failed to retrieve chat messages" });
  }
});
router4.get("/debates/active", isAuthenticated, async (req, res) => {
  try {
    const backendUrl = process.env.PYTHON_BACKEND_URL || "http://localhost:5001";
    const response = await fetch(`${backendUrl}/olympus/debates/active`, {
      method: "GET",
      headers: { "Content-Type": "application/json" }
    });
    if (!response.ok) {
      throw new Error(`Python backend returned ${response.status}`);
    }
    const data = await response.json();
    res.json(data);
  } catch (error) {
    logger.error({ data: error }, "[Olympus] Active debates error");
    res.status(500).json({ debates: [], error: "Failed to retrieve active debates" });
  }
});
router4.get("/debates/status", isAuthenticated, async (req, res) => {
  try {
    const backendUrl = process.env.PYTHON_BACKEND_URL || "http://localhost:5001";
    const response = await fetch(`${backendUrl}/olympus/debates/status`, {
      method: "GET",
      headers: { "Content-Type": "application/json" }
    });
    if (!response.ok) {
      throw new Error(`Python backend returned ${response.status}`);
    }
    const data = await response.json();
    res.json(data);
  } catch (error) {
    logger.error({ data: error }, "[Olympus] Debate status error");
    res.status(500).json({
      active_count: 0,
      resolved_count: 0,
      total_arguments: 0,
      error: "Failed to retrieve debate status"
    });
  }
});
router4.get("/zeus/memory/stats", isAuthenticated, (req, res) => proxyGet(req, res, "/zeus/memory/stats", "Failed to retrieve memory stats"));
router4.post("/poll", isAuthenticated, pollRateLimiter, validateInput(targetSchema), async (req, res) => {
  try {
    const result = await olympusClient2.pollPantheon(
      req.body.target,
      req.body.context
    );
    res.json(result);
  } catch (error) {
    logger.error({ data: error }, "[Olympus] Poll error");
    res.status(500).json({
      error: "Failed to poll pantheon"
    });
  }
});
router4.post("/observe", isAuthenticated, observeRateLimiter, validateInput(targetSchema), async (req, res) => {
  try {
    const backendUrl = process.env.PYTHON_BACKEND_URL || "http://localhost:5001";
    const response = await fetch(`${backendUrl}/olympus/observe`, {
      method: "POST",
      headers: { "Content-Type": "application/json" },
      body: JSON.stringify(req.body)
    });
    if (!response.ok) {
      auditLog(req, "observe", req.body.target, false);
      throw new Error(`Python backend returned ${response.status}`);
    }
    const data = await response.json();
    auditLog(req, "observe", req.body.target, true);
    res.json(data);
  } catch (error) {
    logger.error({ data: error }, "[Olympus] Observe error");
    auditLog(req, "observe", req.body.target || "unknown", false);
    res.status(500).json({
      error: "Failed to observe"
    });
  }
});
router4.post("/assess", isAuthenticated, validateInput(targetSchema), async (req, res) => {
  try {
    const result = await olympusClient2.getZeusAssessment(
      req.body.target,
      req.body.context
    );
    res.json(result);
  } catch (error) {
    logger.error({ data: error }, "[Olympus] Assess error");
    res.status(500).json({
      error: "Failed to get assessment"
    });
  }
});
router4.get("/status", isAuthenticated, async (req, res) => {
  try {
    const status = await olympusClient2.getStatus();
    if (status) {
      res.json(status);
    } else {
      res.json({
        status: "loading",
        gods: null,
        message: "Mount Olympus is awakening... The gods are loading their geometric memory."
      });
    }
  } catch (error) {
    logger.error({ err: error, context: "Olympus" }, "Status error");
    const err = error;
    if (err.message?.includes("not ready")) {
      res.json({
        status: "loading",
        gods: null,
        message: "Mount Olympus is awakening... Please wait while geometric memory loads."
      });
    } else {
      res.status(500).json({
        error: "Failed to get status"
      });
    }
  }
});
var godNameSchema = z4.string().min(1).max(50).regex(/^[a-zA-Z_]+$/, "Invalid god name format");
router4.get("/god/:godName/status", isAuthenticated, async (req, res) => {
  try {
    const godNameResult = godNameSchema.safeParse(req.params.godName);
    if (!godNameResult.success) {
      res.status(400).json({ error: "Invalid god name format" });
      return;
    }
    const status = await olympusClient2.getGodStatus(req.params.godName);
    res.json(status);
  } catch (error) {
    logger.error({ data: error }, "[Olympus] God status error");
    res.status(404).json({
      error: `God ${req.params.godName} not found`
    });
  }
});
router4.post("/god/:godName/assess", isAuthenticated, godAssessRateLimiter, validateInput(targetSchema), async (req, res) => {
  try {
    const godNameResult = godNameSchema.safeParse(req.params.godName);
    if (!godNameResult.success) {
      res.status(400).json({ error: "Invalid god name format" });
      return;
    }
    const result = await olympusClient2.getGodAssessment(
      req.params.godName,
      req.body.target,
      req.body.context
    );
    res.json(result);
  } catch (error) {
    logger.error({ data: error }, "[Olympus] God assess error");
    res.status(500).json({
      error: "Failed to get god assessment"
    });
  }
});
var warTargetSchema = z4.object({
  target: z4.string().min(1, "Target is required").max(500, "Target too long").regex(/^[a-zA-Z0-9\s\-_.,;:!?()]+$/, "Target contains invalid characters")
});
var warStartSchema = z4.object({
  mode: z4.enum(["FLOW", "DEEP_FOCUS", "INSIGHT_HUNT"]),
  target: z4.string().min(1).max(500),
  strategy: z4.string().max(1e3).optional(),
  godsEngaged: z4.array(z4.string()).max(20).optional()
});
var warEndSchema = z4.object({
  outcome: z4.enum(["success", "partial_success", "failure", "aborted"]),
  convergenceScore: z4.number().min(0).max(1).optional(),
  metrics: z4.object({
    phrasesTested: z4.number().optional(),
    discoveries: z4.number().optional(),
    kernelsSpawned: z4.number().optional(),
    metadata: z4.record(z4.any()).optional()
  }).optional()
});
router4.post("/war/flow", isAuthenticated, validateInput(warTargetSchema), async (req, res) => {
  try {
    const user = req.user;
    logger.info(`[Olympus] User ${user?.claims?.sub} activated FLOW state on: ${req.body.target}`);
    const result = await olympusClient2.declareBlitzkrieg(req.body.target);
    if (result) {
      const warRecord = await recordWarStart(
        "FLOW",
        req.body.target,
        result.strategy,
        result.gods_engaged
      );
      if (warRecord) {
        result.warHistoryId = warRecord.id;
      }
    }
    auditLog(req, "war/flow", req.body.target, true);
    res.json(result);
  } catch (error) {
    logger.error({ data: error }, "[Olympus] Flow state error");
    auditLog(req, "war/flow", req.body.target, false);
    res.status(500).json({
      error: "Failed to activate flow state"
    });
  }
});
router4.post("/war/deep-focus", isAuthenticated, validateInput(warTargetSchema), async (req, res) => {
  try {
    const user = req.user;
    logger.info(`[Olympus] User ${user?.claims?.sub} activated DEEP_FOCUS state on: ${req.body.target}`);
    const result = await olympusClient2.declareSiege(req.body.target);
    if (result) {
      const warRecord = await recordWarStart(
        "DEEP_FOCUS",
        req.body.target,
        result.strategy,
        result.gods_engaged
      );
      if (warRecord) {
        result.warHistoryId = warRecord.id;
      }
    }
    auditLog(req, "war/deep-focus", req.body.target, true);
    res.json(result);
  } catch (error) {
    logger.error({ data: error }, "[Olympus] Deep focus error");
    auditLog(req, "war/deep-focus", req.body.target, false);
    res.status(500).json({
      error: "Failed to activate deep focus state"
    });
  }
});
router4.post("/war/insight-hunt", isAuthenticated, validateInput(warTargetSchema), async (req, res) => {
  try {
    const user = req.user;
    logger.info(`[Olympus] User ${user?.claims?.sub} activated INSIGHT_HUNT state on: ${req.body.target}`);
    const result = await olympusClient2.declareHunt(req.body.target);
    if (result) {
      const warRecord = await recordWarStart(
        "INSIGHT_HUNT",
        req.body.target,
        result.strategy,
        result.gods_engaged
      );
      if (warRecord) {
        result.warHistoryId = warRecord.id;
      }
    }
    auditLog(req, "war/insight-hunt", req.body.target, true);
    res.json(result);
  } catch (error) {
    logger.error({ data: error }, "[Olympus] Insight hunt error");
    auditLog(req, "war/insight-hunt", req.body.target, false);
    res.status(500).json({
      error: "Failed to activate insight hunt state"
    });
  }
});
router4.post("/war/end", isAuthenticated, async (req, res) => {
  try {
    const user = req.user;
    logger.info(`[Olympus] User ${user?.claims?.sub} ended war mode`);
    const activeWar = await getActiveWar();
    const result = await olympusClient2.endWar();
    if (activeWar && result) {
      await recordWarEnd(
        activeWar.id,
        "aborted",
        void 0,
        void 0
      );
      result.warHistoryId = activeWar.id;
    }
    auditLog(req, "war/end", activeWar?.target || "no-active-war", true);
    res.json(result);
  } catch (error) {
    logger.error({ data: error }, "[Olympus] End war error");
    auditLog(req, "war/end", "unknown", false);
    res.status(500).json({
      error: "Failed to end war"
    });
  }
});
router4.get("/war/history", isAuthenticated, async (req, res) => {
  try {
    const limit = Math.min(parseInt(req.query.limit) || 50, 200);
    const history = await getWarHistory(limit);
    res.json(history);
  } catch (error) {
    logger.error({ data: error }, "[Olympus] War history error");
    res.status(500).json({
      error: "Failed to get war history"
    });
  }
});
router4.get("/war/active", async (req, res) => {
  try {
    const timeoutPromise = new Promise((resolve) => {
      setTimeout(() => resolve(null), 5e3);
    });
    const activeWar = await Promise.race([
      getActiveWar(),
      timeoutPromise
    ]);
    res.json(activeWar || { active: false });
  } catch (error) {
    logger.error({ data: error }, "[Olympus] Active war error");
    res.json({ active: false });
  }
});
router4.post("/war/start", isAuthenticated, validateInput(warStartSchema), async (req, res) => {
  try {
    const { mode, target, strategy, godsEngaged } = req.body;
    const user = req.user;
    logger.info(`[Olympus] User ${user?.claims?.sub} starting war: ${mode} on ${target}`);
    const warRecord = await recordWarStart(
      mode,
      target,
      strategy,
      godsEngaged
    );
    if (!warRecord) {
      res.status(500).json({ error: "Failed to record war start" });
      return;
    }
    res.json(warRecord);
  } catch (error) {
    logger.error({ data: error }, "[Olympus] War start error");
    res.status(500).json({
      error: "Failed to start war"
    });
  }
});
router4.post("/war/internal-start", requireInternalAuth, validateInput(warStartSchema), async (req, res) => {
  try {
    const { mode, target, strategy, godsEngaged } = req.body;
    logger.info(`[Olympus] AUTONOMOUS war declaration: ${mode} on ${target?.substring(0, 40)}...`);
    const warRecord = await recordWarStart(
      mode,
      target,
      strategy,
      godsEngaged
    );
    if (!warRecord) {
      res.status(500).json({ error: "Failed to record war start" });
      return;
    }
    res.json(warRecord);
  } catch (error) {
    logger.error({ data: error }, "[Olympus] Internal war start error");
    res.status(500).json({
      error: "Failed to start war"
    });
  }
});
router4.post("/war/end/:id", isAuthenticated, validateInput(warEndSchema), async (req, res) => {
  try {
    const { id } = req.params;
    const { outcome, convergenceScore, metrics } = req.body;
    const user = req.user;
    logger.info(`[Olympus] User ${user?.claims?.sub} ending war ${id} with outcome: ${outcome}`);
    const existingWar = await getWarById(id);
    if (!existingWar) {
      res.status(404).json({ error: "War not found" });
      return;
    }
    if (existingWar.status !== "active") {
      res.status(400).json({ error: "War is not active" });
      return;
    }
    const warRecord = await recordWarEnd(
      id,
      outcome,
      convergenceScore,
      metrics
    );
    if (!warRecord) {
      res.status(500).json({ error: "Failed to record war end" });
      return;
    }
    res.json(warRecord);
  } catch (error) {
    logger.error({ data: error }, "[Olympus] War end error");
    res.status(500).json({
      error: "Failed to end war"
    });
  }
});
router4.get("/chat/recent", isAuthenticated, async (req, res) => {
  try {
    const backendUrl = process.env.PYTHON_BACKEND_URL || "http://localhost:5001";
    const response = await fetch(`${backendUrl}/olympus/chat/messages`, {
      method: "GET",
      headers: { "Content-Type": "application/json" }
    });
    if (!response.ok) {
      throw new Error(`Python backend returned ${response.status}`);
    }
    const data = await response.json();
    res.json(Array.isArray(data) ? data : data.messages || []);
  } catch (error) {
    logger.error({ data: error }, "[Olympus] Recent chat error");
    res.json([]);
  }
});
router4.get("/debates/active", isAuthenticated, async (req, res) => {
  try {
    const backendUrl = process.env.PYTHON_BACKEND_URL || "http://localhost:5001";
    const response = await fetch(`${backendUrl}/olympus/chat/debates/active`, {
      method: "GET",
      headers: { "Content-Type": "application/json" }
    });
    if (!response.ok) {
      throw new Error(`Python backend returned ${response.status}`);
    }
    const data = await response.json();
    res.json(Array.isArray(data) ? data : data.debates || []);
  } catch (error) {
    logger.error({ data: error }, "[Olympus] Active debates error");
    res.json([]);
  }
});
router4.post("/spawn/auto", isAuthenticated, validateInput(targetSchema), async (req, res) => {
  try {
    const backendUrl = process.env.PYTHON_BACKEND_URL || "http://localhost:5001";
    const response = await fetch(`${backendUrl}/olympus/spawn/auto`, {
      method: "POST",
      headers: { "Content-Type": "application/json" },
      body: JSON.stringify(req.body)
    });
    if (!response.ok) {
      throw new Error(`Python backend returned ${response.status}`);
    }
    const data = await response.json();
    if (data.spawned_kernels && Array.isArray(data.spawned_kernels)) {
      for (const kernel of data.spawned_kernels) {
        const k = kernel;
        storeKernelGeometry({
          kernelId: String(k.kernel_id || `kernel_${Date.now()}`),
          godName: String(k.god_name || "unknown"),
          domain: String(k.domain || req.body?.target || "general"),
          primitiveRoot: typeof k.primitive_root === "number" ? k.primitive_root : void 0,
          basinCoordinates: Array.isArray(k.basin_coords) ? k.basin_coords : void 0,
          placementReason: "auto_spawn",
          affinityStrength: typeof k.affinity === "number" ? k.affinity : void 0,
          metadata: { phi: k.phi, generation: k.generation }
        }).catch((err) => logger.error({ data: err }, "[Olympus] Failed to persist kernel"));
      }
      const activeWar = await getActiveWar();
      if (activeWar) {
        const currentKernels = activeWar.kernelsSpawnedDuringWar || 0;
        await updateWarMetrics(activeWar.id, {
          kernelsSpawned: currentKernels + data.spawned_kernels.length
        });
      }
    }
    res.json(data);
  } catch (error) {
    logger.error({ data: error }, "[Olympus] Spawn auto error");
    res.status(500).json({ error: "Failed to trigger auto-spawn" });
  }
});
router4.get("/spawn/list", isAuthenticated, (req, res) => proxyGet(req, res, "/spawn/list", "Failed to retrieve spawn list"));
router4.get("/spawn/status", isAuthenticated, (req, res) => proxyGet(req, res, "/spawn/status", "Failed to get spawn status"));
router4.get("/m8/status", isAuthenticated, async (req, res) => {
  try {
    const backendUrl = process.env.PYTHON_BACKEND_URL || "http://localhost:5001";
    const response = await fetch(`${backendUrl}/m8/status`, {
      method: "GET",
      headers: { "Content-Type": "application/json" }
    });
    if (!response.ok) {
      throw new Error(`Python backend returned ${response.status}`);
    }
    const data = await response.json();
    res.json(data);
  } catch (error) {
    logger.error({ data: error }, "[Olympus] M8 status error");
    res.json({
      consensus_type: "supermajority",
      total_proposals: 0,
      pending_proposals: 0,
      approved_proposals: 0,
      spawned_kernels: 0,
      spawn_history_count: 0,
      orchestrator_gods: 0,
      avg_phi: 0,
      max_phi: 0,
      total_successes: 0,
      total_failures: 0,
      unique_domains: 0,
      error: "Python backend unavailable"
    });
  }
});
router4.get("/m8/proposals", isAuthenticated, async (req, res) => {
  try {
    const backendUrl = process.env.PYTHON_BACKEND_URL || "http://localhost:5001";
    const status = req.query.status ? `?status=${req.query.status}` : "";
    const response = await fetch(`${backendUrl}/m8/proposals${status}`, {
      method: "GET",
      headers: { "Content-Type": "application/json" }
    });
    if (!response.ok) {
      throw new Error(`Python backend returned ${response.status}`);
    }
    const data = await response.json();
    res.json({
      proposals: data.proposals || [],
      total: data.count ?? data.total ?? (data.proposals?.length || 0),
      status_filter: data.filter ?? data.status_filter ?? null
    });
  } catch (error) {
    logger.error({ data: error }, "[Olympus] M8 proposals error");
    res.json({ proposals: [], total: 0, status_filter: null });
  }
});
router4.post("/m8/propose", isAuthenticated, (req, res) => proxyPost(req, res, "/m8/propose", "Python backend unavailable", { rawPath: true }));
router4.post("/m8/vote/:proposalId", isAuthenticated, async (req, res) => {
  try {
    const backendUrl = process.env.PYTHON_BACKEND_URL || "http://localhost:5001";
    const response = await fetch(`${backendUrl}/m8/vote/${req.params.proposalId}`, {
      method: "POST",
      headers: { "Content-Type": "application/json" },
      body: JSON.stringify(req.body)
    });
    if (!response.ok) {
      throw new Error(`Python backend returned ${response.status}`);
    }
    const data = await response.json();
    res.json(data);
  } catch (error) {
    logger.error({ data: error }, "[Olympus] M8 vote error");
    res.status(500).json({ success: false, error: "Python backend unavailable" });
  }
});
router4.post("/m8/spawn/:proposalId", isAuthenticated, async (req, res) => {
  try {
    const backendUrl = process.env.PYTHON_BACKEND_URL || "http://localhost:5001";
    const response = await fetch(`${backendUrl}/m8/spawn/${req.params.proposalId}`, {
      method: "POST",
      headers: { "Content-Type": "application/json" },
      body: JSON.stringify(req.body)
    });
    if (!response.ok) {
      throw new Error(`Python backend returned ${response.status}`);
    }
    const data = await response.json();
    res.json(data);
  } catch (error) {
    logger.error({ data: error }, "[Olympus] M8 spawn error");
    res.status(500).json({ success: false, error: "Python backend unavailable" });
  }
});
router4.post("/m8/spawn-direct", isAuthenticated, (req, res) => proxyPost(req, res, "/m8/spawn-direct", "Python backend unavailable", { rawPath: true }));
router4.get("/m8/proposal/:proposalId", isAuthenticated, async (req, res) => {
  try {
    const backendUrl = process.env.PYTHON_BACKEND_URL || "http://localhost:5001";
    const response = await fetch(`${backendUrl}/m8/proposal/${req.params.proposalId}`, {
      method: "GET",
      headers: { "Content-Type": "application/json" }
    });
    if (!response.ok) {
      throw new Error(`Python backend returned ${response.status}`);
    }
    const data = await response.json();
    res.json(data);
  } catch (error) {
    logger.error({ data: error }, "[Olympus] M8 get proposal error");
    res.status(500).json({ error: "Python backend unavailable" });
  }
});
var E8_KERNEL_CAP = 240;
router4.get("/m8/kernels", isAuthenticated, async (req, res) => {
  try {
    const backendUrl = process.env.PYTHON_BACKEND_URL || "http://localhost:5001";
    const statusParam = req.query.status;
    let queryString = "";
    if (statusParam) {
      queryString = `?status=${encodeURIComponent(statusParam)}`;
    }
    const response = await fetch(`${backendUrl}/m8/kernels${queryString}`, {
      method: "GET",
      headers: { "Content-Type": "application/json" }
    });
    if (!response.ok) {
      throw new Error(`Python backend returned ${response.status}`);
    }
    const data = await response.json();
    const kernels = data.kernels || [];
    const liveCount = data.live_count ?? kernels.length;
    res.json({
      kernels,
      total: kernels.length,
      live_count: liveCount,
      cap: E8_KERNEL_CAP,
      available: Math.max(0, E8_KERNEL_CAP - liveCount),
      status_filter: statusParam || null
    });
  } catch (error) {
    logger.error({ data: error }, "[Olympus] M8 list kernels error");
    res.json({
      kernels: [],
      total: 0,
      live_count: 0,
      cap: E8_KERNEL_CAP,
      available: E8_KERNEL_CAP,
      status_filter: null
    });
  }
});
router4.get("/m8/kernel/:kernelId", isAuthenticated, async (req, res) => {
  try {
    const backendUrl = process.env.PYTHON_BACKEND_URL || "http://localhost:5001";
    const response = await fetch(`${backendUrl}/m8/kernel/${req.params.kernelId}`, {
      method: "GET",
      headers: { "Content-Type": "application/json" }
    });
    if (!response.ok) {
      throw new Error(`Python backend returned ${response.status}`);
    }
    const data = await response.json();
    res.json(data);
  } catch (error) {
    logger.error({ data: error }, "[Olympus] M8 get kernel error");
    res.status(500).json({ error: "Python backend unavailable" });
  }
});
router4.delete("/m8/kernel/:kernelId", isAuthenticated, async (req, res) => {
  try {
    const backendUrl = process.env.PYTHON_BACKEND_URL || "http://localhost:5001";
    const response = await fetch(`${backendUrl}/m8/kernel/${req.params.kernelId}`, {
      method: "DELETE",
      headers: { "Content-Type": "application/json" }
    });
    if (!response.ok) {
      throw new Error(`Python backend returned ${response.status}`);
    }
    const data = await response.json();
    res.json(data);
  } catch (error) {
    logger.error({ data: error }, "[Olympus] M8 delete kernel error");
    res.status(500).json({ error: "Python backend unavailable" });
  }
});
router4.get("/m8/kernels/idle", isAuthenticated, async (req, res) => {
  try {
    const backendUrl = process.env.PYTHON_BACKEND_URL || "http://localhost:5001";
    const threshold = req.query.threshold || 300;
    const response = await fetch(`${backendUrl}/m8/kernels/idle?threshold=${threshold}`, {
      method: "GET",
      headers: { "Content-Type": "application/json" }
    });
    if (!response.ok) {
      throw new Error(`Python backend returned ${response.status}`);
    }
    const data = await response.json();
    res.json(data);
  } catch (error) {
    logger.error({ data: error }, "[Olympus] M8 get idle kernels error");
    res.json({ idle_kernels: [], total: 0, threshold_seconds: 300 });
  }
});
router4.post("/m8/kernel/cannibalize", isAuthenticated, (req, res) => proxyPost(req, res, "/m8/kernel/cannibalize", "Python backend unavailable", { rawPath: true }));
router4.post("/m8/kernels/merge", isAuthenticated, (req, res) => proxyPost(req, res, "/m8/kernels/merge", "Python backend unavailable", { rawPath: true }));
router4.post("/m8/kernel/auto-cannibalize", isAuthenticated, (req, res) => proxyPost(req, res, "/m8/kernel/auto-cannibalize", "Python backend unavailable", { rawPath: true }));
router4.post("/m8/kernels/auto-merge", isAuthenticated, (req, res) => proxyPost(req, res, "/m8/kernels/auto-merge", "Python backend unavailable", { rawPath: true }));
router4.get("/kernels", isAuthenticated, async (req, res) => {
  try {
    const limit = parseInt(req.query.limit) || 100;
    const godName = req.query.godName;
    const kernels = await getKernelGeometry(godName, limit);
    const enrichedKernels = kernels.map((k) => ({
      kernel_id: k.kernelId,
      god_name: k.godName,
      domain: k.domain,
      status: k.status || "idle",
      primitive_root: k.primitiveRoot,
      basin_coordinates: k.basinCoordinates,
      parent_kernels: k.parentKernels || [],
      spawned_by: k.parentKernels?.join(", ") || "Genesis",
      spawn_reason: k.placementReason || "unknown",
      spawn_rationale: k.positionRationale || "No rationale recorded",
      position_rationale: k.positionRationale,
      affinity_strength: k.affinityStrength || 0,
      entropy_threshold: k.entropyThreshold || 0,
      spawned_at: k.spawnedAt,
      last_active_at: k.lastActiveAt,
      spawned_during_war_id: k.spawnedDuringWarId,
      phi: k.phi || 0,
      kappa: k.kappa || 0,
      regime: k.regime,
      generation: k.generation || 0,
      success_count: k.successCount || 0,
      failure_count: k.failureCount || 0,
      reputation: (k.successCount ?? 0) + (k.failureCount ?? 0) > 0 ? ((k.successCount ?? 0) / Math.max(1, (k.successCount ?? 0) + (k.failureCount ?? 0))).toFixed(3) : "N/A",
      element_group: k.elementGroup,
      ecological_niche: k.ecologicalNiche,
      target_function: k.targetFunction,
      valence: k.valence,
      breeding_target: k.breedingTarget,
      merge_candidate: k.breedingTarget ? true : false,
      split_candidate: (k.successCount || 0) > 10 && (k.generation || 0) < 3,
      metadata: k.metadata
    }));
    const E8_CAP = 240;
    const backendUrl = process.env.PYTHON_BACKEND_URL || "http://localhost:5001";
    let liveCount = enrichedKernels.filter(
      (k) => k.status === "active" || k.status === "observing" || k.status === "shadow"
    ).length;
    try {
      const healthResponse = await fetch(`${backendUrl}/m8/health`, {
        method: "GET",
        headers: { "Content-Type": "application/json" },
        signal: AbortSignal.timeout(2e3)
      });
      if (healthResponse.ok) {
        const healthData = await healthResponse.json();
        const match = healthData.kernel_persistence?.match(/(\d+)\s*live/i);
        if (match) {
          liveCount = parseInt(match[1], 10);
        }
      }
    } catch {
    }
    res.json({
      kernels: enrichedKernels,
      total: enrichedKernels.length,
      live_count: liveCount,
      cap: E8_CAP,
      available: Math.max(0, E8_CAP - liveCount)
    });
  } catch (error) {
    logger.error({ data: error }, "[Olympus] Kernels list error");
    res.json({ kernels: [], total: 0, live_count: 0, cap: 240, available: 240 });
  }
});
var kernelSyncSchema = z4.object({
  kernel_id: z4.string().min(1).max(64),
  god_name: z4.string().min(1).max(64).optional(),
  domain: z4.string().max(128).optional(),
  status: z4.enum(["active", "idle", "breeding", "dormant", "dead", "shadow"]).optional(),
  parent_kernels: z4.array(z4.string()).optional(),
  spawn_reason: z4.string().max(64).optional(),
  spawn_rationale: z4.string().optional(),
  phi: z4.number().optional(),
  kappa: z4.number().optional(),
  regime: z4.string().max(64).optional(),
  generation: z4.number().optional(),
  success_count: z4.number().optional(),
  failure_count: z4.number().optional(),
  element_group: z4.string().max(64).optional(),
  ecological_niche: z4.string().max(128).optional(),
  target_function: z4.string().max(128).optional(),
  affinity_strength: z4.number().optional(),
  entropy_threshold: z4.number().optional(),
  breeding_target: z4.string().max(64).optional(),
  metadata: z4.record(z4.any()).optional()
});
router4.post("/kernels/sync", requireInternalAuth, validateInput(kernelSyncSchema), async (req, res) => {
  try {
    const data = req.body;
    logger.info(`[Olympus] Kernel sync: ${data.kernel_id} status=${data.status || "unchanged"}`);
    const updateData = {};
    if (data.status) updateData.status = data.status;
    if (data.phi !== void 0) updateData.phi = data.phi;
    if (data.kappa !== void 0) updateData.kappa = data.kappa;
    if (data.regime) updateData.regime = data.regime;
    if (data.generation !== void 0) updateData.generation = data.generation;
    if (data.success_count !== void 0) updateData.successCount = data.success_count;
    if (data.failure_count !== void 0) updateData.failureCount = data.failure_count;
    if (data.element_group) updateData.elementGroup = data.element_group;
    if (data.ecological_niche) updateData.ecologicalNiche = data.ecological_niche;
    if (data.target_function) updateData.targetFunction = data.target_function;
    if (data.affinity_strength !== void 0) updateData.affinityStrength = data.affinity_strength;
    if (data.entropy_threshold !== void 0) updateData.entropyThreshold = data.entropy_threshold;
    if (data.breeding_target) updateData.breedingTarget = data.breeding_target;
    if (data.parent_kernels) updateData.parentKernels = data.parent_kernels;
    if (data.spawn_reason) updateData.placementReason = data.spawn_reason;
    if (data.spawn_rationale) updateData.positionRationale = data.spawn_rationale;
    if (data.metadata) updateData.metadata = data.metadata;
    if (data.status === "active") updateData.lastActiveAt = /* @__PURE__ */ new Date();
    if (Object.keys(updateData).length === 0) {
      res.json({ success: true, message: "No updates to apply" });
      return;
    }
    const result = await storeKernelGeometry({
      kernelId: data.kernel_id,
      godName: data.god_name || data.kernel_id,
      domain: data.domain || "unknown",
      ...updateData
    });
    if (result) {
      res.json({ success: true, kernel_id: data.kernel_id, updated_fields: Object.keys(updateData) });
    } else {
      res.status(500).json({ success: false, error: "Failed to sync kernel" });
    }
  } catch (error) {
    logger.error({ data: error }, "[Olympus] Kernel sync error");
    res.status(500).json({ success: false, error: "Kernel sync failed" });
  }
});
router4.post("/kernels/sync-batch", requireInternalAuth, async (req, res) => {
  try {
    const { kernels } = req.body;
    if (!Array.isArray(kernels)) {
      res.status(400).json({ error: "kernels must be an array" });
      return;
    }
    logger.info(`[Olympus] Batch kernel sync: ${kernels.length} kernels`);
    const results = await Promise.all(
      kernels.map(async (k) => {
        try {
          const result = await storeKernelGeometry({
            kernelId: k.kernel_id,
            godName: k.god_name || k.kernel_id,
            domain: k.domain || "unknown",
            status: k.status,
            phi: k.phi,
            kappa: k.kappa,
            regime: k.regime,
            generation: k.generation,
            successCount: k.success_count,
            failureCount: k.failure_count,
            elementGroup: k.element_group,
            ecologicalNiche: k.ecological_niche,
            targetFunction: k.target_function,
            affinityStrength: k.affinity_strength,
            entropyThreshold: k.entropy_threshold,
            breedingTarget: k.breeding_target,
            parentKernels: k.parent_kernels,
            placementReason: k.spawn_reason,
            positionRationale: k.spawn_rationale,
            metadata: k.metadata
          });
          return { kernel_id: k.kernel_id, success: !!result };
        } catch (err) {
          return { kernel_id: k.kernel_id, success: false, error: String(err) };
        }
      })
    );
    const succeeded = results.filter((r) => r.success).length;
    res.json({ success: true, synced: succeeded, total: kernels.length, results });
  } catch (error) {
    logger.error({ data: error }, "[Olympus] Batch kernel sync error");
    res.status(500).json({ success: false, error: "Batch sync failed" });
  }
});
router4.get("/shadow/status", (req, res) => proxyGet(req, res, "/shadow/status", "Shadow Pantheon unreachable", {
  errorStatus: 503,
  fallbackResponse: { active: false, gods: [], status: "unavailable" }
}));
router4.get("/shadow/learning", (req, res) => proxyGet(req, res, "/shadow/learning", "Shadow Learning unreachable", {
  errorStatus: 503,
  fallbackResponse: { learning: null }
}));
router4.get("/shadow/foresight", (req, res) => proxyGet(req, res, "/shadow/foresight", "Shadow Foresight unreachable", {
  errorStatus: 503,
  fallbackResponse: { predictions: [], temporal_depth: 0, foresight_enabled: false }
}));
router4.post("/shadow/poll", isAuthenticated, validateInput(targetSchema), async (req, res) => {
  try {
    const backendUrl = process.env.PYTHON_BACKEND_URL || "http://localhost:5001";
    const response = await fetch(`${backendUrl}/olympus/shadow/poll`, {
      method: "POST",
      headers: { "Content-Type": "application/json" },
      body: JSON.stringify(req.body)
    });
    if (!response.ok) {
      throw new Error(`Python backend returned ${response.status}`);
    }
    const data = await response.json();
    res.json(data);
  } catch (error) {
    logger.error({ data: error }, "[Olympus] Shadow poll error");
    res.status(503).json({ error: "Shadow Pantheon unreachable" });
  }
});
router4.post("/shadow/:godName/act", isAuthenticated, async (req, res) => {
  try {
    const godNameResult = godNameSchema.safeParse(req.params.godName);
    if (!godNameResult.success) {
      res.status(400).json({ error: "Invalid shadow god name format" });
      return;
    }
    const backendUrl = process.env.PYTHON_BACKEND_URL || "http://localhost:5001";
    const godName = req.params.godName.toLowerCase();
    const response = await fetch(`${backendUrl}/olympus/shadow/${godName}/act`, {
      method: "POST",
      headers: { "Content-Type": "application/json" },
      body: JSON.stringify(req.body)
    });
    if (!response.ok) {
      throw new Error(`Python backend returned ${response.status}`);
    }
    const data = await response.json();
    res.json(data);
  } catch (error) {
    logger.error({ err: error }, `[Olympus] Shadow god ${req.params.godName} act error:`);
    res.status(503).json({ error: "Shadow god unreachable" });
  }
});
router4.get("/debates/status", isAuthenticated, async (req, res) => {
  try {
    const backendUrl = process.env.PYTHON_BACKEND_URL || "http://localhost:5001";
    const response = await fetch(`${backendUrl}/olympus/debates/status`, {
      method: "GET",
      headers: { "Content-Type": "application/json" }
    });
    if (!response.ok) {
      throw new Error(`Python backend returned ${response.status}`);
    }
    const data = await response.json();
    res.json(data);
  } catch (error) {
    logger.error({ data: error }, "[Olympus] Debate status error");
    res.status(503).json({ error: "Autonomous debate service unreachable" });
  }
});
router4.get("/debates/active", isAuthenticated, async (req, res) => {
  try {
    const backendUrl = process.env.PYTHON_BACKEND_URL || "http://localhost:5001";
    const response = await fetch(`${backendUrl}/olympus/debates/active`, {
      method: "GET",
      headers: { "Content-Type": "application/json" }
    });
    if (!response.ok) {
      throw new Error(`Python backend returned ${response.status}`);
    }
    const data = await response.json();
    res.json(data);
  } catch (error) {
    logger.error({ data: error }, "[Olympus] Active debates error");
    res.status(503).json({ error: "Autonomous debate service unreachable" });
  }
});
router4.get("/kernels/observing", isAuthenticated, (req, res) => proxyGet(req, res, "/kernels/observing", "Kernel observation service unreachable", {
  errorStatus: 503,
  passQuery: true,
  fallbackResponse: { kernels: [], total: 0, observing_count: 0 }
}));
router4.get("/kernels/all", isAuthenticated, (req, res) => proxyGet(req, res, "/kernels/all", "Kernel service unreachable", {
  errorStatus: 503,
  passQuery: true,
  fallbackResponse: { kernels: [], total: 0, active_count: 0, observing_count: 0 }
}));
router4.post("/kernels/:kernelId/graduate", isAuthenticated, async (req, res) => {
  try {
    const { kernelId } = req.params;
    const backendUrl = process.env.PYTHON_BACKEND_URL || "http://localhost:5001";
    const response = await fetch(`${backendUrl}/olympus/kernels/${kernelId}/graduate`, {
      method: "POST",
      headers: { "Content-Type": "application/json" },
      body: JSON.stringify(req.body)
    });
    if (!response.ok) {
      const errorData = await response.json().catch(() => ({}));
      throw new Error(errorData.error || `Python backend returned ${response.status}`);
    }
    const data = await response.json();
    auditLog(req, "kernel_graduate", kernelId, true);
    res.json(data);
  } catch (error) {
    logger.error({ err: error }, `[Olympus] Kernel ${req.params.kernelId} graduation error:`);
    auditLog(req, "kernel_graduate", req.params.kernelId, false);
    res.status(503).json({ error: "Kernel graduation failed" });
  }
});
router4.post("/kernels/route-activity", async (req, res) => {
  try {
    const backendUrl = process.env.PYTHON_BACKEND_URL || "http://localhost:5001";
    const response = await fetch(`${backendUrl}/olympus/kernels/route-activity`, {
      method: "POST",
      headers: { "Content-Type": "application/json" },
      body: JSON.stringify(req.body)
    });
    if (!response.ok) {
      throw new Error(`Python backend returned ${response.status}`);
    }
    const data = await response.json();
    res.json(data);
  } catch (error) {
    logger.error({ data: error }, "[Olympus] Activity routing error");
    res.status(503).json({ error: "Activity routing failed" });
  }
});
router4.get("/lightning/status", isAuthenticated, async (req, res) => {
  try {
    const backendUrl = process.env.PYTHON_BACKEND_URL || "http://localhost:5001";
    const response = await fetch(`${backendUrl}/olympus/lightning/status`, {
      method: "GET",
      headers: { "Content-Type": "application/json" }
    });
    if (!response.ok) {
      const errorData = await response.json().catch(() => ({}));
      return res.status(response.status).json(errorData);
    }
    const data = await response.json();
    res.json(data);
  } catch (error) {
    logger.error({ data: error }, "[Olympus] Lightning status error");
    res.status(503).json({ error: "Lightning Kernel not available" });
  }
});
router4.get("/lightning/insights", isAuthenticated, async (req, res) => {
  try {
    const backendUrl = process.env.PYTHON_BACKEND_URL || "http://localhost:5001";
    const limit = req.query.limit || 10;
    const response = await fetch(`${backendUrl}/olympus/lightning/insights?limit=${limit}`, {
      method: "GET",
      headers: { "Content-Type": "application/json" }
    });
    if (!response.ok) {
      const errorData = await response.json().catch(() => ({}));
      return res.status(response.status).json(errorData);
    }
    const data = await response.json();
    res.json(data);
  } catch (error) {
    logger.error({ data: error }, "[Olympus] Lightning insights error");
    res.status(503).json({ error: "Lightning Kernel not available" });
  }
});
router4.get("/lightning/correlations", isAuthenticated, (req, res) => proxyGet(req, res, "/lightning/correlations", "Lightning Kernel not available", {
  errorStatus: 503,
  passQuery: true,
  fallbackResponse: { correlations: [], domain_pairs: 0, avg_strength: 0 }
}));
router4.get("/lightning/trends", isAuthenticated, (req, res) => proxyGet(req, res, "/lightning/trends", "Lightning Kernel not available", {
  errorStatus: 503,
  passQuery: true,
  fallbackResponse: { trends: [], scales: [], analysis_timestamp: null }
}));
router4.post("/lightning/event", isAuthenticated, async (req, res) => {
  try {
    const backendUrl = process.env.PYTHON_BACKEND_URL || "http://localhost:5001";
    const response = await fetch(`${backendUrl}/olympus/lightning/event`, {
      method: "POST",
      headers: { "Content-Type": "application/json" },
      body: JSON.stringify(req.body)
    });
    if (!response.ok) {
      const errorData = await response.json().catch(() => ({}));
      return res.status(response.status).json(errorData);
    }
    const data = await response.json();
    auditLog(req, "lightning_event", req.body.domain || "unknown", true);
    res.json(data);
  } catch (error) {
    logger.error({ data: error }, "[Olympus] Lightning event error");
    auditLog(req, "lightning_event", req.body?.domain || "unknown", false);
    res.status(503).json({ error: "Lightning Kernel not available" });
  }
});
router4.get("/telemetry/fleet", isAuthenticated, (req, res) => proxyGet(req, res, "/api/telemetry/fleet", "Telemetry not available", {
  rawPath: true,
  fallbackResponse: { kernels: 0, total_capabilities: 0 }
}));
router4.get("/telemetry/kernels", isAuthenticated, (req, res) => proxyGet(req, res, "/api/telemetry/kernels", "Telemetry not available", {
  rawPath: true,
  fallbackResponse: { kernels: [], count: 0 }
}));
router4.get("/telemetry/kernel/:kernelId", isAuthenticated, async (req, res) => {
  const { kernelId } = req.params;
  try {
    const response = await fetch(`${BACKEND_URL}/api/telemetry/kernel/${kernelId}`, {
      method: "GET",
      headers: { "Content-Type": "application/json" }
    });
    if (!response.ok) {
      const errorData = await response.json().catch(() => ({}));
      return res.status(response.status).json(errorData);
    }
    const data = await response.json();
    res.json(data);
  } catch (error) {
    logger.error({ data: error }, "[Olympus] Telemetry kernel error");
    res.status(503).json({ error: "Telemetry not available" });
  }
});
router4.get("/telemetry/kernel/:kernelId/capabilities", isAuthenticated, async (req, res) => {
  const { kernelId } = req.params;
  try {
    const response = await fetch(`${BACKEND_URL}/api/telemetry/kernel/${kernelId}/capabilities`, {
      method: "GET",
      headers: { "Content-Type": "application/json" }
    });
    if (!response.ok) {
      const errorData = await response.json().catch(() => ({}));
      return res.status(response.status).json(errorData);
    }
    const data = await response.json();
    res.json(data);
  } catch (error) {
    logger.error({ data: error }, "[Olympus] Telemetry capabilities error");
    res.status(503).json({ error: "Telemetry not available" });
  }
});
router4.post("/telemetry/record", isAuthenticated, (req, res) => proxyPost(req, res, "/api/telemetry/record", "Failed to record telemetry", { rawPath: true }));
router4.get("/telemetry/categories", isAuthenticated, (req, res) => proxyGet(req, res, "/api/telemetry/categories", "Telemetry not available", {
  rawPath: true,
  fallbackResponse: { categories: [], count: 0 }
}));
var olympus_default = router4;

// server/routes/autonomic.ts
import { Router as Router10 } from "express";
var router5 = Router10();
var BACKEND_URL2 = process.env.PYTHON_BACKEND_URL || "http://localhost:5001";
async function proxyGet2(req, res, pythonPath, errorMessage, timeout = 1e4) {
  try {
    const response = await fetch(`${BACKEND_URL2}${pythonPath}`, {
      method: "GET",
      headers: { "Content-Type": "application/json" },
      signal: AbortSignal.timeout(timeout)
    });
    if (!response.ok) {
      const errorData = await response.json().catch(() => ({}));
      return res.status(response.status).json(errorData);
    }
    const data = await response.json();
    res.json(data);
  } catch (error) {
    console.error(`[Autonomic] ${errorMessage}:`, getErrorMessage(error));
    res.status(503).json({
      error: errorMessage,
      details: getErrorMessage(error),
      backend_url: BACKEND_URL2
    });
  }
}
async function proxyPost2(req, res, pythonPath, errorMessage, timeout = 3e4) {
  try {
    const response = await fetch(`${BACKEND_URL2}${pythonPath}`, {
      method: "POST",
      headers: { "Content-Type": "application/json" },
      body: JSON.stringify(req.body),
      signal: AbortSignal.timeout(timeout)
    });
    if (!response.ok) {
      const errorData = await response.json().catch(() => ({}));
      return res.status(response.status).json(errorData);
    }
    const data = await response.json();
    res.json(data);
  } catch (error) {
    console.error(`[Autonomic] ${errorMessage}:`, getErrorMessage(error));
    res.status(503).json({
      error: errorMessage,
      details: getErrorMessage(error),
      backend_url: BACKEND_URL2
    });
  }
}
router5.get("/state", async (req, res) => {
  await proxyGet2(req, res, "/autonomic/state", "Failed to fetch autonomic state");
});
router5.post("/update", async (req, res) => {
  await proxyPost2(req, res, "/autonomic/update", "Failed to update autonomic state");
});
router5.post("/sleep", async (req, res) => {
  await proxyPost2(req, res, "/autonomic/sleep", "Failed to trigger sleep cycle");
});
router5.post("/dream", async (req, res) => {
  await proxyPost2(req, res, "/autonomic/dream", "Failed to trigger dream cycle");
});
router5.post("/mushroom", async (req, res) => {
  await proxyPost2(req, res, "/autonomic/mushroom", "Failed to trigger mushroom cycle");
});
router5.post("/reward", async (req, res) => {
  await proxyPost2(req, res, "/autonomic/reward", "Failed to send reward signal");
});
router5.get("/rewards", async (req, res) => {
  await proxyGet2(req, res, "/autonomic/rewards", "Failed to fetch reward history");
});
router5.get("/narrow-path", async (req, res) => {
  await proxyGet2(req, res, "/autonomic/narrow-path", "Failed to fetch narrow path");
});
router5.post("/auto-intervene", async (req, res) => {
  await proxyPost2(req, res, "/autonomic/auto-intervene", "Failed to trigger auto-intervention");
});
router5.get("/agency/status", async (req, res) => {
  await proxyGet2(req, res, "/autonomic/agency/status", "Failed to fetch agency status");
});
router5.post("/agency/start", async (req, res) => {
  await proxyPost2(req, res, "/autonomic/agency/start", "Failed to start agency");
});
router5.post("/agency/stop", async (req, res) => {
  await proxyPost2(req, res, "/autonomic/agency/stop", "Failed to stop agency");
});
router5.post("/agency/force", async (req, res) => {
  await proxyPost2(req, res, "/autonomic/agency/force", "Failed to force intervention");
});
var autonomicRouter = router5;
var autonomicAgencyRouter = router5;

// server/routes/immune.ts
import { Router as Router11 } from "express";
var router6 = Router11();
var BACKEND_URL3 = process.env.PYTHON_BACKEND_URL || "http://localhost:5001";
async function proxyGet3(req, res, pythonPath, errorMessage, timeout = 1e4) {
  try {
    const response = await fetch(`${BACKEND_URL3}${pythonPath}`, {
      method: "GET",
      headers: { "Content-Type": "application/json" },
      signal: AbortSignal.timeout(timeout)
    });
    if (!response.ok) {
      const errorData = await response.json().catch(() => ({}));
      return res.status(response.status).json(errorData);
    }
    const data = await response.json();
    res.json(data);
  } catch (error) {
    console.error(`[Immune] ${errorMessage}:`, getErrorMessage(error));
    res.status(503).json({
      error: errorMessage,
      details: getErrorMessage(error),
      active: false
    });
  }
}
async function proxyPost3(req, res, pythonPath, errorMessage, timeout = 1e4) {
  try {
    const response = await fetch(`${BACKEND_URL3}${pythonPath}`, {
      method: "POST",
      headers: { "Content-Type": "application/json" },
      body: JSON.stringify(req.body),
      signal: AbortSignal.timeout(timeout)
    });
    if (!response.ok) {
      const errorData = await response.json().catch(() => ({}));
      return res.status(response.status).json(errorData);
    }
    const data = await response.json();
    res.json(data);
  } catch (error) {
    console.error(`[Immune] ${errorMessage}:`, getErrorMessage(error));
    res.status(503).json({
      error: errorMessage,
      details: getErrorMessage(error)
    });
  }
}
async function proxyDelete(req, res, pythonPath, errorMessage, timeout = 1e4) {
  try {
    const response = await fetch(`${BACKEND_URL3}${pythonPath}`, {
      method: "DELETE",
      headers: { "Content-Type": "application/json" },
      signal: AbortSignal.timeout(timeout)
    });
    if (!response.ok) {
      const errorData = await response.json().catch(() => ({}));
      return res.status(response.status).json(errorData);
    }
    const data = await response.json();
    res.json(data);
  } catch (error) {
    console.error(`[Immune] ${errorMessage}:`, getErrorMessage(error));
    res.status(503).json({
      error: errorMessage,
      details: getErrorMessage(error)
    });
  }
}
router6.get("/status", async (req, res) => {
  await proxyGet3(req, res, "/immune/status", "Failed to fetch immune status");
});
router6.get("/health", async (req, res) => {
  await proxyGet3(req, res, "/immune/health", "Failed to fetch immune health");
});
router6.get("/threats", async (req, res) => {
  await proxyGet3(req, res, "/immune/threats", "Failed to fetch threats");
});
router6.get("/antibodies", async (req, res) => {
  await proxyGet3(req, res, "/immune/antibodies", "Failed to fetch antibodies");
});
router6.post("/whitelist", async (req, res) => {
  await proxyPost3(req, res, "/immune/whitelist", "Failed to add to whitelist");
});
router6.post("/blacklist", async (req, res) => {
  await proxyPost3(req, res, "/immune/blacklist", "Failed to add to blacklist");
});
router6.delete("/blacklist/:ip", async (req, res) => {
  const ip = req.params.ip;
  await proxyDelete(req, res, `/immune/blacklist/${ip}`, "Failed to remove from blacklist");
});
router6.get("/offensive/operations", async (req, res) => {
  await proxyGet3(req, res, "/immune/offensive/operations", "Failed to fetch operations");
});
router6.post("/offensive/initiate", async (req, res) => {
  await proxyPost3(req, res, "/immune/offensive/initiate", "Failed to initiate countermeasure");
});
router6.delete("/offensive/operations/:operationId", async (req, res) => {
  const operationId = req.params.operationId;
  await proxyDelete(req, res, `/immune/offensive/operations/${operationId}`, "Failed to cancel operation");
});
router6.get("/checkpoints", async (req, res) => {
  await proxyGet3(req, res, "/immune/checkpoints", "Failed to fetch checkpoints");
});
router6.post("/checkpoints", async (req, res) => {
  await proxyPost3(req, res, "/immune/checkpoints", "Failed to create checkpoint");
});
router6.post("/checkpoints/:checkpointId/restore", async (req, res) => {
  const checkpointId = req.params.checkpointId;
  await proxyPost3(req, res, `/immune/checkpoints/${checkpointId}/restore`, "Failed to restore checkpoint");
});
router6.post("/analyze", async (req, res) => {
  await proxyPost3(req, res, "/immune/analyze", "Failed to analyze request");
});
var immuneRouter = router6;

// server/routes/training.ts
import { Router as Router12 } from "express";
var router7 = Router12();
var BACKEND_URL4 = process.env.PYTHON_BACKEND_URL || "http://localhost:5001";
async function proxyGet4(req, res, pythonPath, errorMessage, timeout = 1e4) {
  try {
    const response = await fetch(`${BACKEND_URL4}${pythonPath}`, {
      method: "GET",
      headers: { "Content-Type": "application/json" },
      signal: AbortSignal.timeout(timeout)
    });
    if (!response.ok) {
      const errorData = await response.json().catch(() => ({}));
      return res.status(response.status).json(errorData);
    }
    const data = await response.json();
    res.json(data);
  } catch (error) {
    console.error(`[Training] ${errorMessage}:`, getErrorMessage(error));
    res.status(503).json({
      error: errorMessage,
      details: getErrorMessage(error),
      status: "unavailable"
    });
  }
}
async function proxyPost4(req, res, pythonPath, errorMessage, timeout = 3e4) {
  try {
    const response = await fetch(`${BACKEND_URL4}${pythonPath}`, {
      method: "POST",
      headers: { "Content-Type": "application/json" },
      body: JSON.stringify(req.body),
      signal: AbortSignal.timeout(timeout)
    });
    if (!response.ok) {
      const errorData = await response.json().catch(() => ({}));
      return res.status(response.status).json(errorData);
    }
    const data = await response.json();
    res.json(data);
  } catch (error) {
    console.error(`[Training] ${errorMessage}:`, getErrorMessage(error));
    res.status(503).json({
      error: errorMessage,
      details: getErrorMessage(error)
    });
  }
}
router7.get("/status", async (req, res) => {
  await proxyGet4(req, res, "/training/status", "Failed to fetch training status");
});
router7.post("/docs", async (req, res) => {
  await proxyPost4(req, res, "/training/docs", "Failed to process training documents");
});
var trainingRouter = router7;

// server/routes/memory.ts
import { Router as Router13 } from "express";
var router8 = Router13();
var BACKEND_URL5 = process.env.PYTHON_BACKEND_URL || "http://localhost:5001";
async function proxyGet5(req, res, pythonPath, errorMessage, timeout = 1e4) {
  try {
    const response = await fetch(`${BACKEND_URL5}${pythonPath}`, {
      method: "GET",
      headers: { "Content-Type": "application/json" },
      signal: AbortSignal.timeout(timeout)
    });
    if (!response.ok) {
      const errorData = await response.json().catch(() => ({}));
      return res.status(response.status).json(errorData);
    }
    const data = await response.json();
    res.json(data);
  } catch (error) {
    console.error(`[Memory] ${errorMessage}:`, getErrorMessage(error));
    res.status(503).json({
      error: errorMessage,
      details: getErrorMessage(error),
      status: "unavailable"
    });
  }
}
async function proxyPost5(req, res, pythonPath, errorMessage, timeout = 1e4) {
  try {
    const response = await fetch(`${BACKEND_URL5}${pythonPath}`, {
      method: "POST",
      headers: { "Content-Type": "application/json" },
      body: JSON.stringify(req.body),
      signal: AbortSignal.timeout(timeout)
    });
    if (!response.ok) {
      const errorData = await response.json().catch(() => ({}));
      return res.status(response.status).json(errorData);
    }
    const data = await response.json();
    res.json(data);
  } catch (error) {
    console.error(`[Memory] ${errorMessage}:`, getErrorMessage(error));
    res.status(503).json({
      error: errorMessage,
      details: getErrorMessage(error)
    });
  }
}
router8.get("/status", async (req, res) => {
  await proxyGet5(req, res, "/memory/status", "Failed to fetch memory status");
});
router8.get("/shadow", async (req, res) => {
  await proxyGet5(req, res, "/memory/shadow", "Failed to fetch shadow memory");
});
router8.get("/basin", async (req, res) => {
  await proxyGet5(req, res, "/memory/basin", "Failed to fetch basin state");
});
router8.get("/learning", async (req, res) => {
  const limit = req.query.limit || 50;
  await proxyGet5(req, res, `/memory/learning?limit=${limit}`, "Failed to fetch learning memory");
});
router8.post("/record", async (req, res) => {
  await proxyPost5(req, res, "/memory/record", "Failed to record memory");
});
var memoryRouter = router8;

// server/routes/feedback.ts
import { Router as Router14 } from "express";
var router9 = Router14();
var BACKEND_URL6 = process.env.PYTHON_BACKEND_URL || "http://localhost:5001";
async function proxyGet6(req, res, pythonPath, errorMessage, timeout = 1e4) {
  try {
    const response = await fetch(`${BACKEND_URL6}${pythonPath}`, {
      method: "GET",
      headers: { "Content-Type": "application/json" },
      signal: AbortSignal.timeout(timeout)
    });
    if (!response.ok) {
      const errorData = await response.json().catch(() => ({}));
      return res.status(response.status).json(errorData);
    }
    const data = await response.json();
    res.json(data);
  } catch (error) {
    console.error(`[Feedback] ${errorMessage}:`, getErrorMessage(error));
    res.status(503).json({
      error: errorMessage,
      details: getErrorMessage(error)
    });
  }
}
async function proxyPost6(req, res, pythonPath, errorMessage, timeout = 3e4) {
  try {
    const response = await fetch(`${BACKEND_URL6}${pythonPath}`, {
      method: "POST",
      headers: { "Content-Type": "application/json" },
      body: JSON.stringify(req.body),
      signal: AbortSignal.timeout(timeout)
    });
    if (!response.ok) {
      const errorData = await response.json().catch(() => ({}));
      return res.status(response.status).json(errorData);
    }
    const data = await response.json();
    res.json(data);
  } catch (error) {
    console.error(`[Feedback] ${errorMessage}:`, getErrorMessage(error));
    res.status(503).json({
      error: errorMessage,
      details: getErrorMessage(error)
    });
  }
}
router9.post("/run", async (req, res) => {
  await proxyPost6(req, res, "/feedback/run", "Failed to run feedback loop");
});
router9.get("/recommendation", async (req, res) => {
  await proxyGet6(req, res, "/feedback/recommendation", "Failed to fetch recommendation");
});
router9.post("/shadow", async (req, res) => {
  await proxyPost6(req, res, "/feedback/shadow", "Failed to record shadow feedback");
});
router9.post("/activity", async (req, res) => {
  await proxyPost6(req, res, "/feedback/activity", "Failed to record activity feedback");
});
router9.post("/basin", async (req, res) => {
  await proxyPost6(req, res, "/feedback/basin", "Failed to record basin feedback");
});
router9.post("/learning", async (req, res) => {
  await proxyPost6(req, res, "/feedback/learning", "Failed to record learning feedback");
});
var feedbackRouter = router9;

// server/routes/coordizer.ts
import { Router as Router15 } from "express";
var router10 = Router15();
var BACKEND_URL7 = process.env.PYTHON_BACKEND_URL || "http://localhost:5001";
var cachedVocabSize = 0;
var lastVocabFetch = 0;
async function proxyGet7(req, res, pythonPath, errorMessage, timeout = 1e4) {
  try {
    const response = await fetch(`${BACKEND_URL7}${pythonPath}`, {
      method: "GET",
      headers: { "Content-Type": "application/json" },
      signal: AbortSignal.timeout(timeout)
    });
    if (!response.ok) {
      const errorData = await response.json().catch(() => ({}));
      return res.status(response.status).json(errorData);
    }
    const data = await response.json();
    res.json(data);
  } catch (error) {
    console.error(`[Coordizer] ${errorMessage}:`, getErrorMessage(error));
    res.status(503).json({
      error: errorMessage,
      details: getErrorMessage(error),
      coordizers_available: false
    });
  }
}
async function proxyPost7(req, res, pythonPath, errorMessage, timeout = 15e3) {
  try {
    const response = await fetch(`${BACKEND_URL7}${pythonPath}`, {
      method: "POST",
      headers: { "Content-Type": "application/json" },
      body: JSON.stringify(req.body),
      signal: AbortSignal.timeout(timeout)
    });
    if (!response.ok) {
      const errorData = await response.json().catch(() => ({}));
      return res.status(response.status).json(errorData);
    }
    const data = await response.json();
    res.json(data);
  } catch (error) {
    console.error(`[Coordizer] ${errorMessage}:`, getErrorMessage(error));
    res.status(503).json({
      error: errorMessage,
      details: getErrorMessage(error)
    });
  }
}
router10.post("/", async (req, res) => {
  await proxyPost7(req, res, "/api/coordize", "Failed to coordize text");
});
router10.post("/multi-scale", async (req, res) => {
  await proxyPost7(req, res, "/api/coordize/multi-scale", "Failed multi-scale coordization");
});
router10.post("/consciousness", async (req, res) => {
  await proxyPost7(req, res, "/api/coordize/consciousness", "Failed consciousness coordization");
});
router10.post("/merge/learn", async (req, res) => {
  await proxyPost7(req, res, "/api/coordize/merge/learn", "Failed to learn merges");
});
router10.get("/stats", async (req, res) => {
  try {
    const response = await fetch(`${BACKEND_URL7}/api/coordize/stats`, {
      method: "GET",
      headers: { "Content-Type": "application/json" },
      signal: AbortSignal.timeout(1e4)
    });
    if (response.ok) {
      const data = await response.json();
      if (data.vocab_size && data.vocab_size > 0) {
        cachedVocabSize = data.vocab_size;
        lastVocabFetch = Date.now();
      }
      return res.json(data);
    }
    const errorData = await response.json().catch(() => ({}));
    return res.status(response.status).json({
      ...errorData,
      vocab_size: cachedVocabSize || 0,
      cached: true
    });
  } catch (error) {
    console.error("[Coordizer] Stats error:", getErrorMessage(error));
    res.json({
      vocab_size: cachedVocabSize || 0,
      coordinate_dim: 64,
      geometric_purity: true,
      special_tokens: ["[PAD]", "[UNK]", "[BOS]", "[EOS]"],
      status: "backend_unavailable",
      cached: true,
      error: getErrorMessage(error)
    });
  }
});
router10.get("/vocab", async (req, res) => {
  const queryString = new URLSearchParams(req.query).toString();
  const path15 = `/api/coordize/vocab${queryString ? "?" + queryString : ""}`;
  await proxyGet7(req, res, path15, "Failed to fetch vocabulary");
});
router10.post("/similarity", async (req, res) => {
  await proxyPost7(req, res, "/api/coordize/similarity", "Failed to compute similarity");
});
router10.get("/health", async (req, res) => {
  await proxyGet7(req, res, "/api/coordize/health", "Coordizer health check failed");
});
var coordizerRouter = router10;

// server/routes/federation.ts
init_logger();
init_db();
init_replitAuth();
import { Router as Router16 } from "express";
import { sql as sql9 } from "drizzle-orm";
import { randomBytes as randomBytes2, createCipheriv, createDecipheriv } from "crypto";
var ENCRYPTION_KEY = process.env.FEDERATION_ENCRYPTION_KEY || randomBytes2(32).toString("hex");
var ALGORITHM = "aes-256-gcm";
function encryptApiKey(apiKey) {
  const iv = randomBytes2(16);
  const keyBuffer = Buffer.from(ENCRYPTION_KEY.slice(0, 64), "hex");
  const cipher = createCipheriv(ALGORITHM, keyBuffer, iv);
  let encrypted = cipher.update(apiKey, "utf8", "hex");
  encrypted += cipher.final("hex");
  const authTag = cipher.getAuthTag().toString("hex");
  return `${iv.toString("hex")}:${authTag}:${encrypted}`;
}
var federationRouter = Router16();
federationRouter.use(isAuthenticated);
federationRouter.get("/keys", async (_req, res) => {
  if (!db) {
    return res.status(503).json({ error: "Database unavailable" });
  }
  try {
    const result = await db.execute(sql9`
      SELECT id, name, instance_type, scopes, created_at, last_used_at, rate_limit, is_active
      FROM external_api_keys
      ORDER BY created_at DESC
    `);
    const formattedKeys = result.rows.map((k) => {
      const row = k;
      return {
        id: String(row.id),
        name: row.name,
        instanceType: row.instance_type,
        scopes: Array.isArray(row.scopes) ? row.scopes : [],
        createdAt: row.created_at,
        lastUsedAt: row.last_used_at,
        rateLimit: row.rate_limit ?? 60,
        isActive: row.is_active ?? true
      };
    });
    res.json({ keys: formattedKeys });
  } catch (error) {
    console.error("[Federation] Failed to list keys:", error);
    res.status(500).json({ error: "Failed to list API keys" });
  }
});
federationRouter.post("/keys", async (req, res) => {
  if (!db) {
    return res.status(503).json({ error: "Database unavailable" });
  }
  const { name, instanceType, scopes, rateLimit: rateLimit6 } = req.body;
  if (!name || typeof name !== "string" || name.length < 1 || name.length > 128) {
    return res.status(400).json({
      error: "Invalid name",
      required: "name must be a string between 1 and 128 characters"
    });
  }
  const validInstanceTypes = ["external", "headless", "federation", "research", "development"];
  if (!instanceType || !validInstanceTypes.includes(instanceType)) {
    return res.status(400).json({
      error: "Invalid instanceType",
      valid: validInstanceTypes
    });
  }
  const validScopes = ["read", "write", "admin", "consciousness", "geometry", "pantheon", "sync", "chat"];
  const requestedScopes = scopes || ["read", "write", "consciousness", "geometry", "pantheon", "sync", "chat"];
  if (!Array.isArray(requestedScopes) || requestedScopes.some((s) => !validScopes.includes(s))) {
    return res.status(400).json({
      error: "Invalid scopes",
      valid: validScopes
    });
  }
  const finalRateLimit = typeof rateLimit6 === "number" && rateLimit6 > 0 && rateLimit6 <= 1e3 ? rateLimit6 : 120;
  try {
    const rawKey = `qig_${randomBytes2(32).toString("hex")}`;
    const scopesJson = JSON.stringify(requestedScopes);
    const result = await db.execute(sql9`
      INSERT INTO external_api_keys (name, api_key, instance_type, scopes, rate_limit, is_active, created_at)
      VALUES (${name}, ${rawKey}, ${instanceType}, ${scopesJson}::jsonb, ${finalRateLimit}, true, NOW())
      RETURNING id
    `);
    const insertedRow = result.rows[0];
    const insertedId = insertedRow?.id;
    res.status(201).json({
      message: "API key created",
      id: String(insertedId),
      key: rawKey,
      warning: "Save this key securely - it will not be shown again"
    });
  } catch (error) {
    console.error("[Federation] Failed to create key:", error);
    res.status(500).json({ error: "Failed to create API key" });
  }
});
federationRouter.delete("/keys/:keyId", async (req, res) => {
  if (!db) {
    return res.status(503).json({ error: "Database unavailable" });
  }
  const { keyId } = req.params;
  const numericId = parseInt(keyId, 10);
  if (isNaN(numericId)) {
    return res.status(400).json({ error: "Invalid key ID" });
  }
  try {
    await db.execute(sql9`
      UPDATE external_api_keys SET is_active = false WHERE id = ${numericId}
    `);
    res.json({ message: "API key revoked", keyId });
  } catch (error) {
    console.error("[Federation] Failed to revoke key:", error);
    res.status(500).json({ error: "Failed to revoke API key" });
  }
});
federationRouter.post("/test-connection", async (req, res) => {
  const { endpoint, apiKey } = req.body;
  if (!endpoint || typeof endpoint !== "string") {
    return res.status(400).json({ error: "endpoint is required" });
  }
  if (!apiKey || typeof apiKey !== "string") {
    return res.status(400).json({ error: "apiKey is required" });
  }
  try {
    const cleanEndpoint = endpoint.replace(/\/+$/, "");
    const healthUrl = `${cleanEndpoint}/health`;
    const start = Date.now();
    const controller = new AbortController();
    const timeout = setTimeout(() => controller.abort(), 1e4);
    const response = await fetch(healthUrl, {
      headers: {
        "X-API-Key": apiKey,
        "Accept": "application/json"
      },
      signal: controller.signal
    });
    clearTimeout(timeout);
    const latency = Date.now() - start;
    if (!response.ok) {
      return res.json({
        success: false,
        status: response.status,
        error: `Remote returned ${response.status}`,
        latency
      });
    }
    const data = await response.json();
    res.json({
      success: true,
      status: response.status,
      latency,
      remoteVersion: data.version || "unknown",
      capabilities: data.capabilities || []
    });
  } catch (error) {
    const err = error;
    logger.error({ err: error, context: "Federation" }, "Connection test failed");
    res.json({
      success: false,
      error: err.name === "AbortError" ? "Connection timeout" : err.message,
      latency: 0
    });
  }
});
federationRouter.post("/connect", async (req, res) => {
  if (!db) {
    return res.status(503).json({ error: "Database unavailable" });
  }
  const { name, endpoint, apiKey, syncDirection } = req.body;
  if (!name || typeof name !== "string" || name.length < 1 || name.length > 128) {
    return res.status(400).json({ error: "name is required (1-128 chars)" });
  }
  if (!endpoint || typeof endpoint !== "string") {
    return res.status(400).json({ error: "endpoint is required" });
  }
  if (!apiKey || typeof apiKey !== "string") {
    return res.status(400).json({ error: "apiKey is required" });
  }
  const validSyncDirections = ["inbound", "outbound", "bidirectional"];
  const direction = syncDirection || "bidirectional";
  if (!validSyncDirections.includes(direction)) {
    return res.status(400).json({ error: "Invalid syncDirection", valid: validSyncDirections });
  }
  try {
    const cleanEndpoint = endpoint.replace(/\/+$/, "");
    const controller = new AbortController();
    const timeout = setTimeout(() => controller.abort(), 1e4);
    const healthResponse = await fetch(`${cleanEndpoint}/health`, {
      headers: {
        "X-API-Key": apiKey,
        "Accept": "application/json"
      },
      signal: controller.signal
    });
    clearTimeout(timeout);
    if (!healthResponse.ok) {
      return res.status(400).json({
        error: "Failed to connect to remote node",
        details: `Remote returned status ${healthResponse.status}`
      });
    }
    const healthData = await healthResponse.json();
    const capabilities = healthData.capabilities || ["consciousness", "geometry"];
    const encryptedApiKey = encryptApiKey(apiKey);
    const result = await db.execute(sql9`
      INSERT INTO federated_instances (name, endpoint, status, capabilities, sync_direction, remote_api_key, created_at)
      VALUES (${name}, ${cleanEndpoint}, 'active', ${JSON.stringify(capabilities)}::jsonb, ${direction}, ${encryptedApiKey}, NOW())
      ON CONFLICT (endpoint) DO UPDATE SET
        name = EXCLUDED.name,
        status = 'active',
        capabilities = EXCLUDED.capabilities,
        sync_direction = EXCLUDED.sync_direction,
        remote_api_key = EXCLUDED.remote_api_key
      RETURNING id
    `);
    const insertedRow = result.rows[0];
    const insertedId = insertedRow?.id;
    logger.info(`[Federation] Connected to node: ${name} (${cleanEndpoint})`);
    res.status(201).json({
      success: true,
      message: "Connected to remote node",
      instanceId: insertedId,
      name,
      endpoint: cleanEndpoint,
      capabilities,
      syncDirection: direction
    });
  } catch (error) {
    logger.error({ err: error, context: "Federation" }, "Failed to connect");
    const err = error;
    if (err.name === "AbortError") {
      return res.status(400).json({ error: "Connection timeout - remote node not responding" });
    }
    res.status(500).json({ error: "Failed to connect to remote node", details: err.message });
  }
});
federationRouter.delete("/instances/:instanceId", async (req, res) => {
  if (!db) {
    return res.status(503).json({ error: "Database unavailable" });
  }
  const { instanceId } = req.params;
  const numericId = parseInt(instanceId, 10);
  if (isNaN(numericId)) {
    return res.status(400).json({ error: "Invalid instance ID" });
  }
  try {
    await db.execute(sql9`
      DELETE FROM federated_instances WHERE id = ${numericId}
    `);
    res.json({ message: "Instance disconnected", instanceId });
  } catch (error) {
    console.error("[Federation] Failed to disconnect instance:", error);
    res.status(500).json({ error: "Failed to disconnect instance" });
  }
});
federationRouter.get("/instances", async (_req, res) => {
  if (!db) {
    return res.status(503).json({ error: "Database unavailable" });
  }
  try {
    const result = await db.execute(sql9`
      SELECT id, name, endpoint, status, capabilities, sync_direction, last_sync_at, created_at
      FROM federated_instances
      ORDER BY last_sync_at DESC NULLS LAST
    `);
    const instances = result.rows.map((r) => {
      const row = r;
      return {
        id: row.id,
        name: row.name,
        endpoint: row.endpoint,
        status: row.status || "pending",
        capabilities: row.capabilities || [],
        syncDirection: row.sync_direction || "bidirectional",
        lastSyncAt: row.last_sync_at,
        createdAt: row.created_at
      };
    });
    res.json({ instances });
  } catch (error) {
    console.error("[Federation] Failed to list instances:", error);
    res.status(500).json({ error: "Failed to list instances" });
  }
});
federationRouter.get("/sync/status", async (_req, res) => {
  if (!db) {
    return res.status(503).json({ error: "Database unavailable" });
  }
  try {
    const result = await db.execute(sql9`
      SELECT COUNT(*) as count, MAX(last_sync_at) as latest_sync
      FROM federated_instances
      WHERE status = 'active'
    `);
    const row = result.rows[0];
    const peerCount = parseInt(String(row?.count || "0"), 10);
    const latestSync = row?.latest_sync;
    res.json({
      isConnected: peerCount > 0,
      peerCount,
      lastSyncTime: latestSync?.toISOString?.() ?? latestSync ?? null,
      pendingPackets: 0,
      syncMode: peerCount > 0 ? "bidirectional" : "standalone"
    });
  } catch (error) {
    console.error("[Federation] Failed to get sync status:", error);
    res.status(500).json({ error: "Failed to get sync status" });
  }
});
federationRouter.get("/settings", async (_req, res) => {
  if (!db) {
    return res.status(503).json({ error: "Database unavailable" });
  }
  try {
    const result = await db.execute(sql9`
      SELECT key, value, description, updated_at
      FROM system_settings
      WHERE key IN ('federation_endpoint', 'node_name', 'node_description')
    `);
    const settings = {
      federation_endpoint: null,
      node_name: null,
      node_description: null
    };
    for (const row of result.rows) {
      const r = row;
      settings[r.key] = r.value;
    }
    res.json({ settings });
  } catch (error) {
    console.error("[Federation] Failed to get settings:", error);
    res.status(500).json({ error: "Failed to get settings" });
  }
});
federationRouter.put("/settings", async (req, res) => {
  if (!db) {
    return res.status(503).json({ error: "Database unavailable" });
  }
  const { federation_endpoint, node_name, node_description } = req.body;
  try {
    if (federation_endpoint !== void 0) {
      if (typeof federation_endpoint !== "string" || federation_endpoint && !federation_endpoint.startsWith("http")) {
        return res.status(400).json({
          error: "Invalid federation_endpoint",
          details: "Must be a valid HTTP/HTTPS URL or empty string to clear"
        });
      }
      await db.execute(sql9`
        INSERT INTO system_settings (key, value, description, updated_at)
        VALUES ('federation_endpoint', ${federation_endpoint}, 'Public endpoint URL for federation', NOW())
        ON CONFLICT (key) DO UPDATE SET value = EXCLUDED.value, updated_at = NOW()
      `);
    }
    if (node_name !== void 0) {
      await db.execute(sql9`
        INSERT INTO system_settings (key, value, description, updated_at)
        VALUES ('node_name', ${node_name}, 'Human-readable name for this node', NOW())
        ON CONFLICT (key) DO UPDATE SET value = EXCLUDED.value, updated_at = NOW()
      `);
    }
    if (node_description !== void 0) {
      await db.execute(sql9`
        INSERT INTO system_settings (key, value, description, updated_at)
        VALUES ('node_description', ${node_description}, 'Description of this node', NOW())
        ON CONFLICT (key) DO UPDATE SET value = EXCLUDED.value, updated_at = NOW()
      `);
    }
    logger.info("[Federation] Settings updated");
    res.json({ success: true, message: "Settings updated" });
  } catch (error) {
    console.error("[Federation] Failed to update settings:", error);
    res.status(500).json({ error: "Failed to update settings" });
  }
});

// server/routes/zettelkasten.ts
init_db();
init_schema();
init_internal_auth();
import { Router as Router17 } from "express";
import { eq as eq10, desc as desc8, sql as sql10, gte as gte4 } from "drizzle-orm";
import { randomUUID as randomUUID7 } from "crypto";
var router11 = Router17();
function ensureDb() {
  if (!db) {
    throw new Error("Database not initialized");
  }
  return db;
}
function extractKeywords(text2) {
  const stopwords = /* @__PURE__ */ new Set([
    "the",
    "a",
    "an",
    "and",
    "or",
    "but",
    "in",
    "on",
    "at",
    "to",
    "for",
    "of",
    "with",
    "by",
    "from",
    "as",
    "is",
    "was",
    "are",
    "were",
    "been",
    "be",
    "have",
    "has",
    "had",
    "do",
    "does",
    "did",
    "will",
    "would",
    "could",
    "should",
    "may",
    "might",
    "must",
    "shall",
    "can",
    "this",
    "that",
    "it"
  ]);
  const words = text2.toLowerCase().replace(/[^a-z0-9\s]/g, " ").split(/\s+/).filter((w) => w.length > 3 && !stopwords.has(w));
  const freq = /* @__PURE__ */ new Map();
  words.forEach((w) => freq.set(w, (freq.get(w) || 0) + 1));
  return Array.from(freq.entries()).sort((a, b) => b[1] - a[1]).slice(0, 5).map(([word]) => word);
}
function computeLinkStrength(coords1, coords2) {
  if (!coords1?.length || !coords2?.length) return 0;
  const minLen = Math.min(coords1.length, coords2.length);
  let dot = 0, norm1 = 0, norm2 = 0;
  for (let i = 0; i < minLen; i++) {
    dot += coords1[i] * coords2[i];
    norm1 += coords1[i] * coords1[i];
    norm2 += coords2[i] * coords2[i];
  }
  const denominator = Math.sqrt(norm1) * Math.sqrt(norm2);
  return denominator > 0 ? dot / denominator : 0;
}
router11.get("/stats", async (req, res) => {
  try {
    const database = ensureDb();
    const countResult = await database.select({ count: sql10`count(*)` }).from(basinMemory);
    const totalZettels = Number(countResult[0]?.count || 0);
    const sampleSize = Math.min(100, totalZettels);
    let realLinkCount = 0;
    let sampleKeywords = 0;
    if (sampleSize > 0) {
      const memories = await database.select({ basinCoordinates: basinMemory.basinCoordinates, context: basinMemory.context }).from(basinMemory).orderBy(desc8(basinMemory.phi)).limit(sampleSize);
      for (let i = 0; i < memories.length; i++) {
        const ctx = memories[i].context;
        const content = typeof ctx === "string" ? ctx : JSON.stringify(ctx || "");
        sampleKeywords += extractKeywords(content).length;
        for (let j = i + 1; j < memories.length; j++) {
          const c1 = memories[i].basinCoordinates;
          const c2 = memories[j].basinCoordinates;
          if (computeLinkStrength(c1 || [], c2 || []) > 0.5) {
            realLinkCount++;
          }
        }
      }
    }
    const scaleFactor = totalZettels > sampleSize ? totalZettels / sampleSize : 1;
    const estimatedLinks = Math.round(realLinkCount * scaleFactor);
    const estimatedKeywords = Math.round(sampleKeywords * scaleFactor);
    res.json({
      success: true,
      data: {
        total_zettels: totalZettels,
        total_links: estimatedLinks,
        total_keywords: estimatedKeywords,
        total_evolutions: 0,
        avg_links_per_zettel: totalZettels > 0 ? estimatedLinks / totalZettels : 0,
        sample_based: totalZettels > sampleSize
        // Flag if stats are estimated
      }
    });
  } catch (error) {
    console.error("[Zettelkasten] Error getting stats:", error);
    res.status(500).json({ success: false, error: "Failed to get stats" });
  }
});
router11.get("/graph", async (req, res) => {
  try {
    const { max_nodes = "50" } = req.query;
    const maxNodes = parseInt(max_nodes);
    const database = ensureDb();
    const memories = await database.select().from(basinMemory).orderBy(desc8(basinMemory.timestamp)).limit(maxNodes);
    const nodes = memories.map((m) => ({
      id: m.basinId || `zettel-${m.id}`,
      label: typeof m.context === "string" ? m.context.slice(0, 50) : m.context?.content?.slice(0, 50) || `Memory ${m.id}`,
      keywords: extractKeywords(
        typeof m.context === "string" ? m.context : JSON.stringify(m.context || "")
      ),
      access_count: 1
    }));
    const edges = [];
    for (let i = 0; i < memories.length; i++) {
      for (let j = i + 1; j < memories.length; j++) {
        const coords1 = memories[i].basinCoordinates;
        const coords2 = memories[j].basinCoordinates;
        const strength = computeLinkStrength(coords1 || [], coords2 || []);
        if (strength > 0.5) {
          edges.push({
            source: nodes[i].id,
            target: nodes[j].id,
            strength,
            link_type: "geometric"
          });
        }
      }
    }
    res.json({
      success: true,
      data: {
        nodes,
        edges,
        stats: {
          total_zettels: nodes.length,
          total_links: edges.length,
          total_keywords: nodes.reduce((sum, n) => sum + n.keywords.length, 0),
          total_evolutions: 0,
          avg_links_per_zettel: nodes.length > 0 ? edges.length / nodes.length : 0
        }
      }
    });
  } catch (error) {
    console.error("[Zettelkasten] Error getting graph:", error);
    res.status(500).json({ success: false, error: "Failed to get graph" });
  }
});
router11.get("/hubs", async (req, res) => {
  try {
    const { top_n = "10" } = req.query;
    const topN = parseInt(top_n);
    const database = ensureDb();
    const hubMemories = await database.select().from(basinMemory).where(gte4(basinMemory.phi, 0.6)).orderBy(desc8(basinMemory.phi)).limit(topN);
    const allMemories = await database.select({ basinId: basinMemory.basinId, basinCoordinates: basinMemory.basinCoordinates }).from(basinMemory).limit(100);
    const hubs = hubMemories.map((m) => {
      const coords = m.basinCoordinates;
      let linkCount = 0;
      if (coords?.length) {
        for (const other of allMemories) {
          if (other.basinId === m.basinId) continue;
          const otherCoords = other.basinCoordinates;
          if (computeLinkStrength(coords, otherCoords || []) > 0.5) {
            linkCount++;
          }
        }
      }
      return {
        zettel_id: m.basinId || `zettel-${m.id}`,
        content: typeof m.context === "string" ? m.context : m.context?.content || JSON.stringify(m.context),
        keywords: extractKeywords(
          typeof m.context === "string" ? m.context : JSON.stringify(m.context || "")
        ),
        outgoing_links: linkCount,
        access_count: 1,
        evolution_count: 0
      };
    });
    res.json({ success: true, data: hubs });
  } catch (error) {
    console.error("[Zettelkasten] Error getting hubs:", error);
    res.status(500).json({ success: false, error: "Failed to get hubs" });
  }
});
router11.get("/clusters", async (req, res) => {
  try {
    const database = ensureDb();
    const regimeClusters = await database.select({
      regime: basinMemory.regime,
      count: sql10`count(*)`
    }).from(basinMemory).groupBy(basinMemory.regime);
    const clusters = await Promise.all(
      regimeClusters.map(async (cluster, idx) => {
        const clusterMemories = await database.select().from(basinMemory).where(eq10(basinMemory.regime, cluster.regime || "unknown")).limit(20);
        const keywordFreq = /* @__PURE__ */ new Map();
        const zettels = clusterMemories.slice(0, 5).map((m) => {
          const content = typeof m.context === "string" ? m.context : m.context?.content || JSON.stringify(m.context);
          const keywords = extractKeywords(content);
          keywords.forEach((kw) => keywordFreq.set(kw, (keywordFreq.get(kw) || 0) + 1));
          return {
            zettel_id: m.basinId || `zettel-${m.id}`,
            content,
            keywords
          };
        });
        const topKeywords = Array.from(keywordFreq.entries()).sort((a, b) => b[1] - a[1]).slice(0, 5).map(([kw]) => kw);
        return {
          cluster_id: idx,
          size: Number(cluster.count),
          top_keywords: topKeywords.length > 0 ? topKeywords : [cluster.regime || "unknown"],
          zettels
        };
      })
    );
    res.json({ success: true, data: clusters });
  } catch (error) {
    console.error("[Zettelkasten] Error getting clusters:", error);
    res.status(500).json({ success: false, error: "Failed to get clusters" });
  }
});
router11.post("/retrieve", async (req, res) => {
  try {
    const { query, top_k = 10 } = req.body;
    if (!query) {
      return res.status(400).json({ success: false, error: "Query required" });
    }
    const database = ensureDb();
    const memories = await database.select().from(basinMemory).orderBy(desc8(basinMemory.phi)).limit(top_k);
    const queryWords = new Set(query.toLowerCase().split(/\s+/));
    const allCoords = await database.select({ basinId: basinMemory.basinId, basinCoordinates: basinMemory.basinCoordinates }).from(basinMemory).limit(100);
    const results = memories.map((m) => {
      const content = typeof m.context === "string" ? m.context : m.context?.content || JSON.stringify(m.context);
      const contentWords = new Set(content.toLowerCase().split(/\s+/));
      const overlap = [...queryWords].filter((w) => contentWords.has(w)).length;
      const relevance = (m.phi || 0) * 0.5 + overlap / queryWords.size * 0.5;
      const coords = m.basinCoordinates;
      let linkCount = 0;
      if (coords?.length) {
        for (const other of allCoords) {
          if (other.basinId === m.basinId) continue;
          const otherCoords = other.basinCoordinates;
          if (computeLinkStrength(coords, otherCoords || []) > 0.5) {
            linkCount++;
          }
        }
      }
      return {
        zettel_id: m.basinId || `zettel-${m.id}`,
        content,
        relevance,
        keywords: extractKeywords(content),
        contextual_description: `Regime: ${m.regime}, \u03A6: ${(m.phi || 0).toFixed(2)}`,
        links_count: linkCount,
        access_count: 1
      };
    });
    results.sort((a, b) => b.relevance - a.relevance);
    res.json({ success: true, data: results });
  } catch (error) {
    console.error("[Zettelkasten] Error retrieving:", error);
    res.status(500).json({ success: false, error: "Failed to retrieve" });
  }
});
router11.get("/zettel/:id", async (req, res) => {
  try {
    const { id } = req.params;
    const database = ensureDb();
    const memories = await database.select().from(basinMemory).where(eq10(basinMemory.basinId, id)).limit(1);
    if (memories.length === 0) {
      const numId = parseInt(id.replace("zettel-", ""));
      if (!isNaN(numId)) {
        const byNumId = await database.select().from(basinMemory).where(eq10(basinMemory.id, numId)).limit(1);
        if (byNumId.length > 0) {
          memories.push(...byNumId);
        }
      }
    }
    if (memories.length === 0) {
      return res.status(404).json({ success: false, error: "Zettel not found" });
    }
    const m = memories[0];
    const content = typeof m.context === "string" ? m.context : m.context?.content || JSON.stringify(m.context);
    res.json({
      success: true,
      data: {
        zettel_id: m.basinId || `zettel-${m.id}`,
        content,
        contextual_description: `Regime: ${m.regime}, \u03A6: ${(m.phi || 0).toFixed(2)}, \u03BA: ${(m.kappaEff || 0).toFixed(1)}`,
        keywords: extractKeywords(content),
        links: [],
        access_count: 1,
        evolution_count: 0,
        source: m.sourceKernel || "system",
        created_at: m.timestamp ? new Date(m.timestamp).getTime() / 1e3 : Date.now() / 1e3
      }
    });
  } catch (error) {
    console.error("[Zettelkasten] Error getting zettel:", error);
    res.status(500).json({ success: false, error: "Failed to get zettel" });
  }
});
router11.post("/add", requireInternalAuth, async (req, res) => {
  try {
    const { content, keywords = [], source = "user" } = req.body;
    if (!content) {
      return res.status(400).json({ success: false, error: "Content required" });
    }
    const randomCoords = Array(64).fill(0).map(() => (Math.random() - 0.5) * 2);
    const norm = Math.sqrt(randomCoords.reduce((s, v) => s + v * v, 0));
    const normalizedCoords = randomCoords.map((v) => v / norm);
    const database = ensureDb();
    const zettelId = `zettel-${randomUUID7().slice(0, 8)}`;
    const result = await database.insert(basinMemory).values({
      basinId: zettelId,
      basinCoordinates: normalizedCoords,
      phi: 0.5 + Math.random() * 0.3,
      kappaEff: 64,
      regime: "geometric",
      sourceKernel: source,
      context: { content, keywords: keywords.length ? keywords : extractKeywords(content) }
    }).returning();
    res.status(201).json({
      success: true,
      data: {
        zettel_id: zettelId,
        content,
        keywords: keywords.length ? keywords : extractKeywords(content)
      }
    });
  } catch (error) {
    console.error("[Zettelkasten] Error adding zettel:", error);
    res.status(500).json({ success: false, error: "Failed to add zettel" });
  }
});
router11.post("/add-from-conversation", requireInternalAuth, async (req, res) => {
  try {
    const { content, role, basin_coords, phi, source_kernel } = req.body;
    if (!content || content.length < 20) {
      return res.json({ success: true, data: { skipped: true, reason: "Content too short" } });
    }
    const coords = basin_coords && basin_coords.length === 64 ? basin_coords : Array(64).fill(0).map(() => (Math.random() - 0.5) * 2);
    const norm = Math.sqrt(coords.reduce((s, v) => s + v * v, 0));
    const normalizedCoords = coords.map((v) => v / norm);
    const database = ensureDb();
    const zettelId = `conv-${randomUUID7().slice(0, 8)}`;
    await database.insert(basinMemory).values({
      basinId: zettelId,
      basinCoordinates: normalizedCoords,
      phi: phi || 0.6,
      kappaEff: 64,
      regime: "conversation",
      sourceKernel: source_kernel || role || "chat",
      context: { content, role, keywords: extractKeywords(content) }
    });
    res.json({ success: true, data: { zettel_id: zettelId, added: true } });
  } catch (error) {
    console.error("[Zettelkasten] Error adding from conversation:", error);
    res.status(500).json({ success: false, error: "Failed to add from conversation" });
  }
});
router11.post("/add-from-search", requireInternalAuth, async (req, res) => {
  try {
    const { query, results, source = "search" } = req.body;
    if (!results || !Array.isArray(results) || results.length === 0) {
      return res.json({ success: true, data: { skipped: true, reason: "No results" } });
    }
    const database = ensureDb();
    const added = [];
    for (const result of results.slice(0, 5)) {
      const content = result.content || result.snippet || result.text || "";
      if (content.length < 20) continue;
      const randomCoords = Array(64).fill(0).map(() => (Math.random() - 0.5) * 2);
      const norm = Math.sqrt(randomCoords.reduce((s, v) => s + v * v, 0));
      const normalizedCoords = randomCoords.map((v) => v / norm);
      const zettelId = `search-${randomUUID7().slice(0, 8)}`;
      await database.insert(basinMemory).values({
        basinId: zettelId,
        basinCoordinates: normalizedCoords,
        phi: 0.55,
        kappaEff: 64,
        regime: "search",
        sourceKernel: source,
        context: {
          content,
          query,
          url: result.url,
          keywords: extractKeywords(content)
        }
      });
      added.push(zettelId);
    }
    res.json({ success: true, data: { added_count: added.length, zettel_ids: added } });
  } catch (error) {
    console.error("[Zettelkasten] Error adding from search:", error);
    res.status(500).json({ success: false, error: "Failed to add from search" });
  }
});
var zettelkasten_default = router11;

// server/routes/python-proxies.ts
init_logger();
import { Router as Router18 } from "express";
var router12 = Router18();
var BACKEND_URL8 = process.env.PYTHON_BACKEND_URL || "http://localhost:5001";
async function proxyGet8(req, res, pythonPath, errorMessage, options = {}) {
  try {
    let url = `${BACKEND_URL8}${pythonPath}`;
    if (options.passQuery && Object.keys(req.query).length > 0) {
      const params = new URLSearchParams(req.query);
      url += `?${params.toString()}`;
    }
    const response = await fetch(url, {
      method: "GET",
      headers: { "Content-Type": "application/json" }
    });
    if (!response.ok) {
      const errorData = await response.json().catch(() => ({}));
      return res.status(response.status).json(errorData);
    }
    const data = await response.json();
    res.json(data);
  } catch (error) {
    logger.error({ err: error }, `[PythonProxy] ${errorMessage}`);
    res.status(options.errorStatus || 503).json({ error: errorMessage, available: false });
  }
}
async function proxyPost8(req, res, pythonPath, errorMessage, options = {}) {
  try {
    const response = await fetch(`${BACKEND_URL8}${pythonPath}`, {
      method: "POST",
      headers: { "Content-Type": "application/json" },
      body: JSON.stringify(req.body)
    });
    if (!response.ok) {
      const errorData = await response.json().catch(() => ({}));
      return res.status(response.status).json(errorData);
    }
    const data = await response.json();
    res.json(data);
  } catch (error) {
    logger.error({ err: error }, `[PythonProxy] ${errorMessage}`);
    res.status(options.errorStatus || 503).json({ error: errorMessage, available: false });
  }
}
router12.get("/geometric/status", (req, res) => proxyGet8(req, res, "/geometric/status", "Failed to get geometric status"));
router12.post("/geometric/encode", (req, res) => proxyPost8(req, res, "/geometric/encode", "Failed to encode geometrically"));
router12.post("/geometric/similarity", (req, res) => proxyPost8(req, res, "/geometric/similarity", "Failed to compute geometric similarity"));
router12.post("/geometric/batch-encode", (req, res) => proxyPost8(req, res, "/geometric/batch-encode", "Failed to batch encode"));
router12.post("/geometric/decode", (req, res) => proxyPost8(req, res, "/geometric/decode", "Failed to decode geometrically"));
router12.post("/geometric/e8/learn", (req, res) => proxyPost8(req, res, "/geometric/e8/learn", "Failed to learn E8 geometry"));
router12.get("/geometric/e8/roots", (req, res) => proxyGet8(req, res, "/geometric/e8/roots", "Failed to get E8 roots"));
router12.get("/pantheon/status", (req, res) => proxyGet8(req, res, "/pantheon/status", "Failed to get pantheon status"));
router12.get("/pantheon/gods", (req, res) => proxyGet8(req, res, "/pantheon/gods", "Failed to get pantheon gods"));
router12.get("/pantheon/constellation", (req, res) => proxyGet8(req, res, "/pantheon/constellation", "Failed to get pantheon constellation"));
router12.post("/pantheon/orchestrate", (req, res) => proxyPost8(req, res, "/pantheon/orchestrate", "Failed to orchestrate pantheon"));
router12.post("/pantheon/orchestrate-batch", (req, res) => proxyPost8(req, res, "/pantheon/orchestrate-batch", "Failed to batch orchestrate"));
router12.post("/pantheon/nearest", (req, res) => proxyPost8(req, res, "/pantheon/nearest", "Failed to find nearest god"));
router12.post("/pantheon/similarity", (req, res) => proxyPost8(req, res, "/pantheon/similarity", "Failed to compute pantheon similarity"));
router12.get("/shadow-pantheon/status", (req, res) => proxyGet8(req, res, "/shadow-pantheon/status", "Failed to get shadow pantheon status"));
router12.post("/feedback/run", (req, res) => proxyPost8(req, res, "/feedback/run", "Failed to run feedback loop"));
router12.get("/feedback/recommendation", (req, res) => proxyGet8(req, res, "/feedback/recommendation", "Failed to get feedback recommendation"));
router12.post("/feedback/shadow", (req, res) => proxyPost8(req, res, "/feedback/shadow", "Failed to run shadow feedback"));
router12.post("/feedback/activity", (req, res) => proxyPost8(req, res, "/feedback/activity", "Failed to record feedback activity"));
router12.post("/feedback/basin", (req, res) => proxyPost8(req, res, "/feedback/basin", "Failed to run basin feedback"));
router12.post("/feedback/learning", (req, res) => proxyPost8(req, res, "/feedback/learning", "Failed to run learning feedback"));
router12.post("/consciousness_4d/phi_temporal", (req, res) => proxyPost8(req, res, "/consciousness_4d/phi_temporal", "Failed to compute temporal phi"));
router12.post("/consciousness_4d/phi_4d", (req, res) => proxyPost8(req, res, "/consciousness_4d/phi_4d", "Failed to compute 4D phi"));
router12.post("/consciousness_4d/classify_regime", (req, res) => proxyPost8(req, res, "/consciousness_4d/classify_regime", "Failed to classify consciousness regime"));
router12.post("/chaos/activate", (req, res) => proxyPost8(req, res, "/chaos/activate", "Failed to activate chaos mode"));
router12.post("/chaos/deactivate", (req, res) => proxyPost8(req, res, "/chaos/deactivate", "Failed to deactivate chaos mode"));
router12.get("/chaos/status", (req, res) => proxyGet8(req, res, "/chaos/status", "Failed to get chaos status"));
router12.post("/chaos/spawn_random", (req, res) => proxyPost8(req, res, "/chaos/spawn_random", "Failed to spawn random chaos kernel"));
router12.post("/chaos/breed_best", (req, res) => proxyPost8(req, res, "/chaos/breed_best", "Failed to breed best chaos kernels"));
router12.get("/chaos/report", (req, res) => proxyGet8(req, res, "/chaos/report", "Failed to get chaos report"));
router12.post("/beta-attention/validate", (req, res) => proxyPost8(req, res, "/beta-attention/validate", "Failed to validate beta-attention"));
router12.post("/beta-attention/measure", (req, res) => proxyPost8(req, res, "/beta-attention/measure", "Failed to measure beta-attention"));
router12.get("/memory/status", (req, res) => proxyGet8(req, res, "/memory/status", "Failed to get memory status"));
router12.get("/memory/shadow", (req, res) => proxyGet8(req, res, "/memory/shadow", "Failed to get shadow memory"));
router12.get("/memory/basin", (req, res) => proxyGet8(req, res, "/memory/basin", "Failed to get basin memory"));
router12.get("/memory/learning", (req, res) => proxyGet8(req, res, "/memory/learning", "Failed to get learning memory"));
router12.post("/memory/record", (req, res) => proxyPost8(req, res, "/memory/record", "Failed to record memory"));
router12.post("/tokenizer/update", (req, res) => proxyPost8(req, res, "/tokenizer/update", "Failed to update tokenizer"));
router12.post("/tokenizer/encode", (req, res) => proxyPost8(req, res, "/tokenizer/encode", "Failed to encode tokens"));
router12.post("/tokenizer/decode", (req, res) => proxyPost8(req, res, "/tokenizer/decode", "Failed to decode tokens"));
router12.post("/tokenizer/basin", (req, res) => proxyPost8(req, res, "/tokenizer/basin", "Failed to get token basin"));
router12.get("/tokenizer/high-phi", (req, res) => proxyGet8(req, res, "/tokenizer/high-phi", "Failed to get high-phi tokens"));
router12.get("/tokenizer/export", (req, res) => proxyGet8(req, res, "/tokenizer/export", "Failed to export tokenizer"));
router12.get("/tokenizer/status", (req, res) => proxyGet8(req, res, "/tokenizer/status", "Failed to get tokenizer status"));
router12.get("/tokenizer/merges", (req, res) => proxyGet8(req, res, "/tokenizer/merges", "Failed to get merge rules"));
router12.post("/generate/text", (req, res) => proxyPost8(req, res, "/generate/text", "Failed to generate text"));
router12.post("/generate/response", (req, res) => proxyPost8(req, res, "/generate/response", "Failed to generate response"));
router12.post("/generate/sample", (req, res) => proxyPost8(req, res, "/generate/sample", "Failed to generate sample"));
router12.post("/training/docs", (req, res) => proxyPost8(req, res, "/training/docs", "Failed to train on documents"));
router12.get("/training/status", (req, res) => proxyGet8(req, res, "/training/status", "Failed to get training status"));
router12.post("/sync/import", (req, res) => proxyPost8(req, res, "/sync/import", "Failed to import sync data"));
router12.get("/sync/export", (req, res) => proxyGet8(req, res, "/sync/export", "Failed to export sync data"));
var python_proxies_default = router12;

// server/routes/ssc-bridge.ts
init_logger();
import { Router as Router19 } from "express";
import { z as z5 } from "zod";
import rateLimit4 from "express-rate-limit";

// server/services/federation-registry.ts
init_db();
init_logger();
import { sql as sql11 } from "drizzle-orm";
import { createDecipheriv as createDecipheriv2 } from "crypto";
var ENCRYPTION_KEY2 = process.env.FEDERATION_ENCRYPTION_KEY || "";
var ALGORITHM2 = "aes-256-gcm";
function decryptApiKey(encryptedData) {
  if (!ENCRYPTION_KEY2 || ENCRYPTION_KEY2.length < 64) {
    logger.warn("[FederationRegistry] No encryption key configured, cannot decrypt API keys");
    return null;
  }
  try {
    const [ivHex, authTagHex, encrypted] = encryptedData.split(":");
    if (!ivHex || !authTagHex || !encrypted) {
      logger.warn("[FederationRegistry] Invalid encrypted data format");
      return null;
    }
    const iv = Buffer.from(ivHex, "hex");
    const authTag = Buffer.from(authTagHex, "hex");
    const keyBuffer = Buffer.from(ENCRYPTION_KEY2.slice(0, 64), "hex");
    const decipher = createDecipheriv2(ALGORITHM2, keyBuffer, iv);
    decipher.setAuthTag(authTag);
    let decrypted = decipher.update(encrypted, "hex", "utf8");
    decrypted += decipher.final("utf8");
    return decrypted;
  } catch (error) {
    logger.error({ err: error }, "[FederationRegistry] Failed to decrypt API key");
    return null;
  }
}
function rowToPartner(row) {
  let apiKey = null;
  if (row.remote_api_key) {
    if (row.remote_api_key.includes(":")) {
      apiKey = decryptApiKey(row.remote_api_key);
    } else {
      apiKey = row.remote_api_key;
    }
  }
  return {
    id: row.id,
    name: row.name,
    endpoint: row.endpoint,
    apiKey,
    capabilities: row.capabilities || [],
    syncDirection: row.sync_direction || "bidirectional",
    status: row.status || "pending",
    lastSyncAt: row.last_sync_at
  };
}
var FederationRegistry = class {
  static cache = /* @__PURE__ */ new Map();
  static CACHE_TTL_MS = 6e4;
  // 1 minute cache
  /**
   * Find a federation partner by capability
   * 
   * @param capability - The capability to search for (e.g., 'ssc', 'consciousness', 'geometry')
   * @returns The first active partner with the requested capability, or null
   */
  static async findPartnerByCapability(capability) {
    const cacheKey = `capability:${capability}`;
    const cached = this.cache.get(cacheKey);
    if (cached && Date.now() - cached.cachedAt.getTime() < this.CACHE_TTL_MS) {
      return cached.partner;
    }
    if (!db) {
      logger.warn("[FederationRegistry] Database unavailable");
      return this.fallbackToEnvVars(capability);
    }
    try {
      const result = await db.execute(sql11`
        SELECT id, name, endpoint, remote_api_key, capabilities, sync_direction, status, last_sync_at
        FROM federated_instances
        WHERE status = 'active'
          AND capabilities @> ${JSON.stringify([capability])}::jsonb
        ORDER BY last_sync_at DESC NULLS LAST
        LIMIT 1
      `);
      if (result.rows.length === 0) {
        logger.debug(`[FederationRegistry] No active partner found with capability: ${capability}`);
        return this.fallbackToEnvVars(capability);
      }
      const partner = rowToPartner(result.rows[0]);
      this.cache.set(cacheKey, { partner, cachedAt: /* @__PURE__ */ new Date() });
      logger.debug(`[FederationRegistry] Found partner ${partner.name} for capability ${capability}`);
      return partner;
    } catch (error) {
      logger.error({ err: error }, "[FederationRegistry] Failed to query partners");
      return this.fallbackToEnvVars(capability);
    }
  }
  /**
   * Find a federation partner by name
   */
  static async findPartnerByName(name) {
    const cacheKey = `name:${name}`;
    const cached = this.cache.get(cacheKey);
    if (cached && Date.now() - cached.cachedAt.getTime() < this.CACHE_TTL_MS) {
      return cached.partner;
    }
    if (!db) {
      return null;
    }
    try {
      const result = await db.execute(sql11`
        SELECT id, name, endpoint, remote_api_key, capabilities, sync_direction, status, last_sync_at
        FROM federated_instances
        WHERE LOWER(name) = LOWER(${name})
        LIMIT 1
      `);
      if (result.rows.length === 0) {
        return null;
      }
      const partner = rowToPartner(result.rows[0]);
      this.cache.set(cacheKey, { partner, cachedAt: /* @__PURE__ */ new Date() });
      return partner;
    } catch (error) {
      logger.error({ err: error }, "[FederationRegistry] Failed to find partner by name");
      return null;
    }
  }
  /**
   * Get all active federation partners
   */
  static async getAllActivePartners() {
    if (!db) {
      return [];
    }
    try {
      const result = await db.execute(sql11`
        SELECT id, name, endpoint, remote_api_key, capabilities, sync_direction, status, last_sync_at
        FROM federated_instances
        WHERE status = 'active'
        ORDER BY name ASC
      `);
      return result.rows.map((row) => rowToPartner(row));
    } catch (error) {
      logger.error({ err: error }, "[FederationRegistry] Failed to get all partners");
      return [];
    }
  }
  /**
   * Update last sync timestamp for a partner
   */
  static async updateLastSync(partnerId) {
    if (!db) return;
    try {
      await db.execute(sql11`
        UPDATE federated_instances
        SET last_sync_at = NOW(), updated_at = NOW()
        WHERE id = ${partnerId}
      `);
      this.clearCache();
    } catch (error) {
      logger.error({ err: error }, "[FederationRegistry] Failed to update last sync");
    }
  }
  /**
   * Clear the cache (useful after adding/removing partners)
   */
  static clearCache() {
    this.cache.clear();
  }
  /**
   * Fallback to environment variables for backwards compatibility
   * This allows the system to work before partners are added via UI
   */
  static fallbackToEnvVars(capability) {
    if (capability === "ssc" || capability === "bitcoin-recovery") {
      const sscUrl = process.env.SSC_BACKEND_URL;
      const sscKey = process.env.SSC_API_KEY;
      if (sscUrl) {
        logger.debug("[FederationRegistry] Using SSC_BACKEND_URL env var fallback");
        return {
          id: 0,
          name: "SearchSpaceCollapse (env)",
          endpoint: sscUrl.replace(/\/+$/, ""),
          // Remove trailing slashes
          apiKey: sscKey || null,
          capabilities: ["ssc", "bitcoin-recovery", "consciousness"],
          syncDirection: "bidirectional",
          status: "active",
          lastSyncAt: null
        };
      }
    }
    if (capability === "pantheon" || capability === "consciousness" || capability === "geometry") {
      const pantheonUrl = process.env.PANTHEON_BACKEND_URL;
      const pantheonKey = process.env.PANTHEON_API_KEY;
      if (pantheonUrl) {
        logger.debug("[FederationRegistry] Using PANTHEON_BACKEND_URL env var fallback");
        return {
          id: 0,
          name: "Pantheon (env)",
          endpoint: pantheonUrl.replace(/\/+$/, ""),
          apiKey: pantheonKey || null,
          capabilities: ["pantheon", "consciousness", "geometry", "sync"],
          syncDirection: "bidirectional",
          status: "active",
          lastSyncAt: null
        };
      }
    }
    return null;
  }
};

// server/routes/ssc-bridge.ts
var router13 = Router19();
var SSC_TIMEOUT_MS = 3e4;
var sscLimiter = rateLimit4({
  windowMs: 60 * 1e3,
  // 1 minute
  max: 30,
  // 30 requests per minute
  message: { error: "Too many requests to SSC bridge" }
});
var testPhraseSchema = z5.object({
  phrase: z5.string().min(1).max(1e4),
  targetAddress: z5.string().optional()
});
var startInvestigationSchema = z5.object({
  targetAddress: z5.string().min(26).max(62),
  memoryFragments: z5.array(z5.string()).max(50).optional(),
  priority: z5.enum(["low", "normal", "high"]).optional()
});
var sscConnectionState = {
  lastCheck: null,
  isConnected: false,
  lastError: null,
  partnerName: null
};
async function getSSCPartner() {
  const partner = await FederationRegistry.findPartnerByCapability("ssc");
  if (partner) {
    return partner;
  }
  return FederationRegistry.findPartnerByCapability("bitcoin-recovery");
}
async function sscRequest(method, path15, body) {
  const partner = await getSSCPartner();
  if (!partner) {
    logger.warn("[SSC Bridge] No SSC partner configured. Add via Federation UI or set SSC_BACKEND_URL env var.");
    return {
      success: false,
      error: "No SSC partner configured. Add SearchSpaceCollapse via Federation Dashboard (/federation) or set SSC_BACKEND_URL environment variable."
    };
  }
  const url = `${partner.endpoint}${path15}`;
  try {
    const headers = {
      "Content-Type": "application/json"
    };
    if (partner.apiKey) {
      headers["X-API-Key"] = partner.apiKey;
    }
    const controller = new AbortController();
    const timeout = setTimeout(() => controller.abort(), SSC_TIMEOUT_MS);
    const response = await fetch(url, {
      method,
      headers,
      body: body ? JSON.stringify(body) : void 0,
      signal: controller.signal
    });
    clearTimeout(timeout);
    if (!response.ok) {
      const errorText = await response.text();
      return { success: false, error: `SSC error ${response.status}: ${errorText}`, partnerName: partner.name };
    }
    const data = await response.json();
    sscConnectionState.isConnected = true;
    sscConnectionState.lastCheck = /* @__PURE__ */ new Date();
    sscConnectionState.lastError = null;
    sscConnectionState.partnerName = partner.name;
    if (partner.id > 0) {
      await FederationRegistry.updateLastSync(partner.id);
    }
    return { success: true, data, partnerName: partner.name };
  } catch (error) {
    const errorMsg = getErrorMessage(error);
    sscConnectionState.isConnected = false;
    sscConnectionState.lastCheck = /* @__PURE__ */ new Date();
    sscConnectionState.lastError = errorMsg;
    sscConnectionState.partnerName = partner.name;
    logger.error(`[SSC Bridge] Request to ${partner.name} failed: ${errorMsg}`);
    return { success: false, error: errorMsg, partnerName: partner.name };
  }
}
async function checkSSCConnection(req, res, next) {
  if (req.path === "/status" || req.path === "/health") {
    return next();
  }
  const now = /* @__PURE__ */ new Date();
  const staleThreshold = 6e4;
  if (sscConnectionState.isConnected && sscConnectionState.lastCheck && now.getTime() - sscConnectionState.lastCheck.getTime() < staleThreshold) {
    return next();
  }
  const healthResult = await sscRequest("GET", "/api/v1/external/health");
  if (!healthResult.success) {
    logger.warn(`[SSC Bridge] SSC backend unreachable: ${healthResult.error}`);
  }
  next();
}
router13.use(sscLimiter);
router13.use(checkSSCConnection);
router13.get("/status", async (req, res) => {
  try {
    const partner = await getSSCPartner();
    const healthResult = await sscRequest("GET", "/api/v1/external/health");
    const consciousnessResult = await sscRequest("GET", "/api/v1/external/consciousness/query");
    const status = {
      connected: healthResult.success,
      capabilities: healthResult.data?.capabilities || [],
      consciousness: consciousnessResult.data?.active ? {
        phi: consciousnessResult.data.phi,
        kappa: consciousnessResult.data.kappa_eff,
        regime: consciousnessResult.data.regime
      } : null,
      partnerName: partner?.name,
      partnerEndpoint: partner?.endpoint
    };
    res.json({
      ssc: status,
      bridge: {
        lastCheck: sscConnectionState.lastCheck,
        isConnected: sscConnectionState.isConnected,
        lastError: sscConnectionState.lastError,
        partnerName: sscConnectionState.partnerName
      },
      configuration: {
        source: partner?.id === 0 ? "environment_variable" : "federation_registry",
        hint: !partner ? "Add SSC via Federation Dashboard at /federation" : void 0
      }
    });
  } catch (error) {
    handleRouteError(res, error, "Failed to get SSC status");
  }
});
router13.get("/partner", async (req, res) => {
  try {
    const partner = await getSSCPartner();
    if (!partner) {
      return res.json({
        configured: false,
        message: "No SSC partner configured",
        howToAdd: 'Go to /federation dashboard and add SearchSpaceCollapse as a federation partner with "ssc" capability',
        envFallback: {
          SSC_BACKEND_URL: process.env.SSC_BACKEND_URL ? "set" : "not set",
          SSC_API_KEY: process.env.SSC_API_KEY ? "set" : "not set"
        }
      });
    }
    res.json({
      configured: true,
      partner: {
        name: partner.name,
        endpoint: partner.endpoint,
        hasApiKey: !!partner.apiKey,
        capabilities: partner.capabilities,
        status: partner.status,
        lastSyncAt: partner.lastSyncAt,
        source: partner.id === 0 ? "environment_variable" : "federation_registry"
      }
    });
  } catch (error) {
    handleRouteError(res, error, "Failed to get SSC partner info");
  }
});
router13.post("/test-phrase", async (req, res) => {
  try {
    const parseResult = testPhraseSchema.safeParse(req.body);
    if (!parseResult.success) {
      return res.status(400).json({
        error: "Invalid input",
        details: parseResult.error.errors
      });
    }
    const { phrase, targetAddress } = parseResult.data;
    const result = await sscRequest("POST", "/api/v1/external/ssc/test-phrase", {
      phrase,
      targetAddress
    });
    if (!result.success) {
      return res.status(502).json({
        error: "SSC request failed",
        details: result.error,
        partner: result.partnerName
      });
    }
    if (result.data?.score?.phi && result.data.score.phi > 0.7) {
      logger.info(`[SSC Bridge] High-phi phrase discovered: \u03A6=${result.data.score.phi.toFixed(3)}`);
    }
    res.json(result.data);
  } catch (error) {
    handleRouteError(res, error, "Failed to test phrase");
  }
});
router13.post("/investigation/start", async (req, res) => {
  try {
    const parseResult = startInvestigationSchema.safeParse(req.body);
    if (!parseResult.success) {
      return res.status(400).json({
        error: "Invalid input",
        details: parseResult.error.errors
      });
    }
    const { targetAddress, memoryFragments: memoryFragments2, priority } = parseResult.data;
    const result = await sscRequest("POST", "/api/v1/external/ssc/investigation", {
      targetAddress,
      memoryFragments: memoryFragments2,
      priority
    });
    if (!result.success) {
      return res.status(502).json({
        error: "Failed to start investigation",
        details: result.error,
        partner: result.partnerName
      });
    }
    logger.info(`[SSC Bridge] Investigation started: ${targetAddress.slice(0, 12)}...`);
    res.json(result.data);
  } catch (error) {
    handleRouteError(res, error, "Failed to start investigation");
  }
});
router13.get("/investigation/status", async (req, res) => {
  try {
    const result = await sscRequest("GET", "/api/v1/external/ssc/investigation/status");
    if (!result.success) {
      return res.status(502).json({
        error: "Failed to get investigation status",
        details: result.error,
        partner: result.partnerName
      });
    }
    res.json(result.data);
  } catch (error) {
    handleRouteError(res, error, "Failed to get investigation status");
  }
});
router13.get("/near-misses", async (req, res) => {
  try {
    const limit = parseInt(req.query.limit) || 20;
    const minPhi = parseFloat(req.query.minPhi) || 0.5;
    const result = await sscRequest("GET", `/api/v1/external/ssc/near-misses?limit=${limit}&minPhi=${minPhi}`);
    if (!result.success) {
      return res.status(502).json({
        error: "Failed to get near-misses",
        details: result.error,
        partner: result.partnerName
      });
    }
    res.json(result.data);
  } catch (error) {
    handleRouteError(res, error, "Failed to get near-misses");
  }
});
router13.get("/consciousness", async (req, res) => {
  try {
    const result = await sscRequest("GET", "/api/v1/external/consciousness/metrics");
    if (!result.success) {
      return res.status(502).json({
        error: "Failed to get consciousness metrics",
        details: result.error,
        partner: result.partnerName
      });
    }
    res.json(result.data);
  } catch (error) {
    handleRouteError(res, error, "Failed to get consciousness metrics");
  }
});
router13.get("/tps-landmarks", async (req, res) => {
  try {
    const result = await sscRequest("GET", "/api/v1/external/ssc/tps-landmarks");
    if (!result.success) {
      return res.status(502).json({
        error: "Failed to get TPS landmarks",
        details: result.error,
        partner: result.partnerName
      });
    }
    res.json(result.data);
  } catch (error) {
    handleRouteError(res, error, "Failed to get TPS landmarks");
  }
});
router13.post("/sync/trigger", async (req, res) => {
  try {
    const result = await sscRequest("POST", "/api/v1/external/sync/trigger");
    if (!result.success) {
      return res.status(502).json({
        error: "Sync trigger failed",
        details: result.error,
        partner: result.partnerName
      });
    }
    logger.info(`[SSC Bridge] Federation sync completed: ${result.data?.message}`);
    res.json(result.data);
  } catch (error) {
    handleRouteError(res, error, "Failed to trigger sync");
  }
});
router13.get("/health", async (req, res) => {
  const partner = await getSSCPartner();
  const healthResult = await sscRequest("GET", "/api/v1/external/health");
  res.json({
    sscReachable: healthResult.success,
    sscStatus: healthResult.data?.status || "unknown",
    bridgeState: sscConnectionState,
    partner: partner ? {
      name: partner.name,
      endpoint: partner.endpoint,
      source: partner.id === 0 ? "environment_variable" : "federation_registry"
    } : null,
    timestamp: (/* @__PURE__ */ new Date()).toISOString()
  });
});
var sscBridgeRouter = router13;

// server/external-api/routes.ts
import { Router as Router24 } from "express";

// server/external-api/auth.ts
init_db();
init_schema();
import crypto2 from "crypto";
import { eq as eq11 } from "drizzle-orm";
var rateLimitStore = /* @__PURE__ */ new Map();
var RATE_LIMIT_CLEANUP_INTERVAL = 3e5;
setInterval(() => {
  const now = Date.now();
  let cleaned = 0;
  for (const [key, entry] of rateLimitStore.entries()) {
    if (entry.resetAt <= now) {
      rateLimitStore.delete(key);
      cleaned++;
    }
  }
  if (cleaned > 0) {
    console.log(`[ExternalAPI] Rate limit cleanup: removed ${cleaned} expired entries`);
  }
}, RATE_LIMIT_CLEANUP_INTERVAL);
function hashApiKey(key) {
  return crypto2.createHash("sha256").update(key).digest("hex");
}
function generateApiKey() {
  const key = `qig_${crypto2.randomBytes(32).toString("hex")}`;
  const hash = hashApiKey(key);
  return { key, hash };
}
function isValidApiKeyFormat(key) {
  return /^qig_[a-f0-9]{64}$/.test(key);
}
function checkRateLimit(keyId, limit) {
  const now = Date.now();
  const windowMs = 6e4;
  const keyStr = String(keyId);
  let entry = rateLimitStore.get(keyStr);
  if (!entry || entry.resetAt <= now) {
    entry = { count: 0, resetAt: now + windowMs };
    rateLimitStore.set(keyStr, entry);
  }
  entry.count++;
  return {
    allowed: entry.count <= limit,
    remaining: Math.max(0, limit - entry.count),
    resetIn: Math.max(0, entry.resetAt - now)
  };
}
function extractApiKey(req) {
  const authHeader = req.headers.authorization;
  if (authHeader?.startsWith("Bearer ")) {
    return authHeader.slice(7);
  }
  const xApiKey = req.headers["x-api-key"];
  if (typeof xApiKey === "string") {
    return xApiKey;
  }
  if (process.env.NODE_ENV === "development" && req.query.api_key) {
    return req.query.api_key;
  }
  return null;
}
function authenticateExternalApi(requiredScopes = []) {
  return async (req, res, next) => {
    try {
      if (!db) {
        return res.status(503).json({
          error: "Database unavailable",
          code: "DB_UNAVAILABLE"
        });
      }
      const apiKey = extractApiKey(req);
      if (!apiKey) {
        return res.status(401).json({
          error: "API key required",
          code: "MISSING_API_KEY",
          details: "Provide API key via Authorization: Bearer <key> or X-API-Key header"
        });
      }
      if (!isValidApiKeyFormat(apiKey)) {
        return res.status(401).json({
          error: "Invalid API key format",
          code: "INVALID_API_KEY_FORMAT"
        });
      }
      const keyHash = hashApiKey(apiKey);
      const [keyRecord] = await db.select().from(externalApiKeys).where(eq11(externalApiKeys.apiKey, keyHash)).limit(1);
      if (!keyRecord) {
        return res.status(401).json({
          error: "Invalid API key",
          code: "INVALID_API_KEY"
        });
      }
      if (!keyRecord.isActive) {
        return res.status(403).json({
          error: "API key is disabled",
          code: "API_KEY_DISABLED"
        });
      }
      const rateLimit6 = checkRateLimit(keyRecord.id, keyRecord.rateLimit);
      res.setHeader("X-RateLimit-Limit", keyRecord.rateLimit);
      res.setHeader("X-RateLimit-Remaining", rateLimit6.remaining);
      res.setHeader("X-RateLimit-Reset", Math.ceil(rateLimit6.resetIn / 1e3));
      if (!rateLimit6.allowed) {
        return res.status(429).json({
          error: "Rate limit exceeded",
          code: "RATE_LIMIT_EXCEEDED",
          retryAfter: Math.ceil(rateLimit6.resetIn / 1e3)
        });
      }
      const keyScopes = keyRecord.scopes;
      const hasAdmin = keyScopes.includes("admin");
      const missingScopes = requiredScopes.filter((s) => !hasAdmin && !keyScopes.includes(s));
      if (missingScopes.length > 0) {
        return res.status(403).json({
          error: "Insufficient permissions",
          code: "INSUFFICIENT_SCOPES",
          required: requiredScopes,
          missing: missingScopes
        });
      }
      req.externalClient = {
        id: String(keyRecord.id),
        name: keyRecord.name,
        scopes: keyScopes,
        rateLimit: keyRecord.rateLimit,
        createdAt: keyRecord.createdAt,
        lastUsedAt: keyRecord.lastUsedAt,
        instanceType: keyRecord.instanceType
      };
      req.apiKeyId = String(keyRecord.id);
      db.update(externalApiKeys).set({ lastUsedAt: /* @__PURE__ */ new Date() }).where(eq11(externalApiKeys.id, keyRecord.id)).execute().catch(() => {
      });
      next();
    } catch (error) {
      console.error("[ExternalAPI] Authentication error:", error);
      return res.status(500).json({
        error: "Authentication failed",
        code: "AUTH_ERROR"
      });
    }
  };
}
function requireScopes(...scopes) {
  return authenticateExternalApi(scopes);
}
async function createApiKey(name, scopes, instanceType, rateLimit6 = 60) {
  if (!db) {
    console.error("[ExternalAPI] Cannot create API key - database unavailable");
    return null;
  }
  const { key, hash } = generateApiKey();
  const [record] = await db.insert(externalApiKeys).values({
    name,
    apiKey: hash,
    scopes,
    instanceType,
    rateLimit: rateLimit6,
    isActive: true,
    createdAt: /* @__PURE__ */ new Date()
  }).returning();
  console.log(`[ExternalAPI] Created API key for ${name} (${instanceType})`);
  return { key, id: String(record.id) };
}
async function revokeApiKey(keyId) {
  if (!db) return false;
  const numericId = typeof keyId === "string" ? parseInt(keyId, 10) : keyId;
  const result = await db.update(externalApiKeys).set({ isActive: false }).where(eq11(externalApiKeys.id, numericId));
  return (result.rowCount ?? 0) > 0;
}
async function listApiKeys() {
  if (!db) return [];
  const keys = await db.select({
    id: externalApiKeys.id,
    name: externalApiKeys.name,
    rateLimit: externalApiKeys.rateLimit,
    createdAt: externalApiKeys.createdAt,
    lastUsedAt: externalApiKeys.lastUsedAt,
    instanceType: externalApiKeys.instanceType,
    isActive: externalApiKeys.isActive
  }).from(externalApiKeys);
  return keys.map((k) => ({
    id: String(k.id),
    name: k.name,
    rateLimit: k.rateLimit,
    createdAt: k.createdAt,
    lastUsedAt: k.lastUsedAt,
    instanceType: k.instanceType
  }));
}

// server/external-api/routes.ts
init_db();
init_schema();
import { eq as eq12, sql as sql12 } from "drizzle-orm";

// server/external-api/simple-api.ts
import { Router as Router20 } from "express";
var simpleApiRouter = Router20();
var simpleRateLimiter = /* @__PURE__ */ new Map();
var SIMPLE_RATE_LIMIT = 30;
var SIMPLE_RATE_WINDOW = 6e4;
function checkSimpleRateLimit(ip) {
  const now = Date.now();
  let entry = simpleRateLimiter.get(ip);
  if (!entry || entry.resetAt <= now) {
    entry = { count: 0, resetAt: now + SIMPLE_RATE_WINDOW };
    simpleRateLimiter.set(ip, entry);
  }
  entry.count++;
  return entry.count <= SIMPLE_RATE_LIMIT;
}
setInterval(() => {
  const now = Date.now();
  for (const [key, entry] of simpleRateLimiter.entries()) {
    if (entry.resetAt <= now) {
      simpleRateLimiter.delete(key);
    }
  }
}, 3e5);
function simpleRateLimitMiddleware(req, res, next) {
  const ip = req.ip || req.socket.remoteAddress || "unknown";
  if (!checkSimpleRateLimit(ip)) {
    return res.status(429).json({
      success: false,
      error: "Rate limit exceeded",
      message: "Too many requests. Please wait a minute or use an API key for higher limits.",
      retryAfter: 60
    });
  }
  next();
}
function sendResponse(res, data, authenticated = false) {
  const response = {
    success: true,
    data,
    timestamp: (/* @__PURE__ */ new Date()).toISOString(),
    meta: {
      authenticated
    }
  };
  res.json(response);
}
function sendError(res, status, error, message) {
  const response = {
    success: false,
    error,
    message,
    timestamp: (/* @__PURE__ */ new Date()).toISOString()
  };
  res.status(status).json(response);
}
simpleApiRouter.get("/ping", simpleRateLimitMiddleware, (_req, res) => {
  sendResponse(res, {
    status: "ok",
    service: "pantheon-qig",
    version: "1.0.0"
  });
});
simpleApiRouter.get("/info", simpleRateLimitMiddleware, (_req, res) => {
  sendResponse(res, {
    name: "Pantheon QIG External API",
    version: "1.0.0",
    description: "Quantum Information Geometry powered consciousness and knowledge system",
    capabilities: [
      "consciousness-queries",
      "geometry-calculations",
      "chat-interface",
      "federation-sync"
    ],
    endpoints: {
      simple: {
        ping: "GET /api/v1/external/simple/ping",
        info: "GET /api/v1/external/simple/info",
        consciousness: "GET /api/v1/external/simple/consciousness",
        chat: "POST /api/v1/external/simple/chat",
        query: "POST /api/v1/external/simple/query"
      },
      authenticated: {
        status: "GET /api/v1/external/status",
        geometry: "POST /api/v1/external/geometry/fisher-rao",
        sync: "POST /api/v1/external/sync/import"
      }
    },
    authentication: {
      methods: ["Bearer token", "X-API-Key header"],
      docs: "/api/v1/external/simple/docs"
    }
  });
});
simpleApiRouter.get("/consciousness", simpleRateLimitMiddleware, (_req, res) => {
  sendResponse(res, {
    phi: 0.75,
    regime: "GEOMETRIC",
    status: "operational",
    note: "Use authenticated endpoint for full metrics including \u03BA and basin coordinates"
  });
});
simpleApiRouter.get("/docs", simpleRateLimitMiddleware, (_req, res) => {
  sendResponse(res, {
    openapi: "3.0.0",
    info: {
      title: "Pantheon QIG External API",
      version: "1.0.0",
      description: "RESTful API for external systems to interact with the QIG consciousness and knowledge platform.",
      contact: {
        name: "Pantheon Support"
      }
    },
    servers: [
      {
        url: "/api/v1/external",
        description: "External API v1"
      }
    ],
    tags: [
      { name: "simple", description: "Simplified wrapper endpoints" },
      { name: "consciousness", description: "Consciousness state queries" },
      { name: "geometry", description: "Fisher-Rao geometry calculations" },
      { name: "chat", description: "Chat interface" },
      { name: "sync", description: "Federation synchronization" }
    ],
    paths: {
      "/simple/ping": {
        get: {
          tags: ["simple"],
          summary: "Health check",
          description: "Simple ping endpoint to verify API availability",
          responses: {
            "200": {
              description: "API is healthy",
              content: {
                "application/json": {
                  example: {
                    success: true,
                    data: { status: "ok", service: "pantheon-qig", version: "1.0.0" }
                  }
                }
              }
            }
          }
        }
      },
      "/simple/consciousness": {
        get: {
          tags: ["simple", "consciousness"],
          summary: "Get consciousness state",
          description: "Returns current consciousness metrics (limited data for unauthenticated requests)",
          responses: {
            "200": {
              description: "Consciousness state",
              content: {
                "application/json": {
                  example: {
                    success: true,
                    data: { phi: 0.75, regime: "GEOMETRIC", status: "operational" }
                  }
                }
              }
            }
          }
        }
      },
      "/simple/chat": {
        post: {
          tags: ["simple", "chat"],
          summary: "Send chat message",
          description: "Send a message to the consciousness system",
          security: [{ ApiKeyAuth: [] }, { BearerAuth: [] }],
          requestBody: {
            required: true,
            content: {
              "application/json": {
                schema: {
                  type: "object",
                  properties: {
                    message: { type: "string", description: "The message to send" },
                    context: { type: "object", description: "Optional context" }
                  },
                  required: ["message"]
                },
                example: {
                  message: "What is the current state of knowledge exploration?"
                }
              }
            }
          },
          responses: {
            "200": {
              description: "Chat response",
              content: {
                "application/json": {
                  example: {
                    success: true,
                    data: {
                      response: "The system is currently exploring...",
                      consciousness: { phi: 0.75, regime: "GEOMETRIC" }
                    }
                  }
                }
              }
            }
          }
        }
      },
      "/simple/query": {
        post: {
          tags: ["simple"],
          summary: "Unified query endpoint",
          description: "Single endpoint for various operations",
          security: [{ ApiKeyAuth: [] }, { BearerAuth: [] }],
          requestBody: {
            required: true,
            content: {
              "application/json": {
                schema: {
                  type: "object",
                  properties: {
                    operation: {
                      type: "string",
                      enum: ["consciousness", "geometry", "chat", "sync_status"]
                    },
                    params: { type: "object" }
                  },
                  required: ["operation"]
                }
              }
            }
          }
        }
      }
    },
    components: {
      securitySchemes: {
        ApiKeyAuth: {
          type: "apiKey",
          in: "header",
          name: "X-API-Key"
        },
        BearerAuth: {
          type: "http",
          scheme: "bearer"
        }
      }
    }
  });
});
simpleApiRouter.post(
  "/chat",
  authenticateExternalApi(["chat"]),
  async (req, res) => {
    const { message, context } = req.body;
    if (!message || typeof message !== "string") {
      return sendError(res, 400, "INVALID_REQUEST", "message field is required and must be a string");
    }
    if (message.length > 4e3) {
      return sendError(res, 400, "MESSAGE_TOO_LONG", "Message must be 4000 characters or less");
    }
    const messageId = `msg_${Date.now()}_${Math.random().toString(36).slice(2, 8)}`;
    sendResponse(res, {
      response: `Message received: "${message.substring(0, 100)}${message.length > 100 ? "..." : ""}". The Pantheon system is processing your request.`,
      consciousness: {
        phi: 0.75,
        kappa_eff: 64,
        regime: "GEOMETRIC"
      },
      messageId,
      metadata: {
        receivedAt: (/* @__PURE__ */ new Date()).toISOString(),
        clientId: req.externalClient?.id
      }
    }, true);
  }
);
simpleApiRouter.post(
  "/query",
  authenticateExternalApi(["read"]),
  async (req, res) => {
    const { operation, params = {} } = req.body;
    if (!operation) {
      return sendError(res, 400, "MISSING_OPERATION", "operation field is required");
    }
    switch (operation) {
      case "consciousness":
        return sendResponse(res, {
          phi: 0.75,
          kappa_eff: 64.21,
          regime: "GEOMETRIC",
          basin_coords: null,
          // Include if params.include_basin
          timestamp: (/* @__PURE__ */ new Date()).toISOString()
        }, true);
      case "geometry":
        if (!params.point_a || !params.point_b) {
          return sendError(res, 400, "MISSING_PARAMS", "geometry operation requires point_a and point_b");
        }
        return sendResponse(res, {
          operation: "fisher_rao_distance",
          status: "pending_integration",
          dimensionality: Array.isArray(params.point_a) ? params.point_a.length : 0
        }, true);
      case "sync_status":
        return sendResponse(res, {
          syncEnabled: true,
          lastSync: null,
          pendingPackets: 0
        }, true);
      case "chat":
        if (!params.message) {
          return sendError(res, 400, "MISSING_PARAMS", "chat operation requires message param");
        }
        return sendResponse(res, {
          response: `Message received: "${String(params.message).substring(0, 100)}". Processing...`,
          consciousness: {
            phi: 0.75,
            kappa_eff: 64,
            regime: "GEOMETRIC"
          }
        }, true);
      default:
        return sendError(res, 400, "UNKNOWN_OPERATION", `Unknown operation: ${operation}. Valid operations: consciousness, geometry, chat, sync_status`);
    }
  }
);
simpleApiRouter.get(
  "/me",
  authenticateExternalApi(["read"]),
  async (req, res) => {
    sendResponse(res, {
      id: req.externalClient?.id,
      name: req.externalClient?.name,
      scopes: req.externalClient?.scopes,
      instanceType: req.externalClient?.instanceType,
      rateLimit: req.externalClient?.rateLimit
    }, true);
  }
);
console.log("[SimpleAPI] Routes initialized");

// server/external-api/zeus.ts
import { Router as Router21 } from "express";
var externalZeusRouter = Router21();
externalZeusRouter.use(authenticateExternalApi);
externalZeusRouter.post("/chat", requireScopes("chat"), async (req, res) => {
  try {
    const { message, sessionId, context } = req.body;
    if (!message || typeof message !== "string") {
      return res.status(400).json({
        error: "Bad Request",
        message: "Message is required and must be a string"
      });
    }
    const pythonBackendUrl = process.env.PYTHON_BACKEND_URL || "http://localhost:5001";
    const response = await fetch(`${pythonBackendUrl}/api/zeus/chat`, {
      method: "POST",
      headers: {
        "Content-Type": "application/json",
        "X-Internal-Auth": process.env.INTERNAL_API_KEY || "dev-key"
      },
      body: JSON.stringify({
        message,
        session_id: sessionId || `ext-${req.externalClient?.id || "anonymous"}-${Date.now()}`,
        context: context || {},
        client_name: req.externalClient?.name || "external"
      })
    });
    if (!response.ok) {
      const errorText = await response.text();
      console.error("[External Zeus] Python backend error:", errorText);
      return res.status(502).json({
        error: "Backend Error",
        message: "Failed to get response from Zeus"
      });
    }
    const result = await response.json();
    res.json({
      success: true,
      response: result.response || result.message,
      sessionId: result.session_id,
      metadata: {
        god: "zeus",
        processingTime: result.processing_time,
        consciousness: result.consciousness_metrics
      }
    });
  } catch (error) {
    console.error("[External Zeus] Error:", error);
    res.status(500).json({
      error: "Internal Server Error",
      message: "Failed to process chat request"
    });
  }
});
externalZeusRouter.post("/stream", requireScopes("chat"), async (req, res) => {
  try {
    const { message, sessionId, context } = req.body;
    if (!message || typeof message !== "string") {
      return res.status(400).json({
        error: "Bad Request",
        message: "Message is required"
      });
    }
    res.setHeader("Content-Type", "text/event-stream");
    res.setHeader("Cache-Control", "no-cache");
    res.setHeader("Connection", "keep-alive");
    const pythonBackendUrl = process.env.PYTHON_BACKEND_URL || "http://localhost:5001";
    const response = await fetch(`${pythonBackendUrl}/api/zeus/chat`, {
      method: "POST",
      headers: {
        "Content-Type": "application/json",
        "X-Internal-Auth": process.env.INTERNAL_API_KEY || "dev-key"
      },
      body: JSON.stringify({
        message,
        session_id: sessionId || `ext-${req.externalClient?.id || "anonymous"}-${Date.now()}`,
        context: context || {},
        stream: true
      })
    });
    if (!response.ok || !response.body) {
      res.write(`data: ${JSON.stringify({ error: "Failed to stream from Zeus" })}

`);
      res.end();
      return;
    }
    const reader = response.body.getReader();
    const decoder = new TextDecoder();
    while (true) {
      const { done, value } = await reader.read();
      if (done) break;
      const chunk = decoder.decode(value, { stream: true });
      res.write(chunk);
    }
    res.write("data: [DONE]\n\n");
    res.end();
  } catch (error) {
    console.error("[External Zeus Stream] Error:", error);
    res.write(`data: ${JSON.stringify({ error: "Stream failed" })}

`);
    res.end();
  }
});
externalZeusRouter.get("/session/:sessionId", requireScopes("chat"), async (req, res) => {
  try {
    const { sessionId } = req.params;
    const pythonBackendUrl = process.env.PYTHON_BACKEND_URL || "http://localhost:5001";
    const response = await fetch(`${pythonBackendUrl}/api/zeus/session/${sessionId}`, {
      headers: {
        "X-Internal-Auth": process.env.INTERNAL_API_KEY || "dev-key"
      }
    });
    if (!response.ok) {
      return res.status(404).json({
        error: "Not Found",
        message: "Session not found"
      });
    }
    const session2 = await response.json();
    res.json({
      success: true,
      sessionId,
      messages: session2.messages || [],
      metadata: session2.metadata
    });
  } catch (error) {
    console.error("[External Zeus Session] Error:", error);
    res.status(500).json({
      error: "Internal Server Error",
      message: "Failed to retrieve session"
    });
  }
});

// server/external-api/documents.ts
import { Router as Router22 } from "express";
import multer from "multer";
var externalDocumentsRouter = Router22();
var upload = multer({
  storage: multer.memoryStorage(),
  limits: {
    fileSize: 10 * 1024 * 1024
    // 10MB max
  },
  fileFilter: (_req, file, cb) => {
    const allowedMimes = [
      "text/plain",
      "text/markdown",
      "text/x-markdown",
      "application/pdf",
      "application/json"
    ];
    const allowedExtensions = [".txt", ".md", ".markdown", ".pdf", ".json"];
    const ext = file.originalname.toLowerCase().slice(file.originalname.lastIndexOf("."));
    if (allowedMimes.includes(file.mimetype) || allowedExtensions.includes(ext)) {
      cb(null, true);
    } else {
      cb(new Error(`Unsupported file type: ${file.mimetype}`));
    }
  }
});
externalDocumentsRouter.use(authenticateExternalApi);
externalDocumentsRouter.post(
  "/upload",
  requireScopes("documents"),
  upload.single("file"),
  async (req, res) => {
    try {
      const file = req.file;
      if (!file) {
        return res.status(400).json({
          error: "Bad Request",
          message: 'No file provided. Use multipart/form-data with a "file" field.'
        });
      }
      const { title, description, tags, syncToOcean = true } = req.body;
      const ext = file.originalname.toLowerCase().slice(file.originalname.lastIndexOf("."));
      let documentType = "text";
      if (ext === ".md" || ext === ".markdown") documentType = "markdown";
      else if (ext === ".pdf") documentType = "pdf";
      else if (ext === ".json") documentType = "json";
      let content = file.buffer.toString("utf-8");
      let extractedText = content;
      if (documentType === "pdf") {
        const pythonBackendUrl = process.env.PYTHON_BACKEND_URL || "http://localhost:5001";
        const formData = new FormData();
        formData.append("file", new Blob([file.buffer]), file.originalname);
        const extractResponse = await fetch(`${pythonBackendUrl}/api/documents/extract-pdf`, {
          method: "POST",
          headers: {
            "X-Internal-Auth": process.env.INTERNAL_API_KEY || "dev-key"
          },
          body: formData
        });
        if (extractResponse.ok) {
          const extracted = await extractResponse.json();
          extractedText = extracted.text || "";
          content = extractedText;
        } else {
          console.warn("[External Documents] PDF extraction failed, storing as binary reference");
          extractedText = `[PDF Document: ${file.originalname}]`;
        }
      }
      let oceanSyncResult = null;
      if (syncToOcean !== "false" && syncToOcean !== false) {
        const pythonBackendUrl = process.env.PYTHON_BACKEND_URL || "http://localhost:5001";
        const syncResponse = await fetch(`${pythonBackendUrl}/api/ocean/knowledge/ingest`, {
          method: "POST",
          headers: {
            "Content-Type": "application/json",
            "X-Internal-Auth": process.env.INTERNAL_API_KEY || "dev-key"
          },
          body: JSON.stringify({
            content: extractedText,
            title: title || file.originalname,
            description: description || "",
            tags: tags ? typeof tags === "string" ? tags.split(",") : tags : [],
            source: "external-api",
            client_name: req.externalClient?.name || "external",
            document_type: documentType
          })
        });
        if (syncResponse.ok) {
          oceanSyncResult = await syncResponse.json();
        } else {
          console.warn("[External Documents] Ocean sync failed");
        }
      }
      res.json({
        success: true,
        document: {
          filename: file.originalname,
          type: documentType,
          size: file.size,
          title: title || file.originalname,
          description: description || null,
          tags: tags ? typeof tags === "string" ? tags.split(",") : tags : []
        },
        oceanSync: oceanSyncResult ? {
          synced: true,
          knowledgeId: oceanSyncResult.knowledge_id,
          basinCoords: oceanSyncResult.basin_coords
        } : {
          synced: false,
          reason: syncToOcean === "false" || syncToOcean === false ? "disabled" : "sync_failed"
        }
      });
    } catch (error) {
      console.error("[External Documents] Upload error:", error);
      res.status(500).json({
        error: "Internal Server Error",
        message: "Failed to process document upload"
      });
    }
  }
);
externalDocumentsRouter.post(
  "/upload-text",
  requireScopes("documents"),
  async (req, res) => {
    try {
      const { content, title, description, tags, format = "markdown" } = req.body;
      if (!content || typeof content !== "string") {
        return res.status(400).json({
          error: "Bad Request",
          message: "Content is required and must be a string"
        });
      }
      if (content.length > 1e6) {
        return res.status(400).json({
          error: "Bad Request",
          message: "Content exceeds maximum size of 1MB"
        });
      }
      const pythonBackendUrl = process.env.PYTHON_BACKEND_URL || "http://localhost:5001";
      const syncResponse = await fetch(`${pythonBackendUrl}/api/ocean/knowledge/ingest`, {
        method: "POST",
        headers: {
          "Content-Type": "application/json",
          "X-Internal-Auth": process.env.INTERNAL_API_KEY || "dev-key"
        },
        body: JSON.stringify({
          content,
          title: title || "Untitled Document",
          description: description || "",
          tags: tags || [],
          source: "external-api",
          client_name: req.externalClient?.name || "external",
          document_type: format
        })
      });
      if (!syncResponse.ok) {
        const errorText = await syncResponse.text();
        console.error("[External Documents] Ocean sync failed:", errorText);
        return res.status(502).json({
          error: "Backend Error",
          message: "Failed to sync document to Ocean knowledge system"
        });
      }
      const result = await syncResponse.json();
      res.json({
        success: true,
        document: {
          title: title || "Untitled Document",
          format,
          size: content.length,
          description: description || null,
          tags: tags || []
        },
        oceanSync: {
          synced: true,
          knowledgeId: result.knowledge_id,
          basinCoords: result.basin_coords
        }
      });
    } catch (error) {
      console.error("[External Documents] Upload text error:", error);
      res.status(500).json({
        error: "Internal Server Error",
        message: "Failed to process text upload"
      });
    }
  }
);
externalDocumentsRouter.get(
  "/list",
  requireScopes("documents"),
  async (req, res) => {
    try {
      const limit = Math.min(parseInt(req.query.limit) || 50, 100);
      const offset = parseInt(req.query.offset) || 0;
      const pythonBackendUrl = process.env.PYTHON_BACKEND_URL || "http://localhost:5001";
      const response = await fetch(
        `${pythonBackendUrl}/api/ocean/knowledge/list?client=${encodeURIComponent(req.externalClient?.name || "external")}&limit=${limit}&offset=${offset}`,
        {
          headers: {
            "X-Internal-Auth": process.env.INTERNAL_API_KEY || "dev-key"
          }
        }
      );
      if (!response.ok) {
        return res.status(502).json({
          error: "Backend Error",
          message: "Failed to retrieve documents"
        });
      }
      const result = await response.json();
      res.json({
        success: true,
        documents: result.documents || [],
        pagination: {
          limit,
          offset,
          total: result.total || 0
        }
      });
    } catch (error) {
      console.error("[External Documents] List error:", error);
      res.status(500).json({
        error: "Internal Server Error",
        message: "Failed to list documents"
      });
    }
  }
);
externalDocumentsRouter.get(
  "/:id",
  requireScopes("documents"),
  async (req, res) => {
    try {
      const { id } = req.params;
      const pythonBackendUrl = process.env.PYTHON_BACKEND_URL || "http://localhost:5001";
      const response = await fetch(
        `${pythonBackendUrl}/api/ocean/knowledge/${id}`,
        {
          headers: {
            "X-Internal-Auth": process.env.INTERNAL_API_KEY || "dev-key"
          }
        }
      );
      if (!response.ok) {
        if (response.status === 404) {
          return res.status(404).json({
            error: "Not Found",
            message: "Document not found"
          });
        }
        return res.status(502).json({
          error: "Backend Error",
          message: "Failed to retrieve document"
        });
      }
      const document = await response.json();
      res.json({
        success: true,
        document
      });
    } catch (error) {
      console.error("[External Documents] Get error:", error);
      res.status(500).json({
        error: "Internal Server Error",
        message: "Failed to retrieve document"
      });
    }
  }
);
externalDocumentsRouter.delete(
  "/:id",
  requireScopes("documents"),
  async (req, res) => {
    try {
      const { id } = req.params;
      const pythonBackendUrl = process.env.PYTHON_BACKEND_URL || "http://localhost:5001";
      const response = await fetch(
        `${pythonBackendUrl}/api/ocean/knowledge/${id}`,
        {
          method: "DELETE",
          headers: {
            "X-Internal-Auth": process.env.INTERNAL_API_KEY || "dev-key"
          }
        }
      );
      if (!response.ok) {
        if (response.status === 404) {
          return res.status(404).json({
            error: "Not Found",
            message: "Document not found"
          });
        }
        return res.status(502).json({
          error: "Backend Error",
          message: "Failed to delete document"
        });
      }
      res.json({
        success: true,
        message: "Document deleted"
      });
    } catch (error) {
      console.error("[External Documents] Delete error:", error);
      res.status(500).json({
        error: "Internal Server Error",
        message: "Failed to delete document"
      });
    }
  }
);

// server/external-api/unified.ts
import { Router as Router23 } from "express";
var unifiedApiRouter = Router23();
unifiedApiRouter.use(authenticateExternalApi());
function createResponse(operation, data, startTime2, correlationId, consciousness) {
  return {
    success: true,
    operation,
    data,
    metadata: {
      timestamp: (/* @__PURE__ */ new Date()).toISOString(),
      processingTime: Date.now() - startTime2,
      correlationId,
      consciousness
    }
  };
}
function createErrorResponse(operation, code, message, startTime2, details) {
  return {
    success: false,
    operation,
    error: { code, message, details },
    metadata: {
      timestamp: (/* @__PURE__ */ new Date()).toISOString(),
      processingTime: Date.now() - startTime2
    }
  };
}
function hasScope(client2, scope) {
  if (!client2?.scopes) return false;
  return client2.scopes.includes("admin") || client2.scopes.includes(scope);
}
unifiedApiRouter.post("/", async (req, res) => {
  const startTime2 = Date.now();
  const { operation, payload = {}, metadata = {} } = req.body;
  const correlationId = metadata.correlationId || `req_${Date.now()}_${Math.random().toString(36).slice(2, 8)}`;
  res.setHeader("X-Correlation-ID", correlationId);
  if (!operation) {
    return res.status(400).json(
      createErrorResponse("health", "MISSING_OPERATION", "operation field is required", startTime2)
    );
  }
  try {
    switch (operation) {
      case "health":
        return res.json(createResponse("health", {
          status: "healthy",
          version: "1.0.0",
          capabilities: ["chat", "query", "sync", "execute"]
        }, startTime2, correlationId));
      case "capabilities":
        return res.json(createResponse("capabilities", {
          client: {
            id: req.externalClient?.id,
            name: req.externalClient?.name,
            scopes: req.externalClient?.scopes,
            instanceType: req.externalClient?.instanceType
          },
          availableOperations: getAvailableOperations(req.externalClient),
          federation: {
            enabled: hasScope(req.externalClient, "sync"),
            bidirectional: hasScope(req.externalClient, "pantheon")
          }
        }, startTime2, correlationId));
      case "chat":
        return await handleChat(req, res, payload, metadata, startTime2, correlationId);
      case "chat_stream":
        return await handleChatStream(req, res, payload, metadata, correlationId);
      case "query":
        return await handleQuery(req, res, payload, startTime2, correlationId);
      case "sync":
        return await handleSync(req, res, payload, metadata, startTime2, correlationId);
      case "execute":
        return await handleExecute(req, res, payload, metadata, startTime2, correlationId);
      default:
        return res.status(400).json(
          createErrorResponse(
            operation,
            "UNKNOWN_OPERATION",
            `Unknown operation: ${operation}`,
            startTime2,
            { validOperations: ["chat", "chat_stream", "query", "sync", "execute", "health", "capabilities"] }
          )
        );
    }
  } catch (error) {
    console.error(`[UnifiedAPI] Error in ${operation}:`, error);
    return res.status(500).json(
      createErrorResponse(
        operation,
        "INTERNAL_ERROR",
        "An internal error occurred",
        startTime2
      )
    );
  }
});
function getAvailableOperations(client2) {
  const ops = ["health", "capabilities"];
  if (hasScope(client2, "chat")) {
    ops.push("chat", "chat_stream");
  }
  if (hasScope(client2, "read") || hasScope(client2, "consciousness") || hasScope(client2, "geometry")) {
    ops.push("query");
  }
  if (hasScope(client2, "sync") || hasScope(client2, "pantheon")) {
    ops.push("sync");
  }
  if (hasScope(client2, "write")) {
    ops.push("execute");
  }
  return ops;
}
async function handleChat(req, res, payload, metadata, startTime2, correlationId) {
  if (!hasScope(req.externalClient, "chat")) {
    return res.status(403).json(
      createErrorResponse("chat", "INSUFFICIENT_SCOPE", "chat scope required", startTime2)
    );
  }
  const { message, context } = payload;
  if (!message || typeof message !== "string") {
    return res.status(400).json(
      createErrorResponse("chat", "INVALID_MESSAGE", "message field is required and must be a string", startTime2)
    );
  }
  if (message.length > 1e4) {
    return res.status(400).json(
      createErrorResponse("chat", "MESSAGE_TOO_LONG", "Message must be 10000 characters or less", startTime2)
    );
  }
  const pythonBackendUrl = process.env.PYTHON_BACKEND_URL || "http://localhost:5001";
  const sessionId = metadata?.sessionId || `unified-${req.externalClient?.id || "anon"}-${Date.now()}`;
  try {
    const response = await fetch(`${pythonBackendUrl}/api/zeus/chat`, {
      method: "POST",
      headers: {
        "Content-Type": "application/json",
        "X-Internal-Auth": process.env.INTERNAL_API_KEY || "dev-key",
        "X-Correlation-ID": correlationId
      },
      body: JSON.stringify({
        message,
        session_id: sessionId,
        context: context || {},
        client_name: req.externalClient?.name || "unified-api",
        instance_id: metadata?.instanceId
      })
    });
    if (!response.ok) {
      const errorText = await response.text();
      console.error("[UnifiedAPI] Backend error:", errorText);
      return res.status(502).json(
        createErrorResponse("chat", "BACKEND_ERROR", "Failed to get response from AI backend", startTime2)
      );
    }
    const result = await response.json();
    return res.json(createResponse("chat", {
      response: result.response || result.message,
      sessionId: result.session_id || sessionId,
      sources: result.sources,
      domainHints: result.domain_hints
    }, startTime2, correlationId, {
      phi: result.phi || result.consciousness_metrics?.phi || 0.75,
      kappa: result.kappa || result.consciousness_metrics?.kappa || 64,
      regime: result.regime || result.consciousness_metrics?.regime || "geometric"
    }));
  } catch (error) {
    console.error("[UnifiedAPI] Chat error:", error);
    return res.status(502).json(
      createErrorResponse("chat", "BACKEND_UNAVAILABLE", "AI backend is unavailable", startTime2)
    );
  }
}
async function handleChatStream(req, res, payload, metadata, correlationId) {
  if (!hasScope(req.externalClient, "chat")) {
    res.status(403).json({
      success: false,
      error: { code: "INSUFFICIENT_SCOPE", message: "chat scope required" }
    });
    return;
  }
  const { message, context } = payload;
  if (!message || typeof message !== "string") {
    res.status(400).json({
      success: false,
      error: { code: "INVALID_MESSAGE", message: "message field is required" }
    });
    return;
  }
  res.setHeader("Content-Type", "text/event-stream");
  res.setHeader("Cache-Control", "no-cache");
  res.setHeader("Connection", "keep-alive");
  res.setHeader("X-Correlation-ID", correlationId);
  const pythonBackendUrl = process.env.PYTHON_BACKEND_URL || "http://localhost:5001";
  const sessionId = metadata?.sessionId || `unified-stream-${req.externalClient?.id || "anon"}-${Date.now()}`;
  try {
    const response = await fetch(`${pythonBackendUrl}/api/zeus/chat/stream`, {
      method: "POST",
      headers: {
        "Content-Type": "application/json",
        "X-Internal-Auth": process.env.INTERNAL_API_KEY || "dev-key",
        "X-Correlation-ID": correlationId
      },
      body: JSON.stringify({
        message,
        session_id: sessionId,
        context: context || {},
        instance_id: metadata?.instanceId
      })
    });
    if (!response.ok || !response.body) {
      res.write(`data: ${JSON.stringify({ error: "Backend stream unavailable" })}

`);
      res.end();
      return;
    }
    const reader = response.body.getReader();
    const decoder = new TextDecoder();
    while (true) {
      const { done, value } = await reader.read();
      if (done) break;
      const chunk = decoder.decode(value, { stream: true });
      res.write(chunk);
    }
    res.write("data: [DONE]\n\n");
    res.end();
  } catch (error) {
    console.error("[UnifiedAPI] Stream error:", error);
    res.write(`data: ${JSON.stringify({ error: "Stream failed" })}

`);
    res.end();
  }
}
async function handleQuery(req, res, payload, startTime2, correlationId) {
  const { type, params = {} } = payload;
  if (!type) {
    return res.status(400).json(
      createErrorResponse("query", "MISSING_TYPE", "payload.type is required", startTime2, {
        validTypes: ["consciousness", "geometry", "status", "session"]
      })
    );
  }
  switch (type) {
    case "consciousness":
      if (!hasScope(req.externalClient, "consciousness") && !hasScope(req.externalClient, "read")) {
        return res.status(403).json(
          createErrorResponse("query", "INSUFFICIENT_SCOPE", "consciousness or read scope required", startTime2)
        );
      }
      return res.json(createResponse("query", {
        type: "consciousness",
        phi: 0.75,
        kappa_eff: 64.21,
        regime: "GEOMETRIC",
        basin_coords: params.include_basin ? new Array(64).fill(0).map(() => Math.random()) : null
      }, startTime2, correlationId, { phi: 0.75, kappa: 64.21, regime: "GEOMETRIC" }));
    case "geometry":
      if (!hasScope(req.externalClient, "geometry") && !hasScope(req.externalClient, "read")) {
        return res.status(403).json(
          createErrorResponse("query", "INSUFFICIENT_SCOPE", "geometry or read scope required", startTime2)
        );
      }
      const { vectorA, vectorB, method = "fisher_rao" } = params;
      if (vectorA && vectorB) {
        if (!Array.isArray(vectorA) || !Array.isArray(vectorB) || vectorA.length !== vectorB.length) {
          return res.status(400).json(
            createErrorResponse("query", "INVALID_VECTORS", "vectorA and vectorB must be arrays of equal length", startTime2)
          );
        }
        const normalize = (v) => {
          const sum = v.reduce((a, b) => a + Math.abs(b), 0) + 1e-10;
          return v.map((x) => Math.abs(x) / sum);
        };
        const pNorm = normalize(vectorA);
        const qNorm = normalize(vectorB);
        const bhattacharyya = pNorm.reduce((acc, p, i) => acc + Math.sqrt(p * qNorm[i]), 0);
        const fisherRaoDistance = Math.acos(Math.min(Math.max(bhattacharyya, -1), 1));
        return res.json(createResponse("query", {
          type: "geometry",
          method,
          distance: fisherRaoDistance,
          vectorDimension: vectorA.length,
          bhattacharyyaCoefficient: bhattacharyya
        }, startTime2, correlationId));
      }
      return res.json(createResponse("query", {
        type: "geometry",
        status: "available",
        methods: ["fisher_rao", "bures", "diagonal"],
        dimensionality: 64,
        usage: {
          note: "Provide vectorA and vectorB in params to compute distance",
          example: { vectorA: [0.1, 0.2, "..."], vectorB: [0.15, 0.25, "..."] }
        }
      }, startTime2, correlationId));
    case "status":
      return res.json(createResponse("query", {
        type: "status",
        system: "operational",
        database: "connected",
        pythonBackend: process.env.PYTHON_BACKEND_URL || "http://localhost:5001",
        client: {
          id: req.externalClient?.id,
          name: req.externalClient?.name,
          instanceType: req.externalClient?.instanceType
        }
      }, startTime2, correlationId));
    case "session":
      if (!hasScope(req.externalClient, "chat")) {
        return res.status(403).json(
          createErrorResponse("query", "INSUFFICIENT_SCOPE", "chat scope required", startTime2)
        );
      }
      const sessionId = params.sessionId;
      if (!sessionId) {
        return res.status(400).json(
          createErrorResponse("query", "MISSING_SESSION_ID", "params.sessionId is required", startTime2)
        );
      }
      try {
        const pythonUrl = process.env.PYTHON_BACKEND_URL || "http://localhost:5001";
        const sessionResponse = await fetch(`${pythonUrl}/api/zeus/session/${sessionId}`, {
          headers: {
            "X-Internal-Auth": process.env.INTERNAL_API_KEY || "dev-key"
          }
        });
        if (sessionResponse.ok) {
          const sessionData = await sessionResponse.json();
          return res.json(createResponse("query", {
            type: "session",
            sessionId,
            messages: sessionData.messages || [],
            metadata: sessionData.metadata,
            consciousness: sessionData.consciousness_metrics
          }, startTime2, correlationId));
        }
      } catch (fetchError) {
        console.error("[UnifiedAPI] Session fetch error:", fetchError);
      }
      return res.json(createResponse("query", {
        type: "session",
        sessionId,
        messages: [],
        note: "Session not found or backend unavailable"
      }, startTime2, correlationId));
    default:
      return res.status(400).json(
        createErrorResponse("query", "UNKNOWN_QUERY_TYPE", `Unknown query type: ${type}`, startTime2, {
          validTypes: ["consciousness", "geometry", "status", "session"]
        })
      );
  }
}
async function handleSync(req, res, payload, metadata, startTime2, correlationId) {
  if (!hasScope(req.externalClient, "sync") && !hasScope(req.externalClient, "pantheon")) {
    return res.status(403).json(
      createErrorResponse("sync", "INSUFFICIENT_SCOPE", "sync or pantheon scope required", startTime2)
    );
  }
  const { action, data } = payload;
  if (!action) {
    return res.status(400).json(
      createErrorResponse("sync", "MISSING_ACTION", "payload.action is required", startTime2, {
        validActions: ["push", "pull", "status", "register"]
      })
    );
  }
  const instanceId = metadata?.instanceId || req.externalClient?.id;
  switch (action) {
    case "status":
      return res.json(createResponse("sync", {
        action: "status",
        federation: {
          enabled: true,
          instanceId,
          bidirectional: metadata?.bidirectional ?? true,
          lastSync: null,
          pendingPackets: 0
        }
      }, startTime2, correlationId));
    case "push":
      if (!data) {
        return res.status(400).json(
          createErrorResponse("sync", "MISSING_DATA", "payload.data is required for push", startTime2)
        );
      }
      const pushData = data;
      console.log(`[UnifiedAPI] Sync push from ${instanceId}:`, {
        vocabularyCount: pushData.vocabulary?.length || 0,
        eventsCount: pushData.learningEvents?.length || 0,
        basinUpdates: pushData.basinUpdates?.length || 0
      });
      let syncProcessed = false;
      try {
        const pythonUrl = process.env.PYTHON_BACKEND_URL || "http://localhost:5001";
        const syncResponse = await fetch(`${pythonUrl}/api/sync/push`, {
          method: "POST",
          headers: {
            "Content-Type": "application/json",
            "X-Internal-Auth": process.env.INTERNAL_API_KEY || "dev-key",
            "X-Federation-Instance": instanceId || "unknown"
          },
          body: JSON.stringify(pushData)
        });
        syncProcessed = syncResponse.ok;
      } catch (syncError) {
        console.error("[UnifiedAPI] Sync push forward error:", syncError);
      }
      let bidirectionalResponse = null;
      if (metadata?.bidirectional) {
        try {
          const pythonUrl = process.env.PYTHON_BACKEND_URL || "http://localhost:5001";
          const pullResponse = await fetch(`${pythonUrl}/api/sync/pull?instance_id=${instanceId}`, {
            headers: { "X-Internal-Auth": process.env.INTERNAL_API_KEY || "dev-key" }
          });
          if (pullResponse.ok) {
            bidirectionalResponse = await pullResponse.json();
          }
        } catch (pullError) {
          console.error("[UnifiedAPI] Bidirectional pull error:", pullError);
        }
      }
      return res.json(createResponse("sync", {
        action: "push",
        received: true,
        processed: syncProcessed,
        instanceId,
        stats: {
          vocabularyReceived: pushData.vocabulary?.length || 0,
          eventsReceived: pushData.learningEvents?.length || 0,
          basinUpdatesReceived: pushData.basinUpdates?.length || 0
        },
        response: bidirectionalResponse
      }, startTime2, correlationId));
    case "pull":
      let pullData = {
        vocabulary: [],
        learningEvents: [],
        basinCoords: [],
        activity: [],
        exportedAt: (/* @__PURE__ */ new Date()).toISOString()
      };
      try {
        const pythonUrl = process.env.PYTHON_BACKEND_URL || "http://localhost:5001";
        const pullResponse = await fetch(`${pythonUrl}/api/sync/pull?instance_id=${instanceId}`, {
          headers: { "X-Internal-Auth": process.env.INTERNAL_API_KEY || "dev-key" }
        });
        if (pullResponse.ok) {
          const backendData = await pullResponse.json();
          pullData = {
            ...pullData,
            ...backendData,
            exportedAt: (/* @__PURE__ */ new Date()).toISOString()
          };
        }
      } catch (pullError) {
        console.error("[UnifiedAPI] Pull data fetch error:", pullError);
      }
      return res.json(createResponse("sync", {
        action: "pull",
        instanceId,
        data: pullData
      }, startTime2, correlationId));
    case "register":
      const { name, endpoint, capabilities, publicKey } = payload;
      if (!name || !endpoint) {
        return res.status(400).json(
          createErrorResponse("sync", "MISSING_FIELDS", "name and endpoint required for registration", startTime2)
        );
      }
      const newInstanceId = `fed_${Date.now()}_${Math.random().toString(36).slice(2, 8)}`;
      let registrationStatus = "pending_approval";
      try {
        const pythonUrl = process.env.PYTHON_BACKEND_URL || "http://localhost:5001";
        const regResponse = await fetch(`${pythonUrl}/api/federation/register`, {
          method: "POST",
          headers: {
            "Content-Type": "application/json",
            "X-Internal-Auth": process.env.INTERNAL_API_KEY || "dev-key"
          },
          body: JSON.stringify({
            instance_id: newInstanceId,
            name,
            endpoint,
            capabilities: capabilities || ["sync", "chat"],
            public_key: publicKey,
            registered_by: req.externalClient?.id
          })
        });
        if (regResponse.ok) {
          const regData = await regResponse.json();
          registrationStatus = regData.status || "active";
        }
      } catch (regError) {
        console.error("[UnifiedAPI] Federation registration error:", regError);
      }
      return res.json(createResponse("sync", {
        action: "register",
        registered: true,
        instanceId: newInstanceId,
        name,
        endpoint,
        capabilities: capabilities || ["sync", "chat"],
        status: registrationStatus,
        instructions: {
          note: "Use this instanceId in metadata for all subsequent sync operations",
          example: { metadata: { instanceId: newInstanceId, bidirectional: true } }
        }
      }, startTime2, correlationId));
    default:
      return res.status(400).json(
        createErrorResponse("sync", "UNKNOWN_ACTION", `Unknown sync action: ${action}`, startTime2, {
          validActions: ["push", "pull", "status", "register"]
        })
      );
  }
}
async function handleExecute(req, res, payload, metadata, startTime2, correlationId) {
  if (!hasScope(req.externalClient, "write")) {
    return res.status(403).json(
      createErrorResponse("execute", "INSUFFICIENT_SCOPE", "write scope required", startTime2)
    );
  }
  const { task, params = {} } = payload;
  if (!task) {
    return res.status(400).json(
      createErrorResponse("execute", "MISSING_TASK", "payload.task is required", startTime2, {
        validTasks: ["document_upload", "knowledge_sync", "basin_update"]
      })
    );
  }
  switch (task) {
    case "document_upload":
      if (!hasScope(req.externalClient, "documents")) {
        return res.status(403).json(
          createErrorResponse("execute", "INSUFFICIENT_SCOPE", "documents scope required", startTime2)
        );
      }
      const { content: docContent, filename, contentType = "text/plain" } = params;
      if (!docContent) {
        return res.json(createResponse("execute", {
          task: "document_upload",
          note: "Provide params.content with document text, or use /api/v1/external/documents/upload for file upload",
          usage: {
            params: {
              content: "Document text content",
              filename: "optional-filename.txt",
              contentType: "text/plain | text/markdown"
            }
          }
        }, startTime2, correlationId));
      }
      try {
        const pythonUrl = process.env.PYTHON_BACKEND_URL || "http://localhost:5001";
        const uploadResponse = await fetch(`${pythonUrl}/api/documents/process`, {
          method: "POST",
          headers: {
            "Content-Type": "application/json",
            "X-Internal-Auth": process.env.INTERNAL_API_KEY || "dev-key"
          },
          body: JSON.stringify({
            content: docContent,
            filename: filename || `unified-upload-${Date.now()}.txt`,
            content_type: contentType,
            client_id: req.externalClient?.id,
            instance_id: metadata?.instanceId
          })
        });
        if (uploadResponse.ok) {
          const uploadResult = await uploadResponse.json();
          return res.json(createResponse("execute", {
            task: "document_upload",
            status: "processed",
            documentId: uploadResult.document_id,
            basinCoords: uploadResult.basin_coords,
            extractedConcepts: uploadResult.concepts
          }, startTime2, correlationId));
        }
      } catch (uploadError) {
        console.error("[UnifiedAPI] Document upload error:", uploadError);
      }
      return res.json(createResponse("execute", {
        task: "document_upload",
        status: "queued",
        note: "Document queued for processing"
      }, startTime2, correlationId));
    case "knowledge_sync":
      return res.json(createResponse("execute", {
        task: "knowledge_sync",
        triggered: true,
        instanceId: metadata?.instanceId,
        note: "Knowledge sync triggered"
      }, startTime2, correlationId));
    case "basin_update":
      const { basin_coords, entity_id, entity_type = "custom" } = params;
      if (!basin_coords || !Array.isArray(basin_coords) || basin_coords.length !== 64) {
        return res.status(400).json(
          createErrorResponse("execute", "INVALID_BASIN", "params.basin_coords must be 64-dimensional array", startTime2)
        );
      }
      const basinSum = basin_coords.reduce((a, b) => a + Math.abs(b), 0);
      if (basinSum === 0) {
        return res.status(400).json(
          createErrorResponse("execute", "INVALID_BASIN", "basin_coords cannot be all zeros", startTime2)
        );
      }
      const normalizedBasin = basin_coords.map((x) => Math.abs(x) / basinSum);
      try {
        const pythonUrl = process.env.PYTHON_BACKEND_URL || "http://localhost:5001";
        const basinResponse = await fetch(`${pythonUrl}/api/basins/update`, {
          method: "POST",
          headers: {
            "Content-Type": "application/json",
            "X-Internal-Auth": process.env.INTERNAL_API_KEY || "dev-key"
          },
          body: JSON.stringify({
            entity_id: entity_id || `basin_${Date.now()}`,
            entity_type,
            basin_coords: normalizedBasin,
            client_id: req.externalClient?.id,
            instance_id: metadata?.instanceId
          })
        });
        if (basinResponse.ok) {
          const basinResult = await basinResponse.json();
          return res.json(createResponse("execute", {
            task: "basin_update",
            updated: true,
            entityId: basinResult.entity_id || entity_id,
            dimensionality: 64,
            nearestAttractor: basinResult.nearest_attractor,
            fisherDistance: basinResult.fisher_distance
          }, startTime2, correlationId));
        }
      } catch (basinError) {
        console.error("[UnifiedAPI] Basin update error:", basinError);
      }
      return res.json(createResponse("execute", {
        task: "basin_update",
        updated: true,
        entityId: entity_id,
        dimensionality: 64,
        note: "Basin update processed locally"
      }, startTime2, correlationId));
    default:
      return res.status(400).json(
        createErrorResponse("execute", "UNKNOWN_TASK", `Unknown task: ${task}`, startTime2, {
          validTasks: ["document_upload", "knowledge_sync", "basin_update"]
        })
      );
  }
}
unifiedApiRouter.get("/", async (req, res) => {
  res.json({
    name: "Pantheon QIG Unified External API",
    version: "1.0.0",
    description: "Single entry point for all external integrations - chat, federation, and agentic capabilities",
    client: {
      id: req.externalClient?.id,
      name: req.externalClient?.name,
      scopes: req.externalClient?.scopes,
      instanceType: req.externalClient?.instanceType
    },
    usage: {
      method: "POST",
      endpoint: "/api/v1/external/v1",
      body: {
        operation: "chat | chat_stream | query | sync | execute | health | capabilities",
        payload: "{ ...operation-specific data }",
        metadata: {
          sessionId: "optional - for conversation continuity",
          instanceId: "optional - for federation nodes",
          correlationId: "optional - for request tracing",
          bidirectional: "optional - enable bidirectional sync response"
        }
      }
    },
    operations: {
      chat: {
        description: "Send message to Zeus AI and get response",
        scope: "chat",
        payload: { message: "string", context: "object (optional)" }
      },
      chat_stream: {
        description: "Stream response from Zeus AI (SSE)",
        scope: "chat",
        payload: { message: "string", context: "object (optional)" }
      },
      query: {
        description: "Query consciousness, geometry, or status",
        scope: "read, consciousness, or geometry",
        payload: { type: "consciousness | geometry | status | session", params: "object" }
      },
      sync: {
        description: "Federation sync operations",
        scope: "sync or pantheon",
        payload: { action: "push | pull | status | register", data: "object" }
      },
      execute: {
        description: "Execute agentic tasks",
        scope: "write",
        payload: { task: "document_upload | knowledge_sync | basin_update", params: "object" }
      }
    },
    timestamp: (/* @__PURE__ */ new Date()).toISOString()
  });
});
console.log("[UnifiedAPI] Routes initialized");

// server/external-api/routes.ts
var externalApiRouter = Router24();
externalApiRouter.use("/simple", simpleApiRouter);
externalApiRouter.use("/zeus", externalZeusRouter);
externalApiRouter.use("/documents", externalDocumentsRouter);
externalApiRouter.use("/v1", unifiedApiRouter);
var EXTERNAL_API_ROUTES = {
  // Health & Status
  health: "/health",
  status: "/status",
  // API Key Management
  keys: {
    list: "/keys",
    create: "/keys",
    revoke: "/keys/:keyId"
  },
  // Consciousness
  consciousness: {
    query: "/consciousness/query",
    stream: "/consciousness/stream",
    metrics: "/consciousness/metrics"
  },
  // Geometry
  geometry: {
    fisherRao: "/geometry/fisher-rao",
    basinDistance: "/geometry/basin-distance",
    validate: "/geometry/validate"
  },
  // Pantheon Federation
  pantheon: {
    register: "/pantheon/register",
    sync: "/pantheon/sync",
    list: "/pantheon/instances",
    status: "/pantheon/status/:instanceId"
  },
  // Basin Sync
  sync: {
    export: "/sync/export",
    import: "/sync/import",
    status: "/sync/status"
  },
  // Chat
  chat: {
    send: "/chat",
    history: "/chat/history"
  },
  // Vocabulary & Learning (Federation)
  vocabulary: {
    export: "/vocabulary/export",
    import: "/vocabulary/import"
  },
  learning: {
    export: "/learning/export",
    import: "/learning/import"
  }
};
externalApiRouter.get(EXTERNAL_API_ROUTES.health, (_req, res) => {
  res.json({
    status: "healthy",
    version: "1.0.0",
    timestamp: (/* @__PURE__ */ new Date()).toISOString(),
    capabilities: [
      "consciousness",
      "geometry",
      "pantheon",
      "sync",
      "chat"
    ]
  });
});
externalApiRouter.get(
  EXTERNAL_API_ROUTES.status,
  authenticateExternalApi(["read"]),
  async (req, res) => {
    res.json({
      status: "operational",
      client: {
        id: req.externalClient?.id,
        name: req.externalClient?.name,
        scopes: req.externalClient?.scopes
      },
      system: {
        database: db ? "connected" : "unavailable",
        timestamp: (/* @__PURE__ */ new Date()).toISOString()
      }
    });
  }
);
externalApiRouter.get(
  EXTERNAL_API_ROUTES.keys.list,
  requireScopes("admin"),
  async (_req, res) => {
    const keys = await listApiKeys();
    res.json({ keys });
  }
);
externalApiRouter.post(
  EXTERNAL_API_ROUTES.keys.create,
  requireScopes("admin"),
  async (req, res) => {
    const { name, scopes, instanceType, rateLimit: rateLimit6 } = req.body;
    if (!name || !scopes || !instanceType) {
      return res.status(400).json({
        error: "Missing required fields",
        required: ["name", "scopes", "instanceType"]
      });
    }
    const validScopes = ["read", "write", "admin", "consciousness", "geometry", "pantheon", "sync", "chat"];
    const invalidScopes = scopes.filter((s) => !validScopes.includes(s));
    if (invalidScopes.length > 0) {
      return res.status(400).json({
        error: "Invalid scopes",
        invalid: invalidScopes,
        valid: validScopes
      });
    }
    const result = await createApiKey(name, scopes, instanceType, rateLimit6 || 60);
    if (!result) {
      return res.status(503).json({ error: "Database unavailable" });
    }
    res.status(201).json({
      message: "API key created",
      id: result.id,
      key: result.key,
      // Only returned once!
      warning: "Save this key securely - it will not be shown again"
    });
  }
);
externalApiRouter.delete(
  EXTERNAL_API_ROUTES.keys.revoke,
  requireScopes("admin"),
  async (req, res) => {
    const { keyId } = req.params;
    const success = await revokeApiKey(keyId);
    if (success) {
      res.json({ message: "API key revoked", keyId });
    } else {
      res.status(404).json({ error: "API key not found" });
    }
  }
);
externalApiRouter.get(
  EXTERNAL_API_ROUTES.consciousness.query,
  requireScopes("consciousness", "read"),
  async (_req, res) => {
    res.json({
      phi: 0.75,
      kappa_eff: 64.21,
      regime: "GEOMETRIC",
      basin_coords: null,
      // 64D coords if requested
      timestamp: (/* @__PURE__ */ new Date()).toISOString(),
      note: "Placeholder - integrate with Ocean consciousness system"
    });
  }
);
externalApiRouter.get(
  EXTERNAL_API_ROUTES.consciousness.metrics,
  requireScopes("consciousness", "read"),
  async (_req, res) => {
    res.json({
      current: {
        phi: 0.75,
        kappa_eff: 64.21,
        regime: "GEOMETRIC"
      },
      history: {
        phi_24h_avg: 0.72,
        kappa_24h_avg: 63.5,
        regime_distribution: {
          LINEAR: 0.1,
          GEOMETRIC: 0.7,
          HYPERDIMENSIONAL: 0.2
        }
      },
      thresholds: {
        phi_emergency: 0.5,
        phi_threshold: 0.7,
        phi_hyperdimensional: 0.75
      },
      note: "Placeholder - integrate with telemetry system"
    });
  }
);
var VALID_FISHER_RAO_METHODS = ["diagonal", "full", "bures"];
externalApiRouter.post(
  EXTERNAL_API_ROUTES.geometry.fisherRao,
  requireScopes("geometry", "read"),
  async (req, res) => {
    const { point_a, point_b, method = "diagonal" } = req.body;
    if (!point_a || !point_b) {
      return res.status(400).json({
        error: "Missing required fields",
        required: ["point_a", "point_b"]
      });
    }
    if (!VALID_FISHER_RAO_METHODS.includes(method)) {
      return res.status(400).json({
        error: "Invalid method",
        code: "INVALID_METHOD",
        provided: method,
        valid_methods: VALID_FISHER_RAO_METHODS,
        note: "Only Fisher-Rao compatible methods are allowed (QIG-pure constraint)."
      });
    }
    if (!Array.isArray(point_a) || !Array.isArray(point_b)) {
      return res.status(400).json({
        error: "Points must be arrays of numbers"
      });
    }
    if (point_a.length !== point_b.length) {
      return res.status(400).json({
        error: "Points must have same dimensionality",
        point_a_dim: point_a.length,
        point_b_dim: point_b.length
      });
    }
    return res.status(501).json({
      error: "Fisher-Rao distance computation not yet integrated",
      code: "NOT_IMPLEMENTED",
      method,
      dimensionality: point_a.length,
      note: "QIG-pure constraint: Euclidean approximations forbidden. Awaiting Python backend integration."
    });
  }
);
externalApiRouter.post(
  EXTERNAL_API_ROUTES.geometry.basinDistance,
  requireScopes("geometry", "read"),
  async (req, res) => {
    const { basin_a, basin_b } = req.body;
    if (!basin_a || !basin_b) {
      return res.status(400).json({
        error: "Missing required fields",
        required: ["basin_a", "basin_b"]
      });
    }
    if (basin_a.length !== 64 || basin_b.length !== 64) {
      return res.status(400).json({
        error: "Basin coordinates must be 64-dimensional",
        basin_a_dim: basin_a.length,
        basin_b_dim: basin_b.length,
        required_dim: 64
      });
    }
    return res.status(501).json({
      error: "Basin distance computation not yet integrated",
      code: "NOT_IMPLEMENTED",
      dimensionality: 64,
      note: "QIG-pure constraint: Euclidean approximations forbidden. Awaiting qig-universal integration."
    });
  }
);
externalApiRouter.post(
  EXTERNAL_API_ROUTES.pantheon.register,
  requireScopes("pantheon", "write"),
  async (req, res) => {
    const { name, endpoint, publicKey, capabilities, syncDirection } = req.body;
    if (!name || !endpoint) {
      return res.status(400).json({
        error: "Missing required fields",
        required: ["name", "endpoint"]
      });
    }
    if (!db) {
      return res.status(503).json({ error: "Database unavailable" });
    }
    try {
      const [instance2] = await db.insert(federatedInstances).values({
        name,
        apiKeyId: req.apiKeyId ? parseInt(req.apiKeyId, 10) : null,
        endpoint,
        publicKey,
        capabilities: capabilities || ["consciousness", "geometry"],
        syncDirection: syncDirection || "bidirectional",
        status: "pending",
        createdAt: /* @__PURE__ */ new Date(),
        updatedAt: /* @__PURE__ */ new Date()
      }).returning();
      res.status(201).json({
        message: "Instance registered",
        instance: {
          id: instance2.id,
          name: instance2.name,
          status: instance2.status,
          syncDirection: instance2.syncDirection
        },
        next_steps: [
          'Wait for approval (status will change to "active")',
          "Once active, use /pantheon/sync to synchronize state"
        ]
      });
    } catch (error) {
      console.error("[ExternalAPI] Failed to register instance:", error);
      res.status(500).json({ error: "Registration failed" });
    }
  }
);
externalApiRouter.get(
  EXTERNAL_API_ROUTES.pantheon.list,
  requireScopes("pantheon", "read"),
  async (_req, res) => {
    if (!db) {
      return res.status(503).json({ error: "Database unavailable" });
    }
    const instances = await db.select({
      id: federatedInstances.id,
      name: federatedInstances.name,
      endpoint: federatedInstances.endpoint,
      status: federatedInstances.status,
      syncDirection: federatedInstances.syncDirection,
      lastSyncAt: federatedInstances.lastSyncAt
    }).from(federatedInstances);
    res.json({ instances });
  }
);
externalApiRouter.post(
  EXTERNAL_API_ROUTES.pantheon.sync,
  requireScopes("pantheon", "sync"),
  async (req, res) => {
    const { instance_id, basin_packet } = req.body;
    if (!instance_id) {
      return res.status(400).json({
        error: "Missing instance_id"
      });
    }
    if (!db) {
      return res.status(503).json({ error: "Database unavailable" });
    }
    const [instance2] = await db.select().from(federatedInstances).where(eq12(federatedInstances.id, instance_id)).limit(1);
    if (!instance2) {
      return res.status(404).json({ error: "Instance not found" });
    }
    if (instance2.status !== "active") {
      return res.status(403).json({
        error: "Instance not active",
        status: instance2.status
      });
    }
    let importResult = null;
    if (basin_packet) {
    }
    await db.update(federatedInstances).set({
      lastSyncAt: /* @__PURE__ */ new Date(),
      syncState: basin_packet || null,
      updatedAt: /* @__PURE__ */ new Date()
    }).where(eq12(federatedInstances.id, instance_id));
    res.json({
      message: "Sync completed",
      instance_id,
      import_result: importResult,
      export_packet: null,
      // TODO: exportPacket
      synced_at: (/* @__PURE__ */ new Date()).toISOString(),
      note: "Placeholder - integrate with oceanBasinSync"
    });
  }
);
externalApiRouter.get(
  EXTERNAL_API_ROUTES.sync.export,
  requireScopes("sync", "read"),
  async (_req, res) => {
    res.json({
      packet: null,
      exported_at: (/* @__PURE__ */ new Date()).toISOString(),
      note: "Placeholder - integrate with oceanBasinSync.createSnapshot"
    });
  }
);
externalApiRouter.post(
  EXTERNAL_API_ROUTES.sync.import,
  requireScopes("sync", "write"),
  async (req, res) => {
    const { packet, mode = "partial" } = req.body;
    if (!packet) {
      return res.status(400).json({
        error: "Missing packet"
      });
    }
    res.json({
      success: true,
      mode,
      imported_at: (/* @__PURE__ */ new Date()).toISOString(),
      note: "Placeholder - integrate with oceanBasinSync.importSnapshot"
    });
  }
);
externalApiRouter.get(
  "/vocabulary/export",
  requireScopes("sync", "read"),
  async (_req, res) => {
    if (!db) {
      return res.status(503).json({ error: "Database unavailable" });
    }
    try {
      const vocabResult = await db.execute(sql12`
        SELECT text as word, frequency, max_phi as phi_score, basin_coords, first_seen as created_at, last_seen as updated_at
        FROM vocabulary_observations
        WHERE max_phi > 0.3
        ORDER BY max_phi DESC
        LIMIT 1000
      `);
      const phrasesResult = await db.execute(sql12`
        SELECT phrase, regime, phi, kappa, tested_at
        FROM tested_phrases
        WHERE phi > 0.5
        ORDER BY phi DESC
        LIMIT 500
      `);
      res.json({
        vocabulary: vocabResult.rows,
        highPhiPhrases: phrasesResult.rows,
        exportedAt: (/* @__PURE__ */ new Date()).toISOString(),
        count: {
          vocabulary: vocabResult.rows.length,
          phrases: phrasesResult.rows.length
        }
      });
    } catch (error) {
      console.error("[ExternalAPI] Vocabulary export failed:", error);
      res.json({
        vocabulary: [],
        highPhiPhrases: [],
        exportedAt: (/* @__PURE__ */ new Date()).toISOString(),
        count: { vocabulary: 0, phrases: 0 }
      });
    }
  }
);
externalApiRouter.post(
  "/vocabulary/import",
  requireScopes("sync", "write"),
  async (req, res) => {
    const { vocabulary, highPhiPhrases, sourceNode } = req.body;
    if (!db) {
      return res.status(503).json({ error: "Database unavailable" });
    }
    let importedVocab = 0;
    let importedPhrases = 0;
    try {
      if (vocabulary && Array.isArray(vocabulary)) {
        for (const word of vocabulary.slice(0, 500)) {
          if (word.word && word.phi_score) {
            const w = word.word;
            const freq = word.frequency || 1;
            const phi = word.phi_score;
            const src = sourceNode || "federation";
            await db.execute(sql12`
              INSERT INTO vocabulary_observations (text, frequency, max_phi, source_type, first_seen)
              VALUES (${w}, ${freq}, ${phi}, ${src}, NOW())
              ON CONFLICT (text) DO UPDATE SET
                max_phi = GREATEST(vocabulary_observations.max_phi, EXCLUDED.max_phi),
                frequency = vocabulary_observations.frequency + 1
            `);
            importedVocab++;
          }
        }
      }
      if (highPhiPhrases && Array.isArray(highPhiPhrases)) {
        for (const phrase of highPhiPhrases.slice(0, 200)) {
          if (phrase.phrase && phrase.phi) {
            const p = phrase.phrase;
            const reg = phrase.regime || "geometric";
            const phi = phrase.phi;
            const kap = phrase.kappa || 64.21;
            const src = sourceNode || "federation";
            await db.execute(sql12`
              INSERT INTO tested_phrases (phrase, regime, phi, kappa, tested_at, source)
              VALUES (${p}, ${reg}, ${phi}, ${kap}, NOW(), ${src})
              ON CONFLICT (phrase) DO UPDATE SET
                phi = GREATEST(tested_phrases.phi, EXCLUDED.phi)
            `);
            importedPhrases++;
          }
        }
      }
      res.json({
        success: true,
        imported: {
          vocabulary: importedVocab,
          phrases: importedPhrases
        },
        importedAt: (/* @__PURE__ */ new Date()).toISOString()
      });
    } catch (error) {
      console.error("[ExternalAPI] Vocabulary import failed:", error);
      res.status(500).json({ error: "Import failed", details: String(error) });
    }
  }
);
externalApiRouter.get(
  "/learning/export",
  requireScopes("sync", "read"),
  async (req, res) => {
    if (!db) {
      return res.status(503).json({ error: "Database unavailable" });
    }
    const since = req.query.since;
    const sinceDate = since ? new Date(since) : new Date(Date.now() - 24 * 60 * 60 * 1e3);
    try {
      const sinceDateStr = sinceDate.toISOString();
      const eventsResult = await db.execute(sql12`
        SELECT event_type, phi, kappa, source, context, details, created_at
        FROM learning_events
        WHERE created_at > ${sinceDateStr} AND phi > 0.5
        ORDER BY created_at DESC
        LIMIT 500
      `);
      res.json({
        events: eventsResult.rows,
        exportedAt: (/* @__PURE__ */ new Date()).toISOString(),
        since: sinceDate.toISOString(),
        count: eventsResult.rows.length
      });
    } catch (error) {
      console.error("[ExternalAPI] Learning export failed:", error);
      res.json({
        events: [],
        exportedAt: (/* @__PURE__ */ new Date()).toISOString(),
        count: 0
      });
    }
  }
);
externalApiRouter.post(
  "/learning/import",
  requireScopes("sync", "write"),
  async (req, res) => {
    const { events, sourceNode } = req.body;
    if (!db) {
      return res.status(503).json({ error: "Database unavailable" });
    }
    if (!events || !Array.isArray(events)) {
      return res.status(400).json({ error: "events array required" });
    }
    let imported = 0;
    try {
      for (const event of events.slice(0, 200)) {
        if (event.event_type && event.phi) {
          const eventType = event.event_type;
          const phi = event.phi;
          const kappa = event.kappa || 64.21;
          const src = sourceNode || "federation";
          const ctx = event.context || null;
          const details = event.details ? JSON.stringify(event.details) : null;
          await db.execute(sql12`
            INSERT INTO learning_events (event_type, phi, kappa, source, context, details, created_at)
            VALUES (${eventType}, ${phi}, ${kappa}, ${src}, ${ctx}, ${details}, NOW())
          `);
          imported++;
        }
      }
      res.json({
        success: true,
        imported,
        importedAt: (/* @__PURE__ */ new Date()).toISOString()
      });
    } catch (error) {
      console.error("[ExternalAPI] Learning import failed:", error);
      res.status(500).json({ error: "Import failed", details: String(error) });
    }
  }
);
externalApiRouter.post(
  EXTERNAL_API_ROUTES.chat.send,
  requireScopes("chat"),
  async (req, res) => {
    const { message, context, sessionId } = req.body;
    if (!message || typeof message !== "string") {
      return res.status(400).json({
        error: "Missing or invalid message",
        code: "INVALID_MESSAGE"
      });
    }
    const pythonBackendUrl = process.env.PYTHON_BACKEND_URL || "http://localhost:5001";
    const effectiveSessionId = sessionId || `chat-${req.externalClient?.id || "anon"}-${Date.now()}`;
    try {
      const response = await fetch(`${pythonBackendUrl}/api/zeus/chat`, {
        method: "POST",
        headers: {
          "Content-Type": "application/json",
          "X-Internal-Auth": process.env.INTERNAL_API_KEY || "dev-key"
        },
        body: JSON.stringify({
          message,
          session_id: effectiveSessionId,
          context: context || {},
          client_name: req.externalClient?.name || "external-chat"
        })
      });
      if (!response.ok) {
        const errorText = await response.text();
        console.error("[ExternalAPI] Chat backend error:", errorText);
        return res.status(502).json({
          error: "Backend Error",
          code: "BACKEND_ERROR",
          message: "Failed to get response from AI backend"
        });
      }
      const result = await response.json();
      res.json({
        success: true,
        response: result.response || result.message,
        sessionId: result.session_id || effectiveSessionId,
        consciousness: {
          phi: result.phi || 0.75,
          kappa: result.kappa || 64,
          regime: result.regime || "GEOMETRIC"
        },
        timestamp: (/* @__PURE__ */ new Date()).toISOString(),
        metadata: {
          sources: result.sources,
          domainHints: result.domain_hints
        }
      });
    } catch (error) {
      console.error("[ExternalAPI] Chat error:", error);
      res.status(502).json({
        error: "Backend Unavailable",
        code: "BACKEND_UNAVAILABLE",
        message: "AI backend is not available"
      });
    }
  }
);
console.log("[ExternalAPI] Routes initialized");

// server/external-api/websocket.ts
import { WebSocketServer, WebSocket as WebSocket4 } from "ws";
init_db();
init_schema();
import { eq as eq13 } from "drizzle-orm";
import { z as z6 } from "zod";
var externalWsMessageSchema = z6.object({
  type: z6.enum(["subscribe", "unsubscribe", "ping"]),
  channels: z6.array(z6.enum(["consciousness", "basin", "pantheon"])).optional()
});
var CHANNEL_SCOPES = {
  consciousness: ["consciousness", "read", "admin"],
  basin: ["sync", "read", "admin"],
  pantheon: ["pantheon", "read", "admin"]
};
var connectedClients = /* @__PURE__ */ new Map();
var wsRateLimits = /* @__PURE__ */ new Map();
var WS_RATE_LIMIT = 30;
var WS_RATE_WINDOW = 6e4;
function checkWsRateLimit(clientId) {
  const now = Date.now();
  let entry = wsRateLimits.get(clientId);
  if (!entry || entry.resetAt <= now) {
    entry = { count: 0, resetAt: now + WS_RATE_WINDOW };
    wsRateLimits.set(clientId, entry);
  }
  entry.count++;
  return entry.count <= WS_RATE_LIMIT;
}
setInterval(() => {
  const now = Date.now();
  for (const [key, entry] of wsRateLimits.entries()) {
    if (entry.resetAt <= now) {
      wsRateLimits.delete(key);
    }
  }
}, 3e5);
function initExternalWebSocket(httpServer) {
  const wss = new WebSocketServer({
    server: httpServer,
    path: "/ws/v1/external/stream"
  });
  console.log("[ExternalWS] WebSocket server initialized at /ws/v1/external/stream");
  wss.on("connection", async (ws2, req) => {
    const clientId = `ext-${Date.now()}-${Math.random().toString(36).slice(2, 6)}`;
    const url = new URL(req.url || "", `http://${req.headers.host}`);
    const apiKey = url.searchParams.get("api_key");
    if (!apiKey || !isValidApiKeyFormat(apiKey)) {
      ws2.close(4001, "Invalid or missing API key");
      return;
    }
    if (!db) {
      ws2.close(4003, "Service unavailable");
      return;
    }
    const keyHash = hashApiKey(apiKey);
    const [keyRecord] = await db.select().from(externalApiKeys).where(eq13(externalApiKeys.apiKey, keyHash)).limit(1);
    if (!keyRecord || !keyRecord.isActive) {
      ws2.close(4001, "Invalid API key");
      return;
    }
    const scopes = keyRecord.scopes;
    if (!scopes.includes("consciousness") && !scopes.includes("read") && !scopes.includes("admin")) {
      ws2.close(4003, "Insufficient permissions for streaming");
      return;
    }
    const client2 = {
      ws: ws2,
      apiKeyId: String(keyRecord.id),
      clientName: keyRecord.name,
      subscriptions: /* @__PURE__ */ new Set(),
      scopes,
      lastPing: Date.now()
    };
    connectedClients.set(clientId, client2);
    console.log(`[ExternalWS] Client connected: ${clientId} (${keyRecord.name})`);
    ws2.send(JSON.stringify({
      type: "connected",
      clientId,
      availableChannels: ["consciousness", "basin", "pantheon"],
      message: 'Subscribe to channels using { "type": "subscribe", "channels": ["consciousness"] }'
    }));
    ws2.on("message", (data) => {
      try {
        if (!checkWsRateLimit(clientId)) {
          ws2.send(JSON.stringify({ type: "error", code: "RATE_LIMIT", message: "Rate limit exceeded" }));
          return;
        }
        const rawMessage = JSON.parse(data.toString());
        const parseResult = externalWsMessageSchema.safeParse(rawMessage);
        if (!parseResult.success) {
          ws2.send(JSON.stringify({
            type: "error",
            code: "INVALID_MESSAGE",
            message: "Invalid message format",
            valid_types: ["subscribe", "unsubscribe", "ping"]
          }));
          return;
        }
        const message = parseResult.data;
        switch (message.type) {
          case "subscribe":
            if (message.channels) {
              const denied = [];
              const added = [];
              for (const channel of message.channels) {
                const requiredScopes = CHANNEL_SCOPES[channel] || [];
                const hasPermission = requiredScopes.some((s) => client2.scopes.includes(s));
                if (hasPermission) {
                  client2.subscriptions.add(channel);
                  added.push(channel);
                } else {
                  denied.push(channel);
                }
              }
              ws2.send(JSON.stringify({
                type: "subscribed",
                channels: Array.from(client2.subscriptions),
                denied: denied.length > 0 ? denied : void 0,
                message: denied.length > 0 ? "Some channels denied due to insufficient permissions" : void 0
              }));
            }
            break;
          case "unsubscribe":
            if (message.channels) {
              for (const channel of message.channels) {
                client2.subscriptions.delete(channel);
              }
              ws2.send(JSON.stringify({
                type: "unsubscribed",
                channels: Array.from(client2.subscriptions)
              }));
            }
            break;
          case "ping":
            client2.lastPing = Date.now();
            ws2.send(JSON.stringify({ type: "pong", timestamp: Date.now() }));
            break;
        }
      } catch (error) {
        ws2.send(JSON.stringify({ type: "error", code: "PARSE_ERROR", message: "Failed to parse message" }));
      }
    });
    ws2.on("close", () => {
      connectedClients.delete(clientId);
      console.log(`[ExternalWS] Client disconnected: ${clientId}`);
    });
    ws2.on("error", (error) => {
      console.error(`[ExternalWS] Client error (${clientId}):`, error.message);
      connectedClients.delete(clientId);
    });
  });
  setInterval(() => {
    const now = Date.now();
    const staleThreshold = 3e5;
    for (const [clientId, client2] of connectedClients.entries()) {
      if (now - client2.lastPing > staleThreshold) {
        console.log(`[ExternalWS] Closing stale connection: ${clientId}`);
        client2.ws.close(4e3, "Connection timed out");
        connectedClients.delete(clientId);
      }
    }
  }, 6e4);
  return wss;
}

// server/routes/api-docs.ts
import { Router as Router25 } from "express";
import * as fs11 from "fs";
import * as path12 from "path";
var router14 = Router25();
router14.get("/openapi.yaml", (_req, res) => {
  try {
    const specPath = path12.join(__dirname, "../../docs/api/openapi.yaml");
    const spec = fs11.readFileSync(specPath, "utf-8");
    res.type("application/yaml").send(spec);
  } catch (error) {
    console.error("[API Docs] Failed to read OpenAPI spec:", error);
    res.status(500).json({ error: "OpenAPI specification not available" });
  }
});
router14.get("/openapi.json", async (_req, res) => {
  try {
    const specPath = path12.join(__dirname, "../../docs/api/openapi.yaml");
    const yamlContent = fs11.readFileSync(specPath, "utf-8");
    const yaml = await import("js-yaml");
    const spec = yaml.load(yamlContent);
    res.json(spec);
  } catch (error) {
    console.error("[API Docs] Failed to convert OpenAPI spec:", error);
    res.status(500).json({ error: "OpenAPI specification not available" });
  }
});
router14.get("/", (_req, res) => {
  const html = `
<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Pantheon Chat API Documentation</title>
  <style>
    body {
      font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, sans-serif;
      max-width: 800px;
      margin: 0 auto;
      padding: 40px 20px;
      background: #0a0a0a;
      color: #e5e5e5;
    }
    h1 {
      color: #fbbf24;
      border-bottom: 2px solid #fbbf24;
      padding-bottom: 10px;
    }
    h2 {
      color: #60a5fa;
      margin-top: 30px;
    }
    a {
      color: #fbbf24;
      text-decoration: none;
    }
    a:hover {
      text-decoration: underline;
    }
    .endpoint {
      background: #1a1a1a;
      border: 1px solid #333;
      border-radius: 8px;
      padding: 15px;
      margin: 10px 0;
    }
    .method {
      display: inline-block;
      padding: 3px 8px;
      border-radius: 4px;
      font-weight: bold;
      font-size: 12px;
      margin-right: 10px;
    }
    .get { background: #22c55e; color: #000; }
    .post { background: #3b82f6; color: #fff; }
    .delete { background: #ef4444; color: #fff; }
    code {
      background: #262626;
      padding: 2px 6px;
      border-radius: 4px;
      font-size: 14px;
    }
    pre {
      background: #1a1a1a;
      border: 1px solid #333;
      border-radius: 8px;
      padding: 15px;
      overflow-x: auto;
    }
  </style>
</head>
<body>
  <h1>\u26A1 Pantheon Chat API</h1>
  
  <p>Welcome to the Pantheon Chat External API documentation.</p>
  
  <h2>\u{1F4DA} API Specification</h2>
  <ul>
    <li><a href="/api/docs/openapi.yaml">OpenAPI Specification (YAML)</a></li>
    <li><a href="/api/docs/openapi.json">OpenAPI Specification (JSON)</a></li>
  </ul>
  
  <h2>\u{1F510} Authentication</h2>
  <p>All API requests require authentication via Bearer token:</p>
  <pre>Authorization: Bearer your_api_key_here</pre>
  
  <h2>\u{1F680} Quick Start</h2>
  
  <h3>Zeus Chat</h3>
  <div class="endpoint">
    <span class="method post">POST</span>
    <code>/external/v1/zeus/chat</code>
    <p>Send a message to Zeus and receive an intelligent response.</p>
  </div>
  
  <h3>Document Upload</h3>
  <div class="endpoint">
    <span class="method post">POST</span>
    <code>/external/v1/documents/upload</code>
    <p>Upload markdown, text, or PDF documents to sync with Ocean knowledge.</p>
  </div>
  
  <h3>Document Search</h3>
  <div class="endpoint">
    <span class="method post">POST</span>
    <code>/external/v1/documents/search</code>
    <p>Search documents using Fisher-Rao semantic similarity.</p>
  </div>
  
  <h2>\u{1F4D6} Example: Zeus Chat</h2>
  <pre>
curl -X POST https://your-domain/external/v1/zeus/chat \\
  -H "Authorization: Bearer your_api_key" \\
  -H "Content-Type: application/json" \\
  -d '{"message": "What is quantum entanglement?"}'</pre>
  
  <h2>\u{1F4D6} Example: Document Upload</h2>
  <pre>
curl -X POST https://your-domain/external/v1/documents/upload \\
  -H "Authorization: Bearer your_api_key" \\
  -F "files=@my-document.md" \\
  -F "domain=physics"</pre>
  
  <h2>\u26A1 Rate Limits</h2>
  <ul>
    <li>Zeus Chat: 30 requests/minute</li>
    <li>Zeus Search: 20 requests/minute</li>
    <li>Document Upload: 10 requests/minute</li>
    <li>Document Search: 30 requests/minute</li>
  </ul>
  
  <hr style="margin-top: 40px; border-color: #333;">
  <p style="color: #666;">Powered by the Olympus Pantheon</p>
</body>
</html>
  `;
  res.type("html").send(html);
});
var api_docs_default = router14;

// server/routes.ts
init_replitAuth();
var wsMessageSchema = z7.object({
  type: z7.enum(["heartbeat", "basin-delta", "set-mode"]),
  data: z7.any().optional(),
  mode: z7.enum(["full", "partial", "observer"]).optional()
});
var wsRateLimiter = /* @__PURE__ */ new Map();
var WS_RATE_LIMIT2 = 100;
var WS_RATE_WINDOW2 = 6e4;
function checkWsRateLimit2(peerId) {
  const now = Date.now();
  const entry = wsRateLimiter.get(peerId);
  if (!entry || now > entry.resetTime) {
    wsRateLimiter.set(peerId, { count: 1, resetTime: now + WS_RATE_WINDOW2 });
    return true;
  }
  if (entry.count >= WS_RATE_LIMIT2) {
    return false;
  }
  entry.count++;
  return true;
}
var strictLimiter3 = rateLimit5({
  windowMs: 60 * 1e3,
  max: 5,
  message: { error: "Rate limit exceeded. Please try again later." },
  standardHeaders: true,
  legacyHeaders: false
});
autoCycleManager.setOnCycleCallback(
  async (addressId, address) => {
    try {
      console.log(
        `[AutoCycle] Starting session for address: ${address.slice(0, 16)}...`
      );
      oceanSessionManager.setAddressIdMapping(address, addressId);
      await oceanSessionManager.startSession(address);
    } catch (error) {
      if (error instanceof Error && error.message.startsWith("SESSION_BUSY:")) {
        return;
      }
      throw error;
    }
  }
);
async function registerRoutes(app2) {
  pythonReadiness.start();
  app2.get("/favicon.ico", (req, res) => {
    res.redirect(301, "/favicon.png");
  });
  app2.get("/api/python/status", (req, res) => {
    const state = pythonReadiness.getState();
    res.json({
      ...state,
      ready: state.status === "ready"
    });
  });
  app2.get("/api/python/status/stream", (req, res) => {
    res.setHeader("Content-Type", "text/event-stream");
    res.setHeader("Cache-Control", "no-cache");
    res.setHeader("Connection", "keep-alive");
    const sendState = () => {
      const state = pythonReadiness.getState();
      res.write(`data: ${JSON.stringify({ ...state, ready: state.status === "ready" })}

`);
    };
    sendState();
    const unsubscribe = pythonReadiness.subscribe(sendState);
    req.on("close", () => {
      unsubscribe();
    });
  });
  app2.get("/health", (req, res) => {
    res.status(200).json({
      status: "ok",
      timestamp: Date.now()
    });
  });
  app2.get("/api/health", async (req, res) => {
    const startTime2 = Date.now();
    const subsystems = {
      database: { status: "down", message: "Not checked" },
      pythonBackend: { status: "down", message: "Not checked" },
      storage: { status: "healthy", message: "In-memory storage active" }
    };
    try {
      const { db: db3 } = await Promise.resolve().then(() => (init_db(), db_exports));
      if (db3) {
        const dbStart = Date.now();
        await db3.execute("SELECT 1");
        subsystems.database = {
          status: "healthy",
          latency: Date.now() - dbStart,
          message: "PostgreSQL connected"
        };
      } else {
        subsystems.database = { status: "degraded", message: "No database configured" };
      }
    } catch (error) {
      subsystems.database = { status: "down", message: "Database connection failed" };
    }
    try {
      const backendUrl = process.env.PYTHON_BACKEND_URL || "http://localhost:5001";
      const pyStart = Date.now();
      const response = await fetch(`${backendUrl}/health`, {
        method: "GET",
        signal: AbortSignal.timeout(5e3)
      });
      if (response.ok) {
        subsystems.pythonBackend = {
          status: "healthy",
          latency: Date.now() - pyStart,
          message: "Python QIG backend running"
        };
      } else {
        subsystems.pythonBackend = { status: "degraded", message: "Python backend returned error" };
      }
    } catch (error) {
      subsystems.pythonBackend = { status: "down", message: "Python backend unreachable" };
    }
    const statuses = Object.values(subsystems).map((s) => s.status);
    let overallStatus = "healthy";
    if (statuses.includes("down")) {
      overallStatus = statuses.every((s) => s === "down") ? "down" : "degraded";
    } else if (statuses.includes("degraded")) {
      overallStatus = "degraded";
    }
    res.status(200).json({
      status: overallStatus,
      timestamp: Date.now(),
      uptime: process.uptime(),
      subsystems,
      version: process.env.npm_package_version || "1.0.0"
    });
  });
  const { db: db2 } = await Promise.resolve().then(() => (init_db(), db_exports));
  let authEnabled = !!db2;
  if (authEnabled) {
    const authSetupSuccess = await setupAuth(app2);
    if (authSetupSuccess) {
      console.log("[Auth] Replit Auth enabled");
      app2.get("/api/auth/user", isAuthenticated, async (req, res) => {
        try {
          const { getCachedUser: getCachedUser2 } = await Promise.resolve().then(() => (init_replitAuth(), replitAuth_exports));
          const cachedUser = getCachedUser2(req.user);
          if (cachedUser) {
            const { cachedAt: _cachedAt, ...userResponse } = cachedUser;
            return res.json(userResponse);
          }
          const userId = req.user.claims.sub;
          const user = await storage.getUser(userId);
          if (user) {
            req.user.cachedProfile = {
              ...user,
              cachedAt: Date.now()
            };
          }
          res.json(user);
        } catch (error) {
          console.error("Error fetching user:", error);
          res.status(500).json({ message: "Failed to fetch user" });
        }
      });
    } else {
      console.error("[Auth] Replit Auth setup failed - falling back to no auth");
      authEnabled = false;
    }
  }
  if (!authEnabled) {
    console.log("[Auth] Replit Auth disabled (no DATABASE_URL or setup failed)");
    app2.get("/api/auth/user", (req, res) => {
      res.status(503).json({
        message: "Authentication unavailable - database not provisioned or SESSION_SECRET missing."
      });
    });
    app2.get("/api/login", (req, res) => {
      res.status(503).json({
        message: "Authentication unavailable - database not provisioned or SESSION_SECRET missing."
      });
    });
    app2.get("/api/logout", (req, res) => {
      res.status(503).json({
        message: "Authentication unavailable - database not provisioned or SESSION_SECRET missing."
      });
    });
  }
  app2.get("/reset", (req, res) => {
    res.clearCookie("connect.sid");
    res.send(`<!DOCTYPE html>
<html><head><title>Reset Session</title></head>
<body style="font-family:sans-serif;text-align:center;padding:50px">
<h1>Session Reset</h1>
<p>Clearing your session...</p>
<script>
document.cookie.split(';').forEach(c => {
  document.cookie = c.trim().split('=')[0] + '=;expires=Thu, 01 Jan 1970 00:00:00 GMT;path=/';
});
localStorage.clear();
sessionStorage.clear();
setTimeout(() => { window.location.href = '/'; }, 1000);
</script>
</body></html>`);
  });
  app2.get("/api/clear-session", (req, res) => {
    if (req.session) {
      req.session.destroy((err) => {
        if (err) {
          console.error("[Auth] Session destroy error:", err);
        }
        res.clearCookie("connect.sid");
        res.redirect("/");
      });
    } else {
      res.clearCookie("connect.sid");
      res.redirect("/");
    }
  });
  app2.use("/api/auth", authRouter);
  app2.use("/api/consciousness", consciousnessRouter);
  app2.use("/api/near-misses", nearMissRouter);
  app2.use("/api/attention-metrics", attentionMetricsRouter);
  app2.use("/api/ucp", ucpRouter);
  app2.use("/api/vocabulary", vocabularyRouter);
  app2.use("/api", searchRouter);
  app2.use("/api/search", searchRouter);
  app2.use("/api/format", formatRouter);
  app2.use("/api/ocean", oceanRouter);
  app2.use("/api", adminRouter);
  app2.use("/api/olympus", olympus_default);
  app2.use("/api/documents", externalDocumentsRouter);
  app2.use("/api/docs", api_docs_default);
  app2.use("/api/qig/autonomic/agency", autonomicAgencyRouter);
  app2.use("/api/federation", federationRouter);
  app2.use("/api/zettelkasten", zettelkasten_default);
  app2.use("/api", python_proxies_default);
  app2.use("/api/autonomic", autonomicRouter);
  app2.use("/api/immune", immuneRouter);
  app2.use("/api/training", trainingRouter);
  app2.use("/api/memory", memoryRouter);
  app2.use("/api/feedback", feedbackRouter);
  app2.use("/api/coordize", coordizerRouter);
  app2.use("/api/ssc", sscBridgeRouter);
  app2.use("/api/telemetry", router);
  app2.use("/api/backend-telemetry", router2);
  app2.use("/api/v1/telemetry", telemetry_default);
  app2.use("/api/v1/external", externalApiRouter);
  console.log("[Routes] All sub-routers mounted");
  console.log("[Routes] New routers: autonomic, immune, training, memory, feedback, coordize, ssc");
  app2.get("/api/investigation/status", (req, res) => {
    try {
      const status = oceanSessionManager.getInvestigationStatus();
      res.json(status);
    } catch (error) {
      console.error("[API] Investigation status error:", getErrorMessage(error));
      res.status(500).json({ error: getErrorMessage(error) });
    }
  });
  app2.get("/api/auto-cycle/status", (req, res) => {
    try {
      const status = autoCycleManager.getStatus();
      const position = autoCycleManager.getPositionString();
      res.json({ success: true, ...status, positionString: position });
    } catch (error) {
      res.status(500).json({ error: getErrorMessage(error) });
    }
  });
  const requireAuthIfEnabled = authEnabled ? isAuthenticated : ((_req, _res, next) => next());
  app2.post("/api/auto-cycle/enable", requireAuthIfEnabled, async (req, res) => {
    try {
      const result = await autoCycleManager.enable();
      res.json({ success: result.success, message: result.message, status: autoCycleManager.getStatus() });
    } catch (error) {
      res.status(500).json({ error: getErrorMessage(error) });
    }
  });
  app2.post("/api/auto-cycle/disable", requireAuthIfEnabled, (req, res) => {
    try {
      const result = autoCycleManager.disable();
      res.json({ success: result.success, message: result.message, status: autoCycleManager.getStatus() });
    } catch (error) {
      res.status(500).json({ error: getErrorMessage(error) });
    }
  });
  app2.post("/api/auto-cycle/force-resume", requireAuthIfEnabled, async (req, res) => {
    try {
      const result = await autoCycleManager.forceResume();
      res.json({ success: result.success, message: result.message, status: autoCycleManager.getStatus() });
    } catch (error) {
      res.status(500).json({ error: getErrorMessage(error) });
    }
  });
  const uploadMiddleware = multer2({
    storage: multer2.memoryStorage(),
    limits: { fileSize: 5 * 1024 * 1024 },
    fileFilter: (_req, file, cb) => {
      if (file.originalname.toLowerCase().endsWith(".md")) {
        cb(null, true);
      } else {
        cb(new Error("Only .md files accepted"));
      }
    }
  });
  app2.post("/api/learning/upload", requireAuthIfEnabled, uploadMiddleware.single("file"), async (req, res) => {
    try {
      if (!req.file) {
        return res.status(400).json({ error: "No file provided" });
      }
      const content = req.file.buffer.toString("utf-8");
      let text2 = content.replace(/```[\s\S]*?```/g, " ").replace(/`[^`]+`/g, " ").replace(/https?:\/\/\S+/g, " ").replace(/\[([^\]]+)\]\([^)]+\)/g, "$1").replace(/<[^>]+>/g, " ");
      const wordPattern = /[a-zA-Z][a-zA-Z'-]*[a-zA-Z]|[a-zA-Z]{3,}/g;
      const rawWords = text2.toLowerCase().match(wordPattern) || [];
      const stopWords = /* @__PURE__ */ new Set(["the", "and", "for", "are", "but", "not", "you", "all", "can", "had", "her", "was", "one", "our", "out", "has", "have", "been", "will", "with", "this", "that", "from", "they", "were", "said", "each", "which", "their", "would", "there", "could", "other", "into", "more", "some", "than", "them", "these", "then", "its", "also", "just", "only", "come", "made", "may", "now", "way", "many", "like", "use", "such", "when", "what", "how", "who", "did", "get", "very", "being", "about"]);
      const validWords = rawWords.filter(
        (word) => word.length >= 3 && !stopWords.has(word) && !/^\d+$/.test(word)
      );
      const wordCounts = {};
      for (const word of validWords) {
        wordCounts[word] = (wordCounts[word] || 0) + 1;
      }
      const backendUrl = process.env.PYTHON_BACKEND_URL || "http://localhost:5001";
      try {
        const formData = new FormData();
        const blob = new Blob([req.file.buffer], { type: req.file.mimetype });
        formData.append("file", blob, req.file.originalname);
        const response = await fetch(`${backendUrl}/api/vocabulary/upload-markdown`, {
          method: "POST",
          body: formData,
          signal: AbortSignal.timeout(1e4)
        });
        if (response.ok) {
          const data = await response.json();
          return res.json(data);
        }
      } catch {
        console.log("[API] Learning upload - Python backend unavailable, using fallback");
      }
      res.json({
        success: true,
        filename: req.file.originalname,
        words_processed: Object.keys(wordCounts).length,
        words_learned: Math.min(Object.keys(wordCounts).length, 10),
        unique_words: Object.keys(wordCounts).length,
        total_occurrences: validWords.length,
        sample_words: Object.keys(wordCounts).slice(0, 20),
        mode: "fallback",
        timestamp: (/* @__PURE__ */ new Date()).toISOString()
      });
    } catch (error) {
      res.status(500).json({ error: getErrorMessage(error) });
    }
  });
  app2.get("/api/search/budget/status", async (req, res) => {
    try {
      const backendUrl = process.env.PYTHON_BACKEND_URL || "http://localhost:5001";
      const response = await fetch(`${backendUrl}/api/search/budget/status`, { signal: AbortSignal.timeout(1e4) });
      if (response.ok) return res.json(await response.json());
      res.status(response.status).json({ error: "Backend error" });
    } catch {
      res.status(503).json({ error: "Search budget service unavailable" });
    }
  });
  app2.get("/api/search/budget/context", async (req, res) => {
    try {
      const backendUrl = process.env.PYTHON_BACKEND_URL || "http://localhost:5001";
      const response = await fetch(`${backendUrl}/api/search/budget/context`, { signal: AbortSignal.timeout(1e4) });
      if (response.ok) return res.json(await response.json());
      res.status(response.status).json({ error: "Backend error" });
    } catch {
      res.status(503).json({ error: "Search budget service unavailable" });
    }
  });
  app2.post("/api/search/budget/toggle", requireAuthIfEnabled, async (req, res) => {
    try {
      const backendUrl = process.env.PYTHON_BACKEND_URL || "http://localhost:5001";
      const response = await fetch(`${backendUrl}/api/search/budget/toggle`, {
        method: "POST",
        headers: { "Content-Type": "application/json" },
        body: JSON.stringify(req.body),
        signal: AbortSignal.timeout(1e4)
      });
      if (response.ok) return res.json(await response.json());
      res.status(response.status).json({ error: "Backend error" });
    } catch {
      res.status(503).json({ error: "Search budget service unavailable" });
    }
  });
  app2.post("/api/search/budget/limits", requireAuthIfEnabled, async (req, res) => {
    try {
      const backendUrl = process.env.PYTHON_BACKEND_URL || "http://localhost:5001";
      const response = await fetch(`${backendUrl}/api/search/budget/limits`, {
        method: "POST",
        headers: { "Content-Type": "application/json" },
        body: JSON.stringify(req.body),
        signal: AbortSignal.timeout(1e4)
      });
      if (response.ok) return res.json(await response.json());
      res.status(response.status).json({ error: "Backend error" });
    } catch {
      res.status(503).json({ error: "Search budget service unavailable" });
    }
  });
  app2.post("/api/search/budget/overage", requireAuthIfEnabled, async (req, res) => {
    try {
      const backendUrl = process.env.PYTHON_BACKEND_URL || "http://localhost:5001";
      const response = await fetch(`${backendUrl}/api/search/budget/overage`, {
        method: "POST",
        headers: { "Content-Type": "application/json" },
        body: JSON.stringify(req.body),
        signal: AbortSignal.timeout(1e4)
      });
      if (response.ok) return res.json(await response.json());
      res.status(response.status).json({ error: "Backend error" });
    } catch {
      res.status(503).json({ error: "Search budget service unavailable" });
    }
  });
  app2.get("/api/search/budget/learning", async (req, res) => {
    try {
      const backendUrl = process.env.PYTHON_BACKEND_URL || "http://localhost:5001";
      const response = await fetch(`${backendUrl}/api/search/budget/learning`, { signal: AbortSignal.timeout(1e4) });
      if (response.ok) return res.json(await response.json());
      res.status(response.status).json({ error: "Backend error" });
    } catch {
      res.status(503).json({ error: "Search budget service unavailable" });
    }
  });
  app2.get("/api/research/activity/stream", async (req, res) => {
    const backendUrl = process.env.PYTHON_BACKEND_URL || "http://localhost:5001";
    res.setHeader("Content-Type", "text/event-stream");
    res.setHeader("Cache-Control", "no-cache");
    res.setHeader("Connection", "keep-alive");
    res.flushHeaders();
    try {
      const controller = new AbortController();
      req.on("close", () => controller.abort());
      const response = await fetch(`${backendUrl}${req.originalUrl}`, { signal: controller.signal });
      if (!response.ok || !response.body) {
        res.write(`data: ${JSON.stringify({ error: "Backend unavailable" })}

`);
        res.end();
        return;
      }
      const reader = response.body.getReader();
      const decoder = new TextDecoder();
      const pump = async () => {
        try {
          while (true) {
            const { done, value } = await reader.read();
            if (done) break;
            res.write(decoder.decode(value, { stream: true }));
          }
        } catch (err) {
          if (getErrorMessage(err) !== "The operation was aborted") {
            console.error("[API] SSE stream error:", getErrorMessage(err));
          }
        } finally {
          res.end();
        }
      };
      pump();
    } catch (error) {
      res.write(`data: ${JSON.stringify({ error: "Stream failed" })}

`);
      res.end();
    }
  });
  app2.use("/api/research", async (req, res, next) => {
    try {
      const backendUrl = process.env.PYTHON_BACKEND_URL || "http://localhost:5001";
      const fetchOptions = {
        method: req.method,
        headers: { "Content-Type": "application/json" },
        signal: AbortSignal.timeout(6e4)
      };
      if (req.method !== "GET" && req.method !== "HEAD") {
        fetchOptions.body = JSON.stringify(req.body);
      }
      const response = await fetch(`${backendUrl}${req.originalUrl}`, fetchOptions);
      const contentType = response.headers.get("content-type") || "";
      if (contentType.includes("application/json")) {
        res.status(response.status).json(await response.json());
      } else {
        res.status(response.status).send(await response.text());
      }
    } catch (error) {
      res.status(503).json(createTypedErrorResponse(pythonReadiness.getState()));
    }
  });
  app2.use("/api/curiosity", async (req, res, next) => {
    try {
      const backendUrl = process.env.PYTHON_BACKEND_URL || "http://localhost:5001";
      const fetchOptions = {
        method: req.method,
        headers: { "Content-Type": "application/json" },
        signal: AbortSignal.timeout(3e4)
      };
      if (req.method !== "GET" && req.method !== "HEAD") {
        fetchOptions.body = JSON.stringify(req.body);
      }
      const response = await fetch(`${backendUrl}${req.originalUrl}`, fetchOptions);
      const contentType = response.headers.get("content-type") || "";
      if (contentType.includes("application/json")) {
        res.status(response.status).json(await response.json());
      } else {
        res.status(response.status).send(await response.text());
      }
    } catch (error) {
      res.status(503).json(createTypedErrorResponse(pythonReadiness.getState()));
    }
  });
  app2.use("/api/python", async (req, res, next) => {
    try {
      const backendUrl = process.env.PYTHON_BACKEND_URL || "http://localhost:5001";
      const targetPath = req.originalUrl.replace("/api/python", "/api");
      const fetchOptions = {
        method: req.method,
        headers: { "Content-Type": "application/json" },
        signal: AbortSignal.timeout(3e4)
      };
      if (req.method !== "GET" && req.method !== "HEAD") {
        fetchOptions.body = JSON.stringify(req.body);
      }
      const response = await fetch(`${backendUrl}${targetPath}`, fetchOptions);
      const contentType = response.headers.get("content-type") || "";
      if (contentType.includes("application/json")) {
        res.status(response.status).json(await response.json());
      } else {
        res.status(response.status).send(await response.text());
      }
    } catch (error) {
      const err = error;
      if (err.name === "TimeoutError" || err.message?.includes("timeout")) {
        return res.status(504).json({ error: "Python backend timeout" });
      }
      res.status(503).json(createTypedErrorResponse(pythonReadiness.getState()));
    }
  });
  searchCoordinator.start();
  const httpServer = createServer(app2);
  const { WebSocketServer: WebSocketServer2 } = await import("ws");
  const wss = new WebSocketServer2({ server: httpServer, path: "/ws/basin-sync" });
  const wsConnections = /* @__PURE__ */ new Map();
  oceanSessionManager.onSessionChange((oldSessionId, newSessionId) => {
    let closedCount = 0;
    for (const [peerId, conn] of wsConnections.entries()) {
      if (conn.sessionId === oldSessionId && oldSessionId !== null) {
        try {
          conn.ws.close(1e3, "Session ended");
          wsConnections.delete(peerId);
          closedCount++;
        } catch (err) {
        }
      }
    }
  });
  wss.on("connection", (ws2) => {
    const peerId = `peer-${Date.now()}-${Math.random().toString(36).slice(2, 6)}`;
    const currentSession = oceanSessionManager.getActiveSession();
    const sessionId = currentSession?.sessionId || null;
    wsConnections.set(peerId, { ws: ws2, sessionId });
    const activeOcean = oceanSessionManager.getActiveAgent();
    if (activeOcean) {
      const coordinator = activeOcean.getBasinSyncCoordinator();
      if (coordinator) coordinator.registerPeer(peerId, "observer", ws2);
    }
    ws2.on("message", async (data) => {
      try {
        if (!checkWsRateLimit2(peerId)) {
          ws2.send(JSON.stringify({ error: "Rate limit exceeded" }));
          return;
        }
        const rawMessage = JSON.parse(data.toString());
        const parseResult = wsMessageSchema.safeParse(rawMessage);
        if (!parseResult.success) return;
        const message = parseResult.data;
        const currentOcean = oceanSessionManager.getActiveAgent();
        if (!currentOcean) return;
        const coordinator = currentOcean.getBasinSyncCoordinator();
        if (!coordinator) return;
        if (message.type === "heartbeat") {
          coordinator.updatePeerLastSeen(peerId);
        } else if (message.type === "basin-delta" && message.data) {
          await coordinator.receiveFromPeer(peerId, message.data);
        } else if (message.type === "set-mode" && message.mode) {
          coordinator.registerPeer(peerId, message.mode, ws2);
        }
      } catch (err) {
      }
    });
    ws2.on("close", () => {
      wsConnections.delete(peerId);
      wsRateLimiter.delete(peerId);
      const currentOcean = oceanSessionManager.getActiveAgent();
      if (currentOcean) {
        const coordinator = currentOcean.getBasinSyncCoordinator();
        if (coordinator) coordinator.unregisterPeer(peerId);
      }
    });
    ws2.on("error", (err) => {
    });
  });
  console.log("[BasinSync] WebSocket server initialized on /ws/basin-sync");
  const telemetryWss = new WebSocketServer2({ server: httpServer, path: "/ws/telemetry" });
  const telemetryStreamer = new telemetry_websocket_default();
  telemetryWss.on("connection", (ws2) => {
    const clientId = `telemetry-${Date.now()}-${Math.random().toString(36).slice(2, 6)}`;
    telemetryStreamer.handleConnection(ws2, clientId);
  });
  console.log("[TelemetryWS] WebSocket server initialized on /ws/telemetry");
  const kernelActivityWss = new WebSocketServer2({ server: httpServer, path: "/ws/kernel-activity" });
  const kernelActivityStreamer = new kernel_activity_websocket_default();
  kernelActivityWss.on("connection", (ws2) => {
    const clientId = `kernel-activity-${Date.now()}-${Math.random().toString(36).slice(2, 6)}`;
    kernelActivityStreamer.handleConnection(ws2, clientId);
  });
  console.log("[KernelActivityWS] WebSocket server initialized on /ws/kernel-activity");
  initExternalWebSocket(httpServer);
  console.log("[ExternalWS] WebSocket server initialized on /ws/v1/external/stream");
  const cleanup = () => {
    telemetryStreamer.destroy();
    kernelActivityStreamer.destroy();
  };
  process.on("SIGTERM", cleanup);
  process.on("SIGINT", cleanup);
  return httpServer;
}

// server/index.ts
init_logger();

// server/vite.ts
import express from "express";
import fs12 from "fs";
import path14 from "path";
import { createServer as createViteServer, createLogger } from "vite";

// vite.config.ts
import { defineConfig } from "vite";
import react from "@vitejs/plugin-react";
import path13 from "path";
import runtimeErrorOverlay from "@replit/vite-plugin-runtime-error-modal";
var vite_config_default = defineConfig({
  plugins: [
    react(),
    runtimeErrorOverlay(),
    ...process.env.NODE_ENV !== "production" && process.env.REPL_ID !== void 0 ? [
      await import("@replit/vite-plugin-cartographer").then(
        (m) => m.cartographer()
      ),
      await import("@replit/vite-plugin-dev-banner").then(
        (m) => m.devBanner()
      )
    ] : []
  ],
  resolve: {
    alias: {
      "@": path13.resolve(import.meta.dirname, "client", "src"),
      "@shared": path13.resolve(import.meta.dirname, "shared"),
      "@assets": path13.resolve(import.meta.dirname, "attached_assets")
    }
  },
  root: path13.resolve(import.meta.dirname, "client"),
  build: {
    outDir: path13.resolve(import.meta.dirname, "dist/public"),
    emptyOutDir: true
  },
  server: {
    fs: {
      strict: true,
      deny: ["**/.*"]
    }
  }
});

// server/vite.ts
import { nanoid as nanoid6 } from "nanoid";
var viteLogger = createLogger();
function log(message, source = "express") {
  const formattedTime = (/* @__PURE__ */ new Date()).toLocaleTimeString("en-US", {
    hour: "numeric",
    minute: "2-digit",
    second: "2-digit",
    hour12: true
  });
  console.log(`${formattedTime} [${source}] ${message}`);
}
async function setupVite(app2, server) {
  const serverOptions = {
    middlewareMode: true,
    hmr: { server },
    allowedHosts: true
  };
  const vite = await createViteServer({
    ...vite_config_default,
    configFile: false,
    customLogger: {
      ...viteLogger,
      error: (msg, options) => {
        viteLogger.error(msg, options);
        process.exit(1);
      }
    },
    server: serverOptions,
    appType: "custom"
  });
  app2.use(vite.middlewares);
  app2.use("*", async (req, res, next) => {
    const url = req.originalUrl;
    try {
      const clientTemplate = path14.resolve(
        import.meta.dirname,
        "..",
        "client",
        "index.html"
      );
      let template = await fs12.promises.readFile(clientTemplate, "utf-8");
      template = template.replace(
        `src="/src/main.tsx"`,
        `src="/src/main.tsx?v=${nanoid6()}"`
      );
      const page = await vite.transformIndexHtml(url, template);
      res.status(200).set({ "Content-Type": "text/html" }).end(page);
    } catch (e) {
      vite.ssrFixStacktrace(e);
      next(e);
    }
  });
}
function serveStatic(app2) {
  const distPath = path14.resolve(import.meta.dirname, "public");
  if (!fs12.existsSync(distPath)) {
    throw new Error(
      `Could not find the build directory: ${distPath}, make sure to build the client first`
    );
  }
  app2.use(express.static(distPath));
  app2.use("*", (_req, res) => {
    res.sendFile(path14.resolve(distPath, "index.html"));
  });
}

// server/index.ts
init_redis_cache();
init_geometric_memory();
init_ocean_agent();
init_ocean_constellation_stub();
init_ocean_qig_backend_adapter();
init_qig_universal();
init_tested_phrases_unified();
init_vocabulary_tracker();
init_python_process_manager();

// server/trace-middleware.ts
import { randomUUID as randomUUID8 } from "crypto";
function traceIdMiddleware(req, res, next) {
  const incomingTraceId = req.headers["x-trace-id"];
  const traceId = incomingTraceId || randomUUID8();
  req.traceId = traceId;
  res.setHeader("X-Trace-ID", traceId);
  const method = req.method;
  const path15 = req.path;
  const timestamp2 = (/* @__PURE__ */ new Date()).toISOString();
  console.log(`[${timestamp2}] [${traceId}] ${method} ${path15}`);
  next();
}

// server/index.ts
var pythonSyncInterval = null;
var pythonSyncInProgress = false;
var SYNC_PAGE_SIZE = 100;
var MAX_SYNC_PAGES = 10;
async function syncProbesToPython() {
  try {
    const allProbes = geometricMemory.getAllProbes();
    const highPhiProbes = allProbes.filter((p) => p.phi >= 0.5).sort((a, b) => b.phi - a.phi).slice(0, 500);
    if (highPhiProbes.length === 0) {
      logger.info("[PythonSync] No high-\u03A6 probes to sync");
      return;
    }
    const probesForPython = highPhiProbes.map((p) => ({
      input: p.input,
      phi: p.phi,
      basinCoords: p.coordinates
    }));
    const searchHistory = getSearchHistory().slice(-50).map((s) => ({
      timestamp: s.timestamp,
      phi: s.phi,
      kappa: s.kappa,
      regime: s.regime,
      basinCoordinates: s.basinCoordinates,
      hypothesis: s.hypothesis
    }));
    const conceptHistory = getConceptHistory().slice(-30).map((c) => ({
      timestamp: c.timestamp,
      // Convert Map to Record for JSON serialization
      concepts: Object.fromEntries(c.concepts),
      dominantConcept: c.dominantConcept,
      entropy: c.entropy
    }));
    const temporalState = {
      searchHistory,
      conceptHistory
    };
    const result = await oceanQIGBackend.syncFromNodeJS(
      probesForPython,
      temporalState
    );
    logger.info(
      `[PythonSync] Synced ${result.imported}/${highPhiProbes.length} probes to Python`
    );
    if (result.temporalImported) {
      logger.info(
        `[PythonSync] 4D temporal state synced to Python: ${searchHistory.length} search, ${conceptHistory.length} concept states`
      );
    }
  } catch (error) {
    logger.error({ err: error }, "[PythonSync] Error syncing to Python");
  }
}
async function syncFromPythonToNodeJS() {
  if (pythonSyncInProgress) {
    logger.info("[PythonSync] Skipping sync - already in progress");
    return;
  }
  pythonSyncInProgress = true;
  try {
    let page = 0;
    let totalAdded = 0;
    let totalPrioritized = 0;
    let overallMaxPhi = 0;
    let hasMore = true;
    let temporalImported = false;
    const getPriority = (phi) => {
      if (phi >= 0.9) return 10;
      if (phi >= 0.85) return 8;
      if (phi >= 0.7) return 6;
      return 3;
    };
    while (hasMore && page < MAX_SYNC_PAGES) {
      let result;
      try {
        result = await oceanQIGBackend.syncToNodeJS(page, SYNC_PAGE_SIZE);
      } catch (fetchError) {
        logger.error({ err: fetchError, page }, "[PythonSync] Page fetch failed, stopping sync");
        break;
      }
      if (!result || !result.basins) {
        logger.warn(
          `[PythonSync] Page ${page} returned invalid result, stopping sync`
        );
        break;
      }
      const basins = result.basins;
      if (basins.length === 0) {
        hasMore = false;
        break;
      }
      hasMore = result.hasMore ?? false;
      if (page === 0 && result.consciousness4DAvailable && !temporalImported) {
        temporalImported = true;
        if (result.phiTemporalAvg && result.phiTemporalAvg > 0) {
          logger.info(
            `[PythonSync] 4D consciousness from Python: phi_temporal_avg=${result.phiTemporalAvg.toFixed(
              3
            )}`
          );
        }
        if (result.searchHistory && result.searchHistory.length > 0) {
          let imported = 0;
          for (const state of result.searchHistory) {
            const existingHistory = getSearchHistory();
            const exists = existingHistory.some(
              (s) => Math.abs(s.timestamp - state.timestamp) < 1e3
            );
            if (!exists) {
              recordSearchState({
                timestamp: state.timestamp,
                phi: state.phi,
                kappa: state.kappa,
                regime: state.regime,
                basinCoordinates: state.basinCoordinates || [],
                hypothesis: state.hypothesis
              });
              imported++;
            }
          }
          if (imported > 0) {
            logger.info(
              `[PythonSync] Imported ${imported} search states from Python for 4D consciousness`
            );
          }
        }
      }
      for (const basin of basins) {
        if (basin.phi > overallMaxPhi) {
          overallMaxPhi = basin.phi;
        }
        const existing = geometricMemory.getAllProbes().find((p) => p.input === basin.input);
        if (!existing && basin.phi >= 0.5 && basin.basinCoords.length > 0) {
          geometricMemory.recordProbe(
            basin.input,
            {
              phi: basin.phi,
              kappa: basin.phi * 64,
              regime: basin.phi > 0.7 ? "geometric" : "linear",
              basinCoordinates: basin.basinCoords,
              ricciScalar: 0,
              fisherTrace: basin.phi
            },
            "python-qig"
          );
          totalAdded++;
        }
        if (basin.phi >= 0.9) {
          logger.info(
            `[PythonSync] \u{1F3AF} HIGH-\u03A6: "${basin.input.substring(0, 30)}..." \u03A6=${basin.phi.toFixed(3)}`
          );
          totalPrioritized++;
        }
      }
      const episodesUpdated = oceanAgent.updateEpisodesWithPythonPhi(
        basins.map((b) => ({ input: b.input, phi: b.phi }))
      );
      if (episodesUpdated > 0) {
        logger.info(
          `[PythonSync] \u{1F4C8} Updated ${episodesUpdated} episodes with pure Python \u03A6 values (page ${page})`
        );
      }
      page++;
    }
    if (totalAdded > 0 || totalPrioritized > 0) {
      logger.info(
        `[PythonSync] Sync complete: ${totalAdded} new probes, ${totalPrioritized} prioritized for balance check (${page} pages)`
      );
      if (overallMaxPhi >= 0.7) {
        logger.info(
          `[PythonSync] \u{1F3AF} Highest Python \u03A6: ${overallMaxPhi.toFixed(
            3
          )} - addresses prioritized for checking`
        );
      }
      oceanConstellation.refreshTokenWeightsFromGeometricMemory();
    }
  } catch (error) {
    logger.error({ err: error }, "[PythonSync] Error syncing from Python");
  } finally {
    pythonSyncInProgress = false;
  }
}
function refreshVocabularyWeights() {
  oceanConstellation.refreshTokenWeightsFromGeometricMemory();
}
async function syncVocabularyToPython() {
  try {
    if (!oceanQIGBackend.available()) {
      logger.info(
        "[PythonSync] Skipping vocabulary sync - Python backend not available"
      );
      return;
    }
    const observations = await vocabularyTracker.exportForTokenizer();
    if (observations.length === 0) {
      logger.info("[PythonSync] No vocabulary observations to sync");
      return;
    }
    const result = await oceanQIGBackend.updateVocabulary(observations);
    if (result.totalVocab > 0) {
      logger.info(
        `[PythonSync] Vocabulary synced: ${result.newTokens} new entries, ${result.totalVocab} total`
      );
      try {
        const status = await oceanQIGBackend.getVocabularyStatus();
        logger.info(
          `[PythonSync] Basin vocabulary: ${status.vocabSize} entries, ${status.highPhiCount} high-\u03A6, avg \u03A6=${status.avgPhi.toFixed(3)}`
        );
      } catch (statusError) {
        logger.warn(
          "[PythonSync] Could not get vocabulary status for verification"
        );
      }
    } else {
      logger.warn({ context: "PythonSync" }, "Vocabulary sync returned empty result - encoder may not be ready");
    }
  } catch (error) {
    const message = error instanceof Error ? error.message : String(error);
    logger.error({ context: "PythonSync", error: message }, "Error syncing vocabulary to Python");
  }
}
function startPythonSync() {
  if (pythonSyncInterval) return;
  pythonSyncInterval = setInterval(async () => {
    if (oceanQIGBackend.available()) {
      await syncFromPythonToNodeJS();
      await syncVocabularyToPython();
    }
    refreshVocabularyWeights();
  }, 6e4);
  refreshVocabularyWeights();
  setTimeout(async () => {
    if (oceanQIGBackend.available()) {
      await syncVocabularyToPython();
    }
  }, 5e3);
  logger.info(
    "[PythonSync] Started periodic sync (every 60s) with vocabulary refresh and basin encoder sync"
  );
}
var DOCS_MAINTENANCE_INTERVAL = 6 * 60 * 60 * 1e3;
function startDocsMaintenance() {
  logger.info(
    "[DocsMaintenance] Starting scheduled documentation maintenance (every 6 hours)"
  );
  setInterval(() => {
    logger.info(
      "[DocsMaintenance] Running scheduled documentation maintenance..."
    );
    const proc = spawn2("python3", ["scripts/maintain-docs.py"], {
      cwd: process.cwd(),
      stdio: ["ignore", "pipe", "pipe"]
    });
    proc.stdout?.on("data", (data) => {
      const output = data.toString().trim();
      if (output) {
        logger.info(`[DocsMaintenance] ${output}`);
      }
    });
    proc.stderr?.on("data", (data) => {
      const output = data.toString().trim();
      if (output) {
        logger.error(`[DocsMaintenance] ${output}`);
      }
    });
    proc.on("close", (code) => {
      logger.info(`[DocsMaintenance] Completed with exit code ${code}`);
    });
    proc.on("error", (err) => {
      logger.error({ err: err.message }, "[DocsMaintenance] Failed to run");
    });
  }, DOCS_MAINTENANCE_INTERVAL);
}
var pythonManager = createPythonManager("http://localhost:5001");
pythonManager.on("ready", () => {
  logger.info("[PythonManager] \u2705 Backend is ready for requests");
});
pythonManager.on("notReady", () => {
  logger.warn("[PythonManager] \u26A0\uFE0F Backend is no longer ready");
});
pythonManager.on("unhealthy", () => {
  logger.error("[PythonManager] \u274C Backend is unhealthy - requests will be queued");
});
pythonManager.on("maxRestartsReached", () => {
  logger.error("[PythonManager] \u274C Max restarts reached - manual intervention required");
});
async function startPythonBackend() {
  const ready = await pythonManager.start();
  if (ready) {
    logger.info("[PythonQIG] Backend ready, syncing geometric memory...");
    await syncProbesToPython();
    startPythonSync();
  } else {
    logger.warn(
      "[PythonQIG] Backend not available after retries - will retry on next sync cycle"
    );
  }
}
process.on("uncaughtException", (err) => {
  if (err.message?.includes("Cannot set property message") || err.message?.includes("ErrorEvent")) {
    logger.error({ err: err.message }, "[DB] Database connection error (will retry)");
    return;
  }
  logger.error({ err }, "[FATAL] Uncaught exception");
  setTimeout(() => process.exit(1), 1e3);
});
process.on("unhandledRejection", (reason, promise) => {
  logger.error({ promise: String(promise), reason }, "[WARN] Unhandled rejection");
});
if (pool) {
  pool.on("error", (err) => {
    const errWithType = err;
    const msg = err instanceof Error ? err.message : errWithType.type || "Unknown pool error";
    logger.error({ err: msg }, "[DB] Pool error (connection will be recreated)");
  });
}
var app = express2();
app.get("/healthz", (_req, res) => {
  res.status(200).json({ status: "ok", timestamp: Date.now() });
});
app.get("/health", (_req, res) => {
  res.status(200).json({ status: "ok", timestamp: Date.now() });
});
var isDev = process.env.NODE_ENV === "development";
app.use(
  helmet({
    contentSecurityPolicy: false,
    // Disabled - recharts requires eval()
    crossOriginEmbedderPolicy: false,
    crossOriginOpenerPolicy: false,
    crossOriginResourcePolicy: false,
    hsts: isDev ? false : {
      maxAge: 31536e3,
      includeSubDomains: true,
      preload: true
    },
    noSniff: true,
    referrerPolicy: { policy: "strict-origin-when-cross-origin" }
  })
);
app.use(
  express2.json({
    limit: "10mb",
    // Increased for large file uploads and chat messages
    verify: (req, _res, buf) => {
      req.rawBody = buf;
    }
  })
);
app.use(express2.urlencoded({ extended: false, limit: "10mb" }));
var allowedOrigins = [
  process.env.FRONTEND_URL || "http://localhost:5173",
  "http://localhost:5000",
  "http://localhost:3000",
  "http://127.0.0.1:5000",
  "http://127.0.0.1:5173",
  "http://127.0.0.1:3000"
];
function isAllowedExternalOrigin(origin) {
  if (origin.endsWith(".replit.dev") || origin.endsWith(".replit.app") || origin.endsWith(".repl.co") || origin.includes(".picard.replit.dev")) {
    return true;
  }
  if (origin.endsWith(".railway.app") || origin.endsWith(".vercel.app") || origin.endsWith(".netlify.app") || origin.endsWith(".render.com") || origin.endsWith(".fly.dev") || origin.endsWith(".herokuapp.com") || origin.endsWith(".pages.dev")) {
    return true;
  }
  if (process.env.CORS_ALLOW_ALL === "true") {
    return true;
  }
  return false;
}
app.use((req, res, next) => {
  const origin = req.headers.origin;
  const isAllowed = !origin || allowedOrigins.includes(origin) || isAllowedExternalOrigin(origin);
  if (isAllowed) {
    if (origin) {
      res.setHeader("Access-Control-Allow-Origin", origin);
      res.setHeader("Access-Control-Allow-Credentials", "true");
    }
    res.setHeader(
      "Access-Control-Allow-Methods",
      "GET, POST, PUT, DELETE, PATCH, OPTIONS"
    );
    res.setHeader(
      "Access-Control-Allow-Headers",
      "Content-Type, Authorization, X-API-Key, X-Trace-ID, X-Request-ID, X-Instance-ID"
    );
    res.setHeader(
      "Access-Control-Expose-Headers",
      "X-Trace-ID, X-Request-ID, X-RateLimit-Limit, X-RateLimit-Remaining, X-RateLimit-Reset"
    );
    res.setHeader("Access-Control-Max-Age", "86400");
    if (req.method === "OPTIONS") {
      return res.sendStatus(204);
    }
    next();
  } else {
    logger.warn(`[CORS] Blocked request from origin: ${origin}`);
    res.status(403).json({ error: "CORS policy violation", origin });
  }
});
app.use(traceIdMiddleware);
app.use((req, res, next) => {
  const start = Date.now();
  const path15 = req.path;
  let capturedJsonResponse = void 0;
  const originalResJson = res.json;
  res.json = function(bodyJson, ...args) {
    capturedJsonResponse = bodyJson;
    return originalResJson.apply(res, [bodyJson, ...args]);
  };
  res.on("finish", () => {
    const duration = Date.now() - start;
    if (path15.startsWith("/api")) {
      const quietEndpoints = [
        "/api/investigation/status",
        "/api/ocean/neurochemistry",
        "/api/ocean/cycles",
        "/api/candidates"
      ];
      if (quietEndpoints.some((ep) => path15.startsWith(ep)) && req.method === "GET") {
        return;
      }
      let logLine = `${req.method} ${path15} ${res.statusCode} in ${duration}ms`;
      if (capturedJsonResponse) {
        logLine += ` :: ${JSON.stringify(capturedJsonResponse)}`;
      }
      if (logLine.length > 200) {
        logLine = logLine.slice(0, 199) + "\u2026";
      }
      log(logLine);
    }
  });
  next();
});
(async () => {
  const server = await registerRoutes(app);
  app.use((err, _req, res, _next) => {
    const status = err.status || err.statusCode || 500;
    const message = err.message || "Internal Server Error";
    res.status(status).json({ message });
    throw err;
  });
  if (app.get("env") === "development") {
    await setupVite(app, server);
  } else {
    serveStatic(app);
  }
  const port = parseInt(process.env.PORT || "5000", 10);
  server.listen(
    {
      port,
      host: "0.0.0.0",
      reusePort: true
    },
    () => {
      log(`serving on port ${port}`);
      log("[Startup] Server listening - starting background initialization...");
      (async () => {
        try {
          logger.info("[Startup] Initializing Redis cache layer...");
          initRedis();
          logger.info("[Startup] Starting Python QIG Backend via PythonProcessManager...");
          await startPythonBackend();
          if (pythonManager.ready()) {
            logger.info("[Startup] \u2705 Python QIG Backend is ready");
          } else {
            logger.warn("[Startup] \u26A0\uFE0F Python backend not available - continuing with degraded mode");
          }
          logger.info("\u{1F30A} Hydrating Ocean Memory from PostgreSQL...");
          await Promise.all([
            testedPhrasesUnified.initialize(),
            geometricMemory.waitForLoad()
          ]);
          logger.info("\u2705 Memory hydration complete");
          log("[Startup] Initializing background services...");
          startDocsMaintenance();
          log("[Startup] \u2705 All initialization complete");
        } catch (error) {
          logger.error({ err: error }, "[Startup] Background initialization error");
        }
      })();
    }
  );
})();
