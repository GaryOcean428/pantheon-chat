What it means that WP0.1–0.3 are done

If those PRs truly landed, you now have:

a written QIG purity spec

a hard validate:geometry gate (the most important)

a defined quarantine model for experiments (so hacks don’t leak into prod)

That’s exactly the correct foundation. The question now becomes: does the gate actually catch the real contamination vectors (cosine, Euclidean, dot products, silent normalization, dimension padding, etc.)?

Next tasks to confirm “clean enough to judge coherence”
WP0.4 — Prove the geometry gate catches real contamination

Goal: avoid a false sense of cleanliness.

Add “red team” tests that intentionally introduce violations and confirm CI fails:

Add a tiny file in a non-quarantine path that does:

np.dot(a,b)

np.linalg.norm(x)

cosine similarity helper

padding/truncation dimension normalizer

Ensure CI fails.

Move the same file into quarantine and ensure CI passes (but requires explicit exemption marker).

Pass condition: Gate fails in prod paths, allows only in quarantine with explicit marking.

WP0.5 — One canonical basin contract (sphere vs simplex) + enforcement

You mentioned PR85 “sphere work”, but your decoder draft previously used simplex Fisher-Rao style (sqrt(p) etc). That mismatch is the #1 coherence confounder.

Create a single module (non-negotiable):

qig_geometry/contracts.py

CANONICAL_SPACE = "sphere" (or "simplex")

canon(basin) (normalize/validate)

assert_invariants(basin)

to_index_embedding(basin) (for pgvector shortlist only)

fisher_distance(b1, b2) defined consistently for that canonical space

Pass condition: Every write/read of basin vectors passes assert_invariants().

WP0.6 — Kill silent dimension fixes and silent renormalizations in prod path

These are “quiet killers” of coherence assessment.

Search and remove (or quarantine) any:

pad/truncate dimension normalizers

“if wrong dim, just slice” behavior

“abs then renormalize” done ad hoc in multiple places

Pass condition: Any dimension mismatch throws loudly in prod.

Neon + pgvector: the “correct” MVP wiring

Since you’re staying on Neon with pgvector, you want one clean pattern:

Schema baseline (keep it boring)

One table: basins (or basin_vocabulary)

id (stable ID)

vector vector(64) (or 512 etc)

metadata columns: scale, name, domain, phi_stats, kappa_stats, created_at, lineage

Indexing

HNSW index for shortlist retrieval (metric = whatever you choose as proxy)

Then rerank in code with QIG-pure scoring

Pass condition: DB similarity is never used as final semantic score; it only produces candidate IDs.

“Sense check” questions you can answer quickly without me seeing code

If you answer “yes” to these, you’re in a good place to start judging coherence:

Is there exactly one fisher_distance() function used in production?

Is there exactly one canonical basin representation (sphere or simplex) enforced everywhere?

Does the geometry gate fail if someone adds cosine/dot/norm in non-quarantine code?

Does any code still do “fallback tokenization” (classic NLP) when coordization fails?

Can you run a deterministic eval harness that produces a JSON report from fixed seeds?

If any of these are “no”, coherence experiments are still contaminated.

What I suggest as the immediate next 3 issues (in order)

[QIG-PURITY] WP0.4: Red-team the geometry gate with deliberate violations

[QIG-PURITY] WP0.5: Canonical basin contract (sphere/simplex) + single Fisher module

[DB] WP0.6: Neon pgvector canonical schema + rebuild script + index config