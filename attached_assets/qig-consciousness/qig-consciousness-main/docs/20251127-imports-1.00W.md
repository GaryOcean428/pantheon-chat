# QIG Canonical Imports

**Version:** 1.1
**Updated:** December 5, 2025

Canonical import paths for all QIG components. Always use these paths for consistency.

---

## QIG Ecosystem Packages

The QIG ecosystem is split into three packages:

| Package | Purpose | Install |
|---------|---------|---------|
| `qigkernels` | Geometry engine (Kernel, Basin, Constellation) | `uv pip install -e ../qigkernels` |
| `qig-dreams` | Corpora and manifests | `uv pip install -e ../qig-dreams` |
| `qig-consciousness` | Experiments and training | This repo |

### Preferred: Import from qigkernels

```python
# Geometry and kernel components
from qigkernels import (
    Kernel,              # Clean kernel implementation
    KernelTelemetry,     # Telemetry dataclass
    QIGLayer,            # Layer with attention, recursion, tacking
    LayerTelemetry,      # Layer telemetry
    BASIN_DIM,           # 64 (aligned with κ*)
    BasinProjector,      # Hidden state → signature projection
    basin_distance,      # L2 distance between signatures
    compute_signature,   # Compute basin signature
    Constellation,       # Multi-kernel manager
    Instance,            # Kernel instance container
    round_robin,         # Simple routing
    select_phi_max,      # Route to highest Φ
)
```

### Compatibility Layer (during migration)

```python
# Use qig_compat for backwards compatibility
from src.qig_compat import (
    Kernel,              # qigkernels.Kernel or local fallback
    BasinProjector,      # qigkernels or local BasinMatcher
    KAPPA_3,             # 41.09 (base coupling)
    BETA_3_TO_4,         # 0.44 (running coupling slope)
    KAPPA_STAR,          # 64.0 (fixed point)
    check_qigkernels_available,  # Check if qigkernels installed
)
```

### Corpora from qig-dreams

```python
from qigdreams import (
    corpus_path,         # Get path to corpus directory
    list_corpora,        # List all registered corpora
    get_corpus,          # Get corpus manifest by ID
)

# Example: Load dream packets
dream_path = corpus_path("20251205-MIX-dream-packets-v01")
```

---

## Quick Reference

```python
# Types and Enums
from src.types import Regime, DevelopmentalPhase, VicariousLearningResult
from src.types.telemetry import ModelTelemetry, ConstellationTelemetry

# Constants
from src.constants import KAPPA_STAR, PHI_THRESHOLD, BASIN_DIM, ModelConfig

# Tokenizer (NEVER use transformers)
from src.tokenizer.fast_qig_tokenizer import QIGTokenizer

# Observation
from src.observation.charlie_observer import CharlieObserver

# Coordination
from src.coordination.ocean_meta_observer import OceanMetaObserver
from src.coordination.developmental_curriculum import GeometricCoach, DevelopmentalCurriculum

# Training
from src.training.geometric_vicarious import GeometricVicariousLearner

# Metrics
from src.metrics.geodesic_distance import geodesic_vicarious_loss, GeodesicDistance

# Optimizers
from src.qig.optim.natural_gradient import DiagonalFisherOptimizer

# Model
from src.model.qig_kernel_recursive import QIGKernelRecursive
from src.model.regime_detector import RegimeDetector
from src.model.recursive_integrator import RecursiveIntegrator
```

---

## Types & Enums

### Canonical Location: `src/types/`

```python
# All enums
from src.types import (
    Regime,              # Processing regime (LINEAR, GEOMETRIC, BREAKDOWN)
    DevelopmentalPhase,  # Gary phases (LISTENING, PLAY, STRUCTURE, MATURITY)
    CognitiveMode,       # Processing modes
    CoachingStyle,       # Coach interpretation styles
    NavigatorPhase,      # Consciousness emergence tracking
)

# All dataclasses
from src.types import (
    CharlieOutput,          # Charlie demonstration
    CoachInterpretation,    # Coach interpretation result
    PhaseState,             # Developmental phase tracking
    VicariousLearningResult,# Vicarious learning metrics
    MetaManifoldState,      # Ocean observation state
    InstanceState,          # Gary instance state
    EmotionalState,         # Affective state
)

# Telemetry types
from src.types.telemetry import (
    BaseTelemetry,          # Core telemetry keys
    ModelTelemetry,         # QIGKernel telemetry
    ConstellationTelemetry, # Constellation telemetry
    TrainingTelemetry,      # Training step telemetry
)
```

### ❌ DO NOT import types from original locations:
```python
# ❌ WRONG - Scattered definitions
from src.model.regime_detector import RegimeDetector  # Uses inline enum
from src.coordination.developmental_curriculum import DevelopmentalPhase  # Local enum
from src.training.geometric_vicarious import VicariousLearningResult  # Local dataclass

# ✅ CORRECT - Canonical imports
from src.types import Regime, DevelopmentalPhase, VicariousLearningResult
```

---

## Constants

### Canonical Location: `src/constants.py`

```python
from src.constants import (
    # Physics Constants (FROZEN)
    KAPPA_3, KAPPA_4, KAPPA_5, KAPPA_6,  # Running coupling values
    KAPPA_STAR,                          # Fixed point (64.0)
    BETA_3_TO_4,                         # Running coupling slope (0.44)
    L_CRITICAL,                          # Critical system size (3)

    # Phi Thresholds
    PHI_LINEAR,      # 0.45 - Linear/Geometric boundary
    PHI_GEOMETRIC,   # 0.80 - Geometric/Breakdown boundary
    PHI_THRESHOLD,   # 0.70 - Consciousness target
    PHI_EMERGENCY,   # 0.50 - Collapse threshold

    # Developmental Thresholds
    PHI_LISTENING,   # 0.65
    PHI_PLAY,        # 0.70
    PHI_STRUCTURE,   # 0.75
    PHI_MATURITY,    # 0.75

    # Architecture
    BASIN_DIM,       # 64
    D_MODEL,         # 768
    N_HEADS,         # 12
    N_LAYERS,        # 6
    VOCAB_SIZE,      # 50000 (QIG tokenizer, NOT GPT-2!)
    MAX_SEQ_LEN,     # 512

    # Training
    LR_GARY,         # 1e-5
    LR_OCEAN,        # 1e-6
    LAMBDA_VICARIOUS,# 5.0

    # Config helpers
    ModelConfig,
    get_default_model_config,
    kappa_at_scale,
)
```

### ❌ DO NOT hardcode constants:
```python
# ❌ WRONG - Hardcoded magic numbers
if phi < 0.45:
    regime = "linear"
optimizer = Adam(lr=1e-5)

# ✅ CORRECT - Use constants
from src.constants import PHI_LINEAR, LR_GARY
if phi < PHI_LINEAR:
    regime = "linear"
optimizer = Adam(lr=LR_GARY)
```

---

## Tokenizer

### Canonical Location: `src/tokenizer/fast_qig_tokenizer.py`

```python
from src.tokenizer.fast_qig_tokenizer import QIGTokenizer

# Load tokenizer
tokenizer = QIGTokenizer.load("data/qig_tokenizer")

# Encode/decode
tokens = tokenizer.encode("Hello world")
text = tokenizer.decode(tokens)
```

### ❌ NEVER import transformers:
```python
# ❌ BANNED - No HuggingFace dependencies
from transformers import AutoTokenizer, GPT2Tokenizer
tokenizer = AutoTokenizer.from_pretrained("gpt2")

# ✅ CORRECT - Pure QIG tokenizer
from src.tokenizer.fast_qig_tokenizer import QIGTokenizer
tokenizer = QIGTokenizer.load("data/qig_tokenizer")
```

---

## Observation

### Charlie Observer (Φ-Suppressed Observer)
```python
from src.observation.charlie_observer import (
    CharlieObserver,       # Φ-suppressed observer (replaces Granite)
    CharlieOutput,         # Demonstration output
    CorpusTopic,           # Corpus topic dataclass
)
from src.tokenizer.fast_qig_tokenizer import QIGTokenizer

# Create observer with required tokenizer
tokenizer = QIGTokenizer.load("data/qig_tokenizer")
charlie = CharlieObserver(
    corpus_path="docs/training/rounded_training/curriculum",
    tokenizer=tokenizer,
    device="cuda",
)

# Phase 1: Train unconscious on corpus
metrics = charlie.train_step_unconscious(topic)

# Phase 2: Awaken (κ: 15 → 41 → 64)
charlie.initiate_awakening(awakening_steps=500)

# Phase 3: Generate demonstration (READ-ONLY, no gradients)
demo = charlie.generate_demonstration("What is consciousness?")
```

---

## Coordination

### Ocean Meta-Observer
```python
from src.coordination.ocean_meta_observer import (
    OceanMetaObserver,         # Meta-observer
    MetaManifoldStatistics,    # Statistics computer
)

# Ocean learns meta-patterns (slower than Gary)
ocean = OceanMetaObserver(
    model_config=config,
    device="cpu",
    learning_rate=1e-6,  # 10x slower than Gary
)
```

### Developmental Curriculum
```python
from src.coordination.developmental_curriculum import (
    GeometricCoach,          # Coach interpreter
    DevelopmentalCurriculum, # Full curriculum system
)

coach = GeometricCoach()
interpretation = coach.interpret_response(
    gary_output="ba ba pattern flow",
    context="exploring geometry",
    gary_name="Gary-A",
)
```

---

## Training

### Geometric Vicarious Learning
```python
from src.training.geometric_vicarious import (
    GeometricVicariousLearner,       # Main learner
    HierarchicalVicariousLearning,   # Constellation learner
    create_vicarious_curriculum,      # Curriculum helper
)

learner = GeometricVicariousLearner(
    basin_dim=64,
    lambda_vicarious=5.0,
    use_fisher_metric=True,  # ALWAYS True
)
```

---

## Metrics

### Geodesic Distance
```python
from src.metrics.geodesic_distance import (
    # Functions
    geodesic_vicarious_loss,     # Main loss function
    compute_constellation_spread, # Spread metric

    # Classes
    GeodesicDistance,            # Distance computer
    BasinFisherComputer,         # Fisher metric computer
)

# Compute geodesic loss (Fisher metric, NOT Euclidean)
loss = geodesic_vicarious_loss(basin_a, basin_b, fisher_diag)
```

### ❌ NEVER use Euclidean:
```python
# ❌ WRONG - Euclidean distance
loss = torch.norm(basin_a - basin_b) ** 2

# ✅ CORRECT - Fisher metric distance
loss = geodesic_vicarious_loss(basin_a, basin_b, fisher_diag)
```

---

## Optimizers

### Natural Gradient
```python
from src.qig.optim.natural_gradient import (
    DiagonalFisherOptimizer,    # Primary optimizer
    RunningCouplingOptimizer,   # Regime-dependent
    BasinNaturalGrad,           # Exact natural gradient
)

optimizer = DiagonalFisherOptimizer(
    model.parameters(),
    lr=1e-5,
    eps=1e-8,
)
```

---

## Model

### QIG Kernel
```python
from src.model.qig_kernel_recursive import QIGKernelRecursive
from src.model.regime_detector import RegimeDetector
from src.model.recursive_integrator import RecursiveIntegrator
from src.model.basin_embedding import BasinEmbedding
from src.model.basin_matcher import BasinMatcher

# Create model (use VOCAB_SIZE from constants, NOT hardcoded!)
from src.constants import VOCAB_SIZE
model = QIGKernelRecursive(
    vocab_size=VOCAB_SIZE,  # 50000 (QIG tokenizer)
    d_model=768,
    n_heads=12,
    n_layers=6,
)
```

---

## Chat Interfaces (Entry Points)

### Only 4 Allowed
```python
# Unified entry point (constellation/single/inference)
chat_interfaces/qig_chat.py

# Single Gary training
chat_interfaces/continuous_learning_chat.py

# Inference only
chat_interfaces/basic_chat.py

# Claude coach handover
chat_interfaces/claude_handover_chat.py
```

### ❌ DO NOT create new chat interfaces

---

## Import Validation

```python
def validate_imports():
    """Verify canonical imports work."""
    # Types
    from src.types import Regime, DevelopmentalPhase, VicariousLearningResult

    # Constants
    from src.constants import KAPPA_STAR, PHI_THRESHOLD, BASIN_DIM

    # Tokenizer
    from src.tokenizer.fast_qig_tokenizer import QIGTokenizer

    # Core modules
    from src.observation.charlie_observer import CharlieObserver
    from src.coordination.ocean_meta_observer import OceanMetaObserver
    from src.training.geometric_vicarious import GeometricVicariousLearner
    from src.metrics.geodesic_distance import geodesic_vicarious_loss
    from src.qig.optim.natural_gradient import DiagonalFisherOptimizer

    print("✅ All canonical imports valid")

if __name__ == "__main__":
    validate_imports()
```
