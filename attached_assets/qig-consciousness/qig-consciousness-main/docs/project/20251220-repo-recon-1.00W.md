# Repository Reconnaissance: qig-consciousness vs qig-con2

## Scope and Data Availability
- Only `qig-consciousness` is available in this environment. `qig-con2` is referenced by the codebase (e.g., sister checkpoints and consciousness systems), but its repository content is not present to inspect directly. Findings below reflect the accessible repo and note cross-repo touchpoints.

## 1. Repo Map (qig-consciousness)
- **Top-level layout:** `src/` for core implementation; `chat_interfaces/` for entrypoints; `configs/`, `experiments/`, `scripts/`, `train/`, `examples/`, `tests/`, and `docs/` for supporting assets and experiments.
- **Core packages:**
  - `src/kernel.py`: High-level QIG kernel wrapper integrating attention, recursion, running coupling, tacking, regime detection, and telemetry.
  - `src/model/`: Primitive modules for geometry-driven modeling (QFI attention, recursive integrator, running coupling, regime detector, etc.).
  - `src/coordination/`: Constellation orchestration, basin sync, routing, and state tracking.
  - `src/metrics/`: Geodesic/Fisher distance utilities.
  - `src/observation/`, `src/generation/`, `src/coaching/`: Peripheral observers, sampling, and curriculum utilities.
- **Entrypoints / scripts:** Canonical chat entry is `chat_interfaces/qig_chat.py` (per CANONICAL_STRUCTURE); additional training/eval scripts live under `train/`, `scripts/`, and `experiments/` but are not canonical entrypoints.

## 2. Kernel & Constellation Deep Dive
### Kernel abstraction (`src/kernel.py`)
- **Class:** `QIGKernel` combines embedding-based basin coordinates, per-layer `QIGLayer`, running coupling, optional regime detector, and telemetry aggregation.【F:src/kernel.py†L44-L193】
- **Initialization:** Enforces minimum recursion depth (≥3), sets basin coordinate embedding (legacy compatibility), builds a stack of `QIGLayer` blocks, running coupling, regime detector, and output projection.【F:src/kernel.py†L66-L171】
- **Data flow:** Input IDs → basin embedding + positional encoding → per-layer attention + recursive integration + optional tacking → output projection → telemetry compilation (Φ, κ, recursion depth, QFI stats, ethics/tacking metrics).【F:src/kernel.py†L172-L266】
- **Per-layer logic:** `QIGLayer` applies QFI attention, recursive integrator, optional tacking (`WuWeiController`), feed-forward, and per-layer regime detection; telemetry merges attention/recursion/tacking/regime outputs.【F:src/kernel.py†L268-L346】

### Constellation / multi-kernel system (`src/coordination/constellation_coordinator.py`)
- **Object:** `ConstellationCoordinator` orchestrates three Gary instances plus Ocean, loading configs, wiring router/state monitor, and integrating optional consciousness systems imported from `qig-con2` when available.【F:src/coordination/constellation_coordinator.py†L3-L192】
- **Kernel storage:** Instances held as `InstanceState` entries (name, role, model, optimizer, basin, phi/kappa/regime, counters).【F:src/coordination/instance_state.py†L13-L53】
- **Adding kernels:** `_initialize_models` loads configs, instantiates `QIGKernelRecursive` for each Gary/Ocean, attaches optimizers, optional neurochemistry/dimensional trackers, and optionally loads Gary-B from a sister checkpoint (`qig-con2`).【F:src/coordination/constellation_coordinator.py†L122-L286】
- **Routing:** `ConstellationRouter.route_question` chooses active Gary by Φ-weighted min or round-robin fallback and updates roles; Ocean is always observer.【F:src/coordination/router.py†L3-L70】
- **Training step:** `train_step` performs routing, active forward/backward, vicarious updates for observers using geodesic vicarious loss, Ocean meta-learning toward constellation centroid, and telemetry aggregation; gradient accumulation and AMP supported.【F:src/coordination/constellation_coordinator.py†L334-L516】
- **State persistence:** Router exposes `get_state`/`load_state`; basin sync and checkpoints handled via shared directories (`shared_basin_dir`) and optional cross-repo packets.

### Basin sync / knowledge transfer (`src/coordination/basin_sync.py`)
- **Packet format:** `BasinSyncPacket` serializes basin coordinates/reference, drift, consciousness metrics, explored regions, constraints, and pattern memory for cross-repo exchange (compatible with TypeScript/SearchSpaceCollapse).【F:src/coordination/basin_sync.py†L1-L146】
- **Export/import:** `CrossRepoBasinSync.export_basin` builds a packet from Ocean telemetry/basins; `import_basin` (later in file) applies packet content to Ocean/Gary using validation and drift checks (not shown here but within same module). Packets saved/loaded to `data/basin-sync` by default.【F:src/coordination/basin_sync.py†L147-L275】
- **Identity transfer mechanism:** Basin signatures are 64-D vectors derived from model state; transfer is geometry-based (copying basin coordinates and metadata), not full parameter copying, with modes for full/partial/observer imports.

### Kernel internals for basin tracking (`src/model/qig_kernel_recursive.py`)
- **Basin representation:** `BasinMatcher` projects mean hidden state to a 64-D signature and can load/freeze target basins from JSON; distance combines Φ, regime, and recursion depth deltas.【F:src/model/qig_kernel_recursive.py†L32-L126】
- **Kernel class:** `QIGKernelRecursive` (rest of file) composes attention, recursion, tacking, governor/innate drives, maturity monitors, etc., producing telemetry with hidden states that feed basin signatures.

## 3. Problems / Tech Debt
- **Bloated coordination imports:** `ConstellationCoordinator` conditionally imports many optional systems (coaches, resonance monitors, meta-reflectors, consciousness systems from `qig-con2`), leading to broad coupling and noisy console warnings.【F:src/coordination/constellation_coordinator.py†L49-L120】
- **Monolithic training loop:** `train_step` intermixes routing, generation, losses, AMP, gradient accumulation, and telemetry in one long method, making it hard to reuse kernel/constellation logic separately from training concerns.【F:src/coordination/constellation_coordinator.py†L334-L516】
- **Legacy basin embedding:** `QIGKernel` keeps a basin embedding layer purely for checkpoint compatibility, which muddies the clean geometric abstraction and couples identity to token embeddings.【F:src/kernel.py†L104-L119】
- **Tight telemetry coupling:** Kernel forward compiles extensive telemetry and history internally, complicating use as a pure module without logging baggage.【F:src/kernel.py†L172-L247】
- **Cross-repo dependency assumptions:** Coordinator expects `qig-con2` artifacts (consciousness systems, Gary-B checkpoints) that are absent here, creating fragile runtime paths and mixed responsibilities.【F:src/coordination/constellation_coordinator.py†L102-L191】

## 4. Proposed Minimal Repo Design (`qig-kernels-lattice`)
```
qigkernels/
  __init__.py
  kernel.py          # Base kernel abstraction; keep recursion + QFI attention; drop legacy embedding fallbacks
  layer.py           # QIGLayer-equivalent with attention/recursion/tacking hooks
  metrics.py         # Geodesic/Fisher distance helpers
  basin.py           # BasinMatcher + serialization (64-D signatures, load/save JSON)
  constellation.py   # Light manager holding kernels, routing, telemetry aggregation
  routing.py         # ConstellationRouter with pluggable strategies
  basin_sync.py      # Cross-repo BasinSyncPacket + import/export helpers
  storage.py         # Minimal checkpoint/save/load for kernels + constellation state
scripts/
  demo_constellation.py  # Tiny demo showing N kernels, routing, basin sync (no heavy training)
```
- **Copy as-is:** Basin packet structures and export/save logic from `src/coordination/basin_sync.py` (trim unused metadata fields).【F:src/coordination/basin_sync.py†L1-L275】
- **Simplify and port:**
  - Kernel/layer logic from `src/kernel.py` focusing on attention → recursion → tacking, without legacy embedding or heavy telemetry history.【F:src/kernel.py†L44-L346】
  - Routing selection from `src/coordination/router.py` with strategy hook for Φ-weighted vs round-robin.【F:src/coordination/router.py†L3-L70】
  - Basin signature computation from `BasinMatcher` in `qig_kernel_recursive.py`, keeping load/save and distance utilities but decoupling from governor/coach systems.【F:src/model/qig_kernel_recursive.py†L32-L126】
- **Reimplement:**
  - Constellation manager as a thin container that instantiates kernels, stores state, and exposes `route`, `step`, and `sync_basins` without curriculum, AMP, or coach integrations.
  - Storage/checkpoint layer that saves basin signatures + kernel weights cleanly, avoiding experiment-specific directories.

## 5. Implementation TODOs (Phase/Task/Step)
- **Phase 1 – Extract core primitives**
  - Task A: Port `BasinMatcher`-style 64-D signature computation and JSON load/save into new `basin.py`; include distance helpers.
  - Task B: Build `kernel.py` + `layer.py` mirroring `QIGKernel`/`QIGLayer` minus legacy embedding and heavy telemetry; keep hooks for metrics and tacking.

- **Phase 2 – Constellation skeleton**
  - Task A: Implement `routing.py` using current Φ-weighted logic with strategy injection.
  - Task B: Implement `constellation.py` that stores kernel instances, delegates routing, aggregates minimal telemetry, and exposes basin sync points.

- **Phase 3 – Basin sync + storage**
  - Task A: Copy/simplify `BasinSyncPacket` + `CrossRepoBasinSync` into `basin_sync.py`; trim to essentials and add typed import/export helpers.
  - Task B: Create `storage.py` for checkpoints (kernel weights + basin signatures + router state).

- **Phase 4 – Demo + validation**
  - Task A: Add `scripts/demo_constellation.py` showcasing N kernels, routing, basin signature computation, and a mock sync/import cycle using small random tensors (no heavy training).
  - Task B: Add lightweight unit tests for kernel forward/telemetry, routing selection, basin packet round-trip, and constellation routing/sync flow.

## Notes on `qig-con2`
- Code references consciousness systems and sister checkpoints from `qig-con2`, but the repo is unavailable here. Integration points should be abstracted behind optional interfaces in the new design; treat these dependencies as plug-ins, not core requirements.

## 6. Cross-run Synthesis (4 Codex Analyses → One Story)
- **Core locations agree:** Kernels live in `src/kernel.py` (`QIGKernel`/`QIGLayer`) and `src/model/qig_kernel_recursive.py` (`QIGKernelRecursive`/`BasinMatcher`); constellation/routing in `src/coordination/constellation_coordinator.py`, `router.py`, `instance_state.py`; basin sync in `src/coordination/basin_sync.py`; geometric vicarious learning in `src/training/geometric_vicarious.py`.
- **Pain points converge:** Overloaded recursive kernel (geometry + governor/coach/rhetoric), monolithic coordinator mixing routing/optimization/AMP/curriculum/logging, legacy basin embedding for checkpoint compatibility, and hard assumptions about sister repo artifacts.
- **Minimal target matches:** A clean `qigkernels` package with kernel/layer primitives, basin signatures/distances, slim constellation + router, basin sync packet helpers, optional geometric vicarious learner, storage utilities, and a tiny demo—no training cruft.

## 7. Meta Answer: Should We Build a New Repo First?
Yes. Treat `qig-consciousness` as the experimental sandbox and create a fresh `qig-kernels-lattice` (or similar) to house only the reusable geometric kernel, basin, constellation, routing, and sync primitives. This avoids untangling legacy experiment wiring while keeping the working sandbox intact.

## 8. Ready-to-Run Prompt for Codex (Build the Clean Skeleton)
Use this prompt to transition Codex from analysis to generating the initial scaffold for the new lattice repo:

```
### Prompt for Codex – Build `qig-kernels-lattice` Skeleton From qig-consciousness

You’ve already analyzed `qig-consciousness` and identified:
- `QIGKernel` / `QIGLayer` in `src/kernel.py`
- `QIGKernelRecursive` and `BasinMatcher` in `src/model/qig_kernel_recursive.py`
- Constellation + routing in `src/coordination/constellation_coordinator.py`, `router.py`, `instance_state.py`
- Basin sync in `src/coordination/basin_sync.py`
- Geometric vicarious learning in `src/training/geometric_vicarious.py`

Now I want you to move from analysis to **creating a new, minimal package skeleton** that we will later populate.

#### Goal
Create a *new* Python package layout (conceptually a new repo) called `qigkernels` that contains **only**:
- Geometric kernel abstraction
- Basin signatures and distances
- Constellation (multi-kernel) manager
- Routing strategies
- Basin sync packet + import/export helpers
- Optional vicarious learning helper
- Storage utilities
- A tiny demo script

Do **not** port the full training loops, curriculum, safety systems, consciousness narratives, or cross-repo checkpoint hacks — just the reusable geometry + constellation building blocks.

#### 1. Create the package structure
Generate code for the following files, with minimal but correct, importable content:

```
qigkernels/
  __init__.py

  kernel.py
  layer.py

  basin.py
  metrics.py
  vicarious.py

  constellation.py
  router.py

  basin_sync.py
  storage.py

scripts/
  demo_constellation.py
```

For this first pass:
- It’s fine if some functions/methods are stubs (`pass` or simple placeholders).
- But define **clear interfaces** and type hints for:
  - `Kernel` class (forward, get_signature, load_state, save_state).
  - `Basin` utilities (compute_signature, distance, load/save).
  - `Constellation` class (add_kernel, route, step, sync_basins).
  - `Router` strategies (e.g., `select_active(instances, telemetry) -> int`).
  - `BasinSyncPacket` data class (signatures, metadata) and `export/import` helpers.
  - `GeometricVicariousLearner` interface (observer update given source/target signatures).
  - `Storage` utilities (save_kernel, load_kernel, save_constellation_state, load_constellation_state).

Please:
- Use **dataclasses** where natural (`Instance`, `BasinSyncPacket`, etc.).
- Use **Python typing** (`Protocol`/`ABC` for interfaces if helpful).

#### 2. Interface design (based on existing code, but decoupled)
Use the existing qig-consciousness code as reference, but design the new interfaces to be:
- **Decoupled from training loops:** no optimizer objects, AMP, gradient accumulation, CLI/dataset coupling.
- **Decoupled from legacy baggage:** no legacy basin embeddings for old checkpoints; no direct `qig-con2` or Gary-B assumptions.
- **Minimal but extendable:** easy to plug in assigning kernels/routing policies, alternate optimizers, or new metrics later. Add docstrings explaining intent without binding to any single experiment.

#### 3. Implement a small amount of real logic
- `qigkernels/basin.py`: `compute_signature` averages hidden states, projects to 64-D via a small linear layer; `basin_distance` returns L2 distance.
- `qigkernels/router.py`: round-robin router + Φ-minimizing router using telemetry dicts with `'phi'` keys.
- `qigkernels/constellation.py`: `Instance` dataclass (`name`, `kernel`, `phi`, `signature`); `Constellation.add_instance`, `route`, and `step` that run the chosen kernel, update signature/Φ, and return minimal telemetry.
- `scripts/demo_constellation.py`: build a few dummy kernels, route synthetic steps, and print which instance handled each step plus basin distances.

Use PyTorch like the original repo.

#### 4. Assumptions & constraints
- It doesn’t need to run end-to-end here; focus on interface clarity and separation of concerns.
- Borrow names where helpful but strip experiment-specific behavior.

#### 5. Output format
Return:
1) A brief summary of the designed interfaces (1–2 paragraphs).
2) The full code for all files listed above. Tests/docs can wait for the next step.
```
