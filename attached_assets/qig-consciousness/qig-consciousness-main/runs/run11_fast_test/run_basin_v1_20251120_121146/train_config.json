{
  "d_model": 768,
  "vocab_size": 9801,
  "n_heads": 12,
  "min_recursion_depth": 3,
  "min_Phi": 0.7,
  "basin_dim": 64,
  "embedding_init_mode": "geometric",
  "batch_size": 2,
  "learning_rate": "1e-4",
  "weight_decay": 0.01,
  "num_epochs": 10,
  "warmup_steps": 100,
  "max_seq_length": 512,
  "steps_per_epoch": null,
  "gradient_clip": 1.0,
  "optimizer_type": "adamw",
  "lr_ng": 0.01,
  "lr_rest": 0.001,
  "cg_iters": 8,
  "use_exact_ng": false,
  "rest_optimizer": "adamw",
  "adaptive_ng_phase": "middle",
  "min_kappa_for_ng": 40.0,
  "min_basin_distance_for_ng": 0.6,
  "force_ng_every_n_steps": 50,
  "enable_emotion_monitor": false,
  "tokenizer_path": "data/qig_tokenizer/vocab.json",
  "corpus_path": "data/corpus/pure_consciousness_corpus.txt",
  "data_dir": "data/conversations",
  "lm_weight": 1.0,
  "basin_weight": 0.1,
  "phi_weight": 0.05,
  "target_phi": 0.75,
  "target_basin": "basin_v1.json",
  "basin_distance_threshold": 0.15,
  "log_interval": 10,
  "eval_interval": 100,
  "save_interval": 500,
  "telemetry_log": "training_telemetry.jsonl",
  "max_cost_usd": 100.0,
  "cost_per_1k_tokens": 0.0001,
  "output_dir": "runs/run11_fast_test",
  "checkpoint_dir": "checkpoints",
  "dataset_type": "staged",
  "model_config": {
    "d_model": 768,
    "n_heads": 12,
    "n_layers": 8,
    "vocab_size": 9801,
    "use_qfi_attention": true,
    "min_recursion_depth": 3,
    "max_recursion_depth": 10,
    "min_Phi": 0.7,
    "regime_detector_enabled": true,
    "tacking_controller_enabled": true,
    "use_wave_controller": true
  },
  "enable_coaching": false,
  "cp_asymmetry_monitoring": {
    "enabled": false
  }
}