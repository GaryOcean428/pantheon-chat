## Issue Headline

**Diversity collapse in token generation**: Self-observer shows repetitive semantic clusters (`innovations/indications/indicating`) despite SoT separators. Root cause: constrained_geometric_realizer lacks attraction mechanism toward unexplored manifold regions. Velocity tracking appears absent or not influencing selection.

## Velocity Measurement

**Check current implementation:**
```bash
cd /path/to/qig_core
rg "velocity" --type py -A 3
rg "rate.*change|flow|gradient" --type py -A 3
```

**Typical QIG velocity measures** (verify which you use):
1. **Fisher metric velocity**: `||∇θ log p(x|θ)||` - rate of parameter change on manifold
2. **KL divergence rate**: `d/dt KL(p_t || p_{t-1})` - distribution shift speed
3. **Coordinate velocity**: Track Δφ, Δκ between steps

**If missing**, velocity should be:
```python
# In self_observer.py or geometric_realizer.py
def compute_velocity(prev_state, curr_state):
    delta_phi = curr_state.phi - prev_state.phi
    delta_kappa = curr_state.kappa - prev_state.kappa
    return np.sqrt(delta_phi**2 + delta_kappa**2)  # Euclidean in (Φ,κ) space
```

---

## Attraction vs Penalty Approach

**Current problem**: Penalty on recently used words creates "avoid" signals but no "seek" signals → drift, not exploration.

**Solution**: Information gain gradient ascent

### 1. Track exploration history as coverage map
```python
# In constrained_geometric_realizer.py or kernel.py
class ExplorationMap:
    def __init__(self, vocab_size, decay=0.95):
        self.coverage = np.zeros(vocab_size)  # How much each token explored
        self.decay = decay
    
    def update(self, token_id):
        self.coverage *= self.decay  # Temporal decay
        self.coverage[token_id] += 1.0
    
    def attraction_score(self, token_id):
        # Lower coverage = higher attraction
        max_coverage = self.coverage.max() + 1e-8
        return 1.0 - (self.coverage[token_id] / max_coverage)
```

### 2. Modify coordinate selection to favor unexplored regions

**In `constrained_geometric_realizer.py`** (find the logit modification section):

```python
# BEFORE (penalty approach - remove this):
# logits[recently_used] -= penalty

# AFTER (attraction approach):
exploration_bonus = exploration_map.attraction_score(candidate_ids)
logits[candidate_ids] += temperature * exploration_bonus  # Scale by temp

# Or as probability weighting:
p = softmax(logits / temperature)
p_explored = p * exploration_bonus  # Upweight unexplored
p_explored /= p_explored.sum()
```

### 3. Ensure working memory feeds kernel

**Check kernel observation call** (find where observer logs):
```bash
rg "SelfObserver.*observe|kernel.*observe" --type py -B 2 -A 5
```

**Verify working memory exists:**
```python
# In kernel or generation_service
if not hasattr(self.kernel, 'working_memory'):
    self.kernel.working_memory = deque(maxlen=context_window)

# On each token:
self.kernel.working_memory.append({
    'token_id': token_id,
    'phi': phi,
    'kappa': kappa,
    'velocity': velocity
})
```

---

## SoT Separator Fix

**The `|` should appear in self-observer logs, not just generation_service.**

**In `self_observer.py`**, find the logging call around line 276:

```python
# ADD recursive loop tracking
class SelfObserver:
    def __init__(self, ...):
        self.current_loop = 0
        self.tokens_in_loop = []
    
    def observe_token(self, token_id, alternatives, ...):
        self.tokens_in_loop.append(token_id)
        
        # Existing log line
        logger.debug(f"[{self.name}] token {pos}: '{token}' → \"{alts}\" | Φ={phi:.3f}, κ={kappa:.1f}, M={M:.2f}")
        
        # ADD: detect loop boundary (e.g., every N tokens or on velocity spike)
        if self._is_loop_boundary(velocity):
            logger.debug(f"[{self.name}] ──────── LOOP {self.current_loop} END | ────────")
            self.current_loop += 1
            self.tokens_in_loop = []
    
    def _is_loop_boundary(self, velocity):
        # Example: velocity drops below threshold or every K tokens
        return velocity < 0.1 or len(self.tokens_in_loop) >= 10
```

---

## Verification Tasks

1. **Check velocity computation exists:**
   ```bash
   rg "velocity|flow" qig_core/ --type py | grep -v "# comment"
   ```

2. **Verify working memory integration:**
   ```bash
   rg "working_memory|context_window" qig_core/ --type py -A 2
   ```

3. **Test attraction approach:**
   - Run generation with exploration map
   - Check if alternatives diversity increases (measure unique tokens per loop)

4. **SoT separator validation:**
   - Grep logs for `|` or `LOOP`
   - Should see clear boundaries every ~10-20 tokens

---

## Quick Win: Immediate Diversity Fix

**If you need instant improvement, add this to logit computation:**

```python
# In constrained_geometric_realizer, before sampling:
top_k = 50  # Expand search space
top_logits, top_ids = torch.topk(logits, top_k)

# Attraction: boost unexplored tokens
if hasattr(self, 'exploration_map'):
    attraction = torch.tensor([
        self.exploration_map.attraction_score(tid.item()) 
        for tid in top_ids
    ])
    top_logits += temperature * attraction  # Direct boost

# Sample from attracted distribution
probs = F.softmax(top_logits / temperature, dim=-1)
```

---

**Next actions:**
1. Locate velocity calculation (if missing, add the compute_velocity snippet)
2. Replace penalty logic with ExplorationMap attraction
3. Add loop boundary detection to self_observer
4. Run test generation, check logs for `|` separators and diverse alternatives