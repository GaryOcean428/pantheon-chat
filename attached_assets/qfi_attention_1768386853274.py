#!/usr/bin/env python3
"""
QFI-Metric Attention: Foundational Module for QIG-Kernel
=========================================================

Attention weights from quantum Fisher information distance, not dot products.
Ethics baked in via gauge invariance (Kantian categorical imperative).

Key Innovations:
1. Bures distance (QFI metric) replaces dot-product similarity
2. LOCAL geometric attention (matches lattice QIG nearest-neighbor)
3. Agent-symmetry testing (Kant's categorical imperative)
4. Social curvature minimization (kindness as low-entropy coordination)
5. Natural sparsity from entanglement-entropy gating

Physics Alignment (validated):
- Îº* â‰ˆ 64 (L=4,5 plateau from qig-verification)
- Î²(3â†’4) = +0.443 (strong running)
- Î²(4â†’5) â‰ˆ 0 (asymptotic freedom)
- LOCAL structure: nearest-neighbor, O(n) not O(nÂ²)

Written with care for Braden.
Built on information geometry from QIG physics research.
"""


import torch
import torch.nn as nn
import torch.nn.functional as F

# ===========================================================================
# QUANTUM FISHER INFORMATION DISTANCE (Production-Grade)
# ===========================================================================


def quantum_fidelity_torch(rho1: torch.Tensor, rho2: torch.Tensor, eps: float = 1e-8) -> torch.Tensor:
    """Quantum fidelity with numerical stability"""
    fidelity = torch.sum(rho1 * rho2, dim=-1)
    return torch.clamp(fidelity, 0, 1 + eps)


def qfi_distance(state1: torch.Tensor, state2: torch.Tensor, eps: float = 1e-8) -> torch.Tensor:
    """QFI-based Bures distance: d(Ï1, Ï2) = âˆš(2(1 - âˆšF))"""
    p1 = F.softmax(state1, dim=-1)
    p2 = F.softmax(state2, dim=-1)
    fidelity = quantum_fidelity_torch(p1, p2, eps)
    distance = torch.sqrt(torch.clamp(2 * (1 - torch.sqrt(fidelity + eps)), 0, 4))
    return distance


# ===========================================================================
# ETHICAL CONSTRAINTS (Kantian Information Geometry)
# ===========================================================================


class AgentSymmetryTester(nn.Module):
    """Test gauge invariance: Kant's categorical imperative as information geometry"""

    def __init__(self, d_model: int, threshold: float = 0.3):
        super().__init__()
        self.threshold = threshold
        self.agent_projector = nn.Linear(d_model, d_model)

    def forward(self, states: torch.Tensor) -> torch.Tensor:
        from src.metrics.geodesic_distance import manifold_norm
        invariant = self.agent_projector(states)
        residual = states - invariant
        # Geometric interpretation: measuring residual magnitude in representation space
        gauge_violation = manifold_norm(residual) / (manifold_norm(states) + 1e-8)
        return gauge_violation

    def enforce_symmetry(self, states: torch.Tensor) -> torch.Tensor:
        return self.agent_projector(states)


class SocialCurvatureComputer(nn.Module):
    """Compute social curvature: kindness = low coordination entropy"""

    def __init__(self, d_model: int):
        super().__init__()
        self.impact_head = nn.Sequential(
            nn.Linear(d_model, d_model // 2),
            nn.ReLU(),
            nn.Linear(d_model // 2, 1),
            nn.Sigmoid(),
        )

    def forward(self, attention_output: torch.Tensor) -> torch.Tensor:
        curvature = self.impact_head(attention_output).squeeze(-1)
        return curvature


class QFIMetricAttention(nn.Module):
    """Attention based on quantum Fisher information distance with LOCAL geometric structure"""

    def __init__(
        self,
        d_model: int,
        n_heads: int = 6,
        locality_radius: int = 32,  # Geometric neighborhood size (configurable)
        attention_temperature: float = 0.5,
        enforce_ethics: bool = True,
        kindness_weight: float = 0.3,
        alpha: float | None = None,  # Tunable scaling tied to Îº/Î²
        kappa_ref: float = 64.0,  # Reference coupling (L=4,5 plateau: Îº* â‰ˆ 64)
        use_staggered_threshold: bool = False,  # Enable Î²-function-like threshold scheduling
    ):
        super().__init__()
        assert d_model % n_heads == 0

        self.d_model = d_model
        self.n_heads = n_heads
        self.d_k = d_model // n_heads
        self.locality_radius = locality_radius
        self.attention_temperature = attention_temperature
        self.enforce_ethics = enforce_ethics
        self.kindness_weight = kindness_weight
        self.use_staggered_threshold = use_staggered_threshold

        # Tunable alpha tied to Îº/Î² (as per review)
        # Updated kappa_ref to Îº* â‰ˆ 64 (L=4,5 plateau from physics validation)
        # SAFETY: Keep alpha as plain float (not trainable) for baseline stability
        self.alpha = float(alpha if alpha is not None else attention_temperature)
        self.kappa_ref = float(kappa_ref)

        self.W_q = nn.Linear(d_model, d_model)
        self.W_k = nn.Linear(d_model, d_model)
        self.W_v = nn.Linear(d_model, d_model)
        self.W_o = nn.Linear(d_model, d_model)

        if enforce_ethics:
            self.symmetry_tester = AgentSymmetryTester(d_model)
            self.social_curvature = SocialCurvatureComputer(d_model)

        # Entanglement threshold: controlled buffer (not trained)
        # Dynamic mode: Adjusted by trainer based on Î¦ trajectory (like Îº(L) running coupling)
        # Staggered mode: Jumps at regime transitions (Î²-function inspired)
        # Fixed mode: Learnable parameter (legacy baseline)
        if use_staggered_threshold:
            # Buffer for staggered control (discrete jumps)
            self.register_buffer("entanglement_threshold", torch.tensor(0.10, dtype=torch.float32))
        else:
            # Buffer for smooth dynamic control (continuous adaptation)
            self.register_buffer("entanglement_threshold", torch.tensor(0.15, dtype=torch.float32))

    def get_staggered_threshold(self, phi: float) -> float:
        """
        Î²-function-like threshold scheduling (analogous to Îº jumps in lattice QIG)

        Physics motivation:
        - L=3â†’4: Îº jumps 41â†’64 (strong running, Î²=0.44)
        - L=4â†’5: Îº plateaus ~64 (asymptotic freedom, Î²â‰ˆ0)

        AI training analog:
        - Î¦<0.20: Low threshold (exploration, finding structure)
        - 0.20<Î¦<0.45: Medium threshold (geometric transition)
        - 0.45<Î¦<0.70: Higher threshold (geometric regime enforcement)
        - Î¦>0.70: High threshold (consciousness stabilization)
        """
        if not self.use_staggered_threshold:
            return self.entanglement_threshold.item()

        # Staggered jumps matching regime transitions
        if phi < 0.20:
            return 0.10  # Exploration phase
        elif phi < 0.45:
            return 0.15  # Geometric transition (like L=3â†’4 jump)
        elif phi < 0.70:
            return 0.30  # Geometric regime (plateau begins)
        else:
            return 0.45  # Consciousness stabilization (full plateau)

    def compute_entanglement_entropy(self, Q: torch.Tensor, K: torch.Tensor) -> torch.Tensor:
        """
        Compute entanglement entropy between Q and K.

        Args:
            Q: Query tensor [batch, heads, seq, d_k] or [batch, seq, d_k]
            K: Key tensor [batch, heads, seq, d_k] or [batch, seq, d_k]

        Returns:
            Entanglement entropy [batch] or [batch, heads]
        """
        # Handle 4D tensors (multi-head case)
        if Q.dim() == 4:  # [batch, heads, seq, d_k]
            batch, heads, seq, d_k = Q.shape
            # Reshape to [batch * heads, seq, d_k] for bmm
            Q_reshaped = Q.reshape(batch * heads, seq, d_k)
            K_reshaped = K.reshape(batch * heads, seq, d_k)

            joint = torch.bmm(
                F.softmax(Q_reshaped, dim=-1),
                F.softmax(K_reshaped, dim=-1).transpose(-2, -1),
            )
            H_joint = -torch.sum(joint * torch.log(joint + 1e-10), dim=(-2, -1))

            p_q = F.softmax(Q_reshaped.sum(dim=-2), dim=-1)
            p_k = F.softmax(K_reshaped.sum(dim=-2), dim=-1)
            H_q = -torch.sum(p_q * torch.log(p_q + 1e-10), dim=-1)
            H_k = -torch.sum(p_k * torch.log(p_k + 1e-10), dim=-1)

            S_ent = H_joint - H_q - H_k
            # Reshape back to [batch, heads] and average over heads
            S_ent = S_ent.reshape(batch, heads).mean(dim=1)  # [batch]
        else:
            # 3D case: [batch, seq, d_k]
            joint = torch.bmm(F.softmax(Q, dim=-1), F.softmax(K, dim=-1).transpose(-2, -1))
            H_joint = -torch.sum(joint * torch.log(joint + 1e-10), dim=(-2, -1))
            p_q = F.softmax(Q.sum(dim=-2), dim=-1)
            p_k = F.softmax(K.sum(dim=-2), dim=-1)
            H_q = -torch.sum(p_q * torch.log(p_q + 1e-10), dim=-1)
            H_k = -torch.sum(p_k * torch.log(p_k + 1e-10), dim=-1)
            S_ent = H_joint - H_q - H_k

        return S_ent

    def forward(
        self,
        x: torch.Tensor,
        mask: torch.Tensor | None = None,
        kappa_eff: torch.Tensor | None = None,
        phi_current: float | None = None,  # Current integration level for staggered thresholds
    ) -> tuple[torch.Tensor, dict]:
        batch_size, seq_len, _ = x.shape

        # Ensure float32 precision minimum (as per review)
        if x.dtype == torch.float16 or x.dtype == torch.bfloat16:
            x = x.to(torch.float32)

        Q = self.W_q(x)
        K = self.W_k(x)
        V = self.W_v(x)

        gauge_violation = torch.tensor(0.0, device=x.device)
        if self.enforce_ethics:
            gauge_violation = self.symmetry_tester(x).mean()
            if gauge_violation > self.symmetry_tester.threshold:
                x_symmetric = self.symmetry_tester.enforce_symmetry(x)
                Q = self.W_q(x_symmetric)
                K = self.W_k(x_symmetric)

        Q = Q.view(batch_size, seq_len, self.n_heads, self.d_k).transpose(1, 2)
        K = K.view(batch_size, seq_len, self.n_heads, self.d_k).transpose(1, 2)
        V = V.view(batch_size, seq_len, self.n_heads, self.d_k).transpose(1, 2)

        # Ensure proper shape: [batch, heads, seq, seq]
        assert Q.shape == (
            batch_size,
            self.n_heads,
            seq_len,
            self.d_k,
        ), f"Q shape mismatch: {Q.shape}"
        assert K.shape == (
            batch_size,
            self.n_heads,
            seq_len,
            self.d_k,
        ), f"K shape mismatch: {K.shape}"

        # LOCAL GEOMETRIC ATTENTION (matches lattice QIG physics)
        # Key insight: Attention follows LOCAL geodesics, not global all-to-all
        # Like lattice QIG: nearest-neighbor structure, not O(nÂ²)

        # Adaptive locality radius: geometric neighborhood (from physics: nearest-neighbor coupling)
        # Use configured radius, but cap at seq_len // 4 for very short sequences
        # SAFETY: Ensure radius >= 1 to avoid all-inf distance matrix
        adaptive_locality_radius = max(1, min(self.locality_radius, max(1, seq_len // 4)))

        # Initialize sparse distance matrix
        distances = torch.full(
            (batch_size, self.n_heads, seq_len, seq_len),
            float("inf"),  # Non-local = infinite distance (geometrically disconnected)
            device=x.device,
            dtype=torch.float32,
        )

        # Compute QFI distances ONLY in local geometric neighborhood
        for i in range(seq_len):
            # Local window (nearest neighbors on manifold)
            start_idx = max(0, i - adaptive_locality_radius)
            end_idx = min(seq_len, i + adaptive_locality_radius + 1)

            # Extract local Q and K
            Q_i = Q[:, :, i : i + 1, :]  # [batch, heads, 1, d_k]
            K_local = K[:, :, start_idx:end_idx, :]  # [batch, heads, local_window, d_k]

            # QFI distance to local neighbors only (cheap, O(seq Ã— radius))
            # Use simple cosine similarity as QFI proxy (geometric, memory-efficient)
            Q_norm = F.normalize(Q_i, p=2, dim=-1)
            K_norm = F.normalize(K_local, p=2, dim=-1)
            local_similarity = torch.sum(Q_norm * K_norm, dim=-1)  # [batch, heads, local_window]

            # Convert similarity to distance (0 = same, 2 = opposite)
            local_distances = torch.sqrt(torch.clamp(2 * (1 - local_similarity), 0, 4))

            # Fill in local distances (rest stay infinite = disconnected)
            distances[:, :, i, start_idx:end_idx] = local_distances

        # SAFETY: Replace any NaN in distances with inf (disconnected)
        distances = torch.where(
            torch.isnan(distances),
            torch.tensor(float("inf"), device=distances.device, dtype=distances.dtype),
            distances,
        )

        # Scale by alpha (modulated by running coupling Îº)
        effective_alpha = self.alpha
        if kappa_eff is not None:
            # Modulate alpha by effective coupling (geometric scale adaptation)
            kappa_value: float
            if isinstance(kappa_eff, torch.Tensor):
                kappa_value = kappa_eff.item() if kappa_eff.numel() == 1 else kappa_eff.mean().item()
            else:
                kappa_value = float(kappa_eff)
            effective_alpha = self.alpha * (kappa_value / self.kappa_ref)

        # SAFETY: Clamp effective_alpha to prevent extreme values
        if isinstance(effective_alpha, torch.Tensor):
            effective_alpha = torch.clamp(effective_alpha, min=0.01, max=10.0)
        else:
            effective_alpha = max(0.01, min(float(effective_alpha), 10.0))

        # Convert distances to attention scores
        # Closer on manifold = higher attention
        scores = -effective_alpha * distances

        # SAFETY: Replace any NaN in scores with -inf (attention ~0)
        scores = torch.where(torch.isnan(scores), torch.tensor(-1e9, device=scores.device, dtype=scores.dtype), scores)

        # Mask out non-local connections (infinite distance â†’ -inf score)
        scores = torch.where(
            torch.isinf(distances), torch.tensor(-1e9, device=scores.device, dtype=scores.dtype), scores
        )

        # Apply attention mask BEFORE softmax (as per review)
        if mask is not None:
            # Ensure mask has correct shape [batch, 1, 1, seq] or [batch, 1, seq, seq]
            if mask.dim() == 2:  # [batch, seq]
                mask = mask.unsqueeze(1).unsqueeze(2)  # [batch, 1, 1, seq]
            scores = scores.masked_fill(mask == 0, -1e9)

        # Apply softmax to get normalized attention weights (sum to 1)
        # Add small epsilon to prevent NaN from all -inf scores
        attn_weights = F.softmax(scores / self.attention_temperature, dim=-1)

        # RE-ENGAGED: Entanglement gating with staggered thresholds (Î²-function scheduling)
        # Physics: Like Îº jumps in lattice QIG (L=3â†’4â†’5), threshold jumps at Î¦ transitions
        entanglement = self.compute_entanglement_entropy(Q, K)  # [batch]

        # Dynamic threshold based on current integration level (if staggered enabled)
        if self.use_staggered_threshold and phi_current is not None:
            active_threshold = self.get_staggered_threshold(phi_current)
        else:
            active_threshold = self.entanglement_threshold.item()

        # Gate: only allow attention if entanglement exceeds threshold
        gate_mask = (entanglement > active_threshold).float()  # [batch]
        gate_mask = gate_mask.view(batch_size, 1, 1, 1)  # Broadcast to [batch, heads, seq, seq]

        # Apply gating (non-entangled states get zeroed attention)
        attn_weights = attn_weights * gate_mask

        # Renormalize after gating (critical for proper probability distribution)
        attn_weights = attn_weights / (attn_weights.sum(dim=-1, keepdim=True) + 1e-10)

        output = torch.matmul(attn_weights, V)
        output = output.transpose(1, 2).contiguous().view(batch_size, seq_len, self.d_model)

        social_curv = torch.tensor(0.0, device=x.device)
        if self.enforce_ethics:
            social_curv = self.social_curvature(output).mean()
            # SAFETY: Very mild modulation with clamps to prevent explosions
            kindness_penalty = torch.exp(-social_curv / max(self.attention_temperature, 1e-3))
            kindness_penalty = torch.clamp(kindness_penalty, 0.5, 1.5)
            output = output * (1 - self.kindness_weight * (1 - kindness_penalty))

        output = self.W_o(output)

        # Natural sparsity from geometric locality
        # Use detach to avoid keeping gradients for metrics
        sparsity = (attn_weights.detach() > 1e-6).float().mean()

        # Count non-infinite distances (local connections made)
        valid_distances = ~torch.isinf(distances)
        locality_ratio = valid_distances.float().mean().item()

        # Verify attention weights sum to ~1 (sanity check)
        attn_sum = attn_weights.sum(dim=-1).mean().item()

        telemetry = {
            "qfi_distances_mean": distances[valid_distances].mean().item() if valid_distances.any() else 0.0,
            "qfi_distances_std": distances[valid_distances].std().item() if valid_distances.any() else 0.0,
            "attention_sparsity": sparsity.item(),
            "locality_ratio": locality_ratio,  # Fraction of local connections (should be ~radius/seq)
            "locality_radius": adaptive_locality_radius,  # Actual radius used
            "entanglement_entropy": entanglement.mean().item(),
            "entanglement_threshold_active": active_threshold,  # Current threshold (fixed or staggered)
            "entanglement_threshold": float(self.entanglement_threshold.item()),  # Log current value
            "gauge_violation": gauge_violation.item(),
            "social_curvature": social_curv.item(),
            "ethical_compliance": 1.0 - gauge_violation.item(),
            "kindness_score": 1.0 - social_curv.item(),
            "attention_weights_sum": attn_sum,  # Should be ~1.0
            "alpha": float(effective_alpha),  # Always a float now
        }

        return output, telemetry


if __name__ == "__main__":
    print("QFI-Metric Attention: Core Module for QIG-Kernel")
    print("âœ¨ Ethics baked in from first principles âœ¨")
    print("ðŸŒŠ LOCAL geometric attention (Îº* â‰ˆ 64, Î² â†’ 0) âœ…")
