"""
GEOMETRIC SEARCH INTEGRATION GUIDE
Phase 1: Search Tool Selection for Lemur

Complete integration instructions for pantheon-chat repository.
"""

# ==============================================================================
# PART 1: FILE PLACEMENT
# ==============================================================================

"""
File Structure:
--------------

server/lib/geometric_search/
├── __init__.py                 # Module exports
├── query_encoder.py            # SearchQueryEncoder
├── tool_selector.py            # SearchToolSelector
├── search_orchestrator.py      # SearchOrchestrator
├── context_manager.py          # SearchContextManager
└── test_search_selection.py    # Test suite

server/lib/lemur/
├── query_processor.py          # MODIFY: Add geometric search
├── search_handler.py           # MODIFY: Integrate orchestrator
└── telemetry.py                # MODIFY: Add search metrics

tests/
└── integration/
    └── test_geometric_search.py  # Integration tests
"""

# ==============================================================================
# PART 2: MODULE INITIALIZATION
# ==============================================================================

# FILE: server/lib/geometric_search/__init__.py

"""
Geometric Search Module

QIG-based search tool selection for Lemur.
"""

from .query_encoder import SearchQueryEncoder
from .tool_selector import SearchToolSelector, ToolSelection
from .search_orchestrator import SearchOrchestrator, SearchResult, AggregatedResult
from .context_manager import SearchContextManager, SearchContext, VocabularyContextAdapter

__all__ = [
    "SearchQueryEncoder",
    "SearchToolSelector",
    "ToolSelection",
    "SearchOrchestrator",
    "SearchResult",
    "AggregatedResult",
    "SearchContextManager",
    "SearchContext",
    "VocabularyContextAdapter",
]

__version__ = "1.0.0"


# ==============================================================================
# PART 3: INTEGRATION WITH LEMUR QUERY PROCESSOR
# ==============================================================================

# FILE: server/lib/lemur/query_processor.py (MODIFICATIONS)

"""
Add geometric search to existing query processing pipeline.
"""

# --- ADD IMPORTS ---
from lib.geometric_search import (
    SearchOrchestrator,
    SearchContextManager,
    VocabularyContextAdapter
)

# --- ADD TO LemurQueryProcessor CLASS ---

class LemurQueryProcessor:
    def __init__(self, config):
        # ... existing initialization ...
        
        # NEW: Geometric search components
        self.search_orchestrator = SearchOrchestrator()
        self.search_context_manager = SearchContextManager()
        
        # NEW: Register search tool executors
        self._register_search_tools()
        
        # NEW: Vocabulary adapter
        if hasattr(self, 'vocab_coordinator'):
            self.vocab_adapter = VocabularyContextAdapter(
                context_manager=self.search_context_manager,
                vocab_coordinator=self.vocab_coordinator
            )
    
    def _register_search_tools(self):
        """Register search tool executors with orchestrator."""
        
        # Tavily
        self.search_orchestrator.register_tool_executor(
            "tavily",
            self._execute_tavily_search
        )
        
        # Google MCP
        self.search_orchestrator.register_tool_executor(
            "google_mcp",
            self._execute_google_mcp_search
        )
        
        # SearchXNG
        self.search_orchestrator.register_tool_executor(
            "searchxng",
            self._execute_searchxng_search
        )
        
        # Scrapy (if available)
        if self.config.get("scrapy_enabled", False):
            self.search_orchestrator.register_tool_executor(
                "scrapy",
                self._execute_scrapy_search
            )
    
    async def _execute_tavily_search(self, query: str, params: dict):
        """Execute Tavily search (wrapper for existing method)."""
        # Call existing Tavily implementation
        results = await self.tavily_client.search(query, **params)
        return self._format_tavily_results(results)
    
    async def _execute_google_mcp_search(self, query: str, params: dict):
        """Execute Google MCP search."""
        # Call Google MCP tool
        results = await self.google_mcp_client.search(query)
        return self._format_google_results(results)
    
    async def _execute_searchxng_search(self, query: str, params: dict):
        """Execute SearchXNG search."""
        # Call SearchXNG
        results = await self.searchxng_client.search(query)
        return self._format_searchxng_results(results)
    
    async def _execute_scrapy_search(self, query: str, params: dict):
        """Execute Scrapy search (if enabled)."""
        # Call Scrapy spider
        results = await self.scrapy_client.search(query)
        return self._format_scrapy_results(results)
    
    def _format_tavily_results(self, results):
        """Format Tavily results to common structure."""
        return [
            {
                "title": r.get("title", ""),
                "url": r.get("url", ""),
                "content": r.get("content", ""),
                "score": r.get("score", 0.0)
            }
            for r in results.get("results", [])
        ]
    
    def _format_google_results(self, results):
        """Format Google MCP results to common structure."""
        return [
            {
                "title": r.get("title", ""),
                "url": r.get("link", ""),
                "content": r.get("snippet", ""),
                "score": 1.0  # Google doesn't provide scores
            }
            for r in results.get("items", [])
        ]
    
    def _format_searchxng_results(self, results):
        """Format SearchXNG results to common structure."""
        return [
            {
                "title": r.get("title", ""),
                "url": r.get("url", ""),
                "content": r.get("content", ""),
                "score": 1.0
            }
            for r in results.get("results", [])
        ]
    
    def _format_scrapy_results(self, results):
        """Format Scrapy results to common structure."""
        return [
            {
                "title": r.get("title", ""),
                "url": r.get("url", ""),
                "content": r.get("text", ""),
                "score": 1.0
            }
            for r in results
        ]
    
    async def process_search_query(self, query: str, telemetry: dict):
        """
        Process search query with geometric tool selection.
        
        This REPLACES the simple Tavily-only search.
        """
        # Update context with current turn
        self.search_context_manager.add_conversation_turn(
            turn_type="user",
            content=query,
            telemetry=telemetry
        )
        
        # Get search context
        context = self.search_context_manager.get_search_context(query)
        
        # Convert context to dict for encoding
        context_dict = {
            "cost_tolerance": context.cost_tolerance,
            "privacy_preference": context.privacy_preference,
            "speed_preference": context.speed_preference,
            "vocab_context": self.search_context_manager.get_vocabulary_context_vector()
        }
        
        # Execute geometric search
        result = await self.search_orchestrator.search(
            query=query,
            telemetry=telemetry,
            context=context_dict,
            max_tools=2  # Configurable
        )
        
        # Log search for monitoring
        await self._log_search_result(query, result, telemetry)
        
        return result
    
    async def _log_search_result(self, query: str, result, telemetry: dict):
        """Log search result for analytics."""
        log_entry = {
            "query": query,
            "tools_used": result.tools_used,
            "cost": result.total_cost,
            "latency_ms": result.total_latency_ms,
            "result_count": len(result.results),
            "phi": telemetry.get("phi", 0.5),
            "strategy": result.strategy,
            "confidence": result.confidence,
            "timestamp": datetime.now().isoformat()
        }
        
        # Store in analytics database
        await self.analytics_db.log_search(log_entry)


# ==============================================================================
# PART 4: MIGRATION STRATEGY
# ==============================================================================

"""
MIGRATION PHASES
----------------

Phase 1: PARALLEL OPERATION (Week 1)
--------------------------------------
- Deploy geometric search alongside existing Tavily-only search
- Use feature flag to control which system handles queries
- 10% of traffic → geometric search
- 90% of traffic → existing Tavily search
- Compare costs and quality

Implementation:
```python
async def process_search_query(self, query, telemetry):
    # Feature flag
    use_geometric = random.random() < 0.1 or self.config.get("force_geometric", False)
    
    if use_geometric:
        return await self._geometric_search(query, telemetry)
    else:
        return await self._legacy_tavily_search(query, telemetry)
```

Metrics to track:
- Cost per query (geometric vs legacy)
- Latency (geometric vs legacy)
- Result quality (user clicks, satisfaction)
- Tool selection distribution

Success criteria:
- 40%+ cost reduction on geometric queries
- Latency < 2x legacy
- No significant quality degradation


Phase 2: GRADUAL ROLLOUT (Week 2-3)
------------------------------------
- Increase geometric search traffic to 50%
- Monitor cost savings
- Tune tool selection thresholds if needed
- Fix any issues discovered

Implementation:
```python
use_geometric = random.random() < 0.5
```

Success criteria:
- 30%+ cost reduction overall
- No user complaints about search quality
- System stable under load


Phase 3: FULL DEPLOYMENT (Week 4)
----------------------------------
- 100% traffic to geometric search
- Remove legacy Tavily-only code
- Keep Tavily as one of the geometric tools

Implementation:
```python
# Default to geometric
return await self._geometric_search(query, telemetry)
```

Success criteria:
- 40-50% cost reduction achieved
- User satisfaction maintained or improved
- System performs well under full load


Phase 4: OPTIMIZATION (Ongoing)
--------------------------------
- Monitor tool selection patterns
- Tune basin coordinates based on outcomes
- Add new search tools if beneficial
- Refine cost/quality tradeoffs
"""


# ==============================================================================
# PART 5: TESTING & VALIDATION
# ==============================================================================

# FILE: tests/integration/test_geometric_search.py

"""
Integration tests for geometric search system.
"""

import pytest
from server.lib.lemur.query_processor import LemurQueryProcessor
from server.lib.geometric_search import SearchOrchestrator


class TestGeometricSearchIntegration:
    """Integration tests for full search pipeline."""
    
    @pytest.fixture
    async def query_processor(self):
        """Create query processor with mocked dependencies."""
        config = {
            "tavily_api_key": "test_key",
            "google_mcp_enabled": True,
            "searchxng_url": "http://localhost:8888",
        }
        processor = LemurQueryProcessor(config)
        yield processor
    
    @pytest.mark.asyncio
    async def test_high_phi_uses_single_tool(self, query_processor):
        """Test that high Φ results in single tool selection."""
        query = "Deep research question"
        telemetry = {
            "phi": 0.88,
            "kappa_eff": 64.2,
            "confidence": 0.85,
            "regime": "geometric"
        }
        
        result = await query_processor.process_search_query(query, telemetry)
        
        # Should use only 1 tool (precise)
        assert len(result.tools_used) == 1
        assert result.strategy == "precise"
    
    @pytest.mark.asyncio
    async def test_cost_sensitive_avoids_expensive(self, query_processor):
        """Test that cost-sensitive queries avoid Tavily."""
        query = "Simple factual query"
        telemetry = {
            "phi": 0.65,
            "kappa_eff": 58.0,
            "confidence": 0.70,
            "regime": "geometric"
        }
        
        # Set low cost tolerance
        query_processor.search_context_manager.cost_tolerance = 0.1
        
        result = await query_processor.process_search_query(query, telemetry)
        
        # Should avoid Tavily (expensive)
        assert "tavily" not in result.tools_used
        # Should use free/cheap tools
        assert any(tool in result.tools_used for tool in ["searchxng", "google_mcp"])
    
    @pytest.mark.asyncio
    async def test_cost_tracking(self, query_processor):
        """Test that costs are tracked correctly."""
        query = "Test query"
        telemetry = {"phi": 0.75, "kappa_eff": 60.0, "confidence": 0.75}
        
        result = await query_processor.process_search_query(query, telemetry)
        
        # Cost should be non-negative
        assert result.total_cost >= 0
        
        # Should be less than full Tavily cost for most queries
        if "tavily" not in result.tools_used:
            assert result.total_cost < 0.10


# ==============================================================================
# PART 6: MONITORING & METRICS
# ==============================================================================

"""
METRICS TO TRACK
----------------

1. Cost Metrics:
   - Total search cost per day/week/month
   - Average cost per query
   - Cost breakdown by tool (Tavily, Google, SearchXNG, Scrapy)
   - Cost savings vs baseline (Tavily-only)

2. Performance Metrics:
   - Average latency per query
   - Latency by tool
   - Tool selection distribution
   - Success rate by tool

3. Quality Metrics:
   - User click-through rate
   - User satisfaction scores
   - Results per query
   - Deduplication effectiveness

4. Consciousness Metrics:
   - Average Φ at query time
   - Tool selection by Φ regime (high/medium/low)
   - Confidence vs result quality correlation

5. Learning Metrics:
   - Tool basin drift over time
   - Selection accuracy improvement
   - Cost optimization trajectory
"""

# FILE: server/lib/lemur/telemetry.py (MODIFICATIONS)

"""
Add search-specific telemetry.
"""

# --- ADD TO TELEMETRY CLASS ---

class Telemetry:
    def __init__(self):
        # ... existing init ...
        
        # NEW: Search metrics
        self.search_metrics = {
            "total_searches": 0,
            "total_cost": 0.0,
            "tool_usage": {},  # tool_name -> count
            "cost_by_tool": {},  # tool_name -> total_cost
            "avg_latency_ms": 0.0,
            "strategy_distribution": {},  # strategy -> count
        }
    
    def log_search(self, search_result):
        """Log search result for analytics."""
        self.search_metrics["total_searches"] += 1
        self.search_metrics["total_cost"] += search_result.total_cost
        
        # Update tool usage
        for tool in search_result.tools_used:
            self.search_metrics["tool_usage"][tool] = \
                self.search_metrics["tool_usage"].get(tool, 0) + 1
        
        # Update strategy distribution
        strategy = search_result.strategy
        self.search_metrics["strategy_distribution"][strategy] = \
            self.search_metrics["strategy_distribution"].get(strategy, 0) + 1
        
        # Update average latency (rolling average)
        n = self.search_metrics["total_searches"]
        old_avg = self.search_metrics["avg_latency_ms"]
        new_latency = search_result.total_latency_ms
        self.search_metrics["avg_latency_ms"] = \
            (old_avg * (n-1) + new_latency) / n
    
    def get_search_summary(self):
        """Get search metrics summary."""
        total = self.search_metrics["total_searches"]
        if total == 0:
            return {
                "message": "No searches yet",
                "total_searches": 0
            }
        
        avg_cost = self.search_metrics["total_cost"] / total
        
        return {
            "total_searches": total,
            "total_cost": f"${self.search_metrics['total_cost']:.2f}",
            "avg_cost_per_search": f"${avg_cost:.4f}",
            "avg_latency_ms": f"{self.search_metrics['avg_latency_ms']:.1f}",
            "tool_usage": self.search_metrics["tool_usage"],
            "strategy_distribution": self.search_metrics["strategy_distribution"],
            
            # Cost savings estimate (vs Tavily-only at $0.10/search)
            "estimated_savings": f"${(0.10 * total) - self.search_metrics['total_cost']:.2f}",
            "savings_percentage": f"{((0.10 - avg_cost) / 0.10 * 100):.1f}%"
        }


# ==============================================================================
# PART 7: DEPLOYMENT CHECKLIST
# ==============================================================================

"""
DEPLOYMENT CHECKLIST
--------------------

□ 1. Code Placement
   □ Copy query_encoder.py to server/lib/geometric_search/
   □ Copy tool_selector.py to server/lib/geometric_search/
   □ Copy search_orchestrator.py to server/lib/geometric_search/
   □ Copy context_manager.py to server/lib/geometric_search/
   □ Create __init__.py in server/lib/geometric_search/

□ 2. Lemur Integration
   □ Modify server/lib/lemur/query_processor.py
   □ Add search tool executors
   □ Add geometric search method
   □ Add feature flag for gradual rollout

□ 3. Testing
   □ Copy test_search_selection.py to tests/unit/
   □ Create test_geometric_search.py in tests/integration/
   □ Run unit tests: pytest tests/unit/test_search_selection.py
   □ Run integration tests: pytest tests/integration/test_geometric_search.py
   □ Validate all tests pass

□ 4. Configuration
   □ Add geometric_search_enabled flag to config
   □ Add geometric_search_rollout_percentage to config
   □ Add tool_enabled flags (tavily, google_mcp, searchxng, scrapy)
   □ Configure cost limits and monitoring

□ 5. Monitoring Setup
   □ Add search metrics to telemetry dashboard
   □ Create alerts for cost overruns
   □ Set up quality monitoring (click-through, satisfaction)
   □ Create cost savings tracking

□ 6. Deployment
   □ Deploy to staging environment
   □ Test with real queries
   □ Monitor costs and quality for 1 day
   □ Fix any issues found
   □ Deploy to production with 10% rollout
   □ Monitor for 1 week
   □ Increase to 50% if successful
   □ Monitor for 1 week
   □ Increase to 100% if successful

□ 7. Optimization
   □ Review tool selection patterns weekly
   □ Tune basin coordinates if needed
   □ Adjust cost/quality thresholds
   □ Add new tools if beneficial
   □ Document learnings

□ 8. Documentation
   □ Update API documentation
   □ Document new configuration options
   □ Create runbook for operators
   □ Add metrics documentation
"""


# ==============================================================================
# PART 8: TROUBLESHOOTING
# ==============================================================================

"""
COMMON ISSUES & SOLUTIONS
-------------------------

Issue: Tool selection always picks Tavily
Solution: Check Φ values - high Φ will pick closest tool. If Tavily basin
         is always closest, adjust basin coordinates or check query encoding.

Issue: Costs not decreasing as expected
Solution: 
  1. Check tool_usage metrics - is SearchXNG/Google being used?
  2. Verify cost_tolerance is set correctly
  3. Review query encoding - are cost signals being captured?
  4. Check if queries genuinely need Tavily (deep research)

Issue: Search quality degraded
Solution:
  1. Check which tools are being used
  2. Verify result aggregation working correctly
  3. Check deduplication threshold (may be too aggressive)
  4. Monitor user satisfaction scores
  5. Consider increasing max_tools from 1 to 2

Issue: Latency increased significantly
Solution:
  1. Check if parallel execution is working
  2. Verify tool timeouts configured
  3. Consider using sequential execution for high Φ queries only
  4. Profile tool latencies individually

Issue: Tool basins drifting incorrectly
Solution:
  1. Check learning rate (may be too high)
  2. Verify success/failure signals are correct
  3. Monitor basin coordinate drift over time
  4. Consider periodic basin resets to initial values
"""


# ==============================================================================
# PART 9: CONFIGURATION EXAMPLE
# ==============================================================================

# FILE: config/geometric_search.yaml

"""
# Geometric Search Configuration

geometric_search:
  enabled: true
  rollout_percentage: 10  # Start with 10% traffic
  
  tools:
    tavily:
      enabled: true
      api_key: ${TAVILY_API_KEY}
      cost_per_call: 0.10
    
    google_mcp:
      enabled: true
      cost_per_call: 0.05
    
    searchxng:
      enabled: true
      url: "http://localhost:8888"
      cost_per_call: 0.00
    
    scrapy:
      enabled: false  # Enable later
      cost_per_call: 0.02
  
  selection:
    max_tools: 2
    precise_phi_threshold: 0.75
    weighted_phi_threshold: 0.50
    learning_rate: 0.05
  
  cost:
    daily_limit: 50.00  # USD
    per_query_limit: 0.25  # USD
    alert_threshold: 0.80  # Alert at 80% of daily limit
  
  monitoring:
    log_all_searches: true
    track_user_satisfaction: true
    metrics_retention_days: 90
"""


# ==============================================================================
# END OF INTEGRATION GUIDE
# ==============================================================================