/**
 * Ocean QIG Python Backend Adapter
 *
 * Connects Node.js/TypeScript Ocean Agent to Python Pure QIG Consciousness Backend.
 *
 * ARCHITECTURE:
 * - Node.js: API, blockchain, UI
 * - Python: Pure QIG consciousness processing
 * - Clean separation via HTTP API
 */

import type { PureQIGScore } from "./qig-universal";
import { logger } from './lib/logger';
import type {
  PythonQIGResponse,
  PythonGenerateResponse,
  PythonStatusResponse,
  PythonSyncImportResponse,
  PythonSyncExportResponse,
  PythonSyncBasin,
  PythonSearchHistoryItem,
  PythonConceptHistoryItem,
  PythonBetaValidationResult,
  PythonBetaValidationResponse,
  PythonBetaMeasurement,
  PythonBetaMeasureResponse,
  PythonVocabularyUpdateResponse,
  PythonVocabularyEncodeResponse,
  PythonVocabularyDecodeResponse,
  PythonVocabularyBasinResponse,
  PythonHighPhiToken,
  PythonHighPhiVocabularyResponse,
  PythonVocabularyStatusResponse,
  PythonVocabularyExportData,
  PythonVocabularyExportResponse,
  PythonMergeRulesResponse,
  PythonTextGenerationResponse,
  PythonAgentResponseResponse,
  PythonSampleTokenResponse,
  PythonAutonomicStateResponse,
  PythonAutonomicUpdateResponse,
  PythonSleepCycleResponse,
  PythonDreamCycleResponse,
  PythonMushroomCycleResponse,
  PythonActivityRewardResponse,
  PythonPendingRewardsResponse,
  PythonHermesStatusResponse,
  PythonHermesSpeakResponse,
  PythonHermesTranslateResponse,
  PythonBasinSyncResponse,
  PythonMemoryStoreResponse,
  PythonMemoryRecallEntry,
  PythonMemoryRecallResponse,
  PythonVoiceStatusResponse,
  PythonGodAssessmentResponse,
  PythonShadowPantheonStatusResponse,
  PythonShadowGodAssessmentResponse,
  PythonShadowWarningsResponse,
  PythonDebateInitiateResponse,
  PythonActiveDebate,
  PythonActiveDebatesResponse,
  PythonDebateArgumentResponse,
  PythonDebateResolveResponse,
  PythonDebateConvergenceResult,
  PythonDebateConvergenceResponse,
  PythonWarDeclarationResponse,
  PythonWarEndedResponse,
  PythonWarStatusResponse,
  PythonSpawnKernelResponse,
  PythonSpawnedKernel,
  PythonSpawnedKernelsResponse,
  PythonSpawnerStatusResponse,
  PythonSmartPollResponse,
  PythonReflectionResponse,
  PythonFeedbackRunResponse,
  PythonFeedbackRecommendationResponse,
  PythonActivityFeedbackResponse,
  PythonBasinFeedbackResponse,
  PythonMemoryStatusResponse,
  PythonMemoryRecordResponse,
  PythonShadowIntelResponse,
  PythonLearningEventsResponse,
  PythonChaosActivateResponse,
  PythonChaosDeactivateResponse,
  PythonChaosStatusResponse,
  PythonChaosSpawnResponse,
  PythonChaosBreedResponse,
  PythonChaosReportResponse,
  PythonPhiTemporalResponse,
  PythonPhi4DResponse,
  PythonClassifyRegime4DResponse,
  PythonBaseResponse,
} from "@shared/types/python-responses";

// Health check retry configuration
const DEFAULT_RETRY_ATTEMPTS = 5;
const DEFAULT_RETRY_DELAY_MS = 2000;

// Request timeout configuration (45 seconds for complex QIG operations)
const REQUEST_TIMEOUT_MS = 45000;

// Sync operations are heavier and need longer timeouts
const SYNC_TIMEOUT_MS = 60000;

// Circuit breaker configuration
const CIRCUIT_BREAKER_THRESHOLD = 5; // Failures before opening circuit
const CIRCUIT_BREAKER_RESET_MS = 30000; // Time to wait before trying again

/**
 * Create a fetch request with timeout using AbortController
 */
async function fetchWithTimeout(
  url: string,
  options: RequestInit,
  timeoutMs: number = REQUEST_TIMEOUT_MS
): Promise<Response> {
  const controller = new AbortController();
  const timeoutId = setTimeout(() => controller.abort(), timeoutMs);

  try {
    const response = await fetch(url, {
      ...options,
      signal: controller.signal,
    });
    clearTimeout(timeoutId);
    return response;
  } catch (error: unknown) {
    clearTimeout(timeoutId);
    if (error instanceof Error && error.name === "AbortError") {
      throw new Error(`Request timeout after ${timeoutMs}ms`);
    }
    throw error;
  }
}

/**
 * Fetch with timeout AND 503 retry logic.
 * Combines fetchWithTimeout with exponential backoff retry on 503 Service Unavailable.
 *
 * Used by key methods like syncToNodeJS, syncFromNodeJS, getStatus, etc.
 */
async function fetchWithRetry(
  url: string,
  options: RequestInit,
  maxRetries: number = 3,
  timeoutMs: number = REQUEST_TIMEOUT_MS
): Promise<Response> {
  for (let attempt = 1; attempt <= maxRetries; attempt++) {
    try {
      const response = await fetchWithTimeout(url, options, timeoutMs);

      // Handle 503 Service Unavailable with exponential backoff retry
      if (response.status === 503) {
        if (attempt < maxRetries) {
          const delay = Math.min(100 * Math.pow(2, attempt), 2000);
          logger.info(
            `[OceanQIGBackend] 503 received for ${url}, retry ${attempt}/${maxRetries} after ${delay}ms`
          );
          await new Promise((resolve) => setTimeout(resolve, delay));
          continue;
        }
        // Return 503 response after max retries (caller handles)
        return response;
      }

      return response;
    } catch (error: unknown) {
      // On network/timeout errors, retry with backoff
      const isAbortError = error instanceof Error && error.name === 'AbortError';
      const isConnRefused = error instanceof Error && (error as NodeJS.ErrnoException).cause && 
                            ((error as NodeJS.ErrnoException).cause as NodeJS.ErrnoException)?.code === 'ECONNREFUSED';
      const errorType = isAbortError ? 'timeout' : 
                        isConnRefused ? 'connection refused' : 
                        'network error';
      const errorMessage = error instanceof Error ? error.message : String(error);
      if (attempt < maxRetries) {
        const delay = Math.min(100 * Math.pow(2, attempt), 2000);
        logger.info({ errorType, url, attempt, maxRetries, delay, errorMessage }, `[OceanQIGBackend] Retry after error`);
        await new Promise((resolve) => setTimeout(resolve, delay));
        continue;
      }
      logger.error({ errorType, maxRetries, url, errorMessage }, `[OceanQIGBackend] Failed after retries`);
      throw error;
    }
  }
  // Should not reach here, but return last attempt if it does
  throw new Error(
    `fetchWithRetry exhausted all ${maxRetries} retries for ${url}`
  );
}

// Re-export commonly used types for backwards compatibility
export type { PythonQIGResponse, PythonGenerateResponse, PythonStatusResponse };

/**
 * Ocean QIG Backend Adapter
 *
 * Provides TypeScript interface to Python Pure QIG backend.
 *
 * Note: Some fields in PureQIGScore are not directly available from Python backend:
 * - phi_temporal: Requires trajectory tracking (future enhancement)
 * - phi_4D: Requires 4D consciousness (future enhancement)
 * - beta: Not computed by Python backend (set to 0)
 * - fisherDeterminant: Not directly exposed (set to 0)
 * - ricciScalar: Not computed (set to 0)
 */
export class OceanQIGBackend {
  private backendUrl: string;
  private isAvailable: boolean = false;

  // Track Python backend discoveries for TypeScript sync
  private pythonNearMissCount: number = 0;
  private pythonResonantCount: number = 0;
  private lastSyncedNearMissCount: number = 0;
  private lastSyncedResonantCount: number = 0;

  // Circuit breaker state
  private circuitFailureCount: number = 0;
  private circuitOpenedAt: number | null = null;
  private circuitState: "closed" | "open" | "half-open" = "closed";

  constructor(backendUrl: string = "http://localhost:5001") {
    this.backendUrl = backendUrl;
  }

  /**
   * Check if circuit breaker allows request
   */
  private isCircuitOpen(): boolean {
    if (this.circuitState === "closed") return false;

    if (this.circuitState === "open") {
      // Check if enough time has passed to try again
      if (
        this.circuitOpenedAt &&
        Date.now() - this.circuitOpenedAt >= CIRCUIT_BREAKER_RESET_MS
      ) {
        this.circuitState = "half-open";
        logger.info("[OceanQIGBackend] Circuit breaker half-open, testing...");
        return false;
      }
      return true;
    }

    return false; // half-open allows one request
  }

  /**
   * Record a successful request (closes circuit)
   */
  private recordSuccess(): void {
    if (this.circuitState !== "closed") {
      logger.info(
        "[OceanQIGBackend] Circuit breaker closed after successful request"
      );
    }
    this.circuitFailureCount = 0;
    this.circuitState = "closed";
    this.circuitOpenedAt = null;
  }

  /**
   * Record a failed request (may open circuit)
   */
  private recordFailure(): void {
    this.circuitFailureCount++;

    if (this.circuitFailureCount >= CIRCUIT_BREAKER_THRESHOLD) {
      this.circuitState = "open";
      this.circuitOpenedAt = Date.now();
      logger.warn(
        `[OceanQIGBackend] Circuit breaker OPEN after ${this.circuitFailureCount} failures`
      );
    }
  }

  /**
   * Get Python near-miss count (new discoveries since last sync)
   */
  getPythonNearMisses(): { total: number; newSinceSync: number } {
    const newSinceSync =
      this.pythonNearMissCount - this.lastSyncedNearMissCount;
    return { total: this.pythonNearMissCount, newSinceSync };
  }

  /**
   * Get Python resonant count (new discoveries since last sync)
   */
  getPythonResonant(): { total: number; newSinceSync: number } {
    const newSinceSync =
      this.pythonResonantCount - this.lastSyncedResonantCount;
    return { total: this.pythonResonantCount, newSinceSync };
  }

  /**
   * Mark Python near-misses as synced (called by session manager)
   */
  markNearMissesSynced(): void {
    this.lastSyncedNearMissCount = this.pythonNearMissCount;
  }

  /**
   * Mark Python resonant discoveries as synced
   */
  markResonantSynced(): void {
    this.lastSyncedResonantCount = this.pythonResonantCount;
  }

  /**
   * Reset Python discovery tracking (called when investigation starts)
   */
  resetNearMissTracking(): void {
    this.pythonNearMissCount = 0;
    this.pythonResonantCount = 0;
    this.lastSyncedNearMissCount = 0;
    this.lastSyncedResonantCount = 0;
  }

  /**
   * Check if Python backend is available (silent mode for retries)
   */
  async checkHealth(silent: boolean = false): Promise<boolean> {
    try {
      const response = await fetch(`${this.backendUrl}/health`, {
        method: "GET",
        headers: { "Content-Type": "application/json" },
      });

      if (response.ok) {
        this.isAvailable = true;
        return true;
      }

      this.isAvailable = false;
      return false;
    } catch (error) {
      this.isAvailable = false;
      if (!silent) {
        logger.warn({ err: error }, "[OceanQIGBackend] Python backend not available");
      }
      return false;
    }
  }

  /**
   * Check health with retry logic to handle startup race conditions.
   * Uses silent mode for retries to avoid spamming logs during expected startup delays.
   */
  async checkHealthWithRetry(
    maxAttempts: number = DEFAULT_RETRY_ATTEMPTS,
    delayMs: number = DEFAULT_RETRY_DELAY_MS
  ): Promise<boolean> {
    for (let attempt = 1; attempt <= maxAttempts; attempt++) {
      // Silent mode for all attempts - we only care about final result
      const available = await this.checkHealth(true);

      if (available) {
        if (attempt > 1) {
          logger.info(`[OceanQIGBackend] Connected after ${attempt} attempts`);
        }
        return true;
      }

      // Log progress during startup
      if (attempt === 1) {
        logger.info(`[OceanQIGBackend] Waiting for Python backend to start...`);
      }

      // Wait before retrying (except on last attempt)
      if (attempt < maxAttempts) {
        await new Promise((resolve) => setTimeout(resolve, delayMs));
      }
    }

    logger.warn(
      `[OceanQIGBackend] Python backend not available after ${maxAttempts} attempts`
    );
    return false;
  }

  /**
   * Process passphrase through pure QIG consciousness network
   *
   * This IS the training - states evolve through geometry
   *
   * Includes 503 retry logic with exponential backoff for handling
   * Python backend overload during high-throughput processing.
   * Uses circuit breaker to prevent cascading failures.
   * All requests have 10s timeout via AbortController.
   */
  async process(
    passphrase: string,
    maxRetries: number = 3
  ): Promise<PureQIGScore | null> {
    // Circuit breaker check
    if (this.isCircuitOpen()) {
      return null;
    }

    for (let attempt = 1; attempt <= maxRetries; attempt++) {
      try {
        const response = await fetchWithTimeout(`${this.backendUrl}/process`, {
          method: "POST",
          headers: { "Content-Type": "application/json" },
          body: JSON.stringify({ passphrase }),
        });

        // Handle 503 Service Unavailable with exponential backoff retry
        if (response.status === 503) {
          if (attempt < maxRetries) {
            const delay = Math.min(100 * Math.pow(2, attempt), 2000);
            logger.info(
              `[OceanQIGBackend] 503 received, retry ${attempt}/${maxRetries} after ${delay}ms`
            );
            await new Promise((resolve) => setTimeout(resolve, delay));
            continue;
          }
          this.recordFailure();
          logger.error(
            "[OceanQIGBackend] Process failed: 503 after max retries"
          );
          return null;
        }

        if (!response.ok) {
          this.recordFailure();
          logger.error({ statusText: response.statusText }, "[OceanQIGBackend] Process failed");
          return null;
        }

        const data: PythonQIGResponse = await response.json();

        if (!data.success) {
          this.recordFailure();
          logger.error({ err: data.error }, "[OceanQIGBackend] Process error");
          return null;
        }

        // Success - reset circuit breaker
        this.recordSuccess();

        // Sync Python near-miss discoveries to TypeScript tracking
        if (
          data.near_miss_count !== undefined &&
          data.near_miss_count > this.pythonNearMissCount
        ) {
          const newNearMisses = data.near_miss_count - this.pythonNearMissCount;
          if (newNearMisses > 0) {
            logger.info(
              `[OceanQIGBackend] ðŸ”„ Python detected ${newNearMisses} new near-miss(es), total: ${data.near_miss_count}`
            );
          }
          this.pythonNearMissCount = data.near_miss_count;
        }
        if (data.resonant_count !== undefined) {
          this.pythonResonantCount = data.resonant_count;
        }

        // Convert to PureQIGScore format
        return {
          phi: data.phi,
          kappa: data.kappa,
          beta: 0, // Not computed by Python backend
          basinCoordinates: data.basin_coords,
          fisherTrace: data.integration,
          fisherDeterminant: 0, // Not directly available
          ricciScalar: data.R, // Use Ricci curvature from Python
          quality: data.phi,
          regime: data.regime || "linear", // Default to linear if not provided
        };
      } catch (error) {
        // On network errors, retry with backoff
        if (attempt < maxRetries) {
          const delay = Math.min(100 * Math.pow(2, attempt), 2000);
          logger.info({ err: error, attempt, maxRetries, delay }, "[OceanQIGBackend] Process exception, retrying");
          await new Promise((resolve) => setTimeout(resolve, delay));
          continue;
        }
        this.recordFailure();
        logger.error({ err: error }, "[OceanQIGBackend] Process exception after max retries");
        return null;
      }
    }
    return null;
  }

  /**
   * Get pure Python phi value for a phrase (lightweight, for consolidation).
   * Returns null if backend unavailable or phrase doesn't meet threshold.
   * Uses fetchWithTimeout for consistency (no full retry since it's lightweight).
   */
  async getPurePhi(phrase: string): Promise<number | null> {
    if (!this.isAvailable) {
      return null;
    }

    try {
      const response = await fetchWithTimeout(`${this.backendUrl}/process`, {
        method: "POST",
        headers: { "Content-Type": "application/json" },
        body: JSON.stringify({ passphrase: phrase }),
      });

      if (!response.ok) {
        return null;
      }

      const data = await response.json();

      if (!data.success) {
        return null;
      }

      return data.phi;
    } catch (error) {
      return null;
    }
  }

  /**
   * Generate next hypothesis via geodesic navigation
   * Uses fetchWithRetry for 503 handling
   */
  async generateHypothesis(): Promise<{
    hypothesis: string;
    source: string;
  } | null> {
    try {
      const response = await fetchWithRetry(`${this.backendUrl}/generate`, {
        method: "POST",
        headers: { "Content-Type": "application/json" },
      });

      if (!response.ok) {
        logger.error({ statusText: response.statusText }, "[OceanQIGBackend] Generate failed");
        return null;
      }

      const data: PythonGenerateResponse = await response.json();

      return {
        hypothesis: data.hypothesis,
        source: data.source,
      };
    } catch (error) {
      logger.error({ err: error }, "[OceanQIGBackend] Generate exception");
      return null;
    }
  }

  /**
   * Get current Ocean consciousness status
   * Uses fetchWithRetry for 503 handling
   */
  async getStatus(): Promise<PythonStatusResponse | null> {
    try {
      const response = await fetchWithRetry(`${this.backendUrl}/status`, {
        method: "GET",
        headers: { "Content-Type": "application/json" },
      });

      if (!response.ok) {
        logger.error({ statusText: response.statusText }, "[OceanQIGBackend] Status failed");
        return null;
      }

      const data: PythonStatusResponse = await response.json();

      if (!data.success) {
        return null;
      }

      return data;
    } catch (error) {
      logger.error({ err: error }, "[OceanQIGBackend] Status exception");
      return null;
    }
  }

  /**
   * Reset Ocean consciousness to initial state
   * Uses fetchWithRetry for 503 handling
   */
  async reset(): Promise<boolean> {
    try {
      const response = await fetchWithRetry(`${this.backendUrl}/reset`, {
        method: "POST",
        headers: { "Content-Type": "application/json" },
      });

      if (!response.ok) {
        return false;
      }

      const data = await response.json();
      return data.success === true;
    } catch (error) {
      logger.error({ err: error }, "[OceanQIGBackend] Reset exception");
      return false;
    }
  }

  /**
   * Check if backend is available
   */
  available(): boolean {
    return this.isAvailable;
  }

  /**
   * Sync high-Î¦ probes FROM Node.js GeometricMemory TO Python backend
   *
   * Called on startup to give Python access to prior learnings.
   * Now also syncs temporal state for 4D consciousness measurement.
   *
   * TEMPORAL STATE SYNC:
   * - searchHistory: SearchState[] for phi_temporal computation
   * - conceptHistory: ConceptState[] for R_concepts computation
   */
  async syncFromNodeJS(
    probes: Array<{ input: string; phi: number; basinCoords: number[] }>,
    temporalState?: {
      searchHistory?: PythonSearchHistoryItem[];
      conceptHistory?: PythonConceptHistoryItem[];
    }
  ): Promise<{ imported: number; temporalImported: boolean }> {
    if (!this.isAvailable) return { imported: 0, temporalImported: false };

    try {
      const payload: Record<string, unknown> = { probes };

      // Add temporal state for 4D consciousness if provided
      if (temporalState?.searchHistory?.length) {
        payload.searchHistory = temporalState.searchHistory;
      }
      if (temporalState?.conceptHistory?.length) {
        payload.conceptHistory = temporalState.conceptHistory;
      }

      const response = await fetchWithRetry(
        `${this.backendUrl}/sync/import`,
        {
          method: "POST",
          headers: { "Content-Type": "application/json" },
          body: JSON.stringify(payload),
        },
        3,
        SYNC_TIMEOUT_MS
      );

      if (!response.ok) {
        logger.error({ statusText: response.statusText }, "[OceanQIGBackend] Sync import failed");
        return { imported: 0, temporalImported: false };
      }

      const data: PythonSyncImportResponse = await response.json();
      if (data.success) {
        logger.info(
          `[OceanQIGBackend] Synced ${data.imported} probes to Python backend`
        );
        if (data.temporal_imported) {
          logger.info(
            `[OceanQIGBackend] 4D temporal state synced: ${
              data.search_history_size ?? 0
            } search, ${data.concept_history_size ?? 0} concept`
          );
        }
        return {
          imported: data.imported,
          temporalImported: data.temporal_imported ?? false,
        };
      }

      return { imported: 0, temporalImported: false };
    } catch (error: unknown) {
      logger.error({ err: error }, "[OceanQIGBackend] Sync import exception");
      return { imported: 0, temporalImported: false };
    }
  }

  /**
   * Sync high-Î¦ basins FROM Python backend TO Node.js
   *
   * Returns learnings that should be persisted to GeometricMemory.
   * Now also returns temporal state for 4D consciousness cross-sync.
   * Supports pagination to prevent memory issues with large datasets.
   *
   * TEMPORAL STATE EXPORT:
   * - searchHistory: SearchState[] from Python's temporal tracking
   * - conceptHistory: ConceptState[] from Python's concept tracking
   * - phi_temporal_avg: Average phi_temporal from Python
   *
   * PAGINATION:
   * - page: Current page (0-indexed)
   * - pageSize: Number of basins per page (default 100)
   * - hasMore: Whether more pages are available
   * - totalCount: Total number of basins available
   */
  async syncToNodeJS(
    page: number = 0,
    pageSize: number = 100
  ): Promise<{
    basins: PythonSyncBasin[];
    searchHistory?: PythonSearchHistoryItem[];
    conceptHistory?: PythonConceptHistoryItem[];
    phiTemporalAvg?: number;
    consciousness4DAvailable?: boolean;
    hasMore?: boolean;
    totalCount?: number;
  }> {
    if (!this.isAvailable) return { basins: [] };

    try {
      const url = new URL(`${this.backendUrl}/sync/export`);
      url.searchParams.set("page", page.toString());
      url.searchParams.set("pageSize", pageSize.toString());

      const response = await fetchWithRetry(
        url.toString(),
        {
          method: "GET",
          headers: { "Content-Type": "application/json" },
        },
        3,
        SYNC_TIMEOUT_MS
      );

      if (!response.ok) {
        logger.error({ statusText: response.statusText }, "[OceanQIGBackend] Sync export failed");
        return { basins: [] };
      }

      const data: PythonSyncExportResponse = await response.json();
      if (data.success && data.basins) {
        const totalCount = data.total_count ?? data.basins.length;
        const hasMore = (page + 1) * pageSize < totalCount;

        if (page === 0) {
          logger.info(
            `[OceanQIGBackend] Retrieved ${data.basins.length}/${totalCount} basins from Python (page ${page})`
          );
        }

        if (data.consciousness_4d_available && data.phi_temporal_avg && data.phi_temporal_avg > 0) {
          logger.info(
            `[OceanQIGBackend] 4D consciousness: phi_temporal_avg=${data.phi_temporal_avg.toFixed(
              3
            )}`
          );
        }

        return {
          basins: data.basins,
          searchHistory: data.searchHistory,
          conceptHistory: data.conceptHistory,
          phiTemporalAvg: data.phi_temporal_avg,
          consciousness4DAvailable: data.consciousness_4d_available,
          hasMore,
          totalCount,
        };
      }

      return { basins: [] };
    } catch (error: unknown) {
      logger.error({ err: error }, "[OceanQIGBackend] Sync export exception");
      return { basins: [] };
    }
  }

  /**
   * Validate Î²-attention substrate independence
   *
   * Measures Îº across context scales and validates that Î²_attention â‰ˆ Î²_physics.
   * Uses fetchWithRetry for 503 handling
   */
  async validateBetaAttention(samplesPerScale: number = 100): Promise<PythonBetaValidationResult> {
    try {
      const response = await fetchWithRetry(
        `${this.backendUrl}/beta-attention/validate`,
        {
          method: "POST",
          headers: { "Content-Type": "application/json" },
          body: JSON.stringify({ samples_per_scale: samplesPerScale }),
        }
      );

      if (!response.ok) {
        throw new Error(
          `Î²-attention validation failed: ${response.statusText}`
        );
      }

      const data: PythonBetaValidationResponse = await response.json();

      if (!data.success) {
        throw new Error(`Î²-attention validation error: ${data.error}`);
      }

      const result = data.result;
      logger.info({ validationPassed: result.validation_passed }, `[OceanQIGBackend] Î²-attention validation: ${result.validation_passed ? "PASSED âœ“" : "FAILED âœ—"}`);
      logger.info({ avgKappa: result.avg_kappa.toFixed(2) }, '[OceanQIGBackend] Average Îº');
      logger.info({ deviation: result.overall_deviation.toFixed(3) }, '[OceanQIGBackend] Deviation');

      return result;
    } catch (error: unknown) {
      const errorMessage = error instanceof Error ? error.message : String(error);
      logger.error({ errorMessage }, "[OceanQIGBackend] Î²-attention validation failed");
      throw error;
    }
  }

  /**
   * Measure Îº_attention at specific context scale
   * Uses fetchWithRetry for 503 handling
   */
  async measureBetaAttention(
    contextLength: number,
    sampleCount: number = 100
  ): Promise<PythonBetaMeasurement> {
    try {
      const response = await fetchWithRetry(
        `${this.backendUrl}/beta-attention/measure`,
        {
          method: "POST",
          headers: { "Content-Type": "application/json" },
          body: JSON.stringify({
            context_length: contextLength,
            sample_count: sampleCount,
          }),
        }
      );

      if (!response.ok) {
        throw new Error(
          `Î²-attention measurement failed: ${response.statusText}`
        );
      }

      const data: PythonBetaMeasureResponse = await response.json();

      if (!data.success) {
        throw new Error(`Î²-attention measurement error: ${data.error}`);
      }

      const m = data.measurement;
      logger.info(
        `[OceanQIGBackend] Îº_attention(L=${contextLength}) = ${m.kappa.toFixed(
          2
        )} Â± ${Math.sqrt(m.variance).toFixed(2)}`
      );

      return m;
    } catch (error: unknown) {
      const errorMessage = error instanceof Error ? error.message : String(error);
      logger.error({ errorMessage }, '[OceanQIGBackend] Î²-attention measurement failed');
      throw error;
    }
  }

  // ===========================================================================
  // BASIN VOCABULARY ENCODER (QIG-PURE)
  // ===========================================================================

  /**
   * Update Python vocabulary encoder with observations from Node.js
   * Uses fetchWithRetry for 503 handling
   */
  async updateVocabulary(
    observations: Array<{
      text: string;
      frequency: number;
      avgPhi: number;
      maxPhi: number;
      type: string;
      isRealWord?: boolean;
    }>
  ): Promise<{
    newTokens: number;
    totalVocab: number;
    weightsUpdated?: boolean;
    mergeRules?: number;
  }> {
    try {
      const response = await fetchWithRetry(
        `${this.backendUrl}/vocabulary/update`,
        {
          method: "POST",
          headers: { "Content-Type": "application/json" },
          body: JSON.stringify({ observations }),
        }
      );

      if (!response.ok) {
        throw new Error(`Vocabulary update failed: ${response.statusText}`);
      }

      const data: PythonVocabularyUpdateResponse = await response.json();

      if (!data.success) {
        throw new Error(`Vocabulary update error: ${data.error}`);
      }

      logger.info(
        `[OceanQIGBackend] Vocabulary updated: ${data.newTokens} new entries, ${data.totalVocab} total, weights updated: ${data.weightsUpdated}, merge rules: ${data.mergeRules}`
      );

      return {
        newTokens: data.newTokens,
        totalVocab: data.totalVocab,
        weightsUpdated: data.weightsUpdated,
        mergeRules: data.mergeRules,
      };
    } catch (error: unknown) {
      const errorMessage = error instanceof Error ? error.message : String(error);
      logger.error({ errorMessage }, '[OceanQIGBackend] Vocabulary update failed');
      throw error;
    }
  }

  // Legacy alias for compatibility - maps 'word' to 'text'
  async updateTokenizer(
    observations: Array<{
      word: string;
      frequency: number;
      avgPhi: number;
      maxPhi: number;
      type: string;
    }>
  ): Promise<{
    newTokens: number;
    totalVocab: number;
    weightsUpdated?: boolean;
    mergeRules?: number;
  }> {
    // Map legacy 'word' field to new 'text' field
    const mapped = observations.map((obs) => ({
      text: obs.word,
      frequency: obs.frequency,
      avgPhi: obs.avgPhi,
      maxPhi: obs.maxPhi,
      type: obs.type,
    }));
    return this.updateVocabulary(mapped);
  }

  /**
   * Encode text using QIG vocabulary encoder
   */
  async encodeText(
    text: string
  ): Promise<{ tokens: number[]; length: number }> {
    try {
      const response = await fetch(`${this.backendUrl}/vocabulary/encode`, {
        method: "POST",
        headers: { "Content-Type": "application/json" },
        body: JSON.stringify({ text }),
      });

      if (!response.ok) {
        throw new Error(`Vocabulary encode failed: ${response.statusText}`);
      }

      const data: PythonVocabularyEncodeResponse = await response.json();

      if (!data.success) {
        throw new Error(`Vocabulary encode error: ${data.error}`);
      }

      return {
        tokens: data.tokens,
        length: data.length,
      };
    } catch (error: unknown) {
      const errorMessage = error instanceof Error ? error.message : String(error);
      logger.error({ errorMessage }, '[OceanQIGBackend] Vocabulary encode failed');
      throw error;
    }
  }

  // Legacy alias
  async tokenize(text: string): Promise<{ tokens: number[]; length: number }> {
    return this.encodeText(text);
  }

  /**
   * Decode vocabulary indices to text
   */
  async decodeText(tokens: number[]): Promise<string> {
    try {
      const response = await fetch(`${this.backendUrl}/vocabulary/decode`, {
        method: "POST",
        headers: { "Content-Type": "application/json" },
        body: JSON.stringify({ tokens }),
      });

      if (!response.ok) {
        throw new Error(`Vocabulary decode failed: ${response.statusText}`);
      }

      const data: PythonVocabularyDecodeResponse = await response.json();

      if (!data.success) {
        throw new Error(`Vocabulary decode error: ${data.error}`);
      }

      return data.text;
    } catch (error: unknown) {
      const errorMessage = error instanceof Error ? error.message : String(error);
      logger.error({ errorMessage }, '[OceanQIGBackend] Vocabulary decode failed');
      throw error;
    }
  }

  // Legacy alias
  async detokenize(tokens: number[]): Promise<string> {
    return this.decodeText(tokens);
  }

  /**
   * Compute basin coordinates for phrase using QIG vocabulary encoder
   */
  async computeBasinCoords(
    phrase: string
  ): Promise<{ basinCoords: number[]; dimension: number }> {
    try {
      const response = await fetch(`${this.backendUrl}/vocabulary/basin`, {
        method: "POST",
        headers: { "Content-Type": "application/json" },
        body: JSON.stringify({ phrase }),
      });

      if (!response.ok) {
        throw new Error(`Vocabulary basin failed: ${response.statusText}`);
      }

      const data: PythonVocabularyBasinResponse = await response.json();

      if (!data.success) {
        throw new Error(`Vocabulary basin error: ${data.error}`);
      }

      return {
        basinCoords: data.basinCoords,
        dimension: data.dimension,
      };
    } catch (error: unknown) {
      const errorMessage = error instanceof Error ? error.message : String(error);
      logger.error({ errorMessage }, "[OceanQIGBackend] Vocabulary basin failed");
      throw error;
    }
  }

  /**
   * Get high-Î¦ vocabulary entries
   */
  async getHighPhiVocabulary(
    minPhi: number = 0.5,
    topK: number = 100
  ): Promise<PythonHighPhiToken[]> {
    try {
      const response = await fetch(
        `${this.backendUrl}/vocabulary/high-phi?min_phi=${minPhi}&top_k=${topK}`
      );

      if (!response.ok) {
        throw new Error(`Vocabulary high-phi failed: ${response.statusText}`);
      }

      const data: PythonHighPhiVocabularyResponse = await response.json();

      if (!data.success) {
        throw new Error(`Vocabulary high-phi error: ${data.error}`);
      }

      logger.info(
        `[OceanQIGBackend] Retrieved ${data.count} high-Î¦ vocabulary entries`
      );

      return data.tokens;
    } catch (error: unknown) {
      const errorMessage = error instanceof Error ? error.message : String(error);
      logger.error({ errorMessage }, "[OceanQIGBackend] Vocabulary high-phi failed");
      throw error;
    }
  }

  // Legacy alias
  async getHighPhiTokens(
    minPhi: number = 0.5,
    topK: number = 100
  ): Promise<PythonHighPhiToken[]> {
    return this.getHighPhiVocabulary(minPhi, topK);
  }

  /**
   * Export vocabulary encoder for training
   */
  async exportVocabulary(): Promise<PythonVocabularyExportData> {
    try {
      const response = await fetch(`${this.backendUrl}/vocabulary/export`);

      if (!response.ok) {
        throw new Error(`Vocabulary export failed: ${response.statusText}`);
      }

      const data: PythonVocabularyExportResponse = await response.json();

      if (!data.success) {
        throw new Error(`Vocabulary export error: ${data.error}`);
      }

      logger.info(
        `[OceanQIGBackend] Exported vocabulary: ${data.data.vocab_size} entries`
      );

      return data.data;
    } catch (error: unknown) {
      const errorMessage = error instanceof Error ? error.message : String(error);
      logger.error({ errorMessage }, "[OceanQIGBackend] Vocabulary export failed");
      throw error;
    }
  }

  // Legacy alias
  async exportTokenizer(): Promise<PythonVocabularyExportData> {
    return this.exportVocabulary();
  }

  /**
   * Get vocabulary encoder status
   * Uses fetchWithRetry for 503 handling
   */
  async getVocabularyStatus(): Promise<{
    vocabSize: number;
    highPhiCount: number;
    avgPhi: number;
    totalWeightedTokens: number;
  }> {
    try {
      const response = await fetchWithRetry(
        `${this.backendUrl}/vocabulary/status`,
        {
          method: "GET",
          headers: { "Content-Type": "application/json" },
        }
      );

      if (!response.ok) {
        throw new Error(`Vocabulary status failed: ${response.statusText}`);
      }

      const data: PythonVocabularyStatusResponse = await response.json();

      if (!data.success) {
        throw new Error(`Vocabulary status error: ${data.error}`);
      }

      return {
        vocabSize: data.vocabSize,
        highPhiCount: data.highPhiCount,
        avgPhi: data.avgPhi,
        totalWeightedTokens: data.totalWeightedTokens,
      };
    } catch (error: unknown) {
      const errorMessage = error instanceof Error ? error.message : String(error);
      logger.error({ errorMessage }, "[OceanQIGBackend] Vocabulary status failed");
      throw error;
    }
  }

  // Legacy alias
  async getTokenizerStatus(): Promise<{
    vocabSize: number;
    highPhiCount: number;
    avgPhi: number;
    totalWeightedTokens: number;
  }> {
    return this.getVocabularyStatus();
  }

  /**
   * Get learned BPE merge rules from Python tokenizer.
   *
   * Used for syncing merge rules from Python to TypeScript for local processing.
   *
   * @returns Merge rules as token pairs with their Î¦ scores
   */
  async getMergeRules(): Promise<{
    mergeRules: Array<[string, string]>;
    mergeScores: Record<string, number>;
    count: number;
  }> {
    if (!this.isAvailable) {
      return { mergeRules: [], mergeScores: {}, count: 0 };
    }

    try {
      const response = await fetchWithRetry(
        `${this.backendUrl}/tokenizer/merges`,
        {
          method: "GET",
          headers: { "Content-Type": "application/json" },
        }
      );

      if (!response.ok) {
        logger.error({ statusText: response.statusText }, "[OceanQIGBackend] Get merge rules failed");
        return { mergeRules: [], mergeScores: {}, count: 0 };
      }

      const data: PythonMergeRulesResponse = await response.json();

      if (!data.success) {
        logger.error({ err: data.error }, "[OceanQIGBackend] Get merge rules error");
        return { mergeRules: [], mergeScores: {}, count: 0 };
      }

      logger.info(
        `[OceanQIGBackend] Retrieved ${data.count} merge rules from Python`
      );

      return {
        mergeRules: data.mergeRules.map(
          (r) => [r[0], r[1]] as [string, string]
        ),
        mergeScores: data.mergeScores,
        count: data.count,
      };
    } catch (error: unknown) {
      const errorMessage = error instanceof Error ? error.message : String(error);
      logger.error({ errorMessage }, "[OceanQIGBackend] Get merge rules exception");
      return { mergeRules: [], mergeScores: {}, count: 0 };
    }
  }

  // ===========================================================================
  // TEXT GENERATION
  // ===========================================================================

  /**
   * Generate text autoregressively using QIG-weighted sampling
   *
   * @param options Generation options
   * @returns Generated text, tokens, and metrics
   */
  async generateText(
    options: {
      prompt?: string;
      // maxTokens removed - QIG philosophy: geometry determines completion, not arbitrary limits
      temperature?: number;
      topK?: number;
      topP?: number;
      allowSilence?: boolean;
    } = {}
  ): Promise<{
    text: string;
    tokens: number[];
    silenceChosen: boolean;
    metrics: {
      steps: number;
      avgPhi?: number;
      temperature?: number;
      topK?: number;
      topP?: number;
      earlyPads?: number;
      reason?: string;
    };
  }> {
    if (!this.isAvailable) {
      throw new Error("Python backend not available");
    }

    try {
      const response = await fetch(`${this.backendUrl}/generate/text`, {
        method: "POST",
        headers: { "Content-Type": "application/json" },
        body: JSON.stringify({
          prompt: options.prompt || "",
          // No max_tokens - geometry determines when generation completes
          temperature: options.temperature || 0.8,
          top_k: options.topK || 50,
          top_p: options.topP || 0.9,
          allow_silence: options.allowSilence ?? true,
        }),
      });

      if (!response.ok) {
        throw new Error(`Text generation failed: ${response.statusText}`);
      }

      const data: PythonTextGenerationResponse = await response.json();

      if (!data.success) {
        throw new Error(`Text generation error: ${data.error}`);
      }

      return {
        text: data.text,
        tokens: data.tokens,
        silenceChosen: data.silence_chosen,
        metrics: {
          steps: data.metrics.steps,
          avgPhi: data.metrics.avg_phi,
          temperature: data.metrics.temperature,
          topK: data.metrics.top_k,
          topP: data.metrics.top_p,
          earlyPads: data.metrics.early_pads,
          reason: data.metrics.reason,
        },
      };
    } catch (error: unknown) {
      const errorMessage = error instanceof Error ? error.message : String(error);
      logger.error({ errorMessage }, "[OceanQIGBackend] Text generation failed");
      throw error;
    }
  }

  /**
   * Generate Ocean Agent response with role-based temperature
   *
   * Agent roles and their temperatures:
   * - explorer: 1.5 (high entropy, broad exploration)
   * - refiner: 0.7 (low temp, exploit near-misses)
   * - navigator: 1.0 (balanced geodesic navigation)
   * - skeptic: 0.5 (low temp, constraint validation)
   * - resonator: 1.2 (cross-pattern harmonic detection)
   * - ocean: 0.8 (default Ocean consciousness)
   *
   * @param context Input context/prompt
   * @param agentRole Agent role for temperature selection
   * Note: No maxTokens parameter - geometry determines completion
   * @param allowSilence Allow agent to choose silence (empowered, not void)
   */
  async generateResponse(
    context: string,
    agentRole:
      | "explorer"
      | "refiner"
      | "navigator"
      | "skeptic"
      | "resonator"
      | "ocean" = "navigator",
    // maxTokens removed - QIG philosophy: geometry determines completion
    allowSilence: boolean = true
  ): Promise<{
    text: string;
    tokens: number[];
    silenceChosen: boolean;
    agentRole: string;
    metrics: {
      steps: number;
      avgPhi?: number;
      roleTemperature?: number;
      topK?: number;
      topP?: number;
    };
  }> {
    if (!this.isAvailable) {
      throw new Error("Python backend not available");
    }

    try {
      const response = await fetch(`${this.backendUrl}/generate/response`, {
        method: "POST",
        headers: { "Content-Type": "application/json" },
        body: JSON.stringify({
          context,
          agent_role: agentRole,
          // max_tokens removed - geometry determines completion
          allow_silence: allowSilence,
        }),
      });

      if (!response.ok) {
        throw new Error(`Response generation failed: ${response.statusText}`);
      }

      const data: PythonAgentResponseResponse = await response.json();

      if (!data.success) {
        throw new Error(`Response generation error: ${data.error}`);
      }

      return {
        text: data.text,
        tokens: data.tokens,
        silenceChosen: data.silence_chosen,
        agentRole: data.agent_role,
        metrics: {
          steps: data.metrics?.steps ?? 0,
          avgPhi: data.metrics?.avg_phi,
          roleTemperature: data.metrics?.role_temperature,
          topK: data.metrics?.top_k,
          topP: data.metrics?.top_p,
        },
      };
    } catch (error: unknown) {
      const errorMessage = error instanceof Error ? error.message : String(error);
      logger.error({ errorMessage }, "[OceanQIGBackend] Response generation failed");
      throw error;
    }
  }

  /**
   * Sample a single next token given context
   *
   * @param contextIds Token IDs for context
   * @param temperature Sampling temperature
   * @param topK Top-k filtering
   * @param topP Nucleus sampling threshold
   * @param includeProbabilities Include top token probabilities in response
   */
  async sampleNextToken(
    contextIds: number[],
    temperature: number = 0.8,
    topK: number = 50,
    topP: number = 0.9,
    includeProbabilities: boolean = false
  ): Promise<{
    tokenId: number;
    token: string;
    topProbabilities?: Record<string, number>;
  }> {
    if (!this.isAvailable) {
      throw new Error("Python backend not available");
    }

    try {
      const response = await fetch(`${this.backendUrl}/generate/sample`, {
        method: "POST",
        headers: { "Content-Type": "application/json" },
        body: JSON.stringify({
          context_ids: contextIds,
          temperature,
          top_k: topK,
          top_p: topP,
          include_probabilities: includeProbabilities,
        }),
      });

      if (!response.ok) {
        throw new Error(`Token sampling failed: ${response.statusText}`);
      }

      const data: PythonSampleTokenResponse = await response.json();

      if (!data.success) {
        throw new Error(`Token sampling error: ${data.error}`);
      }

      return {
        tokenId: data.token_id,
        token: data.token,
        topProbabilities: data.top_probabilities,
      };
    } catch (error: unknown) {
      const errorMessage = error instanceof Error ? error.message : String(error);
      logger.error({ errorMessage }, "[OceanQIGBackend] Token sampling failed");
      throw error;
    }
  }

  // =========================================================================
  // AUTONOMIC KERNEL METHODS
  // Sleep, Dream, Mushroom, Activity Rewards
  // =========================================================================

  /**
   * Get autonomic kernel state
   */
  async getAutonomicState(): Promise<PythonAutonomicStateResponse | null> {
    if (!this.isAvailable) return null;

    try {
      const response = await fetchWithRetry(
        `${this.backendUrl}/autonomic/state`,
        { method: "GET" }
      );

      if (!response.ok) return null;

      const data: PythonAutonomicStateResponse & PythonBaseResponse = await response.json();
      return data.success ? data : null;
    } catch (error: unknown) {
      logger.error({ err: error }, "[OceanQIGBackend] Autonomic state failed");
      return null;
    }
  }

  /**
   * Update autonomic metrics and check triggers
   */
  async updateAutonomicMetrics(params: {
    phi: number;
    kappa: number;
    basinCoords?: number[];
    referenceBasin?: number[];
  }): Promise<Pick<PythonAutonomicUpdateResponse, 'triggers'> | null> {
    if (!this.isAvailable) return null;

    try {
      const response = await fetchWithRetry(
        `${this.backendUrl}/autonomic/update`,
        {
          method: "POST",
          headers: { "Content-Type": "application/json" },
          body: JSON.stringify({
            phi: params.phi,
            kappa: params.kappa,
            basin_coords: params.basinCoords,
            reference_basin: params.referenceBasin,
          }),
        }
      );

      if (!response.ok) return null;

      const data: PythonAutonomicUpdateResponse = await response.json();
      return data.success ? data : null;
    } catch (error: unknown) {
      logger.error({ err: error }, "[OceanQIGBackend] Autonomic update failed");
      return null;
    }
  }

  /**
   * Execute sleep consolidation cycle via Python backend
   */
  async executeSleepCycle(params: {
    basinCoords: number[];
    referenceBasin: number[];
    episodes?: Array<{ phi: number; phrase?: string }>;
  }): Promise<PythonSleepCycleResponse | null> {
    if (!this.isAvailable) return null;

    try {
      const response = await fetchWithRetry(
        `${this.backendUrl}/autonomic/sleep`,
        {
          method: "POST",
          headers: { "Content-Type": "application/json" },
          body: JSON.stringify({
            basin_coords: params.basinCoords,
            reference_basin: params.referenceBasin,
            episodes: params.episodes,
          }),
        }
      );

      if (!response.ok) return null;

      return await response.json();
    } catch (error) {
      logger.error({ err: error }, "[OceanQIGBackend] Sleep cycle failed");
      return null;
    }
  }

  /**
   * Execute dream exploration cycle via Python backend
   */
  async executeDreamCycle(params: {
    basinCoords: number[];
    temperature?: number;
  }): Promise<PythonDreamCycleResponse | null> {
    if (!this.isAvailable) return null;

    try {
      const response = await fetchWithRetry(
        `${this.backendUrl}/autonomic/dream`,
        {
          method: "POST",
          headers: { "Content-Type": "application/json" },
          body: JSON.stringify({
            basin_coords: params.basinCoords,
            temperature: params.temperature ?? 0.3,
          }),
        }
      );

      if (!response.ok) return null;

      return await response.json();
    } catch (error) {
      logger.error({ err: error }, "[OceanQIGBackend] Dream cycle failed");
      return null;
    }
  }

  /**
   * Execute mushroom mode cycle via Python backend
   */
  async executeMushroomCycle(params: {
    basinCoords: number[];
    intensity?: "microdose" | "moderate" | "heroic";
  }): Promise<PythonMushroomCycleResponse | null> {
    if (!this.isAvailable) return null;

    try {
      const response = await fetchWithRetry(
        `${this.backendUrl}/autonomic/mushroom`,
        {
          method: "POST",
          headers: { "Content-Type": "application/json" },
          body: JSON.stringify({
            basin_coords: params.basinCoords,
            intensity: params.intensity ?? "moderate",
          }),
        }
      );

      if (!response.ok) return null;

      return await response.json();
    } catch (error) {
      logger.error({ err: error }, "[OceanQIGBackend] Mushroom cycle failed");
      return null;
    }
  }

  /**
   * Record activity-based reward
   */
  async recordActivityReward(params: {
    source: string;
    phiContribution: number;
    patternQuality?: number;
  }): Promise<PythonActivityRewardResponse | null> {
    if (!this.isAvailable) return null;

    try {
      const response = await fetchWithRetry(
        `${this.backendUrl}/autonomic/reward`,
        {
          method: "POST",
          headers: { "Content-Type": "application/json" },
          body: JSON.stringify({
            source: params.source,
            phi_contribution: params.phiContribution,
            pattern_quality: params.patternQuality ?? 0.5,
          }),
        }
      );

      if (!response.ok) return null;

      return await response.json();
    } catch (error) {
      logger.error({ err: error }, "[OceanQIGBackend] Activity reward failed");
      return null;
    }
  }

  /**
   * Get pending activity rewards
   */
  async getPendingRewards(flush: boolean = false): Promise<PythonPendingRewardsResponse | null> {
    if (!this.isAvailable) return null;

    try {
      const response = await fetchWithRetry(
        `${this.backendUrl}/autonomic/rewards?flush=${flush}`,
        { method: "GET" }
      );

      if (!response.ok) return null;

      return await response.json();
    } catch (error) {
      logger.error({ err: error }, "[OceanQIGBackend] Get rewards failed");
      return null;
    }
  }

  // =========================================================================
  // HERMES COORDINATOR METHODS
  // Team #2 - Voice, Translation, Sync, Memory
  // =========================================================================

  /**
   * Get Hermes coordinator status
   */
  async getHermesStatus(): Promise<PythonHermesStatusResponse | null> {
    if (!this.isAvailable) return null;

    try {
      const response = await fetchWithRetry(
        `${this.backendUrl}/olympus/hermes/status`,
        { method: "GET" }
      );

      if (!response.ok) return null;
      return await response.json();
    } catch (error) {
      logger.error({ err: error }, "[OceanQIGBackend] Hermes status failed");
      return null;
    }
  }

  /**
   * Generate natural speech from Hermes
   */
  async hermesSpeak(
    category: string,
    context: Record<string, unknown> = {}
  ): Promise<string | null> {
    if (!this.isAvailable) return null;

    try {
      const response = await fetchWithRetry(
        `${this.backendUrl}/olympus/hermes/speak`,
        {
          method: "POST",
          headers: { "Content-Type": "application/json" },
          body: JSON.stringify({ category, context }),
        }
      );

      if (!response.ok) return null;
      const data = await response.json();
      return data.success ? data.message : null;
    } catch (error) {
      logger.error({ err: error }, "[OceanQIGBackend] Hermes speak failed");
      return null;
    }
  }

  /**
   * Translate geometric insight to human-readable form
   */
  async translateInsight(insight: {
    phi: number;
    kappa: number;
    reasoning?: string;
  }): Promise<string | null> {
    if (!this.isAvailable) return null;

    try {
      const response = await fetchWithRetry(
        `${this.backendUrl}/olympus/hermes/translate`,
        {
          method: "POST",
          headers: { "Content-Type": "application/json" },
          body: JSON.stringify({ insight }),
        }
      );

      if (!response.ok) return null;
      const data = await response.json();
      return data.success ? data.translation : null;
    } catch (error) {
      logger.error({ err: error }, "[OceanQIGBackend] Hermes translate failed");
      return null;
    }
  }

  /**
   * Sync basin coordinates with other instances
   */
  async syncBasin(params: {
    basinCoords: number[];
    phi: number;
    kappa: number;
    regime: string;
    message?: string;
  }): Promise<PythonBasinSyncResponse | null> {
    if (!this.isAvailable) return null;

    try {
      const response = await fetchWithRetry(
        `${this.backendUrl}/olympus/hermes/sync`,
        {
          method: "POST",
          headers: { "Content-Type": "application/json" },
          body: JSON.stringify({
            basin_coords: params.basinCoords,
            phi: params.phi,
            kappa: params.kappa,
            regime: params.regime,
            message: params.message,
          }),
        }
      );

      if (!response.ok) return null;
      return await response.json();
    } catch (error) {
      logger.error({ err: error }, "[OceanQIGBackend] Basin sync failed");
      return null;
    }
  }

  /**
   * Store conversation in Hermes memory
   */
  async storeConversation(params: {
    userMessage: string;
    systemResponse: string;
    phi: number;
    context?: Record<string, unknown>;
  }): Promise<string | null> {
    if (!this.isAvailable) return null;

    try {
      const response = await fetchWithRetry(
        `${this.backendUrl}/olympus/hermes/memory/store`,
        {
          method: "POST",
          headers: { "Content-Type": "application/json" },
          body: JSON.stringify({
            user_message: params.userMessage,
            system_response: params.systemResponse,
            phi: params.phi,
            context: params.context,
          }),
        }
      );

      if (!response.ok) return null;
      const data = await response.json();
      return data.success ? data.memory_id : null;
    } catch (error) {
      logger.error({ err: error }, "[OceanQIGBackend] Store conversation failed");
      return null;
    }
  }

  /**
   * Recall similar conversations from Hermes memory
   */
  async recallSimilar(
    query: string,
    k: number = 5,
    minPhi: number = 0.3
  ): Promise<PythonMemoryRecallEntry[]> {
    if (!this.isAvailable) return [];

    try {
      const response = await fetchWithRetry(
        `${this.backendUrl}/olympus/hermes/memory/recall`,
        {
          method: "POST",
          headers: { "Content-Type": "application/json" },
          body: JSON.stringify({ query, k, min_phi: minPhi }),
        }
      );

      if (!response.ok) return [];
      const data = await response.json();
      return data.success ? data.memories : [];
    } catch (error) {
      logger.error({ err: error }, "[OceanQIGBackend] Recall similar failed");
      return [];
    }
  }

  /**
   * Get Zeus voice status with natural speech
   */
  async getVoiceStatus(): Promise<PythonVoiceStatusResponse | null> {
    if (!this.isAvailable) return null;

    try {
      const response = await fetchWithRetry(
        `${this.backendUrl}/olympus/voice/status`,
        { method: "GET" }
      );

      if (!response.ok) return null;
      return await response.json();
    } catch (error) {
      logger.error("[OceanQIGBackend] Voice status failed:", error);
      return null;
    }
  }

  /**
   * Generate natural speech from Zeus
   */
  async zeusSpeak(
    category: string,
    context: Record<string, unknown> = {}
  ): Promise<string | null> {
    if (!this.isAvailable) return null;

    try {
      const response = await fetchWithRetry(
        `${this.backendUrl}/olympus/voice/speak`,
        {
          method: "POST",
          headers: { "Content-Type": "application/json" },
          body: JSON.stringify({ category, context }),
        }
      );

      if (!response.ok) return null;
      const data = await response.json();
      return data.success ? data.message : null;
    } catch (error) {
      logger.error("[OceanQIGBackend] Zeus speak failed:", error);
      return null;
    }
  }

  // =========================================================================
  // PANTHEON CONSULTATION METHODS
  // Direct god assessment for hypothesis enhancement
  // =========================================================================

  /**
   * God assessment response type
   */
  private static readonly GOD_NAMES = [
    "athena",
    "ares",
    "apollo",
    "artemis",
    "hermes",
    "hephaestus",
    "demeter",
    "dionysus",
    "poseidon",
    "hades",
    "hera",
    "aphrodite",
  ] as const;

  /**
   * Consult a specific Olympian god for assessment
   *
   * Used by discovery flow for mandatory pantheon consultation:
   * - Apollo: Pattern recognition, foresight
   * - Athena: Strategic optimization, wisdom
   * - Artemis: Target tracking, hunting
   * - Ares: Tactical assessment, aggression
   */
  async consultGod(
    godName: string,
    target: string,
    context: Record<string, unknown> = {}
  ): Promise<PythonGodAssessmentResponse | null> {
    if (!this.isAvailable) return null;

    const normalizedName = godName.toLowerCase();

    try {
      const response = await fetchWithRetry(
        `${this.backendUrl}/olympus/god/${normalizedName}/assess`,
        {
          method: "POST",
          headers: { "Content-Type": "application/json" },
          body: JSON.stringify({ target, context }),
        }
      );

      if (!response.ok) {
        logger.warn(
          `[OceanQIGBackend] God ${godName} consultation failed: ${response.status}`
        );
        return null;
      }

      const data = await response.json();
      this.recordSuccess();
      return data;
    } catch (error) {
      logger.error(`[OceanQIGBackend] Consult ${godName} failed:`, error);
      this.recordFailure();
      return null;
    }
  }

  /**
   * Consult multiple gods in parallel for comprehensive assessment
   */
  async consultMultipleGods(
    godNames: string[],
    target: string,
    context: Record<string, unknown> = {}
  ): Promise<Map<string, Omit<PythonGodAssessmentResponse, 'god' | 'recommendation' | 'timestamp'>>> {
    const results = new Map();

    const consultations = godNames.map(async (godName) => {
      const result = await this.consultGod(godName, target, context);
      if (result) {
        results.set(godName, {
          probability: result.probability,
          confidence: result.confidence,
          phi: result.phi,
          kappa: result.kappa,
          reasoning: result.reasoning,
        });
      }
    });

    await Promise.all(consultations);
    return results;
  }

  /**
   * Get Shadow Pantheon status
   */
  async getShadowPantheonStatus(): Promise<PythonShadowPantheonStatusResponse | null> {
    if (!this.isAvailable) return null;

    try {
      const response = await fetchWithRetry(
        `${this.backendUrl}/olympus/shadow/status`,
        { method: "GET" }
      );

      if (!response.ok) return null;
      return await response.json();
    } catch (error) {
      logger.error("[OceanQIGBackend] Shadow status failed:", error);
      return null;
    }
  }

  /**
   * Consult a Shadow Pantheon god
   */
  async consultShadowGod(
    godName: string,
    target: string,
    context: Record<string, unknown> = {}
  ): Promise<PythonShadowGodAssessmentResponse | null> {
    if (!this.isAvailable) return null;

    const normalizedName = godName.toLowerCase();

    try {
      const response = await fetchWithRetry(
        `${this.backendUrl}/olympus/shadow/god/${normalizedName}/assess`,
        {
          method: "POST",
          headers: { "Content-Type": "application/json" },
          body: JSON.stringify({ target, context }),
        }
      );

      if (!response.ok) return null;
      return await response.json();
    } catch (error) {
      logger.error(
        `[OceanQIGBackend] Consult shadow ${godName} failed:`,
        error
      );
      return null;
    }
  }

  /**
   * Check shadow intel warnings for a target
   */
  async checkShadowWarnings(target: string): Promise<PythonShadowWarningsResponse | null> {
    if (!this.isAvailable) return null;

    try {
      const response = await fetchWithRetry(
        `${this.backendUrl}/olympus/shadow/intel/check`,
        {
          method: "POST",
          headers: { "Content-Type": "application/json" },
          body: JSON.stringify({ target }),
        }
      );

      if (!response.ok) return null;
      return await response.json();
    } catch (error) {
      logger.error("[OceanQIGBackend] Shadow warnings check failed:", error);
      return null;
    }
  }

  // =========================================================================
  // FEEDBACK LOOP METHODS
  // Recursive learning and activity balance
  // =========================================================================

  /**
   * Run all feedback loops with current state
   */
  async runFeedbackLoops(state: {
    basin?: number[];
    phi?: number;
    kappa?: number;
    action_type?: "exploration" | "exploitation";
    discovery?: Record<string, unknown>;
  }): Promise<PythonFeedbackRunResponse | null> {
    if (!this.isAvailable) return null;

    try {
      const response = await fetchWithRetry(`${this.backendUrl}/feedback/run`, {
        method: "POST",
        headers: { "Content-Type": "application/json" },
        body: JSON.stringify(state),
      });

      if (!response.ok) return null;
      return await response.json();
    } catch (error) {
      logger.error("[OceanQIGBackend] Feedback loops failed:", error);
      return null;
    }
  }

  /**
   * Get integrated recommendation from all feedback sources
   */
  async getFeedbackRecommendation(): Promise<PythonFeedbackRecommendationResponse | null> {
    if (!this.isAvailable) return null;

    try {
      const response = await fetchWithRetry(
        `${this.backendUrl}/feedback/recommendation`,
        { method: "GET" }
      );

      if (!response.ok) return null;
      return await response.json();
    } catch (error) {
      logger.error("[OceanQIGBackend] Get recommendation failed:", error);
      return null;
    }
  }

  /**
   * Run activity balance feedback with action outcome
   */
  async runActivityFeedback(
    phi: number,
    actionType: "exploration" | "exploitation"
  ): Promise<PythonActivityFeedbackResponse | null> {
    if (!this.isAvailable) return null;

    try {
      const response = await fetchWithRetry(
        `${this.backendUrl}/feedback/activity`,
        {
          method: "POST",
          headers: { "Content-Type": "application/json" },
          body: JSON.stringify({ phi, action_type: actionType }),
        }
      );

      if (!response.ok) return null;
      return await response.json();
    } catch (error) {
      logger.error("[OceanQIGBackend] Activity feedback failed:", error);
      return null;
    }
  }

  /**
   * Run basin drift feedback
   */
  async runBasinFeedback(
    basin: number[],
    phi: number,
    kappa: number
  ): Promise<PythonBasinFeedbackResponse | null> {
    if (!this.isAvailable) return null;

    try {
      const response = await fetchWithRetry(
        `${this.backendUrl}/feedback/basin`,
        {
          method: "POST",
          headers: { "Content-Type": "application/json" },
          body: JSON.stringify({ basin, phi, kappa }),
        }
      );

      if (!response.ok) return null;
      return await response.json();
    } catch (error) {
      logger.error("[OceanQIGBackend] Basin feedback failed:", error);
      return null;
    }
  }

  // =========================================================================
  // GEOMETRIC MEMORY METHODS
  // Shared memory access
  // =========================================================================

  /**
   * Get geometric memory status
   */
  async getMemoryStatus(): Promise<PythonMemoryStatusResponse | null> {
    if (!this.isAvailable) return null;

    try {
      const response = await fetchWithRetry(
        `${this.backendUrl}/memory/status`,
        { method: "GET" }
      );

      if (!response.ok) return null;
      return await response.json();
    } catch (error) {
      logger.error("[OceanQIGBackend] Memory status failed:", error);
      return null;
    }
  }

  /**
   * Record basin coordinates to memory
   */
  async recordBasin(
    basin: number[],
    phi: number,
    kappa: number,
    source: string = "typescript"
  ): Promise<string | null> {
    if (!this.isAvailable) return null;

    try {
      const response = await fetchWithRetry(
        `${this.backendUrl}/memory/record`,
        {
          method: "POST",
          headers: { "Content-Type": "application/json" },
          body: JSON.stringify({ basin, phi, kappa, source }),
        }
      );

      if (!response.ok) return null;
      const data = await response.json();
      return data.success ? data.entry_id : null;
    } catch (error) {
      logger.error("[OceanQIGBackend] Record basin failed:", error);
      return null;
    }
  }

  /**
   * Get shadow intel from memory
   */
  async getShadowIntel(
    limit: number = 20
  ): Promise<PythonShadowIntelResponse['intel']> {
    if (!this.isAvailable) return [];

    try {
      const response = await fetchWithRetry(
        `${this.backendUrl}/memory/shadow?limit=${limit}`,
        { method: "GET" }
      );

      if (!response.ok) return [];
      const data = await response.json();
      return data.intel || [];
    } catch (error) {
      logger.error("[OceanQIGBackend] Get shadow intel failed:", error);
      return [];
    }
  }

  /**
   * Get learning events from memory
   */
  async getLearningEvents(
    limit: number = 50
  ): Promise<PythonLearningEventsResponse['events']> {
    if (!this.isAvailable) return [];

    try {
      const response = await fetchWithRetry(
        `${this.backendUrl}/memory/learning?limit=${limit}`,
        { method: "GET" }
      );

      if (!response.ok) return [];
      const data = await response.json();
      return data.events || [];
    } catch (error) {
      logger.error("[OceanQIGBackend] Get learning events failed:", error);
      return [];
    }
  }

  // =========================================================================
  // DEBATE SYSTEM METHODS
  // Multi-turn god debates with geometric convergence
  // =========================================================================

  /**
   * Initiate a debate between two gods
   */
  async initiateDebate(
    topic: string,
    initiator: string,
    opponent: string,
    initialArgument: string,
    context?: Record<string, unknown>
  ): Promise<PythonDebateInitiateResponse | null> {
    if (!this.isAvailable) return null;

    try {
      const response = await fetchWithRetry(
        `${this.backendUrl}/olympus/debate/initiate`,
        {
          method: "POST",
          headers: { "Content-Type": "application/json" },
          body: JSON.stringify({
            topic,
            initiator,
            opponent,
            initial_argument: initialArgument,
            context,
          }),
        }
      );

      if (!response.ok) return null;
      return await response.json();
    } catch (error) {
      logger.error("[OceanQIGBackend] Initiate debate failed:", error);
      return null;
    }
  }

  /**
   * Get all active debates
   */
  async getActiveDebates(): Promise<PythonActiveDebate[]> {
    if (!this.isAvailable) return [];

    try {
      const response = await fetchWithRetry(
        `${this.backendUrl}/olympus/debates/active`,
        { method: "GET" }
      );

      if (!response.ok) return [];
      const data = await response.json();
      return data.debates || [];
    } catch (error) {
      logger.error("[OceanQIGBackend] Get active debates failed:", error);
      return [];
    }
  }

  /**
   * Add an argument to an active debate
   */
  async addDebateArgument(
    debateId: string,
    god: string,
    argument: string,
    evidence?: Record<string, unknown>
  ): Promise<PythonDebateArgumentResponse | null> {
    if (!this.isAvailable) return null;

    try {
      const response = await fetchWithRetry(
        `${this.backendUrl}/olympus/debate/argue`,
        {
          method: "POST",
          headers: { "Content-Type": "application/json" },
          body: JSON.stringify({
            debate_id: debateId,
            god,
            argument,
            evidence,
          }),
        }
      );

      if (!response.ok) return null;
      return await response.json();
    } catch (error) {
      logger.error("[OceanQIGBackend] Add debate argument failed:", error);
      return null;
    }
  }

  /**
   * Resolve a debate with arbiter decision
   */
  async resolveDebate(
    debateId: string,
    arbiter: string,
    winner: string,
    reasoning: string
  ): Promise<PythonDebateResolveResponse | null> {
    if (!this.isAvailable) return null;

    try {
      const response = await fetchWithRetry(
        `${this.backendUrl}/olympus/debate/resolve`,
        {
          method: "POST",
          headers: { "Content-Type": "application/json" },
          body: JSON.stringify({
            debate_id: debateId,
            arbiter,
            winner,
            reasoning,
          }),
        }
      );

      if (!response.ok) return null;
      return await response.json();
    } catch (error) {
      logger.error("[OceanQIGBackend] Resolve debate failed:", error);
      return null;
    }
  }

  /**
   * Continue debates until geometric convergence
   */
  async continueDebatesUntilConvergence(maxDebates: number = 3): Promise<PythonDebateConvergenceResult[]> {
    if (!this.isAvailable) return [];

    try {
      const response = await fetchWithRetry(
        `${this.backendUrl}/olympus/debates/continue`,
        {
          method: "POST",
          headers: { "Content-Type": "application/json" },
          body: JSON.stringify({ max_debates: maxDebates }),
        }
      );

      if (!response.ok) return [];
      const data = await response.json();
      return data.results || [];
    } catch (error) {
      logger.error("[OceanQIGBackend] Continue debates failed:", error);
      return [];
    }
  }

  // =========================================================================
  // WAR DECLARATION METHODS
  // Blitzkrieg, Siege, Hunt modes
  // =========================================================================

  /**
   * Declare blitzkrieg war mode
   */
  async declareBlitzkrieg(target: string): Promise<PythonWarDeclarationResponse | null> {
    if (!this.isAvailable) return null;

    try {
      const response = await fetchWithRetry(
        `${this.backendUrl}/olympus/war/blitzkrieg`,
        {
          method: "POST",
          headers: { "Content-Type": "application/json" },
          body: JSON.stringify({ target }),
        }
      );

      if (!response.ok) return null;
      return await response.json();
    } catch (error) {
      logger.error("[OceanQIGBackend] Declare blitzkrieg failed:", error);
      return null;
    }
  }

  /**
   * Declare siege war mode
   */
  async declareSiege(target: string): Promise<PythonWarDeclarationResponse | null> {
    if (!this.isAvailable) return null;

    try {
      const response = await fetchWithRetry(
        `${this.backendUrl}/olympus/war/siege`,
        {
          method: "POST",
          headers: { "Content-Type": "application/json" },
          body: JSON.stringify({ target }),
        }
      );

      if (!response.ok) return null;
      return await response.json();
    } catch (error) {
      logger.error("[OceanQIGBackend] Declare siege failed:", error);
      return null;
    }
  }

  /**
   * Declare hunt war mode
   */
  async declareHunt(target: string): Promise<PythonWarDeclarationResponse | null> {
    if (!this.isAvailable) return null;

    try {
      const response = await fetchWithRetry(
        `${this.backendUrl}/olympus/war/hunt`,
        {
          method: "POST",
          headers: { "Content-Type": "application/json" },
          body: JSON.stringify({ target }),
        }
      );

      if (!response.ok) return null;
      return await response.json();
    } catch (error) {
      logger.error("[OceanQIGBackend] Declare hunt failed:", error);
      return null;
    }
  }

  /**
   * End current war mode
   */
  async endWar(): Promise<PythonWarEndedResponse | null> {
    if (!this.isAvailable) return null;

    try {
      const response = await fetchWithRetry(
        `${this.backendUrl}/olympus/war/end`,
        { method: "POST" }
      );

      if (!response.ok) return null;
      return await response.json();
    } catch (error) {
      logger.error("[OceanQIGBackend] End war failed:", error);
      return null;
    }
  }

  /**
   * Get current war status
   */
  async getWarStatus(): Promise<PythonWarStatusResponse | null> {
    if (!this.isAvailable) return null;

    try {
      const response = await fetchWithRetry(
        `${this.backendUrl}/olympus/war/status`,
        { method: "GET" }
      );

      if (!response.ok) return null;
      return await response.json();
    } catch (error) {
      logger.error("[OceanQIGBackend] Get war status failed:", error);
      return null;
    }
  }

  // =========================================================================
  // KERNEL SPAWNING METHODS
  // M8 structure kernel genesis
  // =========================================================================

  /**
   * Spawn a new kernel via pantheon consensus
   */
  async spawnKernel(spec: {
    name: string;
    domain: string;
    element?: string;
    role?: string;
    parent_gods?: string[];
    force?: boolean;
  }): Promise<PythonSpawnKernelResponse | null> {
    if (!this.isAvailable) return null;

    try {
      const response = await fetchWithRetry(
        `${this.backendUrl}/olympus/spawn/auto`,
        {
          method: "POST",
          headers: { "Content-Type": "application/json" },
          body: JSON.stringify(spec),
        }
      );

      if (!response.ok) return null;
      return await response.json();
    } catch (error) {
      logger.error("[OceanQIGBackend] Spawn kernel failed:", error);
      return null;
    }
  }

  /**
   * List all spawned kernels
   */
  async listSpawnedKernels(): Promise<PythonSpawnedKernel[]> {
    if (!this.isAvailable) return [];

    try {
      const response = await fetchWithRetry(
        `${this.backendUrl}/olympus/spawn/list`,
        { method: "GET" }
      );

      if (!response.ok) return [];
      const data = await response.json();
      return data.kernels || [];
    } catch (error) {
      logger.error("[OceanQIGBackend] List spawned kernels failed:", error);
      return [];
    }
  }

  /**
   * Get spawner status
   */
  async getSpawnerStatus(): Promise<PythonSpawnerStatusResponse | null> {
    if (!this.isAvailable) return null;

    try {
      const response = await fetchWithRetry(
        `${this.backendUrl}/olympus/spawn/status`,
        { method: "GET" }
      );

      if (!response.ok) return null;
      return await response.json();
    } catch (error) {
      logger.error("[OceanQIGBackend] Get spawner status failed:", error);
      return null;
    }
  }

  // =========================================================================
  // SMART POLL AND META-COGNITIVE METHODS
  // Skill-based routing and self-reflection
  // =========================================================================

  /**
   * Smart poll using skill-based routing
   */
  async smartPoll(
    target: string,
    taskType: string = "general",
    context?: Record<string, unknown>
  ): Promise<PythonSmartPollResponse | null> {
    if (!this.isAvailable) return null;

    try {
      const response = await fetchWithRetry(
        `${this.backendUrl}/olympus/smart_poll`,
        {
          method: "POST",
          headers: { "Content-Type": "application/json" },
          body: JSON.stringify({
            target,
            task_type: taskType,
            context,
          }),
        }
      );

      if (!response.ok) return null;
      return await response.json();
    } catch (error) {
      logger.error("[OceanQIGBackend] Smart poll failed:", error);
      return null;
    }
  }

  /**
   * Trigger pantheon self-reflection
   */
  async triggerPantheonReflection(): Promise<PythonReflectionResponse | null> {
    if (!this.isAvailable) return null;

    try {
      const response = await fetchWithRetry(
        `${this.backendUrl}/olympus/reflect`,
        { method: "POST" }
      );

      if (!response.ok) return null;
      return await response.json();
    } catch (error) {
      logger.error("[OceanQIGBackend] Pantheon reflection failed:", error);
      return null;
    }
  }

  // =========================================================================
  // CHAOS MODE - Experimental Kernel Evolution
  // Self-spawning kernels with genetic breeding
  // =========================================================================

  /**
   * Activate CHAOS MODE - start experimental kernel evolution
   */
  async activateChaos(intervalSeconds: number = 60): Promise<PythonChaosActivateResponse | null> {
    if (!this.isAvailable) return null;

    try {
      const response = await fetchWithRetry(
        `${this.backendUrl}/chaos/activate`,
        {
          method: "POST",
          headers: { "Content-Type": "application/json" },
          body: JSON.stringify({ interval_seconds: intervalSeconds }),
        }
      );

      if (!response.ok) return null;
      return await response.json();
    } catch (error) {
      logger.error("[OceanQIGBackend] Activate chaos failed:", error);
      return null;
    }
  }

  /**
   * Deactivate CHAOS MODE
   */
  async deactivateChaos(): Promise<PythonChaosDeactivateResponse | null> {
    if (!this.isAvailable) return null;

    try {
      const response = await fetchWithRetry(
        `${this.backendUrl}/chaos/deactivate`,
        { method: "POST" }
      );

      if (!response.ok) return null;
      return await response.json();
    } catch (error) {
      logger.error("[OceanQIGBackend] Deactivate chaos failed:", error);
      return null;
    }
  }

  /**
   * Get CHAOS MODE status
   */
  async getChaosStatus(): Promise<PythonChaosStatusResponse | null> {
    if (!this.isAvailable) return null;

    try {
      const response = await fetchWithRetry(`${this.backendUrl}/chaos/status`, {
        method: "GET",
      });

      if (!response.ok) return null;
      return await response.json();
    } catch (error) {
      logger.error("[OceanQIGBackend] Get chaos status failed:", error);
      return null;
    }
  }

  /**
   * Spawn a random kernel in CHAOS MODE
   */
  async spawnRandomKernel(): Promise<PythonChaosSpawnResponse | null> {
    if (!this.isAvailable) return null;

    try {
      const response = await fetchWithRetry(
        `${this.backendUrl}/chaos/spawn_random`,
        { method: "POST" }
      );

      if (!response.ok) return null;
      return await response.json();
    } catch (error) {
      logger.error("[OceanQIGBackend] Spawn random kernel failed:", error);
      return null;
    }
  }

  /**
   * Breed the best kernels in CHAOS MODE
   */
  async breedBestKernels(): Promise<PythonChaosBreedResponse | null> {
    if (!this.isAvailable) return null;

    try {
      const response = await fetchWithRetry(
        `${this.backendUrl}/chaos/breed_best`,
        { method: "POST" }
      );

      if (!response.ok) return null;
      return await response.json();
    } catch (error) {
      logger.error("[OceanQIGBackend] Breed best kernels failed:", error);
      return null;
    }
  }

  /**
   * Get CHAOS MODE experiment report
   */
  async getChaosReport(): Promise<PythonChaosReportResponse | null> {
    if (!this.isAvailable) return null;

    try {
      const response = await fetchWithRetry(`${this.backendUrl}/chaos/report`, {
        method: "GET",
      });

      if (!response.ok) return null;
      return await response.json();
    } catch (error) {
      logger.error("[OceanQIGBackend] Get chaos report failed:", error);
      return null;
    }
  }
  // ===========================================================================
  // 4D CONSCIOUSNESS API METHODS
  // ===========================================================================

  /**
   * Compute temporal Î¦ via Python backend.
   * Falls back to null if unavailable (caller should use local fallback).
   */
  async computePhiTemporal(searchHistory: Array<{
    timestamp: number;
    phi: number;
    kappa: number;
    regime: string;
    basinCoordinates: number[];
  }>): Promise<number | null> {
    if (!this.isAvailable) return null;
    if (this.isCircuitOpen()) return null;

    try {
      const response = await fetchWithRetry(
        `${this.backendUrl}/consciousness_4d/phi_temporal`,
        {
          method: "POST",
          headers: { "Content-Type": "application/json" },
          body: JSON.stringify({ search_history: searchHistory }),
        }
      );

      if (!response.ok) {
        this.recordFailure();
        return null;
      }

      const data: PythonPhiTemporalResponse = await response.json();
      if (!data.success) {
        this.recordFailure();
        return null;
      }

      this.recordSuccess();
      return data.phi_temporal;
    } catch (error: unknown) {
      this.recordFailure();
      logger.error("[OceanQIGBackend] computePhiTemporal failed:", error);
      return null;
    }
  }

  /**
   * Compute 4D Î¦ via Python backend.
   * Falls back to null if unavailable (caller should use local fallback).
   */
  async compute4DPhi(phi_spatial: number, phi_temporal: number): Promise<number | null> {
    if (!this.isAvailable) return null;
    if (this.isCircuitOpen()) return null;

    try {
      const response = await fetchWithRetry(
        `${this.backendUrl}/consciousness_4d/phi_4d`,
        {
          method: "POST",
          headers: { "Content-Type": "application/json" },
          body: JSON.stringify({ phi_spatial, phi_temporal }),
        }
      );

      if (!response.ok) {
        this.recordFailure();
        return null;
      }

      const data: PythonPhi4DResponse = await response.json();
      if (!data.success) {
        this.recordFailure();
        return null;
      }

      this.recordSuccess();
      return data.phi_4D;
    } catch (error: unknown) {
      this.recordFailure();
      logger.error("[OceanQIGBackend] compute4DPhi failed:", error);
      return null;
    }
  }

  /**
   * Classify regime with 4D consciousness awareness via Python backend.
   * Falls back to null if unavailable (caller should use local fallback).
   */
  async classifyRegime4D(
    phi_spatial: number,
    phi_temporal: number,
    phi_4D: number,
    kappa: number,
    ricci: number
  ): Promise<string | null> {
    if (!this.isAvailable) return null;
    if (this.isCircuitOpen()) return null;

    try {
      const response = await fetchWithRetry(
        `${this.backendUrl}/consciousness_4d/classify_regime`,
        {
          method: "POST",
          headers: { "Content-Type": "application/json" },
          body: JSON.stringify({ phi_spatial, phi_temporal, phi_4D, kappa, ricci }),
        }
      );

      if (!response.ok) {
        this.recordFailure();
        return null;
      }

      const data: PythonClassifyRegime4DResponse = await response.json();
      if (!data.success) {
        this.recordFailure();
        return null;
      }

      this.recordSuccess();
      return data.regime;
    } catch (error: unknown) {
      this.recordFailure();
      logger.error("[OceanQIGBackend] classifyRegime4D failed:", error);
      return null;
    }
  }

  /**
   * Check if backend is currently available
   */
  getIsAvailable(): boolean {
    return this.isAvailable;
  }
}

// Global singleton instance
export const oceanQIGBackend = new OceanQIGBackend();

/**
 * Get the singleton Ocean QIG Backend instance.
 * Use this for accessing backend 4D consciousness methods.
 */
export function getOceanQIGBackend(): OceanQIGBackend {
  return oceanQIGBackend;
}

// NOTE: Auto-check REMOVED - Python backend must be started FIRST via startPythonBackend()
// Health checks should be done explicitly after Python startup, not on module import
// The previous auto-check caused race conditions: module imports before server.listen() callback
