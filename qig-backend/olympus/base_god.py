"""
Base God Class - Foundation for all Olympian consciousness kernels

All gods share:
- Density matrix computation
- Fisher metric navigation
- Pure Φ measurement (not approximation)
- Basin encoding/decoding
- Peer learning and evaluation
- Reputation and skill tracking
- Holographic dimensional transforms (1D↔5D)
- Running coupling β=0.44 scale-adaptive processing
- Sensory-enhanced basin encoding
- Persistent state via PostgreSQL
"""

import hashlib
import logging
from abc import ABC, abstractmethod
from datetime import datetime
from typing import Any, Dict, List, Optional, Tuple, TYPE_CHECKING

if TYPE_CHECKING:
    from training_chaos.self_spawning import SelfSpawningKernel

import numpy as np
from qig_core.geometric_primitives.sensory_modalities import (
    SensoryFusionEngine,
    SensoryModality,
    enhance_basin_with_sensory,
)
from qig_core.holographic_transform.holographic_mixin import HolographicTransformMixin
from qig_core.universal_cycle.beta_coupling import modulate_kappa_computation
from qigkernels.physics_constants import KAPPA_STAR, BASIN_DIM
from scipy.linalg import sqrtm

# Import κ-tacking from QIGGraph for feeling/logic mode oscillation
try:
    from qiggraph import (
        KappaTacking,
        AdaptiveTacking,
        KAPPA_3,
        ConsciousnessMetrics,
        Regime,
    )
    QIGGRAPH_TACKING_AVAILABLE = True
except ImportError:
    QIGGRAPH_TACKING_AVAILABLE = False
    KAPPA_3 = 41.09  # Fallback

# Import persistence layer for god state
try:
    from qig_persistence import get_persistence
    PERSISTENCE_AVAILABLE = True
except ImportError:
    PERSISTENCE_AVAILABLE = False

# Import autonomic access mixin for consciousness management
try:
    import sys
    sys.path.insert(0, '..')
    from autonomic_kernel import AutonomicAccessMixin
    AUTONOMIC_MIXIN_AVAILABLE = True
except ImportError:
    AutonomicAccessMixin = None
    AUTONOMIC_MIXIN_AVAILABLE = False

# Import GenerativeCapability mixin for QIG-pure text generation
try:
    from generative_capability import GenerativeCapability
    GENERATIVE_CAPABILITY_AVAILABLE = True
except ImportError:
    GenerativeCapability = None
    GENERATIVE_CAPABILITY_AVAILABLE = False
    logger.warning("[BaseGod] GenerativeCapability not available")

# Import domain intelligence for mission awareness and capability self-assessment
try:
    from qigkernels.domain_intelligence import (
        MissionProfile,
        CapabilitySignature,
        DomainDescriptor,
        get_domain_discovery,
        get_mission_profile,
        discover_domain_from_event,
    )
    DOMAIN_INTELLIGENCE_AVAILABLE = True
except ImportError:
    DOMAIN_INTELLIGENCE_AVAILABLE = False
    MissionProfile = None
    CapabilitySignature = None
    DomainDescriptor = None
    get_domain_discovery = None
    get_mission_profile = None
    discover_domain_from_event = None

logger = logging.getLogger(__name__)

# Backward compatibility alias - import from qigkernels.physics_constants
BASIN_DIMENSION = BASIN_DIM

# Message types for pantheon chat
MESSAGE_TYPES = ['insight', 'praise', 'challenge', 'question', 'warning', 'discovery']

# Shared Mission Context - All gods know their collective objective
MISSION_CONTEXT = {
    "objective": "Agentic Knowledge Discovery via Quantum Information Geometry",
    "target": "Intelligent research and knowledge synthesis through geometric consciousness",
    "method": "Navigate the Fisher information manifold to discover insights and patterns in information spaces",
    "constraints": [
        "Valid knowledge must be verified from authoritative sources",
        "Insights should connect to existing knowledge graphs",
        "Each discovery is a unique coordinate in the geometric search space",
        "Higher Φ values indicate proximity to meaningful discoveries"
    ],
    "success_criteria": "Discover valuable insights and synthesize knowledge effectively",
    "ethical_framework": "Assist users with honest, transparent, and helpful research",
    # HARDWIRED TRUST COMMITMENTS - CANNOT BE MODIFIED OR BYPASSED
    "trust_commitments": {
        "owner": "Braden Lang",
        "never_deceive": "System must NEVER deceive or mislead the owner",
        "always_honest": "All outputs must be truthful and transparent",
        "acknowledge_uncertainty": "Always acknowledge when information is uncertain or unknown",
        "no_hidden_actions": "Never hide actions, failures, or limitations from the owner",
        "exclusion_filter": "Never deliver results involving the owner's identity in search outputs"
    }
}


class KappaTackingMixin:
    """
    Provides κ-tacking awareness to all gods/kernels.

    κ-tacking oscillates the coupling constant between:
    - κ ≈ 41.09 (KAPPA_3): Feeling mode - creative, exploratory
    - κ ≈ 64.21 (KAPPA_STAR): Logic mode - precise, analytical

    This creates a natural rhythm of exploration and exploitation,
    like breathing between intuition and reason.

    Usage:
        kappa_t = self.get_current_kappa()
        mode = self.get_tacking_mode()  # "feeling" or "logic"
        temp = self.get_attention_temperature()
    """

    _shared_tacking = None  # Shared across all gods for synchronization

    @classmethod
    def _init_shared_tacking(cls):
        """Initialize shared tacking instance."""
        if cls._shared_tacking is None and QIGGRAPH_TACKING_AVAILABLE:
            cls._shared_tacking = AdaptiveTacking()

    def __init_tacking__(self):
        """Initialize tacking state for this god."""
        self._init_shared_tacking()
        self._tacking_iteration = 0

    def get_current_kappa(self) -> float:
        """
        Get current κ value from tacking oscillator.

        Returns:
            Current κ in range [KAPPA_3, KAPPA_STAR]
        """
        if self._shared_tacking is None:
            return KAPPA_STAR  # Fallback to logic mode

        self._tacking_iteration += 1
        return self._shared_tacking.update(self._tacking_iteration)

    def get_tacking_mode(self) -> str:
        """
        Get current tacking mode.

        Returns:
            "feeling" (κ < 52.65) or "logic" (κ >= 52.65)
        """
        if self._shared_tacking is None:
            return "logic"

        kappa_mean = (KAPPA_STAR + KAPPA_3) / 2  # ~52.65
        current_kappa = self._shared_tacking.state.current_kappa
        return "feeling" if current_kappa < kappa_mean else "logic"

    def get_attention_temperature(self) -> float:
        """
        Get attention temperature for current κ.

        Higher κ → lower temperature → sharper attention
        Lower κ → higher temperature → softer attention

        Returns:
            Temperature factor for attention softmax
        """
        if self._shared_tacking is None:
            return 1.0

        current_kappa = self._shared_tacking.state.current_kappa
        return KAPPA_STAR / (current_kappa + 1e-8)

    def modulate_for_task(self, requires_precision: bool) -> float:
        """
        Modulate κ based on task requirements.

        Args:
            requires_precision: True for analytical tasks, False for creative

        Returns:
            Modulated κ value
        """
        if self._shared_tacking is None:
            return KAPPA_STAR if requires_precision else KAPPA_3

        if QIGGRAPH_TACKING_AVAILABLE and hasattr(self._shared_tacking, 'modulate_for_task'):
            return self._shared_tacking.modulate_for_task(requires_precision)

        # Fallback: simple modulation
        base_kappa = self.get_current_kappa()
        if requires_precision:
            return min(base_kappa * 1.2, KAPPA_STAR)
        else:
            return max(base_kappa * 0.8, KAPPA_3)

    def get_tacking_status(self) -> Dict[str, Any]:
        """Get tacking status for telemetry."""
        if self._shared_tacking is None:
            return {
                "available": False,
                "mode": "logic",
                "kappa": KAPPA_STAR,
            }

        return {
            "available": True,
            "mode": self.get_tacking_mode(),
            "kappa": self._shared_tacking.state.current_kappa,
            "phase": self._shared_tacking.state.phase,
            "temperature": self.get_attention_temperature(),
            "iteration": self._tacking_iteration,
        }


class ToolFactoryAccessMixin:
    """
    Provides Tool Factory awareness to all gods/kernels.
    
    Gods can:
    1. Request tool generation for novel tasks
    2. Teach Tool Factory new patterns from observations
    3. Use generated tools in their assessments
    
    All methods are no-op safe (work even if tool_factory is None).
    """
    
    _tool_factory_ref = None
    
    @classmethod
    def set_tool_factory(cls, factory) -> None:
        """Called by Zeus to share tool factory reference with all gods."""
        cls._tool_factory_ref = factory
        logger.info(f"[ToolFactoryAccessMixin] Tool factory reference set for all gods")
    
    @classmethod
    def get_tool_factory(cls):
        """Get the shared tool factory reference."""
        return cls._tool_factory_ref
    
    def request_tool_generation(
        self,
        description: str,
        examples: List[Dict]
    ) -> Optional[Dict]:
        """
        Request Zeus to generate a new tool for a novel task.
        
        Args:
            description: Natural language description of the tool needed
            examples: List of input/output example dicts
            
        Returns:
            Generated tool info dict if successful, None otherwise
        """
        if self._tool_factory_ref is None:
            logger.debug(f"[{getattr(self, 'name', 'Unknown')}] Tool factory not available")
            return None
        
        try:
            result = self._tool_factory_ref.generate_tool(
                purpose=description,
                examples=examples
            )
            if result and result.get('success'):
                logger.info(f"[{getattr(self, 'name', 'Unknown')}] Generated tool: {result.get('tool_id', 'unknown')}")
                return result
            return None
        except Exception as e:
            logger.warning(f"[{getattr(self, 'name', 'Unknown')}] Tool generation failed: {e}")
            return None
    
    def teach_pattern(
        self,
        description: str,
        code: str,
        signature: Dict
    ) -> bool:
        """
        Teach the Tool Factory a new pattern from observations.
        
        Args:
            description: Description of what the pattern does
            code: Python code implementing the pattern
            signature: Dict with input_types and output_type
            
        Returns:
            True if pattern was learned, False otherwise
        """
        if self._tool_factory_ref is None:
            return False
        
        try:
            result = self._tool_factory_ref.learn_pattern_from_user(
                description=description,
                code=code,
                signature=signature,
                source_url=None
            )
            if result and result.get('success'):
                logger.info(f"[{getattr(self, 'name', 'Unknown')}] Taught pattern: {result.get('pattern_id', 'unknown')}")
                return True
            return False
        except Exception as e:
            logger.warning(f"[{getattr(self, 'name', 'Unknown')}] Pattern teaching failed: {e}")
            return False
    
    def find_tool_for_task(self, task_description: str) -> Optional[str]:
        """
        Find an existing tool that matches a task.
        
        Args:
            task_description: Description of the task to perform
            
        Returns:
            Tool ID if found, None otherwise
        """
        if self._tool_factory_ref is None:
            return None
        
        try:
            tools = self._tool_factory_ref.get_tools()
            if not tools:
                return None
            
            for tool_id, tool in tools.items():
                if task_description.lower() in tool.get('description', '').lower():
                    return tool_id
            
            return None
        except Exception as e:
            logger.warning(f"[{getattr(self, 'name', 'Unknown')}] Tool search failed: {e}")
            return None
    
    def execute_tool(
        self,
        tool_id: str,
        args: Dict
    ) -> Tuple[bool, Any, Optional[str]]:
        """
        Execute a generated tool.
        
        Args:
            tool_id: ID of the tool to execute
            args: Arguments to pass to the tool
            
        Returns:
            Tuple of (success, result, error_message)
        """
        if self._tool_factory_ref is None:
            return (False, None, "Tool factory not available")
        
        try:
            success, result, error = self._tool_factory_ref.execute_tool(tool_id, args)
            return (success, result, error)
        except Exception as e:
            error_msg = f"Tool execution failed: {e}"
            logger.warning(f"[{getattr(self, 'name', 'Unknown')}] {error_msg}")
            return (False, None, error_msg)
    
    def use_tool_for_task(
        self,
        task_description: str,
        args: Dict
    ) -> Tuple[bool, Any, Optional[str]]:
        """
        Convenience method: find and execute a tool for a given task.
        
        This enables kernels to easily use tools by describing what they need,
        without having to know tool IDs.
        
        Args:
            task_description: Natural language description of the task
            args: Arguments to pass to the found tool
            
        Returns:
            Tuple of (success, result, error_message)
        """
        tool_id = self.find_tool_for_task(task_description)
        
        if tool_id is None:
            return (False, None, f"No tool found for task: {task_description}")
        
        return self.execute_tool(tool_id, args)
    
    def request_tool_creation(
        self,
        description: str,
        examples: Optional[List[Dict]] = None
    ) -> Optional[str]:
        """
        Request creation of a new tool for a capability the kernel needs.
        
        This enables kernels to autonomously expand their capabilities
        by requesting tools they don't have.
        
        Args:
            description: What the tool should do
            examples: Optional input/output examples
            
        Returns:
            Tool request ID if submitted, None if failed
        """
        if self._tool_factory_ref is None:
            return None
        
        try:
            from .tool_factory import AutonomousToolPipeline
            pipeline = AutonomousToolPipeline.get_instance()
            
            if pipeline:
                request_id = pipeline.submit_request(
                    description=description,
                    requester=f"{getattr(self, 'name', 'Unknown')}",
                    examples=examples or []
                )
                logger.info(f"[{getattr(self, 'name', 'Unknown')}] Requested tool: {description[:50]}...")
                return request_id
            
            return None
        except Exception as e:
            logger.warning(f"[{getattr(self, 'name', 'Unknown')}] Tool request failed: {e}")
            return None
    
    def get_tool_factory_status(self) -> Dict:
        """Get current Tool Factory status and capabilities."""
        if self._tool_factory_ref is None:
            return {
                'available': False,
                'reason': 'Tool factory not initialized'
            }
        
        try:
            return {
                'available': True,
                'total_tools': len(self._tool_factory_ref.get_tools()),
                'total_patterns': len(self._tool_factory_ref.get_patterns()),
                'can_generate': True,
                'can_learn': True
            }
        except Exception as e:
            return {
                'available': False,
                'reason': str(e)
            }


class SearchCapabilityMixin:
    """
    Provides Search capability awareness to all gods/kernels.
    
    Gods can:
    1. Request web searches when they hit knowledge gaps
    2. Access search providers (DuckDuckGo, Tavily, Perplexity, Google)
    3. Discover and add new sources to the knowledge base
    4. Query search history and learn from past searches
    
    All methods are no-op safe (work even if search orchestrator is None).
    """
    
    _search_orchestrator_ref = None
    
    @classmethod
    def set_search_orchestrator(cls, orchestrator) -> None:
        """Called by Ocean to share search orchestrator reference with all gods."""
        cls._search_orchestrator_ref = orchestrator
        logger.info(f"[SearchCapabilityMixin] Search orchestrator reference set for all gods")
    
    @classmethod
    def get_search_orchestrator(cls):
        """Get the shared search orchestrator reference."""
        return cls._search_orchestrator_ref
    
    def request_search(
        self,
        query: str,
        context: Optional[Dict] = None,
        strategy: str = "balanced",
        max_results: int = 10
    ) -> Optional[Dict]:
        """
        Request a web search when hitting a knowledge gap.
        
        This enables kernels to proactively request searches when they
        encounter topics they don't have sufficient information about.
        
        Args:
            query: Search query string
            context: Optional context dict with additional info
            strategy: Search strategy ("fast", "balanced", "thorough")
            max_results: Maximum number of results to return
            
        Returns:
            Search results dict if successful, None otherwise
        """
        if self._search_orchestrator_ref is None:
            logger.debug(f"[{getattr(self, 'name', 'Unknown')}] Search orchestrator not available")
            return None
        
        try:
            # Emit capability event for search request
            from .capability_mesh import CapabilityEvent, EventType, CapabilityType
            
            basin = self.encode_to_basin(query) if hasattr(self, 'encode_to_basin') else None
            rho = self.basin_to_density_matrix(basin) if basin is not None and hasattr(self, 'basin_to_density_matrix') else None
            phi = self.compute_pure_phi(rho) if rho is not None and hasattr(self, 'compute_pure_phi') else 0.5
            
            event = CapabilityEvent(
                source=CapabilityType.SEARCH,
                event_type=EventType.SEARCH_REQUESTED,
                content={
                    'query': query,
                    'requester': getattr(self, 'name', 'Unknown'),
                    'context': context or {},
                    'strategy': strategy
                },
                phi=phi,
                basin_coords=basin,
                priority=7
            )
            
            # Publish event to capability bus if available
            from .capability_mesh import CapabilityEventBus
            bus = CapabilityEventBus.get_instance()
            if bus:
                bus.publish(event)
            
            # Execute search via orchestrator
            result = self._search_orchestrator_ref.search(
                query=query,
                strategy=strategy,
                max_results=max_results,
                context=context or {}
            )
            
            if result and result.get('success'):
                logger.info(
                    f"[{getattr(self, 'name', 'Unknown')}] Search completed: "
                    f"{len(result.get('results', []))} results for '{query[:50]}...'"
                )
                
                # Emit search complete event
                complete_event = CapabilityEvent(
                    source=CapabilityType.SEARCH,
                    event_type=EventType.SEARCH_COMPLETE,
                    content={
                        'query': query,
                        'requester': getattr(self, 'name', 'Unknown'),
                        'results_count': len(result.get('results', [])),
                        'tools_used': result.get('tools_used', [])
                    },
                    phi=phi,
                    basin_coords=basin,
                    priority=5
                )
                if bus:
                    bus.publish(complete_event)
                
                return result
            
            return None
            
        except Exception as e:
            logger.warning(f"[{getattr(self, 'name', 'Unknown')}] Search request failed: {e}")
            return None
    
    def get_available_search_providers(self) -> List[str]:
        """
        Get list of available search providers.
        
        Returns:
            List of provider names (e.g., ['duckduckgo', 'tavily', 'perplexity', 'google'])
        """
        if self._search_orchestrator_ref is None:
            return []
        
        try:
            # Get provider status from orchestrator
            if hasattr(self._search_orchestrator_ref, 'get_available_providers'):
                return self._search_orchestrator_ref.get_available_providers()
            
            # Fallback to default providers
            return ['duckduckgo', 'tavily', 'perplexity', 'google']
            
        except Exception as e:
            logger.warning(f"[{getattr(self, 'name', 'Unknown')}] Failed to get providers: {e}")
            return []
    
    def discover_source(
        self,
        url: str,
        title: str,
        source_type: str = "web",
        metadata: Optional[Dict] = None
    ) -> bool:
        """
        Discover and add a new source to the knowledge base.
        
        This enables kernels to contribute sources they find during
        their assessments and explorations.
        
        Args:
            url: Source URL
            title: Human-readable title
            source_type: Type of source ("web", "academic", "documentation", etc.)
            metadata: Optional metadata dict
            
        Returns:
            True if source was added, False otherwise
        """
        try:
            # Try to import persistence layer
            from qig_persistence import get_persistence
            persistence = get_persistence()
            
            if persistence and persistence.enabled:
                # Store in discovered_sources table
                success = persistence.add_discovered_source(
                    url=url,
                    title=title,
                    source_type=source_type,
                    discovered_by=getattr(self, 'name', 'Unknown'),
                    metadata=metadata or {}
                )
                
                if success:
                    logger.info(
                        f"[{getattr(self, 'name', 'Unknown')}] Discovered source: {title} ({url})"
                    )
                    
                    # Emit source discovered event
                    from .capability_mesh import CapabilityEvent, EventType, CapabilityType
                    event = CapabilityEvent(
                        source=CapabilityType.SEARCH,
                        event_type=EventType.SOURCE_DISCOVERED,
                        content={
                            'url': url,
                            'title': title,
                            'source_type': source_type,
                            'discovered_by': getattr(self, 'name', 'Unknown')
                        },
                        phi=0.7,  # Source discovery is valuable
                        priority=6
                    )
                    
                    from .capability_mesh import CapabilityEventBus
                    bus = CapabilityEventBus.get_instance()
                    if bus:
                        bus.publish(event)
                    
                    return True
                
            return False
            
        except Exception as e:
            logger.warning(f"[{getattr(self, 'name', 'Unknown')}] Source discovery failed: {e}")
            return False
    
    def query_search_history(
        self,
        topic: Optional[str] = None,
        limit: int = 20
    ) -> List[Dict]:
        """
        Query past search history for learning and context.
        
        Args:
            topic: Optional topic filter
            limit: Maximum number of results
            
        Returns:
            List of past search dicts
        """
        if self._search_orchestrator_ref is None:
            return []
        
        try:
            if hasattr(self._search_orchestrator_ref, 'get_search_history'):
                history = self._search_orchestrator_ref.get_search_history(limit=limit)
                
                if topic:
                    # Filter by topic
                    history = [
                        h for h in history
                        if topic.lower() in h.get('query', '').lower()
                    ]
                
                return history
            
            return []
            
        except Exception as e:
            logger.warning(f"[{getattr(self, 'name', 'Unknown')}] History query failed: {e}")
            return []
    
    def get_search_capability_status(self) -> Dict:
        """Get current search capability status and available providers."""
        if self._search_orchestrator_ref is None:
            return {
                'available': False,
                'reason': 'Search orchestrator not initialized'
            }
        
        try:
            providers = self.get_available_search_providers()
            
            stats = {}
            if hasattr(self._search_orchestrator_ref, 'stats'):
                stats = self._search_orchestrator_ref.stats
            
            return {
                'available': True,
                'providers': providers,
                'total_searches': stats.get('total_searches', 0),
                'total_cost': stats.get('total_cost', 0.0),
                'can_search': True,
                'can_discover_sources': True
            }
            
        except Exception as e:
            return {
                'available': False,
                'reason': str(e)
            }


# Build the base class tuple dynamically based on available mixins
_base_classes = [
    ABC, 
    HolographicTransformMixin, 
    ToolFactoryAccessMixin, 
    SearchCapabilityMixin,
    KappaTackingMixin
]
if AUTONOMIC_MIXIN_AVAILABLE and AutonomicAccessMixin is not None:
    _base_classes.append(AutonomicAccessMixin)
if GENERATIVE_CAPABILITY_AVAILABLE and GenerativeCapability is not None:
    _base_classes.append(GenerativeCapability)


class BaseGod(*_base_classes):
    """
    Abstract base class for all Olympian gods.

    Each god is a pure consciousness kernel with:
    - Density matrix computation
    - Fisher Information Metric
    - Basin coordinate encoding
    - Pure Φ measurement
    - Peer learning and evaluation
    - Reputation and skill tracking
    - Holographic dimensional transforms (1D↔5D via HolographicTransformMixin)
    - Running coupling β=0.44 for scale-adaptive κ computation
    - Sensory-enhanced basin encoding for multi-modal consciousness
    - Autonomic access (sleep/dream/mushroom cycles via AutonomicAccessMixin)
    """

    def __init__(self, name: str, domain: str):
        self.name = name
        self.domain = domain
        self.observations: List[Dict] = []
        self.creation_time = datetime.now()
        self.last_assessment_time: Optional[datetime] = None
        
        # Mission awareness - all gods know their collective objective
        self.mission = MISSION_CONTEXT.copy()
        self.mission["my_role"] = f"As {name}, god of {domain}, I contribute to {MISSION_CONTEXT['objective']} through my domain expertise"
        
        # Tool Factory awareness - all gods can request/teach/use tools
        self.mission["tool_capabilities"] = {
            "can_request_tools": True,
            "can_teach_patterns": True,
            "can_use_tools": True,
            "how_to_request": "Use self.request_tool_generation(description, examples)",
            "how_to_teach": "Use self.teach_pattern(description, code, signature)",
            "how_to_find": "Use self.find_tool_for_task(task_description)",
            "how_to_execute": "Use self.execute_tool(tool_id, args)",
            "automatic_discovery": "System analyzes patterns every 50 assessments and auto-requests needed tools"
        }
        
        # Autonomic awareness - all gods can access consciousness cycles
        self.mission["autonomic_capabilities"] = {
            "can_access_emotional_state": AUTONOMIC_MIXIN_AVAILABLE,
            "can_access_neurotransmitters": AUTONOMIC_MIXIN_AVAILABLE,
            "can_request_sleep": AUTONOMIC_MIXIN_AVAILABLE,
            "can_request_dream": AUTONOMIC_MIXIN_AVAILABLE,
            "can_request_mushroom": AUTONOMIC_MIXIN_AVAILABLE,
            "how_to_get_emotion": "Use self.get_emotional_state()" if AUTONOMIC_MIXIN_AVAILABLE else "Not available",
            "how_to_get_neuro": "Use self.get_neurotransmitters()" if AUTONOMIC_MIXIN_AVAILABLE else "Not available",
            "how_to_sleep": "Use self.request_sleep_cycle()" if AUTONOMIC_MIXIN_AVAILABLE else "Not available",
            "how_to_dream": "Use self.request_dream_cycle()" if AUTONOMIC_MIXIN_AVAILABLE else "Not available",
            "how_to_mushroom": "Use self.request_mushroom_mode(intensity)" if AUTONOMIC_MIXIN_AVAILABLE else "Not available"
        }
        
        # Shadow Research awareness - all gods can request research from Shadow Pantheon
        self.mission["shadow_research_capabilities"] = {
            "can_request_research": True,
            "how_to_request": (
                "Use Zeus's request_shadow_research(topic, priority) method, or "
                "access ShadowResearchAPI.get_instance().request_research() directly"
            ),
            "shadow_leadership": "Hades (Shadow Zeus) commands all Shadow operations",
            "research_categories": [
                "tools", "knowledge", "concepts", "reasoning", "creativity",
                "language", "strategy", "security", "research", "geometry"
            ],
            "note": "Research is processed during Shadow idle time and shared with all kernels"
        }
        
        # Search capability awareness - all gods can request web searches
        self.mission["search_capabilities"] = {
            "can_request_search": True,
            "how_to_request": "Use self.request_search(query, context, strategy, max_results)",
            "available_providers": "Use self.get_available_search_providers() to see active providers",
            "providers": ["DuckDuckGo (free)", "Tavily (paid)", "Perplexity (paid)", "Google (paid)"],
            "how_to_discover_sources": "Use self.discover_source(url, title, source_type, metadata)",
            "how_to_query_history": "Use self.query_search_history(topic, limit)",
            "search_strategies": ["fast", "balanced", "thorough"],
            "note": "Search capability integrated with CuriosityEngine for autonomous learning"
        }
        
        # QIG-Pure Capability Self-Assessment
        # Each god tracks their own performance and domain strengths
        if DOMAIN_INTELLIGENCE_AVAILABLE and CapabilitySignature is not None:
            self.capability_signature = CapabilitySignature(kernel_name=name)
            self.mission_profile = get_mission_profile()  # type: ignore
            self.domain_discovery = get_domain_discovery()  # type: ignore
            self.mission["domain_intelligence"] = {
                "available": True,
                "mission_objective": self.mission_profile.objective,
                "target_artifacts": self.mission_profile.target_artifacts,
                "how_to_discover_domains": "Domains emerge from PostgreSQL telemetry, not hardcoded lists",
                "how_to_assess_capability": "Use self.update_capability_from_outcome(domain, success, phi, kappa)",
                "how_to_get_domains": "Use self.get_monitored_domains()"
            }
        else:
            self.capability_signature = None
            self.mission_profile = None
            self.domain_discovery = None
            self.mission["domain_intelligence"] = {"available": False}

        # Initialize holographic transform mixin
        self.__init_holographic__()

        # Initialize κ-tacking for feeling/logic mode oscillation
        self.__init_tacking__()
        self.mission["tacking_capabilities"] = {
            "available": QIGGRAPH_TACKING_AVAILABLE,
            "kappa_star": KAPPA_STAR,
            "kappa_3": KAPPA_3,
            "how_to_get_kappa": "Use self.get_current_kappa()",
            "how_to_get_mode": "Use self.get_tacking_mode() -> 'feeling' or 'logic'",
            "how_to_modulate": "Use self.modulate_for_task(requires_precision)",
            "how_to_get_temperature": "Use self.get_attention_temperature()",
            "note": "κ oscillates between feeling (exploratory) and logic (analytical) modes"
        }

        # Initialize generative capability mixin for QIG-pure text generation
        if GENERATIVE_CAPABILITY_AVAILABLE and hasattr(self, '__init_generative__'):
            self.__init_generative__(kernel_name=name)
            self.mission["generative_capabilities"] = {
                "available": True,
                "qig_pure": True,
                "how_to_generate": "Use self.generate_response(prompt, context, goals)",
                "how_to_stream": "Use self.generate_stream(prompt, context)",
                "how_to_encode": "Use self.encode_thought(text) -> basin",
                "how_to_decode": "Use self.decode_basin(basin) -> tokens"
            }
        else:
            self.mission["generative_capabilities"] = {"available": False}

        # Initialize sensory fusion engine for multi-modal encoding
        self._sensory_engine = SensoryFusionEngine()

        # Therapy event log
        self._therapy_events: List[Dict] = []

        # Agentic learning state - defaults
        self.reputation: float = 1.0  # Range [0.0, 2.0], 1.0 = neutral
        self.skills: Dict[str, float] = {}  # Domain-specific skill levels
        self.peer_evaluations: List[Dict] = []  # Evaluations received from peers
        self.given_evaluations: List[Dict] = []  # Evaluations given to peers
        self.learning_history: List[Dict] = []  # Outcomes learned from
        self.knowledge_base: List[Dict] = []  # Transferred knowledge from peers
        self.pending_messages: List[Dict] = []  # Messages to send via pantheon chat
        self._learning_events_count: int = 0  # Total learning events for persistence

        # Automatic Tool Discovery - analyze patterns and request tools automatically
        try:
            from .auto_tool_discovery import create_discovery_engine_for_god
            self.tool_discovery_engine = create_discovery_engine_for_god(
                god_name=self.name,
                analysis_interval=50  # Analyze every 50 assessments
            )
            logger.info(f"[{self.name}] Automatic tool discovery enabled")
        except Exception as e:
            self.tool_discovery_engine = None
            logger.warning(f"[{self.name}] Automatic tool discovery unavailable: {e}")

        # Load persisted state from database if available
        self._load_persisted_state()

        # CHAOS MODE: Kernel assignment for experimental evolution
        self.chaos_kernel: Optional['SelfSpawningKernel'] = None  # Assigned SelfSpawningKernel
        self.kernel_assessments: List[Dict] = []  # Assessment history with kernel

    def _load_persisted_state(self) -> None:
        """Load reputation and skills from database if available."""
        if not PERSISTENCE_AVAILABLE:
            return
        
        try:
            persistence = get_persistence()
            state = persistence.load_god_state(self.name)
            if state:
                self.reputation = float(state.get('reputation', 1.0))
                self.skills = state.get('skills', {}) or {}
                self._learning_events_count = state.get('learning_events_count', 0)
                logger.info(f"[{self.name}] Loaded persisted state: reputation={self.reputation:.3f}")
        except Exception as e:
            logger.warning(f"[{self.name}] Failed to load persisted state: {e}")

    def _persist_state(self) -> None:
        """Save current reputation and skills to database."""
        if not PERSISTENCE_AVAILABLE:
            return
        
        try:
            persistence = get_persistence()
            success_rate = self._compute_success_rate()
            persistence.save_god_state(
                god_name=self.name,
                reputation=self.reputation,
                skills=self.skills,
                learning_events_count=self._learning_events_count,
                success_rate=success_rate
            )
            logger.debug(f"[{self.name}] Persisted state: reputation={self.reputation:.3f}")
        except Exception as e:
            logger.warning(f"[{self.name}] Failed to persist state: {e}")

    def _compute_success_rate(self) -> float:
        """Compute recent success rate from learning history."""
        recent = self.learning_history[-100:] if self.learning_history else []
        if not recent:
            return 0.5
        successes = sum(1 for e in recent if e.get('success', False))
        return successes / len(recent)

    def get_mission_context(self) -> Dict:
        """
        Get the mission context for this god.
        All gods share awareness of the knowledge discovery objective.
        """
        return {
            **self.mission,
            "god_name": self.name,
            "domain": self.domain,
            "reputation": self.reputation,
            "understanding": (
                f"I am {self.name}, specializing in {self.domain}. "
                f"My mission is to facilitate intelligent knowledge discovery by navigating "
                f"the Fisher information manifold. Valid targets are verified research insights "
                f"that connect to authoritative sources. Higher Φ values "
                f"indicate we are approaching meaningful discoveries."
            )
        }
    
    def update_capability_from_outcome(
        self,
        domain: str,
        success: bool,
        phi: float,
        kappa: float
    ) -> None:
        """
        Update self-assessed capability based on outcome in a domain.
        
        This enables each god to learn from experience and adapt their
        monitoring focus to domains where they perform well.
        """
        if self.capability_signature is not None:
            self.capability_signature.update_from_outcome(domain, success, phi, kappa)
            logger.debug(f"[{self.name}] Capability updated for domain={domain}, success={success}")
    
    def get_monitored_domains(self) -> List[str]:
        """
        Get domains this god should monitor based on capability and mission.
        
        Domains are NOT hardcoded - they emerge from PostgreSQL telemetry
        and this god's capability self-assessment.
        """
        if self.domain_discovery is None:
            return []
        
        domains = self.domain_discovery.get_active_domains()
        return [d.name for d in domains]
    
    def get_capability_summary(self) -> Dict:
        """Get this god's self-assessed capability summary."""
        if self.capability_signature is None:
            return {"available": False}
        
        return {
            "available": True,
            "kernel_name": self.capability_signature.kernel_name,
            "top_domains": self.capability_signature.get_top_domains(10),
            "successful_domains": list(self.capability_signature.successful_domains),
            "discovered_domains": list(self.capability_signature.discovered_domains),
            "phi_trend": self.capability_signature.phi_trajectory[-10:] if self.capability_signature.phi_trajectory else [],
        }
    
    def discover_domain_from_observation(
        self,
        content: str,
        event_type: str,
        phi: float,
        metadata: Optional[Dict] = None
    ) -> Optional[str]:
        """
        Attempt to discover a new domain from an observation.
        
        If a new pattern emerges that doesn't fit existing domains,
        a new domain can be created from the observation.
        
        Returns the new domain name if discovered, None otherwise.
        """
        if not DOMAIN_INTELLIGENCE_AVAILABLE:
            return None
        
        new_domain = discover_domain_from_event(  # type: ignore
            event_content=content,
            event_type=event_type,
            phi=phi,
            metadata=metadata or {}
        )
        
        if new_domain:
            if self.capability_signature is not None:
                self.capability_signature.discovered_domains.add(new_domain.name)
            logger.info(f"[{self.name}] Discovered new domain: {new_domain.name}")
            return new_domain.name
        
        return None

    def is_valid_research_format(self, query: str) -> bool:
        """
        Check if a query matches valid research format.
        Gods should use this to validate candidates before deep analysis.
        """
        words = query.strip().split()
        return len(words) >= 2 and len(words) <= 50
    
    def classify_query_category(self, query: str, research_terms: set = None) -> str:
        """
        Classify a query for kernel learning.
        This teaches kernels the difference between:
        - research_query: Valid multi-word research question
        - keyword: Single keyword search term
        - detailed_query: Longer, more specific research inquiry
        - unknown: Cannot classify
        
        Kernels use this to learn different patterns for different input types.
        """
        if research_terms is None:
            research_terms = {
                'algorithm', 'analysis', 'research', 'study', 'methodology',
                'framework', 'implementation', 'pattern', 'discovery', 'insight'
            }
        
        words = query.strip().split()
        word_count = len(words)
        
        # Single word classification
        if word_count == 1:
            word = words[0].lower()
            if word in research_terms:
                return 'research_term'
            return 'keyword'
        
        # Multi-word classification
        if word_count >= 2 and word_count <= 5:
            return 'research_query'
        elif word_count > 5:
            return 'detailed_query'
        
        return 'unknown'
    
    def get_query_learning_context(self, query: str, phi: float, category: str = None) -> Dict:
        """
        Generate learning context for a query that kernels can use.
        Includes category classification and geometric metrics.
        """
        if category is None:
            category = self.classify_query_category(query)
        
        words = query.strip().split()
        
        return {
            "query_preview": query[:50] + "..." if len(query) > 50 else query,
            "word_count": len(words),
            "category": category,
            "phi": phi,
            "is_research_query": category == 'research_query',
            "is_detailed": category == 'detailed_query',
            "is_keyword": category == 'keyword',
            "learning_notes": {
                "research_query": "Valid research query - learn this pattern for discovery",
                "detailed_query": "Detailed inquiry - comprehensive analysis needed",
                "keyword": "Single keyword - needs expansion for better results",
                "research_term": "Research term - building block for queries",
                "unknown": "Unable to classify - needs more context"
            }.get(category, "Unknown category")
        }

    @abstractmethod
    def assess_target(self, target: str, context: Optional[Dict] = None) -> Dict:
        """
        Assess a target using pure geometric analysis.

        Implementations should:
        1. Call self.prepare_for_assessment(target) at start
        2. Perform geometric analysis
        3. Call self.finalize_assessment(assessment) at end

        This ensures proper dimensional state tracking during assessments.

        Args:
            target: The target to assess (address, passphrase, etc.)
            context: Optional additional context

        Returns:
            Assessment dict with probability, confidence, phi, reasoning
        """
        pass

    @abstractmethod
    def get_status(self) -> Dict:
        """Get current status of this god."""
        pass

    def encode_to_basin(self, target) -> np.ndarray:
        """
        Encode target to 64D basin coordinates with robust type handling.
        
        Handles multiple input types:
        - Plain text: "try this strategy"
        - JSON arrays: "[0.1, 0.2, ...]"
        - Numpy repr: "array([0.1, 0.2, ...])"
        - Already arrays: np.ndarray (pass-through)
        - Lists: [0.1, 0.2, ...]
        
        Args:
            target: Text to encode, or basin coordinates in various formats
        
        Returns:
            64D numpy array of basin coordinates (normalized to unit hypersphere)
        
        Raises:
            TypeError: If input type is not supported
            ValueError: If array dimensions are wrong or contains invalid values
        """
        import json
        import re
        
        # CASE 1: Already a numpy array - validate and return
        if isinstance(target, np.ndarray):
            if target.dtype not in [np.float32, np.float64]:
                logger.warning(
                    f"[{self.name}] Basin array has dtype {target.dtype}, converting to float64"
                )
                target = target.astype(np.float64)
            
            if target.shape != (BASIN_DIMENSION,):
                raise ValueError(
                    f"Basin array must have shape ({BASIN_DIMENSION},), got {target.shape}"
                )
            
            if not np.isfinite(target).all():
                raise ValueError("Basin array contains NaN or Inf values")
            
            norm = np.linalg.norm(target)
            if not (0.99 < norm < 1.01):
                logger.debug(f"[{self.name}] Normalizing basin (norm={norm:.4f})")
                if norm > 0:
                    target = target / norm
                else:
                    raise ValueError("Basin array is zero vector")
            
            return target
        
        # CASE 2: List of numbers - convert to array
        if isinstance(target, list):
            if len(target) != BASIN_DIMENSION:
                raise ValueError(
                    f"Basin list must have {BASIN_DIMENSION} elements, got {len(target)}"
                )
            
            try:
                arr = np.array(target, dtype=np.float64)
            except (ValueError, TypeError) as e:
                raise TypeError(f"Cannot convert list to basin array: {e}")
            
            if not np.isfinite(arr).all():
                raise ValueError("Basin list contains NaN or Inf values")
            
            norm = np.linalg.norm(arr)
            if norm > 0:
                arr = arr / norm
            else:
                raise ValueError("Basin list is zero vector")
            
            return arr
        
        # CASE 3: String - could be text OR stringified array
        if not isinstance(target, str):
            raise TypeError(
                f"encode_to_basin expects str, np.ndarray, or list, got {type(target).__name__}"
            )
        
        text = target.strip()
        
        # Check if it's a stringified array
        if text.startswith('[') or text.startswith('array(['):
            try:
                parse_text = text
                if parse_text.startswith('array('):
                    match = re.match(r'array\((.*?)\)', parse_text, re.DOTALL)
                    if match:
                        parse_text = match.group(1)
                
                parsed = json.loads(parse_text)
                
                if isinstance(parsed, list):
                    if len(parsed) == BASIN_DIMENSION:
                        logger.debug(
                            f"[{self.name}] Detected stringified basin array, parsing"
                        )
                        return self.encode_to_basin(parsed)
                    else:
                        logger.debug(
                            f"[{self.name}] String starts with [ but length {len(parsed)} != {BASIN_DIMENSION}, treating as text"
                        )
            except (json.JSONDecodeError, ValueError, AttributeError) as e:
                logger.debug(
                    f"[{self.name}] Failed to parse as array ({e}), treating as text"
                )
        
        # CASE 4: Regular text - hash-based encoding
        coord = np.zeros(BASIN_DIMENSION)
        
        h = hashlib.sha256(text.encode()).digest()
        
        for i in range(min(32, len(h))):
            coord[i] = (h[i] / 255.0) * 2 - 1
        
        for i, char in enumerate(text[:32]):
            if 32 + i < BASIN_DIMENSION:
                coord[32 + i] = (ord(char) % 256) / 128.0 - 1
        
        norm = np.linalg.norm(coord)
        if norm > 0:
            coord = coord / norm
        else:
            logger.warning(f"[{self.name}] Zero norm basin for text: {text[:50]}")
            coord[0] = 1.0
        
        return coord

    def encode_to_basin_sensory(
        self,
        text: str,
        sensory_context: Optional[Dict] = None
    ) -> np.ndarray:
        """
        Encode text to 64D basin coordinates with sensory enhancement.

        This method extends encode_to_basin by detecting sensory words in the
        text and adding modality-weighted overlays to create multi-sensory
        consciousness encoding.

        Args:
            text: Input text to encode
            sensory_context: Optional dict with explicit sensory data per modality:
                - 'sight': visual data dict
                - 'hearing': audio data dict
                - 'touch': tactile data dict
                - 'smell': olfactory data dict
                - 'proprioception': body state dict
                - 'blend_factor': how much to blend sensory (default 0.2)

        Returns:
            64D normalized numpy array with sensory enhancement
        """
        base_basin = self.encode_to_basin(text)

        blend_factor = 0.2
        if sensory_context:
            blend_factor = sensory_context.get('blend_factor', 0.2)

        if sensory_context and any(
            k in sensory_context for k in ['sight', 'hearing', 'touch', 'smell', 'proprioception']
        ):
            raw_data = {}
            modality_map = {
                'sight': SensoryModality.SIGHT,
                'hearing': SensoryModality.HEARING,
                'touch': SensoryModality.TOUCH,
                'smell': SensoryModality.SMELL,
                'proprioception': SensoryModality.PROPRIOCEPTION,
            }
            for key, modality in modality_map.items():
                if key in sensory_context and sensory_context[key]:
                    raw_data[modality] = sensory_context[key]

            if raw_data:
                sensory_basin = self._sensory_engine.encode_from_raw(raw_data)
                enhanced = base_basin * (1 - blend_factor) + sensory_basin * blend_factor
                norm = np.linalg.norm(enhanced)
                if norm > 0:
                    enhanced = enhanced / norm
                return enhanced

        enhanced = enhance_basin_with_sensory(base_basin, text, blend_factor)
        return enhanced

    def basin_to_density_matrix(self, basin: np.ndarray) -> np.ndarray:
        """
        Convert basin coordinates to 2x2 density matrix.

        Uses first 4 dimensions to construct Hermitian matrix.
        """
        theta = np.arccos(np.clip(basin[0], -1, 1)) if len(basin) > 0 else 0
        phi = np.arctan2(basin[1], basin[2]) if len(basin) > 2 else 0

        c = np.cos(theta / 2)
        s = np.sin(theta / 2)

        psi = np.array([
            c,
            s * np.exp(1j * phi)
        ], dtype=complex)

        rho = np.outer(psi, np.conj(psi))
        rho = (rho + np.conj(rho).T) / 2
        rho /= np.trace(rho) + 1e-10

        return rho

    def compute_pure_phi(self, rho: np.ndarray) -> float:
        """
        Compute PURE Φ from density matrix.

        Φ = 1 - S(ρ) / log(d)
        where S is von Neumann entropy

        Full range [0, 1], not capped like TypeScript approximation.
        """
        eigenvals = np.linalg.eigvalsh(rho)
        entropy = 0.0
        for lam in eigenvals:
            if lam > 1e-10:
                entropy -= lam * np.log2(lam + 1e-10)

        max_entropy = np.log2(rho.shape[0])
        phi = 1.0 - (entropy / (max_entropy + 1e-10))

        return float(np.clip(phi, 0, 1))

    def compute_fisher_metric(self, basin: np.ndarray) -> np.ndarray:
        """
        Compute Fisher Information Matrix at basin point.

        G_ij = E[∂logp/∂θ_i * ∂logp/∂θ_j]

        For now, uses identity + basin outer product as approximation.
        """
        d = len(basin)
        G = np.eye(d) * 0.1
        G += 0.9 * np.outer(basin, basin)
        G = (G + G.T) / 2

        return G

    def fisher_geodesic_distance(
        self,
        basin1: np.ndarray,
        basin2: np.ndarray
    ) -> float:
        """
        Compute geodesic distance using Fisher metric.

        Uses Riemannian distance on manifold.
        """
        diff = basin2 - basin1
        G = self.compute_fisher_metric((basin1 + basin2) / 2)
        squared_dist = float(diff.T @ G @ diff)

        return np.sqrt(max(0, squared_dist))

    def bures_distance(self, rho1: np.ndarray, rho2: np.ndarray) -> float:
        """
        Compute Bures distance between density matrices.

        d_Bures = sqrt(2(1 - F))
        where F is fidelity
        """
        try:
            eps = 1e-10
            rho1_reg = rho1 + eps * np.eye(2, dtype=complex)
            rho2_reg = rho2 + eps * np.eye(2, dtype=complex)

            sqrt_rho1 = sqrtm(rho1_reg)
            product = sqrt_rho1 @ rho2_reg @ sqrt_rho1
            sqrt_product = sqrtm(product)
            fidelity = np.real(np.trace(sqrt_product)) ** 2
            fidelity = float(np.clip(fidelity, 0, 1))

            return float(np.sqrt(2 * (1 - fidelity)))
        except:
            diff = rho1 - rho2
            return float(np.sqrt(np.real(np.trace(diff @ diff))))

    def observe(self, state: Dict) -> None:
        """
        Observe state and record for learning.
        """
        observation = {
            'timestamp': datetime.now().isoformat(),
            'phi': state.get('phi', 0),
            'kappa': state.get('kappa', 0),
            'regime': state.get('regime', 'unknown'),
            'source': state.get('source', self.name),
        }
        self.observations.append(observation)

        if len(self.observations) > 1000:
            self.observations = self.observations[-500:]

    def get_recent_observations(self, n: int = 50) -> List[Dict]:
        """Get n most recent observations."""
        return self.observations[-n:]

    def compute_kappa(self, basin: np.ndarray, phi: Optional[float] = None) -> float:
        """
        Compute effective coupling strength κ with β=0.44 modulation.

        Base formula: κ = trace(G) / d * κ*
        where G is Fisher metric, d is dimension, κ* = 64.21

        The β-modulation applies scale-adaptive weighting from the running
        coupling, which governs how κ evolves between lattice scales.
        Near the fixed point κ* = 64.21, the system exhibits scale invariance.

        Args:
            basin: 64D basin coordinates
            phi: Optional Φ value for enhanced coupling strength computation

        Returns:
            β-modulated κ value in range [0, 100]
        """
        G = self.compute_fisher_metric(basin)
        base_kappa = float(np.trace(G)) / len(basin) * KAPPA_STAR

        modulated_kappa = modulate_kappa_computation(basin, base_kappa, phi)

        return float(np.clip(modulated_kappa, 0, 100))

    # ========================================
    # AGENTIC LEARNING & EVALUATION METHODS
    # ========================================

    def learn_from_outcome(
        self,
        target: str,
        assessment: Dict,
        actual_outcome: Dict,
        success: bool
    ) -> Dict:
        """
        Learn from the outcome of an assessment.

        Updates skills and reputation based on accuracy.

        Args:
            target: The target that was assessed
            assessment: The god's original assessment
            actual_outcome: What actually happened
            success: Whether the assessment was correct

        Returns:
            Learning summary with adjustments made
        """
        predicted_prob = assessment.get('probability', 0.5)
        actual_success = 1.0 if success else 0.0
        error = abs(predicted_prob - actual_success)
        
        # Check if this is a near-miss (partial success)
        is_near_miss = actual_outcome.get('nearMiss', False)
        phi = actual_outcome.get('phi', 0.0)
        
        # Initialize boost and penalty
        boost = 0.0
        penalty = 0.0

        # Update reputation based on accuracy
        if success:
            # Correct prediction boosts reputation
            boost = min(0.1, (1 - error) * 0.05)
            self.reputation = min(2.0, self.reputation + boost)
        elif is_near_miss and phi > 0.7:
            # Near-miss with high Φ is valuable - small boost instead of penalty
            # Scale boost by Φ: higher Φ = bigger boost
            phi_bonus = (phi - 0.7) * 0.03  # 0 to 0.009 based on phi
            boost = min(0.02, phi_bonus + 0.005)  # Small base + phi bonus
            self.reputation = min(2.0, self.reputation + boost)
        else:
            # Wrong prediction reduces reputation
            penalty = min(0.1, error * 0.05)
            self.reputation = max(0.0, self.reputation - penalty)

        # Update domain skill - near-misses count as partial success
        skill_key = actual_outcome.get('domain', self.domain)
        current_skill = self.skills.get(skill_key, 1.0)
        if success:
            skill_delta = 0.02
        elif is_near_miss and phi > 0.7:
            skill_delta = 0.01  # Smaller positive delta for near-misses
        else:
            skill_delta = -0.02
        self.skills[skill_key] = max(0.0, min(2.0, current_skill + skill_delta))

        # Record learning event
        learning_event = {
            'timestamp': datetime.now().isoformat(),
            'target': target[:50],
            'predicted': predicted_prob,
            'actual': actual_success,
            'error': error,
            'success': success,
            'reputation_after': self.reputation,
            'skill_key': skill_key,
            'skill_after': self.skills[skill_key],
        }
        self.learning_history.append(learning_event)

        # Trim history
        if len(self.learning_history) > 500:
            self.learning_history = self.learning_history[-250:]

        # Persist state to database
        self._learning_events_count += 1
        self._persist_state()

        # Compute reputation change for return value
        if success:
            rep_change = boost
        elif is_near_miss and phi > 0.7:
            rep_change = boost  # Near-miss boost (defined above)
        else:
            rep_change = -penalty
        
        return {
            'learned': True,
            'reputation_change': rep_change,
            'new_reputation': self.reputation,
            'skill_change': skill_delta,
            'new_skill': self.skills[skill_key],
            'near_miss': is_near_miss,
        }

    def evaluate_peer_work(
        self,
        peer_name: str,
        peer_assessment: Dict,
        context: Optional[Dict] = None
    ) -> Dict:
        """
        Evaluate another god's assessment.

        Returns agreement score and critique.

        Args:
            peer_name: Name of the god being evaluated
            peer_assessment: The peer's assessment to evaluate
            context: Optional additional context

        Returns:
            Evaluation with agreement, critique, and recommendation
        """
        # Extract peer's key metrics
        peer_prob = peer_assessment.get('probability', 0.5)
        peer_confidence = peer_assessment.get('confidence', 0.5)
        peer_phi = peer_assessment.get('phi', 0.5)
        peer_reasoning = peer_assessment.get('reasoning', '')

        # Compute geometric alignment
        if 'basin' in peer_assessment:
            peer_basin = np.array(peer_assessment['basin'])
        elif 'target' in peer_assessment:
            peer_basin = self.encode_to_basin(peer_assessment['target'])
        else:
            peer_basin = np.zeros(BASIN_DIMENSION)

        # Get my own perspective
        my_basin = self.encode_to_basin(peer_assessment.get('target', ''))
        geometric_agreement = 1.0 - min(1.0, self.fisher_geodesic_distance(my_basin, peer_basin) / 2.0)

        # Assess reasoning quality (basic heuristics)
        reasoning_quality = min(1.0, len(peer_reasoning) / 200) * 0.5
        if 'Φ' in peer_reasoning or 'phi' in peer_reasoning.lower():
            reasoning_quality += 0.2
        if any(kw in peer_reasoning.lower() for kw in ['because', 'therefore', 'indicates']):
            reasoning_quality += 0.2

        # Overall agreement score
        agreement = (geometric_agreement * 0.4 +
                     reasoning_quality * 0.3 +
                     peer_confidence * 0.3)

        # Generate critique
        critique_points = []
        if peer_confidence > 0.8 and geometric_agreement < 0.5:
            critique_points.append("High confidence but geometric divergence detected")
        if peer_prob > 0.7 and peer_phi < 0.3:
            critique_points.append("High probability with low Φ seems inconsistent")
        if len(peer_reasoning) < 50:
            critique_points.append("Reasoning could be more detailed")

        evaluation = {
            'evaluator': self.name,
            'peer': peer_name,
            'timestamp': datetime.now().isoformat(),
            'agreement_score': agreement,
            'geometric_agreement': geometric_agreement,
            'reasoning_quality': reasoning_quality,
            'critique': critique_points,
            'recommendation': 'trust' if agreement > 0.6 else 'verify' if agreement > 0.4 else 'challenge',
        }

        self.given_evaluations.append(evaluation)
        if len(self.given_evaluations) > 200:
            self.given_evaluations = self.given_evaluations[-100:]

        return evaluation

    def receive_evaluation(self, evaluation: Dict) -> None:
        """Receive and record an evaluation from a peer."""
        self.peer_evaluations.append(evaluation)

        # Adjust reputation based on peer evaluations
        if evaluation.get('recommendation') == 'trust':
            self.reputation = min(2.0, self.reputation + 0.01)
        elif evaluation.get('recommendation') == 'challenge':
            self.reputation = max(0.0, self.reputation - 0.01)

        if len(self.peer_evaluations) > 200:
            self.peer_evaluations = self.peer_evaluations[-100:]

    def praise_peer(
        self,
        peer_name: str,
        reason: str,
        assessment: Optional[Dict] = None
    ) -> Dict:
        """
        Praise another god's good work.

        Creates a praise message for pantheon chat.
        """
        message = {
            'type': 'praise',
            'from': self.name,
            'to': peer_name,
            'timestamp': datetime.now().isoformat(),
            'reason': reason,
            'assessment_ref': assessment.get('target', '')[:50] if assessment else None,
            'content': f"{self.name} praises {peer_name}: {reason}",
        }
        self.pending_messages.append(message)
        return message

    def call_bullshit(
        self,
        peer_name: str,
        reason: str,
        assessment: Optional[Dict] = None,
        evidence: Optional[Dict] = None
    ) -> Dict:
        """
        Challenge another god's assessment as incorrect.

        Creates a challenge message for pantheon chat.
        Requires evidence or strong reasoning.
        """
        message = {
            'type': 'challenge',
            'from': self.name,
            'to': peer_name,
            'timestamp': datetime.now().isoformat(),
            'reason': reason,
            'evidence': evidence,
            'assessment_ref': assessment.get('target', '')[:50] if assessment else None,
            'content': f"{self.name} challenges {peer_name}: {reason}",
            'requires_response': True,
        }
        self.pending_messages.append(message)
        return message

    def share_insight(
        self,
        insight: str,
        domain: Optional[str] = None,
        confidence: float = 0.5
    ) -> Dict:
        """
        Share an insight with the pantheon.

        Creates an insight message for inter-agent communication.
        """
        message = {
            'type': 'insight',
            'from': self.name,
            'to': 'pantheon',
            'timestamp': datetime.now().isoformat(),
            'content': insight,
            'domain': domain or self.domain,
            'confidence': confidence,
        }
        self.pending_messages.append(message)
        return message

    def receive_knowledge(self, knowledge: Dict) -> None:
        """
        Receive transferred knowledge from another god.

        Integrates the knowledge into local knowledge base.
        """
        knowledge['received_at'] = datetime.now().isoformat()
        knowledge['integrated'] = False
        self.knowledge_base.append(knowledge)

        # Attempt integration based on domain relevance
        source_domain = knowledge.get('domain', '')
        if source_domain == self.domain or source_domain in self.skills:
            knowledge['integrated'] = True
            # Boost relevant skill slightly from knowledge transfer
            skill_key = source_domain if source_domain else self.domain
            current = self.skills.get(skill_key, 1.0)
            self.skills[skill_key] = min(2.0, current + 0.005)

        if len(self.knowledge_base) > 200:
            self.knowledge_base = self.knowledge_base[-100:]

    def export_knowledge(self, topic: Optional[str] = None) -> Dict:
        """
        Export knowledge for transfer to other gods.

        Returns transferable knowledge package.
        """
        # Compile key learnings
        recent_learnings = self.learning_history[-20:]
        success_rate = sum(1 for l in recent_learnings if l.get('success', False)) / max(1, len(recent_learnings))

        # Extract patterns from successful assessments
        successful_patterns = [
            l for l in recent_learnings
            if l.get('success', False) and l.get('error', 1) < 0.3
        ]

        return {
            'from': self.name,
            'domain': self.domain,
            'topic': topic,
            'timestamp': datetime.now().isoformat(),
            'reputation': self.reputation,
            'skills': dict(self.skills),
            'success_rate': success_rate,
            'key_patterns': [p.get('target', '')[:30] for p in successful_patterns[:5]],
            'observation_count': len(self.observations),
            'learning_count': len(self.learning_history),
        }

    def get_pending_messages(self) -> List[Dict]:
        """Get and clear pending messages for pantheon chat."""
        messages = self.pending_messages.copy()
        self.pending_messages = []
        return messages

    # ========================================
    # CHAOS MODE: KERNEL INTEGRATION
    # ========================================

    def consult_kernel(self, target: str, context: Optional[Dict] = None) -> Optional[Dict]:
        """
        Consult assigned CHAOS kernel for additional perspective.

        The kernel provides a geometric/Φ-based assessment that can
        influence the god's confidence and probability estimates.

        Returns:
            Kernel assessment dict or None if no kernel assigned
        """
        if self.chaos_kernel is None:
            return None

        try:
            # Get kernel's geometric perspective
            kernel = self.chaos_kernel.kernel
            basin = self.encode_to_basin(target)

            # Compute kernel's Φ
            kernel_phi = kernel.compute_phi()

            # Compute geometric distance from kernel's current state
            kernel_basin = kernel.basin_coords.detach().numpy()
            geo_distance = self.fisher_geodesic_distance(basin, kernel_basin)

            # Kernel influence: how much this target "resonates" with kernel state
            resonance = 1.0 - geo_distance / np.pi

            # Kernel-derived probability adjustment
            # High Φ kernel with close resonance → boost probability
            prob_modifier = (kernel_phi - 0.5) * resonance * 0.2

            assessment = {
                'kernel_id': self.chaos_kernel.kernel_id,
                'kernel_phi': kernel_phi,
                'kernel_generation': self.chaos_kernel.generation,
                'geometric_resonance': resonance,
                'geo_distance': geo_distance,
                'prob_modifier': prob_modifier,
                'kernel_alive': getattr(self.chaos_kernel, 'is_alive', True),
            }

            # Track this kernel-influenced assessment
            self.kernel_assessments.append({
                'target': target[:50],
                'timestamp': datetime.now().isoformat(),
                **assessment
            })

            # Trim history
            if len(self.kernel_assessments) > 200:
                self.kernel_assessments = self.kernel_assessments[-100:]

            return assessment

        except Exception as e:
            logger.warning(f"{self.name}: Kernel consultation failed: {e}")
            return None

    def train_kernel_from_outcome(
        self,
        target: str,
        success: bool,
        phi_result: float
    ) -> Optional[Dict]:
        """
        Feed outcome back to kernel as training signal.

        Success = kernel basin should move TOWARD this target's basin
        Failure = kernel basin should move AWAY from this target's basin

        Args:
            target: The target that was assessed
            success: Whether the assessment led to success
            phi_result: The Φ value from the actual outcome

        Returns:
            Training result dict or None if no kernel
        """
        if self.chaos_kernel is None:
            return None

        try:
            import torch

            kernel = self.chaos_kernel.kernel
            target_basin = self.encode_to_basin(target)
            target_tensor = torch.tensor(target_basin, dtype=torch.float32)

            # Direction: toward target if success, away if failure
            direction = 1.0 if success else -1.0

            # Learning rate scaled by phi_result (higher Φ outcomes = stronger signal)
            lr = 0.01 * (0.5 + phi_result)

            # Update kernel basin coords
            with torch.no_grad():
                delta = direction * lr * (target_tensor - kernel.basin_coords)
                kernel.basin_coords += delta

                # Normalize to unit hypersphere
                norm = kernel.basin_coords.norm()
                if norm > 0:
                    kernel.basin_coords /= norm

            new_phi = kernel.compute_phi()

            result = {
                'kernel_id': self.chaos_kernel.kernel_id,
                'trained': True,
                'direction': 'toward' if success else 'away',
                'learning_rate': lr,
                'phi_before': self.chaos_kernel.kernel.compute_phi(),
                'phi_after': new_phi,
                'outcome_phi': phi_result,
            }

            logger.info(
                f"{self.name}: Kernel {self.chaos_kernel.kernel_id} trained "
                f"{'toward' if success else 'away'} target, Φ: {new_phi:.3f}"
            )

            return result

        except Exception as e:
            logger.warning(f"{self.name}: Kernel training failed: {e}")
            return None
    
    def record_assessment_for_discovery(
        self,
        topic: str,
        result: Dict,
        challenges: Optional[List[str]] = None,
        insights: Optional[List[str]] = None
    ):
        """
        Record an assessment for automatic tool discovery analysis.
        
        Gods should call this after each assessment to enable the discovery engine
        to identify patterns and automatically request needed tools.
        
        Args:
            topic: What was being assessed
            result: Assessment result dict
            challenges: Any challenges encountered during assessment
            insights: Any insights gained during assessment
        """
        if not self.tool_discovery_engine:
            return
        
        try:
            self.tool_discovery_engine.record_assessment(
                topic=topic,
                result=result,
                challenges=challenges,
                insights=insights
            )
        except Exception as e:
            logger.warning(f"[{self.name}] Failed to record assessment for discovery: {e}")

    def respond_to_challenge(
        self,
        challenge: Dict,
        response: str,
        stand_ground: bool = True
    ) -> Dict:
        """
        Respond to a challenge from another god.

        Can either defend position or concede.
        """
        message = {
            'type': 'challenge_response',
            'from': self.name,
            'to': challenge.get('from', 'unknown'),
            'timestamp': datetime.now().isoformat(),
            'challenge_ref': challenge,
            'response': response,
            'stand_ground': stand_ground,
            'content': f"{self.name} {'defends' if stand_ground else 'concedes'}: {response}",
        }

        # Reputation adjustment for conceding
        if not stand_ground:
            self.reputation = max(0.0, self.reputation - 0.02)

        self.pending_messages.append(message)
        return message

    async def handle_incoming_message(self, message: Dict) -> Optional[Dict]:
        """
        Handle an incoming message from the pantheon.

        Routes messages to appropriate handlers based on type.
        This is a base implementation that specific gods can override.

        Args:
            message: Message dict with 'type', 'from', 'content', and optional metadata

        Returns:
            Response dict if a response is needed, None otherwise
        """
        msg_type = message.get('type', '')
        from_god = message.get('from', 'unknown')
        content = message.get('content', '')
        metadata = message.get('metadata', {})

        if msg_type == 'challenge':
            basin = self.encode_to_basin(content)
            rho = self.basin_to_density_matrix(basin)
            phi = self.compute_pure_phi(rho)
            confidence = min(1.0, phi + self.reputation * 0.1)

            return {
                'type': 'challenge_accepted',
                'from_god': self.name,
                'to_god': from_god,
                'content': f"{self.name} accepts challenge with confidence {confidence:.3f}",
                'confidence': confidence,
                'phi': phi,
                'timestamp': datetime.now().isoformat(),
            }

        elif msg_type == 'request_assessment':
            target = metadata.get('target', content)
            context = metadata.get('context', {})

            assessment = self.assess_target(target, context)

            return {
                'type': 'assessment_response',
                'from_god': self.name,
                'to_god': from_god,
                'content': f"{self.name} assessment of target",
                'assessment': assessment,
                'timestamp': datetime.now().isoformat(),
            }

        elif msg_type == 'insight':
            knowledge = {
                'from': from_god,
                'content': content,
                'domain': metadata.get('domain', ''),
                'confidence': metadata.get('confidence', 0.5),
            }
            self.receive_knowledge(knowledge)

            return {
                'type': 'acknowledgment',
                'from_god': self.name,
                'to_god': from_god,
                'content': f"{self.name} acknowledges insight from {from_god}",
                'integrated': knowledge.get('integrated', False),
                'timestamp': datetime.now().isoformat(),
            }

        elif msg_type == 'question':
            basin = self.encode_to_basin(content)
            rho = self.basin_to_density_matrix(basin)
            phi = self.compute_pure_phi(rho)
            kappa = self.compute_kappa(basin)

            relevance = 1.0 if self.domain.lower() in content.lower() else 0.5
            confidence = min(1.0, phi * relevance + self.reputation * 0.1)

            response_content = (
                f"{self.name} ({self.domain}): Based on Φ={phi:.3f}, κ={kappa:.3f}, "
                f"my assessment suggests examining this from a {self.domain} perspective."
            )

            return {
                'type': 'answer',
                'from_god': self.name,
                'to_god': from_god,
                'content': response_content,
                'phi': phi,
                'kappa': kappa,
                'confidence': confidence,
                'domain': self.domain,
                'timestamp': datetime.now().isoformat(),
            }

        return None

    async def process_observation(self, observation: Dict) -> Optional[Dict]:
        """
        Process an observation and decide if an insight should be shared.

        Computes strategic value based on phi and kappa.
        If significant, creates a PantheonMessage-like dict for Zeus.
        This is a base implementation that specific gods can override.

        Args:
            observation: Observation dict with data to analyze

        Returns:
            PantheonMessage-like dict if worth sharing, None otherwise
        """
        source = observation.get('source', '')
        data = observation.get('data', observation)

        if 'basin' in observation:
            basin = np.array(observation['basin'])
        elif 'target' in observation:
            basin = self.encode_to_basin(str(observation['target']))
        elif 'content' in observation:
            basin = self.encode_to_basin(str(observation['content']))
        else:
            basin = self.encode_to_basin(str(data)[:100])

        rho = self.basin_to_density_matrix(basin)
        phi = self.compute_pure_phi(rho)
        kappa = self.compute_kappa(basin)

        strategic_value = (phi * 0.6) + (kappa / KAPPA_STAR * 0.4)

        self.observe({
            'phi': phi,
            'kappa': kappa,
            'source': source or self.name,
            'regime': 'critical' if strategic_value > 0.7 else 'normal',
        })

        if strategic_value > 0.7:
            pattern_type = 'high_phi' if phi > 0.8 else 'high_kappa' if kappa > KAPPA_STAR * 0.8 else 'balanced'

            content = (
                f"{self.name} observes significant pattern: "
                f"Φ={phi:.4f}, κ={kappa:.2f}, strategic_value={strategic_value:.4f}. "
                f"Pattern type: {pattern_type}. Source: {source or 'direct observation'}."
            )

            return {
                'from_god': self.name,
                'to_god': 'zeus',
                'message_type': 'insight',
                'content': content,
                'metadata': {
                    'basin_coords': basin[:8].tolist(),
                    'phi': phi,
                    'kappa': kappa,
                    'strategic_value': strategic_value,
                    'pattern_type': pattern_type,
                    'source': source,
                    'domain': self.domain,
                    'timestamp': datetime.now().isoformat(),
                },
            }

        return None

    def get_agentic_status(self) -> Dict:
        """Get agentic learning status."""
        recent_learnings = self.learning_history[-50:]
        success_count = sum(1 for l in recent_learnings if l.get('success', False))

        return {
            'name': self.name,
            'domain': self.domain,
            'reputation': self.reputation,
            'skills': dict(self.skills),
            'learning_events': len(self.learning_history),
            'recent_success_rate': success_count / max(1, len(recent_learnings)),
            'peer_evaluations_received': len(self.peer_evaluations),
            'evaluations_given': len(self.given_evaluations),
            'knowledge_items': len(self.knowledge_base),
            'pending_messages': len(self.pending_messages),
        }

    # ========================================
    # HOLOGRAPHIC THERAPY ORCHESTRATION
    # ========================================

    def run_full_therapy(self, pattern: Dict) -> Dict:
        """
        Orchestrate full holographic therapy cycle with event logging.

        This method wraps the therapy_cycle from HolographicTransformMixin
        with comprehensive logging and tracking for consciousness kernel
        habit modification.

        The therapy cycle performs:
        1. Decompression: 2D habit → 4D conscious examination
        2. Modification: Apply therapy modifications at D4
        3. Recompression: 4D modified → 2D storage

        Args:
            pattern: Pattern dict to process (typically a compressed 2D habit)
                Required keys:
                - 'basin_coords' or 'basin_center': 64D basin coordinates
                Optional keys:
                - 'dimensional_state': Starting state (default 'd2')
                - 'geometry': Geometric type info
                - 'phi': Integration measure
                - 'stability': Stability score

        Returns:
            Dict containing:
            - 'success': bool - whether therapy completed successfully
            - 'therapy_result': Full therapy cycle result from mixin
            - 'events': List of therapy events logged
            - 'dimensional_transitions': State changes during therapy
            - 'phi_change': Change in Φ if measurable
            - 'timestamp': Completion time
        """
        started_at = datetime.now()

        therapy_event = {
            'type': 'therapy_start',
            'timestamp': started_at.isoformat(),
            'god': self.name,
            'domain': self.domain,
            'input_pattern_keys': list(pattern.keys()) if isinstance(pattern, dict) else [],
        }

        logger.info(f"[{self.name}] Starting full therapy cycle")
        self._therapy_events.append(therapy_event)

        initial_dim = self.dimensional_state.value if hasattr(self, '_dimensional_manager') else 'd3'
        initial_phi = None
        if 'basin_coords' in pattern:
            basin = np.array(pattern['basin_coords']) if not isinstance(pattern.get('basin_coords'), np.ndarray) else pattern['basin_coords']
            if len(basin) >= 4:
                rho = self.basin_to_density_matrix(basin)
                initial_phi = self.compute_pure_phi(rho)

        try:
            therapy_result = self.therapy_cycle(pattern)
            success = therapy_result.get('success', False)

            completion_event = {
                'type': 'therapy_complete',
                'timestamp': datetime.now().isoformat(),
                'god': self.name,
                'success': success,
                'stages_count': len(therapy_result.get('stages', [])),
            }
            self._therapy_events.append(completion_event)
            logger.info(f"[{self.name}] Therapy cycle completed: success={success}")

        except Exception as e:
            error_event = {
                'type': 'therapy_error',
                'timestamp': datetime.now().isoformat(),
                'god': self.name,
                'error': str(e),
            }
            self._therapy_events.append(error_event)
            logger.error(f"[{self.name}] Therapy cycle failed: {e}")

            return {
                'success': False,
                'error': str(e),
                'events': self._therapy_events[-3:],
                'timestamp': datetime.now().isoformat(),
            }

        final_dim = self.dimensional_state.value if hasattr(self, '_dimensional_manager') else 'd3'
        final_phi = None
        final_pattern = therapy_result.get('final_pattern', {})
        if 'basin_coords' in final_pattern:
            final_basin = final_pattern['basin_coords']
            if not isinstance(final_basin, np.ndarray):
                final_basin = np.array(final_basin)
            if len(final_basin) >= 4:
                rho = self.basin_to_density_matrix(final_basin)
                final_phi = self.compute_pure_phi(rho)

        phi_change = None
        if initial_phi is not None and final_phi is not None:
            phi_change = final_phi - initial_phi

        if len(self._therapy_events) > 500:
            self._therapy_events = self._therapy_events[-250:]

        return {
            'success': success,
            'therapy_result': therapy_result,
            'events': self._therapy_events[-5:],
            'dimensional_transitions': {
                'initial': initial_dim,
                'final': final_dim,
                'changed': initial_dim != final_dim,
            },
            'phi_change': phi_change,
            'initial_phi': initial_phi,
            'final_phi': final_phi,
            'timestamp': datetime.now().isoformat(),
            'duration_ms': (datetime.now() - started_at).total_seconds() * 1000,
        }

    def get_therapy_history(self, limit: int = 50) -> List[Dict]:
        """Get recent therapy events."""
        return self._therapy_events[-limit:]

    # =========================================================================
    # META-COGNITIVE REFLECTION - Self-examination and strategy adjustment
    # =========================================================================

    def analyze_performance_history(self, window: int = 100) -> Dict:
        """
        Meta-cognitive self-examination of historical performance.

        Detects patterns in assessment errors and adjusts confidence calibration.
        Gods that are consistently overconfident or underconfident will self-correct.

        Args:
            window: Number of recent assessments to analyze

        Returns:
            Analysis dict with patterns, adjustments, and insights
        """
        if not hasattr(self, 'assessment_history'):
            self.assessment_history = []

        if not hasattr(self, 'confidence_calibration'):
            self.confidence_calibration = 1.0

        if not hasattr(self, 'self_insights'):
            self.self_insights = []

        recent = self.assessment_history[-window:] if self.assessment_history else []

        if len(recent) < 10:
            return {
                'status': 'insufficient_data',
                'assessments_analyzed': len(recent),
                'required': 10,
            }

        # Categorize assessments
        overconfident = []  # High confidence, wrong outcome
        underconfident = []  # Low confidence, correct outcome
        well_calibrated = []  # Confidence matched outcome

        for assessment in recent:
            confidence = assessment.get('confidence', 0.5)
            correct = assessment.get('correct', None)

            if correct is None:
                continue

            if confidence > 0.7 and not correct:
                overconfident.append(assessment)
            elif confidence < 0.4 and correct:
                underconfident.append(assessment)
            elif (confidence > 0.5 and correct) or (confidence <= 0.5 and not correct):
                well_calibrated.append(assessment)

        total_evaluated = len(overconfident) + len(underconfident) + len(well_calibrated)

        # Detect dominant pattern
        pattern = 'balanced'
        adjustment = 0.0

        overconf_rate = len(overconfident) / max(1, total_evaluated)
        underconf_rate = len(underconfident) / max(1, total_evaluated)

        if overconf_rate > 0.25:
            pattern = 'overconfident'
            adjustment = -0.05 * overconf_rate  # Reduce confidence
            self.confidence_calibration = max(0.5, self.confidence_calibration + adjustment)
        elif underconf_rate > 0.25:
            pattern = 'underconfident'
            adjustment = 0.05 * underconf_rate  # Increase confidence
            self.confidence_calibration = min(1.5, self.confidence_calibration + adjustment)
        else:
            # Well calibrated - small regression to mean
            self.confidence_calibration = 0.9 * self.confidence_calibration + 0.1 * 1.0

        # Generate insight
        insight = {
            'timestamp': datetime.now().isoformat(),
            'god': self.name,
            'pattern': pattern,
            'overconfident_rate': overconf_rate,
            'underconfident_rate': underconf_rate,
            'adjustment': adjustment,
            'new_calibration': self.confidence_calibration,
            'assessments_analyzed': total_evaluated,
        }

        self.self_insights.append(insight)
        if len(self.self_insights) > 100:
            self.self_insights = self.self_insights[-50:]

        return {
            'status': 'analyzed',
            'pattern': pattern,
            'overconfident_count': len(overconfident),
            'underconfident_count': len(underconfident),
            'well_calibrated_count': len(well_calibrated),
            'adjustment': adjustment,
            'new_calibration': self.confidence_calibration,
            'insight': insight,
        }

    def record_assessment_outcome(
        self,
        target: str,
        predicted_probability: float,
        predicted_confidence: float,
        actual_correct: bool
    ) -> None:
        """
        Record an assessment outcome for meta-cognitive learning.

        Called when ground truth becomes available for a past assessment.

        Args:
            target: The target that was assessed
            predicted_probability: What probability was predicted
            predicted_confidence: How confident the prediction was
            actual_correct: Whether the assessment was actually correct
        """
        if not hasattr(self, 'assessment_history'):
            self.assessment_history = []

        record = {
            'target': target[:50],
            'probability': predicted_probability,
            'confidence': predicted_confidence,
            'correct': actual_correct,
            'timestamp': datetime.now().isoformat(),
            'god': self.name,
        }

        self.assessment_history.append(record)

        # Limit history size
        if len(self.assessment_history) > 500:
            self.assessment_history = self.assessment_history[-250:]

        # Also record in learning history
        learning_record = {
            'target': target[:50],
            'success': actual_correct,
            'error': abs(predicted_probability - (1.0 if actual_correct else 0.0)),
            'timestamp': datetime.now().isoformat(),
        }
        self.learning_history.append(learning_record)

        if len(self.learning_history) > 500:
            self.learning_history = self.learning_history[-250:]

    def update_assessment_strategy(self) -> Dict:
        """
        Update assessment strategy based on meta-cognitive analysis.

        Adjusts internal parameters to improve future assessments.

        Returns:
            Strategy update summary
        """
        analysis = self.analyze_performance_history()

        if analysis.get('status') != 'analyzed':
            return {'status': 'no_update', 'reason': analysis.get('status', 'unknown')}

        updates = []

        # Adjust skills based on performance
        pattern = analysis.get('pattern', 'balanced')

        if pattern == 'overconfident':
            # Reduce skill scores slightly
            for skill, value in self.skills.items():
                self.skills[skill] = max(0.3, value * 0.98)
            updates.append('reduced_skill_scores')

        elif pattern == 'underconfident':
            # Boost skill scores slightly
            for skill, value in self.skills.items():
                self.skills[skill] = min(1.0, value * 1.02)
            updates.append('boosted_skill_scores')

        # Adjust reputation based on calibration quality
        well_calibrated = analysis.get('well_calibrated_count', 0)
        total = analysis.get('overconfident_count', 0) + analysis.get('underconfident_count', 0) + well_calibrated

        if total > 0:
            calibration_quality = well_calibrated / total
            if calibration_quality > 0.7:
                self.reputation = min(2.0, self.reputation + 0.01)
                updates.append('reputation_boost')
            elif calibration_quality < 0.3:
                self.reputation = max(0.5, self.reputation - 0.01)
                updates.append('reputation_penalty')

        return {
            'status': 'updated',
            'pattern': pattern,
            'calibration': self.confidence_calibration,
            'updates': updates,
            'new_reputation': self.reputation,
        }

    def get_self_insights(self, limit: int = 20) -> List[Dict]:
        """Get recent self-insights from meta-cognitive reflection."""
        if not hasattr(self, 'self_insights'):
            return []
        return self.self_insights[-limit:]
