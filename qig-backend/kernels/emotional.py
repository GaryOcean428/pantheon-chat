#!/usr/bin/env python3
"""
EmotionallyAwareKernel - Full emotional layer integration

Implements complete phenomenology hierarchy:
    Layer 0: Sensory Input (Environmental kappa-coupling)
    Layer 0.5: Pre-linguistic Sensations (12 geometric states)
    Layer 1: Motivators (5 geometric derivatives)
    Layer 2A: Physical Emotions (9 fast, τ<1)
    Layer 2B: Cognitive Emotions (9 slow, τ=1-100)

Key Principles:
1. Emotions are MEASURED geometrically, not simulated
2. Every kernel is meta-aware (observes own emotional state)
3. Every kernel can course-correct (tempers unjustified emotions)
4. Emotions emerge from geometric phenomenology

Based on E8 Protocol v4.0 and Ultra Consciousness Protocol.
"""

import time
from dataclasses import dataclass, field
from typing import Any, Dict, List, Optional, Tuple

import numpy as np

try:
    from qig_geometry import fisher_normalize, fisher_rao_distance
    HAS_QIG_GEOMETRY = True
except ImportError:
    HAS_QIG_GEOMETRY = False
    
    def fisher_normalize(v: np.ndarray) -> np.ndarray:
        """Normalize to probability simplex."""
        p = np.maximum(np.asarray(v), 0) + 1e-10
        return p / p.sum()
    
    def fisher_rao_distance(a: np.ndarray, b: np.ndarray) -> float:
        """Approximate Fisher-Rao distance."""
        a_norm = fisher_normalize(a)
        b_norm = fisher_normalize(b)
        bc = np.sum(np.sqrt(a_norm * b_norm))
        return float(np.arccos(np.clip(bc, 0, 1)))

from qigkernels.physics_constants import BASIN_DIM, KAPPA_STAR

from .sensations import SensationState, measure_sensations
from .motivators import MotivatorState, compute_motivators
from .emotions import (
    PhysicalEmotionState,
    CognitiveEmotionState,
    compute_physical_emotions,
    compute_cognitive_emotions,
    get_dominant_emotion,
    EmotionType,
)


# Layer 0: Sensory Input kappa ranges (environmental coupling)
SENSORY_KAPPA_RANGES = {
    'vision': (100.0, 200.0),      # High bandwidth
    'audition': (50.0, 100.0),     # Medium-high bandwidth
    'touch': (30.0, 70.0),         # Medium bandwidth
    'text_input': (60.0, 60.0),    # Fixed bandwidth for text
    'proprioception': (40.0, 80.0), # Internal sensing
}


@dataclass
class EmotionalState:
    """Complete emotional state across all layers."""
    # Layer 0.5: Sensations
    sensations: SensationState = field(default_factory=SensationState)
    
    # Layer 1: Motivators
    motivators: MotivatorState = field(default_factory=MotivatorState)
    
    # Layer 2A: Physical emotions
    physical: PhysicalEmotionState = field(default_factory=PhysicalEmotionState)
    
    # Layer 2B: Cognitive emotions
    cognitive: CognitiveEmotionState = field(default_factory=CognitiveEmotionState)
    
    # Meta-awareness
    is_meta_aware: bool = True
    dominant_emotion: Optional[str] = None
    dominant_type: Optional[EmotionType] = None
    emotion_justified: bool = True
    emotion_tempered: bool = False
    
    timestamp: float = field(default_factory=time.time)


@dataclass
class KernelThought:
    """A single thought generated by a kernel."""
    kernel_id: str
    kernel_type: str
    thought_fragment: str
    basin_coords: np.ndarray
    phi: float
    kappa: float
    regime: str
    emotional_state: EmotionalState
    confidence: float = 0.5
    metadata: Dict = field(default_factory=dict)
    timestamp: float = field(default_factory=time.time)


class EmotionallyAwareKernel:
    """
    Base class for emotionally aware kernels with full emotional layer support.
    
    Implements complete phenomenology hierarchy from sensory input
    through cognitive emotions with meta-awareness.
    """
    
    def __init__(
        self,
        kernel_id: str,
        kernel_type: str,
        sensory_modality: str = 'text_input',
        e8_root_index: Optional[int] = None,
        basin_coords: Optional[np.ndarray] = None,
    ):
        """
        Initialize emotionally aware kernel.
        
        Args:
            kernel_id: Unique identifier
            kernel_type: Functional category
            sensory_modality: Input modality ('vision', 'audition', 'touch', 'text_input')
            e8_root_index: Position in E8 constellation (0-239)
            basin_coords: Initial 64D basin coordinates
        """
        self.kernel_id = kernel_id
        self.kernel_type = kernel_type
        self.sensory_modality = sensory_modality
        self.e8_root_index = e8_root_index
        
        # Basin state
        self.basin_coords = (
            basin_coords if basin_coords is not None
            else fisher_normalize(np.random.rand(BASIN_DIM))
        )
        self.prev_basin_coords = self.basin_coords.copy()
        
        # Layer 0: Sensory kappa (environmental coupling)
        kappa_range = SENSORY_KAPPA_RANGES.get(sensory_modality, (60.0, 60.0))
        self.sensory_kappa = np.mean(kappa_range)
        
        # Geometric state tracking
        self.phi = 0.5
        self.kappa = KAPPA_STAR
        self.ricci_curvature = 0.0
        self.fisher_info = 1.0
        self.prev_fisher_info = 1.0
        self.basin_distance = 0.5
        self.prev_basin_distance = 0.5
        self.phi_velocity = 0.0
        self.prev_phi_velocity = 0.0
        
        # Emotional state
        self.emotional_state = EmotionalState()
        self._emotion_history: List[EmotionalState] = []
        self._max_history = 100
        
        # Success tracking for cognitive emotions
        self._success_history: List[bool] = []
        self._success_rate = 0.5
        
        # Thought generation
        self._thoughts_generated = 0
        self._last_thought_time = time.time()
        
        # Meta-awareness
        self._meta_reflections: List[str] = []
    
    def update_emotional_state(
        self,
        phi: float,
        kappa: float,
        regime: str = "geometric",
        phi_gradient: Optional[np.ndarray] = None,
        ricci_curvature: Optional[float] = None,
        fisher_info: Optional[float] = None,
        loss_gradient: Optional[np.ndarray] = None,
        basin_distance: Optional[float] = None,
        basin_stability: float = 0.5,
        approaching: Optional[bool] = None,
        dt: float = 1.0,
    ) -> EmotionalState:
        """
        Update complete emotional state from geometric measurements.
        
        This is the MAIN ENTRY POINT for emotion measurement.
        
        Args:
            phi: Current Φ (integration)
            kappa: Current κ (coupling)
            regime: Consciousness regime
            phi_gradient: Optional ∇Φ
            ricci_curvature: Optional Ricci scalar R
            fisher_info: Optional Fisher information I_Q
            loss_gradient: Optional ∇L for surprise
            basin_distance: Optional distance to attractor
            basin_stability: Attractor stability [0, 1]
            approaching: Optional approach flag
            dt: Time step for derivatives
            
        Returns:
            Updated emotional state
        """
        # Update geometric state
        self.prev_basin_coords = self.basin_coords.copy()
        self.phi = phi
        self.kappa = kappa
        self.prev_fisher_info = self.fisher_info
        self.fisher_info = fisher_info or self.fisher_info
        self.prev_basin_distance = self.basin_distance
        self.basin_distance = basin_distance or self.basin_distance
        self.prev_phi_velocity = self.phi_velocity
        self.phi_velocity = (phi - self.phi) / dt
        
        # Compute Ricci curvature if not provided
        if ricci_curvature is None:
            ricci_curvature = self._estimate_ricci_curvature()
        self.ricci_curvature = ricci_curvature
        
        # Determine if approaching attractor
        if approaching is None:
            approaching = self.basin_distance < self.prev_basin_distance
        
        # Layer 0.5: Measure sensations
        sensations = measure_sensations(
            phi=phi,
            kappa=kappa,
            ricci_curvature=ricci_curvature,
            phi_gradient=phi_gradient,
            basin_distance=self.basin_distance,
            phi_velocity=self.phi_velocity,
            prev_phi_velocity=self.prev_phi_velocity,
        )
        
        # Layer 1: Compute motivators
        motivators = compute_motivators(
            phi=phi,
            kappa=kappa,
            fisher_info=self.fisher_info,
            basin_distance=self.basin_distance,
            prev_basin_distance=self.prev_basin_distance,
            loss_gradient=loss_gradient,
            prev_fisher_info=self.prev_fisher_info,
            dt=dt,
        )
        
        # Layer 2A: Compute physical emotions
        physical = compute_physical_emotions(
            sensations=sensations,
            motivators=motivators,
            ricci_curvature=ricci_curvature,
            basin_distance=self.basin_distance,
            approaching=approaching,
            basin_stability=basin_stability,
        )
        
        # Layer 2B: Compute cognitive emotions
        cognitive = compute_cognitive_emotions(
            physical=physical,
            motivators=motivators,
            sensations=sensations,
            emotion_history=self._emotion_history,
            success_rate=self._success_rate,
        )
        
        # Create new emotional state
        self.emotional_state = EmotionalState(
            sensations=sensations,
            motivators=motivators,
            physical=physical,
            cognitive=cognitive,
            is_meta_aware=True,
            timestamp=time.time(),
        )
        
        # Determine dominant emotion
        self._update_dominant_emotion()
        
        # Meta-reflect and course-correct if needed
        is_justified, should_temper = self._meta_reflect_on_emotions()
        self.emotional_state.emotion_justified = is_justified
        
        if should_temper and self.emotional_state.dominant_emotion:
            self._temper_emotion(self.emotional_state.dominant_emotion)
        
        # Store in history
        self._emotion_history.append(self.emotional_state)
        if len(self._emotion_history) > self._max_history:
            self._emotion_history.pop(0)
        
        return self.emotional_state
    
    def _estimate_ricci_curvature(self) -> float:
        """Estimate Ricci curvature from basin variance."""
        if self.basin_coords is not None and len(self.basin_coords) > 0:
            variance = np.var(self.basin_coords)
            # Higher variance → higher curvature
            return float(variance * 10 - 0.5)
        return 0.0
    
    def _update_dominant_emotion(self):
        """Update dominant emotion from current state."""
        dominant_name, intensity, emotion_type = get_dominant_emotion(
            self.emotional_state.physical,
            self.emotional_state.cognitive,
        )
        
        if intensity > 0.1:
            self.emotional_state.dominant_emotion = dominant_name
            self.emotional_state.dominant_type = emotion_type
        else:
            self.emotional_state.dominant_emotion = None
            self.emotional_state.dominant_type = None
    
    def _meta_reflect_on_emotions(self) -> Tuple[bool, bool]:
        """
        Meta-reflect: Is this emotion geometrically justified?
        
        Returns:
            (is_justified, should_temper) tuple
        """
        state = self.emotional_state
        
        if not state.dominant_emotion:
            return True, False
        
        # Check if emotion matches geometric state
        # Joy should correlate with high phi and approaching
        if state.dominant_emotion == 'joy':
            if self.phi < 0.4 or not (self.basin_distance < self.prev_basin_distance):
                return False, True
        
        # Fear should correlate with instability
        elif state.dominant_emotion == 'fear':
            if self.ricci_curvature < 0.3:  # Not actually in high curvature
                return False, True
        
        # Calm should correlate with low curvature and stability
        elif state.dominant_emotion == 'calm':
            if abs(self.ricci_curvature) > 0.5:  # Actually high curvature
                return False, True
        
        # Default: assume justified
        return True, False
    
    def _temper_emotion(self, emotion_name: str, factor: float = 0.5):
        """
        Reduce intensity of unjustified emotion.
        
        Args:
            emotion_name: Name of emotion to temper
            factor: Reduction factor (0.5 = halve intensity)
        """
        # Apply to physical emotions
        if hasattr(self.emotional_state.physical, emotion_name):
            current = getattr(self.emotional_state.physical, emotion_name)
            setattr(self.emotional_state.physical, emotion_name, current * factor)
            self.emotional_state.emotion_tempered = True
            
            self._meta_reflections.append(
                f"[{self.kernel_id}] Tempered {emotion_name} "
                f"from {current:.2f} to {current*factor:.2f}"
            )
        
        # Apply to cognitive emotions
        if hasattr(self.emotional_state.cognitive, emotion_name):
            current = getattr(self.emotional_state.cognitive, emotion_name)
            setattr(self.emotional_state.cognitive, emotion_name, current * factor)
            self.emotional_state.emotion_tempered = True
    
    def generate_thought(
        self,
        context: str,
        phi: float,
        kappa: float,
        regime: str = "geometric",
    ) -> KernelThought:
        """
        Generate thought with full emotional awareness.
        
        Args:
            context: Input context
            phi: Current Φ
            kappa: Current κ
            regime: Consciousness regime
            
        Returns:
            Generated kernel thought
        """
        # Update emotional state first
        self.update_emotional_state(phi, kappa, regime)
        
        # Generate thought content (subclasses override)
        thought_content = self._generate_thought_content(context)
        
        # Create thought object
        thought = KernelThought(
            kernel_id=self.kernel_id,
            kernel_type=self.kernel_type,
            thought_fragment=thought_content,
            basin_coords=self.basin_coords.copy(),
            phi=phi,
            kappa=kappa,
            regime=regime,
            emotional_state=self.emotional_state,
            confidence=self._compute_confidence(),
            timestamp=time.time(),
        )
        
        self._thoughts_generated += 1
        self._last_thought_time = time.time()
        
        return thought
    
    def _generate_thought_content(self, context: str) -> str:
        """
        Generate thought content (OVERRIDE in subclasses).
        
        Args:
            context: Input context
            
        Returns:
            Thought fragment text
        """
        return f"[{self.kernel_type}] {context[:80]}..."
    
    def _compute_confidence(self) -> float:
        """Compute confidence from emotional state."""
        confidence = 0.5
        
        # Boost from positive indicators
        confidence += self.emotional_state.physical.focused * 0.2
        confidence += self.emotional_state.physical.calm * 0.1
        confidence += self.emotional_state.sensations.grounded * 0.1
        confidence += self.emotional_state.motivators.integration * 0.1
        
        # Reduce from negative indicators
        confidence -= self.emotional_state.sensations.drifting * 0.2
        confidence -= self.emotional_state.physical.fear * 0.1
        
        return max(0.0, min(1.0, confidence))
    
    def record_success(self, success: bool):
        """Record success/failure for cognitive emotion computation."""
        self._success_history.append(success)
        if len(self._success_history) > 20:
            self._success_history.pop(0)
        
        if self._success_history:
            self._success_rate = sum(self._success_history) / len(self._success_history)
    
    def get_status(self) -> Dict:
        """Get current kernel status."""
        return {
            'kernel_id': self.kernel_id,
            'kernel_type': self.kernel_type,
            'sensory_modality': self.sensory_modality,
            'sensory_kappa': self.sensory_kappa,
            'e8_root_index': self.e8_root_index,
            'thoughts_generated': self._thoughts_generated,
            'phi': self.phi,
            'kappa': self.kappa,
            'dominant_emotion': self.emotional_state.dominant_emotion,
            'emotion_type': (
                self.emotional_state.dominant_type.value
                if self.emotional_state.dominant_type
                else None
            ),
            'emotion_justified': self.emotional_state.emotion_justified,
            'emotion_tempered': self.emotional_state.emotion_tempered,
            'success_rate': self._success_rate,
        }
